["API Reference\nAmazon Simple Storage Service\nAPI Version 2006-03-01\nCopyright \u00a9 2024 Amazon Web Services, Inc.", "and/or its a\ufb03liates.", "All rights reserved.Amazon Simple Storage Service API Reference\nAmazon Simple Storage Service: API Reference\nCopyright \u00a9 2024 Amazon Web Services, Inc.", "and/or its a\ufb03liates.", "All rights reserved.\nAmazon's trademarks and trade dress may not be used in connection with any product or service \nthat is not Amazon's, in any manner that is likely to cause confusion among customers, or in any \nmanner that disparages or discredits Amazon. All other trademarks not owned by Amazon are \nthe property of their respective owners, who may or may not be a\ufb03liated with, connected to, or \nsponsored by Amazon.Amazon Simple Storage Service API Reference\nTable of Contents\nWelcome...........................................................................................................................................1\nS3 API Reference.............................................................................................................................4\nActions............................................................................................................................................................4\nAmazon S3.............................................................................................................................................11\nAmazon S3 Control............................................................................................................................751\nAmazon S3 on Outposts.................................................................................................................1109\nData Types..............................................................................................................................................1128\nAmazon S3.........................................................................................................................................1138\nAmazon S3 Control..........................................................................................................................1383\nAmazon S3 on Outposts.................................................................................................................1594\nDeveloping with Amazon S3....................................................................................................1602\nMaking requests.....................................................................................................................................1602\nAbout access keys............................................................................................................................1603\nRequest endpoints...........................................................................................................................1605\nMaking requests over IPv6.............................................................................................................1605\nMaking requests using the AWS SDKs.........................................................................................1615\nMaking requests using the REST API...........................................................................................1655\nUsing the AWS CLI................................................................................................................................1667\nLearn more about the AWS CLI....................................................................................................1667\nDeveloping with AWS SDKs................................................................................................................1668\nSDK Programming interfaces........................................................................................................1669\nSpecifying the Signature Version in Request Authentication.................................................1669\nGet Amazon S3 request IDs for AWS Support................................................................................1678\nUsing HTTP to obtain request IDs................................................................................................1679\nUsing a web browser to obtain request IDs...............................................................................1679\nUsing the AWS SDKs to obtain request IDs................................................................................1680\nUsing the AWS CLI to obtain request IDs...................................................................................1682\nUsing Windows PowerShell to obtain request IDs....................................................................1682\nUsing AWS CloudTrail data events to obtain request IDs........................................................1682\nUsing S3 server access logging to obtain request IDs..............................................................1682\nCode examples...........................................................................................................................1683\nAmazon S3..............................................................................................................................................1687\nBasics ...................................................................................................................................................1705\nScenarios............................................................................................................................................2284\nAPI Version 2006-03-01 iiiAmazon Simple Storage Service API Reference\nServerless examples.........................................................................................................................2572\nAmazon S3 Control...............................................................................................................................2584\nBasics ...................................................................................................................................................2588\nAuthenticating Requests (AWS Signature Version 4)..............................................................2638\nAuthentication Methods .......................................................................................................................2639\nIntroduction to Signing Requests......................................................................................................2640\nUsing an Authorization Header ..........................................................................................................2641\nOverview............................................................................................................................................2642\nSignature Calculation: Transfer Payload in a Single Chunk.....................................................2646\nSignature Calculation: Transfer Payload in Multiple Chunks...................................................2663\nSignature Calculation: Including Trailing Headers.....................................................................2676\nUsing Query Parameters......................................................................................................................2682\nCalculating a Signature...................................................................................................................2685\nAn Example ........................................................................................................................................2688\nExample 2 ..........................................................................................................................................2690\nExamples: Signature Calculations......................................................................................................2691\nSignature Calculation Examples Using Java...............................................................................2691\nSignature Calculation Examples Using C#..................................................................................2693\nAuthenticating HTTP POST Requests...............................................................................................2694\nCalculating a Signature...................................................................................................................2696\nAmazon S3 Signature Version 4 Authentication Speci\ufb01c Policy Keys.........................................2697\nBucket Policy Examples Using Signature Version 4 Related Condition Keys........................2700\nBrowser-Based Uploads Using POST........................................................................................2703\nPOST Object...........................................................................................................................................2704\nDescription .........................................................................................................................................2704\nVersioning..........................................................................................................................................2705\nRequests.............................................................................................................................................2705\nExamples ............................................................................................................................................2723\nRelated Resources............................................................................................................................2724\nPOST Object restore.............................................................................................................................2725\nDescription .........................................................................................................................................2725\nQuerying Archives with Select Requests.....................................................................................2725\nRestoring Archives............................................................................................................................2727\nRequests.............................................................................................................................................2728\nResponses...........................................................................................................................................2743\nExamples ............................................................................................................................................2744\nAPI Version 2006-03-01 ivAmazon Simple Storage Service API Reference\nMore Info...........................................................................................................................................2747\nBrowser-Based Uploads Using HTTP POST.....................................................................................2747\nCalculating a Signature........................................................................................................................2749\nCreating HTML Forms...........................................................................................................................2750\nHTML Form Declaration..................................................................................................................2751\nHTML Form Fields............................................................................................................................2752\nPOST Policy............................................................................................................................................2758\nExpiration ...........................................................................................................................................2759\nCondition Matching .........................................................................................................................2759\nConditions ..........................................................................................................................................2761\nCharacter Escaping...........................................................................................................................2766\nPOST Upload Example.........................................................................................................................2767\nUploading a File to Amazon S3 Using HTTP POST...................................................................2767\nBrowser-Based Uploads Using AWS Amplify...................................................................................2770\nUsing the AWS Amplify JavaScript library to Upload Files to Amazon S3...........................2770\nMore Info...........................................................................................................................................2771\nCommon Request Headers........................................................................................................2772\nCommon Response Headers.....................................................................................................2776\nError responses ..........................................................................................................................2781\nREST error responses............................................................................................................................2782\nList of error codes.................................................................................................................................2783\nList of SELECT Object Content Error Codes.....................................................................................2807\nList of Replication-related error codes.............................................................................................2820\nList of Tagging-related error codes...................................................................................................2822\nList of Amazon S3 on Outposts error codes....................................................................................2823\nList of Amazon S3 Storage Lens error codes..................................................................................2824\nList of Amazon S3 Object Lambda error codes..............................................................................2832\nList of Amazon S3 asynchronous error codes.................................................................................2836\nList of Amazon S3 Access Grants Error Codes.................................................................................2838\nAmazon S3 error best practices.........................................................................................................2840\nRetry InternalErrors.........................................................................................................................2841\nTune application for repeated SlowDown errors.......................................................................2841\nIsolate errors.....................................................................................................................................2841\nAWS Glossary.............................................................................................................................2843\nResources....................................................................................................................................2844\nDocument History.....................................................................................................................2846\nAPI Version 2006-03-01 vAmazon Simple Storage Service API Reference\nAppendix ....................................................................................................................................2874\nAppendix: SelectObjectContent Response.......................................................................................2875\nDescription .........................................................................................................................................2875\nResponses...........................................................................................................................................2875\nRelated Resources............................................................................................................................2885\nAppendix: OPTIONS object..................................................................................................................2887\nDescription .........................................................................................................................................2887\nRequests.............................................................................................................................................2887\nResponses...........................................................................................................................................2888\nExamples ............................................................................................................................................2890\nRelated Resources............................................................................................................................2890\nAppendix: SOAP API..............................................................................................................................2891\nOperations on the Service (SOAP API)........................................................................................2891\nOperations on Buckets (SOAP API)..............................................................................................2893\nOperations on Objects (SOAP API)...............................................................................................2907\nAuthenticating SOAP requests......................................................................................................2932\nSetting access policy with SOAP...................................................................................................2934\nCommon elements ...........................................................................................................................2935\nSOAP Error Responses.....................................................................................................................2936\nAppendix: Authenticating requests (AWS signature version 2)....................................................2938\nAuthenticating requests using the REST API (AWS signature version 2)...............................2939\nSigning and authenticating REST requests (AWS signature version 2).................................2942\nBrowser-based uploads using POST (AWS signature version 2).............................................2957\nAppendix: Lifecycle Con\ufb01guration APIs (Deprecated)....................................................................2980\nPUT Bucket lifecycle (Deprecated)................................................................................................2981\nGET Bucket lifecycle (Deprecated)................................................................................................2997\nAPI Version 2006-03-01 viAmazon Simple Storage Service API Reference\nWelcome\nWelcome to the Amazon Simple Storage Service API Reference. This guide explains the Amazon \nSimple Storage Service (Amazon S3) application programming interface (API).\nYou can use any toolkit that supports HTTP to use the REST API.", "You can even use a browser to \nfetch objects, as long as they are anonymously readable.\nThe REST API uses the standard HTTP headers and status codes, so that standard browsers and \ntoolkits work as expected. In some areas, we have added functionality to HTTP (for example, we \nadded headers to support access control).", "In these cases, we have done our best to add the new \nfunctionality in a way that matched the style of standard HTTP usage.\nVersion\nThe current version of the Amazon S3 API is 2006-03-01 .\nType\nAmazon S3 supports the REST API.\nNote\nSupport for SOAP over HTTP is deprecated, but it is still available over HTTPS. However, \nnew Amazon S3 features will not be supported for SOAP. We recommend that you use \neither this REST API or the AWS SDKs at the following link:\nhttps://aws.amazon.com/developer/tools/\nThis REST API reference includes:\n\u2022S3 API Reference \u2014 which contains Actions (operations) and Data Types\n\u2022Headers  \u2014 Common Request Headers and Common Response Headers\n\u2022Error responses\n\u2022Browser-Based Uploads Using POST (AWS Signature Version 4)\nAPI Version 2006-03-01 1Amazon Simple Storage Service API Reference\nImportant\nRead the following about authentication and access control before going to speci\ufb01c API \ntopics.\nRequests to Amazon S3 can be authenticated or anonymous.", "Authenticated access requires \ncredentials that AWS can use to authenticate your requests.\nAPI call recommendations\nMaking REST API calls directly from your code can be cumbersome.", "It requires you to write the \nnecessary code to calculate a valid signature to authenticate your requests. We recommend the \nfollowing alternatives instead:\n\u2022Use the AWS SDKs to send your requests.\nAlso, see the Sample Code and Libraries .\nIf you use the SDKs, you don't need to write code to calculate a signature for request \nauthentication because the SDK clients authenticate your requests by using access keys that you \nprovide.", "Unless you have a good reason not to, you should always use the AWS SDKs.\n\u2022Use the AWS CLI to make Amazon S3 API calls. For information about setting up the AWS CLI and \nexample Amazon S3 commands see the following topics:\nSet Up the AWS CLI in the Amazon Simple Storage Service User Guide.\nUsing Amazon S3 with the AWS Command Line Interface in the AWS Command Line Interface \nUser Guide .\nMaking direct REST API calls\nNote\nThe PUT request header is limited to 8 KB in size.", "Within the PUT request header, the \nsystem-de\ufb01ned metadata is limited to 2 KB in size. The size of system-de\ufb01ned metadata is \nmeasured by taking the sum of the number of bytes in the US-ASCII encoding of each key \nand value.\nAPI Version 2006-03-01 2Amazon Simple Storage Service API Reference\nIf you'd like to make your own REST API calls instead of using one of the above alternatives, there \nare some things to keep in mind.\n\u2022To make direct REST API calls from your code, create a signature using valid credentials and \ninclude the signature in your request.", "For information about various authentication methods and \nsignature calculations, see Authenticating Requests (AWS Signature Version 4).\n\u2022The REST API uses standard HTTP headers and status codes, so standard browsers and toolkits \nwork as expected.", "In some areas, we have added functionality to HTTP (for example, we added \nheaders to support access control). In these cases, we have done our best to add the new \nfunctionality in a way that matches the style of standard HTTP usage.", "For more information \nabout making requests, see Making requests.\nPermissions\nYou can have valid credentials to authenticate your requests, but unless you have S3 permissions \nfrom the account owner or bucket owner you cannot create or access Amazon S3 resources.", "These \npermissions are typically granted through an AWS Identity and Access Management (IAM) policy, \nsuch as a bucket policy.", "For example, you must have permissions to create an S3 bucket or get an \nobject in a bucket. For a complete list of S3 permissions, see Actions, resources, and condition keys \nfor Amazon S3.\nFor more information about the permissions to S3 API operations by S3 resource types, see\nRequired permissions for Amazon S3 API operations in the Amazon Simple Storage Service User \nGuide .\nIf you use the root user credentials of your AWS account, you have all the permissions.", "However, \nusing root user credentials is not recommended.", "Instead, we recommend that you create AWS \nIdentity and Access Management (IAM) roles in your account and manage user permissions.", "For \nmore information, see Access Management in the Amazon Simple Storage Service User Guide.\nAPI Version 2006-03-01 3Amazon Simple Storage Service API Reference\nS3 API Reference\nThis section contains the Amazon S3 API Reference documentation, which includes actions\n(operations) and data types.\nThe S3 API reference groups each of its Actions and Data Types into three sets: Amazon S3 , Amazon \nS3 Control , and Amazon S3 on Outposts .", "There is no functional distinction between the three sets.", "\nIf you don't \ufb01nd an API operation or data type that you're looking for in one set, check one of the \nother sets.\nActions\n\u2022Amazon S3 \u2014 API operations that apply bucket-level and object-level actions.\n\u2022Amazon S3 Control \u2014 API operations for managing all other S3 resources.\n\u2022Amazon S3 on Outposts \u2014 API operations for use with Amazon S3 on Outposts. You \ncommunicate with your Outposts bucket using an access point and endpoint connection over a \nvirtual private cloud (VPC).\nData types\n\u2022Amazon S3 \u2014 Data types of API operations that apply bucket-level and object-level actions.\n\u2022Amazon S3 Control \u2014 Data types of API operations for managing all other S3 resources.\n\u2022Amazon S3 on Outposts \u2014 Data types of API operations for use with Amazon S3 on Outposts.\nActions\nThe following actions are supported by Amazon S3:\n\u2022AbortMultipartUpload\n\u2022CompleteMultipartUpload\n\u2022CopyObject\n\u2022CreateBucket\n\u2022CreateMultipartUpload\n\u2022CreateSession\n\u2022DeleteBucket\nActions API Version 2006-03-01 4Amazon Simple Storage Service API Reference\n\u2022DeleteBucketAnalyticsCon\ufb01guration\n\u2022DeleteBucketCors\n\u2022DeleteBucketEncryption\n\u2022DeleteBucketIntelligentTieringCon\ufb01guration\n\u2022DeleteBucketInventoryCon\ufb01guration\n\u2022DeleteBucketLifecycle\n\u2022DeleteBucketMetricsCon\ufb01guration\n\u2022DeleteBucketOwnershipControls\n\u2022DeleteBucketPolicy\n\u2022DeleteBucketReplication\n\u2022DeleteBucketTagging\n\u2022DeleteBucketWebsite\n\u2022DeleteObject\n\u2022DeleteObjects\n\u2022DeleteObjectTagging\n\u2022DeletePublicAccessBlock\n\u2022GetBucketAccelerateCon\ufb01guration\n\u2022GetBucketAcl\n\u2022GetBucketAnalyticsCon\ufb01guration\n\u2022GetBucketCors\n\u2022GetBucketEncryption\n\u2022GetBucketIntelligentTieringCon\ufb01guration\n\u2022GetBucketInventoryCon\ufb01guration\n\u2022GetBucketLifecycle\n\u2022GetBucketLifecycleCon\ufb01guration\n\u2022GetBucketLocation\n\u2022GetBucketLogging\n\u2022GetBucketMetricsCon\ufb01guration\n\u2022GetBucketNoti\ufb01cation\n\u2022GetBucketNoti\ufb01cationCon\ufb01guration\nActions API Version 2006-03-01 5Amazon Simple Storage Service API Reference\n\u2022GetBucketOwnershipControls\n\u2022GetBucketPolicy\n\u2022GetBucketPolicyStatus\n\u2022GetBucketReplication\n\u2022GetBucketRequestPayment\n\u2022GetBucketTagging\n\u2022GetBucketVersioning\n\u2022GetBucketWebsite\n\u2022GetObject\n\u2022GetObjectAcl\n\u2022GetObjectAttributes\n\u2022GetObjectLegalHold\n\u2022GetObjectLockCon\ufb01guration\n\u2022GetObjectRetention\n\u2022GetObjectTagging\n\u2022GetObjectTorrent\n\u2022GetPublicAccessBlock\n\u2022HeadBucket\n\u2022HeadObject\n\u2022ListBucketAnalyticsCon\ufb01gurations\n\u2022ListBucketIntelligentTieringCon\ufb01gurations\n\u2022ListBucketInventoryCon\ufb01gurations\n\u2022ListBucketMetricsCon\ufb01gurations\n\u2022ListBuckets\n\u2022ListDirectoryBuckets\n\u2022ListMultipartUploads\n\u2022ListObjects\n\u2022ListObjectsV2\n\u2022ListObjectVersions\n\u2022ListParts\nActions API Version 2006-03-01 6Amazon Simple Storage Service API Reference\n\u2022PutBucketAccelerateCon\ufb01guration\n\u2022PutBucketAcl\n\u2022PutBucketAnalyticsCon\ufb01guration\n\u2022PutBucketCors\n\u2022PutBucketEncryption\n\u2022PutBucketIntelligentTieringCon\ufb01guration\n\u2022PutBucketInventoryCon\ufb01guration\n\u2022PutBucketLifecycle\n\u2022PutBucketLifecycleCon\ufb01guration\n\u2022PutBucketLogging\n\u2022PutBucketMetricsCon\ufb01guration\n\u2022PutBucketNoti\ufb01cation\n\u2022PutBucketNoti\ufb01cationCon\ufb01guration\n\u2022PutBucketOwnershipControls\n\u2022PutBucketPolicy\n\u2022PutBucketReplication\n\u2022PutBucketRequestPayment\n\u2022PutBucketTagging\n\u2022PutBucketVersioning\n\u2022PutBucketWebsite\n\u2022PutObject\n\u2022PutObjectAcl\n\u2022PutObjectLegalHold\n\u2022PutObjectLockCon\ufb01guration\n\u2022PutObjectRetention\n\u2022PutObjectTagging\n\u2022PutPublicAccessBlock\n\u2022RestoreObject\n\u2022SelectObjectContent\n\u2022UploadPart\nActions API Version 2006-03-01 7Amazon Simple Storage Service API Reference\n\u2022UploadPartCopy\n\u2022WriteGetObjectResponse\nThe following actions are supported by Amazon S3 Control:\n\u2022AssociateAccessGrantsIdentityCenter\n\u2022CreateAccessGrant\n\u2022CreateAccessGrantsInstance\n\u2022CreateAccessGrantsLocation\n\u2022CreateAccessPoint\n\u2022CreateAccessPointForObjectLambda\n\u2022CreateBucket\n\u2022CreateJob\n\u2022CreateMultiRegionAccessPoint\n\u2022CreateStorageLensGroup\n\u2022DeleteAccessGrant\n\u2022DeleteAccessGrantsInstance\n\u2022DeleteAccessGrantsInstanceResourcePolicy\n\u2022DeleteAccessGrantsLocation\n\u2022DeleteAccessPoint\n\u2022DeleteAccessPointForObjectLambda\n\u2022DeleteAccessPointPolicy\n\u2022DeleteAccessPointPolicyForObjectLambda\n\u2022DeleteBucket\n\u2022DeleteBucketLifecycleCon\ufb01guration\n\u2022DeleteBucketPolicy\n\u2022DeleteBucketReplication\n\u2022DeleteBucketTagging\n\u2022DeleteJobTagging\n\u2022DeleteMultiRegionAccessPoint\n\u2022DeletePublicAccessBlock\nActions API Version 2006-03-01 8Amazon Simple Storage Service API Reference\n\u2022DeleteStorageLensCon\ufb01guration\n\u2022DeleteStorageLensCon\ufb01gurationTagging\n\u2022DeleteStorageLensGroup\n\u2022DescribeJob\n\u2022DescribeMultiRegionAccessPointOperation\n\u2022DissociateAccessGrantsIdentityCenter\n\u2022GetAccessGrant\n\u2022GetAccessGrantsInstance\n\u2022GetAccessGrantsInstanceForPre\ufb01x\n\u2022GetAccessGrantsInstanceResourcePolicy\n\u2022GetAccessGrantsLocation\n\u2022GetAccessPoint\n\u2022GetAccessPointCon\ufb01gurationForObjectLambda\n\u2022GetAccessPointForObjectLambda\n\u2022GetAccessPointPolicy\n\u2022GetAccessPointPolicyForObjectLambda\n\u2022GetAccessPointPolicyStatus\n\u2022GetAccessPointPolicyStatusForObjectLambda\n\u2022GetBucket\n\u2022GetBucketLifecycleCon\ufb01guration\n\u2022GetBucketPolicy\n\u2022GetBucketReplication\n\u2022GetBucketTagging\n\u2022GetBucketVersioning\n\u2022GetDataAccess\n\u2022GetJobTagging\n\u2022GetMultiRegionAccessPoint\n\u2022GetMultiRegionAccessPointPolicy\n\u2022GetMultiRegionAccessPointPolicyStatus\n\u2022GetMultiRegionAccessPointRoutes\nActions API Version 2006-03-01 9Amazon Simple Storage Service API Reference\n\u2022GetPublicAccessBlock\n\u2022GetStorageLensCon\ufb01guration\n\u2022GetStorageLensCon\ufb01gurationTagging\n\u2022GetStorageLensGroup\n\u2022ListAccessGrants\n\u2022ListAccessGrantsInstances\n\u2022ListAccessGrantsLocations\n\u2022ListAccessPoints\n\u2022ListAccessPointsForObjectLambda\n\u2022ListCallerAccessGrants\n\u2022ListJobs\n\u2022ListMultiRegionAccessPoints\n\u2022ListRegionalBuckets\n\u2022ListStorageLensCon\ufb01gurations\n\u2022ListStorageLensGroups\n\u2022ListTagsForResource\n\u2022PutAccessGrantsInstanceResourcePolicy\n\u2022PutAccessPointCon\ufb01gurationForObjectLambda\n\u2022PutAccessPointPolicy\n\u2022PutAccessPointPolicyForObjectLambda\n\u2022PutBucketLifecycleCon\ufb01guration\n\u2022PutBucketPolicy\n\u2022PutBucketReplication\n\u2022PutBucketTagging\n\u2022PutBucketVersioning\n\u2022PutJobTagging\n\u2022PutMultiRegionAccessPointPolicy\n\u2022PutPublicAccessBlock\n\u2022PutStorageLensCon\ufb01guration\n\u2022PutStorageLensCon\ufb01gurationTagging\nActions API Version 2006-03-01 10Amazon Simple Storage Service API Reference\n\u2022SubmitMultiRegionAccessPointRoutes\n\u2022TagResource\n\u2022UntagResource\n\u2022UpdateAccessGrantsLocation\n\u2022UpdateJobPriority\n\u2022UpdateJobStatus\n\u2022UpdateStorageLensGroup\nThe following actions are supported by Amazon S3 on Outposts:\n\u2022CreateEndpoint\n\u2022DeleteEndpoint\n\u2022ListEndpoints\n\u2022ListOutpostsWithS3\n\u2022ListSharedEndpoints\nAmazon S3\nThe following actions are supported by Amazon S3:\n\u2022AbortMultipartUpload\n\u2022CompleteMultipartUpload\n\u2022CopyObject\n\u2022CreateBucket\n\u2022CreateMultipartUpload\n\u2022CreateSession\n\u2022DeleteBucket\n\u2022DeleteBucketAnalyticsCon\ufb01guration\n\u2022DeleteBucketCors\n\u2022DeleteBucketEncryption\n\u2022DeleteBucketIntelligentTieringCon\ufb01guration\n\u2022DeleteBucketInventoryCon\ufb01guration\nAmazon S3 API Version 2006-03-01 11Amazon Simple Storage Service API Reference\n\u2022DeleteBucketLifecycle\n\u2022DeleteBucketMetricsCon\ufb01guration\n\u2022DeleteBucketOwnershipControls\n\u2022DeleteBucketPolicy\n\u2022DeleteBucketReplication\n\u2022DeleteBucketTagging\n\u2022DeleteBucketWebsite\n\u2022DeleteObject\n\u2022DeleteObjects\n\u2022DeleteObjectTagging\n\u2022DeletePublicAccessBlock\n\u2022GetBucketAccelerateCon\ufb01guration\n\u2022GetBucketAcl\n\u2022GetBucketAnalyticsCon\ufb01guration\n\u2022GetBucketCors\n\u2022GetBucketEncryption\n\u2022GetBucketIntelligentTieringCon\ufb01guration\n\u2022GetBucketInventoryCon\ufb01guration\n\u2022GetBucketLifecycle\n\u2022GetBucketLifecycleCon\ufb01guration\n\u2022GetBucketLocation\n\u2022GetBucketLogging\n\u2022GetBucketMetricsCon\ufb01guration\n\u2022GetBucketNoti\ufb01cation\n\u2022GetBucketNoti\ufb01cationCon\ufb01guration\n\u2022GetBucketOwnershipControls\n\u2022GetBucketPolicy\n\u2022GetBucketPolicyStatus\n\u2022GetBucketReplication\n\u2022GetBucketRequestPayment\nAmazon S3 API Version 2006-03-01 12Amazon Simple Storage Service API Reference\n\u2022GetBucketTagging\n\u2022GetBucketVersioning\n\u2022GetBucketWebsite\n\u2022GetObject\n\u2022GetObjectAcl\n\u2022GetObjectAttributes\n\u2022GetObjectLegalHold\n\u2022GetObjectLockCon\ufb01guration\n\u2022GetObjectRetention\n\u2022GetObjectTagging\n\u2022GetObjectTorrent\n\u2022GetPublicAccessBlock\n\u2022HeadBucket\n\u2022HeadObject\n\u2022ListBucketAnalyticsCon\ufb01gurations\n\u2022ListBucketIntelligentTieringCon\ufb01gurations\n\u2022ListBucketInventoryCon\ufb01gurations\n\u2022ListBucketMetricsCon\ufb01gurations\n\u2022ListBuckets\n\u2022ListDirectoryBuckets\n\u2022ListMultipartUploads\n\u2022ListObjects\n\u2022ListObjectsV2\n\u2022ListObjectVersions\n\u2022ListParts\n\u2022PutBucketAccelerateCon\ufb01guration\n\u2022PutBucketAcl\n\u2022PutBucketAnalyticsCon\ufb01guration\n\u2022PutBucketCors\n\u2022PutBucketEncryption\nAmazon S3 API Version 2006-03-01 13Amazon Simple Storage Service API Reference\n\u2022PutBucketIntelligentTieringCon\ufb01guration\n\u2022PutBucketInventoryCon\ufb01guration\n\u2022PutBucketLifecycle\n\u2022PutBucketLifecycleCon\ufb01guration\n\u2022PutBucketLogging\n\u2022PutBucketMetricsCon\ufb01guration\n\u2022PutBucketNoti\ufb01cation\n\u2022PutBucketNoti\ufb01cationCon\ufb01guration\n\u2022PutBucketOwnershipControls\n\u2022PutBucketPolicy\n\u2022PutBucketReplication\n\u2022PutBucketRequestPayment\n\u2022PutBucketTagging\n\u2022PutBucketVersioning\n\u2022PutBucketWebsite\n\u2022PutObject\n\u2022PutObjectAcl\n\u2022PutObjectLegalHold\n\u2022PutObjectLockCon\ufb01guration\n\u2022PutObjectRetention\n\u2022PutObjectTagging\n\u2022PutPublicAccessBlock\n\u2022RestoreObject\n\u2022SelectObjectContent\n\u2022UploadPart\n\u2022UploadPartCopy\n\u2022WriteGetObjectResponse\nAmazon S3 API Version 2006-03-01 14Amazon Simple Storage Service API Reference\nAbortMultipartUpload\nService: Amazon S3\nThis operation aborts a multipart upload.", "After a multipart upload is aborted, no additional parts \ncan be uploaded using that upload ID. The storage consumed by any previously uploaded parts will \nbe freed. However, if any part uploads are currently in progress, those part uploads might or might \nnot succeed. As a result, it might be necessary to abort a given multipart upload multiple times in \norder to completely free all storage consumed by all parts.\nTo verify that all parts have been removed and prevent getting charged for the part storage, you \nshould call the ListParts API operation and ensure that the parts list is empty.\nNote\n\u2022Directory buckets - If multipart uploads in a directory bucket are in progress, you can't \ndelete the bucket until all the in-progress multipart uploads are aborted or completed. \nTo delete these in-progress multipart uploads, use the ListMultipartUploads\noperation to list the in-progress multipart uploads in the bucket and use the\nAbortMultipartUpload  operation to abort all the in-progress multipart uploads.\n\u2022Directory buckets - For directory buckets, you must make requests for this API operation \nto the Zonal endpoint.", "These endpoints support virtual-hosted-style requests in the \nformat https:// bucket_name .s3express- az_id.region.amazonaws.com/ key-\nname .", "Path-style requests are not supported.", "For more information, see Regional and \nZonal endpoints in the Amazon S3 User Guide .\nPermissions\n\u2022General purpose bucket permissions - For information about permissions required to use the \nmultipart upload, see Multipart Upload and Permissions in the Amazon S3 User Guide .\n\u2022Directory bucket permissions - To grant access to this API operation on a directory \nbucket, we recommend that you use the CreateSession  API operation for session-based \nauthorization. Speci\ufb01cally, you grant the s3express:CreateSession  permission to the \ndirectory bucket in a bucket policy or an IAM identity-based policy.", "Then, you make the\nCreateSession  API call on the bucket to obtain a session token. With the session token in \nyour request header, you can make API requests to this operation. After the session token \nexpires, you make another CreateSession  API call to generate a new session token for \nuse.", "AWS CLI or SDKs create session and refresh the session token automatically to avoid \nAmazon S3 API Version 2006-03-01 15Amazon Simple Storage Service API Reference\nservice interruptions when a session expires. For more information about authorization, see\nCreateSession .\nHTTP Host header syntax\nDirectory buckets  - The HTTP Host header syntax is \nBucket_name .s3express- az_id.region.amazonaws.com .\nThe following operations are related to AbortMultipartUpload :\n\u2022CreateMultipartUpload\n\u2022UploadPart\n\u2022CompleteMultipartUpload\n\u2022ListParts\n\u2022ListMultipartUploads\nRequest Syntax\nDELETE / Key+?uploadId= UploadId  HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-request-payer: RequestPayer\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe bucket name to which the upload was taking place.\nDirectory buckets - When you use this operation with a directory \nbucket, you must use virtual-hosted-style requests in the format \nBucket_name .s3express- az_id.region.amazonaws.com .", "Path-style requests are not \nsupported.", "Directory bucket names must be unique in the chosen Availability Zone.", "Bucket \nnames must follow the format  bucket_base_name --az-id--x-s3  (for example,  DOC-\nEXAMPLE-BUCKET --usw2-az1 --x-s3). For information about bucket naming restrictions, see\nDirectory bucket naming rules in the Amazon S3 User Guide .\nAmazon S3 API Version 2006-03-01 16Amazon Simple Storage Service API Reference\nAccess points - When you use this action with an access point, you must provide the alias of the \naccess point in place of the bucket name or specify the access point ARN.", "When using the access \npoint ARN, you must direct requests to the access point hostname.", "The access point hostname \ntakes the form AccessPointName-AccountId .s3-accesspoint.Region.amazonaws.com.", "When using \nthis action with an access point through the AWS SDKs, you provide the access point ARN in \nplace of the bucket name. For more information about access point ARNs, see Using access \npoints  in the Amazon S3 User Guide .\nNote\nAccess points and Object Lambda access points are not supported by directory buckets.\nS3 on Outposts  - When you use this action with Amazon S3 on Outposts, you must direct \nrequests to the S3 on Outposts hostname. The S3 on Outposts hostname takes the form \nAccessPointName -AccountId .outpostID .s3-outposts.", "Region.amazonaws.com .", "\nWhen you use this action with S3 on Outposts through the AWS SDKs, you provide the Outposts \naccess point ARN in place of the bucket name. For more information about S3 on Outposts \nARNs, see What is S3 on Outposts?", "in the Amazon S3 User Guide .\nRequired: Yes\nKey\nKey of the object for which the multipart upload was initiated.\nLength Constraints: Minimum length of 1.\nRequired: Yes\nuploadId\nUpload ID that identi\ufb01es the multipart upload.\nRequired: Yes\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match \nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nAmazon S3 API Version 2006-03-01 17Amazon Simple Storage Service API Reference\nx-amz-request-payer\nCon\ufb01rms that the requester knows that they will be charged for the request. Bucket owners \nneed not specify this parameter in their requests.", "If either the source or destination S3 \nbucket has Requester Pays enabled, the requester will pay for corresponding charges to copy \nthe object. For information about downloading objects from Requester Pays buckets, see\nDownloading Objects in Requester Pays Buckets in the Amazon S3 User Guide .\nNote\nThis functionality is not supported for directory buckets.\nValid Values: requester\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 204\nx-amz-request-charged: RequestCharged\nResponse Elements\nIf the action is successful, the service sends back an HTTP 204 response.\nThe response returns the following HTTP headers.\nx-amz-request-charged\nIf present, indicates that the requester was successfully charged for the request.\nNote\nThis functionality is not supported for directory buckets.\nValid Values: requester\nAmazon S3 API Version 2006-03-01 18Amazon Simple Storage Service API Reference\nErrors\nNoSuchUpload\nThe speci\ufb01ed multipart upload does not exist.\nHTTP Status Code: 404\nExamples\nSample Request for general purpose buckets\nThe following request aborts a multipart upload identi\ufb01ed by its upload ID.\n               DELETE /example-object?\nuploadId=VXBsb2FkIElEIGZvciBlbHZpbmcncyBteS1tb3ZpZS5tMnRzIHVwbG9hZ HTTP/1.1 \n               Host: example-bucket.s3.<Region>.amazonaws.com \n               Date:  Mon, 1 Nov 2010 20:34:56 GMT \n               Authorization: authorization string \n             \nSample Response for general purpose buckets\nThis example illustrates one usage of AbortMultipartUpload.\n               HTTP/1.1 204 OK \n               x-amz-id-2: Weag1LuByRx9e6j5Onimru9pO4ZVKnJ2Qz7/C1NPcfTWAtRPfTaOFg== \n               x-amz-request-id: 996c76696e6727732072657175657374 \n               Date:  Mon, 1 Nov 2010 20:34:56 GMT \n               Content-Length: 0 \n               Connection: keep-alive \n               Server: AmazonS3 \n             \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\nAmazon S3 API Version 2006-03-01 19Amazon Simple Storage Service API Reference\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 20Amazon Simple Storage Service API Reference\nCompleteMultipartUpload\nService: Amazon S3\nCompletes a multipart upload by assembling previously uploaded parts.\nYou \ufb01rst initiate the multipart upload and then upload all parts using the UploadPart operation \nor the UploadPartCopy operation.", "After successfully uploading all relevant parts of an upload, \nyou call this CompleteMultipartUpload  operation to complete the upload.", "Upon receiving this \nrequest, Amazon S3 concatenates all the parts in ascending order by part number to create a new \nobject.", "In the CompleteMultipartUpload request, you must provide the parts list and ensure that \nthe parts list is complete. The CompleteMultipartUpload API operation concatenates the parts that \nyou provide in the list. For each part in the list, you must provide the PartNumber  value and the\nETag value that are returned after that part was uploaded.\nThe processing of a CompleteMultipartUpload request could take several minutes to \ufb01nalize.", "After \nAmazon S3 begins processing the request, it sends an HTTP response header that speci\ufb01es a 200 \nOK response. While processing is in progress, Amazon S3 periodically sends white space characters \nto keep the connection from timing out.", "A request could fail after the initial 200 OK response has \nbeen sent. This means that a 200 OK response can contain either a success or an error. The error \nresponse might be embedded in the 200 OK response. If you call this API operation directly, make \nsure to design your application to parse the contents of the response and handle it appropriately.", "\nIf you use AWS SDKs, SDKs handle this condition. The SDKs detect the embedded error and apply \nerror handling per your con\ufb01guration settings (including automatically retrying the request as \nappropriate). If the condition persists, the SDKs throw an exception (or, for the SDKs that don't use \nexceptions, they return an error).\nNote that if CompleteMultipartUpload  fails, applications should be prepared to retry any \nfailed requests (including 500 error responses).", "For more information, see Amazon S3 Error Best \nPractices.\nImportant\nYou can't use Content-Type: application/x-www-form-urlencoded  for the \nCompleteMultipartUpload requests. Also, if you don't provide a Content-Type  header,\nCompleteMultipartUpload  can still return a 200 OK response.\nFor more information about multipart uploads, see Uploading Objects Using Multipart Upload in \nthe Amazon S3 User Guide .\nAmazon S3 API Version 2006-03-01 21Amazon Simple Storage Service API Reference\nNote\nDirectory buckets - For directory buckets, you must make requests for this API operation \nto the Zonal endpoint. These endpoints support virtual-hosted-style requests in the format\nhttps:// bucket_name .s3express- az_id.region.amazonaws.com/ key-name\n.", "Path-style requests are not supported.", "For more information, see Regional and Zonal \nendpoints  in the Amazon S3 User Guide .\nPermissions\n\u2022General purpose bucket permissions - For information about permissions required to use the \nmultipart upload API, see Multipart Upload and Permissions in the Amazon S3 User Guide .\nIf you provide an additional checksum value  in your MultipartUpload  requests and the \nobject is encrypted with AWS Key Management Service, you must have permission to use the\nkms:Decrypt  action for the CompleteMultipartUpload  request to succeed.\n\u2022Directory bucket permissions - To grant access to this API operation on a directory \nbucket, we recommend that you use the CreateSession  API operation for session-based \nauthorization. Speci\ufb01cally, you grant the s3express:CreateSession  permission to the \ndirectory bucket in a bucket policy or an IAM identity-based policy.", "Then, you make the\nCreateSession  API call on the bucket to obtain a session token. With the session token in \nyour request header, you can make API requests to this operation. After the session token \nexpires, you make another CreateSession  API call to generate a new session token for \nuse. AWS CLI or SDKs create session and refresh the session token automatically to avoid \nservice interruptions when a session expires.", "For more information about authorization, see\nCreateSession .\nIf the object is encrypted with SSE-KMS, you must also have the kms:GenerateDataKey  and\nkms:Decrypt  permissions in IAM identity-based policies and AWS KMS key policies for the \nAWS KMS key.\nSpecial errors\n\u2022Error Code: EntityTooSmall\n\u2022Description: Your proposed upload is smaller than the minimum allowed object size.", "Each \npart must be at least 5 MB in size, except the last part.\n\u2022HTTP Status Code: 400 Bad Request\n\u2022Error Code: InvalidPart\nAmazon S3 API Version 2006-03-01 22Amazon Simple Storage Service API Reference\n\u2022Description: One or more of the speci\ufb01ed parts could not be found.", "The part might not \nhave been uploaded, or the speci\ufb01ed ETag might not have matched the uploaded part's \nETag.\n\u2022HTTP Status Code: 400 Bad Request\n\u2022Error Code: InvalidPartOrder\n\u2022Description: The list of parts was not in ascending order. The parts list must be speci\ufb01ed in \norder by part number.\n\u2022HTTP Status Code: 400 Bad Request\n\u2022Error Code: NoSuchUpload\n\u2022Description: The speci\ufb01ed multipart upload does not exist. The upload ID might be invalid, \nor the multipart upload might have been aborted or completed.\n\u2022HTTP Status Code: 404 Not Found\nHTTP Host header syntax\nDirectory buckets  - The HTTP Host header syntax is \nBucket_name .s3express- az_id.region.amazonaws.com .\nThe following operations are related to CompleteMultipartUpload :\n\u2022CreateMultipartUpload\n\u2022UploadPart\n\u2022AbortMultipartUpload\n\u2022ListParts\n\u2022ListMultipartUploads\nRequest Syntax\nPOST /Key+?uploadId= UploadId  HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-checksum-crc32: ChecksumCRC32\nx-amz-checksum-crc32c: ChecksumCRC32C\nx-amz-checksum-sha1: ChecksumSHA1\nx-amz-checksum-sha256: ChecksumSHA256\nx-amz-request-payer: RequestPayer\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nAmazon S3 API Version 2006-03-01 23Amazon Simple Storage Service API Reference\nIf-None-Match: IfNoneMatch\nx-amz-server-side-encryption-customer-algorithm: SSECustomerAlgorithm\nx-amz-server-side-encryption-customer-key: SSECustomerKey\nx-amz-server-side-encryption-customer-key-MD5: SSECustomerKeyMD5\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<CompleteMultipartUpload  xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n   <Part> \n      <ChecksumCRC32 >string</ChecksumCRC32 > \n      <ChecksumCRC32C >string</ChecksumCRC32C > \n      <ChecksumSHA1 >string</ChecksumSHA1 > \n      <ChecksumSHA256 >string</ChecksumSHA256 > \n      <ETag>string</ETag> \n      <PartNumber >integer</PartNumber > \n   </Part> \n   ...\n</CompleteMultipartUpload >\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nName of the bucket to which the multipart upload was initiated.\nDirectory buckets - When you use this operation with a directory \nbucket, you must use virtual-hosted-style requests in the format \nBucket_name .s3express- az_id.region.amazonaws.com .", "Path-style requests are not \nsupported.", "Directory bucket names must be unique in the chosen Availability Zone.", "Bucket \nnames must follow the format  bucket_base_name --az-id--x-s3  (for example,  DOC-\nEXAMPLE-BUCKET --usw2-az1 --x-s3). For information about bucket naming restrictions, see\nDirectory bucket naming rules in the Amazon S3 User Guide .\nAccess points - When you use this action with an access point, you must provide the alias of the \naccess point in place of the bucket name or specify the access point ARN.", "When using the access \npoint ARN, you must direct requests to the access point hostname.", "The access point hostname \ntakes the form AccessPointName-AccountId .s3-accesspoint.Region.amazonaws.com.", "When using \nthis action with an access point through the AWS SDKs, you provide the access point ARN in \nplace of the bucket name. For more information about access point ARNs, see Using access \npoints  in the Amazon S3 User Guide .\nAmazon S3 API Version 2006-03-01 24Amazon Simple Storage Service API Reference\nNote\nAccess points and Object Lambda access points are not supported by directory buckets.\nS3 on Outposts  - When you use this action with Amazon S3 on Outposts, you must direct \nrequests to the S3 on Outposts hostname. The S3 on Outposts hostname takes the form \nAccessPointName -AccountId .outpostID .s3-outposts.", "Region.amazonaws.com .", "\nWhen you use this action with S3 on Outposts through the AWS SDKs, you provide the Outposts \naccess point ARN in place of the bucket name. For more information about S3 on Outposts \nARNs, see What is S3 on Outposts?", "in the Amazon S3 User Guide .\nRequired: Yes\nIf-None-Match\nUploads the object only if the object key name does not already exist in the bucket speci\ufb01ed. \nOtherwise, Amazon S3 returns a 412 Precondition Failed  error.\nIf a con\ufb02icting operation occurs during the upload S3 returns a 409 \nConditionalRequestConflict  response. On a 409 failure you should re-initiate the \nmultipart upload with CreateMultipartUpload  and re-upload each part.\nExpects the '*' (asterisk) character.\nFor more information about conditional requests, see RFC 7232, or Conditional requests in the\nAmazon S3 User Guide .\nKey\nObject key for which the multipart upload was initiated.\nLength Constraints: Minimum length of 1.\nRequired: Yes\nuploadId\nID for the initiated multipart upload.\nRequired: Yes\nAmazon S3 API Version 2006-03-01 25Amazon Simple Storage Service API Reference\nx-amz-checksum-crc32\nThis header can be used as a data integrity check to verify that the data received is the same \ndata that was originally sent.", "This header speci\ufb01es the base64-encoded, 32-bit CRC-32 \nchecksum of the object.", "For more information, see Checking object integrity in the Amazon S3 \nUser Guide .\nx-amz-checksum-crc32c\nThis header can be used as a data integrity check to verify that the data received is the same \ndata that was originally sent.", "This header speci\ufb01es the base64-encoded, 32-bit CRC-32C \nchecksum of the object.", "For more information, see Checking object integrity in the Amazon S3 \nUser Guide .\nx-amz-checksum-sha1\nThis header can be used as a data integrity check to verify that the data received is the same \ndata that was originally sent.", "This header speci\ufb01es the base64-encoded, 160-bit SHA-1 digest \nof the object.", "For more information, see Checking object integrity in the Amazon S3 User Guide .\nx-amz-checksum-sha256\nThis header can be used as a data integrity check to verify that the data received is the same \ndata that was originally sent.", "This header speci\ufb01es the base64-encoded, 256-bit SHA-256 digest \nof the object.", "For more information, see Checking object integrity in the Amazon S3 User Guide .\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner.", "If the account ID that you provide does not match \nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nx-amz-request-payer\nCon\ufb01rms that the requester knows that they will be charged for the request. Bucket owners \nneed not specify this parameter in their requests.", "If either the source or destination S3 \nbucket has Requester Pays enabled, the requester will pay for corresponding charges to copy \nthe object. For information about downloading objects from Requester Pays buckets, see\nDownloading Objects in Requester Pays Buckets in the Amazon S3 User Guide .\nNote\nThis functionality is not supported for directory buckets.\nAmazon S3 API Version 2006-03-01 26Amazon Simple Storage Service API Reference\nValid Values: requester\nx-amz-server-side-encryption-customer-algorithm\nThe server-side encryption (SSE) algorithm used to encrypt the object.", "This parameter is \nrequired only when the object was created using a checksum algorithm or if your bucket policy \nrequires the use of SSE-C.", "For more information, see Protecting data using SSE-C keys in the\nAmazon S3 User Guide .\nNote\nThis functionality is not supported for directory buckets.\nx-amz-server-side-encryption-customer-key\nThe server-side encryption (SSE) customer managed key.", "This parameter is needed only when \nthe object was created using a checksum algorithm.", "For more information, see Protecting data \nusing SSE-C keys in the Amazon S3 User Guide .\nNote\nThis functionality is not supported for directory buckets.\nx-amz-server-side-encryption-customer-key-MD5\nThe MD5 server-side encryption (SSE) customer managed key.", "This parameter is needed only \nwhen the object was created using a checksum algorithm.", "For more information, see Protecting \ndata using SSE-C keys in the Amazon S3 User Guide .\nNote\nThis functionality is not supported for directory buckets.\nRequest Body\nThe request accepts the following data in XML format.\nAmazon S3 API Version 2006-03-01 27Amazon Simple Storage Service API Reference\nCompleteMultipartUpload\nRoot level tag for the CompleteMultipartUpload parameters.\nRequired: Yes\nPart\nArray of CompletedPart data types.\nIf you do not supply a valid Part with your request, the service sends back an HTTP 400 \nresponse.\nType: Array of CompletedPart data types\nRequired: No\nResponse Syntax\nHTTP/1.1 200\nx-amz-expiration: Expiration\nx-amz-server-side-encryption: ServerSideEncryption\nx-amz-version-id: VersionId\nx-amz-server-side-encryption-aws-kms-key-id: SSEKMSKeyId\nx-amz-server-side-encryption-bucket-key-enabled: BucketKeyEnabled\nx-amz-request-charged: RequestCharged\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<CompleteMultipartUploadResult > \n   <Location >string</Location > \n   <Bucket>string</Bucket> \n   <Key>string</Key> \n   <ETag>string</ETag> \n   <ChecksumCRC32 >string</ChecksumCRC32 > \n   <ChecksumCRC32C >string</ChecksumCRC32C > \n   <ChecksumSHA1 >string</ChecksumSHA1 > \n   <ChecksumSHA256 >string</ChecksumSHA256 >\n</CompleteMultipartUploadResult >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe response returns the following HTTP headers.\nAmazon S3 API Version 2006-03-01 28Amazon Simple Storage Service API Reference\nx-amz-expiration\nIf the object expiration is con\ufb01gured, this will contain the expiration date (expiry-date ) and \nrule ID (rule-id ). The value of rule-id is URL-encoded.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-request-charged\nIf present, indicates that the requester was successfully charged for the request.\nNote\nThis functionality is not supported for directory buckets.\nValid Values: requester\nx-amz-server-side-encryption\nThe server-side encryption algorithm used when storing this object in Amazon S3 (for example,\nAES256 , aws:kms ).\nValid Values: AES256 | aws:kms | aws:kms:dsse\nx-amz-server-side-encryption-aws-kms-key-id\nIf present, indicates the ID of the KMS key that was used for object encryption.\nx-amz-server-side-encryption-bucket-key-enabled\nIndicates whether the multipart upload uses an S3 Bucket Key for server-side encryption with \nAWS Key Management Service (AWS KMS) keys (SSE-KMS).\nx-amz-version-id\nVersion ID of the newly created object, in case the bucket has versioning turned on.\nNote\nThis functionality is not supported for directory buckets.\nAmazon S3 API Version 2006-03-01 29Amazon Simple Storage Service API Reference\nThe following data is returned in XML format by the service.\nCompleteMultipartUploadResult\nRoot level tag for the CompleteMultipartUploadResult parameters.\nRequired: Yes\nBucket\nThe name of the bucket that contains the newly created object.", "Does not return the access \npoint ARN or access point alias if used.\nNote\nAccess points are not supported by directory buckets.\nType: String\nChecksumCRC32\nThe base64-encoded, 32-bit CRC-32 checksum of the object.", "This will only be present if it was \nuploaded with the object. When you use an API operation on an object that was uploaded using \nmultipart uploads, this value may not be a direct checksum value of the full object. Instead, \nit's a calculation based on the checksum values of each individual part.", "For more information \nabout how checksums are calculated with multipart uploads, see  Checking object integrity in \nthe Amazon S3 User Guide .\nType: String\nChecksumCRC32C\nThe base64-encoded, 32-bit CRC-32C checksum of the object.", "This will only be present if it was \nuploaded with the object. When you use an API operation on an object that was uploaded using \nmultipart uploads, this value may not be a direct checksum value of the full object. Instead, \nit's a calculation based on the checksum values of each individual part.", "For more information \nabout how checksums are calculated with multipart uploads, see  Checking object integrity in \nthe Amazon S3 User Guide .\nType: String\nAmazon S3 API Version 2006-03-01 30Amazon Simple Storage Service API Reference\nChecksumSHA1\nThe base64-encoded, 160-bit SHA-1 digest of the object.", "This will only be present if it was \nuploaded with the object. When you use the API operation on an object that was uploaded \nusing multipart uploads, this value may not be a direct checksum value of the full object.", "\nInstead, it's a calculation based on the checksum values of each individual part.", "For more \ninformation about how checksums are calculated with multipart uploads, see  Checking object \nintegrity in the Amazon S3 User Guide .\nType: String\nChecksumSHA256\nThe base64-encoded, 256-bit SHA-256 digest of the object.", "This will only be present if it was \nuploaded with the object. When you use an API operation on an object that was uploaded using \nmultipart uploads, this value may not be a direct checksum value of the full object. Instead, \nit's a calculation based on the checksum values of each individual part.", "For more information \nabout how checksums are calculated with multipart uploads, see  Checking object integrity in \nthe Amazon S3 User Guide .\nType: String\nETag\nEntity tag that identi\ufb01es the newly created object's data.", "Objects with di\ufb00erent object data will \nhave di\ufb00erent entity tags. The entity tag is an opaque string. The entity tag may or may not be \nan MD5 digest of the object data. If the entity tag is not an MD5 digest of the object data, it \nwill contain one or more nonhexadecimal characters and/or will consist of less than 32 or more \nthan 32 hexadecimal digits.", "For more information about how the entity tag is calculated, see\nChecking object integrity in the Amazon S3 User Guide .\nType: String\nKey\nThe object key of the newly created object.\nType: String\nLength Constraints: Minimum length of 1.\nLocation\nThe URI that identi\ufb01es the newly created object.\nAmazon S3 API Version 2006-03-01 31Amazon Simple Storage Service API Reference\nType: String\nExamples\nSample Request for general purpose buckets\nThe following Complete Multipart Upload request speci\ufb01es three parts in the\nCompleteMultipartUpload  element.\n            POST /example-object?\nuploadId=AAAsb2FkIElEIGZvciBlbHZpbmcncyWeeS1tb3ZpZS5tMnRzIRRwbG9hZA HTTP/1.1 \n            Host: example-bucket.s3.<Region>.amazonaws.com \n            Date:  Mon, 1 Nov 2010 20:34:56 GMT \n            Content-Length: 391 \n            Authorization: authorization string \n            <CompleteMultipartUpload> \n             <Part> \n                <PartNumber>1</PartNumber> \n               <ETag>\"a54357aff0632cce46d942af68356b38\"</ETag> \n             </Part> \n             <Part> \n                <PartNumber>2</PartNumber> \n               <ETag>\"0c78aef83f66abc1fa1e8477f296d394\"</ETag> \n             </Part> \n             <Part> \n               <PartNumber>3</PartNumber> \n               <ETag>\"acbd18db4cc2f85cedef654fccc4a4d8\"</ETag> \n             </Part> \n            </CompleteMultipartUpload> \n          \nSample Response for general purpose buckets\nThe following response indicates that an object was successfully assembled.\n            HTTP/1.1 200 OK \n            x-amz-id-2: Uuag1LuByRx9e6j5Onimru9pO4ZVKnJ2Qz7/C1NPcfTWAtRPfTaOFg== \n            x-amz-request-id: 656c76696e6727732072657175657374 \n            Date: Mon, 1 Nov 2010 20:34:56 GMT \nAmazon S3 API Version 2006-03-01 32Amazon Simple Storage Service API Reference\n            Connection: close \n            Server: AmazonS3 \n            <?xml version=\"1.0\" encoding=\"UTF-8\"?> \n            <CompleteMultipartUploadResult xmlns=\"http://s3.amazonaws.com/\ndoc/2006-03-01/\"> \n             <Location>http://Example-Bucket.s3.<Region>.amazonaws.com/Example-Object</\nLocation> \n             <Bucket>Example-Bucket</Bucket> \n             <Key>Example-Object</Key> \n             <ETag>\"3858f62230ac3c915f300c664312c11f-9\"</ETag> \n            </CompleteMultipartUploadResult> \n          \nSample Response for general purpose buckets: Error speci\ufb01ed in header\nThe following response indicates that an error occurred before the HTTP response header was sent.\n            HTTP/1.1 403 Forbidden \n            x-amz-id-2: Uuag1LuByRx9e6j5Onimru9pO4ZVKnJ2Qz7/C1NPcfTWAtRPfTaOFg== \n            x-amz-request-id: 656c76696e6727732072657175657374 \n            Date:  Mon, 1 Nov 2010 20:34:56 GMT \n            Content-Length: 237 \n            Connection: keep-alive \n            Server: AmazonS3 \n            <?xml version=\"1.0\" encoding=\"UTF-8\"?> \n            <Error> \n              <Code>AccessDenied</Code> \n             <Message>Access Denied</Message> \n             <RequestId>656c76696e6727732072657175657374</RequestId> \n             <HostId>Uuag1LuByRx9e6j5Onimru9pO4ZVKnJ2Qz7/C1NPcfTWAtRPfTaOFg==</HostId> \n            </Error> \n          \nSample Response for general purpose buckets: Error speci\ufb01ed in body\nThe following response indicates that an error occurred after the HTTP response header was sent. \nNote that while the HTTP status code is 200 OK, the request actually failed as described in the\nError  element.\nAmazon S3 API Version 2006-03-01 33Amazon Simple Storage Service API Reference\n         HTTP/1.1 200 OK \n         x-amz-id-2: Uuag1LuByRx9e6j5Onimru9pO4ZVKnJ2Qz7/C1NPcfTWAtRPfTaOFg== \n         x-amz-request-id: 656c76696e6727732072657175657374 \n         Date:  Mon, 1 Nov 2010 20:34:56 GMT \n         Connection: close \n         Server: AmazonS3 \n         <?xml version=\"1.0\" encoding=\"UTF-8\"?> \n         <Error> \n          <Code>InternalError</Code> \n          <Message>We encountered an internal error. Please try again.</Message> \n          <RequestId>656c76696e6727732072657175657374</RequestId> \n          <HostId>Uuag1LuByRx9e6j5Onimru9pO4ZVKnJ2Qz7/C1NPcfTWAtRPfTaOFg==</HostId> \n         </Error> \n          \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 34Amazon Simple Storage Service API Reference\nCopyObject\nService: Amazon S3\nCreates a copy of an object that is already stored in Amazon S3.\nNote\nYou can store individual objects of up to 5 TB in Amazon S3.", "You create a copy of your \nobject up to 5 GB in size in a single atomic action using this API. However, to copy \nan object greater than 5 GB, you must use the multipart upload Upload Part - Copy \n(UploadPartCopy) API.", "For more information, see Copy Object Using the REST Multipart \nUpload API .\nYou can copy individual objects between general purpose buckets, between directory buckets, and \nbetween general purpose buckets and directory buckets.\nNote\n\u2022Amazon S3 supports copy operations using Multi-Region Access Points only as a \ndestination when using the Multi-Region Access Point ARN.\n\u2022Directory buckets  - For directory buckets, you must make requests for this API operation \nto the Zonal endpoint. These endpoints support virtual-hosted-style requests in the \nformat https:// bucket_name .s3express- az_id.region.amazonaws.com/ key-\nname .", "Path-style requests are not supported.", "For more information, see Regional and \nZonal endpoints in the Amazon S3 User Guide .\n\u2022VPC endpoints don't support cross-Region requests (including copies). If you're using VPC \nendpoints, your source and destination buckets should be in the same AWS Region as \nyour VPC endpoint.\nBoth the Region that you want to copy the object from and the Region that you want to copy the \nobject to must be enabled for your account.", "For more information about how to enable a Region \nfor your account, see Enable or disable a Region for standalone accounts in the  AWS Account \nManagement Guide .\nAmazon S3 API Version 2006-03-01 35Amazon Simple Storage Service API Reference\nImportant\nAmazon S3 transfer acceleration does not support cross-Region copies.", "If you request a \ncross-Region copy using a transfer acceleration endpoint, you get a 400 Bad Request\nerror.", "For more information, see Transfer Acceleration.\nAuthentication and authorization\nAll CopyObject  requests must be authenticated and signed by using IAM credentials \n(access key ID and secret access key for the IAM identities).", "All headers with the x-amz-\npre\ufb01x, including x-amz-copy-source , must be signed.", "For more information, see REST \nAuthentication .\nDirectory buckets - You must use the IAM credentials to authenticate and authorize your access \nto the CopyObject  API operation, instead of using the temporary security credentials through \nthe CreateSession  API operation.\nAWS CLI or SDKs handles authentication and authorization on your behalf.\nPermissions\nYou must have read access to the source object and write  access to the destination bucket.\n\u2022General purpose bucket permissions - You must have permissions in an IAM policy based on \nthe source and destination bucket types in a CopyObject  operation.\n\u2022If the source object is in a general purpose bucket, you must have  s3:GetObject  \npermission to read the source object that is being copied.\n\u2022If the destination bucket is a general purpose bucket, you must have  s3:PutObject  \npermission to write the object copy to the destination bucket.\n\u2022Directory bucket permissions - You must have permissions in a bucket policy or an IAM \nidentity-based policy based on the source and destination bucket types in a CopyObject\noperation.\n\u2022If the source object that you want to copy is in a directory bucket, you must have the \ns3express:CreateSession   permission in the Action element of a policy to read the \nobject.", "By default, the session is in the ReadWrite  mode.", "If you want to restrict the access, \nyou can explicitly set the s3express:SessionMode  condition key to ReadOnly  on the \ncopy source bucket.\nAmazon S3 API Version 2006-03-01 36Amazon Simple Storage Service API Reference\n\u2022If the copy destination is a directory bucket, you must have the \ns3express:CreateSession   permission in the Action element of a policy to write the \nobject to the destination. The s3express:SessionMode  condition key can't be set to\nReadOnly  on the copy destination bucket.\nIf the object is encrypted with SSE-KMS, you must also have the kms:GenerateDataKey  and\nkms:Decrypt  permissions in IAM identity-based policies and AWS KMS key policies for the \nAWS KMS key.\nFor example policies, see Example bucket policies for S3 Express One Zone and AWS Identity \nand Access Management (IAM) identity-based policies for S3 Express One Zone in the Amazon \nS3 User Guide .\nResponse and special errors\nWhen the request is an HTTP 1.1 request, the response is chunk encoded.", "When the request is \nnot an HTTP 1.1 request, the response would not contain the Content-Length .", "You always \nneed to read the entire response body to check if the copy succeeds.\n\u2022If the copy is successful, you receive a response with information about the copied object.\n\u2022A copy request might return an error when Amazon S3 receives the copy request or while \nAmazon S3 is copying the \ufb01les. A 200 OK response can contain either a success or an error.\n\u2022If the error occurs before the copy action starts, you receive a standard Amazon S3 error.\n\u2022If the error occurs during the copy operation, the error response is embedded in the 200 \nOK response.", "For example, in a cross-region copy, you may encounter throttling and receive \na 200 OK response.", "For more information, see Resolve the Error 200 response when \ncopying objects to Amazon S3.", "The 200 OK status code means the copy was accepted, \nbut it doesn't mean the copy is complete.", "Another example is when you disconnect from \nAmazon S3 before the copy is complete, Amazon S3 might cancel the copy and you \nmay receive a 200 OK response. You must stay connected to Amazon S3 until the entire \nresponse is successfully received and processed.\nIf you call this API operation directly, make sure to design your application to parse the \ncontent of the response and handle it appropriately.", "If you use AWS SDKs, SDKs handle \nthis condition. The SDKs detect the embedded error and apply error handling per your \ncon\ufb01guration settings (including automatically retrying the request as appropriate).", "If the \ncondition persists, the SDKs throw an exception (or, for the SDKs that don't use exceptions, \nthey return an error).\nAmazon S3 API Version 2006-03-01 37Amazon Simple Storage Service API Reference\nCharge\nThe copy request charge is based on the storage class and Region that you specify for the \ndestination object.", "The request can also result in a data retrieval charge for the source if the \nsource storage class bills for data retrieval. If the copy source is in a di\ufb00erent region, the data \ntransfer is billed to the copy source account.", "For pricing information, see Amazon S3 pricing.\nHTTP Host header syntax\nDirectory buckets  - The HTTP Host header syntax is \nBucket_name .s3express- az_id.region.amazonaws.com .\nThe following operations are related to CopyObject :\n\u2022PutObject\n\u2022GetObject\nRequest Syntax\nPUT /Key+ HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-acl: ACL\nCache-Control: CacheControl\nx-amz-checksum-algorithm: ChecksumAlgorithm\nContent-Disposition: ContentDisposition\nContent-Encoding: ContentEncoding\nContent-Language: ContentLanguage\nContent-Type: ContentType\nx-amz-copy-source: CopySource\nx-amz-copy-source-if-match: CopySourceIfMatch\nx-amz-copy-source-if-modified-since: CopySourceIfModifiedSince\nx-amz-copy-source-if-none-match: CopySourceIfNoneMatch\nx-amz-copy-source-if-unmodified-since: CopySourceIfUnmodifiedSince\nExpires: Expires\nx-amz-grant-full-control: GrantFullControl\nx-amz-grant-read: GrantRead\nx-amz-grant-read-acp: GrantReadACP\nx-amz-grant-write-acp: GrantWriteACP\nx-amz-metadata-directive: MetadataDirective\nx-amz-tagging-directive: TaggingDirective\nx-amz-server-side-encryption: ServerSideEncryption\nx-amz-storage-class: StorageClass\nAmazon S3 API Version 2006-03-01 38Amazon Simple Storage Service API Reference\nx-amz-website-redirect-location: WebsiteRedirectLocation\nx-amz-server-side-encryption-customer-algorithm: SSECustomerAlgorithm\nx-amz-server-side-encryption-customer-key: SSECustomerKey\nx-amz-server-side-encryption-customer-key-MD5: SSECustomerKeyMD5\nx-amz-server-side-encryption-aws-kms-key-id: SSEKMSKeyId\nx-amz-server-side-encryption-context: SSEKMSEncryptionContext\nx-amz-server-side-encryption-bucket-key-enabled: BucketKeyEnabled\nx-amz-copy-source-server-side-encryption-customer-\nalgorithm: CopySourceSSECustomerAlgorithm\nx-amz-copy-source-server-side-encryption-customer-key: CopySourceSSECustomerKey\nx-amz-copy-source-server-side-encryption-customer-key-MD5: CopySourceSSECustomerKeyMD5\nx-amz-request-payer: RequestPayer\nx-amz-tagging: Tagging\nx-amz-object-lock-mode: ObjectLockMode\nx-amz-object-lock-retain-until-date: ObjectLockRetainUntilDate\nx-amz-object-lock-legal-hold: ObjectLockLegalHoldStatus\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nx-amz-source-expected-bucket-owner: ExpectedSourceBucketOwner\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe name of the destination bucket.\nDirectory buckets - When you use this operation with a directory \nbucket, you must use virtual-hosted-style requests in the format \nBucket_name .s3express- az_id.region.amazonaws.com .", "Path-style requests are not \nsupported.", "Directory bucket names must be unique in the chosen Availability Zone.", "Bucket \nnames must follow the format  bucket_base_name --az-id--x-s3  (for example,  DOC-\nEXAMPLE-BUCKET --usw2-az1 --x-s3). For information about bucket naming restrictions, see\nDirectory bucket naming rules in the Amazon S3 User Guide .\nAccess points - When you use this action with an access point, you must provide the alias of the \naccess point in place of the bucket name or specify the access point ARN.", "When using the access \npoint ARN, you must direct requests to the access point hostname.", "The access point hostname \ntakes the form AccessPointName-AccountId .s3-accesspoint.Region.amazonaws.com.", "When using \nthis action with an access point through the AWS SDKs, you provide the access point ARN in \nplace of the bucket name. For more information about access point ARNs, see Using access \npoints  in the Amazon S3 User Guide .\nAmazon S3 API Version 2006-03-01 39Amazon Simple Storage Service API Reference\nNote\nAccess points and Object Lambda access points are not supported by directory buckets.\nS3 on Outposts  - When you use this action with Amazon S3 on Outposts, you must direct \nrequests to the S3 on Outposts hostname. The S3 on Outposts hostname takes the form \nAccessPointName -AccountId .outpostID .s3-outposts.", "Region.amazonaws.com .", "\nWhen you use this action with S3 on Outposts through the AWS SDKs, you provide the Outposts \naccess point ARN in place of the bucket name. For more information about S3 on Outposts \nARNs, see What is S3 on Outposts? in the Amazon S3 User Guide .\nRequired: Yes\nCache-Control\nSpeci\ufb01es the caching behavior along the request/reply chain.\nContent-Disposition\nSpeci\ufb01es presentational information for the object.", "Indicates whether an object should be \ndisplayed in a web browser or downloaded as a \ufb01le.", "It allows specifying the desired \ufb01lename for \nthe downloaded \ufb01le.\nContent-Encoding\nSpeci\ufb01es what content encodings have been applied to the object and thus what decoding \nmechanisms must be applied to obtain the media-type referenced by the Content-Type header \n\ufb01eld.\nNote\nFor directory buckets, only the aws-chunked  value is supported in this header \ufb01eld.\nContent-Language\nThe language the content is in.\nContent-Type\nA standard MIME type that describes the format of the object data.\nAmazon S3 API Version 2006-03-01 40Amazon Simple Storage Service API Reference\nExpires\nThe date and time at which the object is no longer cacheable.\nKey\nThe key of the destination object.\nLength Constraints: Minimum length of 1.\nRequired: Yes\nx-amz-acl\nThe canned access control list (ACL) to apply to the object.\nWhen you copy an object, the ACL metadata is not preserved and is set to private by default.", "\nOnly the owner has full access control. To override the default ACL setting, specify a new ACL \nwhen you generate a copy request.", "For more information, see Using ACLs.\nIf the destination bucket that you're copying objects to uses the bucket owner enforced setting \nfor S3 Object Ownership, ACLs are disabled and no longer a\ufb00ect permissions.", "Buckets that use \nthis setting only accept PUT requests that don't specify an ACL or PUT requests that specify \nbucket owner full control ACLs, such as the bucket-owner-full-control  canned ACL or an \nequivalent form of this ACL expressed in the XML format.", "For more information, see Controlling \nownership of objects and disabling ACLs in the Amazon S3 User Guide .\nNote\n\u2022If your destination bucket uses the bucket owner enforced setting for Object \nOwnership, all objects written to the bucket by any account will be owned by the \nbucket owner.\n\u2022This functionality is not supported for directory buckets.\n\u2022This functionality is not supported for Amazon S3 on Outposts.\nValid Values: private | public-read | public-read-write | authenticated-read \n| aws-exec-read | bucket-owner-read | bucket-owner-full-control\nx-amz-checksum-algorithm\nIndicates the algorithm that you want Amazon S3 to use to create the checksum for the object. \nFor more information, see Checking object integrity in the Amazon S3 User Guide .\nAmazon S3 API Version 2006-03-01 41Amazon Simple Storage Service API Reference\nWhen you copy an object, if the source object has a checksum, that checksum value will \nbe copied to the new object by default.", "If the CopyObject  request does not include this\nx-amz-checksum-algorithm  header, the checksum algorithm will be copied from the \nsource object to the destination object (if it's present on the source object). You can optionally \nspecify a di\ufb00erent checksum algorithm to use with the x-amz-checksum-algorithm\nheader.", "Unrecognized or unsupported values will respond with the HTTP status code 400 Bad \nRequest .\nNote\nFor directory buckets, when you use AWS SDKs, CRC32  is the default checksum \nalgorithm that's used for performance.\nValid Values: CRC32 | CRC32C | SHA1 | SHA256\nx-amz-copy-source\nSpeci\ufb01es the source object for the copy operation.", "The source object can be up to 5 GB. If the \nsource object is an object that was uploaded by using a multipart upload, the object copy will \nbe a single part object after the source object is copied to the destination bucket.\nYou specify the value of the copy source in one of two formats, depending on whether you want \nto access the source object through an access point:\n\u2022For objects not accessed through an access point, specify the name of the source bucket \nand the key of the source object, separated by a slash (/).", "For example, to copy the object\nreports/january.pdf  from the general purpose bucket awsexamplebucket , use\nawsexamplebucket/reports/january.pdf .", "The value must be URL-encoded.", "To copy \nthe object reports/january.pdf  from the directory bucket awsexamplebucket--use1-\naz5--x-s3 , use awsexamplebucket--use1-az5--x-s3/reports/january.pdf .", "The \nvalue must be URL-encoded.\n\u2022For objects accessed through access points, specify the Amazon Resource \nName (ARN) of the object as accessed through the access point, in the format\narn:aws:s3:<Region>:<account-id>:accesspoint/<access-point-name>/\nobject/<key> . For example, to copy the object reports/january.pdf  through access \npoint my-access-point  owned by account 123456789012  in Region us-west-2 , use the \nURL encoding of arn:aws:s3:us-west-2:123456789012:accesspoint/my-access-\npoint/object/reports/january.pdf .", "The value must be URL encoded.\nAmazon S3 API Version 2006-03-01 42Amazon Simple Storage Service API Reference\nNote\n\u2022Amazon S3 supports copy operations using Access points only when the source and \ndestination buckets are in the same AWS Region.\n\u2022Access points are not supported by directory buckets.\nAlternatively, for objects accessed through Amazon S3 on Outposts, specify the ARN of \nthe object as accessed in the format arn:aws:s3-outposts:<Region>:<account-\nid>:outpost/<outpost-id>/object/<key> . For example, to copy the object\nreports/january.pdf  through outpost my-outpost  owned by account 123456789012\nin Region us-west-2 , use the URL encoding of arn:aws:s3-outposts:us-\nwest-2:123456789012:outpost/my-outpost/object/reports/january.pdf .", "The \nvalue must be URL-encoded.\nIf your source bucket versioning is enabled, the x-amz-copy-source  header by default \nidenti\ufb01es the current version of an object to copy.", "If the current version is a delete \nmarker, Amazon S3 behaves as if the object was deleted.", "To copy a di\ufb00erent version, \nuse the versionId  query parameter.", "Speci\ufb01cally, append ?versionId=<version-\nid> to the value (for example, awsexamplebucket/reports/january.pdf?\nversionId=QUpfdndhfd8438MNFDN93jdnJFkdmqnh893 ).", "If you don't specify a version ID, \nAmazon S3 copies the latest version of the source object.\nIf you enable versioning on the destination bucket, Amazon S3 generates a unique version \nID for the copied object.", "This version ID is di\ufb00erent from the version ID of the source object.", "\nAmazon S3 returns the version ID of the copied object in the x-amz-version-id  response \nheader in the response.\nIf you do not enable versioning or suspend it on the destination bucket, the version ID that \nAmazon S3 generates in the x-amz-version-id  response header is always null.\nNote\nDirectory buckets - S3 Versioning isn't enabled and supported for directory buckets.\nPattern: \\/.+\\/.+\nAmazon S3 API Version 2006-03-01 43Amazon Simple Storage Service API Reference\nRequired: Yes\nx-amz-copy-source-if-match\nCopies the object if its entity tag (ETag) matches the speci\ufb01ed tag.\nIf both the x-amz-copy-source-if-match  and x-amz-copy-source-if-unmodified-\nsince headers are present in the request and evaluate as follows, Amazon S3 returns 200 OK\nand copies the data:\n\u2022x-amz-copy-source-if-match  condition evaluates to true\n\u2022x-amz-copy-source-if-unmodified-since  condition evaluates to false\nx-amz-copy-source-if-modi\ufb01ed-since\nCopies the object if it has been modi\ufb01ed since the speci\ufb01ed time.\nIf both the x-amz-copy-source-if-none-match  and x-amz-copy-source-if-\nmodified-since  headers are present in the request and evaluate as follows, Amazon S3 \nreturns the 412 Precondition Failed  response code:\n\u2022x-amz-copy-source-if-none-match  condition evaluates to false\n\u2022x-amz-copy-source-if-modified-since  condition evaluates to true\nx-amz-copy-source-if-none-match\nCopies the object if its entity tag (ETag) is di\ufb00erent than the speci\ufb01ed ETag.\nIf both the x-amz-copy-source-if-none-match  and x-amz-copy-source-if-\nmodified-since  headers are present in the request and evaluate as follows, Amazon S3 \nreturns the 412 Precondition Failed  response code:\n\u2022x-amz-copy-source-if-none-match  condition evaluates to false\n\u2022x-amz-copy-source-if-modified-since  condition evaluates to true\nx-amz-copy-source-if-unmodi\ufb01ed-since\nCopies the object if it hasn't been modi\ufb01ed since the speci\ufb01ed time.\nIf both the x-amz-copy-source-if-match  and x-amz-copy-source-if-unmodified-\nsince headers are present in the request and evaluate as follows, Amazon S3 returns 200 OK\nand copies the data:\n\u2022x-amz-copy-source-if-match  condition evaluates to true\nAmazon S3 API Version 2006-03-01 44Amazon Simple Storage Service API Reference\n\u2022x-amz-copy-source-if-unmodified-since  condition evaluates to false\nx-amz-copy-source-server-side-encryption-customer-algorithm\nSpeci\ufb01es the algorithm to use when decrypting the source object (for example, AES256 ).\nIf the source object for the copy is stored in Amazon S3 using SSE-C, you must provide the \nnecessary encryption information in your request so that Amazon S3 can decrypt the object for \ncopying.\nNote\nThis functionality is not supported when the source object is in a directory bucket.\nx-amz-copy-source-server-side-encryption-customer-key\nSpeci\ufb01es the customer-provided encryption key for Amazon S3 to use to decrypt the source \nobject. The encryption key provided in this header must be the same one that was used when \nthe source object was created.\nIf the source object for the copy is stored in Amazon S3 using SSE-C, you must provide the \nnecessary encryption information in your request so that Amazon S3 can decrypt the object for \ncopying.\nNote\nThis functionality is not supported when the source object is in a directory bucket.\nx-amz-copy-source-server-side-encryption-customer-key-MD5\nSpeci\ufb01es the 128-bit MD5 digest of the encryption key according to RFC 1321. Amazon S3 uses \nthis header for a message integrity check to ensure that the encryption key was transmitted \nwithout error.\nIf the source object for the copy is stored in Amazon S3 using SSE-C, you must provide the \nnecessary encryption information in your request so that Amazon S3 can decrypt the object for \ncopying.\nAmazon S3 API Version 2006-03-01 45Amazon Simple Storage Service API Reference\nNote\nThis functionality is not supported when the source object is in a directory bucket.\nx-amz-expected-bucket-owner\nThe account ID of the expected destination bucket owner. If the account ID that you provide \ndoes not match the actual owner of the destination bucket, the request fails with the HTTP \nstatus code 403 Forbidden  (access denied).\nx-amz-grant-full-control\nGives the grantee READ, READ_ACP, and WRITE_ACP permissions on the object.\nNote\n\u2022This functionality is not supported for directory buckets.\n\u2022This functionality is not supported for Amazon S3 on Outposts.\nx-amz-grant-read\nAllows grantee to read the object data and its metadata.\nNote\n\u2022This functionality is not supported for directory buckets.\n\u2022This functionality is not supported for Amazon S3 on Outposts.\nx-amz-grant-read-acp\nAllows grantee to read the object ACL.\nNote\n\u2022This functionality is not supported for directory buckets.\n\u2022This functionality is not supported for Amazon S3 on Outposts.\nAmazon S3 API Version 2006-03-01 46Amazon Simple Storage Service API Reference\nx-amz-grant-write-acp\nAllows grantee to write the ACL for the applicable object.\nNote\n\u2022This functionality is not supported for directory buckets.\n\u2022This functionality is not supported for Amazon S3 on Outposts.\nx-amz-metadata-directive\nSpeci\ufb01es whether the metadata is copied from the source object or replaced with metadata \nthat's provided in the request.", "When copying an object, you can preserve all metadata (the \ndefault) or specify new metadata.", "If this header isn\u2019t speci\ufb01ed, COPY is the default behavior.\nGeneral purpose bucket - For general purpose buckets, when you grant permissions, you can \nuse the s3:x-amz-metadata-directive  condition key to enforce certain metadata behavior \nwhen objects are uploaded. For more information, see Amazon S3 condition key examples in \nthe Amazon S3 User Guide .\nNote\nx-amz-website-redirect-location  is unique to each object and is not copied \nwhen using the x-amz-metadata-directive  header. To copy the value, you must \nspecify x-amz-website-redirect-location  in the request header.\nValid Values: COPY | REPLACE\nx-amz-object-lock-legal-hold\nSpeci\ufb01es whether you want to apply a legal hold to the object copy.\nNote\nThis functionality is not supported for directory buckets.\nValid Values: ON | OFF\nAmazon S3 API Version 2006-03-01 47Amazon Simple Storage Service API Reference\nx-amz-object-lock-mode\nThe Object Lock mode that you want to apply to the object copy.\nNote\nThis functionality is not supported for directory buckets.\nValid Values: GOVERNANCE | COMPLIANCE\nx-amz-object-lock-retain-until-date\nThe date and time when you want the Object Lock of the object copy to expire.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-request-payer\nCon\ufb01rms that the requester knows that they will be charged for the request.", "Bucket owners \nneed not specify this parameter in their requests.", "If either the source or destination S3 \nbucket has Requester Pays enabled, the requester will pay for corresponding charges to copy \nthe object. For information about downloading objects from Requester Pays buckets, see\nDownloading Objects in Requester Pays Buckets in the Amazon S3 User Guide .\nNote\nThis functionality is not supported for directory buckets.\nValid Values: requester\nx-amz-server-side-encryption\nThe server-side encryption algorithm used when storing this object in Amazon S3. \nUnrecognized or unsupported values won\u2019t write a destination object and will receive a 400 \nBad Request  response.\nAmazon S3 API Version 2006-03-01 48Amazon Simple Storage Service API Reference\nAmazon S3 automatically encrypts all new objects that are copied to an S3 bucket. When \ncopying an object, if you don't specify encryption information in your copy request, the \nencryption setting of the target object is set to the default encryption con\ufb01guration of the \ndestination bucket.", "By default, all buckets have a base level of encryption con\ufb01guration that \nuses server-side encryption with Amazon S3 managed keys (SSE-S3). If the destination bucket \nhas a di\ufb00erent default encryption con\ufb01guration, Amazon S3 uses the corresponding encryption \nkey to encrypt the target object copy.\nWith server-side encryption, Amazon S3 encrypts your data as it writes your data to disks in its \ndata centers and decrypts the data when you access it. For more information about server-side \nencryption, see Using Server-Side Encryption in the Amazon S3 User Guide .\nGeneral purpose buckets\n\u2022For general purpose buckets, there are the following supported options for server-side \nencryption: server-side encryption with AWS Key Management Service (AWS KMS) keys \n(SSE-KMS), dual-layer server-side encryption with AWS KMS keys (DSSE-KMS), and server-\nside encryption with customer-provided encryption keys (SSE-C). Amazon S3 uses the \ncorresponding KMS key, or a customer-provided key to encrypt the target object copy.\n\u2022When you perform a CopyObject  operation, if you want to use a di\ufb00erent type of \nencryption setting for the target object, you can specify appropriate encryption-related \nheaders to encrypt the target object with an Amazon S3 managed key, a KMS key, or a \ncustomer-provided key. If the encryption setting in your request is di\ufb00erent from the default \nencryption con\ufb01guration of the destination bucket, the encryption setting in your request \ntakes precedence.\nDirectory buckets\n\u2022For directory buckets, there are only two supported options for server-side encryption: \nserver-side encryption with Amazon S3 managed keys (SSE-S3) (AES256) and server-side \nencryption with AWS KMS keys (SSE-KMS) (aws:kms). We recommend that the bucket's \ndefault encryption uses the desired encryption con\ufb01guration and you don't override the \nbucket default encryption in your CreateSession  requests or PUT object requests.", "Then, \nnew objects are automatically encrypted with the desired encryption settings.", "For more \ninformation, see Protecting data with server-side encryption in the Amazon S3 User Guide . \nFor more information about the encryption overriding behaviors in directory buckets, see\nSpecifying server-side encryption with AWS KMS for new object uploads.\n\u2022To encrypt new object copies to a directory bucket with SSE-KMS, we recommend you \nspecify SSE-KMS as the directory bucket's default encryption con\ufb01guration with a KMS key \nAmazon S3 API Version 2006-03-01 49Amazon Simple Storage Service API Reference\n(speci\ufb01cally, a customer managed key).", "The AWS managed key (aws/s3) isn't supported.", "Your \nSSE-KMS con\ufb01guration can only support 1 customer managed key per directory bucket for \nthe lifetime of the bucket. After you specify a customer managed key for SSE-KMS, you can't \noverride the customer managed key for the bucket's SSE-KMS con\ufb01guration. Then, when you \nperform a CopyObject  operation and want to specify server-side encryption settings for \nnew object copies with SSE-KMS in the encryption-related request headers, you must ensure \nthe encryption key is the same customer managed key that you speci\ufb01ed for the directory \nbucket's default encryption con\ufb01guration.\nValid Values: AES256 | aws:kms | aws:kms:dsse\nx-amz-server-side-encryption-aws-kms-key-id\nSpeci\ufb01es the AWS KMS key ID (Key ID, Key ARN, or Key Alias) to use for object encryption. All \nGET and PUT requests for an object protected by AWS KMS will fail if they're not made via SSL \nor using SigV4.", "For information about con\ufb01guring any of the o\ufb03cially supported AWS SDKs and \nAWS CLI, see Specifying the Signature Version in Request Authentication in the Amazon S3 User \nGuide .\nDirectory buckets - If you specify x-amz-server-side-encryption  with aws:kms , the \nx-amz-server-side-encryption-aws-kms-key-id  header is implicitly assigned the \nID of the AWS KMS symmetric encryption customer managed key that's con\ufb01gured for your \ndirectory bucket's default encryption setting. If you want to specify the  x-amz-server-\nside-encryption-aws-kms-key-id  header explicitly, you can only specify it with the ID \n(Key ID or Key ARN) of the AWS KMS customer managed key that's con\ufb01gured for your directory \nbucket's default encryption setting.", "Otherwise, you get an HTTP 400 Bad Request  error.", "Only \nuse the key ID or key ARN.", "The key alias format of the KMS key isn't supported.", "Your SSE-KMS \ncon\ufb01guration can only support 1 customer managed key per directory bucket for the lifetime of \nthe bucket.", "The AWS managed key (aws/s3) isn't supported.\nx-amz-server-side-encryption-bucket-key-enabled\nSpeci\ufb01es whether Amazon S3 should use an S3 Bucket Key for object encryption with server-\nside encryption using AWS Key Management Service (AWS KMS) keys (SSE-KMS). If a target \nobject uses SSE-KMS, you can enable an S3 Bucket Key for the object.\nSetting this header to true causes Amazon S3 to use an S3 Bucket Key for object encryption \nwith SSE-KMS. Specifying this header with a COPY action doesn\u2019t a\ufb00ect bucket-level settings \nfor S3 Bucket Key.\nFor more information, see Amazon S3 Bucket Keys in the Amazon S3 User Guide .\nAmazon S3 API Version 2006-03-01 50Amazon Simple Storage Service API Reference\nNote\nDirectory buckets - S3 Bucket Keys aren't supported, when you copy SSE-KMS \nencrypted objects from general purpose buckets to directory buckets, from directory \nbuckets to general purpose buckets, or between directory buckets, through CopyObject. \nIn this case, Amazon S3 makes a call to AWS KMS every time a copy request is made for \na KMS-encrypted object.\nx-amz-server-side-encryption-context\nSpeci\ufb01es the AWS KMS Encryption Context as an additional encryption context to use for \nthe destination object encryption.", "The value of this header is a base64-encoded UTF-8 string \nholding JSON with the encryption context key-value pairs.\nGeneral purpose buckets - This value must be explicitly added to specify encryption context for\nCopyObject  requests if you want an additional encryption context for your destination object. \nThe additional encryption context of the source object won't be copied to the destination \nobject.", "For more information, see Encryption context in the Amazon S3 User Guide .\nDirectory buckets - You can optionally provide an explicit encryption context value.", "The value \nmust match the default encryption context - the bucket Amazon Resource Name (ARN).", "An \nadditional encryption context value is not supported.\nx-amz-server-side-encryption-customer-algorithm\nSpeci\ufb01es the algorithm to use when encrypting the object (for example, AES256 ).\nWhen you perform a CopyObject  operation, if you want to use a di\ufb00erent type of encryption \nsetting for the target object, you can specify appropriate encryption-related headers to encrypt \nthe target object with an Amazon S3 managed key, a KMS key, or a customer-provided key. If \nthe encryption setting in your request is di\ufb00erent from the default encryption con\ufb01guration of \nthe destination bucket, the encryption setting in your request takes precedence.\nNote\nThis functionality is not supported when the destination bucket is a directory bucket.\nAmazon S3 API Version 2006-03-01 51Amazon Simple Storage Service API Reference\nx-amz-server-side-encryption-customer-key\nSpeci\ufb01es the customer-provided encryption key for Amazon S3 to use in encrypting data.", "\nThis value is used to store the object and then it is discarded.", "Amazon S3 does not store the \nencryption key.", "The key must be appropriate for use with the algorithm speci\ufb01ed in the x-amz-\nserver-side-encryption-customer-algorithm  header.\nNote\nThis functionality is not supported when the destination bucket is a directory bucket.\nx-amz-server-side-encryption-customer-key-MD5\nSpeci\ufb01es the 128-bit MD5 digest of the encryption key according to RFC 1321.", "Amazon S3 uses \nthis header for a message integrity check to ensure that the encryption key was transmitted \nwithout error.\nNote\nThis functionality is not supported when the destination bucket is a directory bucket.\nx-amz-source-expected-bucket-owner\nThe account ID of the expected source bucket owner.", "If the account ID that you provide does not \nmatch the actual owner of the source bucket, the request fails with the HTTP status code 403 \nForbidden  (access denied).\nx-amz-storage-class\nIf the x-amz-storage-class  header is not used, the copied object will be stored in the\nSTANDARD  Storage Class by default.", "The STANDARD  storage class provides high durability and \nhigh availability.", "Depending on performance needs, you can specify a di\ufb00erent Storage Class.\nNote\n\u2022Directory buckets  - For directory buckets, only the S3 Express One Zone storage \nclass is supported to store newly created objects. Unsupported storage class values \nwon't write a destination object and will respond with the HTTP status code 400 Bad \nRequest .\nAmazon S3 API Version 2006-03-01 52Amazon Simple Storage Service API Reference\n\u2022Amazon S3 on Outposts  - S3 on Outposts only uses the OUTPOSTS  Storage Class.\nYou can use the CopyObject  action to change the storage class of an object that is already \nstored in Amazon S3 by using the x-amz-storage-class  header. For more information, see\nStorage Classes  in the Amazon S3 User Guide .\nBefore using an object as a source object for the copy operation, you must restore a copy of it if \nit meets any of the following conditions:\n\u2022The storage class of the source object is GLACIER  or DEEP_ARCHIVE .\n\u2022The storage class of the source object is INTELLIGENT_TIERING  and it's S3 Intelligent-\nTiering access tier is Archive Access  or Deep Archive Access .\nFor more information, see RestoreObject and Copying Objects in the Amazon S3 User Guide .\nValid Values: STANDARD | REDUCED_REDUNDANCY | STANDARD_IA | ONEZONE_IA | \nINTELLIGENT_TIERING | GLACIER | DEEP_ARCHIVE | OUTPOSTS | GLACIER_IR | \nSNOW | EXPRESS_ONEZONE\nx-amz-tagging\nThe tag-set for the object copy in the destination bucket.", "This value must be used in \nconjunction with the x-amz-tagging-directive  if you choose REPLACE  for the x-amz-\ntagging-directive . If you choose COPY  for the x-amz-tagging-directive , you don't \nneed to set the x-amz-tagging  header, because the tag-set will be copied from the source \nobject directly.", "The tag-set must be encoded as URL Query parameters.\nThe default value is the empty value.\nNote\nDirectory buckets - For directory buckets in a CopyObject  operation, only the empty \ntag-set is supported. Any requests that attempt to write non-empty tags into directory \nbuckets will receive a 501 Not Implemented  status code. When the destination \nbucket is a directory bucket, you will receive a 501 Not Implemented  response in any \nof the following situations:\n\u2022When you attempt to COPY the tag-set from an S3 source object that has non-empty \ntags.\nAmazon S3 API Version 2006-03-01 53Amazon Simple Storage Service API Reference\n\u2022When you attempt to REPLACE the tag-set of a source object and set a non-empty \nvalue to x-amz-tagging .\n\u2022When you don't set the x-amz-tagging-directive  header and the source \nobject has non-empty tags. This is because the default value of x-amz-tagging-\ndirective  is COPY .\nBecause only the empty tag-set is supported for directory buckets in a CopyObject\noperation, the following situations are allowed:\n\u2022When you attempt to COPY the tag-set from a directory bucket source object that \nhas no tags to a general purpose bucket. It copies an empty tag-set to the destination \nobject.\n\u2022When you attempt to REPLACE the tag-set of a directory bucket source object and set \nthe x-amz-tagging  value of the directory bucket destination object to empty.\n\u2022When you attempt to REPLACE the tag-set of a general purpose bucket source object \nthat has non-empty tags and set the x-amz-tagging  value of the directory bucket \ndestination object to empty.\n\u2022When you attempt to REPLACE the tag-set of a directory bucket source object and \ndon't set the x-amz-tagging  value of the directory bucket destination object. This is \nbecause the default value of x-amz-tagging  is the empty value.\nx-amz-tagging-directive\nSpeci\ufb01es whether the object tag-set is copied from the source object or replaced with the tag-\nset that's provided in the request.\nThe default value is COPY .\nNote\nDirectory buckets - For directory buckets in a CopyObject  operation, only the empty \ntag-set is supported.", "Any requests that attempt to write non-empty tags into directory \nbuckets will receive a 501 Not Implemented  status code. When the destination \nbucket is a directory bucket, you will receive a 501 Not Implemented  response in any \nof the following situations:\n\u2022When you attempt to COPY the tag-set from an S3 source object that has non-empty \ntags.\nAmazon S3 API Version 2006-03-01 54Amazon Simple Storage Service API Reference\n\u2022When you attempt to REPLACE the tag-set of a source object and set a non-empty \nvalue to x-amz-tagging .\n\u2022When you don't set the x-amz-tagging-directive  header and the source \nobject has non-empty tags. This is because the default value of x-amz-tagging-\ndirective  is COPY .\nBecause only the empty tag-set is supported for directory buckets in a CopyObject\noperation, the following situations are allowed:\n\u2022When you attempt to COPY the tag-set from a directory bucket source object that \nhas no tags to a general purpose bucket. It copies an empty tag-set to the destination \nobject.\n\u2022When you attempt to REPLACE the tag-set of a directory bucket source object and set \nthe x-amz-tagging  value of the directory bucket destination object to empty.\n\u2022When you attempt to REPLACE the tag-set of a general purpose bucket source object \nthat has non-empty tags and set the x-amz-tagging  value of the directory bucket \ndestination object to empty.\n\u2022When you attempt to REPLACE the tag-set of a directory bucket source object and \ndon't set the x-amz-tagging  value of the directory bucket destination object. This is \nbecause the default value of x-amz-tagging  is the empty value.\nValid Values: COPY | REPLACE\nx-amz-website-redirect-location\nIf the destination bucket is con\ufb01gured as a website, redirects requests for this object copy to \nanother object in the same bucket or to an external URL.", "Amazon S3 stores the value of this \nheader in the object metadata.", "This value is unique to each object and is not copied when using \nthe x-amz-metadata-directive  header.", "Instead, you may opt to provide this header in \ncombination with the x-amz-metadata-directive  header.\nNote\nThis functionality is not supported for directory buckets.\nAmazon S3 API Version 2006-03-01 55Amazon Simple Storage Service API Reference\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\nx-amz-expiration: Expiration\nx-amz-copy-source-version-id: CopySourceVersionId\nx-amz-version-id: VersionId\nx-amz-server-side-encryption: ServerSideEncryption\nx-amz-server-side-encryption-customer-algorithm: SSECustomerAlgorithm\nx-amz-server-side-encryption-customer-key-MD5: SSECustomerKeyMD5\nx-amz-server-side-encryption-aws-kms-key-id: SSEKMSKeyId\nx-amz-server-side-encryption-context: SSEKMSEncryptionContext\nx-amz-server-side-encryption-bucket-key-enabled: BucketKeyEnabled\nx-amz-request-charged: RequestCharged\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<CopyObjectResult > \n   <ETag>string</ETag> \n   <LastModified >timestamp </LastModified > \n   <ChecksumCRC32 >string</ChecksumCRC32 > \n   <ChecksumCRC32C >string</ChecksumCRC32C > \n   <ChecksumSHA1 >string</ChecksumSHA1 > \n   <ChecksumSHA256 >string</ChecksumSHA256 >\n</CopyObjectResult >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe response returns the following HTTP headers.\nx-amz-copy-source-version-id\nVersion ID of the source object that was copied.\nNote\nThis functionality is not supported when the source object is in a directory bucket.\nAmazon S3 API Version 2006-03-01 56Amazon Simple Storage Service API Reference\nx-amz-expiration\nIf the object expiration is con\ufb01gured, the response includes this header.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-request-charged\nIf present, indicates that the requester was successfully charged for the request.\nNote\nThis functionality is not supported for directory buckets.\nValid Values: requester\nx-amz-server-side-encryption\nThe server-side encryption algorithm used when you store this object in Amazon S3 (for \nexample, AES256 , aws:kms , aws:kms:dsse ).\nValid Values: AES256 | aws:kms | aws:kms:dsse\nx-amz-server-side-encryption-aws-kms-key-id\nIf present, indicates the ID of the KMS key that was used for object encryption.\nx-amz-server-side-encryption-bucket-key-enabled\nIndicates whether the copied object uses an S3 Bucket Key for server-side encryption with AWS \nKey Management Service (AWS KMS) keys (SSE-KMS).\nx-amz-server-side-encryption-context\nIf present, indicates the AWS KMS Encryption Context to use for object encryption. The value \nof this header is a base64-encoded UTF-8 string holding JSON with the encryption context key-\nvalue pairs.\nAmazon S3 API Version 2006-03-01 57Amazon Simple Storage Service API Reference\nx-amz-server-side-encryption-customer-algorithm\nIf server-side encryption with a customer-provided encryption key was requested, the response \nwill include this header to con\ufb01rm the encryption algorithm that's used.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-server-side-encryption-customer-key-MD5\nIf server-side encryption with a customer-provided encryption key was requested, the \nresponse will include this header to provide the round-trip message integrity veri\ufb01cation of the \ncustomer-provided encryption key.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-version-id\nVersion ID of the newly created copy.\nNote\nThis functionality is not supported for directory buckets.\nThe following data is returned in XML format by the service.\nCopyObjectResult\nRoot level tag for the CopyObjectResult parameters.\nRequired: Yes\nAmazon S3 API Version 2006-03-01 58Amazon Simple Storage Service API Reference\nChecksumCRC32\nThe base64-encoded, 32-bit CRC-32 checksum of the object.", "This will only be present if it was \nuploaded with the object.", "For more information, see  Checking object integrity in the Amazon \nS3 User Guide .\nType: String\nChecksumCRC32C\nThe base64-encoded, 32-bit CRC-32C checksum of the object.", "This will only be present if it was \nuploaded with the object.", "For more information, see  Checking object integrity in the Amazon \nS3 User Guide .\nType: String\nChecksumSHA1\nThe base64-encoded, 160-bit SHA-1 digest of the object.", "This will only be present if it was \nuploaded with the object.", "For more information, see  Checking object integrity in the Amazon \nS3 User Guide .\nType: String\nChecksumSHA256\nThe base64-encoded, 256-bit SHA-256 digest of the object.", "This will only be present if it was \nuploaded with the object.", "For more information, see  Checking object integrity in the Amazon \nS3 User Guide .\nType: String\nETag\nReturns the ETag of the new object.", "The ETag re\ufb02ects only changes to the contents of an object, \nnot its metadata.\nType: String\nLastModi\ufb01ed\nCreation date of the object.\nType: Timestamp\nAmazon S3 API Version 2006-03-01 59Amazon Simple Storage Service API Reference\nErrors\nObjectNotInActiveTierError\nThe source object of the COPY action is not in the active tier and is only stored in Amazon S3 \nGlacier.\nHTTP Status Code: 403\nExamples\nSample Request for general purpose buckets\nThis example copies my-image.jpg  into the bucket bucket, with the key name my-second-\nimage.jpg .\n                PUT /my-second-image.jpg HTTP/1.1 \n                Host: bucket.s3.<Region>.amazonaws.com \n                Date: Wed, 28 Oct 2009 22:32:00 GMT \n                x-amz-copy-source: /bucket/my-image.jpg \n                Authorization: authorization string \n              \nSample Response for general purpose buckets\nThis example illustrates one usage of CopyObject.\n               HTTP/1.1 200 OK \n               x-amz-id-2: \n eftixk72aD6Ap51TnqcoF8eFidJG9Z/2mkiDFu8yU9AS1ed4OpIszj7UDNEHGran \n               x-amz-request-id: 318BC8BC148832E5 \n               x-amz-copy-source-version-id: 3/L4kqtJlcpXroDTDmJ+rmSpXd3dIbrHY\n+MTRCxf3vjVBH40Nr8X8gdRQBpUMLUo \n               x-amz-version-id: QUpfdndhfd8438MNFDN93jdnJFkdmqnh893 \n               Date: Wed, 28 Oct 2009 22:32:00 GMT \n               Connection: close \n               Server: AmazonS3 \n               <CopyObjectResult> \n                  <LastModified>2009-10-12T17:50:30.000Z</LastModified> \nAmazon S3 API Version 2006-03-01 60Amazon Simple Storage Service API Reference\n                  <ETag>\"9b2cf535f27731c974343645a3985328\"</ETag> \n               </CopyObjectResult> \n              \nSample Request for general purpose buckets: Copying a speci\ufb01ed version of an object\nThe following request copies the my-image.jpg  key with the speci\ufb01ed version ID, copies it into \nthe bucket bucket, and gives it the my-second-image.jpg  key.\n                PUT /my-second-image.jpg HTTP/1.1 \n                Host: bucket.s3.<Region>.amazonaws.com \n                Date: Wed, 28 Oct 2009 22:32:00 GMT \n                x-amz-copy-source: /bucket/my-image.jpg?versionId=3/L4kqtJlcpXroDTDmJ\n+rmSpXd3dIbrHY+MTRCxf3vjVBH40Nr8X8gdRQBpUMLUo \n                Authorization: authorization string \n              \nSuccess Response for general purpose buckets: Copying a versioned object into a version-\nenabled bucket\nThe following response shows that an object was copied into a target bucket where versioning is \nenabled.\n                HTTP/1.1 200 OK \n                x-amz-id-2: \n eftixk72aD6Ap51TnqcoF8eFidJG9Z/2mkiDFu8yU9AS1ed4OpIszj7UDNEHGran \n                x-amz-request-id: 318BC8BC148832E5 \n                x-amz-version-id: QUpfdndhfd8438MNFDN93jdnJFkdmqnh893 \n                x-amz-copy-source-version-id: 09df8234529fjs0dfi0w52935029wefdj \n                Date: Wed, 28 Oct 2009 22:32:00 GMT \n                Connection: close \n                Server: AmazonS3 \n  \n                <?xml version=\"1.0\" encoding=\"UTF-8\"?> \n                <CopyObjectResult> \n                  <LastModified>2009-10-12T17:50:30.000Z</LastModified> \n                  <ETag>\"9b2cf535f27731c974343645a3985328\"</ETag> \n                </CopyObjectResult> \n              \nAmazon S3 API Version 2006-03-01 61Amazon Simple Storage Service API Reference\nSuccess Response for general purpose buckets: Copying a versioned object into a version-\nsuspended bucket\nThe following response shows that an object was copied into a target bucket where versioning is \nsuspended. The parameter VersionId  does not appear.\n               HTTP/1.1 200 OK \n               x-amz-id-2: \n eftixk72aD6Ap51TnqcoF8eFidJG9Z/2mkiDFu8yU9AS1ed4OpIszj7UDNEHGran \n               x-amz-request-id: 318BC8BC148832E5 \n               x-amz-copy-source-version-id: 3/L4kqtJlcpXroDTDmJ+rmSpXd3dIbrHY\n+MTRCxf3vjVBH40Nr8X8gdRQBpUMLUo \n               Date: Wed, 28 Oct 2009 22:32:00 GMT \n               Connection: close \n               Server: AmazonS3 \n               <?xml version=\"1.0\" encoding=\"UTF-8\"?> \n                <CopyObjectResult> \n                  <LastModified>2009-10-28T22:32:00</LastModified> \n                  <ETag>\"9b2cf535f27731c974343645a3985328\"</ETag> \n                </CopyObjectResult> \n              \nSample Request for general purpose buckets: Copy from unencrypted object to an object \nencrypted with server-side encryption with customer-provided encryption keys\nThe following example speci\ufb01es the HTTP PUT header to copy an unencrypted object to an object \nencrypted with server-side encryption with customer-provided encryption keys (SSE-C).\n                PUT /exampleDestinationObject HTTP/1.1 \n                Host: example-destination-bucket.s3.<Region>.amazonaws.com  \n                x-amz-server-side-encryption-customer-algorithm: AES256 \n                x-amz-server-side-encryption-customer-key: Base64(YourKey) \n                x-amz-server-side-encryption-customer-key-MD5 : Base64(MD5(YourKey)) \n                x-amz-metadata-directive: metadata_directive \n                x-amz-copy-source: /example_source_bucket/exampleSourceObject \n                x-amz-copy-source-if-match: etag \n                x-amz-copy-source-if-none-match: etag \n                x-amz-copy-source-if-unmodified-since: time_stamp \n                x-amz-copy-source-if-modified-since: time_stamp \n                 \nAmazon S3 API Version 2006-03-01 62Amazon Simple Storage Service API Reference\n               <request metadata> \n                Authorization: authorization string (see Authenticating Requests (AWS \n Signature Version 4)) \n                Date: date \n              \nSample Request for general purpose buckets: Copy from an object encrypted with SSE-C to an \nobject encrypted with SSE-C\nThe following example speci\ufb01es the HTTP PUT header to copy an object encrypted with server-\nside encryption with customer-provided encryption keys to an object encrypted with server-side \nencryption with customer-provided encryption keys for key rotation.\n                PUT /exampleDestinationObject HTTP/1.1 \n                Host: example-destination-bucket.s3.<Region>.amazonaws.com  \n                x-amz-server-side-encryption-customer-algorithm: AES256 \n                x-amz-server-side-encryption-customer-key: Base64(NewKey) \n                x-amz-server-side-encryption-customer-key-MD5: Base64(MD5(NewKey)) \n                x-amz-metadata-directive: metadata_directive \n                x-amz-copy-source: /source_bucket/sourceObject \n                x-amz-copy-source-if-match: etag \n                x-amz-copy-source-if-none-match: etag \n                x-amz-copy-source-if-unmodified-since: time_stamp \n                x-amz-copy-source-if-modified-since: time_stamp \n                x-amz-copy-source-server-side-encryption-customer-algorithm: AES256 \n                x-amz-copy-source-server-side-encryption-customer-key: Base64(OldKey) \n                x-amz-copy-source-server-side-encryption-customer-key-MD5: \n Base64(MD5(OldKey)) \n                 \n               <request metadata> \n                Authorization: authorization string (see Authenticating Requests (AWS \n Signature Version 4)) \n                Date: date \n              \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\nAmazon S3 API Version 2006-03-01 63Amazon Simple Storage Service API Reference\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 64Amazon Simple Storage Service API Reference\nCreateBucket\nService: Amazon S3\nNote\nThis action creates an Amazon S3 bucket.", "To create an Amazon S3 on Outposts bucket, see\nCreateBucket .\nCreates a new S3 bucket. To create a bucket, you must set up Amazon S3 and have a valid AWS \nAccess Key ID to authenticate requests.", "Anonymous requests are never allowed to create buckets. \nBy creating the bucket, you become the bucket owner.\nThere are two types of buckets: general purpose buckets and directory buckets. For more \ninformation about these bucket types, see Creating, con\ufb01guring, and working with Amazon S3 \nbuckets in the Amazon S3 User Guide .\nNote\n\u2022General purpose buckets - If you send your CreateBucket  request to the\ns3.amazonaws.com  global endpoint, the request goes to the us-east-1  Region.", "So \nthe signature calculations in Signature Version 4 must use us-east-1  as the Region, \neven if the location constraint in the request speci\ufb01es another Region where the bucket \nis to be created. If you create a bucket in a Region other than US East (N.", "Virginia), your \napplication must be able to handle 307 redirect.", "For more information, see Virtual \nhosting of buckets in the Amazon S3 User Guide .\n\u2022Directory buckets  - For directory buckets, you must make requests for this API operation \nto the Regional endpoint. These endpoints support path-style requests in the format\nhttps://s3express-control.", "region_code .amazonaws.com/ bucket-name  .", "\nVirtual-hosted-style requests aren't supported.", "For more information, see Regional and \nZonal endpoints in the Amazon S3 User Guide .\nPermissions\n\u2022General purpose bucket permissions - In addition to the s3:CreateBucket  permission, the \nfollowing permissions are required in a policy when your CreateBucket  request includes \nspeci\ufb01c headers:\nAmazon S3 API Version 2006-03-01 65Amazon Simple Storage Service API Reference\n\u2022Access control lists (ACLs) - In your CreateBucket  request, if you specify an access \ncontrol list (ACL) and set it to public-read , public-read-write , authenticated-\nread, or if you explicitly specify any other custom ACLs, both s3:CreateBucket  and\ns3:PutBucketAcl  permissions are required. In your CreateBucket  request, if you \nset the ACL to private, or if you don't specify any ACLs, only the s3:CreateBucket\npermission is required.\n\u2022Object Lock - In your CreateBucket  request, if you set x-amz-bucket-object-\nlock-enabled  to true, the s3:PutBucketObjectLockConfiguration  and\ns3:PutBucketVersioning  permissions are required.\n\u2022S3 Object Ownership - If your CreateBucket  request includes the x-amz-object-\nownership  header, then the s3:PutBucketOwnershipControls  permission is required.\nImportant\nTo set an ACL on a bucket as part of a CreateBucket  request, you must explicitly \nset S3 Object Ownership for the bucket to a di\ufb00erent value than the default,\nBucketOwnerEnforced .", "Additionally, if your desired bucket ACL grants public \naccess, you must \ufb01rst create the bucket (without the bucket ACL) and then explicitly \ndisable Block Public Access on the bucket before using PutBucketAcl  to set the \nACL. If you try to create a bucket with a public ACL, the request will fail.\nFor the majority of modern use cases in S3, we recommend that you keep all Block \nPublic Access settings enabled and keep ACLs disabled. If you would like to share \ndata with users outside of your account, you can use bucket policies as needed.", "For \nmore information, see Controlling ownership of objects and disabling ACLs for your \nbucket  and Blocking public access to your Amazon S3 storage  in the Amazon S3 \nUser Guide .\n\u2022S3 Block Public Access - If your speci\ufb01c use case requires granting public access to your \nS3 resources, you can disable Block Public Access.", "Speci\ufb01cally, you can create a new bucket \nwith Block Public Access enabled, then separately call the DeletePublicAccessBlock\nAPI.", "To use this operation, you must have the s3:PutBucketPublicAccessBlock\npermission. For more information about S3 Block Public Access, see Blocking public access \nto your Amazon S3 storage  in the Amazon S3 User Guide .\n\u2022Directory bucket permissions - You must have the s3express:CreateBucket  permission \nin an IAM identity-based policy instead of a bucket policy.", "Cross-account access to this API \noperation isn't supported.", "This operation can only be performed by the AWS account that \nAmazon S3 API Version 2006-03-01 66Amazon Simple Storage Service API Reference\nowns the resource. For more information about directory bucket policies and permissions, see\nAWS Identity and Access Management (IAM) for S3 Express One Zone in the Amazon S3 User \nGuide .\nImportant\nThe permissions for ACLs, Object Lock, S3 Object Ownership, and S3 Block Public \nAccess are not supported for directory buckets. For directory buckets, all Block Public \nAccess settings are enabled at the bucket level and S3 Object Ownership is set to \nBucket owner enforced (ACLs disabled). These settings can't be modi\ufb01ed.\nFor more information about permissions for creating and working with directory \nbuckets, see Directory buckets in the Amazon S3 User Guide . For more information \nabout supported S3 features for directory buckets, see Features of S3 Express One \nZone in the Amazon S3 User Guide .\nHTTP Host header syntax\nDirectory buckets  - The HTTP Host header syntax is s3express-\ncontrol. region.amazonaws.com .\nThe following operations are related to CreateBucket :\n\u2022PutObject\n\u2022DeleteBucket\nRequest Syntax\nPUT / HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-acl: ACL\nx-amz-grant-full-control: GrantFullControl\nx-amz-grant-read: GrantRead\nx-amz-grant-read-acp: GrantReadACP\nx-amz-grant-write: GrantWrite\nx-amz-grant-write-acp: GrantWriteACP\nx-amz-bucket-object-lock-enabled: ObjectLockEnabledForBucket\nx-amz-object-ownership: ObjectOwnership\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<CreateBucketConfiguration  xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \nAmazon S3 API Version 2006-03-01 67Amazon Simple Storage Service API Reference\n   <LocationConstraint >string</LocationConstraint > \n   <Location > \n      <Name>string</Name> \n      <Type>string</Type> \n   </Location > \n   <Bucket> \n      <DataRedundancy >string</DataRedundancy > \n      <Type>string</Type> \n   </Bucket>\n</CreateBucketConfiguration >\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe name of the bucket to create.\nGeneral purpose buckets - For information about bucket naming restrictions, see Bucket \nnaming rules  in the Amazon S3 User Guide .\nDirectory buckets  - When you use this operation with a directory bucket, \nyou must use path-style requests in the format https://s3express-\ncontrol. region_code .amazonaws.com/ bucket-name  .", "Virtual-hosted-style requests \naren't supported.", "Directory bucket names must be unique in the chosen Availability Zone.", "\nBucket names must also follow the format  bucket_base_name --az_id--x-s3  (for \nexample,  DOC-EXAMPLE-BUCKET --usw2-az1 --x-s3). For information about bucket naming \nrestrictions, see Directory bucket naming rules in the Amazon S3 User Guide\nRequired: Yes\nx-amz-acl\nThe canned ACL to apply to the bucket.\nNote\nThis functionality is not supported for directory buckets.\nValid Values: private | public-read | public-read-write | authenticated-read\nAmazon S3 API Version 2006-03-01 68Amazon Simple Storage Service API Reference\nx-amz-bucket-object-lock-enabled\nSpeci\ufb01es whether you want S3 Object Lock to be enabled for the new bucket.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-grant-full-control\nAllows grantee the read, write, read ACP, and write ACP permissions on the bucket.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-grant-read\nAllows grantee to list the objects in the bucket.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-grant-read-acp\nAllows grantee to read the bucket ACL.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-grant-write\nAllows grantee to create new objects in the bucket.\nFor the bucket and object owners of existing objects, also allows deletions and overwrites of \nthose objects.\nAmazon S3 API Version 2006-03-01 69Amazon Simple Storage Service API Reference\nNote\nThis functionality is not supported for directory buckets.\nx-amz-grant-write-acp\nAllows grantee to write the ACL for the applicable bucket.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-object-ownership\nThe container element for object ownership for a bucket's ownership controls.\nBucketOwnerPreferred  - Objects uploaded to the bucket change ownership to the bucket \nowner if the objects are uploaded with the bucket-owner-full-control  canned ACL.\nObjectWriter  - The uploading account will own the object if the object is uploaded with the\nbucket-owner-full-control  canned ACL.\nBucketOwnerEnforced  - Access control lists (ACLs) are disabled and no longer a\ufb00ect \npermissions.", "The bucket owner automatically owns and has full control over every object in \nthe bucket. The bucket only accepts PUT requests that don't specify an ACL or specify bucket \nowner full control ACLs (such as the prede\ufb01ned bucket-owner-full-control  canned ACL or \na custom ACL in XML format that grants the same permissions).\nBy default, ObjectOwnership  is set to BucketOwnerEnforced  and ACLs are disabled.", "We \nrecommend keeping ACLs disabled, except in uncommon use cases where you must control \naccess for each object individually.", "For more information about S3 Object Ownership, see\nControlling ownership of objects and disabling ACLs for your bucket in the Amazon S3 User \nGuide .\nNote\nThis functionality is not supported for directory buckets. Directory buckets use the \nbucket owner enforced setting for S3 Object Ownership.\nAmazon S3 API Version 2006-03-01 70Amazon Simple Storage Service API Reference\nValid Values: BucketOwnerPreferred | ObjectWriter | BucketOwnerEnforced\nRequest Body\nThe request accepts the following data in XML format.\nCreateBucketCon\ufb01guration\nRoot level tag for the CreateBucketCon\ufb01guration parameters.\nRequired: Yes\nBucket\nSpeci\ufb01es the information about the bucket that will be created.\nNote\nThis functionality is only supported by directory buckets.\nType: BucketInfo data type\nRequired: No\nLocation\nSpeci\ufb01es the location where the bucket will be created.\nFor directory buckets, the location type is Availability Zone.\nNote\nThis functionality is only supported by directory buckets.\nType: LocationInfo  data type\nRequired: No\nLocationConstraint\nSpeci\ufb01es the Region where the bucket will be created.", "You might choose a Region to optimize \nlatency, minimize costs, or address regulatory requirements.", "For example, if you reside in \nAmazon S3 API Version 2006-03-01 71Amazon Simple Storage Service API Reference\nEurope, you will probably \ufb01nd it advantageous to create buckets in the Europe (Ireland) Region. \nFor more information, see Accessing a bucket in the Amazon S3 User Guide .\nIf you don't specify a Region, the bucket is created in the US East (N.", "Virginia) Region (us-east-1) \nby default.\nNote\nThis functionality is not supported for directory buckets.\nType: String\nValid Values: af-south-1 | ap-east-1 | ap-northeast-1 | ap-northeast-2 | ap-\nnortheast-3 | ap-south-1 | ap-south-2 | ap-southeast-1 | ap-southeast-2 \n| ap-southeast-3 | ca-central-1 | cn-north-1 | cn-northwest-1 | EU | eu-\ncentral-1 | eu-north-1 | eu-south-1 | eu-south-2 | eu-west-1 | eu-west-2 \n| eu-west-3 | me-south-1 | sa-east-1 | us-east-2 | us-gov-east-1 | us-\ngov-west-1 | us-west-1 | us-west-2\nRequired: No\nResponse Syntax\nHTTP/1.1 200\nLocation: Location\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe response returns the following HTTP headers.\nLocation\nA forward slash followed by the name of the bucket.\nAmazon S3 API Version 2006-03-01 72Amazon Simple Storage Service API Reference\nErrors\nBucketAlreadyExists\nThe requested bucket name is not available.", "The bucket namespace is shared by all users of the \nsystem. Select a di\ufb00erent name and try again.\nHTTP Status Code: 409\nBucketAlreadyOwnedByYou\nThe bucket you tried to create already exists, and you own it.", "Amazon S3 returns this error in all \nAWS Regions except in the North Virginia Region. For legacy compatibility, if you re-create an \nexisting bucket that you already own in the North Virginia Region, Amazon S3 returns 200 OK \nand resets the bucket access control lists (ACLs).\nHTTP Status Code: 409\nExamples\nSample Request for general purpose buckets\nThis request creates a bucket named colorpictures .\n            PUT / HTTP/1.1 \n            Host: colorpictures.s3.<Region>.amazonaws.com \n            Content-Length: 0 \n            Date: Wed, 01 Mar  2006 12:00:00 GMT \n            Authorization: authorization string \n          \nSample Response for general purpose buckets\nThis example illustrates one usage of CreateBucket.\n            HTTP/1.1 200 OK \n            x-amz-id-2: \n YgIPIfBiKa2bj0KMg95r/0zo3emzU4dzsD4rcKCHQUAdQkf3ShJTOOpXUueF6QKo \n            x-amz-request-id: 236A8905248E5A01 \n            Date: Wed, 01 Mar  2006 12:00:00 GMT \nAmazon S3 API Version 2006-03-01 73Amazon Simple Storage Service API Reference\n            Location: /colorpictures \n            Content-Length: 0 \n            Connection: close \n            Server: AmazonS3 \n          \nSample Request for general purpose buckets: Setting the Region of a bucket\nThe following request sets the Region for the bucket to Europe.\n            PUT / HTTP/1.1 \n            Host: bucketName.s3.amazonaws.com \n            Date: Wed, 12 Oct 2009 17:50:00 GMT \n            Authorization: authorization string \n            Content-Type: text/plain \n            Content-Length: 124 \n            <CreateBucketConfiguration xmlns=\"http://s3.amazonaws.com/\ndoc/2006-03-01/\">  \n             <LocationConstraint>Europe</LocationConstraint>  \n            </CreateBucketConfiguration > \n          \nSample Request for general purpose buckets: Creating a bucket and applying the ObjectWriter \nsetting for S3 Object Ownership.\nThis request creates a bucket and applies the ObjectWriter  setting for Object Ownership.\n            PUT / HTTP/1.1 \n            Host: amzn-s3-demo-bucket.s3.<Region>.amazonaws.com \n            Content-Length: 0 \n            x-amz-object-ownership: ObjectWriter \n            Date: Tue, 30 Nov  2021 12:00:00 GMT \n            Authorization: authorization string \n          \nSample Response for general purpose buckets\nThis example illustrates one usage of CreateBucket.\nAmazon S3 API Version 2006-03-01 74Amazon Simple Storage Service API Reference\n            HTTP/1.1 200 OK \n            x-amz-id-2: \n YgIPIfBiKa2bj0KMg95r/0zo3emzU4dzsD4rcKCHQUAdQkf3ShJTOOpXUueF6QKo \n            x-amz-request-id: 236A8905248E5A01 \n            Date: Tue, 30 Nov  2021 12:00:00 GMT \n            Location: /amzn-s3-demo-bucket \n            Content-Length: 0 \n            Connection: close \n            Server: AmazonS3 \n          \nSample Request for general purpose buckets: Creating a bucket and con\ufb01guring access \npermissions explicitly\nThis request creates a bucket named colorpictures  and grants WRITE permission to the AWS \naccount identi\ufb01ed by an email address.\n            PUT HTTP/1.1 \n            Host: colorpictures.s3.<Region>.amazonaws.com \n            x-amz-date: Sat, 07 Apr 2012 00:54:40 GMT \n            Authorization: authorization string \n            x-amz-grant-write: emailAddress=\"xyz@amazon.com\", \n emailAddress=\"abc@amazon.com\" \n          \nSample Response for general purpose buckets\nThis example illustrates one usage of CreateBucket.\n           HTTP/1.1 200 OK \n          \nSample Request for general purpose buckets: Creating a bucket and con\ufb01guring access \npermission using a canned ACL\nThis request creates a bucket named colorpictures  and sets the ACL to private.\nAmazon S3 API Version 2006-03-01 75Amazon Simple Storage Service API Reference\n            PUT / HTTP/1.1 \n            Host: colorpictures.s3.<Region>.amazonaws.com \n            Content-Length: 0 \n            x-amz-acl: private \n            Date: Wed, 01 Mar  2006 12:00:00 GMT \n            Authorization: authorization string \n          \nSample Response for general purpose buckets\nThis example illustrates one usage of CreateBucket.\n            HTTP/1.1 200 OK \n            x-amz-id-2: \n YgIPIfBiKa2bj0KMg95r/0zo3emzU4dzsD4rcKCHQUAdQkf3ShJTOOpXUueF6QKo \n            x-amz-request-id: 236A8905248E5A01 \n            Date: Wed, 01 Mar  2006 12:00:00 GMT \n            Location: /colorpictures \n            Content-Length: 0 \n            Connection: close \n            Server: AmazonS3 \n          \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\nAmazon S3 API Version 2006-03-01 76Amazon Simple Storage Service API Reference\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 77Amazon Simple Storage Service API Reference\nCreateMultipartUpload\nService: Amazon S3\nThis action initiates a multipart upload and returns an upload ID.", "This upload ID is used to \nassociate all of the parts in the speci\ufb01c multipart upload. You specify this upload ID in each of \nyour subsequent upload part requests (see UploadPart). You also include this upload ID in the \ufb01nal \nrequest to either complete or abort the multipart upload request.", "For more information about \nmultipart uploads, see Multipart Upload Overview in the Amazon S3 User Guide .\nNote\nAfter you initiate a multipart upload and upload one or more parts, to stop being charged \nfor storing the uploaded parts, you must either complete or abort the multipart upload. \nAmazon S3 frees up the space used to store the parts and stops charging you for storing \nthem only after you either complete or abort a multipart upload.\nIf you have con\ufb01gured a lifecycle rule to abort incomplete multipart uploads, the created \nmultipart upload must be completed within the number of days speci\ufb01ed in the bucket lifecycle \ncon\ufb01guration. Otherwise, the incomplete multipart upload becomes eligible for an abort action \nand Amazon S3 aborts the multipart upload. For more information, see Aborting Incomplete \nMultipart Uploads Using a Bucket Lifecycle Con\ufb01guration.\nNote\n\u2022Directory buckets  - S3 Lifecycle is not supported by directory buckets.\n\u2022Directory buckets  - For directory buckets, you must make requests for this API operation \nto the Zonal endpoint. These endpoints support virtual-hosted-style requests in the \nformat https:// bucket_name .s3express- az_id.region.amazonaws.com/ key-\nname .", "Path-style requests are not supported.", "For more information, see Regional and \nZonal endpoints in the Amazon S3 User Guide .\nRequest signing\nFor request signing, multipart upload is just a series of regular requests. You initiate a multipart \nupload, send one or more requests to upload parts, and then complete the multipart upload \nAmazon S3 API Version 2006-03-01 78Amazon Simple Storage Service API Reference\nprocess.", "You sign each request individually. There is nothing special about signing multipart \nupload requests.", "For more information about signing, see Authenticating Requests (AWS \nSignature Version 4) in the Amazon S3 User Guide .\nPermissions\n\u2022General purpose bucket permissions - To perform a multipart upload with encryption using \nan AWS Key Management Service (AWS KMS) KMS key, the requester must have permission to \nthe kms:Decrypt  and kms:GenerateDataKey  actions on the key.", "The requester must also \nhave permissions for the kms:GenerateDataKey  action for the CreateMultipartUpload\nAPI. Then, the requester needs permissions for the kms:Decrypt  action on the UploadPart\nand UploadPartCopy  APIs.", "These permissions are required because Amazon S3 must \ndecrypt and read data from the encrypted \ufb01le parts before it completes the multipart upload. \nFor more information, see Multipart upload API and permissions and Protecting data using \nserver-side encryption with AWS KMS in the Amazon S3 User Guide .\n\u2022Directory bucket permissions - To grant access to this API operation on a directory \nbucket, we recommend that you use the CreateSession  API operation for session-based \nauthorization. Speci\ufb01cally, you grant the s3express:CreateSession  permission to the \ndirectory bucket in a bucket policy or an IAM identity-based policy.", "Then, you make the\nCreateSession  API call on the bucket to obtain a session token. With the session token in \nyour request header, you can make API requests to this operation. After the session token \nexpires, you make another CreateSession  API call to generate a new session token for \nuse. AWS CLI or SDKs create session and refresh the session token automatically to avoid \nservice interruptions when a session expires.", "For more information about authorization, see\nCreateSession .\nEncryption\n\u2022General purpose buckets - Server-side encryption is for data encryption at rest.", "Amazon S3 \nencrypts your data as it writes it to disks in its data centers and decrypts it when you access it. \nAmazon S3 automatically encrypts all new objects that are uploaded to an S3 bucket.", "When \ndoing a multipart upload, if you don't specify encryption information in your request, the \nencryption setting of the uploaded parts is set to the default encryption con\ufb01guration of \nthe destination bucket.", "By default, all buckets have a base level of encryption con\ufb01guration \nthat uses server-side encryption with Amazon S3 managed keys (SSE-S3). If the destination \nbucket has a default encryption con\ufb01guration that uses server-side encryption with an AWS \nKey Management Service (AWS KMS) key (SSE-KMS), or a customer-provided encryption key \n(SSE-C), Amazon S3 uses the corresponding KMS key, or a customer-provided key to encrypt \nthe uploaded parts. When you perform a CreateMultipartUpload operation, if you want to use \nAmazon S3 API Version 2006-03-01 79Amazon Simple Storage Service API Reference\na di\ufb00erent type of encryption setting for the uploaded parts, you can request that Amazon \nS3 encrypts the object with a di\ufb00erent encryption key (such as an Amazon S3 managed \nkey, a KMS key, or a customer-provided key).", "When the encryption setting in your request is \ndi\ufb00erent from the default encryption con\ufb01guration of the destination bucket, the encryption \nsetting in your request takes precedence.", "If you choose to provide your own encryption key, \nthe request headers you provide in UploadPart and UploadPartCopy requests must match the \nheaders you used in the CreateMultipartUpload  request.\n\u2022Use KMS keys (SSE-KMS) that include the AWS managed key (aws/s3) and AWS KMS \ncustomer managed keys stored in AWS Key Management Service (AWS KMS) \u2013 If you want \nAWS to manage the keys used to encrypt data, specify the following headers in the request.\n\u2022x-amz-server-side-encryption\n\u2022x-amz-server-side-encryption-aws-kms-key-id\n\u2022x-amz-server-side-encryption-context\nNote\n\u2022If you specify x-amz-server-side-encryption:aws:kms , but don't provide\nx-amz-server-side-encryption-aws-kms-key-id , Amazon S3 uses the \nAWS managed key (aws/s3 key) in AWS KMS to protect the data.\n\u2022To perform a multipart upload with encryption by using an AWS KMS \nkey, the requester must have permission to the kms:Decrypt  and\nkms:GenerateDataKey*  actions on the key. These permissions are required \nbecause Amazon S3 must decrypt and read data from the encrypted \ufb01le parts \nbefore it completes the multipart upload. For more information, see Multipart \nupload API and permissions  and Protecting data using server-side encryption \nwith AWS KMS in the Amazon S3 User Guide .\n\u2022If your AWS Identity and Access Management (IAM) user or role is in the same \nAWS account as the KMS key, then you must have these permissions on the key \npolicy. If your IAM user or role is in a di\ufb00erent account from the key, then you \nmust have the permissions on both the key policy and your IAM user or role.\n\u2022All GET and PUT requests for an object protected by AWS KMS fail if you don't \nmake them by using Secure Sockets Layer (SSL), Transport Layer Security (TLS), \nor Signature Version 4.", "For information about con\ufb01guring any of the o\ufb03cially \nsupported AWS SDKs and AWS CLI, see Specifying the Signature Version in \nRequest Authentication in the Amazon S3 User Guide .\nAmazon S3 API Version 2006-03-01 80Amazon Simple Storage Service API Reference\nFor more information about server-side encryption with AWS KMS keys (SSE-KMS), see\nProtecting Data Using Server-Side Encryption with KMS keys in the Amazon S3 User Guide .\n\u2022Use customer-provided encryption keys (SSE-C) \u2013 If you want to manage your own \nencryption keys, provide all the following headers in the request.\n\u2022x-amz-server-side-encryption-customer-algorithm\n\u2022x-amz-server-side-encryption-customer-key\n\u2022x-amz-server-side-encryption-customer-key-MD5\nFor more information about server-side encryption with customer-provided encryption \nkeys (SSE-C), see  Protecting data using server-side encryption with customer-provided \nencryption keys (SSE-C) in the Amazon S3 User Guide .\n\u2022Directory buckets - For directory buckets, there are only two supported options for server-\nside encryption: server-side encryption with Amazon S3 managed keys (SSE-S3) (AES256 ) \nand server-side encryption with AWS KMS keys (SSE-KMS) (aws:kms).", "We recommend that \nthe bucket's default encryption uses the desired encryption con\ufb01guration and you don't \noverride the bucket default encryption in your CreateSession  requests or PUT object \nrequests.", "Then, new objects are automatically encrypted with the desired encryption settings.", "\nFor more information, see Protecting data with server-side encryption in the Amazon S3 User \nGuide .", "For more information about the encryption overriding behaviors in directory buckets, \nsee Specifying server-side encryption with AWS KMS for new object uploads.\nIn the Zonal endpoint API calls (except CopyObject and UploadPartCopy) using the REST API, \nthe encryption request headers must match the encryption settings that are speci\ufb01ed in the\nCreateSession  request. You can't override the values of the encryption settings (x-amz-\nserver-side-encryption , x-amz-server-side-encryption-aws-kms-key-id , x-\namz-server-side-encryption-context , and x-amz-server-side-encryption-\nbucket-key-enabled ) that are speci\ufb01ed in the CreateSession  request. You don't need \nto explicitly specify these encryption settings values in Zonal endpoint API calls, and Amazon \nS3 will use the encryption settings values from the CreateSession  request to protect new \nobjects in the directory bucket.\nNote\nWhen you use the CLI or the AWS SDKs, for CreateSession , the session token \nrefreshes automatically to avoid service interruptions when a session expires. The \nAmazon S3 API Version 2006-03-01 81Amazon Simple Storage Service API Reference\nCLI or the AWS SDKs use the bucket's default encryption con\ufb01guration for the\nCreateSession  request.", "It's not supported to override the encryption settings \nvalues in the CreateSession  request.", "So in the Zonal endpoint API calls (except\nCopyObject and UploadPartCopy), the encryption request headers must match the \ndefault encryption con\ufb01guration of the directory bucket.\nNote\nFor directory buckets, when you perform a CreateMultipartUpload  operation \nand an UploadPartCopy  operation, the request headers you provide in the\nCreateMultipartUpload  request must match the default encryption con\ufb01guration \nof the destination bucket.\nHTTP Host header syntax\nDirectory buckets  - The HTTP Host header syntax is \nBucket_name .s3express- az_id.region.amazonaws.com .\nThe following operations are related to CreateMultipartUpload :\n\u2022UploadPart\n\u2022CompleteMultipartUpload\n\u2022AbortMultipartUpload\n\u2022ListParts\n\u2022ListMultipartUploads\nRequest Syntax\nPOST /{Key+}?uploads HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-acl: ACL\nCache-Control: CacheControl\nContent-Disposition: ContentDisposition\nContent-Encoding: ContentEncoding\nContent-Language: ContentLanguage\nContent-Type: ContentType\nAmazon S3 API Version 2006-03-01 82Amazon Simple Storage Service API Reference\nExpires: Expires\nx-amz-grant-full-control: GrantFullControl\nx-amz-grant-read: GrantRead\nx-amz-grant-read-acp: GrantReadACP\nx-amz-grant-write-acp: GrantWriteACP\nx-amz-server-side-encryption: ServerSideEncryption\nx-amz-storage-class: StorageClass\nx-amz-website-redirect-location: WebsiteRedirectLocation\nx-amz-server-side-encryption-customer-algorithm: SSECustomerAlgorithm\nx-amz-server-side-encryption-customer-key: SSECustomerKey\nx-amz-server-side-encryption-customer-key-MD5: SSECustomerKeyMD5\nx-amz-server-side-encryption-aws-kms-key-id: SSEKMSKeyId\nx-amz-server-side-encryption-context: SSEKMSEncryptionContext\nx-amz-server-side-encryption-bucket-key-enabled: BucketKeyEnabled\nx-amz-request-payer: RequestPayer\nx-amz-tagging: Tagging\nx-amz-object-lock-mode: ObjectLockMode\nx-amz-object-lock-retain-until-date: ObjectLockRetainUntilDate\nx-amz-object-lock-legal-hold: ObjectLockLegalHoldStatus\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nx-amz-checksum-algorithm: ChecksumAlgorithm\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe name of the bucket where the multipart upload is initiated and where the object is \nuploaded.\nDirectory buckets - When you use this operation with a directory \nbucket, you must use virtual-hosted-style requests in the format \nBucket_name .s3express- az_id.region.amazonaws.com .", "Path-style requests are not \nsupported.", "Directory bucket names must be unique in the chosen Availability Zone.", "Bucket \nnames must follow the format  bucket_base_name --az-id--x-s3  (for example,  DOC-\nEXAMPLE-BUCKET --usw2-az1 --x-s3). For information about bucket naming restrictions, see\nDirectory bucket naming rules in the Amazon S3 User Guide .\nAccess points - When you use this action with an access point, you must provide the alias of the \naccess point in place of the bucket name or specify the access point ARN.", "When using the access \npoint ARN, you must direct requests to the access point hostname.", "The access point hostname \nAmazon S3 API Version 2006-03-01 83Amazon Simple Storage Service API Reference\ntakes the form AccessPointName-AccountId .s3-accesspoint.Region.amazonaws.com.", "When using \nthis action with an access point through the AWS SDKs, you provide the access point ARN in \nplace of the bucket name. For more information about access point ARNs, see Using access \npoints  in the Amazon S3 User Guide .\nNote\nAccess points and Object Lambda access points are not supported by directory buckets.\nS3 on Outposts  - When you use this action with Amazon S3 on Outposts, you must direct \nrequests to the S3 on Outposts hostname. The S3 on Outposts hostname takes the form \nAccessPointName -AccountId .outpostID .s3-outposts.", "Region.amazonaws.com .", "\nWhen you use this action with S3 on Outposts through the AWS SDKs, you provide the Outposts \naccess point ARN in place of the bucket name. For more information about S3 on Outposts \nARNs, see What is S3 on Outposts?", "in the Amazon S3 User Guide .\nRequired: Yes\nCache-Control\nSpeci\ufb01es caching behavior along the request/reply chain.\nContent-Disposition\nSpeci\ufb01es presentational information for the object.\nContent-Encoding\nSpeci\ufb01es what content encodings have been applied to the object and thus what decoding \nmechanisms must be applied to obtain the media-type referenced by the Content-Type header \n\ufb01eld.\nNote\nFor directory buckets, only the aws-chunked  value is supported in this header \ufb01eld.\nContent-Language\nThe language that the content is in.\nAmazon S3 API Version 2006-03-01 84Amazon Simple Storage Service API Reference\nContent-Type\nA standard MIME type describing the format of the object data.\nExpires\nThe date and time at which the object is no longer cacheable.\nKey\nObject key for which the multipart upload is to be initiated.\nLength Constraints: Minimum length of 1.\nRequired: Yes\nx-amz-acl\nThe canned ACL to apply to the object. Amazon S3 supports a set of prede\ufb01ned ACLs, known \nas canned ACLs.", "Each canned ACL has a prede\ufb01ned set of grantees and permissions.", "For more \ninformation, see Canned ACL in the Amazon S3 User Guide .\nBy default, all objects are private.", "Only the owner has full access control.", "When uploading an \nobject, you can grant access permissions to individual AWS accounts or to prede\ufb01ned groups \nde\ufb01ned by Amazon S3.", "These permissions are then added to the access control list (ACL) on the \nnew object. For more information, see Using ACLs.", "One way to grant the permissions using the \nrequest headers is to specify a canned ACL with the x-amz-acl  request header.\nNote\n\u2022This functionality is not supported for directory buckets.\n\u2022This functionality is not supported for Amazon S3 on Outposts.\nValid Values: private | public-read | public-read-write | authenticated-read \n| aws-exec-read | bucket-owner-read | bucket-owner-full-control\nx-amz-checksum-algorithm\nIndicates the algorithm that you want Amazon S3 to use to create the checksum for the object. \nFor more information, see Checking object integrity in the Amazon S3 User Guide .\nValid Values: CRC32 | CRC32C | SHA1 | SHA256\nAmazon S3 API Version 2006-03-01 85Amazon Simple Storage Service API Reference\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner.", "If the account ID that you provide does not match \nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nx-amz-grant-full-control\nSpecify access permissions explicitly to give the grantee READ, READ_ACP, and WRITE_ACP \npermissions on the object.\nBy default, all objects are private.", "Only the owner has full access control.", "When uploading an \nobject, you can use this header to explicitly grant access permissions to speci\ufb01c AWS accounts \nor groups.", "This header maps to speci\ufb01c permissions that Amazon S3 supports in an ACL. For \nmore information, see Access Control List (ACL) Overview in the Amazon S3 User Guide .\nYou specify each grantee as a type=value pair, where the type is one of the following:\n\u2022id \u2013 if the value speci\ufb01ed is the canonical user ID of an AWS account\n\u2022uri \u2013 if you are granting permissions to a prede\ufb01ned group\n\u2022emailAddress  \u2013 if the value speci\ufb01ed is the email address of an AWS account\nNote\nUsing email addresses to specify a grantee is only supported in the following AWS \nRegions:\n\u2022US East (N.", "Virginia)\n\u2022US West (N.", "California)\n\u2022US West (Oregon)\n\u2022Asia Paci\ufb01c (Singapore)\n\u2022Asia Paci\ufb01c (Sydney)\n\u2022Asia Paci\ufb01c (Tokyo)\n\u2022Europe (Ireland)\n\u2022South America (S\u00e3o Paulo)\nFor a list of all the Amazon S3 supported Regions and endpoints, see Regions and \nEndpoints  in the AWS General Reference.\nAmazon S3 API Version 2006-03-01 86Amazon Simple Storage Service API Reference\nFor example, the following x-amz-grant-read  header grants the AWS accounts identi\ufb01ed by \naccount IDs permissions to read object data and its metadata:\nx-amz-grant-read: id=\"11112222333\", id=\"444455556666\"\nNote\n\u2022This functionality is not supported for directory buckets.\n\u2022This functionality is not supported for Amazon S3 on Outposts.\nx-amz-grant-read\nSpecify access permissions explicitly to allow grantee to read the object data and its metadata.\nBy default, all objects are private.", "Only the owner has full access control.", "When uploading an \nobject, you can use this header to explicitly grant access permissions to speci\ufb01c AWS accounts \nor groups.", "This header maps to speci\ufb01c permissions that Amazon S3 supports in an ACL. For \nmore information, see Access Control List (ACL) Overview in the Amazon S3 User Guide .\nYou specify each grantee as a type=value pair, where the type is one of the following:\n\u2022id \u2013 if the value speci\ufb01ed is the canonical user ID of an AWS account\n\u2022uri \u2013 if you are granting permissions to a prede\ufb01ned group\n\u2022emailAddress  \u2013 if the value speci\ufb01ed is the email address of an AWS account\nNote\nUsing email addresses to specify a grantee is only supported in the following AWS \nRegions:\n\u2022US East (N.", "Virginia)\n\u2022US West (N.", "California)\n\u2022US West (Oregon)\n\u2022Asia Paci\ufb01c (Singapore)\n\u2022Asia Paci\ufb01c (Sydney)\n\u2022Asia Paci\ufb01c (Tokyo)\n\u2022Europe (Ireland)\nAmazon S3 API Version 2006-03-01 87Amazon Simple Storage Service API Reference\n\u2022South America (S\u00e3o Paulo)\nFor a list of all the Amazon S3 supported Regions and endpoints, see Regions and \nEndpoints  in the AWS General Reference.\nFor example, the following x-amz-grant-read  header grants the AWS accounts identi\ufb01ed by \naccount IDs permissions to read object data and its metadata:\nx-amz-grant-read: id=\"11112222333\", id=\"444455556666\"\nNote\n\u2022This functionality is not supported for directory buckets.\n\u2022This functionality is not supported for Amazon S3 on Outposts.\nx-amz-grant-read-acp\nSpecify access permissions explicitly to allows grantee to read the object ACL.\nBy default, all objects are private.", "Only the owner has full access control.", "When uploading an \nobject, you can use this header to explicitly grant access permissions to speci\ufb01c AWS accounts \nor groups.", "This header maps to speci\ufb01c permissions that Amazon S3 supports in an ACL. For \nmore information, see Access Control List (ACL) Overview in the Amazon S3 User Guide .\nYou specify each grantee as a type=value pair, where the type is one of the following:\n\u2022id \u2013 if the value speci\ufb01ed is the canonical user ID of an AWS account\n\u2022uri \u2013 if you are granting permissions to a prede\ufb01ned group\n\u2022emailAddress  \u2013 if the value speci\ufb01ed is the email address of an AWS account\nNote\nUsing email addresses to specify a grantee is only supported in the following AWS \nRegions:\n\u2022US East (N.", "Virginia)\n\u2022US West (N.", "California)\n\u2022US West (Oregon)\n\u2022Asia Paci\ufb01c (Singapore)\nAmazon S3 API Version 2006-03-01 88Amazon Simple Storage Service API Reference\n\u2022Asia Paci\ufb01c (Sydney)\n\u2022Asia Paci\ufb01c (Tokyo)\n\u2022Europe (Ireland)\n\u2022South America (S\u00e3o Paulo)\nFor a list of all the Amazon S3 supported Regions and endpoints, see Regions and \nEndpoints  in the AWS General Reference.\nFor example, the following x-amz-grant-read  header grants the AWS accounts identi\ufb01ed by \naccount IDs permissions to read object data and its metadata:\nx-amz-grant-read: id=\"11112222333\", id=\"444455556666\"\nNote\n\u2022This functionality is not supported for directory buckets.\n\u2022This functionality is not supported for Amazon S3 on Outposts.\nx-amz-grant-write-acp\nSpecify access permissions explicitly to allows grantee to allow grantee to write the ACL for the \napplicable object.\nBy default, all objects are private.", "Only the owner has full access control.", "When uploading an \nobject, you can use this header to explicitly grant access permissions to speci\ufb01c AWS accounts \nor groups.", "This header maps to speci\ufb01c permissions that Amazon S3 supports in an ACL. For \nmore information, see Access Control List (ACL) Overview in the Amazon S3 User Guide .\nYou specify each grantee as a type=value pair, where the type is one of the following:\n\u2022id \u2013 if the value speci\ufb01ed is the canonical user ID of an AWS account\n\u2022uri \u2013 if you are granting permissions to a prede\ufb01ned group\n\u2022emailAddress  \u2013 if the value speci\ufb01ed is the email address of an AWS account\nNote\nUsing email addresses to specify a grantee is only supported in the following AWS \nRegions:\nAmazon S3 API Version 2006-03-01 89Amazon Simple Storage Service API Reference\n\u2022US East (N.", "Virginia)\n\u2022US West (N.", "California)\n\u2022US West (Oregon)\n\u2022Asia Paci\ufb01c (Singapore)\n\u2022Asia Paci\ufb01c (Sydney)\n\u2022Asia Paci\ufb01c (Tokyo)\n\u2022Europe (Ireland)\n\u2022South America (S\u00e3o Paulo)\nFor a list of all the Amazon S3 supported Regions and endpoints, see Regions and \nEndpoints  in the AWS General Reference.\nFor example, the following x-amz-grant-read  header grants the AWS accounts identi\ufb01ed by \naccount IDs permissions to read object data and its metadata:\nx-amz-grant-read: id=\"11112222333\", id=\"444455556666\"\nNote\n\u2022This functionality is not supported for directory buckets.\n\u2022This functionality is not supported for Amazon S3 on Outposts.\nx-amz-object-lock-legal-hold\nSpeci\ufb01es whether you want to apply a legal hold to the uploaded object.\nNote\nThis functionality is not supported for directory buckets.\nValid Values: ON | OFF\nx-amz-object-lock-mode\nSpeci\ufb01es the Object Lock mode that you want to apply to the uploaded object.\nAmazon S3 API Version 2006-03-01 90Amazon Simple Storage Service API Reference\nNote\nThis functionality is not supported for directory buckets.\nValid Values: GOVERNANCE | COMPLIANCE\nx-amz-object-lock-retain-until-date\nSpeci\ufb01es the date and time when you want the Object Lock to expire.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-request-payer\nCon\ufb01rms that the requester knows that they will be charged for the request.", "Bucket owners \nneed not specify this parameter in their requests.", "If either the source or destination S3 \nbucket has Requester Pays enabled, the requester will pay for corresponding charges to copy \nthe object. For information about downloading objects from Requester Pays buckets, see\nDownloading Objects in Requester Pays Buckets in the Amazon S3 User Guide .\nNote\nThis functionality is not supported for directory buckets.\nValid Values: requester\nx-amz-server-side-encryption\nThe server-side encryption algorithm used when you store this object in Amazon S3 (for \nexample, AES256 , aws:kms ).\n\u2022Directory buckets  - For directory buckets, there are only two supported options for server-\nside encryption: server-side encryption with Amazon S3 managed keys (SSE-S3) (AES256 ) \nand server-side encryption with AWS KMS keys (SSE-KMS) (aws:kms). We recommend that \nthe bucket's default encryption uses the desired encryption con\ufb01guration and you don't \noverride the bucket default encryption in your CreateSession  requests or PUT object \nAmazon S3 API Version 2006-03-01 91Amazon Simple Storage Service API Reference\nrequests.", "Then, new objects are automatically encrypted with the desired encryption settings.", "\nFor more information, see Protecting data with server-side encryption in the Amazon S3 User \nGuide .", "For more information about the encryption overriding behaviors in directory buckets, \nsee Specifying server-side encryption with AWS KMS for new object uploads.\nIn the Zonal endpoint API calls (except CopyObject and UploadPartCopy) using the REST API, \nthe encryption request headers must match the encryption settings that are speci\ufb01ed in the\nCreateSession  request. You can't override the values of the encryption settings (x-amz-\nserver-side-encryption , x-amz-server-side-encryption-aws-kms-key-id , x-\namz-server-side-encryption-context , and x-amz-server-side-encryption-\nbucket-key-enabled ) that are speci\ufb01ed in the CreateSession  request. You don't need \nto explicitly specify these encryption settings values in Zonal endpoint API calls, and Amazon \nS3 will use the encryption settings values from the CreateSession  request to protect new \nobjects in the directory bucket.\nNote\nWhen you use the CLI or the AWS SDKs, for CreateSession , the session token \nrefreshes automatically to avoid service interruptions when a session expires. The \nCLI or the AWS SDKs use the bucket's default encryption con\ufb01guration for the\nCreateSession  request. It's not supported to override the encryption settings \nvalues in the CreateSession  request.", "So in the Zonal endpoint API calls (except\nCopyObject and UploadPartCopy), the encryption request headers must match the \ndefault encryption con\ufb01guration of the directory bucket.\nValid Values: AES256 | aws:kms | aws:kms:dsse\nx-amz-server-side-encryption-aws-kms-key-id\nSpeci\ufb01es the AWS KMS key ID (Key ID, Key ARN, or Key Alias) to use for object encryption. If the \nKMS key doesn't exist in the same account that's issuing the command, you must use the full \nKey ARN not the Key ID.\nGeneral purpose buckets - If you specify x-amz-server-side-encryption  with aws:kms\nor aws:kms:dsse , this header speci\ufb01es the ID (Key ID, Key ARN, or Key Alias) of the AWS KMS \nkey to use. If you specify x-amz-server-side-encryption:aws:kms  or x-amz-server-\nside-encryption:aws:kms:dsse , but do not provide x-amz-server-side-encryption-\naws-kms-key-id , Amazon S3 uses the AWS managed key (aws/s3) to protect the data.\nAmazon S3 API Version 2006-03-01 92Amazon Simple Storage Service API Reference\nDirectory buckets - If you specify x-amz-server-side-encryption  with aws:kms , the \nx-amz-server-side-encryption-aws-kms-key-id  header is implicitly assigned the \nID of the AWS KMS symmetric encryption customer managed key that's con\ufb01gured for your \ndirectory bucket's default encryption setting. If you want to specify the  x-amz-server-\nside-encryption-aws-kms-key-id  header explicitly, you can only specify it with the ID \n(Key ID or Key ARN) of the AWS KMS customer managed key that's con\ufb01gured for your directory \nbucket's default encryption setting.", "Otherwise, you get an HTTP 400 Bad Request  error.", "Only \nuse the key ID or key ARN.", "The key alias format of the KMS key isn't supported.", "Your SSE-KMS \ncon\ufb01guration can only support 1 customer managed key per directory bucket for the lifetime of \nthe bucket.", "The AWS managed key (aws/s3) isn't supported.\nx-amz-server-side-encryption-bucket-key-enabled\nSpeci\ufb01es whether Amazon S3 should use an S3 Bucket Key for object encryption with server-\nside encryption using AWS Key Management Service (AWS KMS) keys (SSE-KMS).\nGeneral purpose buckets - Setting this header to true causes Amazon S3 to use an S3 Bucket \nKey for object encryption with SSE-KMS. Also, specifying this header with a PUT action doesn't \na\ufb00ect bucket-level settings for S3 Bucket Key.\nDirectory buckets - S3 Bucket Keys are always enabled for GET and PUT operations in a \ndirectory bucket and can\u2019t be disabled. S3 Bucket Keys aren't supported, when you copy SSE-\nKMS encrypted objects from general purpose buckets to directory buckets, from directory \nbuckets to general purpose buckets, or between directory buckets, through CopyObject,\nUploadPartCopy, the Copy operation in Batch Operations, or the import jobs. In this case, \nAmazon S3 makes a call to AWS KMS every time a copy request is made for a KMS-encrypted \nobject.\nx-amz-server-side-encryption-context\nSpeci\ufb01es the AWS KMS Encryption Context to use for object encryption.", "The value of this \nheader is a Base64-encoded string of a UTF-8 encoded JSON, which contains the encryption \ncontext as key-value pairs.\nDirectory buckets - You can optionally provide an explicit encryption context value. The value \nmust match the default encryption context - the bucket Amazon Resource Name (ARN).", "An \nadditional encryption context value is not supported.\nx-amz-server-side-encryption-customer-algorithm\nSpeci\ufb01es the algorithm to use when encrypting the object (for example, AES256).\nAmazon S3 API Version 2006-03-01 93Amazon Simple Storage Service API Reference\nNote\nThis functionality is not supported for directory buckets.\nx-amz-server-side-encryption-customer-key\nSpeci\ufb01es the customer-provided encryption key for Amazon S3 to use in encrypting data. \nThis value is used to store the object and then it is discarded; Amazon S3 does not store the \nencryption key.", "The key must be appropriate for use with the algorithm speci\ufb01ed in the x-amz-\nserver-side-encryption-customer-algorithm  header.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-server-side-encryption-customer-key-MD5\nSpeci\ufb01es the 128-bit MD5 digest of the customer-provided encryption key according to RFC \n1321.", "Amazon S3 uses this header for a message integrity check to ensure that the encryption \nkey was transmitted without error.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-storage-class\nBy default, Amazon S3 uses the STANDARD Storage Class to store newly created objects.", "\nThe STANDARD storage class provides high durability and high availability. Depending on \nperformance needs, you can specify a di\ufb00erent Storage Class.", "For more information, see\nStorage Classes  in the Amazon S3 User Guide .\nNote\n\u2022For directory buckets, only the S3 Express One Zone storage class is supported to \nstore newly created objects.\nAmazon S3 API Version 2006-03-01 94Amazon Simple Storage Service API Reference\n\u2022Amazon S3 on Outposts only uses the OUTPOSTS Storage Class.\nValid Values: STANDARD | REDUCED_REDUNDANCY | STANDARD_IA | ONEZONE_IA | \nINTELLIGENT_TIERING | GLACIER | DEEP_ARCHIVE | OUTPOSTS | GLACIER_IR | \nSNOW | EXPRESS_ONEZONE\nx-amz-tagging\nThe tag-set for the object.", "The tag-set must be encoded as URL Query parameters.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-website-redirect-location\nIf the bucket is con\ufb01gured as a website, redirects requests for this object to another object in \nthe same bucket or to an external URL. Amazon S3 stores the value of this header in the object \nmetadata.\nNote\nThis functionality is not supported for directory buckets.\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\nx-amz-abort-date: AbortDate\nx-amz-abort-rule-id: AbortRuleId\nx-amz-server-side-encryption: ServerSideEncryption\nx-amz-server-side-encryption-customer-algorithm: SSECustomerAlgorithm\nx-amz-server-side-encryption-customer-key-MD5: SSECustomerKeyMD5\nx-amz-server-side-encryption-aws-kms-key-id: SSEKMSKeyId\nx-amz-server-side-encryption-context: SSEKMSEncryptionContext\nAmazon S3 API Version 2006-03-01 95Amazon Simple Storage Service API Reference\nx-amz-server-side-encryption-bucket-key-enabled: BucketKeyEnabled\nx-amz-request-charged: RequestCharged\nx-amz-checksum-algorithm: ChecksumAlgorithm\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<InitiateMultipartUploadResult > \n   <Bucket>string</Bucket> \n   <Key>string</Key> \n   <UploadId >string</UploadId >\n</InitiateMultipartUploadResult >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe response returns the following HTTP headers.\nx-amz-abort-date\nIf the bucket has a lifecycle rule con\ufb01gured with an action to abort incomplete multipart \nuploads and the pre\ufb01x in the lifecycle rule matches the object name in the request, the \nresponse includes this header.", "The header indicates when the initiated multipart upload \nbecomes eligible for an abort operation.", "For more information, see  Aborting Incomplete \nMultipart Uploads Using a Bucket Lifecycle Con\ufb01guration in the Amazon S3 User Guide .\nThe response also includes the x-amz-abort-rule-id  header that provides the ID of the \nlifecycle con\ufb01guration rule that de\ufb01nes the abort action.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-abort-rule-id\nThis header is returned along with the x-amz-abort-date  header. It identi\ufb01es the applicable \nlifecycle con\ufb01guration rule that de\ufb01nes the action to abort incomplete multipart uploads.\nNote\nThis functionality is not supported for directory buckets.\nAmazon S3 API Version 2006-03-01 96Amazon Simple Storage Service API Reference\nx-amz-checksum-algorithm\nThe algorithm that was used to create a checksum of the object.\nValid Values: CRC32 | CRC32C | SHA1 | SHA256\nx-amz-request-charged\nIf present, indicates that the requester was successfully charged for the request.\nNote\nThis functionality is not supported for directory buckets.\nValid Values: requester\nx-amz-server-side-encryption\nThe server-side encryption algorithm used when you store this object in Amazon S3 (for \nexample, AES256 , aws:kms ).\nValid Values: AES256 | aws:kms | aws:kms:dsse\nx-amz-server-side-encryption-aws-kms-key-id\nIf present, indicates the ID of the KMS key that was used for object encryption.\nx-amz-server-side-encryption-bucket-key-enabled\nIndicates whether the multipart upload uses an S3 Bucket Key for server-side encryption with \nAWS Key Management Service (AWS KMS) keys (SSE-KMS).\nx-amz-server-side-encryption-context\nIf present, indicates the AWS KMS Encryption Context to use for object encryption. The value \nof this header is a Base64-encoded string of a UTF-8 encoded JSON, which contains the \nencryption context as key-value pairs.\nx-amz-server-side-encryption-customer-algorithm\nIf server-side encryption with a customer-provided encryption key was requested, the response \nwill include this header to con\ufb01rm the encryption algorithm that's used.\nAmazon S3 API Version 2006-03-01 97Amazon Simple Storage Service API Reference\nNote\nThis functionality is not supported for directory buckets.\nx-amz-server-side-encryption-customer-key-MD5\nIf server-side encryption with a customer-provided encryption key was requested, the \nresponse will include this header to provide the round-trip message integrity veri\ufb01cation of the \ncustomer-provided encryption key.\nNote\nThis functionality is not supported for directory buckets.\nThe following data is returned in XML format by the service.\nInitiateMultipartUploadResult\nRoot level tag for the InitiateMultipartUploadResult parameters.\nRequired: Yes\nBucket\nThe name of the bucket to which the multipart upload was initiated. Does not return the access \npoint ARN or access point alias if used.\nNote\nAccess points are not supported by directory buckets.\nType: String\nKey\nObject key for which the multipart upload was initiated.\nType: String\nAmazon S3 API Version 2006-03-01 98Amazon Simple Storage Service API Reference\nLength Constraints: Minimum length of 1.\nUploadId\nID for the initiated multipart upload.\nType: String\nExamples\nSample Request for general purpose buckets\nThis action initiates a multipart upload for the example-object  object.\n            POST /example-object?uploads HTTP/1.1 \n            Host: example-bucket.s3.<Region>.amazonaws.com \n            Date: Mon, 1 Nov 2010 20:34:56 GMT \n            Authorization: authorization string \n          \nSample Response for general purpose buckets\nThis example illustrates one usage of CreateMultipartUpload.\n            HTTP/1.1 200 OK \n            x-amz-id-2: Uuag1LuByRx9e6j5Onimru9pO4ZVKnJ2Qz7/C1NPcfTWAtRPfTaOFg== \n            x-amz-request-id: 656c76696e6727732072657175657374 \n            Date:  Mon, 1 Nov 2010 20:34:56 GMT \n            Transfer-Encoding: chunked \n            Connection: keep-alive \n            Server: AmazonS3 \n            <?xml version=\"1.0\" encoding=\"UTF-8\"?> \n            <InitiateMultipartUploadResult xmlns=\"http://s3.amazonaws.com/\ndoc/2006-03-01/\"> \n              <Bucket>example-bucket</Bucket> \n              <Key>example-object</Key> \n              <UploadId>VXBsb2FkIElEIGZvciA2aWWpbmcncyBteS1tb3ZpZS5tMnRzIHVwbG9hZA</\nUploadId> \n            </InitiateMultipartUploadResult> \n          \nAmazon S3 API Version 2006-03-01 99Amazon Simple Storage Service API Reference\nExample for general purpose buckets: Initiate a multipart upload using server-side encryption \nwith customer-provided encryption keys\nThis example, which initiates a multipart upload request, speci\ufb01es server-side encryption with \ncustomer-provided encryption keys by adding relevant headers.\n            POST /example-object?uploads HTTP/1.1 \n            Host: example-bucket.s3.<Region>.amazonaws.com   \n            Authorization:authorization string   \n            Date: Wed, 28 May 2014 19:34:57 +0000    \n            x-amz-server-side-encryption-customer-key: \n g0lCfA3Dv40jZz5SQJ1ZukLRFqtI5WorC/8SEEXAMPLE    \n            x-amz-server-side-encryption-customer-key-MD5: ZjQrne1X/iTcskbY2example    \n            x-amz-server-side-encryption-customer-algorithm: AES256  \n          \nSample Response for general purpose buckets\nIn the response, Amazon S3 returns an UploadId . In addition, Amazon S3 returns the encryption \nalgorithm and the MD5 digest of the encryption key that you provided in the request.\n           HTTP/1.1 200 OK    \n            x-amz-id-2: \n 36HRCaIGp57F1FvWvVRrvd3hNn9WoBGfEaCVHTCt8QWf00qxdHazQUgfoXAbhFWD    \n            x-amz-request-id: 50FA1D691B62CA43    \n            Date: Wed, 28 May 2014 19:34:58 GMT    \n            x-amz-server-side-encryption-customer-algorithm: AES256    \n            x-amz-server-side-encryption-customer-key-MD5: ZjQrne1X/iTcskbY2m3tFg==    \n            Transfer-Encoding: chunked    \n  \n            <?xml version=\"1.0\" encoding=\"UTF-8\"?> \n            <InitiateMultipartUploadResult \n            xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n              <Bucket>example-bucket</Bucket> \n              <Key>example-object</Key> \n               \n <UploadId>EXAMPLEJZ6e0YupT2h66iePQCc9IEbYbDUy4RTpMeoSMLPRp8Z5o1u8feSRonpvnWsKKG35tI2LB9VDPiCgTy.Gq2VxQLYjrue4Nq.NBdqI-\n</UploadId>\n</InitiateMultipartUploadResult>   \n          \nAmazon S3 API Version 2006-03-01 100Amazon Simple Storage Service API Reference\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 101Amazon Simple Storage Service API Reference\nCreateSession\nService: Amazon S3\nCreates a session that establishes temporary security credentials to support fast authentication and \nauthorization for the Zonal endpoint API operations on directory buckets.", "For more information \nabout Zonal endpoint API operations that include the Availability Zone in the request endpoint, see\nS3 Express One Zone APIs in the Amazon S3 User Guide .\nTo make Zonal endpoint API requests on a directory bucket, use the CreateSession  API \noperation.", "Speci\ufb01cally, you grant s3express:CreateSession  permission to a bucket in a bucket \npolicy or an IAM identity-based policy.", "Then, you use IAM credentials to make the CreateSession\nAPI request on the bucket, which returns temporary security credentials that include the access key \nID, secret access key, session token, and expiration.", "These credentials have associated permissions \nto access the Zonal endpoint API operations. After the session is created, you don\u2019t need to use \nother policies to grant permissions to each Zonal endpoint API individually. Instead, in your Zonal \nendpoint API requests, you sign your requests by applying the temporary security credentials of the \nsession to the request headers and following the SigV4 protocol for authentication.", "You also apply \nthe session token to the x-amz-s3session-token  request header for authorization.", "Temporary \nsecurity credentials are scoped to the bucket and expire after 5 minutes.", "After the expiration time, \nany calls that you make with those credentials will fail.", "You must use IAM credentials again to \nmake a CreateSession  API request that generates a new set of temporary credentials for use. \nTemporary credentials cannot be extended or refreshed beyond the original speci\ufb01ed interval.\nIf you use AWS SDKs, SDKs handle the session token refreshes automatically to avoid service \ninterruptions when a session expires.", "We recommend that you use the AWS SDKs to initiate and \nmanage requests to the CreateSession API.", "For more information, see Performance guidelines and \ndesign patterns in the Amazon S3 User Guide .\nNote\n\u2022You must make requests for this API operation to the Zonal endpoint. \nThese endpoints support virtual-hosted-style requests in the format\nhttps:// bucket_name .s3express- az_id.region.amazonaws.com .", "Path-style \nrequests are not supported.", "For more information, see Regional and Zonal endpoints in \nthe Amazon S3 User Guide .\n\u2022CopyObject  API operation  - Unlike other Zonal endpoint API operations, the\nCopyObject  API operation doesn't use the temporary security credentials returned from \nAmazon S3 API Version 2006-03-01 102Amazon Simple Storage Service API Reference\nthe CreateSession  API operation for authentication and authorization.", "For information \nabout authentication and authorization of the CopyObject  API operation on directory \nbuckets, see CopyObject.\n\u2022HeadBucket  API operation  - Unlike other Zonal endpoint API operations, the\nHeadBucket  API operation doesn't use the temporary security credentials returned from \nthe CreateSession  API operation for authentication and authorization. For information \nabout authentication and authorization of the HeadBucket  API operation on directory \nbuckets, see HeadBucket.\nPermissions\nTo obtain temporary security credentials, you must create a bucket policy or an IAM identity-\nbased policy that grants s3express:CreateSession  permission to the bucket. In a policy, \nyou can have the s3express:SessionMode  condition key to control who can create a\nReadWrite  or ReadOnly  session.", "For more information about ReadWrite  or ReadOnly\nsessions, see x-amz-create-session-mode .", "For example policies, see Example bucket \npolicies for S3 Express One Zone and AWS Identity and Access Management (IAM) identity-\nbased policies for S3 Express One Zone in the Amazon S3 User Guide .\nTo grant cross-account access to Zonal endpoint API operations, the bucket policy should also \ngrant both accounts the s3express:CreateSession  permission.\nIf you want to encrypt objects with SSE-KMS, you must also have the kms:GenerateDataKey\nand the kms:Decrypt  permissions in IAM identity-based policies and AWS KMS key policies for \nthe target AWS KMS key.\nEncryption\nFor directory buckets, there are only two supported options for server-side encryption: server-\nside encryption with Amazon S3 managed keys (SSE-S3) (AES256) and server-side encryption \nwith AWS KMS keys (SSE-KMS) (aws:kms).", "We recommend that the bucket's default encryption \nuses the desired encryption con\ufb01guration and you don't override the bucket default encryption \nin your CreateSession  requests or PUT object requests.", "Then, new objects are automatically \nencrypted with the desired encryption settings.", "For more information, see Protecting data with \nserver-side encryption in the Amazon S3 User Guide . For more information about the encryption \noverriding behaviors in directory buckets, see Specifying server-side encryption with AWS KMS \nfor new object uploads.\nAmazon S3 API Version 2006-03-01 103Amazon Simple Storage Service API Reference\nFor Zonal endpoint (object-level) API operations except CopyObject and UploadPartCopy, you \nauthenticate and authorize requests through CreateSession for low latency. To encrypt new \nobjects in a directory bucket with SSE-KMS, you must specify SSE-KMS as the directory bucket's \ndefault encryption con\ufb01guration with a KMS key (speci\ufb01cally, a customer managed key). Then, \nwhen a session is created for Zonal endpoint API operations, new objects are automatically \nencrypted and decrypted with SSE-KMS and S3 Bucket Keys during the session.\nNote\nOnly 1 customer managed key is supported per directory bucket for the lifetime of the \nbucket.", "The AWS managed key (aws/s3) isn't supported.", "After you specify SSE-KMS as \nyour bucket's default encryption con\ufb01guration with a customer managed key, you can't \nchange the customer managed key for the bucket's SSE-KMS con\ufb01guration.\nIn the Zonal endpoint API calls (except CopyObject and UploadPartCopy) using the REST \nAPI, you can't override the values of the encryption settings (x-amz-server-side-\nencryption , x-amz-server-side-encryption-aws-kms-key-id , x-amz-server-\nside-encryption-context , and x-amz-server-side-encryption-bucket-key-\nenabled) from the CreateSession  request. You don't need to explicitly specify these \nencryption settings values in Zonal endpoint API calls, and Amazon S3 will use the encryption \nsettings values from the CreateSession  request to protect new objects in the directory \nbucket.\nNote\nWhen you use the CLI or the AWS SDKs, for CreateSession , the session token \nrefreshes automatically to avoid service interruptions when a session expires. The \nCLI or the AWS SDKs use the bucket's default encryption con\ufb01guration for the\nCreateSession  request. It's not supported to override the encryption settings \nvalues in the CreateSession  request.", "Also, in the Zonal endpoint API calls (except\nCopyObject and UploadPartCopy), it's not supported to override the values of the \nencryption settings from the CreateSession  request.\nAmazon S3 API Version 2006-03-01 104Amazon Simple Storage Service API Reference\nHTTP Host header syntax\nDirectory buckets  - The HTTP Host header syntax is \nBucket_name .s3express- az_id.region.amazonaws.com .\nRequest Syntax\nGET /?session HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-create-session-mode: SessionMode\nx-amz-server-side-encryption: ServerSideEncryption\nx-amz-server-side-encryption-aws-kms-key-id: SSEKMSKeyId\nx-amz-server-side-encryption-context: SSEKMSEncryptionContext\nx-amz-server-side-encryption-bucket-key-enabled: BucketKeyEnabled\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe name of the bucket that you create a session for.\nRequired: Yes\nx-amz-create-session-mode\nSpeci\ufb01es the mode of the session that will be created, either ReadWrite  or ReadOnly .", "By \ndefault, a ReadWrite  session is created.", "A ReadWrite  session is capable of executing all \nthe Zonal endpoint API operations on a directory bucket.", "A ReadOnly  session is constrained \nto execute the following Zonal endpoint API operations: GetObject , HeadObject ,\nListObjectsV2 , GetObjectAttributes , ListParts , and ListMultipartUploads .\nValid Values: ReadOnly | ReadWrite\nx-amz-server-side-encryption\nThe server-side encryption algorithm to use when you store objects in the directory bucket.\nFor directory buckets, there are only two supported options for server-side encryption: server-\nside encryption with Amazon S3 managed keys (SSE-S3) (AES256) and server-side encryption \nAmazon S3 API Version 2006-03-01 105Amazon Simple Storage Service API Reference\nwith AWS KMS keys (SSE-KMS) (aws:kms).", "By default, Amazon S3 encrypts data with SSE-S3. \nFor more information, see Protecting data with server-side encryption in the Amazon S3 User \nGuide .\nValid Values: AES256 | aws:kms | aws:kms:dsse\nx-amz-server-side-encryption-aws-kms-key-id\nIf you specify x-amz-server-side-encryption  with aws:kms, you must specify the  x-\namz-server-side-encryption-aws-kms-key-id  header with the ID (Key ID or Key ARN) \nof the AWS KMS symmetric encryption customer managed key to use.", "Otherwise, you get an \nHTTP 400 Bad Request  error.", "Only use the key ID or key ARN.", "The key alias format of the \nKMS key isn't supported. Also, if the KMS key doesn't exist in the same account that't issuing the \ncommand, you must use the full Key ARN not the Key ID.\nYour SSE-KMS con\ufb01guration can only support 1 customer managed key per directory bucket for \nthe lifetime of the bucket.", "The AWS managed key (aws/s3) isn't supported.\nx-amz-server-side-encryption-bucket-key-enabled\nSpeci\ufb01es whether Amazon S3 should use an S3 Bucket Key for object encryption with server-\nside encryption using AWS KMS keys (SSE-KMS).\nS3 Bucket Keys are always enabled for GET and PUT operations in a directory bucket and can\u2019t \nbe disabled. S3 Bucket Keys aren't supported, when you copy SSE-KMS encrypted objects \nfrom general purpose buckets to directory buckets, from directory buckets to general purpose \nbuckets, or between directory buckets, through CopyObject, UploadPartCopy, the Copy \noperation in Batch Operations , or the import jobs. In this case, Amazon S3 makes a call to AWS \nKMS every time a copy request is made for a KMS-encrypted object.\nx-amz-server-side-encryption-context\nSpeci\ufb01es the AWS KMS Encryption Context as an additional encryption context to use for \nobject encryption.", "The value of this header is a Base64-encoded string of a UTF-8 encoded \nJSON, which contains the encryption context as key-value pairs.", "This value is stored as object \nmetadata and automatically gets passed on to AWS KMS for future GetObject  operations on \nthis object.\nGeneral purpose buckets - This value must be explicitly added during CopyObject  operations \nif you want an additional encryption context for your object.", "For more information, see\nEncryption context in the Amazon S3 User Guide .\nAmazon S3 API Version 2006-03-01 106Amazon Simple Storage Service API Reference\nDirectory buckets - You can optionally provide an explicit encryption context value. The value \nmust match the default encryption context - the bucket Amazon Resource Name (ARN). An \nadditional encryption context value is not supported.\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\nx-amz-server-side-encryption: ServerSideEncryption\nx-amz-server-side-encryption-aws-kms-key-id: SSEKMSKeyId\nx-amz-server-side-encryption-context: SSEKMSEncryptionContext\nx-amz-server-side-encryption-bucket-key-enabled: BucketKeyEnabled\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<CreateSessionOutput > \n   <Credentials > \n      <AccessKeyId >string</AccessKeyId > \n      <Expiration >timestamp </Expiration > \n      <SecretAccessKey >string</SecretAccessKey > \n      <SessionToken >string</SessionToken > \n   </Credentials >\n</CreateSessionOutput >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe response returns the following HTTP headers.\nx-amz-server-side-encryption\nThe server-side encryption algorithm used when you store objects in the directory bucket.\nValid Values: AES256 | aws:kms | aws:kms:dsse\nx-amz-server-side-encryption-aws-kms-key-id\nIf you specify x-amz-server-side-encryption  with aws:kms , this header indicates the \nID of the AWS KMS symmetric encryption customer managed key that was used for object \nencryption.\nAmazon S3 API Version 2006-03-01 107Amazon Simple Storage Service API Reference\nx-amz-server-side-encryption-bucket-key-enabled\nIndicates whether to use an S3 Bucket Key for server-side encryption with AWS KMS keys (SSE-\nKMS).\nx-amz-server-side-encryption-context\nIf present, indicates the AWS KMS Encryption Context to use for object encryption.", "The value \nof this header is a Base64-encoded string of a UTF-8 encoded JSON, which contains the \nencryption context as key-value pairs.", "This value is stored as object metadata and automatically \ngets passed on to AWS KMS for future GetObject  operations on this object.\nThe following data is returned in XML format by the service.\nCreateSessionOutput\nRoot level tag for the CreateSessionOutput parameters.\nRequired: Yes\nCredentials\nThe established temporary security credentials for the created session.\nType: SessionCredentials data type\nErrors\nNoSuchBucket\nThe speci\ufb01ed bucket does not exist.\nHTTP Status Code: 404\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\nAmazon S3 API Version 2006-03-01 108Amazon Simple Storage Service API Reference\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 109Amazon Simple Storage Service API Reference\nDeleteBucket\nService: Amazon S3\nDeletes the S3 bucket. All objects (including all object versions and delete markers) in the bucket \nmust be deleted before the bucket itself can be deleted.\nNote\n\u2022Directory buckets - If multipart uploads in a directory bucket are in progress, you can't \ndelete the bucket until all the in-progress multipart uploads are aborted or completed.\n\u2022Directory buckets  - For directory buckets, you must make requests for this API operation \nto the Regional endpoint.", "These endpoints support path-style requests in the format\nhttps://s3express-control.", "region_code .amazonaws.com/ bucket-name  .", "\nVirtual-hosted-style requests aren't supported.", "For more information, see Regional and \nZonal endpoints in the Amazon S3 User Guide .\nPermissions\n\u2022General purpose bucket permissions - You must have the s3:DeleteBucket  permission on \nthe speci\ufb01ed bucket in a policy.\n\u2022Directory bucket permissions - You must have the s3express:DeleteBucket  permission \nin an IAM identity-based policy instead of a bucket policy.", "Cross-account access to this API \noperation isn't supported.", "This operation can only be performed by the AWS account that \nowns the resource.", "For more information about directory bucket policies and permissions, see\nAWS Identity and Access Management (IAM) for S3 Express One Zone in the Amazon S3 User \nGuide .\nHTTP Host header syntax\nDirectory buckets  - The HTTP Host header syntax is s3express-\ncontrol. region.amazonaws.com .\nThe following operations are related to DeleteBucket :\n\u2022CreateBucket\n\u2022DeleteObject\nAmazon S3 API Version 2006-03-01 110Amazon Simple Storage Service API Reference\nRequest Syntax\nDELETE / HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nSpeci\ufb01es the bucket being deleted.\nDirectory buckets  - When you use this operation with a directory bucket, \nyou must use path-style requests in the format https://s3express-\ncontrol.", "region_code .amazonaws.com/ bucket-name  .", "Virtual-hosted-style requests \naren't supported.", "Directory bucket names must be unique in the chosen Availability Zone.", "\nBucket names must also follow the format  bucket_base_name --az_id--x-s3  (for \nexample,  DOC-EXAMPLE-BUCKET --usw2-az1 --x-s3). For information about bucket naming \nrestrictions, see Directory bucket naming rules in the Amazon S3 User Guide\nRequired: Yes\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner.", "If the account ID that you provide does not match \nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nNote\nFor directory buckets, this header is not supported in this API operation. If you specify \nthis header, the request fails with the HTTP status code 501 Not Implemented .\nRequest Body\nThe request does not have a request body.\nAmazon S3 API Version 2006-03-01 111Amazon Simple Storage Service API Reference\nResponse Syntax\nHTTP/1.1 204\nResponse Elements\nIf the action is successful, the service sends back an HTTP 204 response with an empty HTTP body.\nExamples\nSample Request for general purpose buckets\nThis request deletes the bucket named quotes .\nDELETE / HTTP/1.1\nHost: quotes.s3.<Region>.amazonaws.com\nDate: Wed, 01 Mar  2006 12:00:00 GMT\nAuthorization: authorization string \n          \nSample Response for general purpose buckets\nHTTP/1.1 204 No Content\nx-amz-id-2: JuKZqmXuiwFeDQxhD7M8KtsKobSzWA1QEjLbTMTagkKdBX2z7Il/jGhDeJ3j6s80\nx-amz-request-id: 32FE2CEB32F5EE25\nDate: Wed, 01 Mar  2006 12:00:00 GMT\nConnection: close\nServer: AmazonS3 \n          \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\nAmazon S3 API Version 2006-03-01 112Amazon Simple Storage Service API Reference\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 113Amazon Simple Storage Service API Reference\nDeleteBucketAnalyticsCon\ufb01guration\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nDeletes an analytics con\ufb01guration for the bucket (speci\ufb01ed by the analytics con\ufb01guration ID).\nTo use this operation, you must have permissions to perform the\ns3:PutAnalyticsConfiguration  action. The bucket owner has this permission by default. The \nbucket owner can grant this permission to others.", "For more information about permissions, see\nPermissions Related to Bucket Subresource Operations and Managing Access Permissions to Your \nAmazon S3 Resources.\nFor information about the Amazon S3 analytics feature, see Amazon S3 Analytics \u2013 Storage Class \nAnalysis .\nThe following operations are related to DeleteBucketAnalyticsConfiguration :\n\u2022GetBucketAnalyticsCon\ufb01guration\n\u2022ListBucketAnalyticsCon\ufb01gurations\n\u2022PutBucketAnalyticsCon\ufb01guration\nRequest Syntax\nDELETE /?analytics&id= Id HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe name of the bucket from which an analytics con\ufb01guration is deleted.\nRequired: Yes\nAmazon S3 API Version 2006-03-01 114Amazon Simple Storage Service API Reference\nid\nThe ID that identi\ufb01es the analytics con\ufb01guration.\nRequired: Yes\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match \nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 204\nResponse Elements\nIf the action is successful, the service sends back an HTTP 204 response with an empty HTTP body.\nExamples\nSample Request\nThe following DELETE request deletes the analytics con\ufb01guration with the ID list1 .\n            DELETE ?/analytics&id=list1 HTTP/1.1 \n            Host: examplebucket.s3.<Region>.amazonaws.com   \n            Date: Wed, 14 May 2014 02:11:22 GMT \n            Authorization: signatureValue  \n          \nSample Response\nThe following successful response shows Amazon S3 returning a 204 No Content  response. The \nanalytics con\ufb01guration with the ID list1 for the bucket has been removed.\nAmazon S3 API Version 2006-03-01 115Amazon Simple Storage Service API Reference\n            HTTP/1.1 204 No Content \n            x-amz-id-2: 0FmFIWsh/\nPpBuzZ0JFRC55ZGVmQW4SHJ7xVDqKwhEdJmf3q63RtrvH8ZuxW1Bol5 \n            x-amz-request-id: 0CF038E9BCF63097 \n            Date: Wed, 14 May 2014 02:11:22 GMT \n            Server: AmazonS3 \n          \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 116Amazon Simple Storage Service API Reference\nDeleteBucketCors\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nDeletes the cors con\ufb01guration information set for the bucket.\nTo use this operation, you must have permission to perform the s3:PutBucketCORS  action. The \nbucket owner has this permission by default and can grant this permission to others.\nFor information about cors , see Enabling Cross-Origin Resource Sharing in the Amazon S3 User \nGuide .\nRelated Resources\n\u2022PutBucketCors\n\u2022RESTOPTIONSobject\nRequest Syntax\nDELETE /?cors HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nSpeci\ufb01es the bucket whose cors con\ufb01guration is being deleted.\nRequired: Yes\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match \nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nAmazon S3 API Version 2006-03-01 117Amazon Simple Storage Service API Reference\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 204\nResponse Elements\nIf the action is successful, the service sends back an HTTP 204 response with an empty HTTP body.\nExamples\nRetrieve cors subresource\nThe following DELETE request deletes the cors subresource from the speci\ufb01ed bucket. This action \nremoves cors con\ufb01guration that is stored in the subresource.\nSample Request\nThis example illustrates one usage of DeleteBucketCors.\nDELETE /?cors HTTP/1.1\nHost: examplebucket.s3.<Region>.amazonaws.com\nDate: Tue, 13 Dec 2011 19:14:42 GMT\nAuthorization: signatureValue \n            \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\nAmazon S3 API Version 2006-03-01 118Amazon Simple Storage Service API Reference\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 119Amazon Simple Storage Service API Reference\nDeleteBucketEncryption\nService: Amazon S3\nThis implementation of the DELETE action resets the default encryption for the bucket as server-\nside encryption with Amazon S3 managed keys (SSE-S3).\nNote\n\u2022General purpose buckets - For information about the bucket default encryption feature, \nsee Amazon S3 Bucket Default Encryption in the Amazon S3 User Guide .\n\u2022Directory buckets - For directory buckets, there are only two supported options \nfor server-side encryption: SSE-S3 and SSE-KMS. For information about the default \nencryption con\ufb01guration in directory buckets, see Setting default server-side encryption \nbehavior for directory buckets.\nPermissions\n\u2022General purpose bucket permissions - The s3:PutEncryptionConfiguration\npermission is required in a policy.", "The bucket owner has this permission by default. The \nbucket owner can grant this permission to others.", "For more information about permissions, \nsee Permissions Related to Bucket Operations and Managing Access Permissions to Your \nAmazon S3 Resources.\n\u2022Directory bucket permissions - To grant access to this API operation, you must have the\ns3express:PutEncryptionConfiguration  permission in an IAM identity-based policy \ninstead of a bucket policy.", "Cross-account access to this API operation isn't supported.", "This \noperation can only be performed by the AWS account that owns the resource.", "For more \ninformation about directory bucket policies and permissions, see AWS Identity and Access \nManagement (IAM) for S3 Express One Zone in the Amazon S3 User Guide .\nHTTP Host header syntax\nDirectory buckets  - The HTTP Host header syntax is s3express-\ncontrol. region.amazonaws.com .\nThe following operations are related to DeleteBucketEncryption :\n\u2022PutBucketEncryption\nAmazon S3 API Version 2006-03-01 120Amazon Simple Storage Service API Reference\n\u2022GetBucketEncryption\nRequest Syntax\nDELETE /?encryption HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe name of the bucket containing the server-side encryption con\ufb01guration to delete.\nDirectory buckets  - When you use this operation with a directory bucket, \nyou must use path-style requests in the format https://s3express-\ncontrol.", "region_code .amazonaws.com/ bucket-name  .", "Virtual-hosted-style requests \naren't supported.", "Directory bucket names must be unique in the chosen Availability Zone.", "\nBucket names must also follow the format  bucket_base_name --az_id--x-s3  (for \nexample,  DOC-EXAMPLE-BUCKET --usw2-az1 --x-s3). For information about bucket naming \nrestrictions, see Directory bucket naming rules in the Amazon S3 User Guide\nRequired: Yes\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner.", "If the account ID that you provide does not match \nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nNote\nFor directory buckets, this header is not supported in this API operation. If you specify \nthis header, the request fails with the HTTP status code 501 Not Implemented .\nRequest Body\nThe request does not have a request body.\nAmazon S3 API Version 2006-03-01 121Amazon Simple Storage Service API Reference\nResponse Syntax\nHTTP/1.1 204\nResponse Elements\nIf the action is successful, the service sends back an HTTP 204 response with an empty HTTP body.\nExamples\nSample Request for a general purpose bucket\nThe following DELETE request resets the default encryption for the bucket as server-side \nencryption with Amazon S3 managed keys (SSE-S3).\nDELETE ?/encryption HTTP/1.1\nHost: examplebucket.s3.<Region>.amazonaws.com   \nDate: Wed, 06 Sep 2017 12:00:00 GMT\nAuthorization: signatureValue  \n            \nSample Response for a general purpose bucket\nThe following successful response shows Amazon S3 returning a 204 No Content  response \ncon\ufb01rming that default encryption for the bucket has been reset as server-side encryption with \nAmazon S3 managed keys (SSE-S3).\nHTTP/1.1 204 No Content\nx-amz-id-2: 0FmFIWsh/PpBuzZ0JFRC55ZGVmQW4SHJ7xVDqKwhEdJmf3q63RtrvH8ZuxW1Bol5\nx-amz-request-id: 0CF038E9BCF63097\nDate: Wed, 06 Sep 2017 12:00:00 GMT\nServer: AmazonS3 \n            \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\nAmazon S3 API Version 2006-03-01 122Amazon Simple Storage Service API Reference\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 123Amazon Simple Storage Service API Reference\nDeleteBucketIntelligentTieringCon\ufb01guration\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nDeletes the S3 Intelligent-Tiering con\ufb01guration from the speci\ufb01ed bucket.\nThe S3 Intelligent-Tiering storage class is designed to optimize storage costs by automatically \nmoving data to the most cost-e\ufb00ective storage access tier, without performance impact or \noperational overhead.", "S3 Intelligent-Tiering delivers automatic cost savings in three low latency \nand high throughput access tiers. To get the lowest storage cost on data that can be accessed in \nminutes to hours, you can choose to activate additional archiving capabilities.\nThe S3 Intelligent-Tiering storage class is the ideal storage class for data with unknown, changing, \nor unpredictable access patterns, independent of object size or retention period.", "If the size of an \nobject is less than 128 KB, it is not monitored and not eligible for auto-tiering.", "Smaller objects can \nbe stored, but they are always charged at the Frequent Access tier rates in the S3 Intelligent-Tiering \nstorage class.\nFor more information, see Storage class for automatically optimizing frequently and infrequently \naccessed objects.\nOperations related to DeleteBucketIntelligentTieringConfiguration  include:\n\u2022GetBucketIntelligentTieringCon\ufb01guration\n\u2022PutBucketIntelligentTieringCon\ufb01guration\n\u2022ListBucketIntelligentTieringCon\ufb01gurations\nRequest Syntax\nDELETE /?intelligent-tiering&id= Id HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nURI Request Parameters\nThe request uses the following URI parameters.\nAmazon S3 API Version 2006-03-01 124Amazon Simple Storage Service API Reference\nBucket\nThe name of the Amazon S3 bucket whose con\ufb01guration you want to modify or retrieve.\nRequired: Yes\nid\nThe ID used to identify the S3 Intelligent-Tiering con\ufb01guration.\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 204\nResponse Elements\nIf the action is successful, the service sends back an HTTP 204 response with an empty HTTP body.\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 125Amazon Simple Storage Service API Reference\nDeleteBucketInventoryCon\ufb01guration\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nDeletes an inventory con\ufb01guration (identi\ufb01ed by the inventory ID) from the bucket.\nTo use this operation, you must have permissions to perform the\ns3:PutInventoryConfiguration  action.", "The bucket owner has this permission by default. The \nbucket owner can grant this permission to others.", "For more information about permissions, see\nPermissions Related to Bucket Subresource Operations and Managing Access Permissions to Your \nAmazon S3 Resources.\nFor information about the Amazon S3 inventory feature, see Amazon S3 Inventory.\nOperations related to DeleteBucketInventoryConfiguration  include:\n\u2022GetBucketInventoryCon\ufb01guration\n\u2022PutBucketInventoryCon\ufb01guration\n\u2022ListBucketInventoryCon\ufb01gurations\nRequest Syntax\nDELETE /?inventory&id= Id HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe name of the bucket containing the inventory con\ufb01guration to delete.\nRequired: Yes\nAmazon S3 API Version 2006-03-01 126Amazon Simple Storage Service API Reference\nid\nThe ID used to identify the inventory con\ufb01guration.\nRequired: Yes\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match \nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 204\nResponse Elements\nIf the action is successful, the service sends back an HTTP 204 response with an empty HTTP body.\nExamples\nSample Request\nThe following DELETE request deletes the inventory con\ufb01guration with the ID list1 .\n        DELETE ?/inventory&id=list1 HTTP/1.1 \n        Host: examplebucket.s3.<Region>.amazonaws.com   \n        Date: Wed, 14 May 2014 02:11:22 GMT \n        Authorization: signatureValue  \n      \nSample Response\nThe following successful response shows Amazon S3 returning a 204 No Content  response. The \ninventory con\ufb01guration with the ID list1 for the bucket has been removed.\nAmazon S3 API Version 2006-03-01 127Amazon Simple Storage Service API Reference\n       HTTP/1.1 204 No Content \n       x-amz-id-2: 0FmFIWsh/PpBuzZ0JFRC55ZGVmQW4SHJ7xVDqKwhEdJmf3q63RtrvH8ZuxW1Bol5 \n       x-amz-request-id: 0CF038E9BCF63097 \n       Date: Wed, 14 May 2014 02:11:22 GMT \n       Server: AmazonS3 \n      \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 128Amazon Simple Storage Service API Reference\nDeleteBucketLifecycle\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nDeletes the lifecycle con\ufb01guration from the speci\ufb01ed bucket. Amazon S3 removes all the lifecycle \ncon\ufb01guration rules in the lifecycle subresource associated with the bucket. Your objects never \nexpire, and Amazon S3 no longer automatically deletes any objects on the basis of rules contained \nin the deleted lifecycle con\ufb01guration.\nTo use this operation, you must have permission to perform the\ns3:PutLifecycleConfiguration  action. By default, the bucket owner has this permission and \nthe bucket owner can grant this permission to others.\nThere is usually some time lag before lifecycle con\ufb01guration deletion is fully propagated to all the \nAmazon S3 systems.\nFor more information about the object expiration, see Elements to Describe Lifecycle Actions.\nRelated actions include:\n\u2022PutBucketLifecycleCon\ufb01guration\n\u2022GetBucketLifecycleCon\ufb01guration\nRequest Syntax\nDELETE /?lifecycle HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe bucket name of the lifecycle to delete.\nAmazon S3 API Version 2006-03-01 129Amazon Simple Storage Service API Reference\nRequired: Yes\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match \nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 204\nResponse Elements\nIf the action is successful, the service sends back an HTTP 204 response with an empty HTTP body.\nExamples\nSample Request\nThe following DELETE request deletes the lifecycle subresource from the speci\ufb01ed bucket.", "This \nremoves lifecycle con\ufb01guration stored in the subresource.\n            DELETE /?lifecycle HTTP/1.1 \n            Host: examplebucket.s3.<Region>.amazonaws.com   \n            Date: Wed, 14 Dec 2011 05:37:16 GMT \n            Authorization: signatureValue \nSample Response\nThe following successful response shows Amazon S3 returning a 204 No Content response. Objects \nin your bucket no longer expire.\n            HTTP/1.1 204 No Content  \n            x-amz-id-2: Uuag1LuByRx9e6j5OnimrSAMPLEtRPfTaOAa==   \nAmazon S3 API Version 2006-03-01 130Amazon Simple Storage Service API Reference\n            x-amz-request-id: 656c76696e672SAMPLE5657374   \n            Date: Wed, 14 Dec 2011 05:37:16 GMT \n            Connection: keep-alive   \n            Server: AmazonS3 \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 131Amazon Simple Storage Service API Reference\nDeleteBucketMetricsCon\ufb01guration\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nDeletes a metrics con\ufb01guration for the Amazon CloudWatch request metrics (speci\ufb01ed by the \nmetrics con\ufb01guration ID) from the bucket. Note that this doesn't include the daily storage metrics.\nTo use this operation, you must have permissions to perform the\ns3:PutMetricsConfiguration  action.", "The bucket owner has this permission by default. The \nbucket owner can grant this permission to others.", "For more information about permissions, see\nPermissions Related to Bucket Subresource Operations and Managing Access Permissions to Your \nAmazon S3 Resources.\nFor information about CloudWatch request metrics for Amazon S3, see Monitoring Metrics with \nAmazon CloudWatch.\nThe following operations are related to DeleteBucketMetricsConfiguration :\n\u2022GetBucketMetricsCon\ufb01guration\n\u2022PutBucketMetricsCon\ufb01guration\n\u2022ListBucketMetricsCon\ufb01gurations\n\u2022Monitoring Metrics with Amazon CloudWatch\nRequest Syntax\nDELETE /?metrics&id= Id HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe name of the bucket containing the metrics con\ufb01guration to delete.\nAmazon S3 API Version 2006-03-01 132Amazon Simple Storage Service API Reference\nRequired: Yes\nid\nThe ID used to identify the metrics con\ufb01guration.", "The ID has a 64 character limit and can only \ncontain letters, numbers, periods, dashes, and underscores.\nRequired: Yes\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match \nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 204\nResponse Elements\nIf the action is successful, the service sends back an HTTP 204 response with an empty HTTP body.\nExamples\nSample Request\nDelete the metric con\ufb01guration with a speci\ufb01ed ID, which disables the CloudWatch metrics with the\nExampleMetrics  value for the FilterId  dimension.\n            DELETE /?metrics&id=ExampleMetrics HTTP/1.1 \n            Host: examplebucket.s3.<Region>.amazonaws.com \n            x-amz-date: Thu, 15 Nov 2016 00:17:21 GMT \n            Authorization: signatureValue \n          \nAmazon S3 API Version 2006-03-01 133Amazon Simple Storage Service API Reference\nSample Response\nDelete the metric con\ufb01guration with a speci\ufb01ed ID, which disables the CloudWatch metrics with the\nExampleMetrics  value for the FilterId  dimension.\n            HTTP/1.1 204 No Content \n            x-amz-id-2: \n ITnGT1y4REXAMPLEPi4hklTXouTf0hccUjo0iCPEXAMPLEutBj3M7fPGlWO2SEWp \n            x-amz-request-id: 51991EXAMPLE5321 \n            Date: Thu, 15 Nov 2016 00:17:22 GMT \n            Server: AmazonS3 \n          \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 134Amazon Simple Storage Service API Reference\nDeleteBucketOwnershipControls\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nRemoves OwnershipControls  for an Amazon S3 bucket.", "To use this operation, you must have \nthe s3:PutBucketOwnershipControls  permission. For more information about Amazon S3 \npermissions, see Specifying Permissions in a Policy.\nFor information about Amazon S3 Object Ownership, see Using Object Ownership.\nThe following operations are related to DeleteBucketOwnershipControls :\n\u2022GetBucketOwnershipControls\n\u2022PutBucketOwnershipControls\nRequest Syntax\nDELETE /?ownershipControls HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe Amazon S3 bucket whose OwnershipControls  you want to delete.\nRequired: Yes\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match \nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nAmazon S3 API Version 2006-03-01 135Amazon Simple Storage Service API Reference\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 204\nResponse Elements\nIf the action is successful, the service sends back an HTTP 204 response with an empty HTTP body.\nExamples\nSample DeleteBucketOwnershipControls Request\nThis example illustrates one usage of DeleteBucketOwnershipControls.\n          DELETE /example-bucket?/ownershipControls HTTP/1.1 \n          Host: examplebucket.s3.<Region>.amazonaws.com \n          Date: Thu, 18 Jun 2017 00:17:22 GMT \n          Authorization: signatureValue; \n         \nSample DeleteBucketOwnershipControls Response\nThis example illustrates one usage of DeleteBucketOwnershipControls.\n          HTTP/1.1 204 No Content \n          x-amz-id-2: dVrxJD3XHDcjZHFtd7eSB+ovpY8hQ6kSe9jPzyRVkWp27cij05qV1pTIvz/\nhjlsrupiy9gEkSdw= \n          x-amz-request-id: 4BFC0B777B448C97 \n          Date: Thu, 18 Jun 2020 22:54:03 GMT \n          Server: AmazonS3 \n         \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\nAmazon S3 API Version 2006-03-01 136Amazon Simple Storage Service API Reference\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 137Amazon Simple Storage Service API Reference\nDeleteBucketPolicy\nService: Amazon S3\nDeletes the policy of a speci\ufb01ed bucket.\nNote\nDirectory buckets  - For directory buckets, you must make requests for this API operation \nto the Regional endpoint.", "These endpoints support path-style requests in the format\nhttps://s3express-control.", "region_code .amazonaws.com/ bucket-name  .", "\nVirtual-hosted-style requests aren't supported.", "For more information, see Regional and \nZonal endpoints in the Amazon S3 User Guide .\nPermissions\nIf you are using an identity other than the root user of the AWS account that owns the bucket, \nthe calling identity must both have the DeleteBucketPolicy  permissions on the speci\ufb01ed \nbucket and belong to the bucket owner's account in order to use this operation.\nIf you don't have DeleteBucketPolicy  permissions, Amazon S3 returns a 403 Access \nDenied error. If you have the correct permissions, but you're not using an identity that belongs \nto the bucket owner's account, Amazon S3 returns a 405 Method Not Allowed  error.\nImportant\nTo ensure that bucket owners don't inadvertently lock themselves out of their \nown buckets, the root principal in a bucket owner's AWS account can perform the\nGetBucketPolicy , PutBucketPolicy , and DeleteBucketPolicy  API actions, \neven if their bucket policy explicitly denies the root principal's access. Bucket owner \nroot principals can only be blocked from performing these API actions by VPC endpoint \npolicies and AWS Organizations policies.\n\u2022General purpose bucket permissions - The s3:DeleteBucketPolicy  permission is \nrequired in a policy. For more information about general purpose buckets bucket policies, see\nUsing Bucket Policies and User Policies in the Amazon S3 User Guide .\n\u2022Directory bucket permissions - To grant access to this API operation, you must have the\ns3express:DeleteBucketPolicy  permission in an IAM identity-based policy instead of a \nAmazon S3 API Version 2006-03-01 138Amazon Simple Storage Service API Reference\nbucket policy.", "Cross-account access to this API operation isn't supported.", "This operation can \nonly be performed by the AWS account that owns the resource.", "For more information about \ndirectory bucket policies and permissions, see AWS Identity and Access Management (IAM) for \nS3 Express One Zone in the Amazon S3 User Guide .\nHTTP Host header syntax\nDirectory buckets  - The HTTP Host header syntax is s3express-\ncontrol. region.amazonaws.com .\nThe following operations are related to DeleteBucketPolicy\n\u2022CreateBucket\n\u2022DeleteObject\nRequest Syntax\nDELETE /?policy HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe bucket name.\nDirectory buckets  - When you use this operation with a directory bucket, \nyou must use path-style requests in the format https://s3express-\ncontrol. region_code .amazonaws.com/ bucket-name  .", "Virtual-hosted-style requests \naren't supported.", "Directory bucket names must be unique in the chosen Availability Zone.", "\nBucket names must also follow the format  bucket_base_name --az_id--x-s3  (for \nexample,  DOC-EXAMPLE-BUCKET --usw2-az1 --x-s3). For information about bucket naming \nrestrictions, see Directory bucket naming rules in the Amazon S3 User Guide\nRequired: Yes\nAmazon S3 API Version 2006-03-01 139Amazon Simple Storage Service API Reference\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match \nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nNote\nFor directory buckets, this header is not supported in this API operation. If you specify \nthis header, the request fails with the HTTP status code 501 Not Implemented .\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 204\nResponse Elements\nIf the action is successful, the service sends back an HTTP 204 response with an empty HTTP body.\nExamples\nSample Request for general purpose buckets\nThis request deletes the bucket named BucketName .\n            DELETE /?policy HTTP/1.1 \n            Host: BucketName.s3.<Region>.amazonaws.com   \n            Date: Tue, 04 Apr 2010 20:34:56 GMT   \n            Authorization: signatureValue  \n          \nSample Response for general purpose buckets\nThis example illustrates one usage of DeleteBucketPolicy.\nAmazon S3 API Version 2006-03-01 140Amazon Simple Storage Service API Reference\n            HTTP/1.1 204 No Content  \n            x-amz-id-2: Uuag1LuByRx9e6j5OnimrSAMPLEtRPfTaOFg==   \n            x-amz-request-id: 656c76696e672SAMPLE5657374   \n            Date: Tue, 04 Apr 2010 20:34:56 GMT   \n            Connection: keep-alive   \n            Server: AmazonS3    \n          \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 141Amazon Simple Storage Service API Reference\nDeleteBucketReplication\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nDeletes the replication con\ufb01guration from the bucket.\nTo use this operation, you must have permissions to perform the\ns3:PutReplicationConfiguration  action. The bucket owner has these permissions by default \nand can grant it to others. For more information about permissions, see Permissions Related to \nBucket Subresource Operations and Managing Access Permissions to Your Amazon S3 Resources.\nNote\nIt can take a while for the deletion of a replication con\ufb01guration to fully propagate.\nFor information about replication con\ufb01guration, see Replication in the Amazon S3 User Guide .\nThe following operations are related to DeleteBucketReplication :\n\u2022PutBucketReplication\n\u2022GetBucketReplication\nRequest Syntax\nDELETE /?replication HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe bucket name.\nAmazon S3 API Version 2006-03-01 142Amazon Simple Storage Service API Reference\nRequired: Yes\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match \nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 204\nResponse Elements\nIf the action is successful, the service sends back an HTTP 204 response with an empty HTTP body.\nExamples\nSample Request\nThe following DELETE request deletes the replication  subresource from the speci\ufb01ed bucket. \nThis removes the replication con\ufb01guration that is set for the bucket.\n           DELETE /?replication HTTP/1.1 \n           Host: examplebucket.s3.<Region>.amazonaws.com   \n           Date: Wed, 11 Feb 2015 05:37:16 GMT \n           20150211T171320Z \n           Authorization: authorization string  \n          \nSample Response\nWhen the replication  subresource has been deleted, Amazon S3 returns a 204 No Content\nresponse. It will not replicate new objects that are stored in the examplebucket  bucket.\nAmazon S3 API Version 2006-03-01 143Amazon Simple Storage Service API Reference\n           HTTP/1.1 204 No Content  \n           x-amz-id-2: Uuag1LuByRx9e6j5OnimrSAMPLEtRPfTaOAa==   \n           x-amz-request-id: 656c76696e672example   \n           Date: Wed, 11 Feb 2015 05:37:16 GMT \n           Connection: keep-alive   \n           Server: AmazonS3   \n          \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 144Amazon Simple Storage Service API Reference\nDeleteBucketTagging\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nDeletes the tags from the bucket.\nTo use this operation, you must have permission to perform the s3:PutBucketTagging  action. \nBy default, the bucket owner has this permission and can grant this permission to others.\nThe following operations are related to DeleteBucketTagging :\n\u2022GetBucketTagging\n\u2022PutBucketTagging\nRequest Syntax\nDELETE /?tagging HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe bucket that has the tag set to be removed.\nRequired: Yes\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match \nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nAmazon S3 API Version 2006-03-01 145Amazon Simple Storage Service API Reference\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 204\nResponse Elements\nIf the action is successful, the service sends back an HTTP 204 response with an empty HTTP body.\nExamples\nSample Request\nThe following DELETE request deletes the tag set from the speci\ufb01ed bucket.\n            DELETE /?tagging HTTP/1.1 \n            Host: examplebucket.s3.<Region>.amazonaws.com   \n            Date: Wed, 14 Dec 2011 05:37:16 GMT \n            Authorization: signatureValue  \n          \nSample Response\nThe following successful response shows Amazon S3 returning a 204 No Content  response. The \ntag set for the bucket has been removed.\n            HTTP/1.1 204 No Content \n            Date: Wed, 25 Nov 2009 12:00:00 GMT \n            Connection: close \n            Server: AmazonS3 \n          \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\nAmazon S3 API Version 2006-03-01 146Amazon Simple Storage Service API Reference\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 147Amazon Simple Storage Service API Reference\nDeleteBucketWebsite\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nThis action removes the website con\ufb01guration for a bucket. Amazon S3 returns a 200 OK response \nupon successfully deleting a website con\ufb01guration on the speci\ufb01ed bucket. You will get a 200 OK\nresponse if the website con\ufb01guration you are trying to delete does not exist on the bucket. Amazon \nS3 returns a 404 response if the bucket speci\ufb01ed in the request does not exist.\nThis DELETE action requires the S3:DeleteBucketWebsite  permission. By default, only the \nbucket owner can delete the website con\ufb01guration attached to a bucket. However, bucket owners \ncan grant other users permission to delete the website con\ufb01guration by writing a bucket policy \ngranting them the S3:DeleteBucketWebsite  permission.\nFor more information about hosting websites, see Hosting Websites on Amazon S3.\nThe following operations are related to DeleteBucketWebsite :\n\u2022GetBucketWebsite\n\u2022PutBucketWebsite\nRequest Syntax\nDELETE /?website HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe bucket name for which you want to remove the website con\ufb01guration.\nRequired: Yes\nAmazon S3 API Version 2006-03-01 148Amazon Simple Storage Service API Reference\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match \nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 204\nResponse Elements\nIf the action is successful, the service sends back an HTTP 204 response with an empty HTTP body.\nExamples\nSample Request\nThis request deletes the website con\ufb01guration on the speci\ufb01ed bucket.\n            DELETE ?website HTTP/1.1 \n            Host: example-bucket.s3.<Region>.amazonaws.com \n            Date: Thu, 27 Jan 2011 12:00:00 GMT \n            Authorization: signatureValue \n          \nSample Response\nThis example illustrates one usage of DeleteBucketWebsite.\n         HTTP/1.1 204 No Content \n         x-amz-id-2: aws-s3integ-s3ws-31008.sea31.amazon.com \n         x-amz-request-id: AF1DD829D3B49707 \n         Date: Thu, 03 Feb 2011 22:10:26 GMT \n         Server: AmazonS3 \nAmazon S3 API Version 2006-03-01 149Amazon Simple Storage Service API Reference\n         \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 150Amazon Simple Storage Service API Reference\nDeleteObject\nService: Amazon S3\nRemoves an object from a bucket.", "The behavior depends on the bucket's versioning state.", "For more \ninformation, see Best practices to consider before deleting an object.\nTo remove a speci\ufb01c version, you must use the versionId  query parameter. Using this query \nparameter permanently deletes the version.", "If the object deleted is a delete marker, Amazon S3 \nsets the response header x-amz-delete-marker  to true.", "If the object you want to delete is in a \nbucket where the bucket versioning con\ufb01guration is MFA delete enabled, you must include the x-\namz-mfa request header in the DELETE versionId  request.", "Requests that include x-amz-mfa\nmust use HTTPS.", "For more information about MFA delete and to see example requests, see Using \nMFA delete and Sample request in the Amazon S3 User Guide .\nNote\n\u2022S3 Versioning isn't enabled and supported for directory buckets.", "For this API operation, \nonly the null value of the version ID is supported by directory buckets. You can only \nspecify null  to the versionId  query parameter in the request.\n\u2022For directory buckets, you must make requests for this API operation to the Zonal \nendpoint.", "These endpoints support virtual-hosted-style requests in the format\nhttps:// bucket_name .s3express- az_id.region.amazonaws.com/ key-name\n.", "Path-style requests are not supported.", "For more information, see Regional and Zonal \nendpoints  in the Amazon S3 User Guide .\n\u2022MFA delete is not supported by directory buckets.\nPermissions\n\u2022General purpose bucket permissions - The following permissions are required in your \npolicies when your DeleteObjects  request includes speci\ufb01c headers.\n\u2022s3:DeleteObject   - To delete an object from a bucket, you must always have the\ns3:DeleteObject  permission.\nNote\nYou can also use PutBucketLifecycle to delete objects in Amazon S3.\nAmazon S3 API Version 2006-03-01 151Amazon Simple Storage Service API Reference\n\u2022s3:DeleteObjectVersion   - To delete a speci\ufb01c version of an object from a versioning-\nenabled bucket, you must have the s3:DeleteObjectVersion  permission.\n\u2022If you want to block users or accounts from removing or deleting objects from your \nbucket, you must deny them the s3:DeleteObject , s3:DeleteObjectVersion , and\ns3:PutLifeCycleConfiguration  permissions.\n\u2022Directory buckets permissions - To grant access to this API operation on a directory bucket, \nwe recommend that you use the CreateSession API operation for session-based authorization.\nHTTP Host header syntax\nDirectory buckets  - The HTTP Host header syntax is \nBucket_name .s3express- az_id.region.amazonaws.com .\nThe following action is related to DeleteObject :\n\u2022PutObject\nRequest Syntax\nDELETE / Key+?versionId= VersionId  HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-mfa: MFA\nx-amz-request-payer: RequestPayer\nx-amz-bypass-governance-retention: BypassGovernanceRetention\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe bucket name of the bucket containing the object.\nDirectory buckets - When you use this operation with a directory \nbucket, you must use virtual-hosted-style requests in the format \nBucket_name .s3express- az_id.region.amazonaws.com .", "Path-style requests are not \nsupported.", "Directory bucket names must be unique in the chosen Availability Zone.", "Bucket \nnames must follow the format  bucket_base_name --az-id--x-s3  (for example,  DOC-\nAmazon S3 API Version 2006-03-01 152Amazon Simple Storage Service API Reference\nEXAMPLE-BUCKET --usw2-az1 --x-s3). For information about bucket naming restrictions, see\nDirectory bucket naming rules in the Amazon S3 User Guide .\nAccess points - When you use this action with an access point, you must provide the alias of the \naccess point in place of the bucket name or specify the access point ARN.", "When using the access \npoint ARN, you must direct requests to the access point hostname.", "The access point hostname \ntakes the form AccessPointName-AccountId .s3-accesspoint.Region.amazonaws.com.", "When using \nthis action with an access point through the AWS SDKs, you provide the access point ARN in \nplace of the bucket name. For more information about access point ARNs, see Using access \npoints  in the Amazon S3 User Guide .\nNote\nAccess points and Object Lambda access points are not supported by directory buckets.\nS3 on Outposts  - When you use this action with Amazon S3 on Outposts, you must direct \nrequests to the S3 on Outposts hostname. The S3 on Outposts hostname takes the form \nAccessPointName -AccountId .outpostID .s3-outposts.", "Region.amazonaws.com .", "\nWhen you use this action with S3 on Outposts through the AWS SDKs, you provide the Outposts \naccess point ARN in place of the bucket name. For more information about S3 on Outposts \nARNs, see What is S3 on Outposts?", "in the Amazon S3 User Guide .\nRequired: Yes\nKey\nKey name of the object to delete.\nLength Constraints: Minimum length of 1.\nRequired: Yes\nversionId\nVersion ID used to reference a speci\ufb01c version of the object.\nNote\nFor directory buckets in this API operation, only the null value of the version ID is \nsupported.\nAmazon S3 API Version 2006-03-01 153Amazon Simple Storage Service API Reference\nx-amz-bypass-governance-retention\nIndicates whether S3 Object Lock should bypass Governance-mode restrictions to process \nthis operation. To use this header, you must have the s3:BypassGovernanceRetention\npermission.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner.", "If the account ID that you provide does not match \nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nx-amz-mfa\nThe concatenation of the authentication device's serial number, a space, and the value that is \ndisplayed on your authentication device. Required to permanently delete a versioned object if \nversioning is con\ufb01gured with MFA delete enabled.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-request-payer\nCon\ufb01rms that the requester knows that they will be charged for the request.", "Bucket owners \nneed not specify this parameter in their requests.", "If either the source or destination S3 \nbucket has Requester Pays enabled, the requester will pay for corresponding charges to copy \nthe object. For information about downloading objects from Requester Pays buckets, see\nDownloading Objects in Requester Pays Buckets in the Amazon S3 User Guide .\nNote\nThis functionality is not supported for directory buckets.\nAmazon S3 API Version 2006-03-01 154Amazon Simple Storage Service API Reference\nValid Values: requester\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 204\nx-amz-delete-marker: DeleteMarker\nx-amz-version-id: VersionId\nx-amz-request-charged: RequestCharged\nResponse Elements\nIf the action is successful, the service sends back an HTTP 204 response.\nThe response returns the following HTTP headers.\nx-amz-delete-marker\nIndicates whether the speci\ufb01ed object version that was permanently deleted was (true) or was \nnot (false) a delete marker before deletion. In a simple DELETE, this header indicates whether \n(true) or not (false) the current version of the object is a delete marker.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-request-charged\nIf present, indicates that the requester was successfully charged for the request.\nNote\nThis functionality is not supported for directory buckets.\nValid Values: requester\nAmazon S3 API Version 2006-03-01 155Amazon Simple Storage Service API Reference\nx-amz-version-id\nReturns the version ID of the delete marker created as a result of the DELETE operation.\nNote\nThis functionality is not supported for directory buckets.\nExamples\nSample Request for general purpose buckets\nThe following request deletes the object my-second-image.jpg .\n            DELETE /my-second-image.jpg HTTP/1.1 \n            Host: bucket.s3.<Region>.amazonaws.com \n            Date: Wed, 12 Oct 2009 17:50:00 GMT \n            Authorization: authorization string \n            Content-Type: text/plain \n          \nSample Response for general purpose buckets\nThis example illustrates one usage of DeleteObject.\n           HTTP/1.1 204 NoContent \n           x-amz-id-2: LriYPLdmOdAiIfgSm/F1YsViT1LW94/xUQxMsF7xiEb1a0wiIOIxl+zbwZ163pt7 \n           x-amz-request-id: 0A49CE4060975EAC \n           Date: Wed, 12 Oct 2009 17:50:00 GMT \n           Content-Length: 0 \n           Connection: close \n           Server: AmazonS3 \n          \nSample Request for general purpose buckets: Deleting a speci\ufb01ed version of an object\nThe following request deletes the speci\ufb01ed version of the object my-third-image.jpg .\nAmazon S3 API Version 2006-03-01 156Amazon Simple Storage Service API Reference\n           DELETE /my-third-image.jpg?\nversionId=UIORUnfndfiufdisojhr398493jfdkjFJjkndnqUifhnw89493jJFJ HTTP/1.1  \n           Host: bucket.s3.<Region>.amazonaws.com \n           Date: Wed, 12 Oct 2009 17:50:00 GMT \n           Authorization: authorization string \n           Content-Type: text/plain \n           Content-Length: 0 \n          \nSample Response for general purpose buckets\nThis example illustrates one usage of DeleteObject.\n           HTTP/1.1 204 NoContent \n           x-amz-id-2: LriYPLdmOdAiIfgSm/F1YsViT1LW94/xUQxMsF7xiEb1a0wiIOIxl+zbwZ163pt7 \n           x-amz-request-id: 0A49CE4060975EAC \n           x-amz-version-id: UIORUnfndfiufdisojhr398493jfdkjFJjkndnqUifhnw89493jJFJ \n           Date: Wed, 12 Oct 2009 17:50:00 GMT \n           Content-Length: 0 \n           Connection: close \n           Server: AmazonS3 \n          \nSample Response for general purpose buckets: If the object deleted is a delete marker\nThis example illustrates one usage of DeleteObject.\n            HTTP/1.1 204 NoContent \n            x-amz-id-2: LriYPLdmOdAiIfgSm/F1YsViT1LW94/xUQxMsF7xiEb1a0wiIOIxl\n+zbwZ163pt7 \n            x-amz-request-id: 0A49CE4060975EAC \n            x-amz-version-id: 3/L4kqtJlcpXroDTDmJ+rmSpXd3dIbrHY\n+MTRCxf3vjVBH40Nr8X8gdRQBpUMLUo \n            x-amz-delete-marker: true \n            Date: Wed, 12 Oct 2009 17:50:00 GMT \n            Content-Length: 0 \n            Connection: close \n            Server: AmazonS3 \n          \nAmazon S3 API Version 2006-03-01 157Amazon Simple Storage Service API Reference\nSample Request for general purpose buckets: Deleting a speci\ufb01ed version of an object in an \nMFA-enabled bucket\nThe following request deletes the speci\ufb01ed version of the object my-third-image.jpg , which is \nstored in an MFA-enabled bucket.\n            DELETE /my-third-image.jpg?versionId=UIORUnfndfiuf HTTP/1.1 \n            Host: bucket.s3.<Region>.amazonaws.com \n            Date: Wed, 12 Oct 2009 17:50:00 GMT \n            x-amz-mfa:[SerialNumber] [AuthenticationCode] \n            Authorization: authorization string \n            Content-Type: text/plain \n            Content-Length: 0 \n          \nSample Response for general purpose buckets\nThis example illustrates one usage of DeleteObject.\n            HTTP/1.1 204 NoContent \n            x-amz-id-2: LriYPLdmOdAiIfgSm/F1YsViT1LW94/xUQxMsF7xiEb1a0wiIOIxl\n+zbwZ163pt7 \n            x-amz-request-id: 0A49CE4060975EAC \n            x-amz-version-id: UIORUnfndfiuf \n            Date: Wed, 12 Oct 2009 17:50:00 GMT \n            Content-Length: 0 \n            Connection: close \n            Server: AmazonS3 \n          \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\nAmazon S3 API Version 2006-03-01 158Amazon Simple Storage Service API Reference\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 159Amazon Simple Storage Service API Reference\nDeleteObjects\nService: Amazon S3\nThis operation enables you to delete multiple objects from a bucket using a single HTTP request.", "\nIf you know the object keys that you want to delete, then this operation provides a suitable \nalternative to sending individual delete requests, reducing per-request overhead.\nThe request can contain a list of up to 1000 keys that you want to delete.", "In the XML, you provide \nthe object key names, and optionally, version IDs if you want to delete a speci\ufb01c version of the \nobject from a versioning-enabled bucket.", "For each key, Amazon S3 performs a delete operation \nand returns the result of that delete, success or failure, in the response. Note that if the object \nspeci\ufb01ed in the request is not found, Amazon S3 returns the result as deleted.\nNote\n\u2022Directory buckets - S3 Versioning isn't enabled and supported for directory buckets.\n\u2022Directory buckets - For directory buckets, you must make requests for this API operation \nto the Zonal endpoint. These endpoints support virtual-hosted-style requests in the \nformat https:// bucket_name .s3express- az_id.region.amazonaws.com/ key-\nname .", "Path-style requests are not supported.", "For more information, see Regional and \nZonal endpoints in the Amazon S3 User Guide .\nThe operation supports two modes for the response: verbose and quiet.", "By default, the operation \nuses verbose mode in which the response includes the result of deletion of each key in your \nrequest. In quiet mode the response includes only keys where the delete operation encountered \nan error. For a successful deletion in a quiet mode, the operation does not return any information \nabout the delete in the response body.\nWhen performing this action on an MFA Delete enabled bucket, that attempts to delete any \nversioned objects, you must include an MFA token. If you do not provide one, the entire request will \nfail, even if there are non-versioned objects you are trying to delete. If you provide an invalid token, \nwhether there are versioned keys in the request or not, the entire Multi-Object Delete request will \nfail.", "For information about MFA Delete, see MFA Delete in the Amazon S3 User Guide .\nAmazon S3 API Version 2006-03-01 160Amazon Simple Storage Service API Reference\nNote\nDirectory buckets - MFA delete is not supported by directory buckets.\nPermissions\n\u2022General purpose bucket permissions - The following permissions are required in your \npolicies when your DeleteObjects  request includes speci\ufb01c headers.\n\u2022s3:DeleteObject   - To delete an object from a bucket, you must always specify the\ns3:DeleteObject  permission.\n\u2022s3:DeleteObjectVersion   - To delete a speci\ufb01c version of an object from a versioning-\nenabled bucket, you must specify the s3:DeleteObjectVersion  permission.\n\u2022Directory bucket permissions - To grant access to this API operation on a directory \nbucket, we recommend that you use the CreateSession  API operation for session-based \nauthorization. Speci\ufb01cally, you grant the s3express:CreateSession  permission to the \ndirectory bucket in a bucket policy or an IAM identity-based policy.", "Then, you make the\nCreateSession  API call on the bucket to obtain a session token. With the session token in \nyour request header, you can make API requests to this operation. After the session token \nexpires, you make another CreateSession  API call to generate a new session token for \nuse. AWS CLI or SDKs create session and refresh the session token automatically to avoid \nservice interruptions when a session expires.", "For more information about authorization, see\nCreateSession .\nContent-MD5 request header\n\u2022General purpose bucket - The Content-MD5 request header is required for all Multi-Object \nDelete requests. Amazon S3 uses the header value to ensure that your request body has not \nbeen altered in transit.\n\u2022Directory bucket - The Content-MD5 request header or a additional checksum request \nheader (including x-amz-checksum-crc32 , x-amz-checksum-crc32c , x-amz-\nchecksum-sha1 , or x-amz-checksum-sha256 ) is required for all Multi-Object Delete \nrequests.\nHTTP Host header syntax\nDirectory buckets  - The HTTP Host header syntax is \nBucket_name .s3express- az_id.region.amazonaws.com .\nAmazon S3 API Version 2006-03-01 161Amazon Simple Storage Service API Reference\nThe following operations are related to DeleteObjects :\n\u2022CreateMultipartUpload\n\u2022UploadPart\n\u2022CompleteMultipartUpload\n\u2022ListParts\n\u2022AbortMultipartUpload\nRequest Syntax\nPOST /?delete HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-mfa: MFA\nx-amz-request-payer: RequestPayer\nx-amz-bypass-governance-retention: BypassGovernanceRetention\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nx-amz-sdk-checksum-algorithm: ChecksumAlgorithm\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<Delete xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n   <Object> \n      <Key>string</Key> \n      <VersionId >string</VersionId > \n   </Object> \n   ... \n   <Quiet>boolean</Quiet>\n</Delete>\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe bucket name containing the objects to delete.\nDirectory buckets - When you use this operation with a directory \nbucket, you must use virtual-hosted-style requests in the format \nBucket_name .s3express- az_id.region.amazonaws.com .", "Path-style requests are not \nsupported.", "Directory bucket names must be unique in the chosen Availability Zone.", "Bucket \nnames must follow the format  bucket_base_name --az-id--x-s3  (for example,  DOC-\nAmazon S3 API Version 2006-03-01 162Amazon Simple Storage Service API Reference\nEXAMPLE-BUCKET --usw2-az1 --x-s3). For information about bucket naming restrictions, see\nDirectory bucket naming rules in the Amazon S3 User Guide .\nAccess points - When you use this action with an access point, you must provide the alias of the \naccess point in place of the bucket name or specify the access point ARN.", "When using the access \npoint ARN, you must direct requests to the access point hostname.", "The access point hostname \ntakes the form AccessPointName-AccountId .s3-accesspoint.Region.amazonaws.com.", "When using \nthis action with an access point through the AWS SDKs, you provide the access point ARN in \nplace of the bucket name. For more information about access point ARNs, see Using access \npoints  in the Amazon S3 User Guide .\nNote\nAccess points and Object Lambda access points are not supported by directory buckets.\nS3 on Outposts  - When you use this action with Amazon S3 on Outposts, you must direct \nrequests to the S3 on Outposts hostname. The S3 on Outposts hostname takes the form \nAccessPointName -AccountId .outpostID .s3-outposts.", "Region.amazonaws.com .", "\nWhen you use this action with S3 on Outposts through the AWS SDKs, you provide the Outposts \naccess point ARN in place of the bucket name. For more information about S3 on Outposts \nARNs, see What is S3 on Outposts?", "in the Amazon S3 User Guide .\nRequired: Yes\nx-amz-bypass-governance-retention\nSpeci\ufb01es whether you want to delete this object even if it has a Governance-type Object Lock in \nplace. To use this header, you must have the s3:BypassGovernanceRetention  permission.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match \nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nAmazon S3 API Version 2006-03-01 163Amazon Simple Storage Service API Reference\nx-amz-mfa\nThe concatenation of the authentication device's serial number, a space, and the value that is \ndisplayed on your authentication device.", "Required to permanently delete a versioned object if \nversioning is con\ufb01gured with MFA delete enabled.\nWhen performing the DeleteObjects  operation on an MFA delete enabled bucket, which \nattempts to delete the speci\ufb01ed versioned objects, you must include an MFA token. If you don't \nprovide an MFA token, the entire request will fail, even if there are non-versioned objects that \nyou are trying to delete. If you provide an invalid token, whether there are versioned object keys \nin the request or not, the entire Multi-Object Delete request will fail.", "For information about MFA \nDelete, see  MFA Delete in the Amazon S3 User Guide .\nNote\nThis functionality is not supported for directory buckets.\nx-amz-request-payer\nCon\ufb01rms that the requester knows that they will be charged for the request.", "Bucket owners \nneed not specify this parameter in their requests.", "If either the source or destination S3 \nbucket has Requester Pays enabled, the requester will pay for corresponding charges to copy \nthe object. For information about downloading objects from Requester Pays buckets, see\nDownloading Objects in Requester Pays Buckets in the Amazon S3 User Guide .\nNote\nThis functionality is not supported for directory buckets.\nValid Values: requester\nx-amz-sdk-checksum-algorithm\nIndicates the algorithm used to create the checksum for the object when you use the SDK.", "\nThis header will not provide any additional functionality if you don't use the SDK.", "When you \nsend this header, there must be a corresponding x-amz-checksum- algorithm   or x-amz-\ntrailer header sent.", "Otherwise, Amazon S3 fails the request with the HTTP status code 400 \nBad Request .\nAmazon S3 API Version 2006-03-01 164Amazon Simple Storage Service API Reference\nFor the x-amz-checksum- algorithm   header, replace  algorithm   with the supported \nalgorithm from the following list:\n\u2022CRC32\n\u2022CRC32C\n\u2022SHA1\n\u2022SHA256\nFor more information, see Checking object integrity in the Amazon S3 User Guide .\nIf the individual checksum value you provide through x-amz-checksum- algorithm   doesn't \nmatch the checksum algorithm you set through x-amz-sdk-checksum-algorithm , Amazon \nS3 ignores any provided ChecksumAlgorithm  parameter and uses the checksum algorithm \nthat matches the provided value in x-amz-checksum- algorithm  .\nIf you provide an individual checksum, Amazon S3 ignores any provided ChecksumAlgorithm\nparameter.\nValid Values: CRC32 | CRC32C | SHA1 | SHA256\nRequest Body\nThe request accepts the following data in XML format.\nDelete\nRoot level tag for the Delete parameters.\nRequired: Yes\nObject\nThe object to delete.\nNote\nDirectory buckets - For directory buckets, an object that's composed entirely of \nwhitespace characters is not supported by the DeleteObjects  API operation. The \nrequest will receive a 400 Bad Request  error and none of the objects in the request \nwill be deleted.\nAmazon S3 API Version 2006-03-01 165Amazon Simple Storage Service API Reference\nType: Array of ObjectIdenti\ufb01er data types\nRequired: Yes\nQuiet\nElement to enable quiet mode for the request.", "When you add this element, you must set its \nvalue to true .\nType: Boolean\nRequired: No\nResponse Syntax\nHTTP/1.1 200\nx-amz-request-charged: RequestCharged\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<DeleteResult > \n   <Deleted> \n      <DeleteMarker >boolean</DeleteMarker > \n      <DeleteMarkerVersionId >string</DeleteMarkerVersionId > \n      <Key>string</Key> \n      <VersionId >string</VersionId > \n   </Deleted> \n   ...", "\n   <Error> \n      <Code>string</Code> \n      <Key>string</Key> \n      <Message>string</Message> \n      <VersionId >string</VersionId > \n   </Error> \n   ...\n</DeleteResult >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe response returns the following HTTP headers.\nx-amz-request-charged\nIf present, indicates that the requester was successfully charged for the request.\nAmazon S3 API Version 2006-03-01 166Amazon Simple Storage Service API Reference\nNote\nThis functionality is not supported for directory buckets.\nValid Values: requester\nThe following data is returned in XML format by the service.\nDeleteResult\nRoot level tag for the DeleteResult parameters.\nRequired: Yes\nDeleted\nContainer element for a successful delete. It identi\ufb01es the object that was successfully deleted.\nType: Array of DeletedObject data types\nError\nContainer for a failed delete action that describes the object that Amazon S3 attempted to \ndelete and the error it encountered.\nType: Array of Error data types\nExamples\nSample Request for general purpose buckets: Multi-object delete resulting in mixed success/\nerror response\nThis example illustrates a Multi-Object Delete request to delete objects that result in mixed success \nand errors response.", "The following request deletes two objects from a bucket (bucketname ).", "In \nthis example, the requester does not have permission to delete the sample2.txt  object.\n            POST /?delete HTTP/1.1 \n            Host: bucketname.s3.<Region>.amazonaws.com \n            Accept: */* \nAmazon S3 API Version 2006-03-01 167Amazon Simple Storage Service API Reference\n            x-amz-date: Wed, 30 Nov 2011 03:39:05 GMT \n            Content-MD5: p5/WA/oEr30qrEEl21PAqw== \n            Authorization: AWS AKIAIOSFODNN7EXAMPLE:W0qPYCLe6JwkZAD1ei6hp9XZIee= \n            Content-Length: 125 \n            Connection: Keep-Alive \n            <Delete> \n             <Object> \n             <Key>sample1.txt</Key> \n             </Object> \n             <Object> \n               <Key>sample2.txt</Key> \n             </Object> \n             </Delete> \n          \nSample Response for general purpose buckets\nThe response includes a DeleteResult  element that includes a Deleted  element for the item \nthat Amazon S3 successfully deleted and an Error element that Amazon S3 did not delete \nbecause you didn't have permission to delete the object.\n            HTTP/1.1 200 OK \n            x-amz-id-2: 5h4FxSNCUS7wP5z92eGCWDshNpMnRuXvETa4HH3LvvH6VAIr0jU7tH9kM7X\n+njXx \n            x-amz-request-id: A437B3B641629AEE \n            Date: Fri, 02 Dec 2011 01:53:42 GMT \n            Content-Type: application/xml \n            Server: AmazonS3 \n            Content-Length: 251 \n            <?xml version=\"1.0\" encoding=\"UTF-8\"?> \n            <DeleteResult xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n             <Deleted> \n               <Key>sample1.txt</Key> \n             </Deleted> \n             <Error> \n              <Key>sample2.txt</Key> \n              <Code>AccessDenied</Code> \n              <Message>Access Denied</Message> \n             </Error> \n            </DeleteResult> \nAmazon S3 API Version 2006-03-01 168Amazon Simple Storage Service API Reference\n         \nSample Request for general purpose buckets: Deleting an object from a versioned bucket\nIf you delete an item from a versioning enabled bucket, all versions of that object remain in the \nbucket; however, Amazon S3 inserts a delete marker. For more information, see  Object Versioning.\nThe following scenarios describe the behavior of a multi-object Delete request when versioning is \nenabled for your bucket.\nCase 1 - Simple Delete: In the following sample request, the multi-object delete request speci\ufb01es \nonly one key.\n            POST /?delete HTTP/1.1 \n            Host: bucketname.s3.<Region>.amazonaws.com \n            Accept: */* \n            x-amz-date: Wed, 30 Nov 2011 03:39:05 GMT \n            Content-MD5: p5/WA/oEr30qrEEl21PAqw== \n            Authorization: AWS AKIAIOSFODNN7EXAMPLE:W0qPYCLe6JwkZAD1ei6hp9XZIee= \n            Content-Length: 79 \n            Connection: Keep-Alive \n            <Delete> \n             <Object> \n               <Key>SampleDocument.txt</Key> \n             </Object> \n            </Delete> \n          \nSample Response for general purpose buckets\nBecause versioning is enabled on the bucket, Amazon S3 does not delete the object.", "Instead, it \nadds a delete marker for this object. The following response indicates that a delete marker was \nadded (the DeleteMarker  element in the response as a value of true) and the version number of \nthe delete marker it added.\n            HTTP/1.1 200 OK \n            x-amz-id-2: P3xqrhuhYxlrefdw3rEzmJh8z5KDtGzb+/FB7oiQaScI9Yaxd8olYXc7d1111ab\n+ \n            x-amz-request-id: 264A17BF16E9E80A \nAmazon S3 API Version 2006-03-01 169Amazon Simple Storage Service API Reference\n            Date: Wed, 30 Nov 2011 03:39:32 GMT \n            Content-Type: application/xml \n            Server: AmazonS3 \n            Content-Length: 276 \n            <?xml version=\"1.0\" encoding=\"UTF-8\"?> \n            <DeleteResult xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n             <Deleted> \n              <Key>SampleDocument.txt</Key> \n               <DeleteMarker>true</DeleteMarker>  \n               <DeleteMarkerVersionId>NeQt5xeFTfgPJD8B4CGWnkSLtluMr11s</\nDeleteMarkerVersionId> \n             </Deleted> \n            </DeleteResult> \n          \nCase 2 for general purpose buckets - Versioned Delete\nThe following request attempts to delete a speci\ufb01c version of an object.\n            POST /?delete HTTP/1.1 \n            Host: bucketname.s3.<Region>.amazonaws.com \n            Accept: */* \n            x-amz-date: Wed, 30 Nov 2011 03:39:05 GMT \n            Content-MD5: p5/WA/oEr30qrEEl21PAqw== \n            Authorization: AWS AKIAIOSFODNN7EXAMPLE:W0qPYCLe6JwkZAD1ei6hp9XZIxx= \n            Content-Length: 140 \n            Connection: Keep-Alive \n            <Delete> \n              <Object> \n               <Key>SampleDocument.txt</Key> \n               <VersionId>OYcLXagmS.WaD..oyH4KRguB95_YhLs7</VersionId> \n              </Object> \n            </Delete> \n          \nSample Response for general purpose buckets\nIn this case, Amazon S3 deletes the speci\ufb01c object version from the bucket and returns the \nfollowing response.", "In the response, Amazon S3 returns the key and version ID of the object \ndeleted.\nAmazon S3 API Version 2006-03-01 170Amazon Simple Storage Service API Reference\n                  HTTP/1.1 400 Bad Request \n                  x-amz-id-2: P3xqrhuhYxlrefdw3rEzmJh8z5KDtGzb+/\nFB7oiQaScI9Yaxd8olYXc7d1111xx+ \n                  x-amz-request-id: 264A17BF16E9E80A \n                  Date: Wed, 30 Nov 2011 03:39:32 GMT \n                  Content-Type: application/xml \n                  Server: AmazonS3 \n                  Content-Length: 219 \n                  <?xml version=\"1.0\" encoding=\"UTF-8\"?> \n                  <DeleteResult xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n                    <Deleted> \n                      <Key>SampleDocument.txt</Key> \n                      <VersionId>OYcLXagmS.WaD..oyH4KRguB95_YhLs7</VersionId> \n                    </Deleted> \n                  </DeleteResult> \n                \nCase 3 for general purpose buckets - Versioned delete of a delete marker\nIn the preceding example, the request refers to a delete marker (instead of an object), then Amazon \nS3 deletes the delete marker.", "The e\ufb00ect of this action is to make your object reappear in your \nbucket.", "Amazon S3 returns a response that indicates the delete marker it deleted (DeleteMarker\nelement with value true) and the version ID of the delete marker.\n               HTTP/1.1 200 OK \n               x-amz-id-2: \n IIPUZrtolxDEmWsKOae9JlSZe6yWfTye3HQ3T2iAe0ZE4XHa6NKvAJcPp51zZaBr \n               x-amz-request-id: D6B284CEC9B05E4E \n               Date: Wed, 30 Nov 2011 03:43:25 GMT \n               Content-Type: application/xml \n               Server: AmazonS3 \n               Content-Length: 331 \n               <?xml version=\"1.0\" encoding=\"UTF-8\"?> \n               <DeleteResult xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n                 <Deleted> \n                   <Key>SampleDocument.txt</Key> \n                   <VersionId>NeQt5xeFTfgPJD8B4CGWnkSLtluMr11s</VersionId> \n                   <DeleteMarker>true</DeleteMarker>   \nAmazon S3 API Version 2006-03-01 171Amazon Simple Storage Service API Reference\n                   <DeleteMarkerVersionId>NeQt5xeFTfgPJD8B4CGWnkSLtluMr11s</\nDeleteMarkerVersionId>  \n                 </Deleted> \n               </DeleteResult> \n             \nSample Response for general purpose buckets\nIn general, when a multi-object Delete request results in Amazon S3 either adding a delete marker \nor removing a delete marker, the response returns the following elements.\n               <DeleteMarker>true</DeleteMarker>   \n               <DeleteMarkerVersionId>NeQt5xeFTfgPJD8B4CGWnkSLtluMr11s</\nDeleteMarkerVersionId>  \n             \nSample Request for general purpose buckets: Malformed XML in the request\nThis example shows how Amazon S3 responds to a request that includes a malformed XML \ndocument. The following request sends a malformed XML document (missing the Delete end \nelement).\n               POST /?delete HTTP/1.1 \n               Host: bucketname.s3.<Region>.amazonaws.com \n               Accept: */* \n               x-amz-date: Wed, 30 Nov 2011 03:39:05 GMT \n               Content-MD5: p5/WA/oEr30qrEEl21PAqw== \n               Authorization: AWS AKIAIOSFODNN7EXAMPLE:W0qPYCLe6JwkZAD1ei6hp9XZIee= \n               Content-Length: 104 \n               Connection: Keep-Alive \n               <Delete> \n                 <Object> \n                   <Key>404.txt</Key> \n                 </Object> \n                 <Object> \n                   <Key>a.txt</Key> \n                 </Object> \n             \nAmazon S3 API Version 2006-03-01 172Amazon Simple Storage Service API Reference\nSample Response for general purpose buckets\nThe response returns the error messages that describe the error.\n               HTTP/1.1 200 OK \n               x-amz-id-2: P3xqrhuhYxlrefdw3rEzmJh8z5KDtGzb+/\nFB7oiQaScI9Yaxd8olYXc7d1111ab+ \n               x-amz-request-id: 264A17BF16E9E80A \n               Date: Wed, 30 Nov 2011 03:39:32 GMT \n               Content-Type: application/xml \n               Server: AmazonS3 \n               Content-Length: 207 \n               <?xml version=\"1.0\" encoding=\"UTF-8\"?> \n               <Error> \n                <Code>MalformedXML</Code> \n                 <Message>The XML you provided was not well-formed or did not  \n                         validate against our published schema</Message> \n                <RequestId>264A17BF16E9E80A</RequestId> \n                <HostId>P3xqrhuhYxlrefdw3rEzmJh8z5KDtGzb+/FB7oiQaScI9Yaxd8olYXc7d1111ab\n+</HostId> \n               </Error> \n             \nSample Request for general purpose buckets: DeleteObjects containing a carriage return\nThe following example illustrates the use of an XML entity code as a substitution for a carriage \nreturn. This DeleteObjects  request deletes an object with the key parameter: /some/prefix/\nobjectwith\\rcarriagereturn  (where the \\r is the carriage return).\n<Delete xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n  <Object> \n    <Key>/some/prefix/objectwith&#13;carriagereturn</Key> \n  </Object>\n</Delete>\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\nAmazon S3 API Version 2006-03-01 173Amazon Simple Storage Service API Reference\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 174Amazon Simple Storage Service API Reference\nDeleteObjectTagging\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nRemoves the entire tag set from the speci\ufb01ed object. For more information about managing object \ntags, see  Object Tagging.\nTo use this operation, you must have permission to perform the s3:DeleteObjectTagging\naction.\nTo delete tags of a speci\ufb01c object version, add the versionId  query parameter in the request. You \nwill need permission for the s3:DeleteObjectVersionTagging  action.\nThe following operations are related to DeleteObjectTagging :\n\u2022PutObjectTagging\n\u2022GetObjectTagging\nRequest Syntax\nDELETE /{Key+}?tagging&versionId= VersionId  HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe bucket name containing the objects from which to remove the tags.\nAccess points - When you use this action with an access point, you must provide the alias of the \naccess point in place of the bucket name or specify the access point ARN.", "When using the access \npoint ARN, you must direct requests to the access point hostname.", "The access point hostname \ntakes the form AccessPointName-AccountId .s3-accesspoint.Region.amazonaws.com. When using \nAmazon S3 API Version 2006-03-01 175Amazon Simple Storage Service API Reference\nthis action with an access point through the AWS SDKs, you provide the access point ARN in \nplace of the bucket name. For more information about access point ARNs, see Using access \npoints  in the Amazon S3 User Guide .\nS3 on Outposts  - When you use this action with Amazon S3 on Outposts, you must direct \nrequests to the S3 on Outposts hostname. The S3 on Outposts hostname takes the form \nAccessPointName -AccountId .outpostID .s3-outposts.", "Region.amazonaws.com .", "\nWhen you use this action with S3 on Outposts through the AWS SDKs, you provide the Outposts \naccess point ARN in place of the bucket name. For more information about S3 on Outposts \nARNs, see What is S3 on Outposts?", "in the Amazon S3 User Guide .\nRequired: Yes\nKey\nThe key that identi\ufb01es the object in the bucket from which to remove all tags.\nLength Constraints: Minimum length of 1.\nRequired: Yes\nversionId\nThe versionId of the object that the tag-set will be removed from.\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match \nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 204\nx-amz-version-id: VersionId\nResponse Elements\nIf the action is successful, the service sends back an HTTP 204 response.\nAmazon S3 API Version 2006-03-01 176Amazon Simple Storage Service API Reference\nThe response returns the following HTTP headers.\nx-amz-version-id\nThe versionId of the object the tag-set was removed from.\nExamples\nSample Request\nThe following DELETE request deletes the tag set from the speci\ufb01ed object.\n             DELETE /exampleobject?tagging HTTP/1.1 \n            Host: examplebucket.s3.<Region>.amazonaws.com   \n            Date: Wed, 25 Nov 2016 12:00:00 GMT \n            Authorization: signatureValue  \n          \nSample Response\nThe following successful response shows Amazon S3 returning a 204 No Content response. The tag \nset for the object has been removed.\n           HTTP/1.1 204 No Content \n           x-amz-version-id: VersionId \n           Date: Wed, 25 Nov 2016 12:00:00 GMT \n           Connection: close \n           Server: AmazonS3 \n          \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\nAmazon S3 API Version 2006-03-01 177Amazon Simple Storage Service API Reference\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 178Amazon Simple Storage Service API Reference\nDeletePublicAccessBlock\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nRemoves the PublicAccessBlock  con\ufb01guration for an Amazon S3 bucket. To use this operation, \nyou must have the s3:PutBucketPublicAccessBlock  permission. For more information about \npermissions, see Permissions Related to Bucket Subresource Operations and Managing Access \nPermissions to Your Amazon S3 Resources.\nThe following operations are related to DeletePublicAccessBlock :\n\u2022Using Amazon S3 Block Public Access\n\u2022GetPublicAccessBlock\n\u2022PutPublicAccessBlock\n\u2022GetBucketPolicyStatus\nRequest Syntax\nDELETE /?publicAccessBlock HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe Amazon S3 bucket whose PublicAccessBlock  con\ufb01guration you want to delete.\nRequired: Yes\nAmazon S3 API Version 2006-03-01 179Amazon Simple Storage Service API Reference\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match \nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 204\nResponse Elements\nIf the action is successful, the service sends back an HTTP 204 response with an empty HTTP body.\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 180Amazon Simple Storage Service API Reference\nGetBucketAccelerateCon\ufb01guration\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nThis implementation of the GET action uses the accelerate  subresource to return the Transfer \nAcceleration state of a bucket, which is either Enabled  or Suspended .", "Amazon S3 Transfer \nAcceleration is a bucket-level feature that enables you to perform faster data transfers to and from \nAmazon S3.\nTo use this operation, you must have permission to perform the\ns3:GetAccelerateConfiguration  action.", "The bucket owner has this permission by default. \nThe bucket owner can grant this permission to others.", "For more information about permissions, see\nPermissions Related to Bucket Subresource Operations and Managing Access Permissions to your \nAmazon S3 Resources in the Amazon S3 User Guide .\nYou set the Transfer Acceleration state of an existing bucket to Enabled  or Suspended  by using \nthe PutBucketAccelerateCon\ufb01guration operation.\nA GET accelerate  request does not return a state value for a bucket that has no transfer \nacceleration state. A bucket has no Transfer Acceleration state if a state has never been set on the \nbucket.\nFor more information about transfer acceleration, see Transfer Acceleration in the Amazon S3 User \nGuide.\nThe following operations are related to GetBucketAccelerateConfiguration :\n\u2022PutBucketAccelerateCon\ufb01guration\nRequest Syntax\nGET /?accelerate HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nx-amz-request-payer: RequestPayer\nAmazon S3 API Version 2006-03-01 181Amazon Simple Storage Service API Reference\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe name of the bucket for which the accelerate con\ufb01guration is retrieved.\nRequired: Yes\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match \nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nx-amz-request-payer\nCon\ufb01rms that the requester knows that they will be charged for the request. Bucket owners \nneed not specify this parameter in their requests.", "If either the source or destination S3 \nbucket has Requester Pays enabled, the requester will pay for corresponding charges to copy \nthe object. For information about downloading objects from Requester Pays buckets, see\nDownloading Objects in Requester Pays Buckets in the Amazon S3 User Guide .\nNote\nThis functionality is not supported for directory buckets.\nValid Values: requester\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\nx-amz-request-charged: RequestCharged\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<AccelerateConfiguration > \n   <Status>string</Status>\nAmazon S3 API Version 2006-03-01 182Amazon Simple Storage Service API Reference\n</AccelerateConfiguration >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe response returns the following HTTP headers.\nx-amz-request-charged\nIf present, indicates that the requester was successfully charged for the request.\nNote\nThis functionality is not supported for directory buckets.\nValid Values: requester\nThe following data is returned in XML format by the service.\nAccelerateCon\ufb01guration\nRoot level tag for the AccelerateCon\ufb01guration parameters.\nRequired: Yes\nStatus\nThe accelerate con\ufb01guration of the bucket.\nType: String\nValid Values: Enabled | Suspended\nExamples\nThis implementation of the GET action returns the following responses.\nExample\nIf the transfer acceleration state is set to Enabled on a bucket, the response is as follows:\nAmazon S3 API Version 2006-03-01 183Amazon Simple Storage Service API Reference\n<AccelerateConfiguration xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n  <Status>Enabled</Status>\n</AccelerateConfiguration>                  \n               \nExample\nIf the transfer acceleration state is set to Suspended  on a bucket, the response is as follows:\n<AccelerateConfiguration xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n  <Status>Suspended</Status>\n</AccelerateConfiguration>                  \n               \nExample\nIf the transfer acceleration state on a bucket has never been set to Enabled  or Suspended , the \nresponse is as follows:\n<AccelerateConfiguration xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\" /> \n               \nRetrieve the transfer acceleration con\ufb01guration for a bucket\nThe following example shows a GET /?accelerate  request to retrieve the transfer acceleration \nstate of the bucket named examplebucket .\n<AccelerateConfiguration xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n  <Status>Enabled</Status>\n</AccelerateConfiguration> \n               \nExample\nThe following is a sample of the response body (only) that shows bucket transfer acceleration is \nenabled.\nAmazon S3 API Version 2006-03-01 184Amazon Simple Storage Service API Reference\nGET /?accelerate HTTP/1.1\nHost: examplebucket.s3.<Region>.amazonaws.com\nDate: Mon, 11 Apr 2016 12:00:00 GMT\nAuthorization: authorization string\nContent-Type: text/plain \n               \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 185Amazon Simple Storage Service API Reference\nGetBucketAcl\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nThis implementation of the GET action uses the acl subresource to return the access control list \n(ACL) of a bucket.", "To use GET to return the ACL of the bucket, you must have the READ_ACP  access \nto the bucket. If READ_ACP  permission is granted to the anonymous user, you can return the ACL of \nthe bucket without using an authorization header.\nWhen you use this API operation with an access point, provide the alias of the access point in place \nof the bucket name.\nWhen you use this API operation with an Object Lambda access point, provide the alias of the \nObject Lambda access point in place of the bucket name. If the Object Lambda access point alias \nin a request is not valid, the error code InvalidAccessPointAliasError  is returned.", "For more \ninformation about InvalidAccessPointAliasError , see List of Error Codes.\nNote\nIf your bucket uses the bucket owner enforced setting for S3 Object Ownership, requests to \nread ACLs are still supported and return the bucket-owner-full-control  ACL with the \nowner being the account that created the bucket. For more information, see  Controlling \nobject ownership and disabling ACLs in the Amazon S3 User Guide .\nThe following operations are related to GetBucketAcl :\n\u2022ListObjects\nRequest Syntax\nGET /?acl HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nAmazon S3 API Version 2006-03-01 186Amazon Simple Storage Service API Reference\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nSpeci\ufb01es the S3 bucket whose ACL is being requested.\nWhen you use this API operation with an access point, provide the alias of the access point in \nplace of the bucket name.\nWhen you use this API operation with an Object Lambda access point, provide the alias of the \nObject Lambda access point in place of the bucket name.", "If the Object Lambda access point \nalias in a request is not valid, the error code InvalidAccessPointAliasError  is returned.", "\nFor more information about InvalidAccessPointAliasError , see List of Error Codes.\nRequired: Yes\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match \nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<AccessControlPolicy > \n   <Owner> \n      <DisplayName >string</DisplayName > \n      <ID>string</ID> \n   </Owner> \n   <AccessControlList > \n      <Grant> \n         < Grantee> \n            < DisplayName >string</DisplayName > \n            < EmailAddress >string</EmailAddress > \nAmazon S3 API Version 2006-03-01 187Amazon Simple Storage Service API Reference\n            < ID>string</ID> \n            < xsi:type >string</xsi:type > \n            < URI>string</URI> \n         </ Grantee> \n         < Permission >string</Permission > \n      </Grant> \n   </AccessControlList >\n</AccessControlPolicy >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nAccessControlPolicy\nRoot level tag for the AccessControlPolicy parameters.\nRequired: Yes\nGrants\nA list of grants.\nType: Array of Grant  data types\nOwner\nContainer for the bucket owner's display name and ID.\nType: Owner  data type\nExamples\nSample Request\nThe following request returns the ACL of the speci\ufb01ed bucket.\nGET ?acl HTTP/1.1\nHost: bucket.s3.<Region>.amazonaws.com\nDate: Wed, 28 Oct 2009 22:32:00 GMT\nAuthorization: authorization string \n            \nAmazon S3 API Version 2006-03-01 188Amazon Simple Storage Service API Reference\nSample Response\nHTTP/1.1 200 OK\nx-amz-id-2: eftixk72aD6Ap51TnqcoF8eFidJG9Z/2mkiDFu8yU9AS1ed4OpIszj7UDNEHGran\nx-amz-request-id: 318BC8BC148832E5\nDate: Wed, 28 Oct 2009 22:32:00 GMT\nLast-Modified: Sun, 1 Jan 2006 12:00:00 GMT\nContent-Length: 124\nContent-Type: text/plain\nConnection: close\nServer: AmazonS3\n<AccessControlPolicy> \n  <Owner> \n    <ID>75aa57f09aa0c8caeab4f8c24e99d10f8e7faeebf76c078efc7c6caea54ba06a</ID> \n    <DisplayName>CustomersName@amazon.com</DisplayName> \n  </Owner> \n  <AccessControlList> \n    <Grant> \n      <Grantee xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" \n   xsi:type=\"CanonicalUser\"> \n        <ID>75aa57f09aa0c8caeab4f8c24e99d10f8e7faeebf76c078efc7c6caea54ba06a</ID> \n        <DisplayName>CustomersName@amazon.com</DisplayName> \n      </Grantee> \n      <Permission>FULL_CONTROL</Permission> \n    </Grant> \n  </AccessControlList>\n</AccessControlPolicy>  \n            \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\nAmazon S3 API Version 2006-03-01 189Amazon Simple Storage Service API Reference\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 190Amazon Simple Storage Service API Reference\nGetBucketAnalyticsCon\ufb01guration\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nThis implementation of the GET action returns an analytics con\ufb01guration (identi\ufb01ed by the \nanalytics con\ufb01guration ID) from the bucket.\nTo use this operation, you must have permissions to perform the\ns3:GetAnalyticsConfiguration  action.", "The bucket owner has this permission by default. The \nbucket owner can grant this permission to others.", "For more information about permissions, see \nPermissions Related to Bucket Subresource Operations and Managing Access Permissions to Your \nAmazon S3 Resources in the Amazon S3 User Guide .\nFor information about Amazon S3 analytics feature, see Amazon S3 Analytics \u2013 Storage Class \nAnalysis  in the Amazon S3 User Guide .\nThe following operations are related to GetBucketAnalyticsConfiguration :\n\u2022DeleteBucketAnalyticsCon\ufb01guration\n\u2022ListBucketAnalyticsCon\ufb01gurations\n\u2022PutBucketAnalyticsCon\ufb01guration\nRequest Syntax\nGET /?analytics&id= Id HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe name of the bucket from which an analytics con\ufb01guration is retrieved.\nAmazon S3 API Version 2006-03-01 191Amazon Simple Storage Service API Reference\nRequired: Yes\nid\nThe ID that identi\ufb01es the analytics con\ufb01guration.\nRequired: Yes\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match \nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<AnalyticsConfiguration > \n   <Id>string</Id> \n   <Filter> \n      <And> \n         < Prefix>string</Prefix> \n         < Tag> \n            < Key>string</Key> \n            < Value>string</Value> \n         </ Tag> \n         ... \n      </ And> \n      <Prefix>string</Prefix> \n      <Tag> \n         < Key>string</Key> \n         < Value>string</Value> \n      </ Tag> \n   </Filter> \n   <StorageClassAnalysis > \n      <DataExport > \n         < Destination > \n            < S3BucketDestination > \nAmazon S3 API Version 2006-03-01 192Amazon Simple Storage Service API Reference\n               < Bucket>string</Bucket> \n               < BucketAccountId >string</BucketAccountId > \n               < Format>string</Format> \n               < Prefix>string</Prefix> \n            </ S3BucketDestination > \n         </ Destination > \n         < OutputSchemaVersion >string</OutputSchemaVersion > \n      </ DataExport > \n   </StorageClassAnalysis >\n</AnalyticsConfiguration >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nAnalyticsCon\ufb01guration\nRoot level tag for the AnalyticsCon\ufb01guration parameters.\nRequired: Yes\nFilter\nThe \ufb01lter used to describe a set of objects for analyses.", "A \ufb01lter must have exactly one pre\ufb01x, \none tag, or one conjunction (AnalyticsAndOperator).", "If no \ufb01lter is provided, all objects will be \nconsidered in any analysis.\nType: AnalyticsFilter data type\nId\nThe ID that identi\ufb01es the analytics con\ufb01guration.\nType: String\nStorageClassAnalysis\nContains data related to access patterns to be collected and made available to analyze the \ntradeo\ufb00s between di\ufb00erent storage classes.\nType: StorageClassAnalysis  data type\nAmazon S3 API Version 2006-03-01 193Amazon Simple Storage Service API Reference\nExamples\nCon\ufb01gure an Analytics Report\nThe following GET request for the bucket examplebucket  returns the inventory con\ufb01guration \nwith the ID list1 :\nGET /?analytics&id=list1 HTTP/1.1\nHost: examplebucket.s3.<Region>.amazonaws.com\nDate: Mon, 31 Oct 2016 12:00:00 GMT\nAuthorization: authorization string \n            \nExample\nThe following is a sample response to the preceding GET request.\nHTTP/1.1 200 OK\nx-amz-id-2: YgIPIfBiKa2bj0KMgUAdQkf3ShJTOOpXUueF6QKo\nx-amz-request-id: 236A8905248E5A02\nDate: Mon, 31 Oct 2016 12:00:00 GMT\nServer: AmazonS3\nContent-Length: length\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<AnalyticsConfiguration xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n  <Id>list1</Id> \n  <Filter> \n    <And> \n      <Prefix>images/</Prefix> \n      <Tag> \n        <Key>dog</Key> \n        <Value>corgi</Value> \n      </Tag> \n    </And> \n  </Filter> \n  <StorageClassAnalysis> \n    <DataExport> \n      <OutputSchemaVersion>V_1</OutputSchemaVersion> \n      <Destination> \n        <S3BucketDestination> \nAmazon S3 API Version 2006-03-01 194Amazon Simple Storage Service API Reference\n          <Format>CSV</Format> \n          <BucketAccountId>123456789012</BucketAccountId> \n          <Bucket>arn:aws:s3:::destination-bucket</Bucket> \n          <Prefix>destination-prefix</Prefix> \n        </S3BucketDestination> \n      </Destination> \n    </DataExport> \n  </StorageClassAnalysis>\n</AnalyticsConfiguration> \n            \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 195Amazon Simple Storage Service API Reference\nGetBucketCors\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nReturns the Cross-Origin Resource Sharing (CORS) con\ufb01guration information set for the bucket.\nTo use this operation, you must have permission to perform the s3:GetBucketCORS  action.", "By \ndefault, the bucket owner has this permission and can grant it to others.\nWhen you use this API operation with an access point, provide the alias of the access point in place \nof the bucket name.\nWhen you use this API operation with an Object Lambda access point, provide the alias of the \nObject Lambda access point in place of the bucket name. If the Object Lambda access point alias \nin a request is not valid, the error code InvalidAccessPointAliasError  is returned.", "For more \ninformation about InvalidAccessPointAliasError , see List of Error Codes.\nFor more information about CORS, see  Enabling Cross-Origin Resource Sharing.\nThe following operations are related to GetBucketCors :\n\u2022PutBucketCors\n\u2022DeleteBucketCors\nRequest Syntax\nGET /?cors HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe bucket name for which to get the cors con\ufb01guration.\nAmazon S3 API Version 2006-03-01 196Amazon Simple Storage Service API Reference\nWhen you use this API operation with an access point, provide the alias of the access point in \nplace of the bucket name.\nWhen you use this API operation with an Object Lambda access point, provide the alias of the \nObject Lambda access point in place of the bucket name.", "If the Object Lambda access point \nalias in a request is not valid, the error code InvalidAccessPointAliasError  is returned.", "\nFor more information about InvalidAccessPointAliasError , see List of Error Codes.\nRequired: Yes\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match \nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<CORSConfiguration > \n   <CORSRule > \n      <AllowedHeader >string</AllowedHeader > \n      ...", "\n      <AllowedMethod >string</AllowedMethod > \n      ... \n      <AllowedOrigin >string</AllowedOrigin > \n      ...", "\n      <ExposeHeader >string</ExposeHeader > \n      ...", "\n      <ID>string</ID> \n      <MaxAgeSeconds >integer</MaxAgeSeconds > \n   </CORSRule > \n   ...\n</CORSConfiguration >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nAmazon S3 API Version 2006-03-01 197Amazon Simple Storage Service API Reference\nThe following data is returned in XML format by the service.\nCORSCon\ufb01guration\nRoot level tag for the CORSCon\ufb01guration parameters.\nRequired: Yes\nCORSRule\nA set of origins and methods (cross-origin access that you want to allow). You can add up to 100 \nrules to the con\ufb01guration.\nType: Array of CORSRule data types\nExamples\nCon\ufb01gure CORS Sample Request\nThe following PUT request adds the cors subresource to a bucket (examplebucket) .\nPUT /?cors HTTP/1.1\nHost: examplebucket.s3.<Region>.amazonaws.com  \nx-amz-date: Tue, 21 Aug 2012 17:54:50 GMT\nContent-MD5: 8dYiLewFWZyGgV2Q5FNI4W==\nAuthorization: authorization string\nContent-Length: 216\n<CORSConfiguration> \n <CORSRule> \n   <AllowedOrigin>http://www.example.com</AllowedOrigin> \n   <AllowedMethod>PUT</AllowedMethod> \n   <AllowedMethod>POST</AllowedMethod> \n   <AllowedMethod>DELETE</AllowedMethod> \n   <AllowedHeader>*</AllowedHeader> \n   <MaxAgeSeconds>3000</MaxAgeSec> \n   <ExposeHeader>x-amz-server-side-encryption</ExposeHeader> \n </CORSRule> \n <CORSRule> \n   <AllowedOrigin>*</AllowedOrigin> \n   <AllowedMethod>GET</AllowedMethod> \n   <AllowedHeader>*</AllowedHeader> \nAmazon S3 API Version 2006-03-01 198Amazon Simple Storage Service API Reference\n   <MaxAgeSeconds>3000</MaxAgeSeconds> \n </CORSRule>\n</CORSConfiguration>  \n             \nExample\nThis is the sample response to the preceding request.\nHTTP/1.1 200 OK\nx-amz-id-2: CCshOvbOPfxzhwOADyC4qHj/Ck3F9Q0viXKw3rivZ+GcBoZSOOahvEJfPisZB7B\nx-amz-request-id: BDC4B83DF5096BBE\nDate: Tue, 21 Aug 2012 17:54:50 GMT\nServer: AmazonS3 \n             \nSample Request: Retrieve cors subresource\nThe following example gets the cors subresource of a bucket.\n            GET /?cors HTTP/1.1 \n            Host: examplebucket.s3.<Region>.amazonaws.com \n            Date: Tue, 13 Dec 2011 19:14:42 GMT \n            Authorization: signatureValue \n          \nExample\nSample Response\n            HTTP/1.1 200 OK \n            x-amz-id-2: 0FmFIWsh/\nPpBuzZ0JFRC55ZGVmQW4SHJ7xVDqKwhEdJmf3q63RtrvH8ZuxW1Bol5 \n            x-amz-request-id: 0CF038E9BCF63097 \n            Date: Tue, 13 Dec 2011 19:14:42 GMT \n            Server: AmazonS3 \n            Content-Length: 280 \n            <CORSConfiguration> \n                 <CORSRule> \nAmazon S3 API Version 2006-03-01 199Amazon Simple Storage Service API Reference\n                   <AllowedOrigin>http://www.example.com</AllowedOrigin> \n                   <AllowedMethod>GET</AllowedMethod> \n                   <MaxAgeSeconds>3000</MaxAgeSec> \n                  <ExposeHeader>x-amz-server-side-encryption</ExposeHeader> \n                </CORSRule> \n            </CORSConfiguration> \n          \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 200Amazon Simple Storage Service API Reference\nGetBucketEncryption\nService: Amazon S3\nReturns the default encryption con\ufb01guration for an Amazon S3 bucket.", "By default, all buckets have \na default encryption con\ufb01guration that uses server-side encryption with Amazon S3 managed keys \n(SSE-S3).\nNote\n\u2022General purpose buckets - For information about the bucket default encryption feature, \nsee Amazon S3 Bucket Default Encryption in the Amazon S3 User Guide .\n\u2022Directory buckets - For directory buckets, there are only two supported options \nfor server-side encryption: SSE-S3 and SSE-KMS. For information about the default \nencryption con\ufb01guration in directory buckets, see Setting default server-side encryption \nbehavior for directory buckets.\nPermissions\n\u2022General purpose bucket permissions - The s3:GetEncryptionConfiguration\npermission is required in a policy.", "The bucket owner has this permission by default. The \nbucket owner can grant this permission to others.", "For more information about permissions, \nsee Permissions Related to Bucket Operations and Managing Access Permissions to Your \nAmazon S3 Resources.\n\u2022Directory bucket permissions - To grant access to this API operation, you must have the\ns3express:GetEncryptionConfiguration  permission in an IAM identity-based policy \ninstead of a bucket policy.", "Cross-account access to this API operation isn't supported.", "This \noperation can only be performed by the AWS account that owns the resource.", "For more \ninformation about directory bucket policies and permissions, see AWS Identity and Access \nManagement (IAM) for S3 Express One Zone in the Amazon S3 User Guide .\nHTTP Host header syntax\nDirectory buckets  - The HTTP Host header syntax is s3express-\ncontrol. region.amazonaws.com .\nThe following operations are related to GetBucketEncryption :\n\u2022PutBucketEncryption\nAmazon S3 API Version 2006-03-01 201Amazon Simple Storage Service API Reference\n\u2022DeleteBucketEncryption\nRequest Syntax\nGET /?encryption HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe name of the bucket from which the server-side encryption con\ufb01guration is retrieved.\nDirectory buckets  - When you use this operation with a directory bucket, \nyou must use path-style requests in the format https://s3express-\ncontrol.", "region_code .amazonaws.com/ bucket-name  .", "Virtual-hosted-style requests \naren't supported.", "Directory bucket names must be unique in the chosen Availability Zone.", "\nBucket names must also follow the format  bucket_base_name --az_id--x-s3  (for \nexample,  DOC-EXAMPLE-BUCKET --usw2-az1 --x-s3). For information about bucket naming \nrestrictions, see Directory bucket naming rules in the Amazon S3 User Guide\nRequired: Yes\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner.", "If the account ID that you provide does not match \nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nNote\nFor directory buckets, this header is not supported in this API operation.", "If you specify \nthis header, the request fails with the HTTP status code 501 Not Implemented .\nRequest Body\nThe request does not have a request body.\nAmazon S3 API Version 2006-03-01 202Amazon Simple Storage Service API Reference\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<ServerSideEncryptionConfiguration > \n   <Rule> \n      <ApplyServerSideEncryptionByDefault > \n         < KMSMasterKeyID >string</KMSMasterKeyID > \n         < SSEAlgorithm >string</SSEAlgorithm > \n      </ ApplyServerSideEncryptionByDefault > \n      <BucketKeyEnabled >boolean</BucketKeyEnabled > \n   </Rule> \n   ...\n</ServerSideEncryptionConfiguration >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nServerSideEncryptionCon\ufb01guration\nRoot level tag for the ServerSideEncryptionCon\ufb01guration parameters.\nRequired: Yes\nRule\nContainer for information about a particular server-side encryption con\ufb01guration rule.\nType: Array of ServerSideEncryptionRule data types\nExamples\nSample Request: Retrieve the encryption con\ufb01guration for an S3 general purpose bucket\nThe following example shows a GET /?encryption request.\n            GET /?encryption HTTP/1.1 \n            Host: examplebucket.s3.<Region>.amazonaws.com \n            Date: Wed, 06 Sep 2017 12:00:00 GMT \nAmazon S3 API Version 2006-03-01 203Amazon Simple Storage Service API Reference\n            Authorization: authorization string \n            Content-Length: length \n          \nSample Response for a general purpose bucket\nThis example illustrates one usage of GetBucketEncryption.\n           HTTP/1.1 200 OK \n            x-amz-id-2: kDmqsuw5FDmgLmxQaUkd9A4NJ/PIiE0c1rAU/ue2Yp60toXs4I5k5fqlwZsA6fV\n+wJQCzRRwygQ= \n            x-amz-request-id: 5D8706FCB2673B7D \n            Date: Wed, 06 Sep 2017 12:00:00 GMT \n            Transfer-Encoding: chunked \n            Server: AmazonS3 \n            <ServerSideEncryptionConfiguration xmlns=\"http://s3.amazonaws.com/\ndoc/2006-03-01/\"> \n             <Rule> \n               <ApplyServerSideEncryptionByDefault> \n                   <SSEAlgorithm>aws:kms</SSEAlgorithm> \n                   <KMSKeyID>arn:aws:kms:us-east-1:1234/5678example</KMSKeyID> \n               </ApplyServerSideEncryptionByDefault> \n            </Rule> \n            </ServerSideEncryptionConfiguration> \n          \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\nAmazon S3 API Version 2006-03-01 204Amazon Simple Storage Service API Reference\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 205Amazon Simple Storage Service API Reference\nGetBucketIntelligentTieringCon\ufb01guration\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nGets the S3 Intelligent-Tiering con\ufb01guration from the speci\ufb01ed bucket.\nThe S3 Intelligent-Tiering storage class is designed to optimize storage costs by automatically \nmoving data to the most cost-e\ufb00ective storage access tier, without performance impact or \noperational overhead. S3 Intelligent-Tiering delivers automatic cost savings in three low latency \nand high throughput access tiers. To get the lowest storage cost on data that can be accessed in \nminutes to hours, you can choose to activate additional archiving capabilities.\nThe S3 Intelligent-Tiering storage class is the ideal storage class for data with unknown, changing, \nor unpredictable access patterns, independent of object size or retention period.", "If the size of an \nobject is less than 128 KB, it is not monitored and not eligible for auto-tiering.", "Smaller objects can \nbe stored, but they are always charged at the Frequent Access tier rates in the S3 Intelligent-Tiering \nstorage class.\nFor more information, see Storage class for automatically optimizing frequently and infrequently \naccessed objects.\nOperations related to GetBucketIntelligentTieringConfiguration  include:\n\u2022DeleteBucketIntelligentTieringCon\ufb01guration\n\u2022PutBucketIntelligentTieringCon\ufb01guration\n\u2022ListBucketIntelligentTieringCon\ufb01gurations\nRequest Syntax\nGET /?intelligent-tiering&id= Id HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nURI Request Parameters\nThe request uses the following URI parameters.\nAmazon S3 API Version 2006-03-01 206Amazon Simple Storage Service API Reference\nBucket\nThe name of the Amazon S3 bucket whose con\ufb01guration you want to modify or retrieve.\nRequired: Yes\nid\nThe ID used to identify the S3 Intelligent-Tiering con\ufb01guration.\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<IntelligentTieringConfiguration > \n   <Id>string</Id> \n   <Filter> \n      <And> \n         < Prefix>string</Prefix> \n         < Tag> \n            < Key>string</Key> \n            < Value>string</Value> \n         </ Tag> \n         ... \n      </ And> \n      <Prefix>string</Prefix> \n      <Tag> \n         < Key>string</Key> \n         < Value>string</Value> \n      </ Tag> \n   </Filter> \n   <Status>string</Status> \n   <Tiering> \n      <AccessTier >string</AccessTier > \n      <Days>integer</Days> \n   </Tiering> \n   ...\nAmazon S3 API Version 2006-03-01 207Amazon Simple Storage Service API Reference\n</IntelligentTieringConfiguration >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nIntelligentTieringCon\ufb01guration\nRoot level tag for the IntelligentTieringCon\ufb01guration parameters.\nRequired: Yes\nFilter\nSpeci\ufb01es a bucket \ufb01lter. The con\ufb01guration only includes objects that meet the \ufb01lter's criteria.\nType: IntelligentTieringFilter  data type\nId\nThe ID used to identify the S3 Intelligent-Tiering con\ufb01guration.\nType: String\nStatus\nSpeci\ufb01es the status of the con\ufb01guration.\nType: String\nValid Values: Enabled | Disabled\nTiering\nSpeci\ufb01es the S3 Intelligent-Tiering storage class tier of the con\ufb01guration.\nType: Array of Tiering  data types\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\nAmazon S3 API Version 2006-03-01 208Amazon Simple Storage Service API Reference\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 209Amazon Simple Storage Service API Reference\nGetBucketInventoryCon\ufb01guration\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nReturns an inventory con\ufb01guration (identi\ufb01ed by the inventory con\ufb01guration ID) from the bucket.\nTo use this operation, you must have permissions to perform the\ns3:GetInventoryConfiguration  action.", "The bucket owner has this permission by default \nand can grant this permission to others.", "For more information about permissions, see Permissions \nRelated to Bucket Subresource Operations and Managing Access Permissions to Your Amazon S3 \nResources.\nFor information about the Amazon S3 inventory feature, see Amazon S3 Inventory.\nThe following operations are related to GetBucketInventoryConfiguration :\n\u2022DeleteBucketInventoryCon\ufb01guration\n\u2022ListBucketInventoryCon\ufb01gurations\n\u2022PutBucketInventoryCon\ufb01guration\nRequest Syntax\nGET /?inventory&id= Id HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe name of the bucket containing the inventory con\ufb01guration to retrieve.\nRequired: Yes\nAmazon S3 API Version 2006-03-01 210Amazon Simple Storage Service API Reference\nid\nThe ID used to identify the inventory con\ufb01guration.\nRequired: Yes\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match \nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<InventoryConfiguration > \n   <Destination > \n      <S3BucketDestination > \n         < AccountId >string</AccountId > \n         < Bucket>string</Bucket> \n         < Encryption > \n            < SSE-KMS> \n               < KeyId>string</KeyId> \n            </ SSE-KMS> \n            < SSE-S3> \n            </ SSE-S3> \n         </ Encryption > \n         < Format>string</Format> \n         < Prefix>string</Prefix> \n      </ S3BucketDestination > \n   </Destination > \n   <IsEnabled >boolean</IsEnabled > \n   <Filter> \n      <Prefix>string</Prefix> \n   </Filter> \n   <Id>string</Id> \n   <IncludedObjectVersions >string</IncludedObjectVersions > \n   <OptionalFields > \nAmazon S3 API Version 2006-03-01 211Amazon Simple Storage Service API Reference\n      <Field> string</Field> \n   </OptionalFields > \n   <Schedule > \n      <Frequency >string</Frequency > \n   </Schedule >\n</InventoryConfiguration >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nInventoryCon\ufb01guration\nRoot level tag for the InventoryCon\ufb01guration parameters.\nRequired: Yes\nDestination\nContains information about where to publish the inventory results.\nType: InventoryDestination data type\nFilter\nSpeci\ufb01es an inventory \ufb01lter.", "The inventory only includes objects that meet the \ufb01lter's criteria.\nType: InventoryFilter data type\nId\nThe ID used to identify the inventory con\ufb01guration.\nType: String\nIncludedObjectVersions\nObject versions to include in the inventory list.", "If set to All, the list includes all the object \nversions, which adds the version-related \ufb01elds VersionId , IsLatest , and DeleteMarker  to \nthe list.", "If set to Current, the list does not contain these version-related \ufb01elds.\nType: String\nValid Values: All | Current\nAmazon S3 API Version 2006-03-01 212Amazon Simple Storage Service API Reference\nIsEnabled\nSpeci\ufb01es whether the inventory is enabled or disabled.", "If set to True, an inventory list is \ngenerated. If set to False, no inventory list is generated.\nType: Boolean\nOptionalFields\nContains the optional \ufb01elds that are included in the inventory results.\nType: Array of strings\nValid Values: Size | LastModifiedDate | StorageClass | ETag | \nIsMultipartUploaded | ReplicationStatus | EncryptionStatus | \nObjectLockRetainUntilDate | ObjectLockMode | ObjectLockLegalHoldStatus \n| IntelligentTieringAccessTier | BucketKeyStatus | ChecksumAlgorithm | \nObjectAccessControlList | ObjectOwner\nSchedule\nSpeci\ufb01es the schedule for generating inventory results.\nType: InventorySchedule data type\nExamples\nSample Request: Con\ufb01gure an inventory report\nThe following GET request for the bucket examplebucket  returns the inventory con\ufb01guration \nwith the ID list1 .\n            GET /?inventory&id=list1 HTTP/1.1 \n            Host: examplebucket.s3.<Region>.amazonaws.com \n            Date: Mon, 31 Oct 2016 12:00:00 GMT \n            Authorization: authorization string  \n          \nSample Response\nThis example illustrates one usage of GetBucketInventoryCon\ufb01guration.\nAmazon S3 API Version 2006-03-01 213Amazon Simple Storage Service API Reference\n         HTTP/1.1 200 OK \n         x-amz-id-2: YgIPIfBiKa2bj0KMgUAdQkf3ShJTOOpXUueF6QKo \n         x-amz-request-id: 236A8905248E5A02 \n         Date: Mon, 31 Oct 2016 12:00:00 GMT \n         Server: AmazonS3 \n         Content-Length: length \n         <?xml version=\"1.0\" encoding=\"UTF-8\"?> \n         <InventoryConfiguration xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n            <Id>report1</Id> \n           <IsEnabled>true</IsEnabled> \n           <Destination> \n              <S3BucketDestination> \n                 <Format>CSV</Format> \n                  <AccountId>123456789012</AccountId> \n                  <Bucket>arn:aws:s3:::destination-bucket</Bucket> \n                 <Prefix>prefix1</Prefix> \n                 <SSE-S3/> \n               </S3BucketDestination> \n            </Destination> \n            <Schedule> \n               <Frequency>Daily</Frequency> \n           </Schedule> \n           <Filter> \n             <Prefix>myprefix/</Prefix> \n           </Filter> \n           <IncludedObjectVersions>All</IncludedObjectVersions> \n           <OptionalFields> \n             <Field>Size</Field> \n             <Field>LastModifiedDate</Field> \n               <Field>ETag</Field> \n               <Field>StorageClass</Field> \n               <Field>IsMultipartUploaded</Field> \n             <Field>ReplicationStatus</Field> \n               <Field>ObjectLockRetainUntilDate</Field> \n               <Field>ObjectLockMode</Field> \n             <Field>ObjectLockLegalHoldStatus</Field>  \n          </OptionalFields> \n         </InventoryConfiguration> \n          \nAmazon S3 API Version 2006-03-01 214Amazon Simple Storage Service API Reference\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 215Amazon Simple Storage Service API Reference\nGetBucketLifecycle\nService: Amazon S3\nImportant\nFor an updated version of this API, see GetBucketLifecycleCon\ufb01guration.", "If you con\ufb01gured \na bucket lifecycle using the filter element, you should see the updated version of this \ntopic. This topic is provided for backward compatibility.\nNote\nThis operation is not supported by directory buckets.\nReturns the lifecycle con\ufb01guration information set on the bucket.", "For information about lifecycle \ncon\ufb01guration, see Object Lifecycle Management.\nTo use this operation, you must have permission to perform the\ns3:GetLifecycleConfiguration  action.", "The bucket owner has this permission by default. The \nbucket owner can grant this permission to others.", "For more information about permissions, see\nPermissions Related to Bucket Subresource Operations and Managing Access Permissions to Your \nAmazon S3 Resources.\nGetBucketLifecycle  has the following special error:\n\u2022Error code: NoSuchLifecycleConfiguration\n\u2022Description: The lifecycle con\ufb01guration does not exist.\n\u2022HTTP Status Code: 404 Not Found\n\u2022SOAP Fault Code Pre\ufb01x: Client\nThe following operations are related to GetBucketLifecycle :\n\u2022GetBucketLifecycleCon\ufb01guration\n\u2022PutBucketLifecycle\n\u2022DeleteBucketLifecycle\nAmazon S3 API Version 2006-03-01 216Amazon Simple Storage Service API Reference\nRequest Syntax\nGET /?lifecycle HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe name of the bucket for which to get the lifecycle information.\nRequired: Yes\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match \nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<LifecycleConfiguration > \n   <Rule> \n      <AbortIncompleteMultipartUpload > \n         < DaysAfterInitiation >integer</DaysAfterInitiation > \n      </ AbortIncompleteMultipartUpload > \n      <Expiration > \n         < Date>timestamp </Date> \n         < Days>integer</Days> \n         < ExpiredObjectDeleteMarker >boolean</ExpiredObjectDeleteMarker > \n      </ Expiration > \n      <ID>string</ID> \n      <NoncurrentVersionExpiration > \nAmazon S3 API Version 2006-03-01 217Amazon Simple Storage Service API Reference\n         < NewerNoncurrentVersions >integer</NewerNoncurrentVersions > \n         < NoncurrentDays >integer</NoncurrentDays > \n      </ NoncurrentVersionExpiration > \n      <NoncurrentVersionTransition > \n         < NewerNoncurrentVersions >integer</NewerNoncurrentVersions > \n         < NoncurrentDays >integer</NoncurrentDays > \n         < StorageClass >string</StorageClass > \n      </ NoncurrentVersionTransition > \n      <Prefix>string</Prefix> \n      <Status>string</Status> \n      <Transition > \n         < Date>timestamp </Date> \n         < Days>integer</Days> \n         < StorageClass >string</StorageClass > \n      </ Transition > \n   </Rule> \n   ...\n</LifecycleConfiguration >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nLifecycleCon\ufb01guration\nRoot level tag for the LifecycleCon\ufb01guration parameters.\nRequired: Yes\nRule\nContainer for a lifecycle rule.\nType: Array of Rule  data types\nExamples\nSample Request: Retrieve a lifecycle subresource\nThis example is a GET request to retrieve the lifecycle subresource from the speci\ufb01ed bucket, and \nan example response with the returned lifecycle con\ufb01guration.\nAmazon S3 API Version 2006-03-01 218Amazon Simple Storage Service API Reference\n            GET /?lifecycle HTTP/1.1 \n            Host: examplebucket.s3.<Region>.amazonaws.com \n            x-amz-date: Thu, 15 Nov 2012 00:17:21 GMT \n            Authorization: signatureValue \n          \nSample Response\nThis example illustrates one usage of GetBucketLifecycle.\n            HTTP/1.1 200 OK \n            x-amz-id-2: \n ITnGT1y4RyTmXa3rPi4hklTXouTf0hccUjo0iCPjz6FnfIutBj3M7fPGlWO2SEWp \n            x-amz-request-id: 51991C342C575321 \n            Date: Thu, 15 Nov 2012 00:17:23 GMT \n            Server: AmazonS3 \n            Content-Length: 358 \n            <?xml version=\"1.0\" encoding=\"UTF-8\"?> \n            <LifecycleConfiguration xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n               <Rule> \n                    <ID>Archive and then delete rule</ID> \n                    <Prefix>projectdocs/</Prefix> \n                   <Status>Enabled</Status> \n                  <Transition> \n                       <Days>30</Days> \n                       <StorageClass>STANDARD_IA</StorageClass> \n                  </Transition> \n                  <Transition> \n                     <Days>365</Days> \n                      <StorageClass>GLACIER</StorageClass> \n                   </Transition> \n                   <Expiration> \n                      <Days>3650</Days> \n                   </Expiration> \n               </Rule> \n            </LifecycleConfiguration> \n          \nAmazon S3 API Version 2006-03-01 219Amazon Simple Storage Service API Reference\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 220Amazon Simple Storage Service API Reference\nGetBucketLifecycleCon\ufb01guration\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nNote\nBucket lifecycle con\ufb01guration now supports specifying a lifecycle rule using an object key \nname pre\ufb01x, one or more object tags, object size, or any combination of these. Accordingly, \nthis section describes the latest API. The previous version of the API supported \ufb01ltering \nbased only on an object key name pre\ufb01x, which is supported for backward compatibility.", "\nFor the related API description, see GetBucketLifecycle.", "Accordingly, this section describes \nthe latest API. The response describes the new \ufb01lter element that you can use to specify \na \ufb01lter to select a subset of objects to which the rule applies.", "If you are using a previous \nversion of the lifecycle con\ufb01guration, it still works. For the earlier action,\nReturns the lifecycle con\ufb01guration information set on the bucket.", "For information about lifecycle \ncon\ufb01guration, see Object Lifecycle Management.\nTo use this operation, you must have permission to perform the\ns3:GetLifecycleConfiguration  action.", "The bucket owner has this permission, by default. The \nbucket owner can grant this permission to others.", "For more information about permissions, see\nPermissions Related to Bucket Subresource Operations and Managing Access Permissions to Your \nAmazon S3 Resources.\nGetBucketLifecycleConfiguration  has the following special error:\n\u2022Error code: NoSuchLifecycleConfiguration\n\u2022Description: The lifecycle con\ufb01guration does not exist.\n\u2022HTTP Status Code: 404 Not Found\n\u2022SOAP Fault Code Pre\ufb01x: Client\nThe following operations are related to GetBucketLifecycleConfiguration :\nAmazon S3 API Version 2006-03-01 221Amazon Simple Storage Service API Reference\n\u2022GetBucketLifecycle\n\u2022PutBucketLifecycle\n\u2022DeleteBucketLifecycle\nRequest Syntax\nGET /?lifecycle HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe name of the bucket for which to get the lifecycle information.\nRequired: Yes\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match \nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\nx-amz-transition-default-minimum-object-size: TransitionDefaultMinimumObjectSize\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<LifecycleConfiguration > \n   <Rule> \n      <AbortIncompleteMultipartUpload > \n         < DaysAfterInitiation >integer</DaysAfterInitiation > \n      </ AbortIncompleteMultipartUpload > \n      <Expiration > \n         < Date>timestamp </Date> \nAmazon S3 API Version 2006-03-01 222Amazon Simple Storage Service API Reference\n         < Days>integer</Days> \n         < ExpiredObjectDeleteMarker >boolean</ExpiredObjectDeleteMarker > \n      </ Expiration > \n      <Filter> \n         < And> \n            < ObjectSizeGreaterThan >long</ObjectSizeGreaterThan > \n            < ObjectSizeLessThan >long</ObjectSizeLessThan > \n            < Prefix>string</Prefix> \n            < Tag> \n               < Key>string</Key> \n               < Value>string</Value> \n            </ Tag> \n            ...", "\n         </ And> \n         < ObjectSizeGreaterThan >long</ObjectSizeGreaterThan > \n         < ObjectSizeLessThan >long</ObjectSizeLessThan > \n         < Prefix>string</Prefix> \n         < Tag> \n            < Key>string</Key> \n            < Value>string</Value> \n         </ Tag> \n      </ Filter> \n      <ID>string</ID> \n      <NoncurrentVersionExpiration > \n         < NewerNoncurrentVersions >integer</NewerNoncurrentVersions > \n         < NoncurrentDays >integer</NoncurrentDays > \n      </ NoncurrentVersionExpiration > \n      <NoncurrentVersionTransition > \n         < NewerNoncurrentVersions >integer</NewerNoncurrentVersions > \n         < NoncurrentDays >integer</NoncurrentDays > \n         < StorageClass >string</StorageClass > \n      </ NoncurrentVersionTransition > \n      ... \n      <Prefix>string</Prefix> \n      <Status>string</Status> \n      <Transition > \n         < Date>timestamp </Date> \n         < Days>integer</Days> \n         < StorageClass >string</StorageClass > \n      </ Transition > \n      ...", "\n   </Rule> \n   ...\nAmazon S3 API Version 2006-03-01 223Amazon Simple Storage Service API Reference\n</LifecycleConfiguration >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe response returns the following HTTP headers.\nx-amz-transition-default-minimum-object-size\nIndicates which default minimum object size behavior is applied to the lifecycle con\ufb01guration.\n\u2022all_storage_classes_128K  - Objects smaller than 128 KB will not transition to any \nstorage class by default.\n\u2022varies_by_storage_class  - Objects smaller than 128 KB will transition to Glacier Flexible \nRetrieval or Glacier Deep Archive storage classes.", "By default, all other storage classes will \nprevent transitions smaller than 128 KB.\nTo customize the minimum object size for any transition you can add a \ufb01lter that speci\ufb01es a \ncustom ObjectSizeGreaterThan  or ObjectSizeLessThan  in the body of your transition \nrule.", "Custom \ufb01lters always take precedence over the default transition behavior.\nValid Values: varies_by_storage_class | all_storage_classes_128K\nThe following data is returned in XML format by the service.\nLifecycleCon\ufb01guration\nRoot level tag for the LifecycleCon\ufb01guration parameters.\nRequired: Yes\nRule\nContainer for a lifecycle rule.\nType: Array of LifecycleRule data types\nExamples\nSample Request\nThis example illustrates one usage of GetBucketLifecycleCon\ufb01guration.\nAmazon S3 API Version 2006-03-01 224Amazon Simple Storage Service API Reference\n            GET /?lifecycle HTTP/1.1 \n            Host: examplebucket.s3.<Region>.amazonaws.com \n            x-amz-date: Thu, 15 Nov 2012 00:17:21 GMT \n            Authorization: signatureValue \n          \nSample Response\nThis example illustrates one usage of GetBucketLifecycleCon\ufb01guration.\n            HTTP/1.1 200 OK \n            x-amz-id-2: \n ITnGT1y4RyTmXa3rPi4hklTXouTf0hccUjo0iCPjz6FnfIutBj3M7fPGlWO2SEWp \n            x-amz-request-id: 51991C342C575321 \n            Date: Thu, 15 Nov 2012 00:17:23 GMT \n            Server: AmazonS3 \n            Content-Length: 358 \n            <?xml version=\"1.0\" encoding=\"UTF-8\"?> \n            <LifecycleConfiguration xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n               <Rule> \n                    <ID>Archive and then delete rule</ID> \n                    <Prefix>projectdocs/</Prefix> \n                   <Status>Enabled</Status> \n                  <Transition> \n                       <Days>30</Days> \n                       <StorageClass>STANDARD_IA</StorageClass> \n                  </Transition> \n                  <Transition> \n                     <Days>365</Days> \n                      <StorageClass>GLACIER</StorageClass> \n                   </Transition> \n                   <Expiration> \n                      <Days>3650</Days> \n                   </Expiration> \n               </Rule> \n            </LifecycleConfiguration> \n          \nAmazon S3 API Version 2006-03-01 225Amazon Simple Storage Service API Reference\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 226Amazon Simple Storage Service API Reference\nGetBucketLocation\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nReturns the Region the bucket resides in.", "You set the bucket's Region using the\nLocationConstraint  request parameter in a CreateBucket  request. For more information, see\nCreateBucket.\nWhen you use this API operation with an access point, provide the alias of the access point in place \nof the bucket name.\nWhen you use this API operation with an Object Lambda access point, provide the alias of the \nObject Lambda access point in place of the bucket name. If the Object Lambda access point alias \nin a request is not valid, the error code InvalidAccessPointAliasError  is returned.", "For more \ninformation about InvalidAccessPointAliasError , see List of Error Codes.\nNote\nWe recommend that you use HeadBucket to return the Region that a bucket resides in. For \nbackward compatibility, Amazon S3 continues to support GetBucketLocation.\nThe following operations are related to GetBucketLocation :\n\u2022GetObject\n\u2022CreateBucket\nRequest Syntax\nGET /?location HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nAmazon S3 API Version 2006-03-01 227Amazon Simple Storage Service API Reference\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe name of the bucket for which to get the location.\nWhen you use this API operation with an access point, provide the alias of the access point in \nplace of the bucket name.\nWhen you use this API operation with an Object Lambda access point, provide the alias of the \nObject Lambda access point in place of the bucket name.", "If the Object Lambda access point \nalias in a request is not valid, the error code InvalidAccessPointAliasError  is returned.", "\nFor more information about InvalidAccessPointAliasError , see List of Error Codes.\nRequired: Yes\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match \nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<LocationConstraint > \n   <LocationConstraint >string</LocationConstraint >\n</LocationConstraint >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nAmazon S3 API Version 2006-03-01 228Amazon Simple Storage Service API Reference\nLocationConstraint\nRoot level tag for the LocationConstraint parameters.\nRequired: Yes\nLocationConstraint\nSpeci\ufb01es the Region where the bucket resides. For a list of all the Amazon S3 supported \nlocation constraints by Region, see Regions and Endpoints.", "Buckets in Region us-east-1  have \na LocationConstraint of null .\nType: String\nValid Values: af-south-1 | ap-east-1 | ap-northeast-1 | ap-northeast-2 | ap-\nnortheast-3 | ap-south-1 | ap-south-2 | ap-southeast-1 | ap-southeast-2 \n| ap-southeast-3 | ca-central-1 | cn-north-1 | cn-northwest-1 | EU | eu-\ncentral-1 | eu-north-1 | eu-south-1 | eu-south-2 | eu-west-1 | eu-west-2 \n| eu-west-3 | me-south-1 | sa-east-1 | us-east-2 | us-gov-east-1 | us-\ngov-west-1 | us-west-1 | us-west-2\nExamples\nSample Request\nThe following request returns the Region of the speci\ufb01ed bucket.\n         GET /?location HTTP/1.1 \n         Host: myBucket.s3.amazonaws.com \n         Date: Tue, 09 Oct 2007 20:26:04 +0000 \n         Authorization: signatureValue \n          \nSample Response\nThis example illustrates one usage of GetBucketLocation.\n         <?xml version=\"1.0\" encoding=\"UTF-8\"?> \n         <LocationConstraint xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\">us-\nwest-2</LocationConstraint> \nAmazon S3 API Version 2006-03-01 229Amazon Simple Storage Service API Reference\n         \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 230Amazon Simple Storage Service API Reference\nGetBucketLogging\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nReturns the logging status of a bucket and the permissions users have to view and modify that \nstatus.\nThe following operations are related to GetBucketLogging :\n\u2022CreateBucket\n\u2022PutBucketLogging\nRequest Syntax\nGET /?logging HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe bucket name for which to get the logging information.\nRequired: Yes\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match \nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nRequest Body\nThe request does not have a request body.\nAmazon S3 API Version 2006-03-01 231Amazon Simple Storage Service API Reference\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<BucketLoggingStatus > \n   <LoggingEnabled > \n      <TargetBucket >string</TargetBucket > \n      <TargetGrants > \n         <Grant> \n            < Grantee> \n               < DisplayName >string</DisplayName > \n               < EmailAddress >string</EmailAddress > \n               < ID>string</ID> \n               < xsi:type >string</xsi:type > \n               < URI>string</URI> \n            </ Grantee> \n            < Permission >string</Permission > \n         </Grant> \n      </ TargetGrants > \n      <TargetObjectKeyFormat > \n         < PartitionedPrefix > \n            < PartitionDateSource >string</PartitionDateSource > \n         </ PartitionedPrefix > \n         < SimplePrefix > \n         </ SimplePrefix > \n      </ TargetObjectKeyFormat > \n      <TargetPrefix >string</TargetPrefix > \n   </LoggingEnabled >\n</BucketLoggingStatus >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nBucketLoggingStatus\nRoot level tag for the BucketLoggingStatus parameters.\nRequired: Yes\nAmazon S3 API Version 2006-03-01 232Amazon Simple Storage Service API Reference\nLoggingEnabled\nDescribes where logs are stored and the pre\ufb01x that Amazon S3 assigns to all log object keys for \na bucket. For more information, see PUT Bucket logging in the Amazon S3 API Reference.\nType: LoggingEnabled  data type\nExamples\nSample Request\nThe following request returns the logging status for mybucket .\n            GET ?logging HTTP/1.1 \n            Host: mybucket.s3.<Region>.amazonaws.com \n            Date: Wed, 25 Nov 2009 12:00:00 GMT \n            Authorization: authorization string \n          \nSample Response: Showing an enabled logging status\nThis example illustrates one usage of GetBucketLogging.\n            HTTP/1.1 200 OK \n            Date: Wed, 25 Nov 2009 12:00:00 GMT \n            Connection: close \n            Server: AmazonS3 \n            <?xml version=\"1.0\" encoding=\"UTF-8\"?> \n            <BucketLoggingStatus xmlns=\"http://doc.s3.amazonaws.com/2006-03-01\"> \n             <LoggingEnabled> \n              <TargetBucket>mybucketlogs</TargetBucket> \n              <TargetPrefix>mybucket-access_log-/</TargetPrefix> \n                <TargetGrants> \n                  <Grant> \n                   <Grantee xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" \n                    xsi:type=\"AmazonCustomerByEmail\"> \n                    <EmailAddress>user@company.com</EmailAddress> \n                   </Grantee> \n                   <Permission>READ</Permission> \nAmazon S3 API Version 2006-03-01 233Amazon Simple Storage Service API Reference\n                 </Grant> \n                </TargetGrants> \n            </LoggingEnabled> \n            </BucketLoggingStatus> \n          \nSample Response: Showing a disabled logging status\nThis example illustrates one usage of GetBucketLogging.\n         HTTP/1.1 200 OK \n         Date: Wed, 25 Nov 2009 12:00:00 GMT \n         Connection: close \n         Server: AmazonS3 \n         <?xml version=\"1.0\" encoding=\"UTF-8\"?> \n         <BucketLoggingStatus xmlns=\"http://doc.s3.amazonaws.com/2006-03-01\" /> \n          \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 234Amazon Simple Storage Service API Reference\nGetBucketMetricsCon\ufb01guration\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nGets a metrics con\ufb01guration (speci\ufb01ed by the metrics con\ufb01guration ID) from the bucket.", "Note that \nthis doesn't include the daily storage metrics.\nTo use this operation, you must have permissions to perform the\ns3:GetMetricsConfiguration  action.", "The bucket owner has this permission by default. The \nbucket owner can grant this permission to others.", "For more information about permissions, see\nPermissions Related to Bucket Subresource Operations and Managing Access Permissions to Your \nAmazon S3 Resources.\nFor information about CloudWatch request metrics for Amazon S3, see Monitoring Metrics with \nAmazon CloudWatch.\nThe following operations are related to GetBucketMetricsConfiguration :\n\u2022PutBucketMetricsCon\ufb01guration\n\u2022DeleteBucketMetricsCon\ufb01guration\n\u2022ListBucketMetricsCon\ufb01gurations\n\u2022Monitoring Metrics with Amazon CloudWatch\nRequest Syntax\nGET /?metrics&id= Id HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe name of the bucket containing the metrics con\ufb01guration to retrieve.\nAmazon S3 API Version 2006-03-01 235Amazon Simple Storage Service API Reference\nRequired: Yes\nid\nThe ID used to identify the metrics con\ufb01guration.", "The ID has a 64 character limit and can only \ncontain letters, numbers, periods, dashes, and underscores.\nRequired: Yes\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match \nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<MetricsConfiguration > \n   <Id>string</Id> \n   <Filter> \n      <AccessPointArn >string</AccessPointArn > \n      <And> \n         < AccessPointArn >string</AccessPointArn > \n         < Prefix>string</Prefix> \n         < Tag> \n            < Key>string</Key> \n            < Value>string</Value> \n         </ Tag> \n         ...", "\n      </ And> \n      <Prefix>string</Prefix> \n      <Tag> \n         < Key>string</Key> \n         < Value>string</Value> \n      </ Tag> \n   </Filter>\n</MetricsConfiguration >\nAmazon S3 API Version 2006-03-01 236Amazon Simple Storage Service API Reference\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nMetricsCon\ufb01guration\nRoot level tag for the MetricsCon\ufb01guration parameters.\nRequired: Yes\nFilter\nSpeci\ufb01es a metrics con\ufb01guration \ufb01lter.", "The metrics con\ufb01guration will only include objects \nthat meet the \ufb01lter's criteria. A \ufb01lter must be a pre\ufb01x, an object tag, an access point ARN, or a \nconjunction (MetricsAndOperator).\nType: MetricsFilter  data type\nId\nThe ID used to identify the metrics con\ufb01guration. The ID has a 64 character limit and can only \ncontain letters, numbers, periods, dashes, and underscores.\nType: String\nExamples\nFirst Sample Request\nRetrieve a metrics con\ufb01guration that \ufb01lters metrics based on a speci\ufb01ed pre\ufb01x.\n            GET /?metrics&id=Documents HTTP/1.1 \n            Host: examplebucket.s3.<Region>.amazonaws.com \n            x-amz-date: Thu, 15 Nov 2016 00:17:21 GMT \n            Authorization: signatureValue \n          \nFirst Sample Response\nThis example illustrates one usage of GetBucketMetricsCon\ufb01guration.\nAmazon S3 API Version 2006-03-01 237Amazon Simple Storage Service API Reference\n            HTTP/1.1 200 OK \n            x-amz-id-2: \n ITnGT1y4REXAMPLEPi4hklTXouTf0hccUjo0iCPEXAMPLEutBj3M7fPGlWO2SEWp \n            x-amz-request-id: 51991EXAMPLE5321 \n            Date: Thu, 15 Nov 2016 00:17:22 GMT \n            Server: AmazonS3 \n            Content-Length: 180 \n  \n            <?xml version=\"1.0\" encoding=\"UTF-8\"?> \n            <MetricsConfiguration xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n               <Id>Documents</Id> \n              <Filter> \n                  <Prefix>documents/</Prefix> \n              </Filter> \n            </MetricsConfiguration> \n          \nSecond Sample Request\nRetrieve a metrics con\ufb01guration that enables metrics for objects that start with a particular pre\ufb01x \nand have speci\ufb01c tags applied.\n            GET /?metrics&id=ImportantBlueDocuments HTTP/1.1 \n            Host: examplebucket.s3.<Region>.amazonaws.com \n            x-amz-date: Thu, 15 Nov 2016 00:17:21 GMT \n            Authorization: signatureValue \n          \nSecond Sample Response\nThis example illustrates one usage of GetBucketMetricsCon\ufb01guration.\n            HTTP/1.1 200 OK \n            x-amz-id-2: \n ITnGT1y4REXAMPLEPi4hklTXouTf0hccUjo0iCPEXAMPLEutBj3M7fPGlWO2SEWp \n            x-amz-request-id: 51991EXAMPLE5321 \n            Date: Thu, 15 Nov 2016 00:17:22 GMT \n            Server: AmazonS3 \n            Content-Length: 480 \nAmazon S3 API Version 2006-03-01 238Amazon Simple Storage Service API Reference\n            <?xml version=\"1.0\" encoding=\"UTF-8\"?> \n            <MetricsConfiguration xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n              <Id>ImportantBlueDocuments</Id> \n              <Filter> \n                  <And> \n                      <Prefix>documents/</Prefix> \n                      <Tag> \n                          <Key>priority</Key> \n                          <Value>high</Value> \n                      </Tag> \n                      <Tag> \n                            <Key>class</Key> \n                            <Value>blue</Value> \n                      </Tag> \n                   </And> \n               </Filter> \n            </MetricsConfiguration> \n          \nThird Sample Request\nRetrieve a metrics con\ufb01guration that enables metrics for a speci\ufb01c access point.\n            GET /?metrics&id=ImportantDocumentsAccessPoint HTTP/1.1 \n            Host: examplebucket.s3.<Region>.amazonaws.com \n            x-amz-date: Thu, 26 Aug 2021 00:17:21 GMT \n            Authorization: signatureValue \n          \nThird Sample Response\nThis example illustrates one usage of GetBucketMetricsCon\ufb01guration.\n            HTTP/1.1 200 OK \n            x-amz-id-2: \n ITnGT1y4REXAMPLEPi4hklTXouTf0hccUjo0iCPEXAMPLEutBj3M7fPGlWO2SEWp \n            x-amz-request-id: 51991EXAMPLE5321 \n            Date: Thu, 26 Aug 2021 00:17:22 GMT \n            Server: AmazonS3 \n            Content-Length: 480 \nAmazon S3 API Version 2006-03-01 239Amazon Simple Storage Service API Reference\n            <?xml version=\"1.0\" encoding=\"UTF-8\"?> \n            <MetricsConfiguration xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n              <Id>ImportantDocumentsAccessPoint</Id> \n              <Filter> \n                  <AccessPointArn>arn:aws:s3:us-west-2:123456789012:accesspoint/test</\nAccessPointArn> \n               </Filter> \n            </MetricsConfiguration> \n          \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 240Amazon Simple Storage Service API Reference\nGetBucketNoti\ufb01cation\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nNo longer used, see GetBucketNoti\ufb01cationCon\ufb01guration.\nRequest Syntax\nGET /?notification HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe name of the bucket for which to get the noti\ufb01cation con\ufb01guration.\nWhen you use this API operation with an access point, provide the alias of the access point in \nplace of the bucket name.\nWhen you use this API operation with an Object Lambda access point, provide the alias of the \nObject Lambda access point in place of the bucket name.", "If the Object Lambda access point \nalias in a request is not valid, the error code InvalidAccessPointAliasError  is returned.", "\nFor more information about InvalidAccessPointAliasError , see List of Error Codes.\nRequired: Yes\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match \nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nAmazon S3 API Version 2006-03-01 241Amazon Simple Storage Service API Reference\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<NotificationConfiguration > \n   <TopicConfiguration > \n      <Event>string</Event> \n      <Event>string</Event> \n      ...", "\n      <Id>string</Id> \n      <Topic>string</Topic> \n   </TopicConfiguration > \n   <QueueConfiguration > \n      <Event>string</Event> \n      <Event>string</Event> \n      ... \n      <Id>string</Id> \n      <Queue>string</Queue> \n   </QueueConfiguration > \n   <CloudFunctionConfiguration > \n      <CloudFunction >string</CloudFunction > \n      <Event>string</Event> \n      <Event>string</Event> \n      ... \n      <Id>string</Id> \n      <InvocationRole >string</InvocationRole > \n   </CloudFunctionConfiguration >\n</NotificationConfiguration >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nNoti\ufb01cationCon\ufb01guration\nRoot level tag for the Noti\ufb01cationCon\ufb01guration parameters.\nRequired: Yes\nAmazon S3 API Version 2006-03-01 242Amazon Simple Storage Service API Reference\nCloudFunctionCon\ufb01guration\nContainer for specifying the AWS Lambda noti\ufb01cation con\ufb01guration.\nType: CloudFunctionCon\ufb01guration data type\nQueueCon\ufb01guration\nThis data type is deprecated. This data type speci\ufb01es the con\ufb01guration for publishing messages \nto an Amazon Simple Queue Service (Amazon SQS) queue when Amazon S3 detects speci\ufb01ed \nevents.\nType: QueueCon\ufb01gurationDeprecated data type\nTopicCon\ufb01guration\nThis data type is deprecated. A container for specifying the con\ufb01guration for publication of \nmessages to an Amazon Simple Noti\ufb01cation Service (Amazon SNS) topic when Amazon S3 \ndetects speci\ufb01ed events.\nType: TopicCon\ufb01gurationDeprecated data type\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 243Amazon Simple Storage Service API Reference\nGetBucketNoti\ufb01cationCon\ufb01guration\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nReturns the noti\ufb01cation con\ufb01guration of a bucket.\nIf noti\ufb01cations are not enabled on the bucket, the action returns an empty\nNotificationConfiguration  element.\nBy default, you must be the bucket owner to read the noti\ufb01cation con\ufb01guration of a bucket. \nHowever, the bucket owner can use a bucket policy to grant permission to other users to read this \ncon\ufb01guration with the s3:GetBucketNotification  permission.\nWhen you use this API operation with an access point, provide the alias of the access point in place \nof the bucket name.\nWhen you use this API operation with an Object Lambda access point, provide the alias of the \nObject Lambda access point in place of the bucket name.", "If the Object Lambda access point alias \nin a request is not valid, the error code InvalidAccessPointAliasError  is returned.", "For more \ninformation about InvalidAccessPointAliasError , see List of Error Codes.\nFor more information about setting and reading the noti\ufb01cation con\ufb01guration on a bucket, see\nSetting Up Noti\ufb01cation of Bucket Events. For more information about bucket policies, see Using \nBucket Policies.\nThe following action is related to GetBucketNotification :\n\u2022PutBucketNoti\ufb01cation\nRequest Syntax\nGET /?notification HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nAmazon S3 API Version 2006-03-01 244Amazon Simple Storage Service API Reference\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe name of the bucket for which to get the noti\ufb01cation con\ufb01guration.\nWhen you use this API operation with an access point, provide the alias of the access point in \nplace of the bucket name.\nWhen you use this API operation with an Object Lambda access point, provide the alias of the \nObject Lambda access point in place of the bucket name.", "If the Object Lambda access point \nalias in a request is not valid, the error code InvalidAccessPointAliasError  is returned.", "\nFor more information about InvalidAccessPointAliasError , see List of Error Codes.\nRequired: Yes\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match \nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<NotificationConfiguration > \n   <TopicConfiguration > \n      <Event>string</Event> \n      ...", "\n      <Filter> \n         < S3Key> \n            < FilterRule > \n               < Name>string</Name> \n               < Value>string</Value> \n            </ FilterRule > \n            ...", "\nAmazon S3 API Version 2006-03-01 245Amazon Simple Storage Service API Reference\n         </ S3Key> \n      </ Filter> \n      <Id>string</Id> \n      <Topic>string</Topic> \n   </TopicConfiguration > \n   ...", "\n   <QueueConfiguration > \n      <Event>string</Event> \n      ...", "\n      <Filter> \n         < S3Key> \n            < FilterRule > \n               < Name>string</Name> \n               < Value>string</Value> \n            </ FilterRule > \n            ... \n         </ S3Key> \n      </ Filter> \n      <Id>string</Id> \n      <Queue>string</Queue> \n   </QueueConfiguration > \n   ...", "\n   <CloudFunctionConfiguration > \n      <Event>string</Event> \n      ...", "\n      <Filter> \n         < S3Key> \n            < FilterRule > \n               < Name>string</Name> \n               < Value>string</Value> \n            </ FilterRule > \n            ... \n         </ S3Key> \n      </ Filter> \n      <Id>string</Id> \n      <CloudFunction >string</CloudFunction > \n   </CloudFunctionConfiguration > \n   ... \n   <EventBridgeConfiguration > \n   </EventBridgeConfiguration >\n</NotificationConfiguration >\nAmazon S3 API Version 2006-03-01 246Amazon Simple Storage Service API Reference\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nNoti\ufb01cationCon\ufb01guration\nRoot level tag for the Noti\ufb01cationCon\ufb01guration parameters.\nRequired: Yes\nCloudFunctionCon\ufb01guration\nDescribes the AWS Lambda functions to invoke and the events for which to invoke them.\nType: Array of LambdaFunctionCon\ufb01guration data types\nEventBridgeCon\ufb01guration\nEnables delivery of events to Amazon EventBridge.\nType: EventBridgeCon\ufb01guration data type\nQueueCon\ufb01guration\nThe Amazon Simple Queue Service queues to publish messages to and the events for which to \npublish messages.\nType: Array of QueueCon\ufb01guration  data types\nTopicCon\ufb01guration\nThe topic to which noti\ufb01cations are sent and the events for which noti\ufb01cations are generated.\nType: Array of TopicCon\ufb01guration data types\nExamples\nSample Request\nThis request returns the noti\ufb01cation con\ufb01guration on the bucket\nquotes.s3.<Region>.amazonaws.com .\nAmazon S3 API Version 2006-03-01 247Amazon Simple Storage Service API Reference\n            GET ?notification HTTP/1.1  \n            Host: quotes.s3.<Region>.amazonaws.com \n            Date: Wed, 15 Oct 2014 16:59:03 GMT \n            Authorization: authorization string \n          \nSample Response\nThis response returns that the noti\ufb01cation con\ufb01guration for the speci\ufb01ed bucket.\n            HTTP/1.1 200 OK \n            x-amz-id-2: YgIPIfBiKa2bj0KMgUAdQkf3ShJTOOpXUueF6QKo \n            x-amz-request-id: 236A8905248E5A02 \n            Date: Wed, 15 Oct 2014 16:59:04 GMT \n            Server: AmazonS3 \n            <?xml version=\"1.0\" encoding=\"UTF-8\"?> \n            <NotificationConfiguration xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n             <TopicConfiguration> \n               <Id>YjVkM2Y0YmUtNGI3NC00ZjQyLWEwNGItNDIyYWUxY2I0N2M4</Id> \n              <Topic>arn:aws:sns:us-east-1:account-id:s3notificationtopic2</Topic> \n              <Event>s3:ReducedRedundancyLostObject</Event> \n              <Event>s3:ObjectCreated:*</Event> \n             </TopicConfiguration> \n            </NotificationConfiguration> \n          \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\nAmazon S3 API Version 2006-03-01 248Amazon Simple Storage Service API Reference\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 249Amazon Simple Storage Service API Reference\nGetBucketOwnershipControls\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nRetrieves OwnershipControls  for an Amazon S3 bucket.", "To use this operation, you must have \nthe s3:GetBucketOwnershipControls  permission. For more information about Amazon S3 \npermissions, see Specifying permissions in a policy.\nFor information about Amazon S3 Object Ownership, see Using Object Ownership.\nThe following operations are related to GetBucketOwnershipControls :\n\u2022PutBucketOwnershipControls\n\u2022DeleteBucketOwnershipControls\nRequest Syntax\nGET /?ownershipControls HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe name of the Amazon S3 bucket whose OwnershipControls  you want to retrieve.\nRequired: Yes\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match \nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nAmazon S3 API Version 2006-03-01 250Amazon Simple Storage Service API Reference\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<OwnershipControls > \n   <Rule> \n      <ObjectOwnership >string</ObjectOwnership > \n   </Rule> \n   ...\n</OwnershipControls >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nOwnershipControls\nRoot level tag for the OwnershipControls parameters.\nRequired: Yes\nRule\nThe container element for an ownership control rule.\nType: Array of OwnershipControlsRule data types\nExamples\nSample GetBucketOwnershipControls Request for BucketOwnerEnforced\nThis example illustrates one usage of GetBucketOwnershipControls.\n          GET /amzn-s3-demo-bucket?/ownershipControls HTTP/1.1 \n          Host: amzn-s3-demo-bucket.s3.<Region>.amazonaws.com \n          Date: Mon, 29 Nov 2021 00:17:22 GMT \nAmazon S3 API Version 2006-03-01 251Amazon Simple Storage Service API Reference\n          Authorization: signatureValue; \n         \nSample GetBucketOwnershipControls Response\nThis example illustrates one usage of GetBucketOwnershipControls.\n          HTTP/1.1 200 OK \n          x-amz-id-2: Adphn7MaAHDEg9mh5JmcTN8mzyVX0JhIztSiQNaqTxnXXcYi4uiZbYdwWC3JXmh/\nXXVUUQwO4Vs= \n          x-amz-request-id: 252631E05F84A415 \n          Date: Mon, 29 Nov 2021 00:17:22 GMT \n          Server: AmazonS3 \n          Content-Length: 194 \n          <OwnershipControls xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n            <Rule> \n              <ObjectOwnership>BucketOwnerEnforced</ObjectOwnership> \n            </Rule> \n          </OwnershipControls> \n         \nSample GetBucketOwnershipControls Request for BucketOwnerPreferred\nThis example illustrates one usage of GetBucketOwnershipControls.\n          GET /amzn-s3-demo-bucket?/ownershipControls HTTP/1.1 \n          Host: amzn-s3-demo-bucket.s3.<Region>.amazonaws.com \n          Date: Thu, 18 Jun 2017 00:17:22 GMT \n          Authorization: signatureValue; \n         \nSample GetBucketOwnershipControls Response\nThis example illustrates one usage of GetBucketOwnershipControls.\n          HTTP/1.1 200 OK \n          x-amz-id-2: Adphn7MaAHDEg9mh5JmcTN8mzyVX0JhIztSiQNaqTxnXXcYi4uiZbYdwWC3JXmh/\nXXVUUQwO4Vs= \nAmazon S3 API Version 2006-03-01 252Amazon Simple Storage Service API Reference\n          x-amz-request-id: 252631E05F84A415 \n          Date: Thu, 18 Jun 2020 00:17:22 GMT \n          Server: AmazonS3 \n          Content-Length: 194 \n          <OwnershipControls xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n            <Rule> \n              <ObjectOwnership>BucketOwnerPreferred</ObjectOwnership> \n            </Rule> \n          </OwnershipControls> \n         \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 253Amazon Simple Storage Service API Reference\nGetBucketPolicy\nService: Amazon S3\nReturns the policy of a speci\ufb01ed bucket.\nNote\nDirectory buckets  - For directory buckets, you must make requests for this API operation \nto the Regional endpoint.", "These endpoints support path-style requests in the format\nhttps://s3express-control.", "region_code .amazonaws.com/ bucket-name  .", "\nVirtual-hosted-style requests aren't supported.", "For more information, see Regional and \nZonal endpoints in the Amazon S3 User Guide .\nPermissions\nIf you are using an identity other than the root user of the AWS account that owns the bucket, \nthe calling identity must both have the GetBucketPolicy  permissions on the speci\ufb01ed bucket \nand belong to the bucket owner's account in order to use this operation.\nIf you don't have GetBucketPolicy  permissions, Amazon S3 returns a 403 Access Denied\nerror. If you have the correct permissions, but you're not using an identity that belongs to the \nbucket owner's account, Amazon S3 returns a 405 Method Not Allowed  error.\nImportant\nTo ensure that bucket owners don't inadvertently lock themselves out of their \nown buckets, the root principal in a bucket owner's AWS account can perform the\nGetBucketPolicy , PutBucketPolicy , and DeleteBucketPolicy  API actions, \neven if their bucket policy explicitly denies the root principal's access. Bucket owner \nroot principals can only be blocked from performing these API actions by VPC endpoint \npolicies and AWS Organizations policies.\n\u2022General purpose bucket permissions - The s3:GetBucketPolicy  permission is required \nin a policy. For more information about general purpose buckets bucket policies, see Using \nBucket Policies and User Policies in the Amazon S3 User Guide .\n\u2022Directory bucket permissions - To grant access to this API operation, you must have the\ns3express:GetBucketPolicy  permission in an IAM identity-based policy instead of a \nAmazon S3 API Version 2006-03-01 254Amazon Simple Storage Service API Reference\nbucket policy.", "Cross-account access to this API operation isn't supported.", "This operation can \nonly be performed by the AWS account that owns the resource.", "For more information about \ndirectory bucket policies and permissions, see AWS Identity and Access Management (IAM) for \nS3 Express One Zone in the Amazon S3 User Guide .\nExample bucket policies\nGeneral purpose buckets example bucket policies - See Bucket policy examples in the Amazon \nS3 User Guide .\nDirectory bucket example bucket policies - See Example bucket policies for S3 Express One \nZone in the Amazon S3 User Guide .\nHTTP Host header syntax\nDirectory buckets  - The HTTP Host header syntax is s3express-\ncontrol. region.amazonaws.com .\nThe following action is related to GetBucketPolicy :\n\u2022GetObject\nRequest Syntax\nGET /?policy HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe bucket name to get the bucket policy for.\nDirectory buckets  - When you use this operation with a directory bucket, \nyou must use path-style requests in the format https://s3express-\ncontrol. region_code .amazonaws.com/ bucket-name  .", "Virtual-hosted-style requests \naren't supported.", "Directory bucket names must be unique in the chosen Availability Zone.", "\nBucket names must also follow the format  bucket_base_name --az_id--x-s3  (for \nAmazon S3 API Version 2006-03-01 255Amazon Simple Storage Service API Reference\nexample,  DOC-EXAMPLE-BUCKET --usw2-az1 --x-s3). For information about bucket naming \nrestrictions, see Directory bucket naming rules in the Amazon S3 User Guide\nAccess points - When you use this API operation with an access point, provide the alias of the \naccess point in place of the bucket name.\nObject Lambda access points - When you use this API operation with an Object \nLambda access point, provide the alias of the Object Lambda access point in place of \nthe bucket name.", "If the Object Lambda access point alias in a request is not valid, the \nerror code InvalidAccessPointAliasError  is returned. For more information about\nInvalidAccessPointAliasError , see List of Error Codes.\nNote\nAccess points and Object Lambda access points are not supported by directory buckets.\nRequired: Yes\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match \nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nNote\nFor directory buckets, this header is not supported in this API operation. If you specify \nthis header, the request fails with the HTTP status code 501 Not Implemented .\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n{ Policy in JSON format  }\nAmazon S3 API Version 2006-03-01 256Amazon Simple Storage Service API Reference\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in JSON format by the service.\n<varlistentry>   Policy   </varlistentry>\nExamples\nSample Request for general purpose buckets\nThe following request returns the policy of the speci\ufb01ed bucket.\n           GET ?policy HTTP/1.1 \n           Host: bucket.s3.<Region>.amazonaws.com \n           Date: Wed, 28 Oct 2009 22:32:00 GMT \n           Authorization: authorization string \n          \nSample Response for general purpose buckets\nThis example illustrates one usage of GetBucketPolicy.\n            HTTP/1.1 200 OK   \n            x-amz-id-2: Uuag1LuByru9pO4SAMPLEAtRPfTaOFg==   \n            x-amz-request-id: 656c76696e67SAMPLE57374   \n            Date: Tue, 04 Apr 2010 20:34:56 GMT   \n            Connection: keep-alive   \n            Server: AmazonS3     \n            { \n            \"Version\":\"2008-10-17\", \n            \"Id\":\"aaaa-bbbb-cccc-dddd\", \n            \"Statement\" : [ \n                { \n                    \"Effect\":\"Deny\", \n                    \"Sid\":\"1\",  \n                    \"Principal\" : { \n                       \"AWS\":[\"111122223333\",\"444455556666\"] \n                    }, \nAmazon S3 API Version 2006-03-01 257Amazon Simple Storage Service API Reference\n                    \"Action\":[\"s3:*\"], \n                    \"Resource\":\"arn:aws:s3:::bucket/*\" \n                } \n             ]  \n            } \n          \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 258Amazon Simple Storage Service API Reference\nGetBucketPolicyStatus\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nRetrieves the policy status for an Amazon S3 bucket, indicating whether the bucket is public.", "In \norder to use this operation, you must have the s3:GetBucketPolicyStatus  permission. For \nmore information about Amazon S3 permissions, see Specifying Permissions in a Policy.\nFor more information about when Amazon S3 considers a bucket public, see The Meaning of \n\"Public\".\nThe following operations are related to GetBucketPolicyStatus :\n\u2022Using Amazon S3 Block Public Access\n\u2022GetPublicAccessBlock\n\u2022PutPublicAccessBlock\n\u2022DeletePublicAccessBlock\nRequest Syntax\nGET /?policyStatus HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe name of the Amazon S3 bucket whose policy status you want to retrieve.\nRequired: Yes\nAmazon S3 API Version 2006-03-01 259Amazon Simple Storage Service API Reference\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match \nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<PolicyStatus > \n   <IsPublic >boolean</IsPublic >\n</PolicyStatus >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nPolicyStatus\nRoot level tag for the PolicyStatus parameters.\nRequired: Yes\nIsPublic\nThe policy status for this bucket.", "TRUE indicates that this bucket is public.", "FALSE  indicates that \nthe bucket is not public.\nType: Boolean\nExamples\nSample Request\nThe following request gets a bucket policy status.\nAmazon S3 API Version 2006-03-01 260Amazon Simple Storage Service API Reference\n            GET /<bucket-name>?policyStatus HTTP/1.1 \n            Host: <bucket-name>.s3.<Region>.amazonaws.com \n            x-amz-date: <Thu, 15 Nov 2016 00:17:21 GMT> \n            Authorization: <signatureValue> \n          \nSample Response\nThis example illustrates one usage of GetBucketPolicyStatus.\n            HTTP/1.1 200 OK \n            x-amz-id-2: \n ITnGT1y4REXAMPLEPi4hklTXouTf0hccUjo0iCPEXAMPLEutBj3M7fPGlWO2SEWp \n            x-amz-request-id: 51991EXAMPLE5321 \n            Date: Thu, 15 Nov 2016 00:17:22 GMT \n            Server: AmazonS3 \n            Content-Length: 0 \n            <PolicyStatus> \n               <IsPublic>TRUE</IsPublic>  \n            </PolicyStatus> \n          \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\nAmazon S3 API Version 2006-03-01 261Amazon Simple Storage Service API Reference\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 262Amazon Simple Storage Service API Reference\nGetBucketReplication\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nReturns the replication con\ufb01guration of a bucket.\nNote\nIt can take a while to propagate the put or delete a replication con\ufb01guration to all Amazon \nS3 systems. Therefore, a get request soon after put or delete can return a wrong result.\nFor information about replication con\ufb01guration, see Replication in the Amazon S3 User Guide .\nThis action requires permissions for the s3:GetReplicationConfiguration  action.", "For more \ninformation about permissions, see Using Bucket Policies and User Policies.\nIf you include the Filter element in a replication con\ufb01guration, you must also include the\nDeleteMarkerReplication  and Priority  elements. The response also returns those elements.\nFor information about GetBucketReplication  errors, see List of replication-related error codes\nThe following operations are related to GetBucketReplication :\n\u2022PutBucketReplication\n\u2022DeleteBucketReplication\nRequest Syntax\nGET /?replication HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nURI Request Parameters\nThe request uses the following URI parameters.\nAmazon S3 API Version 2006-03-01 263Amazon Simple Storage Service API Reference\nBucket\nThe bucket name for which to get the replication information.\nRequired: Yes\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match \nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<ReplicationConfiguration > \n   <Role>string</Role> \n   <Rule> \n      <DeleteMarkerReplication > \n         < Status>string</Status> \n      </ DeleteMarkerReplication > \n      <Destination > \n         < AccessControlTranslation > \n            < Owner>string</Owner> \n         </ AccessControlTranslation > \n         < Account>string</Account> \n         < Bucket>string</Bucket> \n         < EncryptionConfiguration > \n            < ReplicaKmsKeyID >string</ReplicaKmsKeyID > \n         </ EncryptionConfiguration > \n         < Metrics> \n            < EventThreshold > \n               < Minutes>integer</Minutes> \n            </ EventThreshold > \n            < Status>string</Status> \n         </ Metrics> \n         < ReplicationTime > \n            < Status>string</Status> \n            < Time> \nAmazon S3 API Version 2006-03-01 264Amazon Simple Storage Service API Reference\n               < Minutes>integer</Minutes> \n            </ Time> \n         </ ReplicationTime > \n         < StorageClass >string</StorageClass > \n      </ Destination > \n      <ExistingObjectReplication > \n         < Status>string</Status> \n      </ ExistingObjectReplication > \n      <Filter> \n         < And> \n            < Prefix>string</Prefix> \n            < Tag> \n               < Key>string</Key> \n               < Value>string</Value> \n            </ Tag> \n            ... \n         </ And> \n         < Prefix>string</Prefix> \n         < Tag> \n            < Key>string</Key> \n            < Value>string</Value> \n         </ Tag> \n      </ Filter> \n      <ID>string</ID> \n      <Prefix>string</Prefix> \n      <Priority >integer</Priority > \n      <SourceSelectionCriteria > \n         < ReplicaModifications > \n            < Status>string</Status> \n         </ ReplicaModifications > \n         < SseKmsEncryptedObjects > \n            < Status>string</Status> \n         </ SseKmsEncryptedObjects > \n      </ SourceSelectionCriteria > \n      <Status>string</Status> \n   </Rule> \n   ...\n</ReplicationConfiguration >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nAmazon S3 API Version 2006-03-01 265Amazon Simple Storage Service API Reference\nReplicationCon\ufb01guration\nRoot level tag for the ReplicationCon\ufb01guration parameters.\nRequired: Yes\nRole\nThe Amazon Resource Name (ARN) of the AWS Identity and Access Management (IAM) role \nthat Amazon S3 assumes when replicating objects. For more information, see How to Set Up \nReplication in the Amazon S3 User Guide .\nType: String\nRule\nA container for one or more replication rules. A replication con\ufb01guration must have at least one \nrule and can contain a maximum of 1,000 rules.\nType: Array of ReplicationRule data types\nExamples\nSample Request: Retrieve replication con\ufb01guration information\nThe following GET request retrieves information about the replication con\ufb01guration set for the\nexamplebucket  bucket:\n            GET /?replication HTTP/1.1 \n            Host: examplebucket.s3.<Region>.amazonaws.com \n            Date: Tue, 10 Feb 2015 00:17:21 GMT \n            Authorization: authorization string \n          \nSample Response\nThe following response shows that replication is enabled on the bucket. The empty pre\ufb01x indicates \nthat Amazon S3 will replicate all objects that are created in the examplebucket  bucket. The\nDestination  element identi\ufb01es the target bucket where Amazon S3 creates the object replicas, \nand the storage class (STANDARD_IA) that Amazon S3 uses when creating replicas.\nAmazon S3 API Version 2006-03-01 266Amazon Simple Storage Service API Reference\nAmazon S3 assumes the speci\ufb01ed IAM role to replicate objects on behalf of the bucket owner, \nwhich is the AWS account that created the bucket.\n            HTTP/1.1 200 OK \n            x-amz-id-2: \n ITnGT1y4RyTmXa3rPi4hklTXouTf0hccUjo0iCPjz6FnfIutBj3M7fPGlWO2SEWp \n            x-amz-request-id: 51991C342example \n            Date: Tue, 10 Feb 2015 00:17:23 GMT \n            Server: AmazonS3 \n            Content-Length: contentlength \n            <?xml version=\"1.0\" encoding=\"UTF-8\"?> \n            <ReplicationConfiguration> \n              <Role>arn:aws:iam::35667example:role/CrossRegionReplicationRoleForS3</\nRole> \n             <Rule> \n               <ID>rule1</ID> \n               <Status>Enabled</Status> \n               <Priority>1</Priority> \n               <DeleteMarkerReplication> \n                   <Status>Disabled</Status> \n               </DeleteMarkerReplication> \n               <Filter> \n                  <And> \n                       <Prefix>TaxDocs</Prefix> \n                       <Tag> \n                         <Key>key1</Key> \n                         <Value>value1</Value> \n                       </Tag> \n                       <Tag> \n                         <Key>key1</Key> \n                        <Value>value1</Value> \n                      </Tag> \n                  </And> \n                </Filter> \n               <Destination> \n                  <Bucket>arn:aws:s3:::exampletargetbucket</Bucket> \n               </Destination> \n              </Rule> \n            </ReplicationConfiguration> \n          \nAmazon S3 API Version 2006-03-01 267Amazon Simple Storage Service API Reference\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 268Amazon Simple Storage Service API Reference\nGetBucketRequestPayment\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nReturns the request payment con\ufb01guration of a bucket. To use this version of the operation, you \nmust be the bucket owner. For more information, see Requester Pays Buckets.\nThe following operations are related to GetBucketRequestPayment :\n\u2022ListObjects\nRequest Syntax\nGET /?requestPayment HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe name of the bucket for which to get the payment request con\ufb01guration\nRequired: Yes\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match \nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nRequest Body\nThe request does not have a request body.\nAmazon S3 API Version 2006-03-01 269Amazon Simple Storage Service API Reference\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<RequestPaymentConfiguration > \n   <Payer>string</Payer>\n</RequestPaymentConfiguration >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nRequestPaymentCon\ufb01guration\nRoot level tag for the RequestPaymentCon\ufb01guration parameters.\nRequired: Yes\nPayer\nSpeci\ufb01es who pays for the download and request fees.\nType: String\nValid Values: Requester | BucketOwner\nExamples\nSample Request\nThe following request returns the payer for the bucket, colorpictures .\n            GET ?requestPayment HTTP/1.1 \n            Host: colorpictures.s3.<Region>.amazonaws.com \n            Date: Wed, 01 Mar 2009 12:00:00 GMT \n            Authorization: authorization string \n          \nAmazon S3 API Version 2006-03-01 270Amazon Simple Storage Service API Reference\nSample Response\nThis response shows that the bucket is a Requester Pays bucket, meaning the person requesting a \ndownload from this bucket pays the transfer fees.\n            HTTP/1.1 200 OK \n            x-amz-id-2: \n YgIPIfBiKa2bj0KMg95r/0zo3emzU4dzsD4rcKCHQUAdQkf3ShJTOOpXUueF6QKo \n            x-amz-request-id: 236A8905248E5A01 \n            Date: Wed, 01 Mar 2009 12:00:00 GMT \n            Content-Type: [type] \n            Content-Length: 0 \n            Connection: close \n            Server: AmazonS3 \n            <?xml version=\"1.0\" encoding=\"UTF-8\"?> \n            <RequestPaymentConfiguration xmlns=\"http://s3.amazonaws.com/\ndoc/2006-03-01/\"> \n              <Payer>Requester</Payer> \n            </RequestPaymentConfiguration> \n          \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 271Amazon Simple Storage Service API Reference\nGetBucketTagging\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nReturns the tag set associated with the bucket.\nTo use this operation, you must have permission to perform the s3:GetBucketTagging  action. \nBy default, the bucket owner has this permission and can grant this permission to others.\nGetBucketTagging  has the following special error:\n\u2022Error code: NoSuchTagSet\n\u2022Description: There is no tag set associated with the bucket.\nThe following operations are related to GetBucketTagging :\n\u2022PutBucketTagging\n\u2022DeleteBucketTagging\nRequest Syntax\nGET /?tagging HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe name of the bucket for which to get the tagging information.\nRequired: Yes\nAmazon S3 API Version 2006-03-01 272Amazon Simple Storage Service API Reference\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match \nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<Tagging> \n   <TagSet> \n      <Tag> \n         < Key>string</Key> \n         < Value>string</Value> \n      </Tag> \n   </TagSet>\n</Tagging>\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nTagging\nRoot level tag for the Tagging parameters.\nRequired: Yes\nTagSet\nContains the tag set.\nType: Array of Tag data types\nAmazon S3 API Version 2006-03-01 273Amazon Simple Storage Service API Reference\nExamples\nSample Request\nThe following request returns the tag set of the speci\ufb01ed bucket.\n            GET ?tagging HTTP/1.1 \n            Host: bucket.s3.<Region>.amazonaws.com \n            Date: Wed, 28 Oct 2009 22:32:00 GMT \n            Authorization: authorization string \n          \nSample Response\nDelete the metric con\ufb01guration with a speci\ufb01ed ID, which disables the CloudWatch metrics with the\nExampleMetrics  value for the FilterId  dimension.\n         HTTP/1.1 200 OK \n         Date: Wed, 25 Nov 2009 12:00:00 GMT \n         Connection: close \n         Server: AmazonS3 \n         <Tagging> \n           <TagSet> \n              <Tag> \n                <Key>Project</Key> \n               <Value>Project One</Value> \n              </Tag> \n              <Tag> \n                <Key>User</Key> \n                <Value>jsmith</Value> \n              </Tag> \n           </TagSet> \n         </Tagging>  \n          \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\nAmazon S3 API Version 2006-03-01 274Amazon Simple Storage Service API Reference\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 275Amazon Simple Storage Service API Reference\nGetBucketVersioning\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nReturns the versioning state of a bucket.\nTo retrieve the versioning state of a bucket, you must be the bucket owner.\nThis implementation also returns the MFA Delete status of the versioning state. If the MFA Delete \nstatus is enabled, the bucket owner must use an authentication device to change the versioning \nstate of the bucket.\nThe following operations are related to GetBucketVersioning :\n\u2022GetObject\n\u2022PutObject\n\u2022DeleteObject\nRequest Syntax\nGET /?versioning HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe name of the bucket for which to get the versioning information.\nRequired: Yes\nAmazon S3 API Version 2006-03-01 276Amazon Simple Storage Service API Reference\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match \nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<VersioningConfiguration > \n   <Status>string</Status> \n   <MfaDelete >string</MfaDelete >\n</VersioningConfiguration >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nVersioningCon\ufb01guration\nRoot level tag for the VersioningCon\ufb01guration parameters.\nRequired: Yes\nMFADelete\nSpeci\ufb01es whether MFA delete is enabled in the bucket versioning con\ufb01guration. This element is \nonly returned if the bucket has been con\ufb01gured with MFA delete. If the bucket has never been \nso con\ufb01gured, this element is not returned.\nType: String\nValid Values: Enabled | Disabled\nStatus\nThe versioning state of the bucket.\nAmazon S3 API Version 2006-03-01 277Amazon Simple Storage Service API Reference\nType: String\nValid Values: Enabled | Suspended\nExamples\nExample\nThis example returns the versioning state of myBucket .\n         GET /?versioning HTTP/1.1 \n         Host: myBucket.s3.<Region>.amazonaws.com \n         Date: Wed, 12 Oct 2009 17:50:00 GMT \n         Authorization: authorization string \n         Content-Type: text/plain \n         \nExample\nThere are three versioning states:\nIf you enabled versioning on a bucket, the response is:\n     <VersioningConfiguration xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n        <Status>Enabled</Status> \n     </VersioningConfiguration> \n         \nExample\nIf you suspended versioning on a bucket, the response is:\n     <VersioningConfiguration xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n        <Status>Suspended</Status> \n     </VersioningConfiguration> \n      \nExample\nIf you never enabled (or suspended) versioning on a bucket, the response is:\nAmazon S3 API Version 2006-03-01 278Amazon Simple Storage Service API Reference\n     <VersioningConfiguration xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"/> \n      \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 279Amazon Simple Storage Service API Reference\nGetBucketWebsite\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nReturns the website con\ufb01guration for a bucket. To host website on Amazon S3, you can con\ufb01gure a \nbucket as website by adding a website con\ufb01guration. For more information about hosting websites, \nsee Hosting Websites on Amazon S3.\nThis GET action requires the S3:GetBucketWebsite  permission.", "By default, only the \nbucket owner can read the bucket website con\ufb01guration. However, bucket owners can allow \nother users to read the website con\ufb01guration by writing a bucket policy granting them the\nS3:GetBucketWebsite  permission.\nThe following operations are related to GetBucketWebsite :\n\u2022DeleteBucketWebsite\n\u2022PutBucketWebsite\nRequest Syntax\nGET /?website HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe bucket name for which to get the website con\ufb01guration.\nRequired: Yes\nAmazon S3 API Version 2006-03-01 280Amazon Simple Storage Service API Reference\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match \nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<WebsiteConfiguration > \n   <RedirectAllRequestsTo > \n      <HostName >string</HostName > \n      <Protocol >string</Protocol > \n   </RedirectAllRequestsTo > \n   <IndexDocument > \n      <Suffix>string</Suffix> \n   </IndexDocument > \n   <ErrorDocument > \n      <Key>string</Key> \n   </ErrorDocument > \n   <RoutingRules > \n      <RoutingRule> \n         < Condition > \n            < HttpErrorCodeReturnedEquals >string</HttpErrorCodeReturnedEquals > \n            < KeyPrefixEquals >string</KeyPrefixEquals > \n         </ Condition > \n         < Redirect > \n            < HostName >string</HostName > \n            < HttpRedirectCode >string</HttpRedirectCode > \n            < Protocol >string</Protocol > \n            < ReplaceKeyPrefixWith >string</ReplaceKeyPrefixWith > \n            < ReplaceKeyWith >string</ReplaceKeyWith > \n         </ Redirect > \n      </RoutingRule> \n   </RoutingRules >\n</WebsiteConfiguration >\nAmazon S3 API Version 2006-03-01 281Amazon Simple Storage Service API Reference\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nWebsiteCon\ufb01guration\nRoot level tag for the WebsiteCon\ufb01guration parameters.\nRequired: Yes\nErrorDocument\nThe object key name of the website error document to use for 4XX class errors.\nType: ErrorDocument data type\nIndexDocument\nThe name of the index document for the website (for example index.html ).\nType: IndexDocument  data type\nRedirectAllRequestsTo\nSpeci\ufb01es the redirect behavior of all requests to a website endpoint of an Amazon S3 bucket.\nType: RedirectAllRequestsTo data type\nRoutingRules\nRules that de\ufb01ne when a redirect is applied and the redirect behavior.\nType: Array of RoutingRule data types\nExamples\nSample Request\nThis request retrieves website con\ufb01guration on the speci\ufb01ed bucket.\n            GET ?website HTTP/1.1 \n            Host: example-bucket.s3.<Region>.amazonaws.com \n            Date: Thu, 27 Jan 2011 00:49:20 GMT \nAmazon S3 API Version 2006-03-01 282Amazon Simple Storage Service API Reference\n            Authorization: AWS AKIAIOSFODNN7EXAMPLE:n0Nhek72Ufg/u7Sm5C1dqRLs8XX= \n          \n          \nSample Response\nThis example illustrates one usage of GetBucketWebsite.\n         HTTP/1.1 200 OK \n         x-amz-id-2: YgIPIfBiKa2bj0KMgUAdQkf3ShJTOOpXUueF6QKo \n         x-amz-request-id: 3848CD259D811111 \n         Date: Thu, 27 Jan 2011 00:49:26 GMT \n         Content-Length: 240 \n         Content-Type: application/xml \n         Transfer-Encoding: chunked \n         Server: AmazonS3 \n         <?xml version=\"1.0\" encoding=\"UTF-8\"?> \n         <WebsiteConfiguration xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n           <IndexDocument> \n             <Suffix>index.html</Suffix> \n           </IndexDocument> \n          <ErrorDocument> \n            <Key>404.html</Key> \n          </ErrorDocument> \n         </WebsiteConfiguration> \n          \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\nAmazon S3 API Version 2006-03-01 283Amazon Simple Storage Service API Reference\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 284Amazon Simple Storage Service API Reference\nGetObject\nService: Amazon S3\nRetrieves an object from Amazon S3.\nIn the GetObject  request, specify the full key name for the object.\nGeneral purpose buckets - Both the virtual-hosted-style requests and the path-style requests \nare supported.", "For a virtual hosted-style request example, if you have the object photos/2006/\nFebruary/sample.jpg , specify the object key name as /photos/2006/February/\nsample.jpg . For a path-style request example, if you have the object photos/2006/\nFebruary/sample.jpg  in the bucket named examplebucket , specify the object key name as /\nexamplebucket/photos/2006/February/sample.jpg .", "For more information about request \ntypes, see HTTP Host Header Bucket Speci\ufb01cation in the Amazon S3 User Guide .\nDirectory buckets - Only virtual-hosted-style requests are supported.", "For a virtual hosted-style \nrequest example, if you have the object photos/2006/February/sample.jpg  in the bucket \nnamed examplebucket--use1-az5--x-s3 , specify the object key name as /photos/2006/\nFebruary/sample.jpg .", "Also, when you make requests to this API operation, your requests are \nsent to the Zonal endpoint.", "These endpoints support virtual-hosted-style requests in the format\nhttps:// bucket_name .s3express- az_id.region.amazonaws.com/ key-name  .", "Path-\nstyle requests are not supported.", "For more information, see Regional and Zonal endpoints in the\nAmazon S3 User Guide .\nPermissions\n\u2022General purpose bucket permissions - You must have the required permissions in a policy.", "To \nuse GetObject , you must have the READ access to the object (or version). If you grant READ\naccess to the anonymous user, the GetObject  operation returns the object without using \nan authorization header.", "For more information, see Specifying permissions in a policy in the\nAmazon S3 User Guide .\nIf you include a versionId  in your request header, you must have the\ns3:GetObjectVersion  permission to access a speci\ufb01c version of an object. The\ns3:GetObject  permission is not required in this scenario.\nIf you request the current version of an object without a speci\ufb01c versionId  in the request \nheader, only the s3:GetObject  permission is required. The s3:GetObjectVersion\npermission is not required in this scenario.\nAmazon S3 API Version 2006-03-01 285Amazon Simple Storage Service API Reference\nIf the object that you request doesn\u2019t exist, the error that Amazon S3 returns depends on \nwhether you also have the s3:ListBucket  permission.\n\u2022If you have the s3:ListBucket  permission on the bucket, Amazon S3 returns an HTTP \nstatus code 404 Not Found  error.\n\u2022If you don\u2019t have the s3:ListBucket  permission, Amazon S3 returns an HTTP status code\n403 Access Denied  error.\n\u2022Directory bucket permissions - To grant access to this API operation on a directory \nbucket, we recommend that you use the CreateSession  API operation for session-based \nauthorization. Speci\ufb01cally, you grant the s3express:CreateSession  permission to the \ndirectory bucket in a bucket policy or an IAM identity-based policy.", "Then, you make the\nCreateSession  API call on the bucket to obtain a session token. With the session token in \nyour request header, you can make API requests to this operation. After the session token \nexpires, you make another CreateSession  API call to generate a new session token for \nuse. AWS CLI or SDKs create session and refresh the session token automatically to avoid \nservice interruptions when a session expires.", "For more information about authorization, see\nCreateSession .\nIf the object is encrypted using SSE-KMS, you must also have the kms:GenerateDataKey\nand kms:Decrypt  permissions in IAM identity-based policies and AWS KMS key policies for \nthe AWS KMS key.\nStorage classes\nIf the object you are retrieving is stored in the S3 Glacier Flexible Retrieval storage class, \nthe S3 Glacier Deep Archive storage class, the S3 Intelligent-Tiering Archive Access tier, \nor the S3 Intelligent-Tiering Deep Archive Access tier, before you can retrieve the object \nyou must \ufb01rst restore a copy using RestoreObject.", "Otherwise, this operation returns an\nInvalidObjectState  error.", "For information about restoring archived objects, see Restoring \nArchived Objects in the Amazon S3 User Guide .\nDirectory buckets  - For directory buckets, only the S3 Express One Zone storage class is \nsupported to store newly created objects. Unsupported storage class values won't write a \ndestination object and will respond with the HTTP status code 400 Bad Request .\nEncryption\nEncryption request headers, like x-amz-server-side-encryption , should not be sent for \nthe GetObject  requests, if your object uses server-side encryption with Amazon S3 managed \nAmazon S3 API Version 2006-03-01 286Amazon Simple Storage Service API Reference\nencryption keys (SSE-S3), server-side encryption with AWS Key Management Service (AWS KMS) \nkeys (SSE-KMS), or dual-layer server-side encryption with AWS KMS keys (DSSE-KMS). If you \ninclude the header in your GetObject  requests for the object that uses these types of keys, \nyou\u2019ll get an HTTP 400 Bad Request  error.\nDirectory buckets - For directory buckets, there are only two supported options for server-side \nencryption: SSE-S3 and SSE-KMS.", "SSE-C isn't supported.", "For more information, see Protecting \ndata with server-side encryption in the Amazon S3 User Guide .\nOverriding response header values through the request\nThere are times when you want to override certain response header values of a GetObject\nresponse.", "For example, you might override the Content-Disposition  response header value \nthrough your GetObject  request.\nYou can override values for a set of response headers.", "These modi\ufb01ed response header values \nare included only in a successful response, that is, when the HTTP status code 200 OK  is \nreturned.", "The headers you can override using the following query parameters in the request are \na subset of the headers that Amazon S3 accepts when you create an object.\nThe response headers that you can override for the GetObject  response are Cache-Control ,\nContent-Disposition , Content-Encoding , Content-Language , Content-Type , and\nExpires .\nTo override values for a set of response headers in the GetObject  response, you can use the \nfollowing query parameters in the request.\n\u2022response-cache-control\n\u2022response-content-disposition\n\u2022response-content-encoding\n\u2022response-content-language\n\u2022response-content-type\n\u2022response-expires\nNote\nWhen you use these parameters, you must sign the request by using either an \nAuthorization header or a presigned URL. These parameters cannot be used with an \nunsigned (anonymous) request.\nAmazon S3 API Version 2006-03-01 287Amazon Simple Storage Service API Reference\nHTTP Host header syntax\nDirectory buckets  - The HTTP Host header syntax is \nBucket_name .s3express- az_id.region.amazonaws.com .\nThe following operations are related to GetObject :\n\u2022ListBuckets\n\u2022GetObjectAcl\nRequest Syntax\nGET /Key+?partNumber= PartNumber &response-cache-control= ResponseCacheControl &response-\ncontent-disposition= ResponseContentDisposition &response-\ncontent-encoding= ResponseContentEncoding &response-content-\nlanguage= ResponseContentLanguage &response-content-type= ResponseContentType &response-\nexpires= ResponseExpires &versionId= VersionId  HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nIf-Match: IfMatch\nIf-Modified-Since: IfModifiedSince\nIf-None-Match: IfNoneMatch\nIf-Unmodified-Since: IfUnmodifiedSince\nRange: Range\nx-amz-server-side-encryption-customer-algorithm: SSECustomerAlgorithm\nx-amz-server-side-encryption-customer-key: SSECustomerKey\nx-amz-server-side-encryption-customer-key-MD5: SSECustomerKeyMD5\nx-amz-request-payer: RequestPayer\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nx-amz-checksum-mode: ChecksumMode\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe bucket name containing the object.\nDirectory buckets - When you use this operation with a directory \nbucket, you must use virtual-hosted-style requests in the format \nBucket_name .s3express- az_id.region.amazonaws.com . Path-style requests are not \nAmazon S3 API Version 2006-03-01 288Amazon Simple Storage Service API Reference\nsupported.", "Directory bucket names must be unique in the chosen Availability Zone.", "Bucket \nnames must follow the format  bucket_base_name --az-id--x-s3  (for example,  DOC-\nEXAMPLE-BUCKET --usw2-az1 --x-s3). For information about bucket naming restrictions, see\nDirectory bucket naming rules in the Amazon S3 User Guide .\nAccess points - When you use this action with an access point, you must provide the alias of the \naccess point in place of the bucket name or specify the access point ARN.", "When using the access \npoint ARN, you must direct requests to the access point hostname.", "The access point hostname \ntakes the form AccessPointName-AccountId .s3-accesspoint.Region.amazonaws.com.", "When using \nthis action with an access point through the AWS SDKs, you provide the access point ARN in \nplace of the bucket name.", "For more information about access point ARNs, see Using access \npoints  in the Amazon S3 User Guide .\nObject Lambda access points - When you use this action with an Object Lambda access \npoint, you must direct requests to the Object Lambda access point hostname. The Object \nLambda access point hostname takes the form AccessPointName-AccountId .s3-object-\nlambda. Region.amazonaws.com.\nNote\nAccess points and Object Lambda access points are not supported by directory buckets.\nS3 on Outposts  - When you use this action with Amazon S3 on Outposts, you must direct \nrequests to the S3 on Outposts hostname. The S3 on Outposts hostname takes the form \nAccessPointName -AccountId .outpostID .s3-outposts.", "Region.amazonaws.com .", "\nWhen you use this action with S3 on Outposts through the AWS SDKs, you provide the Outposts \naccess point ARN in place of the bucket name. For more information about S3 on Outposts \nARNs, see What is S3 on Outposts?", "in the Amazon S3 User Guide .\nRequired: Yes\nIf-Match\nReturn the object only if its entity tag (ETag) is the same as the one speci\ufb01ed in this header; \notherwise, return a 412 Precondition Failed  error.\nIf both of the If-Match  and If-Unmodified-Since  headers are present in the request \nas follows: If-Match  condition evaluates to true , and; If-Unmodified-Since  condition \nevaluates to false; then, S3 returns 200 OK and the data requested.\nAmazon S3 API Version 2006-03-01 289Amazon Simple Storage Service API Reference\nFor more information about conditional requests, see RFC 7232.\nIf-Modi\ufb01ed-Since\nReturn the object only if it has been modi\ufb01ed since the speci\ufb01ed time; otherwise, return a 304 \nNot Modified  error.\nIf both of the If-None-Match  and If-Modified-Since  headers are present in the request as \nfollows: If-None-Match  condition evaluates to false , and; If-Modified-Since  condition \nevaluates to true; then, S3 returns 304 Not Modified  status code.\nFor more information about conditional requests, see RFC 7232.\nIf-None-Match\nReturn the object only if its entity tag (ETag) is di\ufb00erent from the one speci\ufb01ed in this header; \notherwise, return a 304 Not Modified  error.\nIf both of the If-None-Match  and If-Modified-Since  headers are present in the request as \nfollows: If-None-Match  condition evaluates to false , and; If-Modified-Since  condition \nevaluates to true; then, S3 returns 304 Not Modified  HTTP status code.\nFor more information about conditional requests, see RFC 7232.\nIf-Unmodi\ufb01ed-Since\nReturn the object only if it has not been modi\ufb01ed since the speci\ufb01ed time; otherwise, return a\n412 Precondition Failed  error.\nIf both of the If-Match  and If-Unmodified-Since  headers are present in the request \nas follows: If-Match  condition evaluates to true , and; If-Unmodified-Since  condition \nevaluates to false; then, S3 returns 200 OK and the data requested.\nFor more information about conditional requests, see RFC 7232.\nKey\nKey of the object to get.\nLength Constraints: Minimum length of 1.\nRequired: Yes\nAmazon S3 API Version 2006-03-01 290Amazon Simple Storage Service API Reference\npartNumber\nPart number of the object being read.", "This is a positive integer between 1 and 10,000.", "\nE\ufb00ectively performs a 'ranged' GET request for the part speci\ufb01ed.", "Useful for downloading just a \npart of an object.\nRange\nDownloads the speci\ufb01ed byte range of an object.", "For more information about the HTTP Range \nheader, see https://www.rfc-editor.org/rfc/rfc9110.html#name-range.\nNote\nAmazon S3 doesn't support retrieving multiple ranges of data per GET request.\nresponse-cache-control\nSets the Cache-Control  header of the response.\nresponse-content-disposition\nSets the Content-Disposition  header of the response.\nresponse-content-encoding\nSets the Content-Encoding  header of the response.\nresponse-content-language\nSets the Content-Language  header of the response.\nresponse-content-type\nSets the Content-Type  header of the response.\nresponse-expires\nSets the Expires header of the response.\nversionId\nVersion ID used to reference a speci\ufb01c version of the object.\nBy default, the GetObject  operation returns the current version of an object. To return a \ndi\ufb00erent version, use the versionId  subresource.\nAmazon S3 API Version 2006-03-01 291Amazon Simple Storage Service API Reference\nNote\n\u2022If you include a versionId  in your request header, you must have the\ns3:GetObjectVersion  permission to access a speci\ufb01c version of an object. The\ns3:GetObject  permission is not required in this scenario.\n\u2022If you request the current version of an object without a speci\ufb01c versionId\nin the request header, only the s3:GetObject  permission is required. The\ns3:GetObjectVersion  permission is not required in this scenario.\n\u2022Directory buckets - S3 Versioning isn't enabled and supported for directory buckets.", "\nFor this API operation, only the null value of the version ID is supported by directory \nbuckets. You can only specify null  to the versionId  query parameter in the \nrequest.\nFor more information about versioning, see PutBucketVersioning.\nx-amz-checksum-mode\nTo retrieve the checksum, this mode must be enabled.\nGeneral purpose buckets - In addition, if you enable checksum mode and the object is \nuploaded with a checksum  and encrypted with an AWS Key Management Service (AWS KMS) \nkey, you must have permission to use the kms:Decrypt  action to retrieve the checksum.\nValid Values: ENABLED\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner.", "If the account ID that you provide does not match \nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nx-amz-request-payer\nCon\ufb01rms that the requester knows that they will be charged for the request. Bucket owners \nneed not specify this parameter in their requests.", "If either the source or destination S3 \nbucket has Requester Pays enabled, the requester will pay for corresponding charges to copy \nthe object. For information about downloading objects from Requester Pays buckets, see\nDownloading Objects in Requester Pays Buckets in the Amazon S3 User Guide .\nAmazon S3 API Version 2006-03-01 292Amazon Simple Storage Service API Reference\nNote\nThis functionality is not supported for directory buckets.\nValid Values: requester\nx-amz-server-side-encryption-customer-algorithm\nSpeci\ufb01es the algorithm to use when decrypting the object (for example, AES256 ).\nIf you encrypt an object by using server-side encryption with customer-provided encryption \nkeys (SSE-C) when you store the object in Amazon S3, then when you GET the object, you must \nuse the following headers:\n\u2022x-amz-server-side-encryption-customer-algorithm\n\u2022x-amz-server-side-encryption-customer-key\n\u2022x-amz-server-side-encryption-customer-key-MD5\nFor more information about SSE-C, see Server-Side Encryption (Using Customer-Provided \nEncryption Keys) in the Amazon S3 User Guide .\nNote\nThis functionality is not supported for directory buckets.\nx-amz-server-side-encryption-customer-key\nSpeci\ufb01es the customer-provided encryption key that you originally provided for Amazon S3 to \nencrypt the data before storing it.", "This value is used to decrypt the object when recovering it \nand must match the one used when storing the data.", "The key must be appropriate for use with \nthe algorithm speci\ufb01ed in the x-amz-server-side-encryption-customer-algorithm\nheader.\nIf you encrypt an object by using server-side encryption with customer-provided encryption \nkeys (SSE-C) when you store the object in Amazon S3, then when you GET the object, you must \nuse the following headers:\n\u2022x-amz-server-side-encryption-customer-algorithm\n\u2022x-amz-server-side-encryption-customer-key\nAmazon S3 API Version 2006-03-01 293Amazon Simple Storage Service API Reference\n\u2022x-amz-server-side-encryption-customer-key-MD5\nFor more information about SSE-C, see Server-Side Encryption (Using Customer-Provided \nEncryption Keys) in the Amazon S3 User Guide .\nNote\nThis functionality is not supported for directory buckets.\nx-amz-server-side-encryption-customer-key-MD5\nSpeci\ufb01es the 128-bit MD5 digest of the customer-provided encryption key according to RFC \n1321. Amazon S3 uses this header for a message integrity check to ensure that the encryption \nkey was transmitted without error.\nIf you encrypt an object by using server-side encryption with customer-provided encryption \nkeys (SSE-C) when you store the object in Amazon S3, then when you GET the object, you must \nuse the following headers:\n\u2022x-amz-server-side-encryption-customer-algorithm\n\u2022x-amz-server-side-encryption-customer-key\n\u2022x-amz-server-side-encryption-customer-key-MD5\nFor more information about SSE-C, see Server-Side Encryption (Using Customer-Provided \nEncryption Keys) in the Amazon S3 User Guide .\nNote\nThis functionality is not supported for directory buckets.\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\nx-amz-delete-marker: DeleteMarker\naccept-ranges: AcceptRanges\nAmazon S3 API Version 2006-03-01 294Amazon Simple Storage Service API Reference\nx-amz-expiration: Expiration\nx-amz-restore: Restore\nLast-Modified: LastModified\nContent-Length: ContentLength\nETag: ETag\nx-amz-checksum-crc32: ChecksumCRC32\nx-amz-checksum-crc32c: ChecksumCRC32C\nx-amz-checksum-sha1: ChecksumSHA1\nx-amz-checksum-sha256: ChecksumSHA256\nx-amz-missing-meta: MissingMeta\nx-amz-version-id: VersionId\nCache-Control: CacheControl\nContent-Disposition: ContentDisposition\nContent-Encoding: ContentEncoding\nContent-Language: ContentLanguage\nContent-Range: ContentRange\nContent-Type: ContentType\nExpires: Expires\nx-amz-website-redirect-location: WebsiteRedirectLocation\nx-amz-server-side-encryption: ServerSideEncryption\nx-amz-server-side-encryption-customer-algorithm: SSECustomerAlgorithm\nx-amz-server-side-encryption-customer-key-MD5: SSECustomerKeyMD5\nx-amz-server-side-encryption-aws-kms-key-id: SSEKMSKeyId\nx-amz-server-side-encryption-bucket-key-enabled: BucketKeyEnabled\nx-amz-storage-class: StorageClass\nx-amz-request-charged: RequestCharged\nx-amz-replication-status: ReplicationStatus\nx-amz-mp-parts-count: PartsCount\nx-amz-tagging-count: TagCount\nx-amz-object-lock-mode: ObjectLockMode\nx-amz-object-lock-retain-until-date: ObjectLockRetainUntilDate\nx-amz-object-lock-legal-hold: ObjectLockLegalHoldStatus\nBody\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe response returns the following HTTP headers.\naccept-ranges\nIndicates that a range of bytes was speci\ufb01ed in the request.\nAmazon S3 API Version 2006-03-01 295Amazon Simple Storage Service API Reference\nCache-Control\nSpeci\ufb01es caching behavior along the request/reply chain.\nContent-Disposition\nSpeci\ufb01es presentational information for the object.\nContent-Encoding\nIndicates what content encodings have been applied to the object and thus what decoding \nmechanisms must be applied to obtain the media-type referenced by the Content-Type header \n\ufb01eld.\nContent-Language\nThe language the content is in.\nContent-Length\nSize of the body in bytes.\nContent-Range\nThe portion of the object returned in the response.\nContent-Type\nA standard MIME type describing the format of the object data.\nETag\nAn entity tag (ETag) is an opaque identi\ufb01er assigned by a web server to a speci\ufb01c version of a \nresource found at a URL.\nExpires\nThe date and time at which the object is no longer cacheable.\nLast-Modi\ufb01ed\nDate and time when the object was last modi\ufb01ed.\nGeneral purpose buckets  - When you specify a versionId  of the object in your request, if the \nspeci\ufb01ed version in the request is a delete marker, the response returns a 405 Method Not \nAllowed error and the Last-Modified: timestamp  response header.\nAmazon S3 API Version 2006-03-01 296Amazon Simple Storage Service API Reference\nx-amz-checksum-crc32\nThe base64-encoded, 32-bit CRC-32 checksum of the object.", "This will only be present if it was \nuploaded with the object.", "For more information, see  Checking object integrity in the Amazon \nS3 User Guide .\nx-amz-checksum-crc32c\nThe base64-encoded, 32-bit CRC-32C checksum of the object.", "This will only be present if it was \nuploaded with the object.", "For more information, see  Checking object integrity in the Amazon \nS3 User Guide .\nx-amz-checksum-sha1\nThe base64-encoded, 160-bit SHA-1 digest of the object.", "This will only be present if it was \nuploaded with the object.", "For more information, see  Checking object integrity in the Amazon \nS3 User Guide .\nx-amz-checksum-sha256\nThe base64-encoded, 256-bit SHA-256 digest of the object.", "This will only be present if it was \nuploaded with the object.", "For more information, see  Checking object integrity in the Amazon \nS3 User Guide .\nx-amz-delete-marker\nIndicates whether the object retrieved was (true) or was not (false) a Delete Marker. If false, this \nresponse header does not appear in the response.\nNote\n\u2022If the current version of the object is a delete marker, Amazon S3 behaves as if the \nobject was deleted and includes x-amz-delete-marker: true  in the response.\n\u2022If the speci\ufb01ed version in the request is a delete marker, the response returns a 405 \nMethod Not Allowed  error and the Last-Modified: timestamp  response \nheader.\nx-amz-expiration\nIf the object expiration is con\ufb01gured (see PutBucketLifecycleConfiguration ), the \nresponse includes this header.", "It includes the expiry-date  and rule-id key-value pairs \nproviding object expiration information.", "The value of the rule-id is URL-encoded.\nAmazon S3 API Version 2006-03-01 297Amazon Simple Storage Service API Reference\nNote\nThis functionality is not supported for directory buckets.\nx-amz-missing-meta\nThis is set to the number of metadata entries not returned in the headers that are pre\ufb01xed with\nx-amz-meta- .", "This can happen if you create metadata using an API like SOAP that supports \nmore \ufb02exible metadata than the REST API.", "For example, using SOAP, you can create metadata \nwhose values are not legal HTTP headers.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-mp-parts-count\nThe count of parts this object has.", "This value is only returned if you specify partNumber  in your \nrequest and the object was uploaded as a multipart upload.\nx-amz-object-lock-legal-hold\nIndicates whether this object has an active legal hold.", "This \ufb01eld is only returned if you have \npermission to view an object's legal hold status.\nNote\nThis functionality is not supported for directory buckets.\nValid Values: ON | OFF\nx-amz-object-lock-mode\nThe Object Lock mode that's currently in place for this object.\nNote\nThis functionality is not supported for directory buckets.\nAmazon S3 API Version 2006-03-01 298Amazon Simple Storage Service API Reference\nValid Values: GOVERNANCE | COMPLIANCE\nx-amz-object-lock-retain-until-date\nThe date and time when this object's Object Lock will expire.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-replication-status\nAmazon S3 can return this if your request involves a bucket that is either a source or destination \nin a replication rule.\nNote\nThis functionality is not supported for directory buckets.\nValid Values: COMPLETE | PENDING | FAILED | REPLICA | COMPLETED\nx-amz-request-charged\nIf present, indicates that the requester was successfully charged for the request.\nNote\nThis functionality is not supported for directory buckets.\nValid Values: requester\nx-amz-restore\nProvides information about object restoration action and expiration time of the restored object \ncopy.\nAmazon S3 API Version 2006-03-01 299Amazon Simple Storage Service API Reference\nNote\nThis functionality is not supported for directory buckets. Only the S3 Express One Zone \nstorage class is supported by directory buckets to store objects.\nx-amz-server-side-encryption\nThe server-side encryption algorithm used when you store this object in Amazon S3.\nValid Values: AES256 | aws:kms | aws:kms:dsse\nx-amz-server-side-encryption-aws-kms-key-id\nIf present, indicates the ID of the KMS key that was used for object encryption.\nx-amz-server-side-encryption-bucket-key-enabled\nIndicates whether the object uses an S3 Bucket Key for server-side encryption with AWS Key \nManagement Service (AWS KMS) keys (SSE-KMS).\nx-amz-server-side-encryption-customer-algorithm\nIf server-side encryption with a customer-provided encryption key was requested, the response \nwill include this header to con\ufb01rm the encryption algorithm that's used.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-server-side-encryption-customer-key-MD5\nIf server-side encryption with a customer-provided encryption key was requested, the \nresponse will include this header to provide the round-trip message integrity veri\ufb01cation of the \ncustomer-provided encryption key.\nNote\nThis functionality is not supported for directory buckets.\nAmazon S3 API Version 2006-03-01 300Amazon Simple Storage Service API Reference\nx-amz-storage-class\nProvides storage class information of the object. Amazon S3 returns this header for all objects \nexcept for S3 Standard storage class objects.\nNote\nDirectory buckets  - Only the S3 Express One Zone storage class is supported by \ndirectory buckets to store objects.\nValid Values: STANDARD | REDUCED_REDUNDANCY | STANDARD_IA | ONEZONE_IA | \nINTELLIGENT_TIERING | GLACIER | DEEP_ARCHIVE | OUTPOSTS | GLACIER_IR | \nSNOW | EXPRESS_ONEZONE\nx-amz-tagging-count\nThe number of tags, if any, on the object, when you have the relevant permission to read object \ntags.\nYou can use GetObjectTagging to retrieve the tag set associated with an object.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-version-id\nVersion ID of the object.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-website-redirect-location\nIf the bucket is con\ufb01gured as a website, redirects requests for this object to another object in \nthe same bucket or to an external URL. Amazon S3 stores the value of this header in the object \nmetadata.\nAmazon S3 API Version 2006-03-01 301Amazon Simple Storage Service API Reference\nNote\nThis functionality is not supported for directory buckets.\nThe following data is returned in binary format by the service.\n<varlistentry>   Body    </varlistentry>\nErrors\nInvalidObjectState\nObject is archived and inaccessible until restored.\nIf the object you are retrieving is stored in the S3 Glacier Flexible Retrieval storage class, \nthe S3 Glacier Deep Archive storage class, the S3 Intelligent-Tiering Archive Access tier, \nor the S3 Intelligent-Tiering Deep Archive Access tier, before you can retrieve the object \nyou must \ufb01rst restore a copy using RestoreObject.", "Otherwise, this operation returns an\nInvalidObjectState  error.", "For information about restoring archived objects, see Restoring \nArchived Objects in the Amazon S3 User Guide .\nHTTP Status Code: 403\nNoSuchKey\nThe speci\ufb01ed key does not exist.\nHTTP Status Code: 404\nExamples\nSample Request for general purpose buckets\nThe following request returns the object my-image.jpg .\n            GET /my-image.jpg HTTP/1.1 \n            Host: bucket.s3.<Region>.amazonaws.com \n            Date: Mon, 3 Oct 2016 22:32:00 GMT \n            Authorization: authorization string \nAmazon S3 API Version 2006-03-01 302Amazon Simple Storage Service API Reference\n         \nSample Response for general purpose buckets\nThis example illustrates one usage of GetObject.\n            HTTP/1.1 200 OK \n            x-amz-id-2: \n eftixk72aD6Ap51TnqcoF8eFidJG9Z/2mkiDFu8yU9AS1ed4OpIszj7UDNEHGran \n            x-amz-request-id: 318BC8BC148832E5 \n            Date: Mon, 3 Oct 2016 22:32:00 GMT \n            Last-Modified: Wed, 12 Oct 2009 17:50:00 GMT \n            ETag: \"fba9dede5f27731c9771645a39863328\" \n            Content-Length: 434234 \n           [434234 bytes of object data] \n          \nSample Response for general purpose buckets: Object with associated tags\nIf the object had tags associated with it, Amazon S3 returns the x-amz-tagging-count  header \nwith tag count.\n            HTTP/1.1 200 OK \n            x-amz-id-2: \n eftixk72aD6Ap51TnqcoF8eFidJG9Z/2mkiDFu8yU9AS1ed4OpIszj7UDNEHGran \n            x-amz-request-id: 318BC8BC148832E5 \n            Date: Mon, 3 Oct 2016 22:32:00 GMT \n            Last-Modified: Wed, 12 Oct 2009 17:50:00 GMT \n            ETag: \"fba9dede5f27731c9771645a39863328\" \n            Content-Length: 434234 \n            x-amz-tagging-count: 2 \n           [434234 bytes of object data] \n          \nSample Response for general purpose buckets: Object with an expiration\nIf the object had expiration set using lifecycle con\ufb01guration, you get the following response with \nthe x-amz-expiration  header.\nAmazon S3 API Version 2006-03-01 303Amazon Simple Storage Service API Reference\n            HTTP/1.1 200 OK \n            x-amz-id-2: \n eftixk72aD6Ap51TnqcoF8eFidJG9Z/2mkiDFu8yU9AS1ed4OpIszj7UDNEHGran \n            x-amz-request-id: 318BC8BC148832E5 \n            Date: Wed, 28 Oct 2009 22:32:00 GMT \n            Last-Modified: Wed, 12 Oct 2009 17:50:00 GMT \n            x-amz-expiration: expiry-date=\"Fri, 23 Dec 2012 00:00:00 GMT\", rule-\nid=\"picture-deletion-rule\" \n            ETag: \"fba9dede5f27731c9771645a39863328\" \n            Content-Length: 434234 \n            Content-Type: text/plain \n            [434234 bytes of object data] \n          \nSample Response for general purpose buckets: If an object is archived in the S3 Glacier Flexible \nRetrieval or S3 Glacier Deep Archive storage classes\nIf the object you are retrieving is stored in the S3 Glacier Flexible Retrieval or S3 Glacier Deep \nArchive storage classes, you must \ufb01rst restore a copy using RestoreObject. Otherwise, this action \nreturns an InvalidObjectState  error.\n            HTTP/1.1 403 Forbidden \n            x-amz-request-id: CD4BD8A1310A11B3 \n            x-amz-id-2: m9RDbQU0+RRBTjOUN1ChQ1eqMUnr9dv8b\n+KP6I2gHfRJZSTSrMCoRP8RtPRzX9mb \n            Content-Type: application/xml \n            Date: Mon, 12 Nov 2012 23:53:21 GMT \n            Server: Amazon S3 \n            Content-Length: 231 \n            <Error> \n              <Code>InvalidObjectState</Code> \n              <Message>The action is not valid for the object's storage class</Message> \n              <RequestId>9FEFFF118E15B86F</RequestId> \n              <HostId>WVQ5kzhiT+oiUfDCOiOYv8W4Tk9eNcxWi/MK+hTS/av34Xy4rBU3zsavf0aaaaa</\nHostId> \n            </Error> \n          \nAmazon S3 API Version 2006-03-01 304Amazon Simple Storage Service API Reference\nSample Response for general purpose buckets: If an object is archived with the S3 Intelligent-\nTiering Archive or S3 Intelligent-Tiering Deep Archive tiers\nIf the object you are retrieving is stored in the S3 Intelligent-Tiering Archive or S3 Intelligent-\nTiering Deep Archive tiers, you must \ufb01rst restore a copy using RestoreObject. Otherwise, this action \nreturns an InvalidObjectState  error.", "When restoring from Archive Access or Deep Archive \nAccess tiers, the response will include StorageClass  and AccessTier  elements. Access tier valid \nvalues are ARCHIVE_ACCESS  and DEEP_ARCHIVE_ACCESS .", "There is no syntax change if there is an \nongoing restore.\n            HTTP/1.1 403 Forbidden \n            x-amz-request-id: CB6AW8C4332B23B7 \n            x-amz-id-2: n3RRfT90+PJDUhut3nhGW2ehfhfNU5f55c\n+a2ceCC36ab7c7fe3a71Q273b9Q45b1R5 \n            Content-Type: application/xml \n            Date: Mon, 12 Nov 2012 23:53:21 GMT \n            Server: Amazon S3 \n            Content-Length: 231 \n            <Error> \n              <Code>InvalidObjectState</Code> \n              <Message>The action is not valid for the object's access tier</Message> \n              <StorageClass>INTELLIGENT_TIERING</StorageClass> \n              <AccessTier>ARCHIVE_ACCESS</AccessTier> \n              <RequestId>9FEFFF118E15B86F</RequestId> \n              <HostId>WVQ5kzhiT+oiUfDCOiOYv8W4Tk9eNcxWi/MK+hTS/av34Xy4rBU3zsavf0aaaaa</\nHostId> \n            </Error> \n             \nSample Response for general purpose buckets: If the Latest Object Is a Delete Marker\nNotice that the delete marker returns a 404 Not Found error.\n            HTTP/1.1 404 Not Found \n            x-amz-request-id: 318BC8BC148832E5 \n            x-amz-id-2: eftixk72aD6Ap51Tnqzj7UDNEHGran \n            x-amz-version-id: 3GL4kqtJlcpXroDTDm3vjVBH40Nr8X8g \n            x-amz-delete-marker:  true \n            Date: Wed, 28 Oct 2009 22:32:00 GMT \nAmazon S3 API Version 2006-03-01 305Amazon Simple Storage Service API Reference\n            Content-Type: text/plain \n            Connection: close \n            Server: AmazonS3 \n          \nSample Request for general purpose buckets: Getting a speci\ufb01ed version of an object\nThe following request returns the speci\ufb01ed version of an object.\n            GET /myObject?versionId=3/L4kqtJlcpXroDTDmpUMLUo HTTP/1.1 \n            Host: bucket.s3.<Region>.amazonaws.com \n            Date: Wed, 28 Oct 2009 22:32:00 GMT \n            Authorization: authorization string \n          \nSample Response for general purpose buckets: GET a versioned object\nThis example illustrates one usage of GetObject.\n            HTTP/1.1 200 OK \n            x-amz-id-2: eftixk72aD6Ap54OpIszj7UDNEHGran \n            x-amz-request-id: 318BC8BC148832E5 \n            Date: Wed, 28 Oct 2009 22:32:00 GMT \n            Last-Modified: Sun, 1 Jan 2006 12:00:00 GMT \n            x-amz-version-id: 3/L4kqtJlcpXroDTDmJ+rmSpXd3QBpUMLUo \n            ETag: \"fba9dede5f27731c9771645a39863328\" \n            Content-Length: 434234 \n            Content-Type: text/plain \n            Connection: close \n            Server: AmazonS3 \n            [434234 bytes of object data] \n          \nSample Request for general purpose buckets: Parameters altering response header values\nThe following request speci\ufb01es all the query string parameters in a GET request overriding the \nresponse header values.\nAmazon S3 API Version 2006-03-01 306Amazon Simple Storage Service API Reference\n            GET /Junk3.txt?response-cache-control=No-cache&response-content-\ndisposition=attachment%3B%20filename%3Dtesting.txt&response-content-encoding=x-\ngzip&response-content-language=mi%2C%20en&response-expires=Thu%2C%2001%20Dec\n%201994%2016:00:00%20GMT HTTP/1.1 \n            x-amz-date: Sun, 19 Dec 2010 01:53:44 GMT \n            Accept: */* \n            Authorization: AWS AKIAIOSFODNN7EXAMPLE:aaStE6nKnw8ihhiIdReoXYlMamW= \n          \nSample Response for general purpose buckets: With overridden response header values\nThe following request speci\ufb01es all the query string parameters in a GET request overriding the \nresponse header values.\n            HTTP/1.1 200 OK \n            x-amz-id-2: SIidWAK3hK+Il3/\nQqiu1ZKEuegzLAAspwsgwnwygb9GgFseeFHL5CII8NXSrfWW2 \n            x-amz-request-id: 881B1CBD9DF17WA1 \n            Date: Sun, 19 Dec 2010 01:54:01 GMT \n            x-amz-meta-param1: value 1 \n            x-amz-meta-param2: value 2 \n            Cache-Control: No-cache \n            Content-Language: mi, en \n            Expires: Thu, 01 Dec 1994 16:00:00 GMT \n            Content-Disposition: attachment; filename=testing.txt \n            Content-Encoding: x-gzip \n            Last-Modified: Fri, 17 Dec 2010 18:10:41 GMT \n            ETag: \"0332bee1a7bf845f176c5c0d1ae7cf07\" \n            Accept-Ranges: bytes \n            Content-Type: text/plain \n            Content-Length: 22 \n            Server: AmazonS3 \n            [object data not shown] \n          \nSample Request for general purpose buckets: Range header\nThe following request speci\ufb01es the HTTP Range header to retrieve the \ufb01rst 10 bytes of an \nobject. For more information about the HTTP Range header, see https://www.rfc-editor.org/rfc/ \nrfc9110.html#name-range.\nAmazon S3 API Version 2006-03-01 307Amazon Simple Storage Service API Reference\nNote\nAmazon S3 doesn't support retrieving multiple ranges of data per GET request.\n            GET /example-object HTTP/1.1 \n            Host: example-bucket.s3.<Region>.amazonaws.com \n            x-amz-date: Fri, 28 Jan 2011 21:32:02 GMT \n            Range: bytes=0-9 \n            Authorization: AWS AKIAIOSFODNN7EXAMPLE:Yxg83MZaEgh3OZ3l0rLo5RTX11o= \n            Sample Response with Specified Range of the Object Bytes \n          \nSample Response for general purpose buckets\nIn the following sample response, note that the header values are set to the values speci\ufb01ed in the \ntrue request.\n            HTTP/1.1 206 Partial Content \n            x-amz-id-2: MzRISOwyjmnupCzjI1WC06l5TTAzm7/JypPGXLh0OVFGcJaaO3KW/\nhRAqKOpIEEp \n            x-amz-request-id: 47622117804B3E11 \n            Date: Fri, 28 Jan 2011 21:32:09 GMT \n            x-amz-meta-title: the title \n            Last-Modified: Fri, 28 Jan 2011 20:10:32 GMT \n            ETag: \"b2419b1e3fd45d596ee22bdf62aaaa2f\" \n            Accept-Ranges: bytes \n            Content-Range: bytes 0-9/443 \n            Content-Type: text/plain \n            Content-Length: 10 \n            Server: AmazonS3 \n           [10 bytes of object data] \n          \nAmazon S3 API Version 2006-03-01 308Amazon Simple Storage Service API Reference\nSample Request for general purpose buckets: Get an object stored using server-side encryption \nwith customer-provided encryption keys\nIf an object is stored in Amazon S3 using server-side encryption with customer-provided \nencryption keys, Amazon S3 needs encryption information so that it can decrypt the object before \nsending it to you in response to a GET request. You provide the encryption information in your GET \nrequest using the relevant headers, as shown in the following example request.\n            GET /example-object HTTP/1.1 \n            Host: example-bucket.s3.<Region>.amazonaws.com  \n            Accept: */* \n            Authorization:authorization string    \n            Date: Wed, 28 May 2014 19:24:44 +0000    \n            x-amz-server-side-encryption-customer-\nkey:g0lCfA3Dv40jZz5SQJ1ZukLRFqtI5WorC/8SEKEXAMPLE    \n            x-amz-server-side-encryption-customer-key-MD5:ZjQrne1X/iTcskbY2m3example   \n            x-amz-server-side-encryption-customer-algorithm:AES256 \n          \nSample Response for general purpose buckets\nThe following sample response shows some of the response headers Amazon S3 returns. Note that \nit includes the encryption information in the response.\n            HTTP/1.1 200 OK \n            x-amz-id-2: ka5jRm8X3N12ZiY29Z989zg2tNSJPMcK+to7jNjxImXBbyChqc6tLAv\n+sau7Vjzh \n            x-amz-request-id: 195157E3E073D3F9    \n            Date: Wed, 28 May 2014 19:24:45 GMT    \n            Last-Modified: Wed, 28 May 2014 19:21:01 GMT    \n            ETag: \"c12022c9a3c6d3a28d29d90933a2b096\"    \n            x-amz-server-side-encryption-customer-algorithm: AES256    \n            x-amz-server-side-encryption-customer-key-MD5: ZjQrne1X/iTcskbY2m3example   \n   \n          \nAmazon S3 API Version 2006-03-01 309Amazon Simple Storage Service API Reference\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 310Amazon Simple Storage Service API Reference\nGetObjectAcl\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nReturns the access control list (ACL) of an object.", "To use this operation, you must have\ns3:GetObjectAcl  permissions or READ_ACP  access to the object. For more information, see\nMapping of ACL permissions and access policy permissions in the Amazon S3 User Guide\nThis functionality is not supported for Amazon S3 on Outposts.\nBy default, GET returns ACL information about the current version of an object. To return ACL \ninformation about a di\ufb00erent version, use the versionId subresource.\nNote\nIf your bucket uses the bucket owner enforced setting for S3 Object Ownership, requests to \nread ACLs are still supported and return the bucket-owner-full-control  ACL with the \nowner being the account that created the bucket. For more information, see  Controlling \nobject ownership and disabling ACLs in the Amazon S3 User Guide .\nThe following operations are related to GetObjectAcl :\n\u2022GetObject\n\u2022GetObjectAttributes\n\u2022DeleteObject\n\u2022PutObject\nRequest Syntax\nGET /{Key+}?acl&versionId= VersionId  HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-request-payer: RequestPayer\nAmazon S3 API Version 2006-03-01 311Amazon Simple Storage Service API Reference\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe bucket name that contains the object for which to get the ACL information.\nAccess points - When you use this action with an access point, you must provide the alias of the \naccess point in place of the bucket name or specify the access point ARN.", "When using the access \npoint ARN, you must direct requests to the access point hostname.", "The access point hostname \ntakes the form AccessPointName-AccountId .s3-accesspoint.Region.amazonaws.com.", "When using \nthis action with an access point through the AWS SDKs, you provide the access point ARN in \nplace of the bucket name. For more information about access point ARNs, see Using access \npoints  in the Amazon S3 User Guide .\nRequired: Yes\nKey\nThe key of the object for which to get the ACL information.\nLength Constraints: Minimum length of 1.\nRequired: Yes\nversionId\nVersion ID used to reference a speci\ufb01c version of the object.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match \nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nAmazon S3 API Version 2006-03-01 312Amazon Simple Storage Service API Reference\nx-amz-request-payer\nCon\ufb01rms that the requester knows that they will be charged for the request. Bucket owners \nneed not specify this parameter in their requests.", "If either the source or destination S3 \nbucket has Requester Pays enabled, the requester will pay for corresponding charges to copy \nthe object. For information about downloading objects from Requester Pays buckets, see\nDownloading Objects in Requester Pays Buckets in the Amazon S3 User Guide .\nNote\nThis functionality is not supported for directory buckets.\nValid Values: requester\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\nx-amz-request-charged: RequestCharged\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<AccessControlPolicy > \n   <Owner> \n      <DisplayName >string</DisplayName > \n      <ID>string</ID> \n   </Owner> \n   <AccessControlList > \n      <Grant> \n         < Grantee> \n            < DisplayName >string</DisplayName > \n            < EmailAddress >string</EmailAddress > \n            < ID>string</ID> \n            < xsi:type >string</xsi:type > \n            < URI>string</URI> \n         </ Grantee> \n         < Permission >string</Permission > \n      </Grant> \n   </AccessControlList >\nAmazon S3 API Version 2006-03-01 313Amazon Simple Storage Service API Reference\n</AccessControlPolicy >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe response returns the following HTTP headers.\nx-amz-request-charged\nIf present, indicates that the requester was successfully charged for the request.\nNote\nThis functionality is not supported for directory buckets.\nValid Values: requester\nThe following data is returned in XML format by the service.\nAccessControlPolicy\nRoot level tag for the AccessControlPolicy parameters.\nRequired: Yes\nGrants\nA list of grants.\nType: Array of Grant  data types\nOwner\nContainer for the bucket owner's display name and ID.\nType: Owner  data type\nErrors\nNoSuchKey\nThe speci\ufb01ed key does not exist.\nAmazon S3 API Version 2006-03-01 314Amazon Simple Storage Service API Reference\nHTTP Status Code: 404\nExamples\nSample Request\nThe following request returns information, including the ACL, of the object my-image.jpg .\n         GET /my-image.jpg?acl HTTP/1.1 \n         Host: bucket.s3.<Region>.amazonaws.com \n         Date: Wed, 28 Oct 2009 22:32:00 GMT \n         Authorization: authorization string \n          \nSample Response\nThis example illustrates one usage of GetObjectAcl.\n            HTTP/1.1 200 OK \n            x-amz-id-2: \n eftixk72aD6Ap51TnqcoF8eFidJG9Z/2mkiDFu8yU9AS1ed4OpIszj7UDNEHGran \n            x-amz-request-id: 318BC8BC148832E5 \n            x-amz-version-id: 4HL4kqtJlcpXroDTDmJ+rmSpXd3dIbrHY+MTRCxf3vjVBH40Nrjfkd \n            Date: Wed, 28 Oct 2009 22:32:00 GMT \n            Last-Modified: Sun, 1 Jan 2006 12:00:00 GMT \n            Content-Length: 124 \n            Content-Type: text/plain \n            Connection: close \n            Server: AmazonS3 \n  \n            <AccessControlPolicy> \n              <Owner> \n                <ID>75aa57f09aa0c8caeab4f8c24e99d10f8e7faeebf76c078efc7c6caea54ba06a</\nID> \n                <DisplayName>mtd@amazon.com</DisplayName> \n              </Owner> \n              <AccessControlList> \n                <Grant> \n                 <Grantee xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"> \n                   \n <ID>75aa57f09aa0c8caeab4f8c24e99d10f8e7faeebf76c078efc7c6caea54ba06a</ID> \nAmazon S3 API Version 2006-03-01 315Amazon Simple Storage Service API Reference\n                   <DisplayName>mtd@amazon.com</DisplayName> \n                   <Type>CanonicalUser</Type> \n                  </Grantee> \n                  <Permission>FULL_CONTROL</Permission> \n               </Grant> \n              </AccessControlList> \n            </AccessControlPolicy> \n          \nSample Request: Getting the ACL of the speci\ufb01c version of an object\nThe following request returns information, including the ACL, of the speci\ufb01ed version of the object, \nmy-image.jpg.\n            GET /my-image.jpg?versionId=3/L4kqtJlcpXroDVBH40Nr8X8gdRQBpUMLUo&acl \n HTTP/1.1 \n            Host: bucket.s3.<Region>.amazonaws.com \n            Date: Wed, 28 Oct 2009 22:32:00 GMT \n            Authorization: authorization string \n          \nSample Response: Showing the ACL of the speci\ufb01c version\nThis example illustrates one usage of GetObjectAcl.\n            HTTP/1.1 200 OK \n            x-amz-id-2: \n eftixk72aD6Ap51TnqcoF8eFidJG9Z/2mkiDFu8yU9AS1ed4OpIszj7UDNEHGran \n            x-amz-request-id: 318BC8BC148832E5 \n            Date: Wed, 28 Oct 2009 22:32:00 GMT \n            Last-Modified: Sun, 1 Jan 2006 12:00:00 GMT \n            x-amz-version-id: 3/L4kqtJlcpXroDTDmJ+rmSpXd3dIbrHY\n+MTRCxf3vjVBH40Nr8X8gdRQBpUMLUo \n            Content-Length: 124 \n            Content-Type: text/plain \n            Connection: close \n            Server: AmazonS3 \n  \n            <AccessControlPolicy> \n             <Owner> \nAmazon S3 API Version 2006-03-01 316Amazon Simple Storage Service API Reference\n               <ID>75aa57f09aa0c8caeab4f8c24e99d10f8e7faeebf76c078efc7c6caea54ba06a</\nID> \n               <DisplayName>mdtd@amazon.com</DisplayName> \n             </Owner> \n             <AccessControlList> \n               <Grant> \n                 <Grantee xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"> \n                   \n <ID>75aa57f09aa0c8caeab4f8c24e99d10f8e7faeebf76c078efc7c6caea54ba06a</ID> \n                   <DisplayName>mdtd@amazon.com</DisplayName> \n                   <Type>CanonicalUser</Type> \n                 </Grantee> \n                 <Permission>FULL_CONTROL</Permission> \n               </Grant> \n             </AccessControlList> \n            </AccessControlPolicy> \n          \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 317Amazon Simple Storage Service API Reference\nGetObjectAttributes\nService: Amazon S3\nRetrieves all the metadata from an object without returning the object itself.", "This operation is \nuseful if you're interested only in an object's metadata.\nGetObjectAttributes  combines the functionality of HeadObject  and ListParts . All \nof the data returned with each of those individual calls can be returned with a single call to\nGetObjectAttributes .\nNote\nDirectory buckets - For directory buckets, you must make requests for this API operation \nto the Zonal endpoint.", "These endpoints support virtual-hosted-style requests in the format\nhttps:// bucket_name .s3express- az_id.region.amazonaws.com/ key-name\n.", "Path-style requests are not supported.", "For more information, see Regional and Zonal \nendpoints  in the Amazon S3 User Guide .\nPermissions\n\u2022General purpose bucket permissions - To use GetObjectAttributes , you must \nhave READ access to the object.", "The permissions that you need to use this operation \ndepend on whether the bucket is versioned.", "If the bucket is versioned, you need both \nthe s3:GetObjectVersion  and s3:GetObjectVersionAttributes  permissions \nfor this operation. If the bucket is not versioned, you need the s3:GetObject  and\ns3:GetObjectAttributes  permissions. For more information, see Specifying Permissions \nin a Policy in the Amazon S3 User Guide . If the object that you request does not exist, the \nerror Amazon S3 returns depends on whether you also have the s3:ListBucket  permission.\n\u2022If you have the s3:ListBucket  permission on the bucket, Amazon S3 returns an HTTP \nstatus code 404 Not Found  (\"no such key\") error.\n\u2022If you don't have the s3:ListBucket  permission, Amazon S3 returns an HTTP status code\n403 Forbidden  (\"access denied\") error.\n\u2022Directory bucket permissions - To grant access to this API operation on a directory \nbucket, we recommend that you use the CreateSession  API operation for session-based \nauthorization. Speci\ufb01cally, you grant the s3express:CreateSession  permission to the \ndirectory bucket in a bucket policy or an IAM identity-based policy.", "Then, you make the\nCreateSession  API call on the bucket to obtain a session token.", "With the session token in \nAmazon S3 API Version 2006-03-01 318Amazon Simple Storage Service API Reference\nyour request header, you can make API requests to this operation.", "After the session token \nexpires, you make another CreateSession  API call to generate a new session token for \nuse. AWS CLI or SDKs create session and refresh the session token automatically to avoid \nservice interruptions when a session expires.", "For more information about authorization, see\nCreateSession .\nIf the object is encrypted with SSE-KMS, you must also have the kms:GenerateDataKey  and\nkms:Decrypt  permissions in IAM identity-based policies and AWS KMS key policies for the \nAWS KMS key.\nEncryption\nNote\nEncryption request headers, like x-amz-server-side-encryption , should not \nbe sent for HEAD requests if your object uses server-side encryption with AWS Key \nManagement Service (AWS KMS) keys (SSE-KMS), dual-layer server-side encryption \nwith AWS KMS keys (DSSE-KMS), or server-side encryption with Amazon S3 managed \nencryption keys (SSE-S3). The x-amz-server-side-encryption  header is used when \nyou PUT an object to S3 and want to specify the encryption method.", "If you include this \nheader in a GET request for an object that uses these types of keys, you\u2019ll get an HTTP\n400 Bad Request  error.", "It's because the encryption method can't be changed when \nyou retrieve the object.\nIf you encrypt an object by using server-side encryption with customer-provided encryption \nkeys (SSE-C) when you store the object in Amazon S3, then when you retrieve the metadata \nfrom the object, you must use the following headers to provide the encryption key for the \nserver to be able to retrieve the object's metadata. The headers are:\n\u2022x-amz-server-side-encryption-customer-algorithm\n\u2022x-amz-server-side-encryption-customer-key\n\u2022x-amz-server-side-encryption-customer-key-MD5\nFor more information about SSE-C, see Server-Side Encryption (Using Customer-Provided \nEncryption Keys) in the Amazon S3 User Guide .\nAmazon S3 API Version 2006-03-01 319Amazon Simple Storage Service API Reference\nNote\nDirectory bucket permissions - For directory buckets, there are only two supported \noptions for server-side encryption: server-side encryption with Amazon S3 managed \nkeys (SSE-S3) (AES256) and server-side encryption with AWS KMS keys (SSE-KMS) \n(aws:kms).", "We recommend that the bucket's default encryption uses the desired \nencryption con\ufb01guration and you don't override the bucket default encryption in your\nCreateSession  requests or PUT object requests.", "Then, new objects are automatically \nencrypted with the desired encryption settings.", "For more information, see Protecting \ndata with server-side encryption in the Amazon S3 User Guide . For more information \nabout the encryption overriding behaviors in directory buckets, see Specifying server-\nside encryption with AWS KMS for new object uploads.\nVersioning\nDirectory buckets - S3 Versioning isn't enabled and supported for directory buckets.", "For this \nAPI operation, only the null value of the version ID is supported by directory buckets. You can \nonly specify null  to the versionId  query parameter in the request.\nConditional request headers\nConsider the following when using request headers:\n\u2022If both of the If-Match  and If-Unmodified-Since  headers are present in the request as \nfollows, then Amazon S3 returns the HTTP status code 200 OK and the data requested:\n\u2022If-Match  condition evaluates to true .\n\u2022If-Unmodified-Since  condition evaluates to false .\nFor more information about conditional requests, see RFC 7232.\n\u2022If both of the If-None-Match  and If-Modified-Since  headers are present in the request \nas follows, then Amazon S3 returns the HTTP status code 304 Not Modified :\n\u2022If-None-Match  condition evaluates to false .\n\u2022If-Modified-Since  condition evaluates to true .\nFor more information about conditional requests, see RFC 7232.\nAmazon S3 API Version 2006-03-01 320Amazon Simple Storage Service API Reference\nHTTP Host header syntax\nDirectory buckets  - The HTTP Host header syntax is \nBucket_name .s3express- az_id.region.amazonaws.com .\nThe following actions are related to GetObjectAttributes :\n\u2022GetObject\n\u2022GetObjectAcl\n\u2022GetObjectLegalHold\n\u2022GetObjectLockCon\ufb01guration\n\u2022GetObjectRetention\n\u2022GetObjectTagging\n\u2022HeadObject\n\u2022ListParts\nRequest Syntax\nGET /{Key+}?attributes&versionId= VersionId  HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-max-parts: MaxParts\nx-amz-part-number-marker: PartNumberMarker\nx-amz-server-side-encryption-customer-algorithm: SSECustomerAlgorithm\nx-amz-server-side-encryption-customer-key: SSECustomerKey\nx-amz-server-side-encryption-customer-key-MD5: SSECustomerKeyMD5\nx-amz-request-payer: RequestPayer\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nx-amz-object-attributes: ObjectAttributes\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe name of the bucket that contains the object.\nDirectory buckets - When you use this operation with a directory \nbucket, you must use virtual-hosted-style requests in the format \nAmazon S3 API Version 2006-03-01 321Amazon Simple Storage Service API Reference\nBucket_name .s3express- az_id.region.amazonaws.com .", "Path-style requests are not \nsupported.", "Directory bucket names must be unique in the chosen Availability Zone.", "Bucket \nnames must follow the format  bucket_base_name --az-id--x-s3  (for example,  DOC-\nEXAMPLE-BUCKET --usw2-az1 --x-s3). For information about bucket naming restrictions, see\nDirectory bucket naming rules in the Amazon S3 User Guide .\nAccess points - When you use this action with an access point, you must provide the alias of the \naccess point in place of the bucket name or specify the access point ARN.", "When using the access \npoint ARN, you must direct requests to the access point hostname.", "The access point hostname \ntakes the form AccessPointName-AccountId .s3-accesspoint.Region.amazonaws.com.", "When using \nthis action with an access point through the AWS SDKs, you provide the access point ARN in \nplace of the bucket name. For more information about access point ARNs, see Using access \npoints  in the Amazon S3 User Guide .\nNote\nAccess points and Object Lambda access points are not supported by directory buckets.\nS3 on Outposts  - When you use this action with Amazon S3 on Outposts, you must direct \nrequests to the S3 on Outposts hostname. The S3 on Outposts hostname takes the form \nAccessPointName -AccountId .outpostID .s3-outposts.", "Region.amazonaws.com .", "\nWhen you use this action with S3 on Outposts through the AWS SDKs, you provide the Outposts \naccess point ARN in place of the bucket name. For more information about S3 on Outposts \nARNs, see What is S3 on Outposts?", "in the Amazon S3 User Guide .\nRequired: Yes\nKey\nThe object key.\nLength Constraints: Minimum length of 1.\nRequired: Yes\nversionId\nThe version ID used to reference a speci\ufb01c version of the object.\nAmazon S3 API Version 2006-03-01 322Amazon Simple Storage Service API Reference\nNote\nS3 Versioning isn't enabled and supported for directory buckets.", "For this API operation, \nonly the null value of the version ID is supported by directory buckets. You can only \nspecify null  to the versionId  query parameter in the request.\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match \nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nx-amz-max-parts\nSets the maximum number of parts to return.\nx-amz-object-attributes\nSpeci\ufb01es the \ufb01elds at the root level that you want returned in the response.", "Fields that you do \nnot specify are not returned.\nValid Values: ETag | Checksum | ObjectParts | StorageClass | ObjectSize\nRequired: Yes\nx-amz-part-number-marker\nSpeci\ufb01es the part after which listing should begin. Only parts with higher part numbers will be \nlisted.\nx-amz-request-payer\nCon\ufb01rms that the requester knows that they will be charged for the request.", "Bucket owners \nneed not specify this parameter in their requests.", "If either the source or destination S3 \nbucket has Requester Pays enabled, the requester will pay for corresponding charges to copy \nthe object. For information about downloading objects from Requester Pays buckets, see\nDownloading Objects in Requester Pays Buckets in the Amazon S3 User Guide .\nNote\nThis functionality is not supported for directory buckets.\nAmazon S3 API Version 2006-03-01 323Amazon Simple Storage Service API Reference\nValid Values: requester\nx-amz-server-side-encryption-customer-algorithm\nSpeci\ufb01es the algorithm to use when encrypting the object (for example, AES256).\nNote\nThis functionality is not supported for directory buckets.\nx-amz-server-side-encryption-customer-key\nSpeci\ufb01es the customer-provided encryption key for Amazon S3 to use in encrypting data. \nThis value is used to store the object and then it is discarded; Amazon S3 does not store the \nencryption key.", "The key must be appropriate for use with the algorithm speci\ufb01ed in the x-amz-\nserver-side-encryption-customer-algorithm  header.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-server-side-encryption-customer-key-MD5\nSpeci\ufb01es the 128-bit MD5 digest of the encryption key according to RFC 1321.", "Amazon S3 uses \nthis header for a message integrity check to ensure that the encryption key was transmitted \nwithout error.\nNote\nThis functionality is not supported for directory buckets.\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\nAmazon S3 API Version 2006-03-01 324Amazon Simple Storage Service API Reference\nx-amz-delete-marker: DeleteMarker\nLast-Modified: LastModified\nx-amz-version-id: VersionId\nx-amz-request-charged: RequestCharged\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<GetObjectAttributesOutput > \n   <ETag>string</ETag> \n   <Checksum > \n      <ChecksumCRC32 >string</ChecksumCRC32 > \n      <ChecksumCRC32C >string</ChecksumCRC32C > \n      <ChecksumSHA1 >string</ChecksumSHA1 > \n      <ChecksumSHA256 >string</ChecksumSHA256 > \n   </Checksum > \n   <ObjectParts > \n      <IsTruncated >boolean</IsTruncated > \n      <MaxParts >integer</MaxParts > \n      <NextPartNumberMarker >integer</NextPartNumberMarker > \n      <PartNumberMarker >integer</PartNumberMarker > \n      <Part> \n         < ChecksumCRC32 >string</ChecksumCRC32 > \n         < ChecksumCRC32C >string</ChecksumCRC32C > \n         < ChecksumSHA1 >string</ChecksumSHA1 > \n         < ChecksumSHA256 >string</ChecksumSHA256 > \n         < PartNumber >integer</PartNumber > \n         < Size>long</Size> \n      </ Part> \n      ... \n      <PartsCount >integer</PartsCount > \n   </ObjectParts > \n   <StorageClass >string</StorageClass > \n   <ObjectSize >long</ObjectSize >\n</GetObjectAttributesOutput >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe response returns the following HTTP headers.\nLast-Modi\ufb01ed\nThe creation date of the object.\nAmazon S3 API Version 2006-03-01 325Amazon Simple Storage Service API Reference\nx-amz-delete-marker\nSpeci\ufb01es whether the object retrieved was (true ) or was not ( false) a delete marker. If false , \nthis response header does not appear in the response.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-request-charged\nIf present, indicates that the requester was successfully charged for the request.\nNote\nThis functionality is not supported for directory buckets.\nValid Values: requester\nx-amz-version-id\nThe version ID of the object.\nNote\nThis functionality is not supported for directory buckets.\nThe following data is returned in XML format by the service.\nGetObjectAttributesOutput\nRoot level tag for the GetObjectAttributesOutput parameters.\nRequired: Yes\nChecksum\nThe checksum or digest of the object.\nType: Checksum  data type\nAmazon S3 API Version 2006-03-01 326Amazon Simple Storage Service API Reference\nETag\nAn ETag is an opaque identi\ufb01er assigned by a web server to a speci\ufb01c version of a resource \nfound at a URL.\nType: String\nObjectParts\nA collection of parts associated with a multipart upload.\nType: GetObjectAttributesParts data type\nObjectSize\nThe size of the object in bytes.\nType: Long\nStorageClass\nProvides the storage class information of the object. Amazon S3 returns this header for all \nobjects except for S3 Standard storage class objects.\nFor more information, see Storage Classes .\nNote\nDirectory buckets - Only the S3 Express One Zone storage class is supported by \ndirectory buckets to store objects.\nType: String\nValid Values: STANDARD | REDUCED_REDUNDANCY | STANDARD_IA | ONEZONE_IA | \nINTELLIGENT_TIERING | GLACIER | DEEP_ARCHIVE | OUTPOSTS | GLACIER_IR | \nSNOW | EXPRESS_ONEZONE\nErrors\nNoSuchKey\nThe speci\ufb01ed key does not exist.\nAmazon S3 API Version 2006-03-01 327Amazon Simple Storage Service API Reference\nHTTP Status Code: 404\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 328Amazon Simple Storage Service API Reference\nGetObjectLegalHold\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nGets an object's current legal hold status. For more information, see Locking Objects.\nThis functionality is not supported for Amazon S3 on Outposts.\nThe following action is related to GetObjectLegalHold :\n\u2022GetObjectAttributes\nRequest Syntax\nGET /{Key+}?legal-hold&versionId= VersionId  HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-request-payer: RequestPayer\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe bucket name containing the object whose legal hold status you want to retrieve.\nAccess points - When you use this action with an access point, you must provide the alias of the \naccess point in place of the bucket name or specify the access point ARN.", "When using the access \npoint ARN, you must direct requests to the access point hostname.", "The access point hostname \ntakes the form AccessPointName-AccountId .s3-accesspoint.Region.amazonaws.com.", "When using \nthis action with an access point through the AWS SDKs, you provide the access point ARN in \nplace of the bucket name. For more information about access point ARNs, see Using access \npoints  in the Amazon S3 User Guide .\nRequired: Yes\nAmazon S3 API Version 2006-03-01 329Amazon Simple Storage Service API Reference\nKey\nThe key name for the object whose legal hold status you want to retrieve.\nLength Constraints: Minimum length of 1.\nRequired: Yes\nversionId\nThe version ID of the object whose legal hold status you want to retrieve.\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner.", "If the account ID that you provide does not match \nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nx-amz-request-payer\nCon\ufb01rms that the requester knows that they will be charged for the request. Bucket owners \nneed not specify this parameter in their requests.", "If either the source or destination S3 \nbucket has Requester Pays enabled, the requester will pay for corresponding charges to copy \nthe object. For information about downloading objects from Requester Pays buckets, see\nDownloading Objects in Requester Pays Buckets in the Amazon S3 User Guide .\nNote\nThis functionality is not supported for directory buckets.\nValid Values: requester\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<LegalHold > \n   <Status>string</Status>\nAmazon S3 API Version 2006-03-01 330Amazon Simple Storage Service API Reference\n</LegalHold >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nLegalHold\nRoot level tag for the LegalHold parameters.\nRequired: Yes\nStatus\nIndicates whether the speci\ufb01ed object has a legal hold in place.\nType: String\nValid Values: ON | OFF\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 331Amazon Simple Storage Service API Reference\nGetObjectLockCon\ufb01guration\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nGets the Object Lock con\ufb01guration for a bucket.", "The rule speci\ufb01ed in the Object Lock con\ufb01guration \nwill be applied by default to every new object placed in the speci\ufb01ed bucket. For more information, \nsee Locking Objects.\nThe following action is related to GetObjectLockConfiguration :\n\u2022GetObjectAttributes\nRequest Syntax\nGET /?object-lock HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe bucket whose Object Lock con\ufb01guration you want to retrieve.\nAccess points - When you use this action with an access point, you must provide the alias of the \naccess point in place of the bucket name or specify the access point ARN.", "When using the access \npoint ARN, you must direct requests to the access point hostname.", "The access point hostname \ntakes the form AccessPointName-AccountId .s3-accesspoint.Region.amazonaws.com.", "When using \nthis action with an access point through the AWS SDKs, you provide the access point ARN in \nplace of the bucket name. For more information about access point ARNs, see Using access \npoints  in the Amazon S3 User Guide .\nRequired: Yes\nAmazon S3 API Version 2006-03-01 332Amazon Simple Storage Service API Reference\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner.", "If the account ID that you provide does not match \nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<ObjectLockConfiguration > \n   <ObjectLockEnabled >string</ObjectLockEnabled > \n   <Rule> \n      <DefaultRetention > \n         < Days>integer</Days> \n         < Mode>string</Mode> \n         < Years>integer</Years> \n      </ DefaultRetention > \n   </Rule>\n</ObjectLockConfiguration >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nObjectLockCon\ufb01guration\nRoot level tag for the ObjectLockCon\ufb01guration parameters.\nRequired: Yes\nObjectLockEnabled\nIndicates whether this bucket has an Object Lock con\ufb01guration enabled.", "Enable\nObjectLockEnabled  when you apply ObjectLockConfiguration  to a bucket.\nType: String\nAmazon S3 API Version 2006-03-01 333Amazon Simple Storage Service API Reference\nValid Values: Enabled\nRule\nSpeci\ufb01es the Object Lock rule for the speci\ufb01ed object. Enable the this rule when you apply\nObjectLockConfiguration  to a bucket. Bucket settings require both a mode and a period.", "\nThe period can be either Days  or Years but you must select one.", "You cannot specify Days  and\nYears  at the same time.\nType: ObjectLockRule data type\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 334Amazon Simple Storage Service API Reference\nGetObjectRetention\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nRetrieves an object's retention settings. For more information, see Locking Objects.\nThis functionality is not supported for Amazon S3 on Outposts.\nThe following action is related to GetObjectRetention :\n\u2022GetObjectAttributes\nRequest Syntax\nGET /{Key+}?retention&versionId= VersionId  HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-request-payer: RequestPayer\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe bucket name containing the object whose retention settings you want to retrieve.\nAccess points - When you use this action with an access point, you must provide the alias of the \naccess point in place of the bucket name or specify the access point ARN.", "When using the access \npoint ARN, you must direct requests to the access point hostname.", "The access point hostname \ntakes the form AccessPointName-AccountId .s3-accesspoint.Region.amazonaws.com.", "When using \nthis action with an access point through the AWS SDKs, you provide the access point ARN in \nplace of the bucket name. For more information about access point ARNs, see Using access \npoints  in the Amazon S3 User Guide .\nRequired: Yes\nAmazon S3 API Version 2006-03-01 335Amazon Simple Storage Service API Reference\nKey\nThe key name for the object whose retention settings you want to retrieve.\nLength Constraints: Minimum length of 1.\nRequired: Yes\nversionId\nThe version ID for the object whose retention settings you want to retrieve.\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner.", "If the account ID that you provide does not match \nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nx-amz-request-payer\nCon\ufb01rms that the requester knows that they will be charged for the request. Bucket owners \nneed not specify this parameter in their requests.", "If either the source or destination S3 \nbucket has Requester Pays enabled, the requester will pay for corresponding charges to copy \nthe object. For information about downloading objects from Requester Pays buckets, see\nDownloading Objects in Requester Pays Buckets in the Amazon S3 User Guide .\nNote\nThis functionality is not supported for directory buckets.\nValid Values: requester\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<Retention > \n   <Mode>string</Mode> \nAmazon S3 API Version 2006-03-01 336Amazon Simple Storage Service API Reference\n   <RetainUntilDate >timestamp </RetainUntilDate >\n</Retention >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nRetention\nRoot level tag for the Retention parameters.\nRequired: Yes\nMode\nIndicates the Retention mode for the speci\ufb01ed object.\nType: String\nValid Values: GOVERNANCE | COMPLIANCE\nRetainUntilDate\nThe date on which this Object Lock Retention will expire.\nType: Timestamp\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\nAmazon S3 API Version 2006-03-01 337Amazon Simple Storage Service API Reference\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 338Amazon Simple Storage Service API Reference\nGetObjectTagging\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nReturns the tag-set of an object. You send the GET request against the tagging subresource \nassociated with the object.\nTo use this operation, you must have permission to perform the s3:GetObjectTagging\naction.", "By default, the GET action returns information about current version of an object.", "For \na versioned bucket, you can have multiple versions of an object in your bucket.", "To retrieve \ntags of any other version, use the versionId query parameter.", "You also need permission for the\ns3:GetObjectVersionTagging  action.\nBy default, the bucket owner has this permission and can grant this permission to others.\nFor information about the Amazon S3 object tagging feature, see Object Tagging.\nThe following actions are related to GetObjectTagging :\n\u2022DeleteObjectTagging\n\u2022GetObjectAttributes\n\u2022PutObjectTagging\nRequest Syntax\nGET /{Key+}?tagging&versionId= VersionId  HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nx-amz-request-payer: RequestPayer\nURI Request Parameters\nThe request uses the following URI parameters.\nAmazon S3 API Version 2006-03-01 339Amazon Simple Storage Service API Reference\nBucket\nThe bucket name containing the object for which to get the tagging information.\nAccess points - When you use this action with an access point, you must provide the alias of the \naccess point in place of the bucket name or specify the access point ARN.", "When using the access \npoint ARN, you must direct requests to the access point hostname.", "The access point hostname \ntakes the form AccessPointName-AccountId .s3-accesspoint.Region.amazonaws.com.", "When using \nthis action with an access point through the AWS SDKs, you provide the access point ARN in \nplace of the bucket name.", "For more information about access point ARNs, see Using access \npoints  in the Amazon S3 User Guide .\nS3 on Outposts  - When you use this action with Amazon S3 on Outposts, you must direct \nrequests to the S3 on Outposts hostname. The S3 on Outposts hostname takes the form \nAccessPointName -AccountId .outpostID .s3-outposts.", "Region.amazonaws.com .", "\nWhen you use this action with S3 on Outposts through the AWS SDKs, you provide the Outposts \naccess point ARN in place of the bucket name. For more information about S3 on Outposts \nARNs, see What is S3 on Outposts?", "in the Amazon S3 User Guide .\nRequired: Yes\nKey\nObject key for which to get the tagging information.\nLength Constraints: Minimum length of 1.\nRequired: Yes\nversionId\nThe versionId of the object for which to get the tagging information.\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner.", "If the account ID that you provide does not match \nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nx-amz-request-payer\nCon\ufb01rms that the requester knows that they will be charged for the request. Bucket owners \nneed not specify this parameter in their requests.", "If either the source or destination S3 \nAmazon S3 API Version 2006-03-01 340Amazon Simple Storage Service API Reference\nbucket has Requester Pays enabled, the requester will pay for corresponding charges to copy \nthe object. For information about downloading objects from Requester Pays buckets, see\nDownloading Objects in Requester Pays Buckets in the Amazon S3 User Guide .\nNote\nThis functionality is not supported for directory buckets.\nValid Values: requester\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\nx-amz-version-id: VersionId\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<Tagging> \n   <TagSet> \n      <Tag> \n         < Key>string</Key> \n         < Value>string</Value> \n      </Tag> \n   </TagSet>\n</Tagging>\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe response returns the following HTTP headers.\nx-amz-version-id\nThe versionId of the object for which you got the tagging information.\nThe following data is returned in XML format by the service.\nAmazon S3 API Version 2006-03-01 341Amazon Simple Storage Service API Reference\nTagging\nRoot level tag for the Tagging parameters.\nRequired: Yes\nTagSet\nContains the tag set.\nType: Array of Tag data types\nExamples\nSample Request\nThe following request returns the tag set of the speci\ufb01ed object.\n            GET /example-object?tagging HTTP/1.1 \n            Host: examplebucket.s3.<Region>.amazonaws.com \n            Date: Thu, 22 Sep 2016 21:33:08 GMT \n            Authorization: authorization string \n          \nSample Response\nThis example illustrates one usage of GetObjectTagging.\n            HTTP/1.1 200 OK \n            Date: Thu, 22 Sep 2016 21:33:08 GMT \n            Connection: close \n            Server: AmazonS3 \n            <?xml version=\"1.0\" encoding=\"UTF-8\"?> \n            <Tagging xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n               <TagSet> \n                 <Tag> \n                   <Key>tag1</Key> \n                   <Value>val1</Value> \n                </Tag> \n                <Tag> \n                    <Key>tag2</Key> \nAmazon S3 API Version 2006-03-01 342Amazon Simple Storage Service API Reference\n                    <Value>val2</Value> \n                 </Tag> \n              </TagSet> \n            </Tagging>  \n          \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 343Amazon Simple Storage Service API Reference\nGetObjectTorrent\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nReturns torrent \ufb01les from a bucket. BitTorrent can save you bandwidth when you're distributing \nlarge \ufb01les.\nNote\nYou can get torrent only for objects that are less than 5 GB in size, and that are not \nencrypted using server-side encryption with a customer-provided encryption key.\nTo use GET, you must have READ access to the object.\nThis functionality is not supported for Amazon S3 on Outposts.\nThe following action is related to GetObjectTorrent :\n\u2022GetObject\nRequest Syntax\nGET /{Key+}?torrent HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-request-payer: RequestPayer\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe name of the bucket containing the object for which to get the torrent \ufb01les.\nAmazon S3 API Version 2006-03-01 344Amazon Simple Storage Service API Reference\nRequired: Yes\nKey\nThe object key for which to get the information.\nLength Constraints: Minimum length of 1.\nRequired: Yes\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner.", "If the account ID that you provide does not match \nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nx-amz-request-payer\nCon\ufb01rms that the requester knows that they will be charged for the request. Bucket owners \nneed not specify this parameter in their requests.", "If either the source or destination S3 \nbucket has Requester Pays enabled, the requester will pay for corresponding charges to copy \nthe object. For information about downloading objects from Requester Pays buckets, see\nDownloading Objects in Requester Pays Buckets in the Amazon S3 User Guide .\nNote\nThis functionality is not supported for directory buckets.\nValid Values: requester\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\nx-amz-request-charged: RequestCharged\nBody\nAmazon S3 API Version 2006-03-01 345Amazon Simple Storage Service API Reference\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe response returns the following HTTP headers.\nx-amz-request-charged\nIf present, indicates that the requester was successfully charged for the request.\nNote\nThis functionality is not supported for directory buckets.\nValid Values: requester\nThe following data is returned in binary format by the service.\n<varlistentry>   Body    </varlistentry>\nExamples\nGetting torrent \ufb01les in a bucket\nThis example retrieves the Torrent  \ufb01le for the Nelson object in the quotes bucket.\n            GET /quotes/Nelson?torrent HTTP/1.0 \n            Host: bucket.s3.<Region>.amazonaws.com \n            Date: Wed, 28 Oct 2009 22:32:00 GMT \n            Authorization: authorization string  \n          \nSample Response\nThis example illustrates one usage of GetObjectTorrent.\n            HTTP/1.1 200 OK \n            x-amz-request-id: 7CD745EBB7AB5ED9 \n            Date: Wed, 25 Nov 2009 12:00:00 GMT \nAmazon S3 API Version 2006-03-01 346Amazon Simple Storage Service API Reference\n            Content-Disposition: attachment; filename=Nelson.torrent; \n            Content-Type: application/x-bittorrent \n            Content-Length: 537 \n            Server: AmazonS3 \n            <body: a Bencoded dictionary as defined by the BitTorrent specification> \n          \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 347Amazon Simple Storage Service API Reference\nGetPublicAccessBlock\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nRetrieves the PublicAccessBlock  con\ufb01guration for an Amazon S3 bucket.", "To use this operation, \nyou must have the s3:GetBucketPublicAccessBlock  permission. For more information about \nAmazon S3 permissions, see Specifying Permissions in a Policy.\nImportant\nWhen Amazon S3 evaluates the PublicAccessBlock  con\ufb01guration for a bucket or an \nobject, it checks the PublicAccessBlock  con\ufb01guration for both the bucket (or the bucket \nthat contains the object) and the bucket owner's account. If the PublicAccessBlock\nsettings are di\ufb00erent between the bucket and the account, Amazon S3 uses the most \nrestrictive combination of the bucket-level and account-level settings.\nFor more information about when Amazon S3 considers a bucket or an object public, see The \nMeaning of \"Public\".\nThe following operations are related to GetPublicAccessBlock :\n\u2022Using Amazon S3 Block Public Access\n\u2022PutPublicAccessBlock\n\u2022GetPublicAccessBlock\n\u2022DeletePublicAccessBlock\nRequest Syntax\nGET /?publicAccessBlock HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nAmazon S3 API Version 2006-03-01 348Amazon Simple Storage Service API Reference\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe name of the Amazon S3 bucket whose PublicAccessBlock  con\ufb01guration you want to \nretrieve.\nRequired: Yes\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match \nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<PublicAccessBlockConfiguration > \n   <BlockPublicAcls >boolean</BlockPublicAcls > \n   <IgnorePublicAcls >boolean</IgnorePublicAcls > \n   <BlockPublicPolicy >boolean</BlockPublicPolicy > \n   <RestrictPublicBuckets >boolean</RestrictPublicBuckets >\n</PublicAccessBlockConfiguration >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nPublicAccessBlockCon\ufb01guration\nRoot level tag for the PublicAccessBlockCon\ufb01guration parameters.\nRequired: Yes\nAmazon S3 API Version 2006-03-01 349Amazon Simple Storage Service API Reference\nBlockPublicAcls\nSpeci\ufb01es whether Amazon S3 should block public access control lists (ACLs) for this bucket and \nobjects in this bucket. Setting this element to TRUE causes the following behavior:\n\u2022PUT Bucket ACL and PUT Object ACL calls fail if the speci\ufb01ed ACL is public.\n\u2022PUT Object calls fail if the request includes a public ACL.\n\u2022PUT Bucket calls fail if the request includes a public ACL.\nEnabling this setting doesn't a\ufb00ect existing policies or ACLs.\nType: Boolean\nBlockPublicPolicy\nSpeci\ufb01es whether Amazon S3 should block public bucket policies for this bucket. Setting this \nelement to TRUE causes Amazon S3 to reject calls to PUT Bucket policy if the speci\ufb01ed bucket \npolicy allows public access.\nEnabling this setting doesn't a\ufb00ect existing bucket policies.\nType: Boolean\nIgnorePublicAcls\nSpeci\ufb01es whether Amazon S3 should ignore public ACLs for this bucket and objects in this \nbucket. Setting this element to TRUE causes Amazon S3 to ignore all public ACLs on this bucket \nand objects in this bucket.\nEnabling this setting doesn't a\ufb00ect the persistence of any existing ACLs and doesn't prevent \nnew public ACLs from being set.\nType: Boolean\nRestrictPublicBuckets\nSpeci\ufb01es whether Amazon S3 should restrict public bucket policies for this bucket. Setting this \nelement to TRUE restricts access to this bucket to only AWS service principals and authorized \nusers within this account if the bucket has a public policy.\nEnabling this setting doesn't a\ufb00ect previously stored bucket policies, except that public and \ncross-account access within any public bucket policy, including non-public delegation to speci\ufb01c \naccounts, is blocked.\nAmazon S3 API Version 2006-03-01 350Amazon Simple Storage Service API Reference\nType: Boolean\nExamples\nSample Request\nThe following request gets a bucket PublicAccessBlock  con\ufb01guration.\n            GET /<bucket-name>?publicAccessBlock HTTP/1.1 \n            Host: <bucket-name>.s3. <Region> .amazonaws.com \n            x-amz-date: <Thu, 15 Nov 2016 00:17:21 GMT> \n            Authorization: <signatureValue> \n          \nSample Response\nThis example illustrates one usage of GetPublicAccessBlock.\n         HTTP/1.1 200 OK \n         x-amz-id-2: ITnGT1y4REXAMPLEPi4hklTXouTf0hccUjo0iCPEXAMPLEutBj3M7fPGlWO2SEWp \n         x-amz-request-id: 51991EXAMPLE5321 \n         Date: Thu, 15 Nov 2016 00:17:22 GMT \n         Server: AmazonS3 \n         Content-Length: 0 \n         <PublicAccessBlockConfiguration> \n            <BlockPublicAcls>TRUE</BlockPublicAcls>  \n            <IgnorePublicAcls>FALSE</IgnorePublicAcls>  \n            <BlockPublicPolicy>FALSE</BlockPublicPolicy>  \n            <RestrictPublicBuckets>FALSE</RestrictPublicBuckets> \n         </PublicAccessBlockConfiguration> \n          \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\nAmazon S3 API Version 2006-03-01 351Amazon Simple Storage Service API Reference\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 352Amazon Simple Storage Service API Reference\nHeadBucket\nService: Amazon S3\nYou can use this operation to determine if a bucket exists and if you have permission to access it. \nThe action returns a 200 OK if the bucket exists and you have permission to access it.\nNote\nIf the bucket does not exist or you do not have permission to access it, the HEAD request \nreturns a generic 400 Bad Request , 403 Forbidden  or 404 Not Found  code.", "A \nmessage body is not included, so you cannot determine the exception beyond these HTTP \nresponse codes.\nAuthentication and authorization\nGeneral purpose buckets - Request to public buckets that grant the s3:ListBucket permission \npublicly do not need to be signed.", "All other HeadBucket  requests must be authenticated and \nsigned by using IAM credentials (access key ID and secret access key for the IAM identities).", "All \nheaders with the x-amz- pre\ufb01x, including x-amz-copy-source , must be signed.", "For more \ninformation, see REST Authentication .\nDirectory buckets - You must use IAM credentials to authenticate and authorize your access to \nthe HeadBucket  API operation, instead of using the temporary security credentials through the\nCreateSession  API operation.\nAWS CLI or SDKs handles authentication and authorization on your behalf.\nPermissions\n\u2022General purpose bucket permissions - To use this operation, you must have permissions to \nperform the s3:ListBucket  action.", "The bucket owner has this permission by default and \ncan grant this permission to others.", "For more information about permissions, see Managing \naccess permissions to your Amazon S3 resources in the Amazon S3 User Guide .\n\u2022Directory bucket permissions - You must have the  s3express:CreateSession  \npermission in the Action element of a policy.", "By default, the session is in the ReadWrite\nmode.", "If you want to restrict the access, you can explicitly set the s3express:SessionMode\ncondition key to ReadOnly  on the bucket.\nAmazon S3 API Version 2006-03-01 353Amazon Simple Storage Service API Reference\nFor more information about example bucket policies, see Example bucket policies for S3 \nExpress One Zone and AWS Identity and Access Management (IAM) identity-based policies for \nS3 Express One Zone in the Amazon S3 User Guide .\nHTTP Host header syntax\nDirectory buckets  - The HTTP Host header syntax is \nBucket_name .s3express- az_id.region.amazonaws.com .\nNote\nYou must make requests for this API operation to the Zonal endpoint. \nThese endpoints support virtual-hosted-style requests in the format\nhttps:// bucket_name .s3express- az_id.region.amazonaws.com .", "Path-style \nrequests are not supported.", "For more information, see Regional and Zonal endpoints in \nthe Amazon S3 User Guide .\nRequest Syntax\nHEAD / HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe bucket name.\nDirectory buckets - When you use this operation with a directory \nbucket, you must use virtual-hosted-style requests in the format \nBucket_name .s3express- az_id.region.amazonaws.com .", "Path-style requests are not \nsupported.", "Directory bucket names must be unique in the chosen Availability Zone.", "Bucket \nnames must follow the format  bucket_base_name --az-id--x-s3  (for example,  DOC-\nEXAMPLE-BUCKET --usw2-az1 --x-s3). For information about bucket naming restrictions, see\nDirectory bucket naming rules in the Amazon S3 User Guide .\nAmazon S3 API Version 2006-03-01 354Amazon Simple Storage Service API Reference\nAccess points - When you use this action with an access point, you must provide the alias of the \naccess point in place of the bucket name or specify the access point ARN.", "When using the access \npoint ARN, you must direct requests to the access point hostname.", "The access point hostname \ntakes the form AccessPointName-AccountId .s3-accesspoint.Region.amazonaws.com.", "When using \nthis action with an access point through the AWS SDKs, you provide the access point ARN in \nplace of the bucket name. For more information about access point ARNs, see Using access \npoints  in the Amazon S3 User Guide .\nObject Lambda access points - When you use this API operation with an Object \nLambda access point, provide the alias of the Object Lambda access point in place of \nthe bucket name.", "If the Object Lambda access point alias in a request is not valid, the \nerror code InvalidAccessPointAliasError  is returned.", "For more information about\nInvalidAccessPointAliasError , see List of Error Codes.\nNote\nAccess points and Object Lambda access points are not supported by directory buckets.\nS3 on Outposts  - When you use this action with Amazon S3 on Outposts, you must direct \nrequests to the S3 on Outposts hostname. The S3 on Outposts hostname takes the form \nAccessPointName -AccountId .outpostID .s3-outposts.", "Region.amazonaws.com .", "\nWhen you use this action with S3 on Outposts through the AWS SDKs, you provide the Outposts \naccess point ARN in place of the bucket name. For more information about S3 on Outposts \nARNs, see What is S3 on Outposts?", "in the Amazon S3 User Guide .\nRequired: Yes\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match \nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nRequest Body\nThe request does not have a request body.\nAmazon S3 API Version 2006-03-01 355Amazon Simple Storage Service API Reference\nResponse Syntax\nHTTP/1.1 200\nx-amz-bucket-location-type: BucketLocationType\nx-amz-bucket-location-name: BucketLocationName\nx-amz-bucket-region: BucketRegion\nx-amz-access-point-alias: AccessPointAlias\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe response returns the following HTTP headers.\nx-amz-access-point-alias\nIndicates whether the bucket name used in the request is an access point alias.\nNote\nFor directory buckets, the value of this \ufb01eld is false .\nx-amz-bucket-location-name\nThe name of the location where the bucket will be created.\nFor directory buckets, the AZ ID of the Availability Zone where the bucket is created. An \nexample AZ ID value is usw2-az1 .\nNote\nThis functionality is only supported by directory buckets.\nx-amz-bucket-location-type\nThe type of location where the bucket is created.\nNote\nThis functionality is only supported by directory buckets.\nAmazon S3 API Version 2006-03-01 356Amazon Simple Storage Service API Reference\nValid Values: AvailabilityZone\nx-amz-bucket-region\nThe Region that the bucket is located.\nLength Constraints: Minimum length of 0. Maximum length of 20.\nErrors\nNoSuchBucket\nThe speci\ufb01ed bucket does not exist.\nHTTP Status Code: 404\nExamples\nSample Request for general purpose buckets\nThis example illustrates one usage of HeadBucket.\n            HEAD / HTTP/1.1 \n            Date: Fri, 10 Feb 2012 21:34:55 GMT \n            Authorization: authorization string \n            Host: myawsbucket.s3.amazonaws.com \n            Connection: Keep-Alive \n          \nSample Response for general purpose buckets\nThis example illustrates one usage of HeadBucket.\n            HTTP/1.1 200 OK \n            x-amz-id-2: JuKZqmXuiwFeDQxhD7M8KtsKobSzWA1QEjLbTMTagkKdBX2z7Il/\njGhDeJ3j6s80 \n            x-amz-request-id: 32FE2CEB32F5EE25 \n            x-amz-bucket-region: us-west-2 \n            x-amz-access-point-alias: false \n            Date: Fri, 10 2012 21:34:56 GMT \nAmazon S3 API Version 2006-03-01 357Amazon Simple Storage Service API Reference\n            Server: AmazonS3 \n          \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 358Amazon Simple Storage Service API Reference\nHeadObject\nService: Amazon S3\nThe HEAD operation retrieves metadata from an object without returning the object itself. This \noperation is useful if you're interested only in an object's metadata.\nNote\nA HEAD request has the same options as a GET operation on an object. The response is \nidentical to the GET response except that there is no response body. Because of this, if the\nHEAD request generates an error, it returns a generic code, such as 400 Bad Request ,\n403 Forbidden , 404 Not Found , 405 Method Not Allowed , 412 Precondition \nFailed , or 304 Not Modified . It's not possible to retrieve the exact exception of these \nerror codes.\nRequest headers are limited to 8 KB in size.", "For more information, see Common Request Headers.\nPermissions\n\u2022General purpose bucket permissions - To use HEAD, you must have the s3:GetObject\npermission.", "You need the relevant read object (or version) permission for this operation.", "For \nmore information, see Actions, resources, and condition keys for Amazon S3 in the Amazon S3 \nUser Guide . For more information about the permissions to S3 API operations by S3 resource \ntypes, see Required permissions for Amazon S3 API operations in the Amazon S3 User Guide .\nIf the object you request doesn't exist, the error that Amazon S3 returns depends on whether \nyou also have the s3:ListBucket  permission.\n\u2022If you have the s3:ListBucket  permission on the bucket, Amazon S3 returns an HTTP \nstatus code 404 Not Found  error.\n\u2022If you don\u2019t have the s3:ListBucket  permission, Amazon S3 returns an HTTP status code\n403 Forbidden  error.\n\u2022Directory bucket permissions - To grant access to this API operation on a directory \nbucket, we recommend that you use the CreateSession  API operation for session-based \nauthorization. Speci\ufb01cally, you grant the s3express:CreateSession  permission to the \ndirectory bucket in a bucket policy or an IAM identity-based policy.", "Then, you make the\nCreateSession  API call on the bucket to obtain a session token.", "With the session token in \nAmazon S3 API Version 2006-03-01 359Amazon Simple Storage Service API Reference\nyour request header, you can make API requests to this operation.", "After the session token \nexpires, you make another CreateSession  API call to generate a new session token for \nuse. AWS CLI or SDKs create session and refresh the session token automatically to avoid \nservice interruptions when a session expires.", "For more information about authorization, see\nCreateSession .\nIf you enable x-amz-checksum-mode  in the request and the object is encrypted with AWS \nKey Management Service (AWS KMS), you must also have the kms:GenerateDataKey  and\nkms:Decrypt  permissions in IAM identity-based policies and AWS KMS key policies for the \nAWS KMS key to retrieve the checksum of the object.\nEncryption\nNote\nEncryption request headers, like x-amz-server-side-encryption , should not \nbe sent for HEAD requests if your object uses server-side encryption with AWS Key \nManagement Service (AWS KMS) keys (SSE-KMS), dual-layer server-side encryption \nwith AWS KMS keys (DSSE-KMS), or server-side encryption with Amazon S3 managed \nencryption keys (SSE-S3). The x-amz-server-side-encryption  header is used when \nyou PUT an object to S3 and want to specify the encryption method.", "If you include this \nheader in a HEAD request for an object that uses these types of keys, you\u2019ll get an HTTP\n400 Bad Request  error.", "It's because the encryption method can't be changed when \nyou retrieve the object.\nIf you encrypt an object by using server-side encryption with customer-provided encryption \nkeys (SSE-C) when you store the object in Amazon S3, then when you retrieve the metadata \nfrom the object, you must use the following headers to provide the encryption key for the \nserver to be able to retrieve the object's metadata. The headers are:\n\u2022x-amz-server-side-encryption-customer-algorithm\n\u2022x-amz-server-side-encryption-customer-key\n\u2022x-amz-server-side-encryption-customer-key-MD5\nFor more information about SSE-C, see Server-Side Encryption (Using Customer-Provided \nEncryption Keys) in the Amazon S3 User Guide .\nAmazon S3 API Version 2006-03-01 360Amazon Simple Storage Service API Reference\nNote\nDirectory bucket  - For directory buckets, there are only two supported options \nfor server-side encryption: SSE-S3 and SSE-KMS.", "SSE-C isn't supported.", "For more \ninformation, see Protecting data with server-side encryption in the Amazon S3 User \nGuide .\nVersioning\n\u2022If the current version of the object is a delete marker, Amazon S3 behaves as if the object was \ndeleted and includes x-amz-delete-marker: true  in the response.\n\u2022If the speci\ufb01ed version is a delete marker, the response returns a 405 Method Not \nAllowed error and the Last-Modified: timestamp  response header.\nNote\n\u2022Directory buckets - Delete marker is not supported by directory buckets.\n\u2022Directory buckets - S3 Versioning isn't enabled and supported for directory buckets.", "\nFor this API operation, only the null value of the version ID is supported by directory \nbuckets. You can only specify null  to the versionId  query parameter in the \nrequest.\nHTTP Host header syntax\nDirectory buckets  - The HTTP Host header syntax is \nBucket_name .s3express- az_id.region.amazonaws.com .\nNote\nFor directory buckets, you must make requests for this API operation to the Zonal \nendpoint. These endpoints support virtual-hosted-style requests in the format\nhttps:// bucket_name .s3express- az_id.region.amazonaws.com/ key-name\n.", "Path-style requests are not supported.", "For more information, see Regional and Zonal \nendpoints  in the Amazon S3 User Guide .\nAmazon S3 API Version 2006-03-01 361Amazon Simple Storage Service API Reference\nThe following actions are related to HeadObject :\n\u2022GetObject\n\u2022GetObjectAttributes\nRequest Syntax\nHEAD /Key+?partNumber= PartNumber &response-cache-control= ResponseCacheControl &response-\ncontent-disposition= ResponseContentDisposition &response-\ncontent-encoding= ResponseContentEncoding &response-content-\nlanguage= ResponseContentLanguage &response-content-type= ResponseContentType &response-\nexpires= ResponseExpires &versionId= VersionId  HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nIf-Match: IfMatch\nIf-Modified-Since: IfModifiedSince\nIf-None-Match: IfNoneMatch\nIf-Unmodified-Since: IfUnmodifiedSince\nRange: Range\nx-amz-server-side-encryption-customer-algorithm: SSECustomerAlgorithm\nx-amz-server-side-encryption-customer-key: SSECustomerKey\nx-amz-server-side-encryption-customer-key-MD5: SSECustomerKeyMD5\nx-amz-request-payer: RequestPayer\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nx-amz-checksum-mode: ChecksumMode\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe name of the bucket that contains the object.\nDirectory buckets - When you use this operation with a directory \nbucket, you must use virtual-hosted-style requests in the format \nBucket_name .s3express- az_id.region.amazonaws.com .", "Path-style requests are not \nsupported.", "Directory bucket names must be unique in the chosen Availability Zone.", "Bucket \nnames must follow the format  bucket_base_name --az-id--x-s3  (for example,  DOC-\nEXAMPLE-BUCKET --usw2-az1 --x-s3). For information about bucket naming restrictions, see\nDirectory bucket naming rules in the Amazon S3 User Guide .\nAmazon S3 API Version 2006-03-01 362Amazon Simple Storage Service API Reference\nAccess points - When you use this action with an access point, you must provide the alias of the \naccess point in place of the bucket name or specify the access point ARN.", "When using the access \npoint ARN, you must direct requests to the access point hostname.", "The access point hostname \ntakes the form AccessPointName-AccountId .s3-accesspoint.Region.amazonaws.com.", "When using \nthis action with an access point through the AWS SDKs, you provide the access point ARN in \nplace of the bucket name. For more information about access point ARNs, see Using access \npoints  in the Amazon S3 User Guide .\nNote\nAccess points and Object Lambda access points are not supported by directory buckets.\nS3 on Outposts  - When you use this action with Amazon S3 on Outposts, you must direct \nrequests to the S3 on Outposts hostname. The S3 on Outposts hostname takes the form \nAccessPointName -AccountId .outpostID .s3-outposts.", "Region.amazonaws.com .", "\nWhen you use this action with S3 on Outposts through the AWS SDKs, you provide the Outposts \naccess point ARN in place of the bucket name. For more information about S3 on Outposts \nARNs, see What is S3 on Outposts?", "in the Amazon S3 User Guide .\nRequired: Yes\nIf-Match\nReturn the object only if its entity tag (ETag) is the same as the one speci\ufb01ed; otherwise, return \na 412 (precondition failed) error.\nIf both of the If-Match  and If-Unmodified-Since  headers are present in the request as \nfollows:\n\u2022If-Match  condition evaluates to true , and;\n\u2022If-Unmodified-Since  condition evaluates to false ;\nThen Amazon S3 returns 200 OK and the data requested.\nFor more information about conditional requests, see RFC 7232.\nIf-Modi\ufb01ed-Since\nReturn the object only if it has been modi\ufb01ed since the speci\ufb01ed time; otherwise, return a 304 \n(not modi\ufb01ed) error.\nAmazon S3 API Version 2006-03-01 363Amazon Simple Storage Service API Reference\nIf both of the If-None-Match  and If-Modified-Since  headers are present in the request as \nfollows:\n\u2022If-None-Match  condition evaluates to false , and;\n\u2022If-Modified-Since  condition evaluates to true ;\nThen Amazon S3 returns the 304 Not Modified  response code.\nFor more information about conditional requests, see RFC 7232.\nIf-None-Match\nReturn the object only if its entity tag (ETag) is di\ufb00erent from the one speci\ufb01ed; otherwise, \nreturn a 304 (not modi\ufb01ed) error.\nIf both of the If-None-Match  and If-Modified-Since  headers are present in the request as \nfollows:\n\u2022If-None-Match  condition evaluates to false , and;\n\u2022If-Modified-Since  condition evaluates to true ;\nThen Amazon S3 returns the 304 Not Modified  response code.\nFor more information about conditional requests, see RFC 7232.\nIf-Unmodi\ufb01ed-Since\nReturn the object only if it has not been modi\ufb01ed since the speci\ufb01ed time; otherwise, return a \n412 (precondition failed) error.\nIf both of the If-Match  and If-Unmodified-Since  headers are present in the request as \nfollows:\n\u2022If-Match  condition evaluates to true , and;\n\u2022If-Unmodified-Since  condition evaluates to false ;\nThen Amazon S3 returns 200 OK and the data requested.\nFor more information about conditional requests, see RFC 7232.\nKey\nThe object key.\nLength Constraints: Minimum length of 1.\nAmazon S3 API Version 2006-03-01 364Amazon Simple Storage Service API Reference\nRequired: Yes\npartNumber\nPart number of the object being read.", "This is a positive integer between 1 and 10,000.", "\nE\ufb00ectively performs a 'ranged' HEAD request for the part speci\ufb01ed.", "Useful querying about the \nsize of the part and the number of parts in this object.\nRange\nHeadObject returns only the metadata for an object.", "If the Range is satis\ufb01able, only the\nContentLength  is a\ufb00ected in the response.", "If the Range is not satis\ufb01able, S3 returns a 416 - \nRequested Range Not Satisfiable  error.\nresponse-cache-control\nSets the Cache-Control  header of the response.\nresponse-content-disposition\nSets the Content-Disposition  header of the response.\nresponse-content-encoding\nSets the Content-Encoding  header of the response.\nresponse-content-language\nSets the Content-Language  header of the response.\nresponse-content-type\nSets the Content-Type  header of the response.\nresponse-expires\nSets the Expires header of the response.\nversionId\nVersion ID used to reference a speci\ufb01c version of the object.\nNote\nFor directory buckets in this API operation, only the null value of the version ID is \nsupported.\nAmazon S3 API Version 2006-03-01 365Amazon Simple Storage Service API Reference\nx-amz-checksum-mode\nTo retrieve the checksum, this parameter must be enabled.\nGeneral purpose buckets - If you enable checksum mode and the object is uploaded with a\nchecksum  and encrypted with an AWS Key Management Service (AWS KMS) key, you must have \npermission to use the kms:Decrypt  action to retrieve the checksum.\nDirectory buckets - If you enable ChecksumMode  and the object is encrypted with AWS \nKey Management Service (AWS KMS), you must also have the kms:GenerateDataKey  and\nkms:Decrypt  permissions in IAM identity-based policies and AWS KMS key policies for the \nAWS KMS key to retrieve the checksum of the object.\nValid Values: ENABLED\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner.", "If the account ID that you provide does not match \nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nx-amz-request-payer\nCon\ufb01rms that the requester knows that they will be charged for the request. Bucket owners \nneed not specify this parameter in their requests.", "If either the source or destination S3 \nbucket has Requester Pays enabled, the requester will pay for corresponding charges to copy \nthe object. For information about downloading objects from Requester Pays buckets, see\nDownloading Objects in Requester Pays Buckets in the Amazon S3 User Guide .\nNote\nThis functionality is not supported for directory buckets.\nValid Values: requester\nx-amz-server-side-encryption-customer-algorithm\nSpeci\ufb01es the algorithm to use when encrypting the object (for example, AES256).\nAmazon S3 API Version 2006-03-01 366Amazon Simple Storage Service API Reference\nNote\nThis functionality is not supported for directory buckets.\nx-amz-server-side-encryption-customer-key\nSpeci\ufb01es the customer-provided encryption key for Amazon S3 to use in encrypting data. \nThis value is used to store the object and then it is discarded; Amazon S3 does not store the \nencryption key.", "The key must be appropriate for use with the algorithm speci\ufb01ed in the x-amz-\nserver-side-encryption-customer-algorithm  header.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-server-side-encryption-customer-key-MD5\nSpeci\ufb01es the 128-bit MD5 digest of the encryption key according to RFC 1321.", "Amazon S3 uses \nthis header for a message integrity check to ensure that the encryption key was transmitted \nwithout error.\nNote\nThis functionality is not supported for directory buckets.\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\nx-amz-delete-marker: DeleteMarker\naccept-ranges: AcceptRanges\nx-amz-expiration: Expiration\nx-amz-restore: Restore\nx-amz-archive-status: ArchiveStatus\nLast-Modified: LastModified\nAmazon S3 API Version 2006-03-01 367Amazon Simple Storage Service API Reference\nContent-Length: ContentLength\nx-amz-checksum-crc32: ChecksumCRC32\nx-amz-checksum-crc32c: ChecksumCRC32C\nx-amz-checksum-sha1: ChecksumSHA1\nx-amz-checksum-sha256: ChecksumSHA256\nETag: ETag\nx-amz-missing-meta: MissingMeta\nx-amz-version-id: VersionId\nCache-Control: CacheControl\nContent-Disposition: ContentDisposition\nContent-Encoding: ContentEncoding\nContent-Language: ContentLanguage\nContent-Type: ContentType\nExpires: Expires\nx-amz-website-redirect-location: WebsiteRedirectLocation\nx-amz-server-side-encryption: ServerSideEncryption\nx-amz-server-side-encryption-customer-algorithm: SSECustomerAlgorithm\nx-amz-server-side-encryption-customer-key-MD5: SSECustomerKeyMD5\nx-amz-server-side-encryption-aws-kms-key-id: SSEKMSKeyId\nx-amz-server-side-encryption-bucket-key-enabled: BucketKeyEnabled\nx-amz-storage-class: StorageClass\nx-amz-request-charged: RequestCharged\nx-amz-replication-status: ReplicationStatus\nx-amz-mp-parts-count: PartsCount\nx-amz-object-lock-mode: ObjectLockMode\nx-amz-object-lock-retain-until-date: ObjectLockRetainUntilDate\nx-amz-object-lock-legal-hold: ObjectLockLegalHoldStatus\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe response returns the following HTTP headers.\naccept-ranges\nIndicates that a range of bytes was speci\ufb01ed.\nCache-Control\nSpeci\ufb01es caching behavior along the request/reply chain.\nContent-Disposition\nSpeci\ufb01es presentational information for the object.\nAmazon S3 API Version 2006-03-01 368Amazon Simple Storage Service API Reference\nContent-Encoding\nIndicates what content encodings have been applied to the object and thus what decoding \nmechanisms must be applied to obtain the media-type referenced by the Content-Type header \n\ufb01eld.\nContent-Language\nThe language the content is in.\nContent-Length\nSize of the body in bytes.\nContent-Type\nA standard MIME type describing the format of the object data.\nETag\nAn entity tag (ETag) is an opaque identi\ufb01er assigned by a web server to a speci\ufb01c version of a \nresource found at a URL.\nExpires\nThe date and time at which the object is no longer cacheable.\nLast-Modi\ufb01ed\nDate and time when the object was last modi\ufb01ed.\nx-amz-archive-status\nThe archive state of the head object.\nNote\nThis functionality is not supported for directory buckets.\nValid Values: ARCHIVE_ACCESS | DEEP_ARCHIVE_ACCESS\nx-amz-checksum-crc32\nThe base64-encoded, 32-bit CRC-32 checksum of the object.", "This will only be present if it was \nuploaded with the object.", "When you use an API operation on an object that was uploaded using \nAmazon S3 API Version 2006-03-01 369Amazon Simple Storage Service API Reference\nmultipart uploads, this value may not be a direct checksum value of the full object.", "Instead, \nit's a calculation based on the checksum values of each individual part.", "For more information \nabout how checksums are calculated with multipart uploads, see  Checking object integrity in \nthe Amazon S3 User Guide .\nx-amz-checksum-crc32c\nThe base64-encoded, 32-bit CRC-32C checksum of the object.", "This will only be present if it was \nuploaded with the object. When you use an API operation on an object that was uploaded using \nmultipart uploads, this value may not be a direct checksum value of the full object. Instead, \nit's a calculation based on the checksum values of each individual part.", "For more information \nabout how checksums are calculated with multipart uploads, see  Checking object integrity in \nthe Amazon S3 User Guide .\nx-amz-checksum-sha1\nThe base64-encoded, 160-bit SHA-1 digest of the object.", "This will only be present if it was \nuploaded with the object. When you use the API operation on an object that was uploaded \nusing multipart uploads, this value may not be a direct checksum value of the full object.", "\nInstead, it's a calculation based on the checksum values of each individual part.", "For more \ninformation about how checksums are calculated with multipart uploads, see  Checking object \nintegrity in the Amazon S3 User Guide .\nx-amz-checksum-sha256\nThe base64-encoded, 256-bit SHA-256 digest of the object.", "This will only be present if it was \nuploaded with the object. When you use an API operation on an object that was uploaded using \nmultipart uploads, this value may not be a direct checksum value of the full object. Instead, \nit's a calculation based on the checksum values of each individual part.", "For more information \nabout how checksums are calculated with multipart uploads, see  Checking object integrity in \nthe Amazon S3 User Guide .\nx-amz-delete-marker\nSpeci\ufb01es whether the object retrieved was (true) or was not (false) a Delete Marker. If false, this \nresponse header does not appear in the response.\nNote\nThis functionality is not supported for directory buckets.\nAmazon S3 API Version 2006-03-01 370Amazon Simple Storage Service API Reference\nx-amz-expiration\nIf the object expiration is con\ufb01gured (see PutBucketLifecycleConfiguration ), the \nresponse includes this header.", "It includes the expiry-date  and rule-id key-value pairs \nproviding object expiration information.", "The value of the rule-id is URL-encoded.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-missing-meta\nThis is set to the number of metadata entries not returned in x-amz-meta  headers.", "This can \nhappen if you create metadata using an API like SOAP that supports more \ufb02exible metadata \nthan the REST API.", "For example, using SOAP, you can create metadata whose values are not \nlegal HTTP headers.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-mp-parts-count\nThe count of parts this object has.", "This value is only returned if you specify partNumber  in your \nrequest and the object was uploaded as a multipart upload.\nx-amz-object-lock-legal-hold\nSpeci\ufb01es whether a legal hold is in e\ufb00ect for this object.", "This header is only returned if the \nrequester has the s3:GetObjectLegalHold  permission.", "This header is not returned if the \nspeci\ufb01ed version of this object has never had a legal hold applied.", "For more information about \nS3 Object Lock, see Object Lock.\nNote\nThis functionality is not supported for directory buckets.\nValid Values: ON | OFF\nAmazon S3 API Version 2006-03-01 371Amazon Simple Storage Service API Reference\nx-amz-object-lock-mode\nThe Object Lock mode, if any, that's in e\ufb00ect for this object. This header is only returned if \nthe requester has the s3:GetObjectRetention  permission. For more information about S3 \nObject Lock, see Object Lock.\nNote\nThis functionality is not supported for directory buckets.\nValid Values: GOVERNANCE | COMPLIANCE\nx-amz-object-lock-retain-until-date\nThe date and time when the Object Lock retention period expires. This header is only returned if \nthe requester has the s3:GetObjectRetention  permission.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-replication-status\nAmazon S3 can return this header if your request involves a bucket that is either a source or a \ndestination in a replication rule.\nIn replication, you have a source bucket on which you con\ufb01gure replication and destination \nbucket or buckets where Amazon S3 stores object replicas. When you request an object \n(GetObject ) or object metadata (HeadObject ) from these buckets, Amazon S3 will return the\nx-amz-replication-status  header in the response as follows:\n\u2022If requesting an object from the source bucket, Amazon S3 will return the x-amz-\nreplication-status  header if the object in your request is eligible for replication.\nFor example, suppose that in your replication con\ufb01guration, you specify object pre\ufb01x\nTaxDocs requesting Amazon S3 to replicate objects with key pre\ufb01x TaxDocs.", "Any objects \nyou upload with this key name pre\ufb01x, for example TaxDocs/document1.pdf , are eligible \nfor replication.", "For any object request with this key name pre\ufb01x, Amazon S3 will return the x-\nAmazon S3 API Version 2006-03-01 372Amazon Simple Storage Service API Reference\namz-replication-status  header with value PENDING, COMPLETED or FAILED indicating \nobject replication status.\n\u2022If requesting an object from a destination bucket, Amazon S3 will return the x-amz-\nreplication-status  header with value REPLICA if the object in your request is a replica \nthat Amazon S3 created and there is no replica modi\ufb01cation replication in progress.\n\u2022When replicating objects to multiple destination buckets, the x-amz-replication-\nstatus header acts di\ufb00erently.", "The header of the source object will only return a value of \nCOMPLETED when replication is successful to all destinations. The header will remain at value \nPENDING until replication has completed for all destinations.", "If one or more destinations fails \nreplication the header will return FAILED.\nFor more information, see Replication.\nNote\nThis functionality is not supported for directory buckets.\nValid Values: COMPLETE | PENDING | FAILED | REPLICA | COMPLETED\nx-amz-request-charged\nIf present, indicates that the requester was successfully charged for the request.\nNote\nThis functionality is not supported for directory buckets.\nValid Values: requester\nx-amz-restore\nIf the object is an archived object (an object whose storage class is GLACIER), the response \nincludes this header if either the archive restoration is in progress (see RestoreObject or an \narchive copy is already restored.\nIf an archive copy is already restored, the header value indicates when Amazon S3 is scheduled \nto delete the object copy. For example:\nAmazon S3 API Version 2006-03-01 373Amazon Simple Storage Service API Reference\nx-amz-restore: ongoing-request=\"false\", expiry-date=\"Fri, 21 Dec 2012 \n00:00:00 GMT\"\nIf the object restoration is in progress, the header returns the value ongoing-\nrequest=\"true\" .\nFor more information about archiving objects, see Transitioning Objects: General \nConsiderations .\nNote\nThis functionality is not supported for directory buckets. Only the S3 Express One Zone \nstorage class is supported by directory buckets to store objects.\nx-amz-server-side-encryption\nThe server-side encryption algorithm used when you store this object in Amazon S3 (for \nexample, AES256 , aws:kms , aws:kms:dsse ).\nValid Values: AES256 | aws:kms | aws:kms:dsse\nx-amz-server-side-encryption-aws-kms-key-id\nIf present, indicates the ID of the KMS key that was used for object encryption.\nx-amz-server-side-encryption-bucket-key-enabled\nIndicates whether the object uses an S3 Bucket Key for server-side encryption with AWS Key \nManagement Service (AWS KMS) keys (SSE-KMS).\nx-amz-server-side-encryption-customer-algorithm\nIf server-side encryption with a customer-provided encryption key was requested, the response \nwill include this header to con\ufb01rm the encryption algorithm that's used.\nNote\nThis functionality is not supported for directory buckets.\nAmazon S3 API Version 2006-03-01 374Amazon Simple Storage Service API Reference\nx-amz-server-side-encryption-customer-key-MD5\nIf server-side encryption with a customer-provided encryption key was requested, the \nresponse will include this header to provide the round-trip message integrity veri\ufb01cation of the \ncustomer-provided encryption key.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-storage-class\nProvides storage class information of the object. Amazon S3 returns this header for all objects \nexcept for S3 Standard storage class objects.\nFor more information, see Storage Classes .\nNote\nDirectory buckets  - Only the S3 Express One Zone storage class is supported by \ndirectory buckets to store objects.\nValid Values: STANDARD | REDUCED_REDUNDANCY | STANDARD_IA | ONEZONE_IA | \nINTELLIGENT_TIERING | GLACIER | DEEP_ARCHIVE | OUTPOSTS | GLACIER_IR | \nSNOW | EXPRESS_ONEZONE\nx-amz-version-id\nVersion ID of the object.\nNote\nThis functionality is not supported for directory buckets.\nAmazon S3 API Version 2006-03-01 375Amazon Simple Storage Service API Reference\nx-amz-website-redirect-location\nIf the bucket is con\ufb01gured as a website, redirects requests for this object to another object in \nthe same bucket or to an external URL. Amazon S3 stores the value of this header in the object \nmetadata.\nNote\nThis functionality is not supported for directory buckets.\nErrors\nNoSuchKey\nThe speci\ufb01ed key does not exist.\nHTTP Status Code: 404\nExamples\nSample Request for general purpose buckets\nThe following request returns the metadata of an object.\n            HEAD /my-image.jpg HTTP/1.1 \n            Host: bucket.s3.<Region>.amazonaws.com \n            Date: Wed, 28 Oct 2009 22:32:00 GMT \n            Authorization: AWS AKIAIOSFODNN7EXAMPLE:02236Q3V0RonhpaBX5sCYVf1bNRuU= \n          \nSample Response for general purpose buckets\nThis example illustrates one usage of HeadObject.\n            HTTP/1.1 200 OK \n            x-amz-id-2: ef8yU9AS1ed4OpIszj7UDNEHGran \n            x-amz-request-id: 318BC8BC143432E5 \n            x-amz-version-id: 3HL4kqtJlcpXroDTDmjVBH40Nrjfkd \nAmazon S3 API Version 2006-03-01 376Amazon Simple Storage Service API Reference\n            Date: Wed, 28 Oct 2009 22:32:00 GMT \n            Last-Modified: Sun, 1 Jan 2006 12:00:00 GMT \n            ETag: \"fba9dede5f27731c9771645a39863328\" \n            Content-Length: 434234 \n            Content-Type: text/plain \n            Connection: close \n            Server: AmazonS3 \n          \nSample Response for general purpose buckets: With an expiration tag\nIf the object is scheduled to expire according to a lifecycle con\ufb01guration set on the bucket, the \nresponse returns the x-amz-expiration  tag with information about when Amazon S3 will delete \nthe object. For more information, see Transitioning Objects: General Considerations.\n            HTTP/1.1 200 OK \n            x-amz-id-2: azQRZtQJ2m1P8R+TIsG9h0VuC/DmiSJmjXUMq7snk\n+LKSJeurtmfzSlGhR46GzSJ \n            x-amz-request-id: 0EFF61CCE3F24A26 \n            Date: Mon, 17 Dec 2012 02:26:39 GMT \n            Last-Modified: Mon, 17 Dec 2012 02:14:10 GMT \n            x-amz-expiration: expiry-date=\"Fri, 21 Dec 2012 00:00:00 GMT\", rule-\nid=\"Rule for testfile.txt\" \n            ETag: \"54b0c58c7ce9f2a8b551351102ee0938\" \n            Accept-Ranges: bytes \n            Content-Type: text/plain \n            Content-Length: 14 \n            Server: AmazonS3 \n          \nSample Request for general purpose buckets: Getting metadata from a speci\ufb01ed version of an \nobject\nThe following request returns the metadata of the speci\ufb01ed version of an object.\n            HEAD /my-image.jpg?versionId=3HL4kqCxf3vjVBH40Nrjfkd HTTP/1.1 \n            Host: bucket.s3.<Region>.amazonaws.com \n            Date: Wed, 28 Oct 2009 22:32:00 GMT \n            Authorization: AWS AKIAIOSFODNN7EXAMPLE:02236Q3V0WpaBX5sCYVf1bNRuU= \n          \nAmazon S3 API Version 2006-03-01 377Amazon Simple Storage Service API Reference\nSample Response for general purpose buckets: To a versioned HEAD request\nThis example illustrates one usage of HeadObject.\n            HTTP/1.1 200 OK \n            x-amz-id-2: eftixk72aD6Ap51TnqcoF8epIszj7UDNEHGran \n            x-amz-request-id: 318BC8BC143432E5 \n            x-amz-version-id: 3HL4kqtJlcpXrof3vjVBH40Nrjfkd \n            Date: Wed, 28 Oct 2009 22:32:00 GMT \n            Last-Modified: Sun, 1 Jan 2006 12:00:00 GMT \n            ETag: \"fba9dede5f27731c9771645a39863328\" \n            Content-Length: 434234 \n            Content-Type: text/plain \n            Connection: close \n            Server: AmazonS3 \n          \nSample Request for general purpose buckets: For an S3 Glacier object\nFor an archived object, the x-amz-restore  header provides the date when the restored copy \nexpires, as shown in the following response. Even if the object is stored in S3 Glacier, all object \nmetadata is still available.\n            HEAD /my-image.jpg HTTP/1.1 \n            Host: bucket.s3.<Region>.amazonaws.com \n            Date: 13 Nov 2012 00:28:38 GMT \n            Authorization: AWS AKIAIOSFODNN7EXAMPLE:02236Q3V0RonhpaBX5sCYVf1bNRuU= \n          \nSample Response for general purpose buckets: S3 Glacier object\nIf the object is already restored, the x-amz-restore  header provides the date when the restored \ncopy will expire, as shown in the following response.\n            HTTP/1.1 200 OK \n            x-amz-id-2: FSVaTMjrmBp3Izs1NnwBZeu7M19iI8UbxMbi0A8AirHANJBo\n+hEftBuiESACOMJp \n            x-amz-request-id: E5CEFCB143EB505A \n            Date: Tue, 13 Nov 2012 00:28:38 GMT \nAmazon S3 API Version 2006-03-01 378Amazon Simple Storage Service API Reference\n            Last-Modified: Mon, 15 Oct 2012 21:58:07 GMT \n            x-amz-restore: ongoing-request=\"false\", expiry-date=\"Wed, 07 Nov 2012 \n 00:00:00 GMT\" \n            ETag: \"1accb31fcf202eba0c0f41fa2f09b4d7\" \n            Accept-Ranges: bytes \n            Content-Type: binary/octet-stream \n            Content-Length: 300 \n            Server: AmazonS3 \n          \nSample Response for general purpose buckets: In-progress restoration\nIf the restoration is in progress, the x-amz-restore  header returns a message accordingly.\n            HTTP/1.1 200 OK \n            x-amz-id-2: b+V2mDiMHTdy1myoUBpctvmJl95H9U/OSUm/\njRtHxjh0+pCk5SvByL4xu2TDv4GM \n            x-amz-request-id: E2E7B6AEE4E9BD2B \n            Date: Tue, 13 Nov 2012 00:43:32 GMT \n            Last-Modified: Sat, 20 Oct 2012 21:28:27 GMT \n            x-amz-restore: ongoing-request=\"true\" \n            ETag: \"1accb31fcf202eba0c0f41fa2f09b4d7\" \n            Accept-Ranges: bytes \n            Content-Type: binary/octet-stream \n            Content-Length: 300 \n            Server: AmazonS3 \n          \nSample Response for general purpose buckets: Object archived using S3 Intelligent-Tiering\nIf an object is stored using the S3 Intelligent-Tiering storage class and is currently in one of the \narchive tiers, then this action shows the current tier using the x-amz-archive-status  header.\n            HTTP/1.1 200 OK \n            x-amz-id-2: FSVaTMjrmBp3Izs1NnwBZeu7M19iI8UbxMbi0A8AirHANJBo\n+hEftBuiESACOMJp \n            x-amz-request-id: E5CEFCB143EB505A \n            Date: Fri, 13 Nov 2020 00:28:38 GMT \n            Last-Modified: Mon, 15 Oct 2012 21:58:07 GMT \n            ETag: \"1accb31fcf202eba0c0f41fa2f09b4d7\" \n     x-amz-storage-class: 'INTELLIGENT_TIERING' \nAmazon S3 API Version 2006-03-01 379Amazon Simple Storage Service API Reference\n            x-amz-archive-status: 'ARCHIVE_ACCESS' \n            Accept-Ranges: bytes \n            Content-Type: binary/octet-stream \n            Content-Length: 300 \n            Server: AmazonS3 \n          \nSample Response for general purpose buckets: Object archived using S3 Intelligent-Tiering \nwith restore in progress\nIf an object is stored using the S3 Intelligent-Tiering storage class and is currently in the process of \nbeing restored from one of the archive tiers, then this action shows the current tier using the x-\namz-archive-status  header and the current restore status using the x-amz-restore  header.\n            HTTP/1.1 200 OK \n            x-amz-id-2: FSVaTMjrmBp3Izs1NnwBZeu7M19iI8UbxMbi0A8AirHANJBo\n+hEftBuiESACOMJp \n            x-amz-request-id: E5CEFCB143EB505A \n            Date: Fri, 13 Nov 2020 00:28:38 GMT \n            Last-Modified: Mon, 15 Oct 2012 21:58:07 GMT \n            ETag: \"1accb31fcf202eba0c0f41fa2f09b4d7\" \n     x-amz-storage-class: 'INTELLIGENT_TIERING' \n     x-amz-archive-status: 'ARCHIVE_ACCESS' \n     x-amz-restore: 'ongoing-request=\"true\"' \n            x-amz-restore-request-date: 'Fri, 13 Nov 2020 00:20:00 GMT' \n            Accept-Ranges: bytes \n            Content-Type: binary/octet-stream \n            Content-Length: 300 \n            Server: AmazonS3 \n          \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\nAmazon S3 API Version 2006-03-01 380Amazon Simple Storage Service API Reference\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 381Amazon Simple Storage Service API Reference\nListBucketAnalyticsCon\ufb01gurations\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nLists the analytics con\ufb01gurations for the bucket.", "You can have up to 1,000 analytics con\ufb01gurations \nper bucket.\nThis action supports list pagination and does not return more than 100 con\ufb01gurations at a \ntime.", "You should always check the IsTruncated  element in the response. If there are no more \ncon\ufb01gurations to list, IsTruncated  is set to false. If there are more con\ufb01gurations to list,\nIsTruncated  is set to true, and there will be a value in NextContinuationToken .", "You use the\nNextContinuationToken  value to continue the pagination of the list by passing the value in \ncontinuation-token in the request to GET the next page.\nTo use this operation, you must have permissions to perform the\ns3:GetAnalyticsConfiguration  action.", "The bucket owner has this permission by default. The \nbucket owner can grant this permission to others.", "For more information about permissions, see\nPermissions Related to Bucket Subresource Operations and Managing Access Permissions to Your \nAmazon S3 Resources.\nFor information about Amazon S3 analytics feature, see Amazon S3 Analytics \u2013 Storage Class \nAnalysis .\nThe following operations are related to ListBucketAnalyticsConfigurations :\n\u2022GetBucketAnalyticsCon\ufb01guration\n\u2022DeleteBucketAnalyticsCon\ufb01guration\n\u2022PutBucketAnalyticsCon\ufb01guration\nRequest Syntax\nGET /?analytics&continuation-token= ContinuationToken  HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nAmazon S3 API Version 2006-03-01 382Amazon Simple Storage Service API Reference\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe name of the bucket from which analytics con\ufb01gurations are retrieved.\nRequired: Yes\ncontinuation-token\nThe ContinuationToken  that represents a placeholder from where this request should begin.\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match \nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<ListBucketAnalyticsConfigurationResult > \n   <IsTruncated >boolean</IsTruncated > \n   <ContinuationToken >string</ContinuationToken > \n   <NextContinuationToken >string</NextContinuationToken > \n   <AnalyticsConfiguration > \n      <Filter> \n         < And> \n            < Prefix>string</Prefix> \n            < Tag> \n               < Key>string</Key> \n               < Value>string</Value> \n            </ Tag> \n            ... \n         </ And> \n         < Prefix>string</Prefix> \n         < Tag> \nAmazon S3 API Version 2006-03-01 383Amazon Simple Storage Service API Reference\n            < Key>string</Key> \n            < Value>string</Value> \n         </ Tag> \n      </ Filter> \n      <Id>string</Id> \n      <StorageClassAnalysis > \n         < DataExport > \n            < Destination > \n               < S3BucketDestination > \n                  < Bucket>string</Bucket> \n                  < BucketAccountId >string</BucketAccountId > \n                  < Format>string</Format> \n                  < Prefix>string</Prefix> \n               </ S3BucketDestination > \n            </ Destination > \n            < OutputSchemaVersion >string</OutputSchemaVersion > \n         </ DataExport > \n      </ StorageClassAnalysis > \n   </AnalyticsConfiguration > \n   ...\n</ListBucketAnalyticsConfigurationResult >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nListBucketAnalyticsCon\ufb01gurationResult\nRoot level tag for the ListBucketAnalyticsCon\ufb01gurationResult parameters.\nRequired: Yes\nAnalyticsCon\ufb01guration\nThe list of analytics con\ufb01gurations for a bucket.\nType: Array of AnalyticsCon\ufb01guration data types\nContinuationToken\nThe marker that is used as a starting point for this analytics con\ufb01guration list response. This \nvalue is present if it was sent in the request.\nType: String\nAmazon S3 API Version 2006-03-01 384Amazon Simple Storage Service API Reference\nIsTruncated\nIndicates whether the returned list of analytics con\ufb01gurations is complete.", "A value of true \nindicates that the list is not complete and the NextContinuationToken will be provided for a \nsubsequent request.\nType: Boolean\nNextContinuationToken\nNextContinuationToken  is sent when isTruncated  is true, which indicates that \nthere are more analytics con\ufb01gurations to list. The next request must include this\nNextContinuationToken .", "The token is obfuscated and is not a usable value.\nType: String\nExamples\nSample Request\nDelete the metric con\ufb01guration with a speci\ufb01ed ID, which disables the CloudWatch metrics with the\nExampleMetrics  value for the FilterId  dimension.\n            GET /?analytics HTTP/1.1 \n            Host: example-bucket.s3.<Region>.amazonaws.com \n            x-amz-date: 20160430T233541Z \n            Authorization: authorization string \n          \nSample Response\nThis example illustrates one usage of ListBucketAnalyticsCon\ufb01gurations.\nHTTP/1.1 200 OK\nx-amz-id-2: gyB+3jRPnrkN98ZajxHXr3u7EFM67bNgSAxexeEHndCX/7GRnfTXxReKUQF28IfP\nx-amz-request-id: 3B3C7C725673C630\nDate: Sat, 30 Apr 2016 23:29:37 GMT\nContent-Length: length\nServer: AmazonS3\nAmazon S3 API Version 2006-03-01 385Amazon Simple Storage Service API Reference\n<ListBucketAnalyticsConfigurationResult xmlns=\"http://s3.amazonaws.com/\ndoc/2006-03-01/\"> \n    <AnalyticsConfiguration> \n        <Id>list1</Id> \n        <Filter> \n            <And> \n                <Prefix>images/</Prefix> \n                <Tag> \n                    <Key>dog</Key> \n                    <Value>corgi</Value> \n                </Tag> \n            </And> \n        </Filter> \n        <StorageClassAnalysis> \n            <DataExport> \n                <OutputSchemaVersion>V_1</OutputSchemaVersion> \n                <Destination> \n                    <S3BucketDestination> \n                        <Format>CSV</Format> \n                        <BucketAccountId>123456789012</BucketAccountId> \n                        <Bucket>arn:aws:s3:::destination-bucket</Bucket> \n                        <Prefix>destination-prefix</Prefix> \n                    </S3BucketDestination> \n                </Destination> \n            </DataExport> \n        </StorageClassAnalysis> \n    </AnalyticsConfiguration> \n    <AnalyticsConfiguration> \n        <Id>report1</Id> \n        <Filter> \n            <And> \n                <Prefix>images/</Prefix> \n                <Tag> \n                    <Key>dog</Key> \n                    <Value>bulldog</Value> \n                </Tag> \n            </And> \n        </Filter> \n        <StorageClassAnalysis> \n            <DataExport> \n                <OutputSchemaVersion>V_1</OutputSchemaVersion> \n                <Destination> \n                    <S3BucketDestination> \nAmazon S3 API Version 2006-03-01 386Amazon Simple Storage Service API Reference\n                        <Format>CSV</Format> \n                        <BucketAccountId>123456789012</BucketAccountId> \n                        <Bucket>arn:aws:s3:::destination-bucket</Bucket> \n                        <Prefix>destination-prefix</Prefix> \n                    </S3BucketDestination> \n                </Destination> \n            </DataExport> \n        </StorageClassAnalysis> \n    </AnalyticsConfiguration> \n    ...", "\n    <IsTruncated>false</IsTruncated> \n    <!-- If ContinuationToken was provided in the request.", "--> \n    <ContinuationToken>...</ContinuationToken> \n    <!-- if IsTruncated == true --> \n    <IsTruncated>true</IsTruncated> \n   <NextContinuationToken>...</NextContinuationToken>\n</ListBucketAnalyticsConfigurationResult> \n          \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 387Amazon Simple Storage Service API Reference\nListBucketIntelligentTieringCon\ufb01gurations\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nLists the S3 Intelligent-Tiering con\ufb01guration from the speci\ufb01ed bucket.\nThe S3 Intelligent-Tiering storage class is designed to optimize storage costs by automatically \nmoving data to the most cost-e\ufb00ective storage access tier, without performance impact or \noperational overhead. S3 Intelligent-Tiering delivers automatic cost savings in three low latency \nand high throughput access tiers. To get the lowest storage cost on data that can be accessed in \nminutes to hours, you can choose to activate additional archiving capabilities.\nThe S3 Intelligent-Tiering storage class is the ideal storage class for data with unknown, changing, \nor unpredictable access patterns, independent of object size or retention period.", "If the size of an \nobject is less than 128 KB, it is not monitored and not eligible for auto-tiering.", "Smaller objects can \nbe stored, but they are always charged at the Frequent Access tier rates in the S3 Intelligent-Tiering \nstorage class.\nFor more information, see Storage class for automatically optimizing frequently and infrequently \naccessed objects.\nOperations related to ListBucketIntelligentTieringConfigurations  include:\n\u2022DeleteBucketIntelligentTieringCon\ufb01guration\n\u2022PutBucketIntelligentTieringCon\ufb01guration\n\u2022GetBucketIntelligentTieringCon\ufb01guration\nRequest Syntax\nGET /?intelligent-tiering&continuation-token= ContinuationToken  HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nURI Request Parameters\nThe request uses the following URI parameters.\nAmazon S3 API Version 2006-03-01 388Amazon Simple Storage Service API Reference\nBucket\nThe name of the Amazon S3 bucket whose con\ufb01guration you want to modify or retrieve.\nRequired: Yes\ncontinuation-token\nThe ContinuationToken  that represents a placeholder from where this request should begin.\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<ListBucketIntelligentTieringConfigurationsOutput > \n   <IsTruncated >boolean</IsTruncated > \n   <ContinuationToken >string</ContinuationToken > \n   <NextContinuationToken >string</NextContinuationToken > \n   <IntelligentTieringConfiguration > \n      <Filter> \n         < And> \n            < Prefix>string</Prefix> \n            < Tag> \n               < Key>string</Key> \n               < Value>string</Value> \n            </ Tag> \n            ... \n         </ And> \n         < Prefix>string</Prefix> \n         < Tag> \n            < Key>string</Key> \n            < Value>string</Value> \n         </ Tag> \n      </ Filter> \n      <Id>string</Id> \n      <Status>string</Status> \n      <Tiering> \n         < AccessTier >string</AccessTier > \n         < Days>integer</Days> \n      </ Tiering> \nAmazon S3 API Version 2006-03-01 389Amazon Simple Storage Service API Reference\n      ... \n   </IntelligentTieringConfiguration > \n   ...\n</ListBucketIntelligentTieringConfigurationsOutput >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nListBucketIntelligentTieringCon\ufb01gurationsOutput\nRoot level tag for the ListBucketIntelligentTieringCon\ufb01gurationsOutput parameters.\nRequired: Yes\nContinuationToken\nThe ContinuationToken  that represents a placeholder from where this request should begin.\nType: String\nIntelligentTieringCon\ufb01guration\nThe list of S3 Intelligent-Tiering con\ufb01gurations for a bucket.\nType: Array of IntelligentTieringCon\ufb01guration  data types\nIsTruncated\nIndicates whether the returned list of analytics con\ufb01gurations is complete.", "A value of true\nindicates that the list is not complete and the NextContinuationToken  will be provided for a \nsubsequent request.\nType: Boolean\nNextContinuationToken\nThe marker used to continue this inventory con\ufb01guration listing. Use the\nNextContinuationToken  from this response to continue the listing in a subsequent request.", "\nThe continuation token is an opaque value that Amazon S3 understands.\nType: String\nAmazon S3 API Version 2006-03-01 390Amazon Simple Storage Service API Reference\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 391Amazon Simple Storage Service API Reference\nListBucketInventoryCon\ufb01gurations\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nReturns a list of inventory con\ufb01gurations for the bucket.", "You can have up to 1,000 analytics \ncon\ufb01gurations per bucket.\nThis action supports list pagination and does not return more than 100 con\ufb01gurations at a time.", "\nAlways check the IsTruncated  element in the response. If there are no more con\ufb01gurations to \nlist, IsTruncated  is set to false. If there are more con\ufb01gurations to list, IsTruncated  is set to \ntrue, and there is a value in NextContinuationToken .", "You use the NextContinuationToken\nvalue to continue the pagination of the list by passing the value in continuation-token in the \nrequest to GET the next page.\nTo use this operation, you must have permissions to perform the\ns3:GetInventoryConfiguration  action.", "The bucket owner has this permission by default. The \nbucket owner can grant this permission to others.", "For more information about permissions, see\nPermissions Related to Bucket Subresource Operations and Managing Access Permissions to Your \nAmazon S3 Resources.\nFor information about the Amazon S3 inventory feature, see Amazon S3 Inventory\nThe following operations are related to ListBucketInventoryConfigurations :\n\u2022GetBucketInventoryCon\ufb01guration\n\u2022DeleteBucketInventoryCon\ufb01guration\n\u2022PutBucketInventoryCon\ufb01guration\nRequest Syntax\nGET /?inventory&continuation-token= ContinuationToken  HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nAmazon S3 API Version 2006-03-01 392Amazon Simple Storage Service API Reference\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe name of the bucket containing the inventory con\ufb01gurations to retrieve.\nRequired: Yes\ncontinuation-token\nThe marker used to continue an inventory con\ufb01guration listing that has been truncated.", "Use the\nNextContinuationToken  from a previously truncated list response to continue the listing.", "\nThe continuation token is an opaque value that Amazon S3 understands.\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match \nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<ListInventoryConfigurationsResult > \n   <ContinuationToken >string</ContinuationToken > \n   <InventoryConfiguration > \n      <Destination > \n         < S3BucketDestination > \n            < AccountId >string</AccountId > \n            < Bucket>string</Bucket> \n            < Encryption > \n               < SSE-KMS> \n                  < KeyId>string</KeyId> \n               </ SSE-KMS> \n               < SSE-S3> \n               </ SSE-S3> \n            </ Encryption > \nAmazon S3 API Version 2006-03-01 393Amazon Simple Storage Service API Reference\n            < Format>string</Format> \n            < Prefix>string</Prefix> \n         </ S3BucketDestination > \n      </ Destination > \n      <Filter> \n         < Prefix>string</Prefix> \n      </ Filter> \n      <Id>string</Id> \n      <IncludedObjectVersions >string</IncludedObjectVersions > \n      <IsEnabled >boolean</IsEnabled > \n      <OptionalFields > \n         <Field> string</Field> \n      </ OptionalFields > \n      <Schedule > \n         < Frequency >string</Frequency > \n      </ Schedule > \n   </InventoryConfiguration > \n   ... \n   <IsTruncated >boolean</IsTruncated > \n   <NextContinuationToken >string</NextContinuationToken >\n</ListInventoryConfigurationsResult >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nListInventoryCon\ufb01gurationsResult\nRoot level tag for the ListInventoryCon\ufb01gurationsResult parameters.\nRequired: Yes\nContinuationToken\nIf sent in the request, the marker that is used as a starting point for this inventory con\ufb01guration \nlist response.\nType: String\nInventoryCon\ufb01guration\nThe list of inventory con\ufb01gurations for a bucket.\nType: Array of InventoryCon\ufb01guration data types\nAmazon S3 API Version 2006-03-01 394Amazon Simple Storage Service API Reference\nIsTruncated\nTells whether the returned list of inventory con\ufb01gurations is complete. A value of true indicates \nthat the list is not complete and the NextContinuationToken is provided for a subsequent \nrequest.\nType: Boolean\nNextContinuationToken\nThe marker used to continue this inventory con\ufb01guration listing. Use the\nNextContinuationToken  from this response to continue the listing in a subsequent request.", "\nThe continuation token is an opaque value that Amazon S3 understands.\nType: String\nExamples\nSample Request\nThe following request returns the inventory con\ufb01gurations in example-bucket .\nGET /?inventory HTTP/1.1\nHost: example-bucket.s3.<Region>.amazonaws.com\nx-amz-date: 20160430T233541Z\nAuthorization: authorization string\nContent-Type: text/plain    \n          \nSample Response\nDelete the metric con\ufb01guration with a speci\ufb01ed ID, which disables the CloudWatch metrics with the\nExampleMetrics  value for the FilterId  dimension.\nHTTP/1.1 200 OK\nx-amz-id-2: gyB+3jRPnrkN98ZajxHXr3u7EFM67bNgSAxexeEHndCX/7GRnfTXxReKUQF28IfP\nx-amz-request-id: 3B3C7C725673C630\nDate: Sat, 30 Apr 2016 23:29:37 GMT\nContent-Type: application/xml\nContent-Length: length\nConnection: close\nAmazon S3 API Version 2006-03-01 395Amazon Simple Storage Service API Reference\nServer: AmazonS3\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<ListInventoryConfigurationsResult xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n   <InventoryConfiguration> \n      <Id>report1</Id> \n      <IsEnabled>true</IsEnabled> \n      <Destination> \n         <S3BucketDestination> \n            <Format>CSV</Format> \n            <AccountId>123456789012</AccountId> \n            <Bucket>arn:aws:s3:::destination-bucket</Bucket> \n            <Prefix>prefix1</Prefix> \n         </S3BucketDestination> \n      </Destination> \n      <Schedule> \n         <Frequency>Daily</Frequency> \n      </Schedule> \n      <Filter> \n         <Prefix>prefix/One</Prefix> \n      </Filter> \n      <IncludedObjectVersions>All</IncludedObjectVersions> \n      <OptionalFields> \n         <Field>Size</Field> \n         <Field>LastModifiedDate</Field> \n         <Field>ETag</Field> \n         <Field>StorageClass</Field> \n         <Field>IsMultipartUploaded</Field> \n         <Field>ReplicationStatus</Field> \n      </OptionalFields> \n   </InventoryConfiguration> \n      <InventoryConfiguration> \n      <Id>report2</Id> \n      <IsEnabled>true</IsEnabled> \n      <Destination> \n         <S3BucketDestination> \n            <Format>CSV</Format> \n            <AccountId>123456789012</AccountId> \n            <Bucket>arn:aws:s3:::bucket2</Bucket> \n            <Prefix>prefix2</Prefix> \n         </S3BucketDestination> \n      </Destination> \n      <Schedule> \n         <Frequency>Daily</Frequency> \nAmazon S3 API Version 2006-03-01 396Amazon Simple Storage Service API Reference\n      </Schedule> \n      <Filter> \n         <Prefix>prefix/Two</Prefix> \n      </Filter> \n      <IncludedObjectVersions>All</IncludedObjectVersions> \n      <OptionalFields> \n         <Field>Size</Field> \n         <Field>LastModifiedDate</Field> \n         <Field>ETag</Field> \n         <Field>StorageClass</Field> \n         <Field>IsMultipartUploaded</Field> \n         <Field>ReplicationStatus</Field> \n         <Field>ObjectLockRetainUntilDate</Field> \n         <Field>ObjectLockMode</Field> \n         <Field>ObjectLockLegalHoldStatus</Field>  \n      </OptionalFields> \n   </InventoryConfiguration> \n   <InventoryConfiguration> \n      <Id>report3</Id> \n      <IsEnabled>true</IsEnabled> \n      <Destination> \n         <S3BucketDestination> \n            <Format>CSV</Format> \n            <AccountId>123456789012</AccountId> \n            <Bucket>arn:aws:s3:::bucket3</Bucket> \n            <Prefix>prefix3</Prefix> \n         </S3BucketDestination> \n      </Destination> \n      <Schedule> \n         <Frequency>Daily</Frequency> \n      </Schedule> \n      <Filter> \n         <Prefix>prefix/Three</Prefix> \n      </Filter> \n      <IncludedObjectVersions>All</IncludedObjectVersions> \n      <OptionalFields> \n         <Field>Size</Field> \n         <Field>LastModifiedDate</Field> \n         <Field>ETag</Field> \n         <Field>StorageClass</Field> \n         <Field>IsMultipartUploaded</Field> \n         <Field>ReplicationStatus</Field> \n      </OptionalFields> \n   </InventoryConfiguration> \nAmazon S3 API Version 2006-03-01 397Amazon Simple Storage Service API Reference\n    ...", "\n    <IsTruncated>false</IsTruncated> \n    <!-- If ContinuationToken was provided in the request.", "--> \n    <ContinuationToken>...</ContinuationToken> \n    <!-- if IsTruncated == true --> \n    <IsTruncated>true</IsTruncated> \n   <NextContinuationToken>...</NextContinuationToken>\n</ListInventoryConfigurationsResult> \n          \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 398Amazon Simple Storage Service API Reference\nListBucketMetricsCon\ufb01gurations\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nLists the metrics con\ufb01gurations for the bucket.", "The metrics con\ufb01gurations are only for the request \nmetrics of the bucket and do not provide information on daily storage metrics. You can have up to \n1,000 con\ufb01gurations per bucket.\nThis action supports list pagination and does not return more than 100 con\ufb01gurations at a time.", "\nAlways check the IsTruncated  element in the response. If there are no more con\ufb01gurations to \nlist, IsTruncated  is set to false. If there are more con\ufb01gurations to list, IsTruncated  is set to \ntrue, and there is a value in NextContinuationToken .", "You use the NextContinuationToken\nvalue to continue the pagination of the list by passing the value in continuation-token  in the \nrequest to GET the next page.\nTo use this operation, you must have permissions to perform the\ns3:GetMetricsConfiguration  action.", "The bucket owner has this permission by default. The \nbucket owner can grant this permission to others.", "For more information about permissions, see\nPermissions Related to Bucket Subresource Operations and Managing Access Permissions to Your \nAmazon S3 Resources.\nFor more information about metrics con\ufb01gurations and CloudWatch request metrics, see\nMonitoring Metrics with Amazon CloudWatch.\nThe following operations are related to ListBucketMetricsConfigurations :\n\u2022PutBucketMetricsCon\ufb01guration\n\u2022GetBucketMetricsCon\ufb01guration\n\u2022DeleteBucketMetricsCon\ufb01guration\nRequest Syntax\nGET /?metrics&continuation-token= ContinuationToken  HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nAmazon S3 API Version 2006-03-01 399Amazon Simple Storage Service API Reference\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe name of the bucket containing the metrics con\ufb01gurations to retrieve.\nRequired: Yes\ncontinuation-token\nThe marker that is used to continue a metrics con\ufb01guration listing that has been truncated.", "\nUse the NextContinuationToken  from a previously truncated list response to continue the \nlisting.", "The continuation token is an opaque value that Amazon S3 understands.\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match \nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<ListMetricsConfigurationsResult > \n   <IsTruncated >boolean</IsTruncated > \n   <ContinuationToken >string</ContinuationToken > \n   <NextContinuationToken >string</NextContinuationToken > \n   <MetricsConfiguration > \n      <Filter> \n         < AccessPointArn >string</AccessPointArn > \n         < And> \n            < AccessPointArn >string</AccessPointArn > \n            < Prefix>string</Prefix> \n            < Tag> \n               < Key>string</Key> \nAmazon S3 API Version 2006-03-01 400Amazon Simple Storage Service API Reference\n               < Value>string</Value> \n            </ Tag> \n            ...", "\n         </ And> \n         < Prefix>string</Prefix> \n         < Tag> \n            < Key>string</Key> \n            < Value>string</Value> \n         </ Tag> \n      </ Filter> \n      <Id>string</Id> \n   </MetricsConfiguration > \n   ...\n</ListMetricsConfigurationsResult >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nListMetricsCon\ufb01gurationsResult\nRoot level tag for the ListMetricsCon\ufb01gurationsResult parameters.\nRequired: Yes\nContinuationToken\nThe marker that is used as a starting point for this metrics con\ufb01guration list response. This \nvalue is present if it was sent in the request.\nType: String\nIsTruncated\nIndicates whether the returned list of metrics con\ufb01gurations is complete.", "A value of true \nindicates that the list is not complete and the NextContinuationToken will be provided for a \nsubsequent request.\nType: Boolean\nMetricsCon\ufb01guration\nThe list of metrics con\ufb01gurations for a bucket.\nAmazon S3 API Version 2006-03-01 401Amazon Simple Storage Service API Reference\nType: Array of MetricsCon\ufb01guration  data types\nNextContinuationToken\nThe marker used to continue a metrics con\ufb01guration listing that has been truncated.", "Use the\nNextContinuationToken  from a previously truncated list response to continue the listing.", "\nThe continuation token is an opaque value that Amazon S3 understands.\nType: String\nExamples\nSample Request\nDelete the metric con\ufb01guration with a speci\ufb01ed ID, which disables the CloudWatch metrics with the\nExampleMetrics  value for the FilterId  dimension.\nGET /?metrics HTTP/1.1\nHost: examplebucket.s3.<Region>.amazonaws.com\nx-amz-date: Thu, 15 Nov 2016 00:17:21 GMT\nAuthorization: signatureValue \n          \nSample Response\nDelete the metric con\ufb01guration with a speci\ufb01ed ID, which disables the CloudWatch metrics with the\nExampleMetrics  value for the FilterId  dimension.\nHTTP/1.1 200 OK\nx-amz-id-2: ITnGT1y4REXAMPLEPi4hklTXouTf0hccUjo0iCPEXAMPLEutBj3M7fPGlWO2SEWp\nx-amz-request-id: 51991EXAMPLE5321\nDate: Thu, 15 Nov 2016 00:17:22 GMT\nServer: AmazonS3\nContent-Length: 758 \n  \n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<ListMetricsConfigurationsResult xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n    <MetricsConfiguration> \n        <Id>EntireBucket</Id> \n    </MetricsConfiguration> \nAmazon S3 API Version 2006-03-01 402Amazon Simple Storage Service API Reference\n    <MetricsConfiguration> \n        <Id>Documents</Id> \n        <Filter> \n            <Prefix>documents/</Prefix> \n        </Filter> \n    </MetricsConfiguration> \n    <MetricsConfiguration> \n        <Id>BlueDocuments</Id> \n        <Filter> \n            <And> \n                <Prefix>documents/</Prefix> \n                <Tag> \n                    <Key>class</Key> \n                    <Value>blue</Value> \n                </Tag> \n            </And> \n        </Filter> \n    </MetricsConfiguration> \n    <IsTruncated>false</IsTruncated>\n</ListMetricsConfigurationsResult> \n          \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 403Amazon Simple Storage Service API Reference\nListBuckets\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nReturns a list of all buckets owned by the authenticated sender of the request. To use this \noperation, you must have the s3:ListAllMyBuckets  permission.\nFor information about Amazon S3 buckets, see Creating, con\ufb01guring, and working with Amazon S3 \nbuckets.\nRequest Syntax\nGET /?bucket-region= BucketRegion &continuation-token= ContinuationToken &max-\nbuckets= MaxBuckets &prefix= Prefix HTTP/1.1\nHost: s3.amazonaws.com\nURI Request Parameters\nThe request uses the following URI parameters.\nbucket-region\nLimits the response to buckets that are located in the speci\ufb01ed AWS Region.", "The AWS Region \nmust be expressed according to the AWS Region code, such as us-west-2  for the US West \n(Oregon) Region. For a list of the valid values for all of the AWS Regions, see Regions and \nEndpoints .\nNote\nRequests made to a Regional endpoint that is di\ufb00erent from the bucket-region\nparameter are not supported. For example, if you want to limit the response to your \nbuckets in Region us-west-2 , the request must be made to an endpoint in Region us-\nwest-2 .\nAmazon S3 API Version 2006-03-01 404Amazon Simple Storage Service API Reference\ncontinuation-token\nContinuationToken  indicates to Amazon S3 that the list is being continued on this bucket \nwith a token.", "ContinuationToken  is obfuscated and is not a real key.", "You can use this\nContinuationToken  for pagination of the list results.\nLength Constraints: Minimum length of 0.", "Maximum length of 1024.\nRequired: No.\nmax-buckets\nMaximum number of buckets to be returned in response. When the number is more than the \ncount of buckets that are owned by an AWS account, return all the buckets in response.\nValid Range: Minimum value of 1. Maximum value of 1000.\npre\ufb01x\nLimits the response to bucket names that begin with the speci\ufb01ed bucket name pre\ufb01x.\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<ListAllMyBucketsResult > \n   <Buckets> \n      <Bucket> \n         < BucketRegion >string</BucketRegion > \n         < CreationDate >timestamp </CreationDate > \n         < Name>string</Name> \n      </Bucket> \n   </Buckets> \n   <Owner> \n      <DisplayName >string</DisplayName > \n      <ID>string</ID> \n   </Owner> \n   <ContinuationToken >string</ContinuationToken > \n   <Prefix>string</Prefix>\n</ListAllMyBucketsResult >\nAmazon S3 API Version 2006-03-01 405Amazon Simple Storage Service API Reference\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nListAllMyBucketsResult\nRoot level tag for the ListAllMyBucketsResult parameters.\nRequired: Yes\nBuckets\nThe list of buckets owned by the requester.\nType: Array of Bucket data types\nContinuationToken\nContinuationToken  is included in the response when there are more buckets that can be \nlisted with pagination. The next ListBuckets  request to Amazon S3 can be continued with \nthis ContinuationToken . ContinuationToken  is obfuscated and is not a real bucket.\nType: String\nOwner\nThe owner of the buckets listed.\nType: Owner  data type\nPre\ufb01x\nIf Prefix was sent with the request, it is included in the response.\nAll bucket names in the response begin with the speci\ufb01ed bucket name pre\ufb01x.\nType: String\nExamples\nSample Request\nThe following request returns a list of all buckets of the sender.\nAmazon S3 API Version 2006-03-01 406Amazon Simple Storage Service API Reference\nHTTP/1.1 200 OK\n<ListAllMyBucketsResult> \n   <Buckets> \n      <Bucket> \n         <CreationDate>2019-12-11T23:32:47+00:00</CreationDate> \n         <Name>DOC-EXAMPLE-BUCKET</Name> \n      </Bucket> \n      <Bucket> \n         <CreationDate>2019-11-10T23:32:13+00:00</CreationDate> \n         <Name>DOC-EXAMPLE-BUCKET2</Name> \n      </Bucket> \n   </Buckets> \n   <Owner> \n      <DisplayName>Account+Name</DisplayName> \n      <ID>AIDACKCEVSQ6C2EXAMPLE</ID> \n   </Owner>   \n</ListAllMyBucketsResult>    \n          \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 407Amazon Simple Storage Service API Reference\nListDirectoryBuckets\nService: Amazon S3\nReturns a list of all Amazon S3 directory buckets owned by the authenticated sender of the \nrequest. For more information about directory buckets, see Directory buckets in the Amazon S3 \nUser Guide .\nNote\nDirectory buckets  - For directory buckets, you must make requests for this API operation \nto the Regional endpoint. These endpoints support path-style requests in the format\nhttps://s3express-control.", "region_code .amazonaws.com/ bucket-name  .", "\nVirtual-hosted-style requests aren't supported.", "For more information, see Regional and \nZonal endpoints in the Amazon S3 User Guide .\nPermissions\nYou must have the s3express:ListAllMyDirectoryBuckets  permission in an IAM \nidentity-based policy instead of a bucket policy.", "Cross-account access to this API operation isn't \nsupported.", "This operation can only be performed by the AWS account that owns the resource.", "\nFor more information about directory bucket policies and permissions, see AWS Identity and \nAccess Management (IAM) for S3 Express One Zone in the Amazon S3 User Guide .\nHTTP Host header syntax\nDirectory buckets  - The HTTP Host header syntax is s3express-\ncontrol. region.amazonaws.com .\nRequest Syntax\nGET /?continuation-token= ContinuationToken &max-directory-buckets= MaxDirectoryBuckets\n HTTP/1.1\nHost: s3.amazonaws.com\nURI Request Parameters\nThe request uses the following URI parameters.\nAmazon S3 API Version 2006-03-01 408Amazon Simple Storage Service API Reference\ncontinuation-token\nContinuationToken  indicates to Amazon S3 that the list is being continued on buckets in this \naccount with a token.", "ContinuationToken  is obfuscated and is not a real bucket name.", "You \ncan use this ContinuationToken  for the pagination of the list results.\nLength Constraints: Minimum length of 0.", "Maximum length of 1024.\nmax-directory-buckets\nMaximum number of buckets to be returned in response. When the number is more than the \ncount of buckets that are owned by an AWS account, return all the buckets in response.\nValid Range: Minimum value of 0. Maximum value of 1000.\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<ListDirectoryBucketsOutput > \n   <Buckets> \n      <Bucket> \n         < BucketRegion >string</BucketRegion > \n         < CreationDate >timestamp </CreationDate > \n         < Name>string</Name> \n      </Bucket> \n   </Buckets> \n   <ContinuationToken >string</ContinuationToken >\n</ListDirectoryBucketsOutput >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nListDirectoryBucketsOutput\nRoot level tag for the ListDirectoryBucketsOutput parameters.\nAmazon S3 API Version 2006-03-01 409Amazon Simple Storage Service API Reference\nRequired: Yes\nBuckets\nThe list of buckets owned by the requester.\nType: Array of Bucket data types\nContinuationToken\nIf ContinuationToken  was sent with the request, it is included in the response.", "You can use \nthe returned ContinuationToken  for pagination of the list response.\nType: String\nLength Constraints: Minimum length of 0.", "Maximum length of 1024.\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 410Amazon Simple Storage Service API Reference\nListMultipartUploads\nService: Amazon S3\nThis operation lists in-progress multipart uploads in a bucket. An in-progress multipart upload is \na multipart upload that has been initiated by the CreateMultipartUpload  request, but has not \nyet been completed or aborted.\nNote\nDirectory buckets - If multipart uploads in a directory bucket are in progress, you can't \ndelete the bucket until all the in-progress multipart uploads are aborted or completed. To \ndelete these in-progress multipart uploads, use the ListMultipartUploads  operation to \nlist the in-progress multipart uploads in the bucket and use the AbortMultipartUpload\noperation to abort all the in-progress multipart uploads.\nThe ListMultipartUploads  operation returns a maximum of 1,000 multipart uploads in the \nresponse. The limit of 1,000 multipart uploads is also the default value. You can further limit the \nnumber of uploads in a response by specifying the max-uploads  request parameter. If there \nare more than 1,000 multipart uploads that satisfy your ListMultipartUploads  request, \nthe response returns an IsTruncated  element with the value of true , a NextKeyMarker\nelement, and a NextUploadIdMarker  element. To list the remaining multipart uploads, you \nneed to make subsequent ListMultipartUploads  requests.", "In these requests, include two \nquery parameters: key-marker  and upload-id-marker . Set the value of key-marker  to the\nNextKeyMarker  value from the previous response.", "Similarly, set the value of upload-id-marker\nto the NextUploadIdMarker  value from the previous response.\nNote\nDirectory buckets - The upload-id-marker  element and the NextUploadIdMarker\nelement aren't supported by directory buckets.", "To list the additional multipart uploads, you \nonly need to set the value of key-marker  to the NextKeyMarker  value from the previous \nresponse.\nFor more information about multipart uploads, see Uploading Objects Using Multipart Upload in \nthe Amazon S3 User Guide .\nAmazon S3 API Version 2006-03-01 411Amazon Simple Storage Service API Reference\nNote\nDirectory buckets - For directory buckets, you must make requests for this API operation \nto the Zonal endpoint. These endpoints support virtual-hosted-style requests in the format\nhttps:// bucket_name .s3express- az_id.region.amazonaws.com/ key-name\n.", "Path-style requests are not supported.", "For more information, see Regional and Zonal \nendpoints  in the Amazon S3 User Guide .\nPermissions\n\u2022General purpose bucket permissions - For information about permissions required to use the \nmultipart upload API, see Multipart Upload and Permissions in the Amazon S3 User Guide .\n\u2022Directory bucket permissions - To grant access to this API operation on a directory \nbucket, we recommend that you use the CreateSession  API operation for session-based \nauthorization. Speci\ufb01cally, you grant the s3express:CreateSession  permission to the \ndirectory bucket in a bucket policy or an IAM identity-based policy.", "Then, you make the\nCreateSession  API call on the bucket to obtain a session token. With the session token in \nyour request header, you can make API requests to this operation. After the session token \nexpires, you make another CreateSession  API call to generate a new session token for \nuse. AWS CLI or SDKs create session and refresh the session token automatically to avoid \nservice interruptions when a session expires.", "For more information about authorization, see\nCreateSession .\nSorting of multipart uploads in response\n\u2022General purpose bucket - In the ListMultipartUploads  response, the multipart uploads \nare sorted based on two criteria:\n\u2022Key-based sorting - Multipart uploads are initially sorted in ascending order based on their \nobject keys.\n\u2022Time-based sorting - For uploads that share the same object key, they are further sorted in \nascending order based on the upload initiation time. Among uploads with the same key, the \none that was initiated \ufb01rst will appear before the ones that were initiated later.\n\u2022Directory bucket - In the ListMultipartUploads  response, the multipart uploads aren't \nsorted lexicographically based on the object keys.\nAmazon S3 API Version 2006-03-01 412Amazon Simple Storage Service API Reference\nHTTP Host header syntax\nDirectory buckets  - The HTTP Host header syntax is \nBucket_name .s3express- az_id.region.amazonaws.com .\nThe following operations are related to ListMultipartUploads :\n\u2022CreateMultipartUpload\n\u2022UploadPart\n\u2022CompleteMultipartUpload\n\u2022ListParts\n\u2022AbortMultipartUpload\nRequest Syntax\nGET /?uploads&delimiter= Delimiter &encoding-type= EncodingType &key-marker= KeyMarker &max-\nuploads= MaxUploads &prefix= Prefix&upload-id-marker= UploadIdMarker  HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nx-amz-request-payer: RequestPayer\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe name of the bucket to which the multipart upload was initiated.\nDirectory buckets - When you use this operation with a directory \nbucket, you must use virtual-hosted-style requests in the format \nBucket_name .s3express- az_id.region.amazonaws.com .", "Path-style requests are not \nsupported.", "Directory bucket names must be unique in the chosen Availability Zone.", "Bucket \nnames must follow the format  bucket_base_name --az-id--x-s3  (for example,  DOC-\nEXAMPLE-BUCKET --usw2-az1 --x-s3). For information about bucket naming restrictions, see\nDirectory bucket naming rules in the Amazon S3 User Guide .\nAccess points - When you use this action with an access point, you must provide the alias of the \naccess point in place of the bucket name or specify the access point ARN. When using the access \nAmazon S3 API Version 2006-03-01 413Amazon Simple Storage Service API Reference\npoint ARN, you must direct requests to the access point hostname. The access point hostname \ntakes the form AccessPointName-AccountId .s3-accesspoint.Region.amazonaws.com.", "When using \nthis action with an access point through the AWS SDKs, you provide the access point ARN in \nplace of the bucket name. For more information about access point ARNs, see Using access \npoints  in the Amazon S3 User Guide .\nNote\nAccess points and Object Lambda access points are not supported by directory buckets.\nS3 on Outposts  - When you use this action with Amazon S3 on Outposts, you must direct \nrequests to the S3 on Outposts hostname. The S3 on Outposts hostname takes the form \nAccessPointName -AccountId .outpostID .s3-outposts.", "Region.amazonaws.com .", "\nWhen you use this action with S3 on Outposts through the AWS SDKs, you provide the Outposts \naccess point ARN in place of the bucket name. For more information about S3 on Outposts \nARNs, see What is S3 on Outposts?", "in the Amazon S3 User Guide .\nRequired: Yes\ndelimiter\nCharacter you use to group keys.\nAll keys that contain the same string between the pre\ufb01x, if speci\ufb01ed, and the \ufb01rst occurrence \nof the delimiter after the pre\ufb01x are grouped under a single result element, CommonPrefixes .", "\nIf you don't specify the pre\ufb01x parameter, then the substring starts at the beginning of the key.", "\nThe keys that are grouped under CommonPrefixes  result element are not returned elsewhere \nin the response.\nNote\nDirectory buckets - For directory buckets, / is the only supported delimiter.\nencoding-type\nEncoding type used by Amazon S3 to encode the object keys in the response.", "Responses are \nencoded only in UTF-8.", "An object key can contain any Unicode character.", "However, the XML 1.0 \nAmazon S3 API Version 2006-03-01 414Amazon Simple Storage Service API Reference\nparser can't parse certain characters, such as characters with an ASCII value from 0 to 10. For \ncharacters that aren't supported in XML 1.0, you can add this parameter to request that Amazon \nS3 encode the keys in the response.", "For more information about characters to avoid in object \nkey names, see Object key naming guidelines.\nNote\nWhen using the URL encoding type, non-ASCII characters that are used in an object's \nkey name will be percent-encoded according to UTF-8 code values.", "For example, the \nobject test_file(3).png  will appear as test_file%283%29.png .\nValid Values: url\nkey-marker\nSpeci\ufb01es the multipart upload after which listing should begin.\nNote\n\u2022General purpose buckets - For general purpose buckets, key-marker  is an object \nkey. Together with upload-id-marker , this parameter speci\ufb01es the multipart \nupload after which listing should begin.\nIf upload-id-marker  is not speci\ufb01ed, only the keys lexicographically greater than \nthe speci\ufb01ed key-marker  will be included in the list.\nIf upload-id-marker  is speci\ufb01ed, any multipart uploads for a key equal to the key-\nmarker might also be included, provided those multipart uploads have upload IDs \nlexicographically greater than the speci\ufb01ed upload-id-marker .\n\u2022Directory buckets - For directory buckets, key-marker  is obfuscated and isn't a \nreal object key. The upload-id-marker  parameter isn't supported by directory \nbuckets.", "To list the additional multipart uploads, you only need to set the value of\nkey-marker  to the NextKeyMarker  value from the previous response.\nIn the ListMultipartUploads  response, the multipart uploads aren't sorted \nlexicographically based on the object keys.\nAmazon S3 API Version 2006-03-01 415Amazon Simple Storage Service API Reference\nmax-uploads\nSets the maximum number of multipart uploads, from 1 to 1,000, to return in the response \nbody.", "1,000 is the maximum number of uploads that can be returned in a response.\npre\ufb01x\nLists in-progress uploads only for those keys that begin with the speci\ufb01ed pre\ufb01x.", "You can use \npre\ufb01xes to separate a bucket into di\ufb00erent grouping of keys. (You can think of using prefix  to \nmake groups in the same way that you'd use a folder in a \ufb01le system.)\nNote\nDirectory buckets - For directory buckets, only pre\ufb01xes that end in a delimiter (/) are \nsupported.\nupload-id-marker\nTogether with key-marker, speci\ufb01es the multipart upload after which listing should begin. \nIf key-marker is not speci\ufb01ed, the upload-id-marker parameter is ignored. Otherwise, any \nmultipart uploads for a key equal to the key-marker might be included in the list only if they \nhave an upload ID lexicographically greater than the speci\ufb01ed upload-id-marker .\nNote\nThis functionality is not supported for directory buckets.\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match \nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nx-amz-request-payer\nCon\ufb01rms that the requester knows that they will be charged for the request. Bucket owners \nneed not specify this parameter in their requests.", "If either the source or destination S3 \nbucket has Requester Pays enabled, the requester will pay for corresponding charges to copy \nAmazon S3 API Version 2006-03-01 416Amazon Simple Storage Service API Reference\nthe object. For information about downloading objects from Requester Pays buckets, see\nDownloading Objects in Requester Pays Buckets in the Amazon S3 User Guide .\nNote\nThis functionality is not supported for directory buckets.\nValid Values: requester\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\nx-amz-request-charged: RequestCharged\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<ListMultipartUploadsResult > \n   <Bucket>string</Bucket> \n   <KeyMarker >string</KeyMarker > \n   <UploadIdMarker >string</UploadIdMarker > \n   <NextKeyMarker >string</NextKeyMarker > \n   <Prefix>string</Prefix> \n   <Delimiter >string</Delimiter > \n   <NextUploadIdMarker >string</NextUploadIdMarker > \n   <MaxUploads >integer</MaxUploads > \n   <IsTruncated >boolean</IsTruncated > \n   <Upload> \n      <ChecksumAlgorithm >string</ChecksumAlgorithm > \n      <Initiated >timestamp </Initiated > \n      <Initiator > \n         < DisplayName >string</DisplayName > \n         < ID>string</ID> \n      </ Initiator > \n      <Key>string</Key> \n      <Owner> \n         < DisplayName >string</DisplayName > \n         < ID>string</ID> \n      </ Owner> \n      <StorageClass >string</StorageClass > \nAmazon S3 API Version 2006-03-01 417Amazon Simple Storage Service API Reference\n      <UploadId >string</UploadId > \n   </Upload> \n   ...", "\n   <CommonPrefixes > \n      <Prefix>string</Prefix> \n   </CommonPrefixes > \n   ...", "\n   <EncodingType >string</EncodingType >\n</ListMultipartUploadsResult >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe response returns the following HTTP headers.\nx-amz-request-charged\nIf present, indicates that the requester was successfully charged for the request.\nNote\nThis functionality is not supported for directory buckets.\nValid Values: requester\nThe following data is returned in XML format by the service.\nListMultipartUploadsResult\nRoot level tag for the ListMultipartUploadsResult parameters.\nRequired: Yes\nBucket\nThe name of the bucket to which the multipart upload was initiated.", "Does not return the access \npoint ARN or access point alias if used.\nType: String\nAmazon S3 API Version 2006-03-01 418Amazon Simple Storage Service API Reference\nCommonPre\ufb01xes\nIf you specify a delimiter in the request, then the result returns each distinct key pre\ufb01x \ncontaining the delimiter in a CommonPrefixes  element.", "The distinct key pre\ufb01xes are returned \nin the Prefix  child element.\nNote\nDirectory buckets - For directory buckets, only pre\ufb01xes that end in a delimiter (/) are \nsupported.\nType: Array of CommonPre\ufb01x data types\nDelimiter\nContains the delimiter you speci\ufb01ed in the request. If you don't specify a delimiter in your \nrequest, this element is absent from the response.\nNote\nDirectory buckets - For directory buckets, / is the only supported delimiter.\nType: String\nEncodingType\nEncoding type used by Amazon S3 to encode object keys in the response.\nIf you specify the encoding-type  request parameter, Amazon S3 includes this element in the \nresponse, and returns encoded key name values in the following response elements:\nDelimiter , KeyMarker , Prefix , NextKeyMarker , Key.\nType: String\nValid Values: url\nIsTruncated\nIndicates whether the returned list of multipart uploads is truncated.", "A value of true indicates \nthat the list was truncated.", "The list can be truncated if the number of multipart uploads exceeds \nthe limit allowed or speci\ufb01ed by max uploads.\nAmazon S3 API Version 2006-03-01 419Amazon Simple Storage Service API Reference\nType: Boolean\nKeyMarker\nThe key at or after which the listing began.\nType: String\nMaxUploads\nMaximum number of multipart uploads that could have been included in the response.\nType: Integer\nNextKeyMarker\nWhen a list is truncated, this element speci\ufb01es the value that should be used for the key-marker \nrequest parameter in a subsequent request.\nType: String\nNextUploadIdMarker\nWhen a list is truncated, this element speci\ufb01es the value that should be used for the upload-\nid-marker  request parameter in a subsequent request.\nNote\nThis functionality is not supported for directory buckets.\nType: String\nPre\ufb01x\nWhen a pre\ufb01x is provided in the request, this \ufb01eld contains the speci\ufb01ed pre\ufb01x. The result \ncontains only keys starting with the speci\ufb01ed pre\ufb01x.\nNote\nDirectory buckets - For directory buckets, only pre\ufb01xes that end in a delimiter (/) are \nsupported.\nType: String\nAmazon S3 API Version 2006-03-01 420Amazon Simple Storage Service API Reference\nUpload\nContainer for elements related to a particular multipart upload.", "A response can contain zero or \nmore Upload  elements.\nType: Array of MultipartUpload data types\nUploadIdMarker\nTogether with key-marker, speci\ufb01es the multipart upload after which listing should begin. \nIf key-marker is not speci\ufb01ed, the upload-id-marker parameter is ignored. Otherwise, any \nmultipart uploads for a key equal to the key-marker might be included in the list only if they \nhave an upload ID lexicographically greater than the speci\ufb01ed upload-id-marker .\nNote\nThis functionality is not supported for directory buckets.\nType: String\nExamples\nSample Request for general purpose buckets\nThe following request lists three multipart uploads. The request speci\ufb01es the max-uploads\nrequest parameter to set the maximum number of multipart uploads to return in the response \nbody.\nGET /?uploads&max-uploads=3 HTTP/1.1\nHost: example-bucket.s3.<Region>.amazonaws.com\nDate: Mon, 1 Nov 2010 20:34:56 GMT\nAuthorization: authorization string \n          \nSample Response for general purpose buckets\nThe following sample response indicates that the multipart upload list was truncated and provides \nthe NextKeyMarker  and the NextUploadIdMarker  elements. You specify these values in \nyour subsequent requests to read the next set of multipart uploads.", "That is, send a subsequent \nAmazon S3 API Version 2006-03-01 421Amazon Simple Storage Service API Reference\nrequest specifying key-marker=my-movie2.m2ts  (value of the NextKeyMarker  element) and\nupload-id-marker=YW55IGlkZWEgd2h5IGVsdmluZydzIHVwbG9hZCBmYWlsZWQ  (value of the\nNextUploadIdMarker ).\nThe sample response also shows a case of two multipart uploads in progress with the same key \n(my-movie.m2ts ).", "That is, the response shows two uploads with the same key. This response \nshows the uploads sorted by key, and within each key the uploads are sorted in ascending order by \nthe time the multipart upload was initiated.\nHTTP/1.1 200 OK\nx-amz-id-2: Uuag1LuByRx9e6j5Onimru9pO4ZVKnJ2Qz7/C1NPcfTWAtRPfTaOFg==\nx-amz-request-id: 656c76696e6727732072657175657374\nDate: Mon, 1 Nov 2010 20:34:56 GMT\nContent-Length: 1330\nConnection: keep-alive\nServer: AmazonS3\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<ListMultipartUploadsResult xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n  <Bucket>bucket</Bucket> \n  <KeyMarker></KeyMarker> \n  <UploadIdMarker></UploadIdMarker> \n  <NextKeyMarker>my-movie.m2ts</NextKeyMarker> \n  <NextUploadIdMarker>YW55IGlkZWEgd2h5IGVsdmluZydzIHVwbG9hZCBmYWlsZWQ</\nNextUploadIdMarker> \n  <MaxUploads>3</MaxUploads> \n  <IsTruncated>true</IsTruncated> \n  <Upload> \n    <Key>my-divisor</Key> \n    <UploadId>XMgbGlrZSBlbHZpbmcncyBub3QgaGF2aW5nIG11Y2ggbHVjaw</UploadId> \n    <Initiator> \n      <ID>arn:aws:iam::111122223333:user/user1-11111a31-17b5-4fb7-9df5-b111111f13de</\nID> \n      <DisplayName>user1-11111a31-17b5-4fb7-9df5-b111111f13de</DisplayName> \n    </Initiator> \n    <Owner> \n      <ID>75aa57f09aa0c8caeab4f8c24e99d10f8e7faeebf76c078efc7c6caea54ba06a</ID> \n      <DisplayName>OwnerDisplayName</DisplayName> \n    </Owner> \n    <StorageClass>STANDARD</StorageClass> \n    <Initiated>2010-11-10T20:48:33.000Z</Initiated>   \n  </Upload> \nAmazon S3 API Version 2006-03-01 422Amazon Simple Storage Service API Reference\n  <Upload> \n    <Key>my-movie.m2ts</Key> \n    <UploadId>VXBsb2FkIElEIGZvciBlbHZpbmcncyBteS1tb3ZpZS5tMnRzIHVwbG9hZA</UploadId> \n    <Initiator> \n      <ID>b1d16700c70b0b05597d7acd6a3f92be</ID> \n      <DisplayName>InitiatorDisplayName</DisplayName> \n    </Initiator> \n    <Owner> \n      <ID>b1d16700c70b0b05597d7acd6a3f92be</ID> \n      <DisplayName>OwnerDisplayName</DisplayName> \n    </Owner> \n    <StorageClass>STANDARD</StorageClass> \n    <Initiated>2010-11-10T20:48:33.000Z</Initiated> \n  </Upload> \n  <Upload> \n    <Key>my-movie.m2ts</Key> \n    <UploadId>YW55IGlkZWEgd2h5IGVsdmluZydzIHVwbG9hZCBmYWlsZWQ</UploadId> \n    <Initiator> \n      <ID>arn:aws:iam::444455556666:user/user1-22222a31-17b5-4fb7-9df5-b222222f13de</\nID> \n      <DisplayName>user1-22222a31-17b5-4fb7-9df5-b222222f13de</DisplayName> \n    </Initiator> \n    <Owner> \n      <ID>b1d16700c70b0b05597d7acd6a3f92be</ID> \n      <DisplayName>OwnerDisplayName</DisplayName> \n    </Owner> \n    <StorageClass>STANDARD</StorageClass> \n    <Initiated>2010-11-10T20:49:33.000Z</Initiated> \n  </Upload>\n</ListMultipartUploadsResult> \n          \nSample Request for general purpose buckets: Using the delimiter and the pre\ufb01x parameters\nAssume you have a multipart upload in progress for the following keys in your bucket, example-\nbucket .\n\u2022photos/2006/January/sample.jpg\n\u2022photos/2006/February/sample.jpg\n\u2022photos/2006/March/sample.jpg\n\u2022videos/2006/March/sample.wmv\n\u2022sample.jpg\nAmazon S3 API Version 2006-03-01 423Amazon Simple Storage Service API Reference\nThe following list multipart upload request speci\ufb01es the delimiter parameter with value \"/\".\nGET /?uploads&delimiter=/ HTTP/1.1\nHost: example-bucket.s3.<Region>.amazonaws.com\nDate: Mon, 1 Nov 2010 20:34:56 GMT\nAuthorization: authorization string \n          \nSample Response for general purpose buckets\nThe following sample response lists multipart uploads on the speci\ufb01ed bucket, example-bucket .\nThe response returns multipart upload for the sample.jpg  key in an <Upload>  element.\nHowever, because all the other keys contain the speci\ufb01ed delimiter, a distinct substring, from \nthe beginning of the key to the \ufb01rst occurrence of the delimiter, from each of these keys is \nreturned in a <CommonPre\ufb01xes> element. The key substrings, photos/  and videos/  in the \n<CommonPre\ufb01xes> element, indicate that there are one or more in-progress multipart uploads \nwith these key pre\ufb01xes.\nThis is a useful scenario if you use key pre\ufb01xes for your objects to create a logical folder like \nstructure.", "In this case, you can interpret the result as the folders photos/  and videos/ have one \nor more multipart uploads in progress.\n<ListMultipartUploadsResult xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n  <Bucket>example-bucket</Bucket> \n  <KeyMarker/> \n  <UploadIdMarker/> \n  <NextKeyMarker>sample.jpg</NextKeyMarker> \n  \n <NextUploadIdMarker>Xgw4MJT6ZPAVxpY0SAuGN7q4uWJJM22ZYg1W99trdp4tpO88.PT6.MhO0w2E17eutfAvQfQWoajgE_W2gpcxQw--\n</NextUploadIdMarker> \n  <Delimiter>/</Delimiter> \n  <Prefix/> \n  <MaxUploads>1000</MaxUploads> \n  <IsTruncated>false</IsTruncated> \n  <Upload> \n    <Key>sample.jpg</Key> \nAmazon S3 API Version 2006-03-01 424Amazon Simple Storage Service API Reference\n   \n <UploadId>Agw4MJT6ZPAVxpY0SAuGN7q4uWJJM22ZYg1N99trdp4tpO88.PT6.MhO0w2E17eutfAvQfQWoajgE_W2gpcxQw--\n</UploadId> \n    <Initiator> \n      <ID>314133b66967d86f031c7249d1d9a80249109428335cd0ef1cdc487b4566cb1b</ID> \n      <DisplayName>string</DisplayName> \n    </Initiator> \n    <Owner> \n      <ID>314133b66967d86f031c7249d1d9a80249109428335cd0ef1cdc487b4566cb1b</ID> \n      <DisplayName>string</DisplayName> \n    </Owner> \n    <StorageClass>STANDARD</StorageClass> \n    <Initiated>2010-11-26T19:24:17.000Z</Initiated> \n  </Upload> \n  <CommonPrefixes> \n    <Prefix>photos/</Prefix> \n  </CommonPrefixes> \n  <CommonPrefixes> \n    <Prefix>videos/</Prefix> \n  </CommonPrefixes> \n  </ListMultipartUploadsResult> \n          \nSample Request for general purpose buckets\nIn addition to the delimiter parameter, you can \ufb01lter results by adding a pre\ufb01x parameter as shown \nin the following request.\nGET /?uploads&delimiter=/&prefix=photos/2006/ HTTP/1.1\nHost: example-bucket.s3.<Region>.amazonaws.com\nDate: Mon, 1 Nov 2010 20:34:56 GMT\nAuthorization: authorization string \n          \nSample Response for general purpose buckets\nIn this case, the response will include only multipart uploads for keys that start with the speci\ufb01ed \npre\ufb01x. The value returned in the <CommonPre\ufb01xes> element is a substring from the beginning of \nthe key to the \ufb01rst occurrence of the speci\ufb01ed delimiter after the pre\ufb01x.\nAmazon S3 API Version 2006-03-01 425Amazon Simple Storage Service API Reference\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<ListMultipartUploadsResult xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n  <Bucket>example-bucket</Bucket> \n  <KeyMarker/> \n  <UploadIdMarker/> \n  <NextKeyMarker/> \n  <NextUploadIdMarker/> \n  <Delimiter>/</Delimiter> \n  <Prefix>photos/2006/</Prefix> \n  <MaxUploads>1000</MaxUploads> \n  <IsTruncated>false</IsTruncated> \n  <CommonPrefixes> \n    <Prefix>photos/2006/February/</Prefix> \n  </CommonPrefixes> \n  <CommonPrefixes> \n    <Prefix>photos/2006/January/</Prefix> \n  </CommonPrefixes> \n  <CommonPrefixes> \n    <Prefix>photos/2006/March/</Prefix> \n  </CommonPrefixes>\n</ListMultipartUploadsResult> \n          \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 426Amazon Simple Storage Service API Reference\nListObjects\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nReturns some or all (up to 1,000) of the objects in a bucket. You can use the request parameters as \nselection criteria to return a subset of the objects in a bucket.", "A 200 OK response can contain valid \nor invalid XML.", "Be sure to design your application to parse the contents of the response and handle \nit appropriately.\nImportant\nThis action has been revised.", "We recommend that you use the newer version,\nListObjectsV2, when developing applications.", "For backward compatibility, Amazon S3 \ncontinues to support ListObjects .\nThe following operations are related to ListObjects :\n\u2022ListObjectsV2\n\u2022GetObject\n\u2022PutObject\n\u2022CreateBucket\n\u2022ListBuckets\nRequest Syntax\nGET /?delimiter= Delimiter &encoding-type= EncodingType &marker= Marker&max-\nkeys=MaxKeys&prefix= Prefix HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-request-payer: RequestPayer\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nx-amz-optional-object-attributes: OptionalObjectAttributes\nAmazon S3 API Version 2006-03-01 427Amazon Simple Storage Service API Reference\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe name of the bucket containing the objects.\nDirectory buckets - When you use this operation with a directory \nbucket, you must use virtual-hosted-style requests in the format \nBucket_name .s3express- az_id.region.amazonaws.com .", "Path-style requests are not \nsupported.", "Directory bucket names must be unique in the chosen Availability Zone.", "Bucket \nnames must follow the format  bucket_base_name --az-id--x-s3  (for example,  DOC-\nEXAMPLE-BUCKET --usw2-az1 --x-s3). For information about bucket naming restrictions, see\nDirectory bucket naming rules in the Amazon S3 User Guide .\nAccess points - When you use this action with an access point, you must provide the alias of the \naccess point in place of the bucket name or specify the access point ARN.", "When using the access \npoint ARN, you must direct requests to the access point hostname.", "The access point hostname \ntakes the form AccessPointName-AccountId .s3-accesspoint.Region.amazonaws.com.", "When using \nthis action with an access point through the AWS SDKs, you provide the access point ARN in \nplace of the bucket name. For more information about access point ARNs, see Using access \npoints  in the Amazon S3 User Guide .\nNote\nAccess points and Object Lambda access points are not supported by directory buckets.\nS3 on Outposts  - When you use this action with Amazon S3 on Outposts, you must direct \nrequests to the S3 on Outposts hostname. The S3 on Outposts hostname takes the form \nAccessPointName -AccountId .outpostID .s3-outposts.", "Region.amazonaws.com .", "\nWhen you use this action with S3 on Outposts through the AWS SDKs, you provide the Outposts \naccess point ARN in place of the bucket name. For more information about S3 on Outposts \nARNs, see What is S3 on Outposts?", "in the Amazon S3 User Guide .\nRequired: Yes\ndelimiter\nA delimiter is a character that you use to group keys.\nAmazon S3 API Version 2006-03-01 428Amazon Simple Storage Service API Reference\nencoding-type\nEncoding type used by Amazon S3 to encode the object keys in the response.", "Responses are \nencoded only in UTF-8.", "An object key can contain any Unicode character.", "However, the XML 1.0 \nparser can't parse certain characters, such as characters with an ASCII value from 0 to 10.", "For \ncharacters that aren't supported in XML 1.0, you can add this parameter to request that Amazon \nS3 encode the keys in the response.", "For more information about characters to avoid in object \nkey names, see Object key naming guidelines.\nNote\nWhen using the URL encoding type, non-ASCII characters that are used in an object's \nkey name will be percent-encoded according to UTF-8 code values.", "For example, the \nobject test_file(3).png  will appear as test_file%283%29.png .\nValid Values: url\nmarker\nMarker is where you want Amazon S3 to start listing from. Amazon S3 starts listing after this \nspeci\ufb01ed key.", "Marker can be any key in the bucket.\nmax-keys\nSets the maximum number of keys returned in the response.", "By default, the action returns up to \n1,000 key names.", "The response might contain fewer keys but will never contain more.\npre\ufb01x\nLimits the response to keys that begin with the speci\ufb01ed pre\ufb01x.\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match \nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nx-amz-optional-object-attributes\nSpeci\ufb01es the optional \ufb01elds that you want returned in the response.", "Fields that you do not \nspecify are not returned.\nAmazon S3 API Version 2006-03-01 429Amazon Simple Storage Service API Reference\nValid Values: RestoreStatus\nx-amz-request-payer\nCon\ufb01rms that the requester knows that she or he will be charged for the list objects request.", "\nBucket owners need not specify this parameter in their requests.\nValid Values: requester\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\nx-amz-request-charged: RequestCharged\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<ListBucketResult > \n   <IsTruncated >boolean</IsTruncated > \n   <Marker>string</Marker> \n   <NextMarker >string</NextMarker > \n   <Contents > \n      <ChecksumAlgorithm >string</ChecksumAlgorithm > \n      ...", "\n      <ETag>string</ETag> \n      <Key>string</Key> \n      <LastModified >timestamp </LastModified > \n      <Owner> \n         < DisplayName >string</DisplayName > \n         < ID>string</ID> \n      </ Owner> \n      <RestoreStatus > \n         < IsRestoreInProgress >boolean</IsRestoreInProgress > \n         < RestoreExpiryDate >timestamp </RestoreExpiryDate > \n      </ RestoreStatus > \n      <Size>long</Size> \n      <StorageClass >string</StorageClass > \n   </Contents > \n   ...", "\n   <Name>string</Name> \n   <Prefix>string</Prefix> \n   <Delimiter >string</Delimiter > \nAmazon S3 API Version 2006-03-01 430Amazon Simple Storage Service API Reference\n   <MaxKeys>integer</MaxKeys> \n   <CommonPrefixes > \n      <Prefix>string</Prefix> \n   </CommonPrefixes > \n   ... \n   <EncodingType >string</EncodingType >\n</ListBucketResult >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe response returns the following HTTP headers.\nx-amz-request-charged\nIf present, indicates that the requester was successfully charged for the request.\nNote\nThis functionality is not supported for directory buckets.\nValid Values: requester\nThe following data is returned in XML format by the service.\nListBucketResult\nRoot level tag for the ListBucketResult parameters.\nRequired: Yes\nCommonPre\ufb01xes\nAll of the keys (up to 1,000) rolled up in a common pre\ufb01x count as a single return when \ncalculating the number of returns.\nA response can contain CommonPrefixes  only if you specify a delimiter.\nCommonPrefixes  contains all (if there are any) keys between Prefix and the next occurrence \nof the string speci\ufb01ed by the delimiter.\nAmazon S3 API Version 2006-03-01 431Amazon Simple Storage Service API Reference\nCommonPrefixes  lists keys that act like subdirectories in the directory speci\ufb01ed by Prefix .\nFor example, if the pre\ufb01x is notes/  and the delimiter is a slash ( /), as in notes/summer/july , \nthe common pre\ufb01x is notes/summer/ .", "All of the keys that roll up into a common pre\ufb01x count \nas a single return when calculating the number of returns.\nType: Array of CommonPre\ufb01x data types\nContents\nMetadata about each object returned.\nType: Array of Object data types\nDelimiter\nCauses keys that contain the same string between the pre\ufb01x and the \ufb01rst occurrence of the \ndelimiter to be rolled up into a single result element in the CommonPrefixes  collection. These \nrolled-up keys are not returned elsewhere in the response.", "Each rolled-up result counts as only \none return against the MaxKeys  value.\nType: String\nEncodingType\nEncoding type used by Amazon S3 to encode the object keys in the response.", "Responses are \nencoded only in UTF-8.", "An object key can contain any Unicode character.", "However, the XML 1.0 \nparser can't parse certain characters, such as characters with an ASCII value from 0 to 10.", "For \ncharacters that aren't supported in XML 1.0, you can add this parameter to request that Amazon \nS3 encode the keys in the response.", "For more information about characters to avoid in object \nkey names, see Object key naming guidelines.\nNote\nWhen using the URL encoding type, non-ASCII characters that are used in an object's \nkey name will be percent-encoded according to UTF-8 code values.", "For example, the \nobject test_file(3).png  will appear as test_file%283%29.png .\nType: String\nValid Values: url\nAmazon S3 API Version 2006-03-01 432Amazon Simple Storage Service API Reference\nIsTruncated\nA \ufb02ag that indicates whether Amazon S3 returned all of the results that satis\ufb01ed the search \ncriteria.\nType: Boolean\nMarker\nIndicates where in the bucket listing begins.", "Marker is included in the response if it was sent \nwith the request.\nType: String\nMaxKeys\nThe maximum number of keys returned in the response body.\nType: Integer\nName\nThe bucket name.\nType: String\nNextMarker\nWhen the response is truncated (the IsTruncated  element value in the response is true), you \ncan use the key name in this \ufb01eld as the marker parameter in the subsequent request to get \nthe next set of objects.", "Amazon S3 lists objects in alphabetical order.\nNote\nThis element is returned only if you have the delimiter  request parameter speci\ufb01ed. \nIf the response does not include the NextMarker  element and it is truncated, you can \nuse the value of the last Key element in the response as the marker  parameter in the \nsubsequent request to get the next set of object keys.\nType: String\nPre\ufb01x\nKeys that begin with the indicated pre\ufb01x.\nAmazon S3 API Version 2006-03-01 433Amazon Simple Storage Service API Reference\nType: String\nErrors\nNoSuchBucket\nThe speci\ufb01ed bucket does not exist.\nHTTP Status Code: 404\nExamples\nSample Request\nThis request returns the objects in BucketName .\nGET / HTTP/1.1\nHost: BucketName.s3.<Region>.amazonaws.com\nDate: Wed, 12 Oct 2009 17:50:00 GMT\nAuthorization: authorization string\nContent-Type: text/plain    \n          \nSample Response\nThis example illustrates one usage of ListObjects.\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<ListBucketResult xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n    <Name>bucket</Name> \n    <Prefix/> \n    <Marker/> \n    <MaxKeys>1000</MaxKeys> \n    <IsTruncated>false</IsTruncated> \n    <Contents> \n        <Key>my-image.jpg</Key> \n        <LastModified>2009-10-12T17:50:30.000Z</LastModified> \n        <ETag>\"fba9dede5f27731c9771645a39863328\"</ETag> \n        <Size>434234</Size> \n        <StorageClass>STANDARD</StorageClass> \nAmazon S3 API Version 2006-03-01 434Amazon Simple Storage Service API Reference\n        <Owner> \n            <ID>75aa57f09aa0c8caeab4f8c24e99d10f8e7faeebf76c078efc7c6caea54ba06a</ID> \n            <DisplayName>mtd@amazon.com</DisplayName> \n        </Owner> \n    </Contents> \n    <Contents> \n       <Key>my-third-image.jpg</Key> \n         <LastModified>2009-10-12T17:50:30.000Z</LastModified> \n         <ETag>\"1b2cf535f27731c974343645a3985328\"</ETag> \n         <Size>64994</Size> \n         <StorageClass>STANDARD_IA</StorageClass> \n         <Owner> \n            <ID>75aa57f09aa0c8caeab4f8c24e99d10f8e7faeebf76c078efc7c6caea54ba06a</ID> \n            <DisplayName>mtd@amazon.com</DisplayName> \n        </Owner> \n    </Contents>\n</ListBucketResult> \n          \nSample Request: Using request parameters\nThis example lists up to 40 keys in the quotes bucket that start with N and occur lexicographically \nafter Ned.\nGET /?prefix=N&marker=Ned&max-keys=40 HTTP/1.1\nHost: quotes.s3.<Region>.amazonaws.com\nDate: Wed, 01 Mar  2006 12:00:00 GMT\nAuthorization: authorization string \n          \nSample Response\nThis example illustrates one usage of ListObjects.\nHTTP/1.1 200 OK\nx-amz-id-2: gyB+3jRPnrkN98ZajxHXr3u7EFM67bNgSAxexeEHndCX/7GRnfTXxReKUQF28IfP\nx-amz-request-id: 3B3C7C725673C630\nDate: Wed, 01 Mar  2006 12:00:00 GMT\nContent-Type: application/xml\nContent-Length: 302\nAmazon S3 API Version 2006-03-01 435Amazon Simple Storage Service API Reference\nConnection: close\nServer: AmazonS3\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<ListBucketResult xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n  <Name>quotes</Name> \n  <Prefix>N</Prefix> \n  <Marker>Ned</Marker> \n  <MaxKeys>40</MaxKeys> \n  <IsTruncated>false</IsTruncated> \n  <Contents> \n    <Key>Nelson</Key> \n    <LastModified>2006-01-01T12:00:00.000Z</LastModified> \n    <ETag>\"828ef3fdfa96f00ad9f27c383fc9ac7f\"</ETag> \n    <Size>5</Size> \n    <StorageClass>STANDARD</StorageClass> \n    <Owner> \n      <ID>bcaf161ca5fb16fd081034f</ID> \n      <DisplayName>webfile</DisplayName> \n     </Owner> \n  </Contents> \n  <Contents> \n    <Key>Neo</Key> \n    <LastModified>2006-01-01T12:00:00.000Z</LastModified> \n    <ETag>\"828ef3fdfa96f00ad9f27c383fc9ac7f\"</ETag> \n    <Size>4</Size> \n    <StorageClass>STANDARD</StorageClass> \n     <Owner> \n      <ID>bcaf1ffd86a5fb16fd081034f</ID> \n      <DisplayName>webfile</DisplayName> \n    </Owner> \n </Contents>\n</ListBucketResult> \n          \nSample Request: Using a pre\ufb01x and delimiter\nFor this example, we assume that you have the following keys in your bucket:\n\u2022sample.jpg\n\u2022photos/2006/January/sample.jpg\n\u2022photos/2006/February/sample2.jpg\nAmazon S3 API Version 2006-03-01 436Amazon Simple Storage Service API Reference\n\u2022photos/2006/February/sample3.jpg\n\u2022photos/2006/February/sample4.jpg\nThe following GET request speci\ufb01es the delimiter  parameter with a value of /.\nGET /?delimiter=/ HTTP/1.1\nHost: example-bucket.s3.<Region>.amazonaws.com\nDate: Wed, 01 Mar  2006 12:00:00 GMT\nAuthorization: authorization string    \n          \nSample Response\nThe key sample.jpg  does not contain the delimiter character, and Amazon S3 returns it in the\nContents  element in the response.", "However, all of the other keys contain the delimiter character.", "\nAmazon S3 groups these keys and returns a single CommonPrefixes  element with the Prefix\nvalue photos/, which is a substring from the beginning of these keys to the \ufb01rst occurrence of the \nspeci\ufb01ed delimiter.\n<ListBucketResult xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n  <Name>example-bucket</Name> \n  <Prefix></Prefix> \n  <Marker></Marker> \n  <MaxKeys>1000</MaxKeys> \n  <Delimiter>/</Delimiter> \n  <IsTruncated>false</IsTruncated> \n  <Contents> \n    <Key>sample.jpg</Key> \n    <LastModified>2011-02-26T01:56:20.000Z</LastModified> \n    <ETag>\"bf1d737a4d46a19f3bced6905cc8b902\"</ETag> \n    <Size>142863</Size> \n    <Owner> \n      <ID>canonical-user-id</ID> \n      <DisplayName>display-name</DisplayName> \n    </Owner> \n    <StorageClass>STANDARD</StorageClass> \n  </Contents> \n  <CommonPrefixes> \nAmazon S3 API Version 2006-03-01 437Amazon Simple Storage Service API Reference\n    <Prefix>photos/</Prefix> \n  </CommonPrefixes>\n</ListBucketResult>   \n          \nSample Request\nThe following GET request speci\ufb01es the delimiter  parameter with the value /, and the prefix\nparameter with the value photos/2006/ .\nGET /?prefix=photos/2006/&delimiter=/ HTTP/1.1\nHost: example-bucket.s3.<Region>.amazonaws.com\nDate: Wed, 01 Mar  2006 12:00:00 GMT\nAuthorization: authorization string \n          \nSample Response\nIn response, Amazon S3 returns only the keys that start with the speci\ufb01ed pre\ufb01x. Amazon S3 uses \nthe delimiter character to group keys that contain the same substring until the \ufb01rst occurrence \nof the delimiter character after the speci\ufb01ed pre\ufb01x. For each such key group, Amazon S3 returns \none CommonPrefixes  element in the response.", "The keys grouped under this CommonPrefixes\nelement are not returned elsewhere in the response.", "The value returned in the CommonPrefixes\nelement is a substring that starts at the beginning of the key and ends at the \ufb01rst occurrence of the \nspeci\ufb01ed delimiter after the pre\ufb01x.\n<ListBucketResult xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n  <Name>example-bucket</Name> \n  <Prefix>photos/2006/</Prefix> \n  <Marker></Marker> \n  <MaxKeys>1000</MaxKeys> \n  <Delimiter>/</Delimiter> \n  <IsTruncated>false</IsTruncated> \n  <CommonPrefixes> \n    <Prefix>photos/2006/February/</Prefix> \n  </CommonPrefixes> \nAmazon S3 API Version 2006-03-01 438Amazon Simple Storage Service API Reference\n  <CommonPrefixes> \n    <Prefix>photos/2006/January/</Prefix> \n  </CommonPrefixes>\n</ListBucketResult> \n          \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 439Amazon Simple Storage Service API Reference\nListObjectsV2\nService: Amazon S3\nReturns some or all (up to 1,000) of the objects in a bucket with each request. You can use the \nrequest parameters as selection criteria to return a subset of the objects in a bucket.", "A 200 OK\nresponse can contain valid or invalid XML.", "Make sure to design your application to parse the \ncontents of the response and handle it appropriately.", "For more information about listing objects, \nsee Listing object keys programmatically in the Amazon S3 User Guide .", "To get a list of your buckets, \nsee ListBuckets.\nNote\n\u2022General purpose bucket - For general purpose buckets, ListObjectsV2  doesn't return \npre\ufb01xes that are related only to in-progress multipart uploads.\n\u2022Directory buckets - For directory buckets, ListObjectsV2  response includes the \npre\ufb01xes that are related only to in-progress multipart uploads.\n\u2022Directory buckets - For directory buckets, you must make requests for this API operation \nto the Zonal endpoint.", "These endpoints support virtual-hosted-style requests in the \nformat https:// bucket_name .s3express- az_id.region.amazonaws.com/ key-\nname .", "Path-style requests are not supported.", "For more information, see Regional and \nZonal endpoints in the Amazon S3 User Guide .\nPermissions\n\u2022General purpose bucket permissions - To use this operation, you must have READ access to \nthe bucket.", "You must have permission to perform the s3:ListBucket  action.", "The bucket \nowner has this permission by default and can grant this permission to others.", "For more \ninformation about permissions, see Permissions Related to Bucket Subresource Operations\nand Managing Access Permissions to Your Amazon S3 Resources in the Amazon S3 User Guide .\n\u2022Directory bucket permissions - To grant access to this API operation on a directory \nbucket, we recommend that you use the CreateSession  API operation for session-based \nauthorization. Speci\ufb01cally, you grant the s3express:CreateSession  permission to the \ndirectory bucket in a bucket policy or an IAM identity-based policy.", "Then, you make the\nCreateSession  API call on the bucket to obtain a session token. With the session token in \nyour request header, you can make API requests to this operation.", "After the session token \nexpires, you make another CreateSession  API call to generate a new session token for \nAmazon S3 API Version 2006-03-01 440Amazon Simple Storage Service API Reference\nuse.", "AWS CLI or SDKs create session and refresh the session token automatically to avoid \nservice interruptions when a session expires.", "For more information about authorization, see\nCreateSession .\nSorting order of returned objects\n\u2022General purpose bucket - For general purpose buckets, ListObjectsV2  returns objects in \nlexicographical order based on their key names.\n\u2022Directory bucket - For directory buckets, ListObjectsV2  does not return objects in \nlexicographical order.\nHTTP Host header syntax\nDirectory buckets  - The HTTP Host header syntax is \nBucket_name .s3express- az_id.region.amazonaws.com .\nImportant\nThis section describes the latest revision of this action.", "We recommend that you use this \nrevised API operation for application development.", "For backward compatibility, Amazon S3 \ncontinues to support the prior version of this API operation, ListObjects.\nThe following operations are related to ListObjectsV2 :\n\u2022GetObject\n\u2022PutObject\n\u2022CreateBucket\nRequest Syntax\nGET /?list-type=2&continuation-token= ContinuationToken &delimiter= Delimiter &encoding-\ntype=EncodingType &fetch-owner= FetchOwner &max-keys= MaxKeys&prefix= Prefix&start-\nafter=StartAfter  HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-request-payer: RequestPayer\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nx-amz-optional-object-attributes: OptionalObjectAttributes\nAmazon S3 API Version 2006-03-01 441Amazon Simple Storage Service API Reference\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nDirectory buckets - When you use this operation with a directory \nbucket, you must use virtual-hosted-style requests in the format \nBucket_name .s3express- az_id.region.amazonaws.com .", "Path-style requests are not \nsupported.", "Directory bucket names must be unique in the chosen Availability Zone.", "Bucket \nnames must follow the format  bucket_base_name --az-id--x-s3  (for example,  DOC-\nEXAMPLE-BUCKET --usw2-az1 --x-s3). For information about bucket naming restrictions, see\nDirectory bucket naming rules in the Amazon S3 User Guide .\nAccess points - When you use this action with an access point, you must provide the alias of the \naccess point in place of the bucket name or specify the access point ARN.", "When using the access \npoint ARN, you must direct requests to the access point hostname.", "The access point hostname \ntakes the form AccessPointName-AccountId .s3-accesspoint.Region.amazonaws.com.", "When using \nthis action with an access point through the AWS SDKs, you provide the access point ARN in \nplace of the bucket name. For more information about access point ARNs, see Using access \npoints  in the Amazon S3 User Guide .\nNote\nAccess points and Object Lambda access points are not supported by directory buckets.\nS3 on Outposts  - When you use this action with Amazon S3 on Outposts, you must direct \nrequests to the S3 on Outposts hostname. The S3 on Outposts hostname takes the form \nAccessPointName -AccountId .outpostID .s3-outposts.", "Region.amazonaws.com .", "\nWhen you use this action with S3 on Outposts through the AWS SDKs, you provide the Outposts \naccess point ARN in place of the bucket name. For more information about S3 on Outposts \nARNs, see What is S3 on Outposts?", "in the Amazon S3 User Guide .\nRequired: Yes\nAmazon S3 API Version 2006-03-01 442Amazon Simple Storage Service API Reference\ncontinuation-token\nContinuationToken  indicates to Amazon S3 that the list is being continued on this bucket \nwith a token.", "ContinuationToken  is obfuscated and is not a real key.", "You can use this\nContinuationToken  for pagination of the list results.\ndelimiter\nA delimiter is a character that you use to group keys.\nNote\n\u2022Directory buckets - For directory buckets, / is the only supported delimiter.\n\u2022Directory buckets  - When you query ListObjectsV2  with a delimiter during in-\nprogress multipart uploads, the CommonPrefixes  response parameter contains \nthe pre\ufb01xes that are associated with the in-progress multipart uploads.", "For more \ninformation about multipart uploads, see Multipart Upload Overview in the Amazon \nS3 User Guide .\nencoding-type\nEncoding type used by Amazon S3 to encode the object keys in the response.", "Responses are \nencoded only in UTF-8.", "An object key can contain any Unicode character.", "However, the XML 1.0 \nparser can't parse certain characters, such as characters with an ASCII value from 0 to 10.", "For \ncharacters that aren't supported in XML 1.0, you can add this parameter to request that Amazon \nS3 encode the keys in the response.", "For more information about characters to avoid in object \nkey names, see Object key naming guidelines.\nNote\nWhen using the URL encoding type, non-ASCII characters that are used in an object's \nkey name will be percent-encoded according to UTF-8 code values.", "For example, the \nobject test_file(3).png  will appear as test_file%283%29.png .\nValid Values: url\nAmazon S3 API Version 2006-03-01 443Amazon Simple Storage Service API Reference\nfetch-owner\nThe owner \ufb01eld is not present in ListObjectsV2  by default.", "If you want to return the owner \n\ufb01eld with each key in the result, then set the FetchOwner  \ufb01eld to true .\nNote\nDirectory buckets - For directory buckets, the bucket owner is returned as the object \nowner for all objects.\nmax-keys\nSets the maximum number of keys returned in the response.", "By default, the action returns up to \n1,000 key names.", "The response might contain fewer keys but will never contain more.\npre\ufb01x\nLimits the response to keys that begin with the speci\ufb01ed pre\ufb01x.\nNote\nDirectory buckets - For directory buckets, only pre\ufb01xes that end in a delimiter (/) are \nsupported.\nstart-after\nStartAfter is where you want Amazon S3 to start listing from. Amazon S3 starts listing after this \nspeci\ufb01ed key.", "StartAfter can be any key in the bucket.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner.", "If the account ID that you provide does not match \nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nAmazon S3 API Version 2006-03-01 444Amazon Simple Storage Service API Reference\nx-amz-optional-object-attributes\nSpeci\ufb01es the optional \ufb01elds that you want returned in the response.", "Fields that you do not \nspecify are not returned.\nNote\nThis functionality is not supported for directory buckets.\nValid Values: RestoreStatus\nx-amz-request-payer\nCon\ufb01rms that the requester knows that she or he will be charged for the list objects request in \nV2 style. Bucket owners need not specify this parameter in their requests.\nNote\nThis functionality is not supported for directory buckets.\nValid Values: requester\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\nx-amz-request-charged: RequestCharged\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<ListBucketResult > \n   <IsTruncated >boolean</IsTruncated > \n   <Contents > \n      <ChecksumAlgorithm >string</ChecksumAlgorithm > \n      ...", "\n      <ETag>string</ETag> \n      <Key>string</Key> \n      <LastModified >timestamp </LastModified > \nAmazon S3 API Version 2006-03-01 445Amazon Simple Storage Service API Reference\n      <Owner> \n         < DisplayName >string</DisplayName > \n         < ID>string</ID> \n      </ Owner> \n      <RestoreStatus > \n         < IsRestoreInProgress >boolean</IsRestoreInProgress > \n         < RestoreExpiryDate >timestamp </RestoreExpiryDate > \n      </ RestoreStatus > \n      <Size>long</Size> \n      <StorageClass >string</StorageClass > \n   </Contents > \n   ...", "\n   <Name>string</Name> \n   <Prefix>string</Prefix> \n   <Delimiter >string</Delimiter > \n   <MaxKeys>integer</MaxKeys> \n   <CommonPrefixes > \n      <Prefix>string</Prefix> \n   </CommonPrefixes > \n   ...", "\n   <EncodingType >string</EncodingType > \n   <KeyCount >integer</KeyCount > \n   <ContinuationToken >string</ContinuationToken > \n   <NextContinuationToken >string</NextContinuationToken > \n   <StartAfter >string</StartAfter >\n</ListBucketResult >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe response returns the following HTTP headers.\nx-amz-request-charged\nIf present, indicates that the requester was successfully charged for the request.\nNote\nThis functionality is not supported for directory buckets.\nValid Values: requester\nAmazon S3 API Version 2006-03-01 446Amazon Simple Storage Service API Reference\nThe following data is returned in XML format by the service.\nListBucketResult\nRoot level tag for the ListBucketResult parameters.\nRequired: Yes\nCommonPre\ufb01xes\nAll of the keys (up to 1,000) that share the same pre\ufb01x are grouped together.", "When counting \nthe total numbers of returns by this API operation, this group of keys is considered as one item.\nA response can contain CommonPrefixes  only if you specify a delimiter.\nCommonPrefixes  contains all (if there are any) keys between Prefix and the next occurrence \nof the string speci\ufb01ed by a delimiter.\nCommonPrefixes  lists keys that act like subdirectories in the directory speci\ufb01ed by Prefix .\nFor example, if the pre\ufb01x is notes/  and the delimiter is a slash ( /) as in notes/summer/july , \nthe common pre\ufb01x is notes/summer/ .", "All of the keys that roll up into a common pre\ufb01x count \nas a single return when calculating the number of returns.\nNote\n\u2022Directory buckets - For directory buckets, only pre\ufb01xes that end in a delimiter (/) are \nsupported.\n\u2022Directory buckets  - When you query ListObjectsV2  with a delimiter during in-\nprogress multipart uploads, the CommonPrefixes  response parameter contains \nthe pre\ufb01xes that are associated with the in-progress multipart uploads.", "For more \ninformation about multipart uploads, see Multipart Upload Overview in the Amazon \nS3 User Guide .\nType: Array of CommonPre\ufb01x data types\nContents\nMetadata about each object returned.\nType: Array of Object data types\nAmazon S3 API Version 2006-03-01 447Amazon Simple Storage Service API Reference\nContinuationToken\nIf ContinuationToken  was sent with the request, it is included in the response.", "You can \nuse the returned ContinuationToken  for pagination of the list response. You can use this\nContinuationToken  for pagination of the list results.\nType: String\nDelimiter\nCauses keys that contain the same string between the prefix and the \ufb01rst occurrence of the \ndelimiter to be rolled up into a single result element in the CommonPrefixes  collection.", "These \nrolled-up keys are not returned elsewhere in the response.", "Each rolled-up result counts as only \none return against the MaxKeys  value.\nNote\nDirectory buckets - For directory buckets, / is the only supported delimiter.\nType: String\nEncodingType\nEncoding type used by Amazon S3 to encode object key names in the XML response.\nIf you specify the encoding-type  request parameter, Amazon S3 includes this element in the \nresponse, and returns encoded key name values in the following response elements:\nDelimiter, Prefix, Key,  and StartAfter .\nType: String\nValid Values: url\nIsTruncated\nSet to false if all of the results were returned.", "Set to true if more keys are available to return.", "\nIf the number of results exceeds that speci\ufb01ed by MaxKeys, all of the results might not be \nreturned.\nType: Boolean\nAmazon S3 API Version 2006-03-01 448Amazon Simple Storage Service API Reference\nKeyCount\nKeyCount  is the number of keys returned with this request.", "KeyCount  will always be less than \nor equal to the MaxKeys \ufb01eld. For example, if you ask for 50 keys, your result will include 50 \nkeys or fewer.\nType: Integer\nMaxKeys\nSets the maximum number of keys returned in the response. By default, the action returns up to \n1,000 key names.", "The response might contain fewer keys but will never contain more.\nType: Integer\nName\nThe bucket name.\nType: String\nNextContinuationToken\nNextContinuationToken  is sent when isTruncated  is true, which means there are more \nkeys in the bucket that can be listed.", "The next list requests to Amazon S3 can be continued with \nthis NextContinuationToken . NextContinuationToken  is obfuscated and is not a real key\nType: String\nPre\ufb01x\nKeys that begin with the indicated pre\ufb01x.\nNote\nDirectory buckets - For directory buckets, only pre\ufb01xes that end in a delimiter (/) are \nsupported.\nType: String\nStartAfter\nIf StartAfter was sent with the request, it is included in the response.\nAmazon S3 API Version 2006-03-01 449Amazon Simple Storage Service API Reference\nNote\nThis functionality is not supported for directory buckets.\nType: String\nErrors\nNoSuchBucket\nThe speci\ufb01ed bucket does not exist.\nHTTP Status Code: 404\nExamples\nSample Request for general purpose buckets: Listing keys\nThis request returns the objects in bucket. The request speci\ufb01es the list-type  parameter, which \nindicates version 2 of the API operation.\nGET /?list-type=2 HTTP/1.1\nHost: bucket.s3.<Region>.amazonaws.com\nx-amz-date: 20160430T233541Z\nAuthorization: authorization string\nContent-Type: text/plain \n          \nSample Response for general purpose buckets\nThis example illustrates one usage of ListObjectsV2.\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<ListBucketResult xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n    <Name>bucket</Name> \n    <Prefix/> \nAmazon S3 API Version 2006-03-01 450Amazon Simple Storage Service API Reference\n    <KeyCount>205</KeyCount> \n    <MaxKeys>1000</MaxKeys> \n    <IsTruncated>false</IsTruncated> \n    <Contents> \n        <Key>my-image.jpg</Key> \n        <LastModified>2009-10-12T17:50:30.000Z</LastModified> \n        <ETag>\"fba9dede5f27731c9771645a39863328\"</ETag> \n        <Size>434234</Size> \n        <StorageClass>STANDARD</StorageClass> \n    </Contents> \n    <Contents> \n       ... \n    </Contents> \n    ...\n</ListBucketResult> \n          \nSample Request for general purpose buckets: Listing keys using the max-keys, pre\ufb01x, and start-\nafter parameters\nIn addition to the list-type  parameter that indicates version 2 of the API operation, the request \nalso speci\ufb01es additional parameters to retrieve up to three keys in the quotes bucket that start \nwith E and occur lexicographically after ExampleGuide.pdf .\nGET /?list-type=2&max-keys=3&prefix=E&start-after=ExampleGuide.pdf HTTP/1.1\nHost: quotes.s3.<Region>.amazonaws.com\nx-amz-date: 20160430T232933Z\nAuthorization: authorization string \n          \nSample Response for general purpose buckets\nThis example illustrates one usage of ListObjectsV2.\nHTTP/1.1 200 OK\nx-amz-id-2: gyB+3jRPnrkN98ZajxHXr3u7EFM67bNgSAxexeEHndCX/7GRnfTXxReKUQF28IfP\nx-amz-request-id: 3B3C7C725673C630\nDate: Sat, 30 Apr 2016 23:29:37 GMT\nContent-Type: application/xml\nAmazon S3 API Version 2006-03-01 451Amazon Simple Storage Service API Reference\nContent-Length: length\nConnection: close\nServer: AmazonS3\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<ListBucketResult xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n  <Name>quotes</Name> \n  <Prefix>E</Prefix> \n  <StartAfter>ExampleGuide.pdf</StartAfter> \n  <KeyCount>1</KeyCount> \n  <MaxKeys>3</MaxKeys> \n  <IsTruncated>false</IsTruncated> \n  <Contents> \n    <Key>ExampleObject.txt</Key> \n    <LastModified>2013-09-17T18:07:53.000Z</LastModified> \n    <ETag>\"599bab3ed2c697f1d26842727561fd94\"</ETag> \n    <Size>857</Size> \n    <StorageClass>REDUCED_REDUNDANCY</StorageClass> \n  </Contents>\n</ListBucketResult> \n          \nSample Request for general purpose buckets: Listing keys by using the pre\ufb01x and delimiter \nparameters\nThis example illustrates the use of the prefix  and the delimiter  parameters in the request. For \nthis example, we assume that you have the following keys in your bucket:\n\u2022sample.jpg\n\u2022photos/2006/January/sample.jpg\n\u2022photos/2006/February/sample2.jpg\n\u2022photos/2006/February/sample3.jpg\n\u2022photos/2006/February/sample4.jpg\nThe following GET request speci\ufb01es the delimiter  parameter with a value of /.\nGET /?list-type=2&delimiter=/ HTTP/1.1\nHost: example-bucket.s3.<Region>.amazonaws.com\nAmazon S3 API Version 2006-03-01 452Amazon Simple Storage Service API Reference\nx-amz-date: 20160430T235931Z\nAuthorization: authorization string    \n          \nSample Response for general purpose buckets\nThe key sample.jpg  does not contain the delimiter character, and Amazon S3 returns it in the\nContents  element in the response.", "However, all of the other keys contain the delimiter character.", "\nAmazon S3 groups these keys and returns a single CommonPrefixes  element with the Prefix\nvalue photos/ . The Prefix element is a substring that starts at the beginning of these keys and \nends at the \ufb01rst occurrence of the speci\ufb01ed delimiter.\n<ListBucketResult xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n  <Name>example-bucket</Name> \n  <Prefix></Prefix> \n  <KeyCount>2</KeyCount> \n  <MaxKeys>1000</MaxKeys> \n  <Delimiter>/</Delimiter> \n  <IsTruncated>false</IsTruncated> \n  <Contents> \n    <Key>sample.jpg</Key> \n    <LastModified>2011-02-26T01:56:20.000Z</LastModified> \n    <ETag>\"bf1d737a4d46a19f3bced6905cc8b902\"</ETag> \n    <Size>142863</Size> \n    <StorageClass>STANDARD</StorageClass> \n  </Contents> \n  <CommonPrefixes> \n    <Prefix>photos/</Prefix> \n  </CommonPrefixes>\n</ListBucketResult>  \n          \nSample Request for general purpose buckets\nThe following request speci\ufb01es the delimiter  parameter with the value /, and the prefix\nparameter with the value photos/2006/ .\nGET /?list-type=2&prefix=photos/2006/&delimiter=/ HTTP/1.1\nHost: example-bucket.s3.<Region>.amazonaws.com\nAmazon S3 API Version 2006-03-01 453Amazon Simple Storage Service API Reference\nx-amz-date: 20160501T000433Z\nAuthorization: authorization string \n          \nSample Response for general purpose buckets\nIn response, Amazon S3 returns only the keys that start with the speci\ufb01ed pre\ufb01x. Further, \nAmazon S3 uses the delimiter character to group keys that contain the same substring until the \n\ufb01rst occurrence of the delimiter character after the speci\ufb01ed pre\ufb01x. For each such key group, \nAmazon S3 returns one CommonPrefixes  element in the response.", "The keys grouped under \nthis CommonPrefixes  element are not returned elsewhere in the response.", "The Prefix  value \nreturned in the CommonPrefixes  element is a substring that starts at the beginning of the key \nand ends at the \ufb01rst occurrence of the speci\ufb01ed delimiter after the pre\ufb01x.\nNote\nIf you created folders by using the Amazon S3 console, you will see an additional 0-byte \nobject with a key of photos/2006/ .", "This object is created because of the way that the \nconsole supports folder structures.", "For more information, see Organizing objects in the \nAmazon S3 console using folders in the Amazon S3 User Guide .\n<ListBucketResult xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n  <Name>example-bucket</Name> \n  <Prefix>photos/2006/</Prefix> \n  <KeyCount>2</KeyCount> \n  <MaxKeys>1000</MaxKeys> \n  <Delimiter>/</Delimiter> \n  <IsTruncated>false</IsTruncated> \n  <CommonPrefixes> \n    <Prefix>photos/2006/February/</Prefix> \n  </CommonPrefixes> \n  <CommonPrefixes> \n    <Prefix>photos/2006/January/</Prefix> \n  </CommonPrefixes>\n</ListBucketResult> \n          \nAmazon S3 API Version 2006-03-01 454Amazon Simple Storage Service API Reference\nSample Request for general purpose buckets: Using a continuation token\nIn this example, the initial request returns more than 1,000 keys. In response to this request, \nAmazon S3 returns the IsTruncated  element with the value set to true  and with a\nNextContinuationToken  element.\nGET /?list-type=2 HTTP/1.1\nHost: bucket.s3.<Region>.amazonaws.com\nDate: Mon, 02 May 2016 23:17:07 GMT\nAuthorization: authorization string \n          \nSample Response for general purpose buckets: Using a continuation token\nThis example illustrates one usage of ListObjectsV2.\nHTTP/1.1 200 OK\nx-amz-id-2: gyB+3jRPnrkN98ZajxHXr3u7EFM67bNgSAxexeEHndCX/7GRnfTXxReKUQF28IfP\nx-amz-request-id: 3B3C7C725673C630\nDate: Sat, 30 Apr 2016 23:29:37 GMT\nContent-Type: application/xml\nContent-Length: length\nConnection: close\nServer: AmazonS3\n<ListBucketResult xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n  <Name>bucket</Name> \n  <Prefix></Prefix> \n  <NextContinuationToken>1ueGcxLPRx1Tr/XYExHnhbYLgveDs2J/wm36Hy4vbOwM=</\nNextContinuationToken> \n  <KeyCount>1000</KeyCount> \n  <MaxKeys>1000</MaxKeys> \n  <IsTruncated>true</IsTruncated> \n  <Contents> \n    <Key>happyface.jpg</Key> \n    <LastModified>2014-11-21T19:40:05.000Z</LastModified> \n    <ETag>\"70ee1738b6b21e2c8a43f3a5ab0eee71\"</ETag> \n    <Size>11</Size> \n    <StorageClass>STANDARD</StorageClass> \n  </Contents> \nAmazon S3 API Version 2006-03-01 455Amazon Simple Storage Service API Reference\n   ...\n</ListBucketResult> \n          \nSample request for general purpose buckets\nIn the following subsequent request, we include a continuation-token  query parameter in the \nrequest with the value of the NextContinuationToken  element from the preceding response.\nGET /?list-type=2 HTTP/1.1\nGET /?list-type=2&continuation-token=1ueGcxLPRx1Tr/XYExHnhbYLgveDs2J/wm36Hy4vbOwM= \n HTTP/1.1\nHost: bucket.s3.<Region>.amazonaws.com\nDate: Mon, 02 May 2016 23:17:07 GMT\nAuthorization: authorization string \n          \nSample response for general purpose buckets:\nAmazon S3 returns a list of the next set of keys starting where the previous request ended.\nHTTP/1.1 200 OK\nx-amz-id-2: gyB+3jRPnrkN98ZajxHXr3u7EFM67bNgSAxexeEHndCX/7GRnfTXxReKUQF28IfP\nx-amz-request-id: 3B3C7C725673C630\nDate: Sat, 30 Apr 2016 23:29:37 GMT\nContent-Type: application/xml\nContent-Length: length\nConnection: close\nServer: AmazonS3\n<ListBucketResult xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n  <Name>bucket</Name> \n  <Prefix></Prefix> \n  <ContinuationToken>1ueGcxLPRx1Tr/XYExHnhbYLgveDs2J/wm36Hy4vbOwM=</ContinuationToken> \n  <KeyCount>112</KeyCount> \n  <MaxKeys>1000</MaxKeys> \n  <IsTruncated>false</IsTruncated> \nAmazon S3 API Version 2006-03-01 456Amazon Simple Storage Service API Reference\n  <Contents> \n    <Key>happyfacex.jpg</Key> \n    <LastModified>2014-11-21T19:40:05.000Z</LastModified> \n    <ETag>\"70ee1738b6b21e2c8a43f3a5ab0eee71\"</ETag> \n    <Size>1111</Size> \n    <StorageClass>STANDARD</StorageClass> \n  </Contents> \n   ...\n</ListBucketResult> \n          \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 457Amazon Simple Storage Service API Reference\nListObjectVersions\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nReturns metadata about all versions of the objects in a bucket.", "You can also use request \nparameters as selection criteria to return metadata about a subset of all the object versions.\nImportant\nTo use this operation, you must have permission to perform the\ns3:ListBucketVersions  action.", "Be aware of the name di\ufb00erence.\nNote\nA 200 OK response can contain valid or invalid XML.", "Make sure to design your application \nto parse the contents of the response and handle it appropriately.\nTo use this operation, you must have READ access to the bucket.\nThe following operations are related to ListObjectVersions :\n\u2022ListObjectsV2\n\u2022GetObject\n\u2022PutObject\n\u2022DeleteObject\nRequest Syntax\nGET /?versions&delimiter= Delimiter &encoding-type= EncodingType &key-marker= KeyMarker &max-\nkeys=MaxKeys&prefix= Prefix&version-id-marker= VersionIdMarker  HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nAmazon S3 API Version 2006-03-01 458Amazon Simple Storage Service API Reference\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nx-amz-request-payer: RequestPayer\nx-amz-optional-object-attributes: OptionalObjectAttributes\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe bucket name that contains the objects.\nRequired: Yes\ndelimiter\nA delimiter is a character that you specify to group keys.", "All keys that contain the same string \nbetween the prefix and the \ufb01rst occurrence of the delimiter are grouped under a single result \nelement in CommonPrefixes . These groups are counted as one result against the max-keys\nlimitation.", "These keys are not returned elsewhere in the response.\nencoding-type\nEncoding type used by Amazon S3 to encode the object keys in the response.", "Responses are \nencoded only in UTF-8.", "An object key can contain any Unicode character.", "However, the XML 1.0 \nparser can't parse certain characters, such as characters with an ASCII value from 0 to 10.", "For \ncharacters that aren't supported in XML 1.0, you can add this parameter to request that Amazon \nS3 encode the keys in the response.", "For more information about characters to avoid in object \nkey names, see Object key naming guidelines.\nNote\nWhen using the URL encoding type, non-ASCII characters that are used in an object's \nkey name will be percent-encoded according to UTF-8 code values.", "For example, the \nobject test_file(3).png  will appear as test_file%283%29.png .\nValid Values: url\nkey-marker\nSpeci\ufb01es the key to start with when listing objects in a bucket.\nAmazon S3 API Version 2006-03-01 459Amazon Simple Storage Service API Reference\nmax-keys\nSets the maximum number of keys returned in the response.", "By default, the action returns \nup to 1,000 key names. The response might contain fewer keys but will never contain more. \nIf additional keys satisfy the search criteria, but were not returned because max-keys  was \nexceeded, the response contains <isTruncated>true</isTruncated> .", "To return the \nadditional keys, see key-marker  and version-id-marker .\npre\ufb01x\nUse this parameter to select only those keys that begin with the speci\ufb01ed pre\ufb01x.", "You can use \npre\ufb01xes to separate a bucket into di\ufb00erent groupings of keys. (You can think of using prefix\nto make groups in the same way that you'd use a folder in a \ufb01le system.) You can use prefix\nwith delimiter  to roll up numerous objects into a single result under CommonPrefixes .\nversion-id-marker\nSpeci\ufb01es the object version you want to start listing from.\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match \nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nx-amz-optional-object-attributes\nSpeci\ufb01es the optional \ufb01elds that you want returned in the response.", "Fields that you do not \nspecify are not returned.\nValid Values: RestoreStatus\nx-amz-request-payer\nCon\ufb01rms that the requester knows that they will be charged for the request.", "Bucket owners \nneed not specify this parameter in their requests.", "If either the source or destination S3 \nbucket has Requester Pays enabled, the requester will pay for corresponding charges to copy \nthe object. For information about downloading objects from Requester Pays buckets, see\nDownloading Objects in Requester Pays Buckets in the Amazon S3 User Guide .\nNote\nThis functionality is not supported for directory buckets.\nAmazon S3 API Version 2006-03-01 460Amazon Simple Storage Service API Reference\nValid Values: requester\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\nx-amz-request-charged: RequestCharged\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<ListVersionsResult > \n   <IsTruncated >boolean</IsTruncated > \n   <KeyMarker >string</KeyMarker > \n   <VersionIdMarker >string</VersionIdMarker > \n   <NextKeyMarker >string</NextKeyMarker > \n   <NextVersionIdMarker >string</NextVersionIdMarker > \n   <Version> \n      <ChecksumAlgorithm >string</ChecksumAlgorithm > \n      ...", "\n      <ETag>string</ETag> \n      <IsLatest >boolean</IsLatest > \n      <Key>string</Key> \n      <LastModified >timestamp </LastModified > \n      <Owner> \n         < DisplayName >string</DisplayName > \n         < ID>string</ID> \n      </ Owner> \n      <RestoreStatus > \n         < IsRestoreInProgress >boolean</IsRestoreInProgress > \n         < RestoreExpiryDate >timestamp </RestoreExpiryDate > \n      </ RestoreStatus > \n      <Size>long</Size> \n      <StorageClass >string</StorageClass > \n      <VersionId >string</VersionId > \n   </Version> \n   ... \n   <DeleteMarker > \n      <IsLatest >boolean</IsLatest > \n      <Key>string</Key> \n      <LastModified >timestamp </LastModified > \n      <Owner> \n         < DisplayName >string</DisplayName > \nAmazon S3 API Version 2006-03-01 461Amazon Simple Storage Service API Reference\n         < ID>string</ID> \n      </ Owner> \n      <VersionId >string</VersionId > \n   </DeleteMarker > \n   ...", "\n   <Name>string</Name> \n   <Prefix>string</Prefix> \n   <Delimiter >string</Delimiter > \n   <MaxKeys>integer</MaxKeys> \n   <CommonPrefixes > \n      <Prefix>string</Prefix> \n   </CommonPrefixes > \n   ...", "\n   <EncodingType >string</EncodingType >\n</ListVersionsResult >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe response returns the following HTTP headers.\nx-amz-request-charged\nIf present, indicates that the requester was successfully charged for the request.\nNote\nThis functionality is not supported for directory buckets.\nValid Values: requester\nThe following data is returned in XML format by the service.\nListVersionsResult\nRoot level tag for the ListVersionsResult parameters.\nRequired: Yes\nAmazon S3 API Version 2006-03-01 462Amazon Simple Storage Service API Reference\nCommonPre\ufb01xes\nAll of the keys rolled up into a common pre\ufb01x count as a single return when calculating the \nnumber of returns.\nType: Array of CommonPre\ufb01x data types\nDeleteMarker\nContainer for an object that is a delete marker.\nType: Array of DeleteMarkerEntry data types\nDelimiter\nThe delimiter grouping the included keys.", "A delimiter is a character that you specify to group \nkeys. All keys that contain the same string between the pre\ufb01x and the \ufb01rst occurrence of the \ndelimiter are grouped under a single result element in CommonPrefixes . These groups are \ncounted as one result against the max-keys  limitation.", "These keys are not returned elsewhere \nin the response.\nType: String\nEncodingType\nEncoding type used by Amazon S3 to encode object key names in the XML response.\nIf you specify the encoding-type  request parameter, Amazon S3 includes this element in the \nresponse, and returns encoded key name values in the following response elements:\nKeyMarker, NextKeyMarker, Prefix, Key , and Delimiter .\nType: String\nValid Values: url\nIsTruncated\nA \ufb02ag that indicates whether Amazon S3 returned all of the results that satis\ufb01ed the search \ncriteria. If your results were truncated, you can make a follow-up paginated request by using \nthe NextKeyMarker  and NextVersionIdMarker  response parameters as a starting place in \nanother request to return the rest of the results.\nType: Boolean\nAmazon S3 API Version 2006-03-01 463Amazon Simple Storage Service API Reference\nKeyMarker\nMarks the last key returned in a truncated response.\nType: String\nMaxKeys\nSpeci\ufb01es the maximum number of objects to return.\nType: Integer\nName\nThe bucket name.\nType: String\nNextKeyMarker\nWhen the number of responses exceeds the value of MaxKeys , NextKeyMarker  speci\ufb01es the \n\ufb01rst key not returned that satis\ufb01es the search criteria.", "Use this value for the key-marker request \nparameter in a subsequent request.\nType: String\nNextVersionIdMarker\nWhen the number of responses exceeds the value of MaxKeys , NextVersionIdMarker\nspeci\ufb01es the \ufb01rst object version not returned that satis\ufb01es the search criteria.", "Use this value for \nthe version-id-marker  request parameter in a subsequent request.\nType: String\nPre\ufb01x\nSelects objects that start with the value supplied by this parameter.\nType: String\nVersion\nContainer for version information.\nType: Array of ObjectVersion data types\nVersionIdMarker\nMarks the last version of the key returned in a truncated response.\nAmazon S3 API Version 2006-03-01 464Amazon Simple Storage Service API Reference\nType: String\nExamples\nSample Request\nThe following request returns all of the versions of all of the objects in the speci\ufb01ed bucket.\nGET /?versions HTTP/1.1\nHost: BucketName.s3.<Region>.amazonaws.com\nDate: Wed, 28 Oct 2009 22:32:00 +0000\nAuthorization: authorization string (see Authenticating Requests (AWS Signature Version \n  4)) \n          \nSample Response\nThis example illustrates one usage of ListObjectVersions.\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<ListVersionsResult xmlns=\"http://s3.amazonaws.com/doc/2006-03-01\"> \n    <Name>bucket</Name> \n    <Prefix>my</Prefix> \n    <KeyMarker/> \n    <VersionIdMarker/> \n    <MaxKeys>5</MaxKeys> \n    <IsTruncated>false</IsTruncated> \n    <Version> \n        <Key>my-image.jpg</Key> \n        <VersionId>3/L4kqtJl40Nr8X8gdRQBpUMLUo</VersionId> \n        <IsLatest>true</IsLatest> \n         <LastModified>2009-10-12T17:50:30.000Z</LastModified> \n        <ETag>\"fba9dede5f27731c9771645a39863328\"</ETag> \n        <Size>434234</Size> \n        <StorageClass>STANDARD</StorageClass> \n        <Owner> \n            <ID>75aa57f09aa0c8caeab4f8c24e99d10f8e7faeebf76c078efc7c6caea54ba06a</ID> \n            <DisplayName>mtd@amazon.com</DisplayName> \n        </Owner> \n    </Version> \nAmazon S3 API Version 2006-03-01 465Amazon Simple Storage Service API Reference\n    <DeleteMarker> \n        <Key>my-second-image.jpg</Key> \n        <VersionId>03jpff543dhffds434rfdsFDN943fdsFkdmqnh892</VersionId> \n        <IsLatest>true</IsLatest> \n        <LastModified>2009-11-12T17:50:30.000Z</LastModified> \n        <Owner> \n            <ID>75aa57f09aa0c8caeab4f8c24e99d10f8e7faeebf76c078efc7c6caea54ba06a</ID> \n            <DisplayName>mtd@amazon.com</DisplayName> \n        </Owner>     \n    </DeleteMarker> \n    <Version> \n        <Key>my-second-image.jpg</Key> \n        <VersionId>QUpfdndhfd8438MNFDN93jdnJFkdmqnh893</VersionId> \n        <IsLatest>false</IsLatest> \n        <LastModified>2009-10-10T17:50:30.000Z</LastModified> \n        <ETag>\"9b2cf535f27731c974343645a3985328\"</ETag> \n        <Size>166434</Size> \n        <StorageClass>STANDARD</StorageClass> \n        <Owner> \n            <ID>75aa57f09aa0c8caeab4f8c24e99d10f8e7faeebf76c078efc7c6caea54ba06a</ID> \n            <DisplayName>mtd@amazon.com</DisplayName> \n        </Owner> \n    </Version> \n    <DeleteMarker> \n        <Key>my-third-image.jpg</Key> \n        <VersionId>03jpff543dhffds434rfdsFDN943fdsFkdmqnh892</VersionId> \n        <IsLatest>true</IsLatest> \n        <LastModified>2009-10-15T17:50:30.000Z</LastModified> \n        <Owner> \n            <ID>75aa57f09aa0c8caeab4f8c24e99d10f8e7faeebf76c078efc7c6caea54ba06a</ID> \n            <DisplayName>mtd@amazon.com</DisplayName> \n        </Owner>     \n    </DeleteMarker>    \n    <Version> \n        <Key>my-third-image.jpg</Key> \n        <VersionId>UIORUnfndfhnw89493jJFJ</VersionId> \n        <IsLatest>false</IsLatest> \n        <LastModified>2009-10-11T12:50:30.000Z</LastModified> \n        <ETag>\"772cf535f27731c974343645a3985328\"</ETag> \n        <Size>64</Size> \n        <StorageClass>STANDARD</StorageClass> \n        <Owner> \n            <ID>75aa57f09aa0c8caeab4f8c24e99d10f8e7faeebf76c078efc7c6caea54ba06a</ID> \n            <DisplayName>mtd@amazon.com</DisplayName> \nAmazon S3 API Version 2006-03-01 466Amazon Simple Storage Service API Reference\n        </Owner> \n     </Version>\n</ListVersionsResult> \n          \nSample Request\nThe following request returns objects in the order that they were stored, returning the most \nrecently stored object \ufb01rst, starting with the value for key-marker .\nGET /?versions&key-marker=key2 HTTP/1.1\nHost: s3.amazonaws.com\nPragma: no-cache\nAccept: image/gif, image/x-xbitmap, image/jpeg, image/pjpeg, */*\nDate: Thu, 10 Dec 2009 22:46:32 +0000\nAuthorization: signatureValue \n          \nSample Response\nThis example illustrates one usage of ListObjectVersions.\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<ListVersionsResult xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n  <Name>mtp-versioning-fresh</Name> \n  <Prefix/> \n  <KeyMarker>key2</KeyMarker> \n  <VersionIdMarker/> \n  <MaxKeys>1000</MaxKeys> \n  <IsTruncated>false</IsTruncated> \n  <Version> \n    <Key>key3</Key> \n    <VersionId>I5VhmK6CDDdQ5Pwfe1gcHZWmHDpcv7gfmfc29UBxsKU.</VersionId> \n    <IsLatest>true</IsLatest> \n    <LastModified>2009-12-09T00:19:04.000Z</LastModified> \n    <ETag>\"396fefef536d5ce46c7537ecf978a360\"</ETag> \n    <Size>217</Size> \n    <Owner> \n      <ID>75aa57f09aa0c8caeab4f8c24e99d10f8e7faeebf76c078efc7c6caea54ba06a</ID> \n    </Owner> \nAmazon S3 API Version 2006-03-01 467Amazon Simple Storage Service API Reference\n    <StorageClass>STANDARD</StorageClass> \n  </Version> \n  <DeleteMarker> \n    <Key>sourcekey</Key> \n    <VersionId>qDhprLU80sAlCFLu2DWgXAEDgKzWarn-HS_JU0TvYqs.</VersionId> \n    <IsLatest>true</IsLatest> \n    <LastModified>2009-12-10T16:38:11.000Z</LastModified> \n    <Owner> \n      <ID>75aa57f09aa0c8caeab4f8c24e99d10f8e7faeebf76c078efc7c6caea54ba06a</ID> \n    </Owner> \n  </DeleteMarker> \n  <Version> \n    <Key>sourcekey</Key> \n    <VersionId>wxxQ7ezLaL5JN2Sislq66Syxxo0k7uHTUpb9qiiMxNg.</VersionId> \n    <IsLatest>false</IsLatest> \n    <LastModified>2009-12-10T16:37:44.000Z</LastModified> \n    <ETag>\"396fefef536d5ce46c7537ecf978a360\"</ETag> \n    <Size>217</Size> \n    <Owner> \n      <ID>75aa57f09aa0c8caeab4f8c24e99d10f8e7faeebf76c078efc7c6caea54ba06a</ID> \n    </Owner> \n    <StorageClass>STANDARD</StorageClass> \n  </Version>\n</ListVersionsResult> \n          \nSample Request Using the pre\ufb01x Parameter\nThis example returns objects whose keys begin with source .\nGET /?versions&prefix=source HTTP/1.1\nHost: bucket.s3.<Region>.amazonaws.com\nDate: Wed, 28 Oct 2009 22:32:00 +0000\nAuthorization: authorization string \n          \nSample Response\nThis example illustrates one usage of ListObjectVersions.\nAmazon S3 API Version 2006-03-01 468Amazon Simple Storage Service API Reference\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<ListVersionsResult xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n  <Name>mtp-versioning-fresh</Name> \n  <Prefix>source</Prefix> \n  <KeyMarker/> \n  <VersionIdMarker/> \n  <MaxKeys>1000</MaxKeys> \n  <IsTruncated>false</IsTruncated> \n  <DeleteMarker> \n    <Key>sourcekey</Key> \n    <VersionId>qDhprLU80sAlCFLu2DWgXAEDgKzWarn-HS_JU0TvYqs.</VersionId> \n    <IsLatest>true</IsLatest> \n    <LastModified>2009-12-10T16:38:11.000Z</LastModified> \n    <Owner> \n      <ID>75aa57f09aa0c8caeab4f8c24e99d10f8e7faeebf76c078efc7c6caea54ba06a</ID> \n    </Owner> \n  </DeleteMarker> \n  <Version> \n    <Key>sourcekey</Key> \n    <VersionId>wxxQ7ezLaL5JN2Sislq66Syxxo0k7uHTUpb9qiiMxNg.</VersionId> \n    <IsLatest>false</IsLatest> \n    <LastModified>2009-12-10T16:37:44.000Z</LastModified> \n    <ETag>\"396fefef536d5ce46c7537ecf978a360\"</ETag> \n    <Size>217</Size> \n    <Owner> \n      <ID>75aa57f09aa0c8caeab4f8c24e99d10f8e7faeebf76c078efc7c6caea54ba06a</ID> \n    </Owner> \n    <StorageClass>STANDARD</StorageClass> \n  </Version>\n</ListVersionsResult> \n          \nSample Request: Using the key-marker and version-id-marker Parameters\nThe following example returns objects starting at the speci\ufb01ed key (key-marker ) and version ID \n(version-id-marker ).\nGET /?versions&key-marker=key3&version-id-marker=t46ZenlYTZBnj HTTP/1.1\nHost: bucket.s3.<Region>.amazonaws.com\nDate: Wed, 28 Oct 2009 22:32:00 +0000\nAuthorization: signatureValue \nAmazon S3 API Version 2006-03-01 469Amazon Simple Storage Service API Reference\n         \nSample Response\nThis example illustrates one usage of ListObjectVersions.\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<ListVersionsResult xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n  <Name>mtp-versioning-fresh</Name> \n  <Prefix/> \n  <KeyMarker>key3</KeyMarker> \n  <VersionIdMarker>t46ZenlYTZBnj</VersionIdMarker> \n  <MaxKeys>1000</MaxKeys> \n  <IsTruncated>false</IsTruncated> \n  <DeleteMarker> \n    <Key>sourcekey</Key> \n    <VersionId>qDhprLU80sAlCFLu2DWgXAEDgKzWarn-HS_JU0TvYqs.</VersionId> \n    <IsLatest>true</IsLatest> \n    <LastModified>2009-12-10T16:38:11.000Z</LastModified> \n    <Owner> \n      <ID>75aa57f09aa0c8caeab4f8c24e99d10f8e7faeebf76c078efc7c6caea54ba06a</ID> \n    </Owner> \n  </DeleteMarker> \n  <Version> \n    <Key>sourcekey</Key> \n    <VersionId>wxxQ7ezLaL5JN2Sislq66Syxxo0k7uHTUpb9qiiMxNg.</VersionId> \n    <IsLatest>false</IsLatest> \n    <LastModified>2009-12-10T16:37:44.000Z</LastModified> \n    <ETag>\"396fefef536d5ce46c7537ecf978a360\"</ETag> \n    <Size>217</Size> \n    <Owner> \n      <ID>75aa57f09aa0c8caeab4f8c24e99d10f8e7faeebf76c078efc7c6caea54ba06a</ID> \n    </Owner> \n    <StorageClass>STANDARD</StorageClass> \n  </Version>\n</ListVersionsResult> \n          \nSample Request: Using the key-marker, version-id-marker, and max-keys Parameters\nThe following request returns up to three (the value of max-keys ) objects starting with the key \nspeci\ufb01ed by key-marker  and the version ID speci\ufb01ed by version-id-marker .\nAmazon S3 API Version 2006-03-01 470Amazon Simple Storage Service API Reference\nGET /?versions&key-marker=key3&version-id-marker=t46Z0menlYTZBnj&max-keys=3\nHost: bucket.s3.<Region>.amazonaws.com\nDate: Wed, 28 Oct 2009 22:32:00 +0000\nAuthorization: authorization string \n          \nSample Response\nThis example illustrates one usage of ListObjectVersions.\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<ListVersionsResult xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n  <Name>mtp-versioning-fresh</Name> \n  <Prefix/> \n  <KeyMarker>key3</KeyMarker> \n  <VersionIdMarker>null</VersionIdMarker> \n  <NextKeyMarker>key3</NextKeyMarker> \n  <NextVersionIdMarker>d-d309mfjFrUmoQ0DBsVqmcMV15OI.</NextVersionIdMarker> \n  <MaxKeys>3</MaxKeys> \n  <IsTruncated>true</IsTruncated> \n  <Version> \n    <Key>key3</Key> \n    <VersionId>8XECiENpj8pydEDJdd-_VRrvaGKAHOaGMNW7tg6UViI.</VersionId> \n    <IsLatest>false</IsLatest> \n    <LastModified>2009-12-09T00:18:23.000Z</LastModified> \n    <ETag>\"396fefef536d5ce46c7537ecf978a360\"</ETag> \n    <Size>217</Size> \n    <Owner> \n      <ID>75aa57f09aa0c8caeab4f8c24e99d10f8e7faeebf76c078efc7c6caea54ba06a</ID> \n    </Owner> \n    <StorageClass>STANDARD</StorageClass> \n  </Version> \n  <Version> \n    <Key>key3</Key> \n    <VersionId>d-d309mfjFri40QYukDozqBt3UmoQ0DBsVqmcMV15OI.</VersionId> \n    <IsLatest>false</IsLatest> \n    <LastModified>2009-12-09T00:18:08.000Z</LastModified> \n    <ETag>\"396fefef536d5ce46c7537ecf978a360\"</ETag> \n    <Size>217</Size> \n    <Owner> \n      <ID>75aa57f09aa0c8caeab4f8c24e99d10f8e7faeebf76c078efc7c6caea54ba06a</ID> \nAmazon S3 API Version 2006-03-01 471Amazon Simple Storage Service API Reference\n    </Owner> \n    <StorageClass>STANDARD</StorageClass> \n  </Version>\n</ListVersionsResult> \n             \nSample Request: Using the delimiter and pre\ufb01x Parameters\nAssume you have the following keys in your bucket, example-bucket .\nphotos/2006/January/sample.jpg\nphotos/2006/February/sample.jpg\nphotos/2006/March/sample.jpg\nvideos/2006/March/sample.wmv\nsample.jpg\nThe following GET versions request speci\ufb01es the delimiter  parameter with the value /.\nGET /?versions&delimiter=/ HTTP/1.1\nHost: example-bucket.s3.<Region>.amazonaws.com\nDate: Wed, 02 Feb 2011 20:34:56 GMT\nAuthorization: authorization string \n             \nSample Response\nThe list of keys from the speci\ufb01ed bucket is shown in the following response.\nThe response returns the sample.jpg  key in a Version element.", "However, because all the other \nkeys contain the speci\ufb01ed delimiter, a distinct substring, from the beginning of the key to the \ufb01rst \noccurrence of the delimiter, from each of these keys is returned in a CommonPrefixes  element. \nThe key substrings, photos/  and videos/ , in the CommonPrefixes  element indicate that there \nare one or more keys with these key pre\ufb01xes.\nThis is a useful scenario if you use key pre\ufb01xes for your objects to create a logical folder-like \nstructure. In this case, you can interpret the result as the folders photos/  and videos/ have one \nor more objects.\nAmazon S3 API Version 2006-03-01 472Amazon Simple Storage Service API Reference\n<ListVersionsResult xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n  <Name>mvbucketwithversionon1</Name> \n  <Prefix></Prefix> \n  <KeyMarker></KeyMarker> \n  <VersionIdMarker></VersionIdMarker> \n  <MaxKeys>1000</MaxKeys> \n  <Delimiter>/</Delimiter> \n  <IsTruncated>false</IsTruncated> \n   \n  <Version> \n    <Key>Sample.jpg</Key> \n    <VersionId>toxMzQlBsGyGCz1YuMWMp90cdXLzqOCH</VersionId> \n    <IsLatest>true</IsLatest> \n    <LastModified>2011-02-02T18:46:20.000Z</LastModified> \n    <ETag>\"3305f2cfc46c0f04559748bb039d69ae\"</ETag> \n    <Size>3191</Size> \n    <Owner> \n      <ID>852b113e7a2f25102679df27bb0ae12b3f85be6f290b936c4393484be31bebcc</ID> \n      <DisplayName>display-name</DisplayName> \n    </Owner> \n    <StorageClass>STANDARD</StorageClass> \n  </Version> \n  \n  <CommonPrefixes> \n    <Prefix>photos/</Prefix> \n  </CommonPrefixes> \n  <CommonPrefixes> \n    <Prefix>videos/</Prefix> \n  </CommonPrefixes>\n</ListVersionsResult> \n             \nExample\nIn addition to the delimiter  parameter, you can \ufb01lter results by adding a prefix  parameter as \nshown in the following request.\nGET /?versions&prefix=photos/2006/&delimiter=/ HTTP/1.1\nHost: example-bucket.s3.<Region>.amazonaws.com\nDate: Wed, 02 Feb 2011 19:34:02 GMT\nAmazon S3 API Version 2006-03-01 473Amazon Simple Storage Service API Reference\nAuthorization: authorization string  \n             \nExample\nIn this case, the response will include only object keys that start with the speci\ufb01ed pre\ufb01x. The value \nreturned in the CommonPrefixes  element is a substring from the beginning of the key to the \ufb01rst \noccurrence of the speci\ufb01ed delimiter after the pre\ufb01x.\nNote\nIf you created folders by using the Amazon S3 console, you will see an additional 0-byte \nobject with a key of photos/2006/ .", "This object is created because of the way that the \nconsole supports folder structures.", "For more information, see Organizing objects in the \nAmazon S3 console using folders in the Amazon S3 User Guide .\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<ListVersionsResult xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n  <Name>example-bucket</Name> \n  <Prefix>photos/2006/</Prefix> \n  <KeyMarker></KeyMarker> \n  <VersionIdMarker></VersionIdMarker> \n  <MaxKeys>1000</MaxKeys> \n  <Delimiter>/</Delimiter> \n  <IsTruncated>false</IsTruncated> \n  <CommonPrefixes> \n    <Prefix>photos/2006/February/</Prefix> \n  </CommonPrefixes> \n  <CommonPrefixes> \n    <Prefix>photos/2006/January/</Prefix> \n  </CommonPrefixes> \n  <CommonPrefixes> \n    <Prefix>photos/2006/March/</Prefix> \n  </CommonPrefixes>\n</ListVersionsResult> \n             \nAmazon S3 API Version 2006-03-01 474Amazon Simple Storage Service API Reference\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 475Amazon Simple Storage Service API Reference\nListParts\nService: Amazon S3\nLists the parts that have been uploaded for a speci\ufb01c multipart upload.\nTo use this operation, you must provide the upload ID  in the request.", "You obtain this uploadID by \nsending the initiate multipart upload request through CreateMultipartUpload.\nThe ListParts  request returns a maximum of 1,000 uploaded parts.", "The limit of 1,000 parts is \nalso the default value. You can restrict the number of parts in a response by specifying the max-\nparts request parameter. If your multipart upload consists of more than 1,000 parts, the response \nreturns an IsTruncated  \ufb01eld with the value of true , and a NextPartNumberMarker  element. \nTo list remaining uploaded parts, in subsequent ListParts  requests, include the part-number-\nmarker query string parameter and set its value to the NextPartNumberMarker  \ufb01eld value from \nthe previous response.\nFor more information on multipart uploads, see Uploading Objects Using Multipart Upload in the\nAmazon S3 User Guide .\nNote\nDirectory buckets - For directory buckets, you must make requests for this API operation \nto the Zonal endpoint.", "These endpoints support virtual-hosted-style requests in the format\nhttps:// bucket_name .s3express- az_id.region.amazonaws.com/ key-name\n.", "Path-style requests are not supported.", "For more information, see Regional and Zonal \nendpoints  in the Amazon S3 User Guide .\nPermissions\n\u2022General purpose bucket permissions - For information about permissions required to use the \nmultipart upload API, see Multipart Upload and Permissions in the Amazon S3 User Guide .\nIf the upload was created using server-side encryption with AWS Key Management Service \n(AWS KMS) keys (SSE-KMS) or dual-layer server-side encryption with AWS KMS keys (DSSE-\nKMS), you must have permission to the kms:Decrypt  action for the ListParts  request to \nsucceed.\n\u2022Directory bucket permissions - To grant access to this API operation on a directory \nbucket, we recommend that you use the CreateSession  API operation for session-based \nAmazon S3 API Version 2006-03-01 476Amazon Simple Storage Service API Reference\nauthorization. Speci\ufb01cally, you grant the s3express:CreateSession  permission to the \ndirectory bucket in a bucket policy or an IAM identity-based policy.", "Then, you make the\nCreateSession  API call on the bucket to obtain a session token.", "With the session token in \nyour request header, you can make API requests to this operation. After the session token \nexpires, you make another CreateSession  API call to generate a new session token for \nuse. AWS CLI or SDKs create session and refresh the session token automatically to avoid \nservice interruptions when a session expires.", "For more information about authorization, see\nCreateSession .\nHTTP Host header syntax\nDirectory buckets  - The HTTP Host header syntax is \nBucket_name .s3express- az_id.region.amazonaws.com .\nThe following operations are related to ListParts :\n\u2022CreateMultipartUpload\n\u2022UploadPart\n\u2022CompleteMultipartUpload\n\u2022AbortMultipartUpload\n\u2022GetObjectAttributes\n\u2022ListMultipartUploads\nRequest Syntax\nGET /Key+?max-parts= MaxParts &part-number-marker= PartNumberMarker &uploadId= UploadId\n HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-request-payer: RequestPayer\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nx-amz-server-side-encryption-customer-algorithm: SSECustomerAlgorithm\nx-amz-server-side-encryption-customer-key: SSECustomerKey\nx-amz-server-side-encryption-customer-key-MD5: SSECustomerKeyMD5\nURI Request Parameters\nThe request uses the following URI parameters.\nAmazon S3 API Version 2006-03-01 477Amazon Simple Storage Service API Reference\nBucket\nThe name of the bucket to which the parts are being uploaded.\nDirectory buckets - When you use this operation with a directory \nbucket, you must use virtual-hosted-style requests in the format \nBucket_name .s3express- az_id.region.amazonaws.com .", "Path-style requests are not \nsupported.", "Directory bucket names must be unique in the chosen Availability Zone.", "Bucket \nnames must follow the format  bucket_base_name --az-id--x-s3  (for example,  DOC-\nEXAMPLE-BUCKET --usw2-az1 --x-s3). For information about bucket naming restrictions, see\nDirectory bucket naming rules in the Amazon S3 User Guide .\nAccess points - When you use this action with an access point, you must provide the alias of the \naccess point in place of the bucket name or specify the access point ARN.", "When using the access \npoint ARN, you must direct requests to the access point hostname.", "The access point hostname \ntakes the form AccessPointName-AccountId .s3-accesspoint.Region.amazonaws.com.", "When using \nthis action with an access point through the AWS SDKs, you provide the access point ARN in \nplace of the bucket name. For more information about access point ARNs, see Using access \npoints  in the Amazon S3 User Guide .\nNote\nAccess points and Object Lambda access points are not supported by directory buckets.\nS3 on Outposts  - When you use this action with Amazon S3 on Outposts, you must direct \nrequests to the S3 on Outposts hostname. The S3 on Outposts hostname takes the form \nAccessPointName -AccountId .outpostID .s3-outposts.", "Region.amazonaws.com .", "\nWhen you use this action with S3 on Outposts through the AWS SDKs, you provide the Outposts \naccess point ARN in place of the bucket name. For more information about S3 on Outposts \nARNs, see What is S3 on Outposts?", "in the Amazon S3 User Guide .\nRequired: Yes\nKey\nObject key for which the multipart upload was initiated.\nLength Constraints: Minimum length of 1.\nAmazon S3 API Version 2006-03-01 478Amazon Simple Storage Service API Reference\nRequired: Yes\nmax-parts\nSets the maximum number of parts to return.\npart-number-marker\nSpeci\ufb01es the part after which listing should begin. Only parts with higher part numbers will be \nlisted.\nuploadId\nUpload ID identifying the multipart upload whose parts are being listed.\nRequired: Yes\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match \nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nx-amz-request-payer\nCon\ufb01rms that the requester knows that they will be charged for the request. Bucket owners \nneed not specify this parameter in their requests.", "If either the source or destination S3 \nbucket has Requester Pays enabled, the requester will pay for corresponding charges to copy \nthe object. For information about downloading objects from Requester Pays buckets, see\nDownloading Objects in Requester Pays Buckets in the Amazon S3 User Guide .\nNote\nThis functionality is not supported for directory buckets.\nValid Values: requester\nx-amz-server-side-encryption-customer-algorithm\nThe server-side encryption (SSE) algorithm used to encrypt the object.", "This parameter is needed \nonly when the object was created using a checksum algorithm.", "For more information, see\nProtecting data using SSE-C keys in the Amazon S3 User Guide .\nAmazon S3 API Version 2006-03-01 479Amazon Simple Storage Service API Reference\nNote\nThis functionality is not supported for directory buckets.\nx-amz-server-side-encryption-customer-key\nThe server-side encryption (SSE) customer managed key.", "This parameter is needed only when \nthe object was created using a checksum algorithm.", "For more information, see Protecting data \nusing SSE-C keys in the Amazon S3 User Guide .\nNote\nThis functionality is not supported for directory buckets.\nx-amz-server-side-encryption-customer-key-MD5\nThe MD5 server-side encryption (SSE) customer managed key.", "This parameter is needed only \nwhen the object was created using a checksum algorithm.", "For more information, see Protecting \ndata using SSE-C keys in the Amazon S3 User Guide .\nNote\nThis functionality is not supported for directory buckets.\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\nx-amz-abort-date: AbortDate\nx-amz-abort-rule-id: AbortRuleId\nx-amz-request-charged: RequestCharged\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<ListPartsResult > \nAmazon S3 API Version 2006-03-01 480Amazon Simple Storage Service API Reference\n   <Bucket>string</Bucket> \n   <Key>string</Key> \n   <UploadId >string</UploadId > \n   <PartNumberMarker >integer</PartNumberMarker > \n   <NextPartNumberMarker >integer</NextPartNumberMarker > \n   <MaxParts >integer</MaxParts > \n   <IsTruncated >boolean</IsTruncated > \n   <Part> \n      <ChecksumCRC32 >string</ChecksumCRC32 > \n      <ChecksumCRC32C >string</ChecksumCRC32C > \n      <ChecksumSHA1 >string</ChecksumSHA1 > \n      <ChecksumSHA256 >string</ChecksumSHA256 > \n      <ETag>string</ETag> \n      <LastModified >timestamp </LastModified > \n      <PartNumber >integer</PartNumber > \n      <Size>long</Size> \n   </Part> \n   ... \n   <Initiator > \n      <DisplayName >string</DisplayName > \n      <ID>string</ID> \n   </Initiator > \n   <Owner> \n      <DisplayName >string</DisplayName > \n      <ID>string</ID> \n   </Owner> \n   <StorageClass >string</StorageClass > \n   <ChecksumAlgorithm >string</ChecksumAlgorithm >\n</ListPartsResult >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe response returns the following HTTP headers.\nx-amz-abort-date\nIf the bucket has a lifecycle rule con\ufb01gured with an action to abort incomplete multipart \nuploads and the pre\ufb01x in the lifecycle rule matches the object name in the request, then the \nresponse includes this header indicating when the initiated multipart upload will become \neligible for abort operation. For more information, see Aborting Incomplete Multipart Uploads \nUsing a Bucket Lifecycle Con\ufb01guration.\nAmazon S3 API Version 2006-03-01 481Amazon Simple Storage Service API Reference\nThe response will also include the x-amz-abort-rule-id  header that will provide the ID of \nthe lifecycle con\ufb01guration rule that de\ufb01nes this action.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-abort-rule-id\nThis header is returned along with the x-amz-abort-date  header. It identi\ufb01es applicable \nlifecycle con\ufb01guration rule that de\ufb01nes the action to abort incomplete multipart uploads.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-request-charged\nIf present, indicates that the requester was successfully charged for the request.\nNote\nThis functionality is not supported for directory buckets.\nValid Values: requester\nThe following data is returned in XML format by the service.\nListPartsResult\nRoot level tag for the ListPartsResult parameters.\nRequired: Yes\nBucket\nThe name of the bucket to which the multipart upload was initiated.", "Does not return the access \npoint ARN or access point alias if used.\nAmazon S3 API Version 2006-03-01 482Amazon Simple Storage Service API Reference\nType: String\nChecksumAlgorithm\nThe algorithm that was used to create a checksum of the object.\nType: String\nValid Values: CRC32 | CRC32C | SHA1 | SHA256\nInitiator\nContainer element that identi\ufb01es who initiated the multipart upload.", "If the initiator is an AWS \naccount, this element provides the same information as the Owner  element. If the initiator is an \nIAM User, this element provides the user ARN and display name.\nType: Initiator  data type\nIsTruncated\nIndicates whether the returned list of parts is truncated.", "A true value indicates that the list \nwas truncated.", "A list can be truncated if the number of parts exceeds the limit returned in the \nMaxParts element.\nType: Boolean\nKey\nObject key for which the multipart upload was initiated.\nType: String\nLength Constraints: Minimum length of 1.\nMaxParts\nMaximum number of parts that were allowed in the response.\nType: Integer\nNextPartNumberMarker\nWhen a list is truncated, this element speci\ufb01es the last part in the list, as well as the value to \nuse for the part-number-marker  request parameter in a subsequent request.\nType: Integer\nAmazon S3 API Version 2006-03-01 483Amazon Simple Storage Service API Reference\nOwner\nContainer element that identi\ufb01es the object owner, after the object is created. If multipart \nupload is initiated by an IAM user, this element provides the parent account ID and display \nname.\nNote\nDirectory buckets - The bucket owner is returned as the object owner for all the parts.\nType: Owner  data type\nPart\nContainer for elements related to a particular part.", "A response can contain zero or more Part\nelements.\nType: Array of Part data types\nPartNumberMarker\nSpeci\ufb01es the part after which listing should begin.", "Only parts with higher part numbers will be \nlisted.\nType: Integer\nStorageClass\nThe class of storage used to store the uploaded object.\nNote\nDirectory buckets - Only the S3 Express One Zone storage class is supported by \ndirectory buckets to store objects.\nType: String\nValid Values: STANDARD | REDUCED_REDUNDANCY | STANDARD_IA | ONEZONE_IA | \nINTELLIGENT_TIERING | GLACIER | DEEP_ARCHIVE | OUTPOSTS | GLACIER_IR | \nSNOW | EXPRESS_ONEZONE\nAmazon S3 API Version 2006-03-01 484Amazon Simple Storage Service API Reference\nUploadId\nUpload ID identifying the multipart upload whose parts are being listed.\nType: String\nExamples\nSample Request for general purpose buckets\nAssume you have uploaded parts with sequential part numbers starting with 1.", "The following \nList Parts request speci\ufb01es max-parts  and part-number-marker  query parameters. The \nrequest lists the \ufb01rst two parts that follow part number 1, that is, you will get parts 2 and 3 \nin the response. If more parts exist, the result is a truncated result and therefore the response \nwill return an IsTruncated  element with the value true.", "The response will also return the\nNextPartNumberMarker  element with the value 3, which should be used for the value of the\npart-number-marker  request query string parameter in the next ListParts request.\nGET /example-object?\nuploadId=XXBsb2FkIElEIGZvciBlbHZpbmcncyVcdS1tb3ZpZS5tMnRzEEEwbG9hZA&max-parts=2&part-\nnumber-marker=1 HTTP/1.1\nHost: example-bucket.s3.<Region>.amazonaws.com\nDate: Mon, 1 Nov 2010 20:34:56 GMT\nAuthorization: authorization string \n          \nSample Response for general purpose buckets\nThis example illustrates one usage of ListParts.\nHTTP/1.1 200 OK\nx-amz-id-2: Uuag1LuByRx9e6j5Onimru9pO4ZVKnJ2Qz7/C1NPcfTWAtRPfTaOFg==\nx-amz-request-id: 656c76696e6727732072657175657374\nDate: Mon, 1 Nov 2010 20:34:56 GMT\nContent-Length: 985\nConnection: keep-alive\nServer: AmazonS3\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\nAmazon S3 API Version 2006-03-01 485Amazon Simple Storage Service API Reference\n<ListPartsResult xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n  <Bucket>example-bucket</Bucket> \n  <Key>example-object</Key> \n  <UploadId>XXBsb2FkIElEIGZvciBlbHZpbmcncyVcdS1tb3ZpZS5tMnRzEEEwbG9hZA</UploadId> \n  <Initiator> \n      <ID>arn:aws:iam::111122223333:user/some-user-11116a31-17b5-4fb7-9df5-\nb288870f11xx</ID> \n      <DisplayName>umat-user-11116a31-17b5-4fb7-9df5-b288870f11xx</DisplayName> \n  </Initiator> \n  <Owner> \n    <ID>75aa57f09aa0c8caeab4f8c24e99d10f8e7faeebf76c078efc7c6caea54ba06a</ID> \n    <DisplayName>someName</DisplayName> \n  </Owner> \n  <StorageClass>STANDARD</StorageClass> \n  <PartNumberMarker>1</PartNumberMarker> \n  <NextPartNumberMarker>3</NextPartNumberMarker> \n  <MaxParts>2</MaxParts> \n  <IsTruncated>true</IsTruncated> \n  <Part> \n    <PartNumber>2</PartNumber> \n    <LastModified>2010-11-10T20:48:34.000Z</LastModified> \n    <ETag>\"7778aef83f66abc1fa1e8477f296d394\"</ETag> \n    <Size>10485760</Size> \n  </Part> \n  <Part> \n    <PartNumber>3</PartNumber> \n    <LastModified>2010-11-10T20:48:33.000Z</LastModified> \n    <ETag>\"aaaa18db4cc2f85cedef654fccc4a4x8\"</ETag> \n    <Size>10485760</Size> \n  </Part>\n</ListPartsResult> \n          \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\nAmazon S3 API Version 2006-03-01 486Amazon Simple Storage Service API Reference\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 487Amazon Simple Storage Service API Reference\nPutBucketAccelerateCon\ufb01guration\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nSets the accelerate con\ufb01guration of an existing bucket.", "Amazon S3 Transfer Acceleration is a \nbucket-level feature that enables you to perform faster data transfers to Amazon S3.\nTo use this operation, you must have permission to perform the\ns3:PutAccelerateConfiguration  action.", "The bucket owner has this permission by default. \nThe bucket owner can grant this permission to others.", "For more information about permissions, see\nPermissions Related to Bucket Subresource Operations and Managing Access Permissions to Your \nAmazon S3 Resources.\nThe Transfer Acceleration state of a bucket can be set to one of the following two values:\n\u2022Enabled \u2013 Enables accelerated data transfers to the bucket.\n\u2022Suspended \u2013 Disables accelerated data transfers to the bucket.\nThe GetBucketAccelerateCon\ufb01guration action returns the transfer acceleration state of a bucket.\nAfter setting the Transfer Acceleration state of a bucket to Enabled, it might take up to thirty \nminutes before the data transfer rates to the bucket increase.\nThe name of the bucket used for Transfer Acceleration must be DNS-compliant and must not \ncontain periods (\".\").\nFor more information about transfer acceleration, see Transfer Acceleration.\nThe following operations are related to PutBucketAccelerateConfiguration :\n\u2022GetBucketAccelerateCon\ufb01guration\n\u2022CreateBucket\nRequest Syntax\nPUT /?accelerate HTTP/1.1\nAmazon S3 API Version 2006-03-01 488Amazon Simple Storage Service API Reference\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nx-amz-sdk-checksum-algorithm: ChecksumAlgorithm\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<AccelerateConfiguration  xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n   <Status>string</Status>\n</AccelerateConfiguration >\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe name of the bucket for which the accelerate con\ufb01guration is set.\nRequired: Yes\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner.", "If the account ID that you provide does not match \nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nx-amz-sdk-checksum-algorithm\nIndicates the algorithm used to create the checksum for the object when you use the SDK.", "This \nheader will not provide any additional functionality if you don't use the SDK.", "When you send \nthis header, there must be a corresponding x-amz-checksum  or x-amz-trailer  header sent.", "\nOtherwise, Amazon S3 fails the request with the HTTP status code 400 Bad Request . For \nmore information, see Checking object integrity in the Amazon S3 User Guide .\nIf you provide an individual checksum, Amazon S3 ignores any provided ChecksumAlgorithm\nparameter.\nValid Values: CRC32 | CRC32C | SHA1 | SHA256\nRequest Body\nThe request accepts the following data in XML format.\nAccelerateCon\ufb01guration\nRoot level tag for the AccelerateCon\ufb01guration parameters.\nAmazon S3 API Version 2006-03-01 489Amazon Simple Storage Service API Reference\nRequired: Yes\nStatus\nSpeci\ufb01es the transfer acceleration status of the bucket.\nType: String\nValid Values: Enabled | Suspended\nRequired: No\nResponse Syntax\nHTTP/1.1 200\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\nExamples\nSample Request: Add transfer acceleration con\ufb01guration to set acceleration status\nThe following is an example of a PUT /?accelerate  request that enables transfer acceleration \nfor the bucket named examplebucket .\nPUT /?accelerate HTTP/1.1\nHost: examplebucket.s3.<Region>.amazonaws.com\nDate: Mon, 11 Apr 2016 12:00:00 GMT\nAuthorization: authorization string\nContent-Type: text/plain\nContent-Length: length \n  \n<AccelerateConfiguration xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\">  \n  <Status>Enabled</Status>  \n</AccelerateConfiguration> \n          \nSample Response\nThis example illustrates one usage of PutBucketAccelerateCon\ufb01guration.\nAmazon S3 API Version 2006-03-01 490Amazon Simple Storage Service API Reference\nHTTP/1.1 200 OK\nx-amz-id-2: YgIPIfBiKa2bj0KMg95r/0zo3emzU4dzsD4rcKCHQUAdQkf3ShJTOOpXUueF6QKo\nx-amz-request-id: 236A8905248E5A01\nDate: Mon, 11 Apr 2016 12:00:00 GMT\nContent-Length: 0\nServer: AmazonS3 \n          \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 491Amazon Simple Storage Service API Reference\nPutBucketAcl\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nSets the permissions on an existing bucket using access control lists (ACL).", "For more information, \nsee Using ACLs.", "To set the ACL of a bucket, you must have the WRITE_ACP  permission.\nYou can use one of the following two ways to set a bucket's permissions:\n\u2022Specify the ACL in the request body\n\u2022Specify permissions using request headers\nNote\nYou cannot specify access permission using both the body and the request headers.\nDepending on your application needs, you may choose to set the ACL on a bucket using either the \nrequest body or the headers. For example, if you have an existing application that updates a bucket \nACL using the request body, then you can continue to use that approach.\nImportant\nIf your bucket uses the bucket owner enforced setting for S3 Object Ownership, ACLs \nare disabled and no longer a\ufb00ect permissions. You must use policies to grant access to \nyour bucket and the objects in it.", "Requests to set ACLs or update ACLs fail and return \nthe AccessControlListNotSupported  error code. Requests to read ACLs are still \nsupported.", "For more information, see Controlling object ownership in the Amazon S3 User \nGuide .\nPermissions\nYou can set access permissions by using one of the following methods:\nAmazon S3 API Version 2006-03-01 492Amazon Simple Storage Service API Reference\n\u2022Specify a canned ACL with the x-amz-acl  request header. Amazon S3 supports a set of \nprede\ufb01ned ACLs, known as canned ACLs.", "Each canned ACL has a prede\ufb01ned set of grantees \nand permissions. Specify the canned ACL name as the value of x-amz-acl .", "If you use this \nheader, you cannot use other access control-speci\ufb01c headers in your request. For more \ninformation, see Canned ACL.\n\u2022Specify access permissions explicitly with the x-amz-grant-read , x-amz-grant-read-\nacp, x-amz-grant-write-acp , and x-amz-grant-full-control  headers.", "When \nusing these headers, you specify explicit access permissions and grantees (AWS accounts or \nAmazon S3 groups) who will receive the permission.", "If you use these ACL-speci\ufb01c headers, \nyou cannot use the x-amz-acl  header to set a canned ACL.", "These parameters map to the set \nof permissions that Amazon S3 supports in an ACL.", "For more information, see Access Control \nList (ACL) Overview.\nYou specify each grantee as a type=value pair, where the type is one of the following:\n\u2022id \u2013 if the value speci\ufb01ed is the canonical user ID of an AWS account\n\u2022uri \u2013 if you are granting permissions to a prede\ufb01ned group\n\u2022emailAddress  \u2013 if the value speci\ufb01ed is the email address of an AWS account\nNote\nUsing email addresses to specify a grantee is only supported in the following AWS \nRegions:\n\u2022US East (N.", "Virginia)\n\u2022US West (N.", "California)\n\u2022US West (Oregon)\n\u2022Asia Paci\ufb01c (Singapore)\n\u2022Asia Paci\ufb01c (Sydney)\n\u2022Asia Paci\ufb01c (Tokyo)\n\u2022Europe (Ireland)\n\u2022South America (S\u00e3o Paulo)\nFor a list of all the Amazon S3 supported Regions and endpoints, see Regions and \nEndpoints  in the AWS General Reference.\nAmazon S3 API Version 2006-03-01 493Amazon Simple Storage Service API Reference\nFor example, the following x-amz-grant-write  header grants create, overwrite, and delete \nobjects permission to LogDelivery group prede\ufb01ned by Amazon S3 and two AWS accounts \nidenti\ufb01ed by their email addresses.\nx-amz-grant-write: uri=\"http://acs.amazonaws.com/groups/s3/\nLogDelivery\", id=\"111122223333\", id=\"555566667777\"\nYou can use either a canned ACL or specify access permissions explicitly. You cannot do both.\nGrantee Values\nYou can specify the person (grantee) to whom you're assigning access rights (using request \nelements) in the following ways:\n\u2022By the person's ID:\n<Grantee xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-\ninstance\" xsi:type=\"CanonicalUser\"><ID><>ID<></\nID><DisplayName><>GranteesEmail<></DisplayName> </Grantee>\nDisplayName is optional and ignored in the request\n\u2022By URI:\n<Grantee xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" \nxsi:type=\"Group\"><URI><>http://acs.amazonaws.com/groups/global/\nAuthenticatedUsers<></URI></Grantee>\n\u2022By Email address:\n<Grantee xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" \nxsi:type=\"AmazonCustomerByEmail\"><EmailAddress><>Grantees@email.com<></\nEmailAddress>&</Grantee>\nThe grantee is resolved to the CanonicalUser and, in a response to a GET Object acl request, \nappears as the CanonicalUser.\nNote\nUsing email addresses to specify a grantee is only supported in the following AWS \nRegions:\n\u2022US East (N.", "Virginia)\nAmazon S3 API Version 2006-03-01 494Amazon Simple Storage Service API Reference\n\u2022US West (N. California)\n\u2022US West (Oregon)\n\u2022Asia Paci\ufb01c (Singapore)\n\u2022Asia Paci\ufb01c (Sydney)\n\u2022Asia Paci\ufb01c (Tokyo)\n\u2022Europe (Ireland)\n\u2022South America (S\u00e3o Paulo)\nFor a list of all the Amazon S3 supported Regions and endpoints, see Regions and \nEndpoints  in the AWS General Reference.\nThe following operations are related to PutBucketAcl :\n\u2022CreateBucket\n\u2022DeleteBucket\n\u2022GetObjectAcl\nRequest Syntax\nPUT /?acl HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-acl: ACL\nContent-MD5: ContentMD5\nx-amz-sdk-checksum-algorithm: ChecksumAlgorithm\nx-amz-grant-full-control: GrantFullControl\nx-amz-grant-read: GrantRead\nx-amz-grant-read-acp: GrantReadACP\nx-amz-grant-write: GrantWrite\nx-amz-grant-write-acp: GrantWriteACP\nx-amz-expected-bucket-owner: ExpectedBucketOwner\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<AccessControlPolicy  xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n   <AccessControlList > \n      <Grant> \n         < Grantee> \n            < DisplayName >string</DisplayName > \n            < EmailAddress >string</EmailAddress > \n            < ID>string</ID> \nAmazon S3 API Version 2006-03-01 495Amazon Simple Storage Service API Reference\n            < xsi:type >string</xsi:type > \n            < URI>string</URI> \n         </ Grantee> \n         < Permission >string</Permission > \n      </Grant> \n   </AccessControlList > \n   <Owner> \n      <DisplayName >string</DisplayName > \n      <ID>string</ID> \n   </Owner>\n</AccessControlPolicy >\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe bucket to which to apply the ACL.\nRequired: Yes\nContent-MD5\nThe base64-encoded 128-bit MD5 digest of the data.", "This header must be used as a message \nintegrity check to verify that the request body was not corrupted in transit.", "For more \ninformation, go to RFC 1864.\nFor requests made using the AWS Command Line Interface (CLI) or AWS SDKs, this \ufb01eld is \ncalculated automatically.\nx-amz-acl\nThe canned ACL to apply to the bucket.\nValid Values: private | public-read | public-read-write | authenticated-read\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match \nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nx-amz-grant-full-control\nAllows grantee the read, write, read ACP, and write ACP permissions on the bucket.\nAmazon S3 API Version 2006-03-01 496Amazon Simple Storage Service API Reference\nx-amz-grant-read\nAllows grantee to list the objects in the bucket.\nx-amz-grant-read-acp\nAllows grantee to read the bucket ACL.\nx-amz-grant-write\nAllows grantee to create new objects in the bucket.\nFor the bucket and object owners of existing objects, also allows deletions and overwrites of \nthose objects.\nx-amz-grant-write-acp\nAllows grantee to write the ACL for the applicable bucket.\nx-amz-sdk-checksum-algorithm\nIndicates the algorithm used to create the checksum for the object when you use the SDK.", "This \nheader will not provide any additional functionality if you don't use the SDK.", "When you send \nthis header, there must be a corresponding x-amz-checksum  or x-amz-trailer  header sent.", "\nOtherwise, Amazon S3 fails the request with the HTTP status code 400 Bad Request . For \nmore information, see Checking object integrity in the Amazon S3 User Guide .\nIf you provide an individual checksum, Amazon S3 ignores any provided ChecksumAlgorithm\nparameter.\nValid Values: CRC32 | CRC32C | SHA1 | SHA256\nRequest Body\nThe request accepts the following data in XML format.\nAccessControlPolicy\nRoot level tag for the AccessControlPolicy parameters.\nRequired: Yes\nGrants\nA list of grants.\nAmazon S3 API Version 2006-03-01 497Amazon Simple Storage Service API Reference\nType: Array of Grant  data types\nRequired: No\nOwner\nContainer for the bucket owner's display name and ID.\nType: Owner  data type\nRequired: No\nResponse Syntax\nHTTP/1.1 200\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\nExamples\nSample Request: Access permissions speci\ufb01ed in the body\nThe following request grants access permission to the existing examplebucket  bucket.", "The \nrequest speci\ufb01es the ACL in the body.", "In addition to granting full control to the bucket owner, the \nXML speci\ufb01es the following grants.\n\u2022Grant the AllUsers  group READ permission on the bucket.\n\u2022Grant the LogDelivery  group WRITE permission on the bucket.\n\u2022Grant an AWS account, identi\ufb01ed by email address, WRITE_ACP permission.\n\u2022Grant an AWS account, identi\ufb01ed by canonical user ID, READ_ACP permission.\nPUT ?acl HTTP/1.1\nHost: examplebucket.s3.<Region>.amazonaws.com\nContent-Length: 1660\nx-amz-date: Thu, 12 Apr 2012 20:04:21 GMT\nAuthorization: authorization string\n<AccessControlPolicy xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \nAmazon S3 API Version 2006-03-01 498Amazon Simple Storage Service API Reference\n  <Owner> \n    <ID>852b113e7a2f25102679df27bb0ae12b3f85be6BucketOwnerCanonicalUserID</ID> \n    <DisplayName>OwnerDisplayName</DisplayName> \n  </Owner> \n  <AccessControlList> \n    <Grant> \n      <Grantee xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" \n xsi:type=\"CanonicalUser\"> \n        <ID>852b113e7a2f25102679df27bb0ae12b3f85be6BucketOwnerCanonicalUserID</ID> \n        <DisplayName>OwnerDisplayName</DisplayName> \n      </Grantee> \n      <Permission>FULL_CONTROL</Permission> \n    </Grant> \n    <Grant> \n      <Grantee xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:type=\"Group\"> \n        <URI xmlns=\"\">http://acs.amazonaws.com/groups/global/AllUsers</URI> \n      </Grantee> \n      <Permission xmlns=\"\">READ</Permission> \n    </Grant> \n    <Grant> \n      <Grantee xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:type=\"Group\"> \n        <URI xmlns=\"\">http://acs.amazonaws.com/groups/s3/LogDelivery</URI> \n      </Grantee> \n      <Permission xmlns=\"\">WRITE</Permission> \n    </Grant> \n    <Grant> \n      <Grantee xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" \n xsi:type=\"AmazonCustomerByEmail\"> \n        <EmailAddress xmlns=\"\">xyz@amazon.com</EmailAddress> \n      </Grantee> \n      <Permission xmlns=\"\">WRITE_ACP</Permission> \n    </Grant> \n    <Grant> \n      <Grantee xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" \n xsi:type=\"CanonicalUser\"> \n        <ID \n xmlns=\"\">f30716ab7115dcb44a5ef76e9d74b8e20567f63TestAccountCanonicalUserID</ID> \n      </Grantee> \n      <Permission xmlns=\"\">READ_ACP</Permission> \n    </Grant> \n  </AccessControlList>\n</AccessControlPolicy> \n          \nAmazon S3 API Version 2006-03-01 499Amazon Simple Storage Service API Reference\nSample Response\nThis example illustrates one usage of PutBucketAcl.\nHTTP/1.1 200 OK\nx-amz-id-2: NxqO3PNiMHXXGwjgv15LLgUoAmPVmG0xtZw2sxePXLhpIvcyouXDrcQUaWWXcOK0\nx-amz-request-id: C651BC9B4E1BD401\nDate: Thu, 12 Apr 2012 20:04:28 GMT\nContent-Length: 0\nServer: AmazonS3 \n          \nSample Request: Access permissions speci\ufb01ed using headers\nThe following request uses ACL-speci\ufb01c request headers to grant the following permissions:\n\u2022Write permission to the Amazon S3 LogDelivery  group and an AWS account identi\ufb01ed by the \nemail xyz@amazon.com .\n\u2022Read permission to the Amazon S3 AllUsers  group\nPUT ?acl HTTP/1.1\nHost: examplebucket.s3.<Region>.amazonaws.com\nx-amz-date: Sun, 29 Apr 2012 22:00:57 GMT\nx-amz-grant-write: uri=\"http://acs.amazonaws.com/groups/s3/LogDelivery\", \n emailAddress=\"xyz@amazon.com\"\nx-amz-grant-read: uri=\"http://acs.amazonaws.com/groups/global/AllUsers\"\nAccept: */*\nAuthorization: authorization string \n          \nSample Response\nThis example illustrates one usage of PutBucketAcl.\nHTTP/1.1 200 OK\nx-amz-id-2: 0w9iImt23VF9s6QofOTDzelF7mrryz7d04Mw23FQCi4O205Zw28Zn+d340/RytoQ\nx-amz-request-id: A6A8F01A38EC7138\nAmazon S3 API Version 2006-03-01 500Amazon Simple Storage Service API Reference\nDate: Sun, 29 Apr 2012 22:01:10 GMT\nContent-Length: 0\nServer: AmazonS3 \n          \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 501Amazon Simple Storage Service API Reference\nPutBucketAnalyticsCon\ufb01guration\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nSets an analytics con\ufb01guration for the bucket (speci\ufb01ed by the analytics con\ufb01guration ID).", "You can \nhave up to 1,000 analytics con\ufb01gurations per bucket.\nYou can choose to have storage class analysis export analysis reports sent to a comma-separated \nvalues (CSV) \ufb02at \ufb01le.", "See the DataExport  request element.", "Reports are updated daily and \nare based on the object \ufb01lters that you con\ufb01gure.", "When selecting data export, you specify a \ndestination bucket and an optional destination pre\ufb01x where the \ufb01le is written. You can export the \ndata to a destination bucket in a di\ufb00erent account.", "However, the destination bucket must be in \nthe same Region as the bucket that you are making the PUT analytics con\ufb01guration to.", "For more \ninformation, see Amazon S3 Analytics \u2013 Storage Class Analysis.\nImportant\nYou must create a bucket policy on the destination bucket where the exported \ufb01le is \nwritten to grant permissions to Amazon S3 to write objects to the bucket. For an example \npolicy, see Granting Permissions for Amazon S3 Inventory and Storage Class Analysis.\nTo use this operation, you must have permissions to perform the\ns3:PutAnalyticsConfiguration  action.", "The bucket owner has this permission by default. The \nbucket owner can grant this permission to others.", "For more information about permissions, see\nPermissions Related to Bucket Subresource Operations and Managing Access Permissions to Your \nAmazon S3 Resources.\nPutBucketAnalyticsConfiguration  has the following special errors:\n\u2022\u2022HTTP Error: HTTP 400 Bad Request\n\u2022Code: InvalidArgument\n\u2022Cause: Invalid argument.\n\u2022\u2022HTTP Error: HTTP 400 Bad Request\nAmazon S3 API Version 2006-03-01 502Amazon Simple Storage Service API Reference\n\u2022Code: TooManyCon\ufb01gurations\n\u2022Cause: You are attempting to create a new con\ufb01guration but have already reached the 1,000-\ncon\ufb01guration limit.\n\u2022\u2022HTTP Error: HTTP 403 Forbidden\n\u2022Code: AccessDenied\n\u2022Cause: You are not the owner of the speci\ufb01ed bucket, or you do not have the \ns3:PutAnalyticsCon\ufb01guration bucket permission to set the con\ufb01guration on the bucket.\nThe following operations are related to PutBucketAnalyticsConfiguration :\n\u2022GetBucketAnalyticsCon\ufb01guration\n\u2022DeleteBucketAnalyticsCon\ufb01guration\n\u2022ListBucketAnalyticsCon\ufb01gurations\nRequest Syntax\nPUT /?analytics&id= Id HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<AnalyticsConfiguration  xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n   <Id>string</Id> \n   <Filter> \n      <And> \n         < Prefix>string</Prefix> \n         < Tag> \n            < Key>string</Key> \n            < Value>string</Value> \n         </ Tag> \n         ... \n      </ And> \n      <Prefix>string</Prefix> \n      <Tag> \n         < Key>string</Key> \n         < Value>string</Value> \n      </ Tag> \n   </Filter> \n   <StorageClassAnalysis > \n      <DataExport > \nAmazon S3 API Version 2006-03-01 503Amazon Simple Storage Service API Reference\n         < Destination > \n            < S3BucketDestination > \n               < Bucket>string</Bucket> \n               < BucketAccountId >string</BucketAccountId > \n               < Format>string</Format> \n               < Prefix>string</Prefix> \n            </ S3BucketDestination > \n         </ Destination > \n         < OutputSchemaVersion >string</OutputSchemaVersion > \n      </ DataExport > \n   </StorageClassAnalysis >\n</AnalyticsConfiguration >\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe name of the bucket to which an analytics con\ufb01guration is stored.\nRequired: Yes\nid\nThe ID that identi\ufb01es the analytics con\ufb01guration.\nRequired: Yes\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match \nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nRequest Body\nThe request accepts the following data in XML format.\nAnalyticsCon\ufb01guration\nRoot level tag for the AnalyticsCon\ufb01guration parameters.\nRequired: Yes\nAmazon S3 API Version 2006-03-01 504Amazon Simple Storage Service API Reference\nFilter\nThe \ufb01lter used to describe a set of objects for analyses.", "A \ufb01lter must have exactly one pre\ufb01x, \none tag, or one conjunction (AnalyticsAndOperator). If no \ufb01lter is provided, all objects will be \nconsidered in any analysis.\nType: AnalyticsFilter data type\nRequired: No\nId\nThe ID that identi\ufb01es the analytics con\ufb01guration.\nType: String\nRequired: Yes\nStorageClassAnalysis\nContains data related to access patterns to be collected and made available to analyze the \ntradeo\ufb00s between di\ufb00erent storage classes.\nType: StorageClassAnalysis  data type\nRequired: Yes\nResponse Syntax\nHTTP/1.1 200\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\nExamples\nExample 1: Creating an analytics con\ufb01guration\nThe following PUT request for the bucket examplebucket  creates a new or replaces an existing \nanalytics con\ufb01guration with the ID report1. The con\ufb01guration is de\ufb01ned in the request body.\nAmazon S3 API Version 2006-03-01 505Amazon Simple Storage Service API Reference\nPUT /?analytics&id=report1 HTTP/1.1\nHost: examplebucket.s3.<Region>.amazonaws.com\nDate: Mon, 31 Oct 2016 12:00:00 GMT\nAuthorization: authorization string\nContent-Length: length \n  \n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<AnalyticsConfiguration xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n  <Id>report1</Id> \n  <Filter> \n    <And> \n      <Prefix>images/</Prefix> \n      <Tag> \n        <Key>dog</Key> \n        <Value>corgi</Value> \n      </Tag> \n    </And> \n  </Filter> \n  <StorageClassAnalysis> \n    <DataExport> \n      <OutputSchemaVersion>V_1</OutputSchemaVersion> \n      <Destination> \n        <S3BucketDestination> \n          <Format>CSV</Format> \n          <BucketAccountId>123456789012</BucketAccountId> \n          <Bucket>arn:aws:s3:::destination-bucket</Bucket> \n          <Prefix>destination-prefix</Prefix> \n        </S3BucketDestination> \n      </Destination> \n    </DataExport> \n  </StorageClassAnalysis>\n</AnalyticsConfiguration>\nSample Response\nThis example illustrates one usage of PutBucketAnalyticsCon\ufb01guration.\nHTTP/1.1 200 OK\nx-amz-id-2: YgIPIfBiKa2bj0KMg95r/0zo3emzU4dzsD4rcKCHQUAdQkf3ShJTOOpXUueF6QKo\nx-amz-request-id: 236A8905248E5A01\nDate: Mon, 31 Oct 2016 12:00:00 GMT\nAmazon S3 API Version 2006-03-01 506Amazon Simple Storage Service API Reference\nContent-Length: 0\nServer: AmazonS3 \n          \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 507Amazon Simple Storage Service API Reference\nPutBucketCors\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nSets the cors con\ufb01guration for your bucket. If the con\ufb01guration exists, Amazon S3 replaces it.\nTo use this operation, you must be allowed to perform the s3:PutBucketCORS  action.", "By default, \nthe bucket owner has this permission and can grant it to others.\nYou set this con\ufb01guration on a bucket so that the bucket can service cross-origin requests. For \nexample, you might want to enable a request whose origin is http://www.example.com\nto access your Amazon S3 bucket at my.example.bucket.com  by using the browser's\nXMLHttpRequest  capability.\nTo enable cross-origin resource sharing (CORS) on a bucket, you add the cors subresource to \nthe bucket.", "The cors subresource is an XML document in which you con\ufb01gure rules that identify \norigins and the HTTP methods that can be executed on your bucket.", "The document is limited to 64 \nKB in size.\nWhen Amazon S3 receives a cross-origin request (or a pre-\ufb02ight OPTIONS request) against a \nbucket, it evaluates the cors con\ufb01guration on the bucket and uses the \ufb01rst CORSRule  rule that \nmatches the incoming browser request to enable a cross-origin request. For a rule to match, the \nfollowing conditions must be met:\n\u2022The request's Origin  header must match AllowedOrigin  elements.\n\u2022The request method (for example, GET, PUT, HEAD, and so on) or the Access-Control-\nRequest-Method  header in case of a pre-\ufb02ight OPTIONS request must be one of the\nAllowedMethod  elements.\n\u2022Every header speci\ufb01ed in the Access-Control-Request-Headers  request header of a pre-\n\ufb02ight request must match an AllowedHeader  element.\nFor more information about CORS, go to Enabling Cross-Origin Resource Sharing in the Amazon S3 \nUser Guide .\nAmazon S3 API Version 2006-03-01 508Amazon Simple Storage Service API Reference\nThe following operations are related to PutBucketCors :\n\u2022GetBucketCors\n\u2022DeleteBucketCors\n\u2022RESTOPTIONSobject\nRequest Syntax\nPUT /?cors HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nContent-MD5: ContentMD5\nx-amz-sdk-checksum-algorithm: ChecksumAlgorithm\nx-amz-expected-bucket-owner: ExpectedBucketOwner\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<CORSConfiguration  xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n   <CORSRule > \n      <AllowedHeader >string</AllowedHeader > \n      ...", "\n      <AllowedMethod >string</AllowedMethod > \n      ... \n      <AllowedOrigin >string</AllowedOrigin > \n      ...", "\n      <ExposeHeader >string</ExposeHeader > \n      ...", "\n      <ID>string</ID> \n      <MaxAgeSeconds >integer</MaxAgeSeconds > \n   </CORSRule > \n   ...\n</CORSConfiguration >\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nSpeci\ufb01es the bucket impacted by the corscon\ufb01guration.\nRequired: Yes\nAmazon S3 API Version 2006-03-01 509Amazon Simple Storage Service API Reference\nContent-MD5\nThe base64-encoded 128-bit MD5 digest of the data.", "This header must be used as a message \nintegrity check to verify that the request body was not corrupted in transit.", "For more \ninformation, go to RFC 1864.\nFor requests made using the AWS Command Line Interface (CLI) or AWS SDKs, this \ufb01eld is \ncalculated automatically.\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match \nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nx-amz-sdk-checksum-algorithm\nIndicates the algorithm used to create the checksum for the object when you use the SDK.", "This \nheader will not provide any additional functionality if you don't use the SDK.", "When you send \nthis header, there must be a corresponding x-amz-checksum  or x-amz-trailer  header sent.", "\nOtherwise, Amazon S3 fails the request with the HTTP status code 400 Bad Request . For \nmore information, see Checking object integrity in the Amazon S3 User Guide .\nIf you provide an individual checksum, Amazon S3 ignores any provided ChecksumAlgorithm\nparameter.\nValid Values: CRC32 | CRC32C | SHA1 | SHA256\nRequest Body\nThe request accepts the following data in XML format.\nCORSCon\ufb01guration\nRoot level tag for the CORSCon\ufb01guration parameters.\nRequired: Yes\nCORSRule\nA set of origins and methods (cross-origin access that you want to allow). You can add up to 100 \nrules to the con\ufb01guration.\nAmazon S3 API Version 2006-03-01 510Amazon Simple Storage Service API Reference\nType: Array of CORSRule data types\nRequired: Yes\nResponse Syntax\nHTTP/1.1 200\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\nExamples\nExample: CORS con\ufb01guration on a bucket with two rules\n\u2022The \ufb01rst CORSRule  allows cross-origin PUT, POST, and DELETE requests whose origin is\nhttp://www.example.com  origins.", "The rule also allows all headers in a pre-\ufb02ight OPTIONS \nrequest through the Access-Control-Request-Headers  header.", "Therefore, in response to \nany pre-\ufb02ight OPTIONS request, Amazon S3 will return any requested headers.\n\u2022The second rule allows cross-origin GET requests from all the origins. The '*' wildcard character \nrefers to all origins.\n<CORSConfiguration> \n <CORSRule> \n   <AllowedOrigin>http://www.example.com</AllowedOrigin> \n   <AllowedMethod>PUT</AllowedMethod> \n   <AllowedMethod>POST</AllowedMethod> \n   <AllowedMethod>DELETE</AllowedMethod> \n   <AllowedHeader>*</AllowedHeader> \n </CORSRule> \n <CORSRule> \n   <AllowedOrigin>*</AllowedOrigin> \n   <AllowedMethod>GET</AllowedMethod> \n </CORSRule>\n</CORSConfiguration>\nAmazon S3 API Version 2006-03-01 511Amazon Simple Storage Service API Reference\nExample: CORS con\ufb01guration allows cross-origin PUT and POST requests from http://\nwww.example.com\nThe cors con\ufb01guration also allows additional optional con\ufb01guration parameters as shown in the \nfollowing cors con\ufb01guration on a bucket. For example,\nIn the preceding con\ufb01guration, CORSRule  includes the following additional optional parameters:\n\u2022MaxAgeSeconds \u2014Speci\ufb01es the time in seconds that the browser will cache an Amazon S3 \nresponse to a pre-\ufb02ight OPTIONS request for the speci\ufb01ed resource.", "In this example, this \nparameter is 3000 seconds.", "Caching enables the browsers to avoid sending pre-\ufb02ight OPTIONS \nrequest to Amazon S3 for repeated requests.\n\u2022ExposeHeader \u2014Identi\ufb01es the response header (in this case x-amz-server-side-\nencryption ) that you want customers to be able to access from their applications (for example, \nfrom a JavaScript XMLHttpRequest  object).\n<CORSConfiguration> \n <CORSRule> \n   <AllowedOrigin>http://www.example.com</AllowedOrigin> \n   <AllowedMethod>PUT</AllowedMethod> \n   <AllowedMethod>POST</AllowedMethod> \n   <AllowedMethod>DELETE</AllowedMethod> \n   <AllowedHeader>*</AllowedHeader>\n   <MaxAgeSeconds>3000</MaxAgeSeconds> \n   <ExposeHeader>x-amz-server-side-encryption</ExposeHeader>\n </CORSRule>\n</CORSConfiguration>\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\nAmazon S3 API Version 2006-03-01 512Amazon Simple Storage Service API Reference\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 513Amazon Simple Storage Service API Reference\nPutBucketEncryption\nService: Amazon S3\nThis operation con\ufb01gures default encryption and Amazon S3 Bucket Keys for an existing bucket.\nNote\nDirectory buckets  - For directory buckets, you must make requests for this API operation \nto the Regional endpoint. These endpoints support path-style requests in the format\nhttps://s3express-control.", "region_code .amazonaws.com/ bucket-name  .", "\nVirtual-hosted-style requests aren't supported.", "For more information, see Regional and \nZonal endpoints in the Amazon S3 User Guide .\nBy default, all buckets have a default encryption con\ufb01guration that uses server-side encryption \nwith Amazon S3 managed keys (SSE-S3).\nNote\n\u2022General purpose buckets\n\u2022You can optionally con\ufb01gure default encryption for a bucket by using server-side \nencryption with AWS Key Management Service (AWS KMS) keys (SSE-KMS) or dual-\nlayer server-side encryption with AWS KMS keys (DSSE-KMS). If you specify default \nencryption by using SSE-KMS, you can also con\ufb01gure Amazon S3 Bucket Keys. For \ninformation about the bucket default encryption feature, see Amazon S3 Bucket \nDefault Encryption in the Amazon S3 User Guide .\n\u2022If you use PutBucketEncryption to set your default bucket encryption to SSE-KMS, you \nshould verify that your KMS key ID is correct. Amazon S3 doesn't validate the KMS key \nID provided in PutBucketEncryption requests.\n\u2022Directory buckets  - You can optionally con\ufb01gure default encryption for a bucket by \nusing server-side encryption with AWS Key Management Service (AWS KMS) keys (SSE-\nKMS).\n\u2022We recommend that the bucket's default encryption uses the desired encryption \ncon\ufb01guration and you don't override the bucket default encryption in your\nCreateSession  requests or PUT object requests.", "Then, new objects are automatically \nencrypted with the desired encryption settings.", "For more information about the \nAmazon S3 API Version 2006-03-01 514Amazon Simple Storage Service API Reference\nencryption overriding behaviors in directory buckets, see Specifying server-side \nencryption with AWS KMS for new object uploads.\n\u2022Your SSE-KMS con\ufb01guration can only support 1 customer managed key per directory \nbucket for the lifetime of the bucket. The AWS managed key (aws/s3) isn't supported.\n\u2022S3 Bucket Keys are always enabled for GET and PUT operations in a directory \nbucket and can\u2019t be disabled. S3 Bucket Keys aren't supported, when you copy SSE-\nKMS encrypted objects from general purpose buckets to directory buckets, from \ndirectory buckets to general purpose buckets, or between directory buckets, through\nCopyObject, UploadPartCopy, the Copy operation in Batch Operations, or the import \njobs. In this case, Amazon S3 makes a call to AWS KMS every time a copy request is \nmade for a KMS-encrypted object.\n\u2022When you specify an AWS KMS customer managed key for encryption in your directory \nbucket, only use the key ID or key ARN. The key alias format of the KMS key isn't \nsupported.\n\u2022For directory buckets, if you use PutBucketEncryption to set your default bucket \nencryption to SSE-KMS, Amazon S3 validates the KMS key ID provided in \nPutBucketEncryption requests.\nImportant\nIf you're specifying a customer managed KMS key, we recommend using a fully quali\ufb01ed \nKMS key ARN. If you use a KMS key alias instead, then AWS KMS resolves the key within the \nrequester\u2019s account. This behavior can result in data that's encrypted with a KMS key that \nbelongs to the requester, and not the bucket owner.\nAlso, this action requires AWS Signature Version 4. For more information, see \nAuthenticating Requests (AWS Signature Version 4).\nPermissions\n\u2022General purpose bucket permissions - The s3:PutEncryptionConfiguration\npermission is required in a policy.", "The bucket owner has this permission by default. The \nbucket owner can grant this permission to others.", "For more information about permissions, \nsee Permissions Related to Bucket Operations and Managing Access Permissions to Your \nAmazon S3 Resources in the Amazon S3 User Guide .\nAmazon S3 API Version 2006-03-01 515Amazon Simple Storage Service API Reference\n\u2022Directory bucket permissions - To grant access to this API operation, you must have the\ns3express:PutEncryptionConfiguration  permission in an IAM identity-based policy \ninstead of a bucket policy.", "Cross-account access to this API operation isn't supported.", "This \noperation can only be performed by the AWS account that owns the resource.", "For more \ninformation about directory bucket policies and permissions, see AWS Identity and Access \nManagement (IAM) for S3 Express One Zone in the Amazon S3 User Guide .\nTo set a directory bucket default encryption with SSE-KMS, you must also have the\nkms:GenerateDataKey  and the kms:Decrypt  permissions in IAM identity-based policies \nand AWS KMS key policies for the target AWS KMS key.\nHTTP Host header syntax\nDirectory buckets  - The HTTP Host header syntax is s3express-\ncontrol. region.amazonaws.com .\nThe following operations are related to PutBucketEncryption :\n\u2022GetBucketEncryption\n\u2022DeleteBucketEncryption\nRequest Syntax\nPUT /?encryption HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nContent-MD5: ContentMD5\nx-amz-sdk-checksum-algorithm: ChecksumAlgorithm\nx-amz-expected-bucket-owner: ExpectedBucketOwner\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<ServerSideEncryptionConfiguration  xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n   <Rule> \n      <ApplyServerSideEncryptionByDefault > \n         < KMSMasterKeyID >string</KMSMasterKeyID > \n         < SSEAlgorithm >string</SSEAlgorithm > \n      </ ApplyServerSideEncryptionByDefault > \n      <BucketKeyEnabled >boolean</BucketKeyEnabled > \n   </Rule> \n   ...\n</ServerSideEncryptionConfiguration >\nAmazon S3 API Version 2006-03-01 516Amazon Simple Storage Service API Reference\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nSpeci\ufb01es default encryption for a bucket using server-side encryption with di\ufb00erent key \noptions.\nDirectory buckets  - When you use this operation with a directory bucket, \nyou must use path-style requests in the format https://s3express-\ncontrol.", "region_code .amazonaws.com/ bucket-name  .", "Virtual-hosted-style requests \naren't supported.", "Directory bucket names must be unique in the chosen Availability Zone.", "\nBucket names must also follow the format  bucket_base_name --az_id--x-s3  (for \nexample,  DOC-EXAMPLE-BUCKET --usw2-az1 --x-s3). For information about bucket naming \nrestrictions, see Directory bucket naming rules in the Amazon S3 User Guide\nRequired: Yes\nContent-MD5\nThe base64-encoded 128-bit MD5 digest of the server-side encryption con\ufb01guration.\nFor requests made using the AWS Command Line Interface (CLI) or AWS SDKs, this \ufb01eld is \ncalculated automatically.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner.", "If the account ID that you provide does not match \nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nNote\nFor directory buckets, this header is not supported in this API operation.", "If you specify \nthis header, the request fails with the HTTP status code 501 Not Implemented .\nAmazon S3 API Version 2006-03-01 517Amazon Simple Storage Service API Reference\nx-amz-sdk-checksum-algorithm\nIndicates the algorithm used to create the checksum for the object when you use the SDK.", "This \nheader will not provide any additional functionality if you don't use the SDK.", "When you send \nthis header, there must be a corresponding x-amz-checksum  or x-amz-trailer  header sent.", "\nOtherwise, Amazon S3 fails the request with the HTTP status code 400 Bad Request . For \nmore information, see Checking object integrity in the Amazon S3 User Guide .\nIf you provide an individual checksum, Amazon S3 ignores any provided ChecksumAlgorithm\nparameter.\nNote\nFor directory buckets, when you use AWS SDKs, CRC32  is the default checksum \nalgorithm that's used for performance.\nValid Values: CRC32 | CRC32C | SHA1 | SHA256\nRequest Body\nThe request accepts the following data in XML format.\nServerSideEncryptionCon\ufb01guration\nRoot level tag for the ServerSideEncryptionCon\ufb01guration parameters.\nRequired: Yes\nRule\nContainer for information about a particular server-side encryption con\ufb01guration rule.\nType: Array of ServerSideEncryptionRule data types\nRequired: Yes\nResponse Syntax\nHTTP/1.1 200\nAmazon S3 API Version 2006-03-01 518Amazon Simple Storage Service API Reference\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\nExamples\nIn the request, you specify the encryption con\ufb01guration in the request body. The encryption \ncon\ufb01guration is speci\ufb01ed as XML, as shown in the following examples that show setting encryption \nusing SSE-S3, SSE-KMS, or DSSE-KMS.\nRequest Body for Setting SSE-S3 for general purpose buckets\nThis example illustrates one usage of PutBucketEncryption.\n           <ServerSideEncryptionConfiguration xmlns=\"http://s3.amazonaws.com/\ndoc/2006-03-01/\"> \n               <Rule> \n                  <ApplyServerSideEncryptionByDefault> \n                     <SSEAlgorithm>AES256</SSEAlgorithm> \n                  </ApplyServerSideEncryptionByDefault> \n               </Rule> \n            </ServerSideEncryptionConfiguration> \n         \nRequest Body for Setting SSE-KMS for general purpose buckets\nThis example illustrates one usage of PutBucketEncryption.\n           <ServerSideEncryptionConfiguration xmlns=\"http://s3.amazonaws.com/\ndoc/2006-03-01/\"> \n               <Rule> \n                  <ApplyServerSideEncryptionByDefault> \n                      <SSEAlgorithm>aws:kms:dsse</SSEAlgorithm> \n                      <KMSKeyID>arn:aws:kms:us-east-1:1234/5678example</KMSKeyID> \n                  </ApplyServerSideEncryptionByDefault> \n               </Rule> \n            </ServerSideEncryptionConfiguration> \n         \nAmazon S3 API Version 2006-03-01 519Amazon Simple Storage Service API Reference\nSet the Default Encryption Con\ufb01guration for an S3 general purpose bucket\nThe following is an example of a PUT /? encryption request that speci\ufb01es to use SSE-KMS \nencryption.\nPUT /?encryption HTTP/1.1\nHost: examplebucket.<Region>s3.amazonaws.com\nDate: Wed, 06 Sep 2017 12:00:00 GMT\nAuthorization: authorization  \nContent-Length: length\n<ServerSideEncryptionConfiguration xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n  <Rule> \n    <ApplyServerSideEncryptionByDefault> \n        <SSEAlgorithm>aws:kms</SSEAlgorithm> \n        <KMSKeyID>arn:aws:kms:us-east-1:1234/5678example</KMSKeyID> \n    </ApplyServerSideEncryptionByDefault>\n</Rule>\n</ServerSideEncryptionConfiguration> \n         \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 520Amazon Simple Storage Service API Reference\nPutBucketIntelligentTieringCon\ufb01guration\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nPuts a S3 Intelligent-Tiering con\ufb01guration to the speci\ufb01ed bucket. You can have up to 1,000 S3 \nIntelligent-Tiering con\ufb01gurations per bucket.\nThe S3 Intelligent-Tiering storage class is designed to optimize storage costs by automatically \nmoving data to the most cost-e\ufb00ective storage access tier, without performance impact or \noperational overhead. S3 Intelligent-Tiering delivers automatic cost savings in three low latency \nand high throughput access tiers. To get the lowest storage cost on data that can be accessed in \nminutes to hours, you can choose to activate additional archiving capabilities.\nThe S3 Intelligent-Tiering storage class is the ideal storage class for data with unknown, changing, \nor unpredictable access patterns, independent of object size or retention period.", "If the size of an \nobject is less than 128 KB, it is not monitored and not eligible for auto-tiering.", "Smaller objects can \nbe stored, but they are always charged at the Frequent Access tier rates in the S3 Intelligent-Tiering \nstorage class.\nFor more information, see Storage class for automatically optimizing frequently and infrequently \naccessed objects.\nOperations related to PutBucketIntelligentTieringConfiguration  include:\n\u2022DeleteBucketIntelligentTieringCon\ufb01guration\n\u2022GetBucketIntelligentTieringCon\ufb01guration\n\u2022ListBucketIntelligentTieringCon\ufb01gurations\nNote\nYou only need S3 Intelligent-Tiering enabled on a bucket if you want to automatically \nmove objects stored in the S3 Intelligent-Tiering storage class to the Archive Access or \nDeep Archive Access tier.\nAmazon S3 API Version 2006-03-01 521Amazon Simple Storage Service API Reference\nPutBucketIntelligentTieringConfiguration  has the following special errors:\nHTTP 400 Bad Request Error\nCode:  InvalidArgument\nCause:  Invalid Argument\nHTTP 400 Bad Request Error\nCode:  TooManyCon\ufb01gurations\nCause:  You are attempting to create a new con\ufb01guration but have already reached the 1,000-\ncon\ufb01guration limit.\nHTTP 403 Forbidden Error\nCause:  You are not the owner of the speci\ufb01ed bucket, or you do not have the\ns3:PutIntelligentTieringConfiguration  bucket permission to set the con\ufb01guration on \nthe bucket.\nRequest Syntax\nPUT /?intelligent-tiering&id= Id HTTP/1.1\nHost: Bucket.s3.amazonaws.com\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<IntelligentTieringConfiguration  xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n   <Id>string</Id> \n   <Filter> \n      <And> \n         < Prefix>string</Prefix> \n         < Tag> \n            < Key>string</Key> \n            < Value>string</Value> \n         </ Tag> \n         ... \n      </ And> \n      <Prefix>string</Prefix> \n      <Tag> \n         < Key>string</Key> \n         < Value>string</Value> \n      </ Tag> \n   </Filter> \n   <Status>string</Status> \nAmazon S3 API Version 2006-03-01 522Amazon Simple Storage Service API Reference\n   <Tiering> \n      <AccessTier >string</AccessTier > \n      <Days>integer</Days> \n   </Tiering> \n   ...\n</IntelligentTieringConfiguration >\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe name of the Amazon S3 bucket whose con\ufb01guration you want to modify or retrieve.\nRequired: Yes\nid\nThe ID used to identify the S3 Intelligent-Tiering con\ufb01guration.\nRequired: Yes\nRequest Body\nThe request accepts the following data in XML format.\nIntelligentTieringCon\ufb01guration\nRoot level tag for the IntelligentTieringCon\ufb01guration parameters.\nRequired: Yes\nFilter\nSpeci\ufb01es a bucket \ufb01lter. The con\ufb01guration only includes objects that meet the \ufb01lter's criteria.\nType: IntelligentTieringFilter  data type\nRequired: No\nId\nThe ID used to identify the S3 Intelligent-Tiering con\ufb01guration.\nAmazon S3 API Version 2006-03-01 523Amazon Simple Storage Service API Reference\nType: String\nRequired: Yes\nStatus\nSpeci\ufb01es the status of the con\ufb01guration.\nType: String\nValid Values: Enabled | Disabled\nRequired: Yes\nTiering\nSpeci\ufb01es the S3 Intelligent-Tiering storage class tier of the con\ufb01guration.\nType: Array of Tiering  data types\nRequired: Yes\nResponse Syntax\nHTTP/1.1 200\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\nAmazon S3 API Version 2006-03-01 524Amazon Simple Storage Service API Reference\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 525Amazon Simple Storage Service API Reference\nPutBucketInventoryCon\ufb01guration\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nThis implementation of the PUT action adds an inventory con\ufb01guration (identi\ufb01ed by the inventory \nID) to the bucket. You can have up to 1,000 inventory con\ufb01gurations per bucket.\nAmazon S3 inventory generates inventories of the objects in the bucket on a daily or weekly \nbasis, and the results are published to a \ufb02at \ufb01le. The bucket that is inventoried is called the source\nbucket, and the bucket where the inventory \ufb02at \ufb01le is stored is called the destination  bucket. The\ndestination  bucket must be in the same AWS Region as the source  bucket.\nWhen you con\ufb01gure an inventory for a source  bucket, you specify the destination  bucket where you \nwant the inventory to be stored, and whether to generate the inventory daily or weekly.", "You can \nalso con\ufb01gure what object metadata to include and whether to inventory all object versions or only \ncurrent versions.", "For more information, see Amazon S3 Inventory in the Amazon S3 User Guide.\nImportant\nYou must create a bucket policy on the destination  bucket to grant permissions to Amazon \nS3 to write objects to the bucket in the de\ufb01ned location. For an example policy, see \nGranting Permissions for Amazon S3 Inventory and Storage Class Analysis.\nPermissions\nTo use this operation, you must have permission to perform the\ns3:PutInventoryConfiguration  action. The bucket owner has this permission by default \nand can grant this permission to others.\nThe s3:PutInventoryConfiguration  permission allows a user to create an S3 Inventory\nreport that includes all object metadata \ufb01elds available and to specify the destination bucket to \nstore the inventory. A user with read access to objects in the destination bucket can also access \nall object metadata \ufb01elds that are available in the inventory report.\nAmazon S3 API Version 2006-03-01 526Amazon Simple Storage Service API Reference\nTo restrict access to an inventory report, see Restricting access to an Amazon S3 Inventory \nreport in the Amazon S3 User Guide . For more information about the metadata \ufb01elds available \nin S3 Inventory, see Amazon S3 Inventory lists in the Amazon S3 User Guide . For more \ninformation about permissions, see Permissions related to bucket subresource operations and\nIdentity and access management in Amazon S3 in the Amazon S3 User Guide .\nPutBucketInventoryConfiguration  has the following special errors:\nHTTP 400 Bad Request Error\nCode:  InvalidArgument\nCause:  Invalid Argument\nHTTP 400 Bad Request Error\nCode:  TooManyCon\ufb01gurations\nCause:  You are attempting to create a new con\ufb01guration but have already reached the 1,000-\ncon\ufb01guration limit.\nHTTP 403 Forbidden Error\nCause:  You are not the owner of the speci\ufb01ed bucket, or you do not have the\ns3:PutInventoryConfiguration  bucket permission to set the con\ufb01guration on the bucket.\nThe following operations are related to PutBucketInventoryConfiguration :\n\u2022GetBucketInventoryCon\ufb01guration\n\u2022DeleteBucketInventoryCon\ufb01guration\n\u2022ListBucketInventoryCon\ufb01gurations\nRequest Syntax\nPUT /?inventory&id= Id HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<InventoryConfiguration  xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \nAmazon S3 API Version 2006-03-01 527Amazon Simple Storage Service API Reference\n   <Destination > \n      <S3BucketDestination > \n         < AccountId >string</AccountId > \n         < Bucket>string</Bucket> \n         < Encryption > \n            < SSE-KMS> \n               < KeyId>string</KeyId> \n            </ SSE-KMS> \n            < SSE-S3> \n            </ SSE-S3> \n         </ Encryption > \n         < Format>string</Format> \n         < Prefix>string</Prefix> \n      </ S3BucketDestination > \n   </Destination > \n   <IsEnabled >boolean</IsEnabled > \n   <Filter> \n      <Prefix>string</Prefix> \n   </Filter> \n   <Id>string</Id> \n   <IncludedObjectVersions >string</IncludedObjectVersions > \n   <OptionalFields > \n      <Field> string</Field> \n   </OptionalFields > \n   <Schedule > \n      <Frequency >string</Frequency > \n   </Schedule >\n</InventoryConfiguration >\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe name of the bucket where the inventory con\ufb01guration will be stored.\nRequired: Yes\nid\nThe ID used to identify the inventory con\ufb01guration.\nRequired: Yes\nAmazon S3 API Version 2006-03-01 528Amazon Simple Storage Service API Reference\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner.", "If the account ID that you provide does not match \nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nRequest Body\nThe request accepts the following data in XML format.\nInventoryCon\ufb01guration\nRoot level tag for the InventoryCon\ufb01guration parameters.\nRequired: Yes\nDestination\nContains information about where to publish the inventory results.\nType: InventoryDestination data type\nRequired: Yes\nFilter\nSpeci\ufb01es an inventory \ufb01lter. The inventory only includes objects that meet the \ufb01lter's criteria.\nType: InventoryFilter data type\nRequired: No\nId\nThe ID used to identify the inventory con\ufb01guration.\nType: String\nRequired: Yes\nIncludedObjectVersions\nObject versions to include in the inventory list.", "If set to All, the list includes all the object \nversions, which adds the version-related \ufb01elds VersionId , IsLatest , and DeleteMarker  to \nthe list.", "If set to Current, the list does not contain these version-related \ufb01elds.\nAmazon S3 API Version 2006-03-01 529Amazon Simple Storage Service API Reference\nType: String\nValid Values: All | Current\nRequired: Yes\nIsEnabled\nSpeci\ufb01es whether the inventory is enabled or disabled.", "If set to True, an inventory list is \ngenerated. If set to False, no inventory list is generated.\nType: Boolean\nRequired: Yes\nOptionalFields\nContains the optional \ufb01elds that are included in the inventory results.\nType: Array of strings\nValid Values: Size | LastModifiedDate | StorageClass | ETag | \nIsMultipartUploaded | ReplicationStatus | EncryptionStatus | \nObjectLockRetainUntilDate | ObjectLockMode | ObjectLockLegalHoldStatus \n| IntelligentTieringAccessTier | BucketKeyStatus | ChecksumAlgorithm | \nObjectAccessControlList | ObjectOwner\nRequired: No\nSchedule\nSpeci\ufb01es the schedule for generating inventory results.\nType: InventorySchedule data type\nRequired: Yes\nResponse Syntax\nHTTP/1.1 200\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\nAmazon S3 API Version 2006-03-01 530Amazon Simple Storage Service API Reference\nExamples\nExample: Create an inventory con\ufb01guration\nThe following PUT request and response for the bucket examplebucket  creates a new or replaces \nan existing inventory con\ufb01guration with the ID report1. The con\ufb01guration is de\ufb01ned in the \nrequest body.\nPUT /?inventory&id=report1 HTTP/1.1\nHost: examplebucket.s3.<Region>.amazonaws.com\nDate: Mon, 31 Oct 2016 12:00:00 GMT\nAuthorization: authorization string\nContent-Length: length \n  \n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<InventoryConfiguration xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n   <Id>report1</Id> \n   <IsEnabled>true</IsEnabled> \n   <Filter> \n      <Prefix>filterPrefix</Prefix> \n   </Filter> \n   <Destination> \n      <S3BucketDestination> \n         <Format>CSV</Format> \n         <AccountId>123456789012</AccountId> \n         <Bucket>arn:aws:s3:::destination-bucket</Bucket> \n         <Prefix>prefix1</Prefix> \n         <Encryption> \n            <SSE-KMS> \n               <KeyId>arn:aws:kms:us-\nwest-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab</KeyId> \n            </SSE-KMS> \n         </Encryption> \n      </S3BucketDestination> \n   </Destination> \n   <Schedule> \n      <Frequency>Daily</Frequency> \n   </Schedule> \n   <IncludedObjectVersions>All</IncludedObjectVersions> \n   <OptionalFields> \n      <Field>Size</Field> \n      <Field>LastModifiedDate</Field> \n      <Field>ETag</Field> \nAmazon S3 API Version 2006-03-01 531Amazon Simple Storage Service API Reference\n      <Field>StorageClass</Field> \n      <Field>IsMultipartUploaded</Field> \n      <Field>ReplicationStatus</Field> \n      <Field>EncryptionStatus</Field> \n      <Field>ObjectLockRetainUntilDate</Field>  \n      <Field>ObjectLockMode</Field> \n      <Field>ObjectLockLegalHoldStatus</Field>       \n   </OptionalFields>\n</InventoryConfiguration> \n            \nHTTP/1.1 200 OK\nx-amz-id-2: YgIPIfBiKa2bj0KMg95r/0zo3emzU4dzsD4rcKCHQUAdQkf3ShJTOOpXUueF6QKo\nx-amz-request-id: 236A8905248E5A01\nDate: Mon, 31 Oct 2016 12:00:00 GMT\nContent-Length: 0\nServer: AmazonS3 \n            \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 532Amazon Simple Storage Service API Reference\nPutBucketLifecycle\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nImportant\nFor an updated version of this API, see PutBucketLifecycleCon\ufb01guration.", "This version \nhas been deprecated. Existing lifecycle con\ufb01gurations will work. For new lifecycle \ncon\ufb01gurations, use the updated API.\nCreates a new lifecycle con\ufb01guration for the bucket or replaces an existing lifecycle con\ufb01guration.", "\nFor information about lifecycle con\ufb01guration, see Object Lifecycle Management in the Amazon S3 \nUser Guide .\nBy default, all Amazon S3 resources, including buckets, objects, and related subresources (for \nexample, lifecycle con\ufb01guration and website con\ufb01guration) are private.", "Only the resource owner, \nthe AWS account that created the resource, can access it. The resource owner can optionally grant \naccess permissions to others by writing an access policy.", "For this operation, users must get the\ns3:PutLifecycleConfiguration  permission.\nYou can also explicitly deny permissions.", "Explicit denial also supersedes any other permissions.", "If \nyou want to prevent users or accounts from removing or deleting objects from your bucket, you \nmust deny them permissions for the following actions:\n\u2022s3:DeleteObject\n\u2022s3:DeleteObjectVersion\n\u2022s3:PutLifecycleConfiguration\nFor more information about permissions, see Managing Access Permissions to your Amazon S3 \nResources in the Amazon S3 User Guide .\nFor more examples of transitioning objects to storage classes such as STANDARD_IA or \nONEZONE_IA, see Examples of Lifecycle Con\ufb01guration.\nAmazon S3 API Version 2006-03-01 533Amazon Simple Storage Service API Reference\nThe following operations are related to PutBucketLifecycle :\n\u2022GetBucketLifecycle(Deprecated)\n\u2022GetBucketLifecycleCon\ufb01guration\n\u2022RestoreObject\n\u2022By default, a resource owner\u2014in this case, a bucket owner, which is the AWS account that \ncreated the bucket\u2014can perform any of the operations.", "A resource owner can also grant others \npermission to perform the operation.", "For more information, see the following topics in the \nAmazon S3 User Guide:\n\u2022Specifying Permissions in a Policy\n\u2022Managing Access Permissions to your Amazon S3 Resources\nRequest Syntax\nPUT /?lifecycle HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nContent-MD5: ContentMD5\nx-amz-sdk-checksum-algorithm: ChecksumAlgorithm\nx-amz-expected-bucket-owner: ExpectedBucketOwner\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<LifecycleConfiguration  xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n   <Rule> \n      <AbortIncompleteMultipartUpload > \n         < DaysAfterInitiation >integer</DaysAfterInitiation > \n      </ AbortIncompleteMultipartUpload > \n      <Expiration > \n         < Date>timestamp </Date> \n         < Days>integer</Days> \n         < ExpiredObjectDeleteMarker >boolean</ExpiredObjectDeleteMarker > \n      </ Expiration > \n      <ID>string</ID> \n      <NoncurrentVersionExpiration > \n         < NewerNoncurrentVersions >integer</NewerNoncurrentVersions > \n         < NoncurrentDays >integer</NoncurrentDays > \n      </ NoncurrentVersionExpiration > \n      <NoncurrentVersionTransition > \n         < NewerNoncurrentVersions >integer</NewerNoncurrentVersions > \n         < NoncurrentDays >integer</NoncurrentDays > \n         < StorageClass >string</StorageClass > \n      </ NoncurrentVersionTransition > \nAmazon S3 API Version 2006-03-01 534Amazon Simple Storage Service API Reference\n      <Prefix>string</Prefix> \n      <Status>string</Status> \n      <Transition > \n         < Date>timestamp </Date> \n         < Days>integer</Days> \n         < StorageClass >string</StorageClass > \n      </ Transition > \n   </Rule> \n   ...\n</LifecycleConfiguration >\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nRequired: Yes\nContent-MD5\nFor requests made using the AWS Command Line Interface (CLI) or AWS SDKs, this \ufb01eld is \ncalculated automatically.\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match \nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nx-amz-sdk-checksum-algorithm\nIndicates the algorithm used to create the checksum for the object when you use the SDK.", "This \nheader will not provide any additional functionality if you don't use the SDK.", "When you send \nthis header, there must be a corresponding x-amz-checksum  or x-amz-trailer  header sent.", "\nOtherwise, Amazon S3 fails the request with the HTTP status code 400 Bad Request . For \nmore information, see Checking object integrity in the Amazon S3 User Guide .\nIf you provide an individual checksum, Amazon S3 ignores any provided ChecksumAlgorithm\nparameter.\nValid Values: CRC32 | CRC32C | SHA1 | SHA256\nAmazon S3 API Version 2006-03-01 535Amazon Simple Storage Service API Reference\nRequest Body\nThe request accepts the following data in XML format.\nLifecycleCon\ufb01guration\nRoot level tag for the LifecycleCon\ufb01guration parameters.\nRequired: Yes\nRule\nSpeci\ufb01es lifecycle con\ufb01guration rules for an Amazon S3 bucket.\nType: Array of Rule  data types\nRequired: Yes\nResponse Syntax\nHTTP/1.1 200\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\nExamples\nSample Request: Body of a basic lifecycle con\ufb01guration\nIn the request, you specify the lifecycle con\ufb01guration in the request body.", "The lifecycle \ncon\ufb01guration is speci\ufb01ed as XML. The following is an example of a basic lifecycle con\ufb01guration. \nIt speci\ufb01es one rule. The Prefix in the rule identi\ufb01es objects to which the rule applies. The rule \nalso speci\ufb01es two actions (Transition  and Expiration ).", "Each action speci\ufb01es a time line \nwhen Amazon S3 should perform the action. The Status indicates whether the rule is enabled or \ndisabled.\n<LifecycleConfiguration> \n    <Rule> \n        <ID>sample-rule</ID> \n        <Prefix>key-prefix</Prefix> \nAmazon S3 API Version 2006-03-01 536Amazon Simple Storage Service API Reference\n        <Status>rule-status</Status> \n        <Transition>         \n           <Date>value</Date>         \n           <StorageClass>storage class</StorageClass>        \n        </Transition>     \n        <Expiration> \n           <Days>value</Days> \n        </Expiration> \n    </Rule>\n</LifecycleConfiguration>                \n            \nSample Request: Body of a lifecycle con\ufb01guration specifying noncurrent versions\nIf the state of your bucket is versioning-enabled or versioning-suspended, you can have many \nversions of the same object: one current version and zero or more noncurrent versions. The \nfollowing lifecycle con\ufb01guration speci\ufb01es the actions (NoncurrentVersionTransition ,\nNoncurrentVersionExpiration ) that are speci\ufb01c to noncurrent object versions.\n<LifecycleConfiguration> \n    <Rule> \n        <ID>sample-rule</ID> \n        <Prefix>key-prefix</Prefix> \n        <Status>rule-status</Status> \n        <NoncurrentVersionTransition>         \n           <NoncurrentDays>value</NoncurrentDays>         \n           <StorageClass>storage class</StorageClass>        \n        </NoncurrentVersionTransition>     \n        <NoncurrentVersionExpiration> \n           <NoncurrentDays>value</NoncurrentDays> \n        </NoncurrentVersionExpiration> \n    </Rule>\n</LifecycleConfiguration>                \n            \nSample Request: Body of a lifecycle con\ufb01guration that speci\ufb01es a rule with \nAbortIncompleteMultipartUpload\nYou can use the multipart upload to upload large objects in parts.", "For more information about \nmultipart uploads, see Multipart Upload Overview in the Amazon S3 User Guide . With lifecycle \ncon\ufb01guration, you can tell Amazon S3 to abort incomplete multipart uploads, which are identi\ufb01ed \nAmazon S3 API Version 2006-03-01 537Amazon Simple Storage Service API Reference\nby the key name pre\ufb01x speci\ufb01ed in the rule, if they don't complete within a speci\ufb01ed number of \ndays. When Amazon S3 aborts a multipart upload, it deletes all parts associated with the upload. \nThis ensures that you don't have incomplete multipart uploads that have left parts stored in \nAmazon S3, so you don't have to pay storage costs for them.", "The following is an example lifecycle \ncon\ufb01guration that speci\ufb01es a rule with the AbortIncompleteMultipartUpload  action.", "This \naction tells Amazon S3 to abort incomplete multipart uploads seven days after initiation.\n<LifecycleConfiguration> \n    <Rule> \n        <ID>sample-rule</ID> \n        <Prefix>SomeKeyPrefix</Prefix> \n        <Status>rule-status</Status> \n        <AbortIncompleteMultipartUpload>         \n           <DaysAfterInitiation>7</DaysAfterInitiation>         \n        </AbortIncompleteMultipartUpload>     \n    </Rule>\n</LifecycleConfiguration>                \n            \nAdd lifecycle con\ufb01guration to a bucket that is not versioning-enabled\nThe following is a sample PUT /?lifecycle  request that adds the lifecycle con\ufb01guration to the\nexamplebucket  bucket. The lifecycle con\ufb01guration speci\ufb01es two rules, each with one action:\n\u2022The Transition  action tells Amazon S3 to transition objects with the \"documents/\" pre\ufb01x to \nthe GLACIER storage class 30 days after creation.\n\u2022The Expiration  action tells Amazon S3 to delete objects with the \"logs/\" pre\ufb01x 365 days after \ncreation.\nThe sample response follows the sample request.\nPUT /?lifecycle HTTP/1.1\nHost: examplebucket.s3.<Region>.amazonaws.com  \nx-amz-date: Wed, 14 May 2014 02:11:21 GMT\nContent-MD5: q6yJDlIkcBaGGfb3QLY69A==\nAuthorization: authorization string\nContent-Length: 415\n<LifecycleConfiguration> \n  <Rule> \nAmazon S3 API Version 2006-03-01 538Amazon Simple Storage Service API Reference\n    <ID>id1</ID> \n    <Prefix>documents/</Prefix> \n    <Status>Enabled</Status> \n    <Transition> \n      <Days>30</Days> \n      <StorageClass>GLACIER</StorageClass> \n    </Transition> \n  </Rule> \n  <Rule> \n    <ID>id2</ID> \n    <Prefix>logs/</Prefix> \n    <Status>Enabled</Status> \n    <Expiration> \n      <Days>365</Days> \n    </Expiration> \n  </Rule>\n</LifecycleConfiguration> \n             \nHTTP/1.1 200 OK\nx-amz-id-2: r+qR7+nhXtJDDIJ0JJYcd+1j5nM/rUFiiiZ/fNbDOsd3JUE8NWMLNHXmvPfwMpdc\nx-amz-request-id: 9E26D08072A8EF9E\nDate: Wed, 14 May 2014 02:11:22 GMT\nContent-Length: 0\nServer: AmazonS3                \n             \nAdd lifecycle con\ufb01guration to a bucket that is versioning-enabled\nThe following is a sample PUT /?lifecycle request that adds the lifecycle con\ufb01guration to the\nexamplebucket  bucket.", "The lifecycle con\ufb01guration speci\ufb01es two rules, each with one action.", "You \nspecify these actions when your bucket is versioning-enabled or versioning is suspended:\n\u2022The NoncurrentVersionExpiration  action tells Amazon S3 to expire noncurrent versions of \nobjects with the \"logs/\" pre\ufb01x 100 days after the objects become noncurrent.\n\u2022The NoncurrentVersionTransition  action tells Amazon S3 to transition noncurrent versions \nof objects with the \"documents/\" pre\ufb01x to the GLACIER storage class 30 days after they become \nnoncurrent.\nThe sample response follows the sample request.\nAmazon S3 API Version 2006-03-01 539Amazon Simple Storage Service API Reference\nPUT /?lifecycle HTTP/1.1\nHost: examplebucket.s3.<Region>.amazonaws.com  \nx-amz-date: Wed, 14 May 2014 02:21:48 GMT\nContent-MD5: 96rxH9mDqVNKkaZDddgnw==\nAuthorization: authorization string\nContent-Length: 598\n<LifecycleConfiguration> \n  <Rule> \n    <ID>id1</ID> \n    <Prefix>logs/</Prefix> \n    <Status>Enabled</Status> \n    <NoncurrentVersionExpiration> \n      <NoncurrentDays>1</NoncurrentDays> \n    </NoncurrentVersionExpiration> \n  </Rule> \n  <Rule> \n    <ID>TransitionSoonAfterBecomingNonCurrent</ID> \n    <Prefix>documents/</Prefix> \n    <Status>Enabled</Status> \n    <NoncurrentVersionTransition> \n      <NoncurrentDays>0</NoncurrentDays> \n      <StorageClass>GLACIER</StorageClass> \n    </NoncurrentVersionTransition> \n  </Rule>\n</LifecycleConfiguration> \n             \nHTTP/1.1 200 OK\nx-amz-id-2: aXQ+KbIrmMmoO//3bMdDTw/CnjArwje+J49Hf+j44yRb/VmbIkgIO5A+PT98Cp/6k07hf\n+LD2mY=\nx-amz-request-id: 02D7EC4C10381EB1\nDate: Wed, 14 May 2014 02:21:50 GMT\nContent-Length: 0\nServer: AmazonS3 \n             \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\nAmazon S3 API Version 2006-03-01 540Amazon Simple Storage Service API Reference\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 541Amazon Simple Storage Service API Reference\nPutBucketLifecycleCon\ufb01guration\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nCreates a new lifecycle con\ufb01guration for the bucket or replaces an existing lifecycle con\ufb01guration.", "\nKeep in mind that this will overwrite an existing lifecycle con\ufb01guration, so if you want to retain any \ncon\ufb01guration details, they must be included in the new lifecycle con\ufb01guration.", "For information \nabout lifecycle con\ufb01guration, see Managing your storage lifecycle.\nImportant\nWhen making a request using the REST API, you must include the Content-MD5  header.\nRules\nYou specify the lifecycle con\ufb01guration in your request body.", "The lifecycle con\ufb01guration is \nspeci\ufb01ed as XML consisting of one or more rules.", "An Amazon S3 Lifecycle con\ufb01guration can \nhave up to 1,000 rules.", "This limit is not adjustable.\nBucket lifecycle con\ufb01guration supports specifying a lifecycle rule using an object key name \npre\ufb01x, one or more object tags, object size, or any combination of these.", "Accordingly, this \nsection describes the latest API. The previous version of the API supported \ufb01ltering based only \non an object key name pre\ufb01x, which is supported for backward compatibility.", "For the related \nAPI description, see PutBucketLifecycle.\nA lifecycle rule consists of the following:\n\u2022A \ufb01lter identifying a subset of objects to which the rule applies.", "The \ufb01lter can be based on a \nkey name pre\ufb01x, object tags, object size, or any combination of these.\n\u2022A status indicating whether the rule is in e\ufb00ect.\n\u2022One or more lifecycle transition and expiration actions that you want Amazon S3 to perform \non the objects identi\ufb01ed by the \ufb01lter. If the state of your bucket is versioning-enabled or \nversioning-suspended, you can have many versions of the same object (one current version \nAmazon S3 API Version 2006-03-01 542Amazon Simple Storage Service API Reference\nand zero or more noncurrent versions). Amazon S3 provides prede\ufb01ned actions that you can \nspecify for current and noncurrent object versions.\nFor more information, see Object Lifecycle Management and Lifecycle Con\ufb01guration Elements.\nPermissions\nBy default, all Amazon S3 resources are private, including buckets, objects, and related \nsubresources (for example, lifecycle con\ufb01guration and website con\ufb01guration).", "Only the resource \nowner (that is, the AWS account that created it) can access the resource. The resource owner can \noptionally grant access permissions to others by writing an access policy.", "For this operation, a \nuser must get the s3:PutLifecycleConfiguration  permission.\nYou can also explicitly deny permissions.", "An explicit deny also supersedes any other \npermissions.", "If you want to block users or accounts from removing or deleting objects from your \nbucket, you must deny them permissions for the following actions:\n\u2022s3:DeleteObject\n\u2022s3:DeleteObjectVersion\n\u2022s3:PutLifecycleConfiguration\nFor more information about permissions, see Managing Access Permissions to Your Amazon S3 \nResources.\nThe following operations are related to PutBucketLifecycleConfiguration :\n\u2022Examples of Lifecycle Con\ufb01guration\n\u2022GetBucketLifecycleCon\ufb01guration\n\u2022DeleteBucketLifecycle\nRequest Syntax\nPUT /?lifecycle HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-sdk-checksum-algorithm: ChecksumAlgorithm\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nx-amz-transition-default-minimum-object-size: TransitionDefaultMinimumObjectSize\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<LifecycleConfiguration  xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n   <Rule> \nAmazon S3 API Version 2006-03-01 543Amazon Simple Storage Service API Reference\n      <AbortIncompleteMultipartUpload > \n         < DaysAfterInitiation >integer</DaysAfterInitiation > \n      </ AbortIncompleteMultipartUpload > \n      <Expiration > \n         < Date>timestamp </Date> \n         < Days>integer</Days> \n         < ExpiredObjectDeleteMarker >boolean</ExpiredObjectDeleteMarker > \n      </ Expiration > \n      <Filter> \n         < And> \n            < ObjectSizeGreaterThan >long</ObjectSizeGreaterThan > \n            < ObjectSizeLessThan >long</ObjectSizeLessThan > \n            < Prefix>string</Prefix> \n            < Tag> \n               < Key>string</Key> \n               < Value>string</Value> \n            </ Tag> \n            ...", "\n         </ And> \n         < ObjectSizeGreaterThan >long</ObjectSizeGreaterThan > \n         < ObjectSizeLessThan >long</ObjectSizeLessThan > \n         < Prefix>string</Prefix> \n         < Tag> \n            < Key>string</Key> \n            < Value>string</Value> \n         </ Tag> \n      </ Filter> \n      <ID>string</ID> \n      <NoncurrentVersionExpiration > \n         < NewerNoncurrentVersions >integer</NewerNoncurrentVersions > \n         < NoncurrentDays >integer</NoncurrentDays > \n      </ NoncurrentVersionExpiration > \n      <NoncurrentVersionTransition > \n         < NewerNoncurrentVersions >integer</NewerNoncurrentVersions > \n         < NoncurrentDays >integer</NoncurrentDays > \n         < StorageClass >string</StorageClass > \n      </ NoncurrentVersionTransition > \n      ...", "\n      <Prefix>string</Prefix> \n      <Status>string</Status> \n      <Transition > \n         < Date>timestamp </Date> \n         < Days>integer</Days> \n         < StorageClass >string</StorageClass > \nAmazon S3 API Version 2006-03-01 544Amazon Simple Storage Service API Reference\n      </ Transition > \n      ...", "\n   </Rule> \n   ...\n</LifecycleConfiguration >\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe name of the bucket for which to set the con\ufb01guration.\nRequired: Yes\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match \nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nx-amz-sdk-checksum-algorithm\nIndicates the algorithm used to create the checksum for the object when you use the SDK.", "This \nheader will not provide any additional functionality if you don't use the SDK.", "When you send \nthis header, there must be a corresponding x-amz-checksum  or x-amz-trailer  header sent.", "\nOtherwise, Amazon S3 fails the request with the HTTP status code 400 Bad Request . For \nmore information, see Checking object integrity in the Amazon S3 User Guide .\nIf you provide an individual checksum, Amazon S3 ignores any provided ChecksumAlgorithm\nparameter.\nValid Values: CRC32 | CRC32C | SHA1 | SHA256\nx-amz-transition-default-minimum-object-size\nIndicates which default minimum object size behavior is applied to the lifecycle con\ufb01guration.\n\u2022all_storage_classes_128K  - Objects smaller than 128 KB will not transition to any \nstorage class by default.\n\u2022varies_by_storage_class  - Objects smaller than 128 KB will transition to Glacier Flexible \nRetrieval or Glacier Deep Archive storage classes. By default, all other storage classes will \nprevent transitions smaller than 128 KB.\nAmazon S3 API Version 2006-03-01 545Amazon Simple Storage Service API Reference\nTo customize the minimum object size for any transition you can add a \ufb01lter that speci\ufb01es a \ncustom ObjectSizeGreaterThan  or ObjectSizeLessThan  in the body of your transition \nrule. Custom \ufb01lters always take precedence over the default transition behavior.\nValid Values: varies_by_storage_class | all_storage_classes_128K\nRequest Body\nThe request accepts the following data in XML format.\nLifecycleCon\ufb01guration\nRoot level tag for the LifecycleCon\ufb01guration parameters.\nRequired: Yes\nRule\nA lifecycle rule for individual objects in an Amazon S3 bucket.\nType: Array of LifecycleRule data types\nRequired: Yes\nResponse Syntax\nHTTP/1.1 200\nx-amz-transition-default-minimum-object-size: TransitionDefaultMinimumObjectSize\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe response returns the following HTTP headers.\nx-amz-transition-default-minimum-object-size\nIndicates which default minimum object size behavior is applied to the lifecycle con\ufb01guration.\n\u2022all_storage_classes_128K  - Objects smaller than 128 KB will not transition to any \nstorage class by default.\nAmazon S3 API Version 2006-03-01 546Amazon Simple Storage Service API Reference\n\u2022varies_by_storage_class  - Objects smaller than 128 KB will transition to Glacier Flexible \nRetrieval or Glacier Deep Archive storage classes. By default, all other storage classes will \nprevent transitions smaller than 128 KB.\nTo customize the minimum object size for any transition you can add a \ufb01lter that speci\ufb01es a \ncustom ObjectSizeGreaterThan  or ObjectSizeLessThan  in the body of your transition \nrule.", "Custom \ufb01lters always take precedence over the default transition behavior.\nValid Values: varies_by_storage_class | all_storage_classes_128K\nExamples\nExample 1: Add lifecycle con\ufb01guration - bucket not versioning-enabled\nThe following lifecycle con\ufb01guration speci\ufb01es two rules, each with one action.\n\u2022The Transition  action requests Amazon S3 to transition objects with the \"documents/\" pre\ufb01x \nto the GLACIER storage class 30 days after creation.\n\u2022The Expiration  action requests Amazon S3 to delete objects with the \"logs/\" pre\ufb01x 365 days \nafter creation.\n            \n<LifecycleConfiguration> \n  <Rule> \n    <ID>id1</ID> \n    <Filter> \n       <Prefix>documents/</Prefix> \n    </Filter> \n    <Status>Enabled</Status> \n    <Transition> \n      <Days>30</Days> \n      <StorageClass>GLACIER</StorageClass> \n    </Transition> \n  </Rule> \n  <Rule> \n    <ID>id2</ID> \n    <Filter> \n       <Prefix>logs/</Prefix> \n    </Filter> \nAmazon S3 API Version 2006-03-01 547Amazon Simple Storage Service API Reference\n    <Status>Enabled</Status> \n    <Expiration> \n      <Days>365</Days> \n    </Expiration> \n  </Rule>\n</LifecycleConfiguration> \n          \nExample\nThe following is a sample PUT /?lifecycle  request that adds the preceding lifecycle \ncon\ufb01guration to the examplebucket  bucket.\nPUT /?lifecycle HTTP/1.1\nHost: examplebucket.s3.<Region>.amazonaws.com  \nx-amz-date: Wed, 14 May 2014 02:11:21 GMT\nContent-MD5: q6yJDlIkcBaGGfb3QLY69A==\nAuthorization: authorization string\nContent-Length: 415\n<LifecycleConfiguration> \n  <Rule> \n    <ID>id1</ID> \n    <Filter> \n       <Prefix>documents/</Prefix> \n    </Filter> \n    <Status>Enabled</Status> \n    <Transition> \n      <Days>30</Days> \n      <StorageClass>GLACIER</StorageClass> \n    </Transition> \n  </Rule> \n  <Rule> \n    <ID>id2</ID> \n    <Filter> \n       <Prefix>logs/</Prefix> \n    </Filter> \n    <Status>Enabled</Status> \n    <Expiration> \n      <Days>365</Days> \n    </Expiration> \n  </Rule>\nAmazon S3 API Version 2006-03-01 548Amazon Simple Storage Service API Reference\n</LifecycleConfiguration> \n          \nSample Response\nThis example illustrates one usage of PutBucketLifecycleCon\ufb01guration.\nHTTP/1.1 200 OK\nx-amz-id-2: r+qR7+nhXtJDDIJ0JJYcd+1j5nM/rUFiiiZ/fNbDOsd3JUE8NWMLNHXmvPfwMpdc\nx-amz-request-id: 9E26D08072A8EF9E\nDate: Wed, 14 May 2014 02:11:22 GMT\nContent-Length: 0\nServer: AmazonS3 \n          \nExample 2: Add lifecycle con\ufb01guration - bucket is versioning-enabled\nThe following lifecycle con\ufb01guration speci\ufb01es two rules, each with one action for Amazon S3 \nto perform. You specify these actions when your bucket is versioning-enabled or versioning is \nsuspended:\n\u2022The NoncurrentVersionExpiration  action requests Amazon S3 to expire noncurrent \nversions of objects with the \"logs/\" pre\ufb01x 100 days after the objects become noncurrent.\n\u2022The NoncurrentVersionTransition  action requests Amazon S3 to transition noncurrent \nversions of objects with the \"documents/\" pre\ufb01x to the GLACIER storage class 30 days after they \nbecome noncurrent.\n<LifeCycleConfiguration> \n  <Rule> \n    <ID>DeleteAfterBecomingNonCurrent</ID> \n    <Filter> \n       <Prefix>logs/</Prefix> \n    </Filter> \n    <Status>Enabled</Status> \n    <NoncurrentVersionExpiration> \n      <NoncurrentDays>100</NoncurrentDays> \n    </NoncurrentVersionExpiration> \n  </Rule> \nAmazon S3 API Version 2006-03-01 549Amazon Simple Storage Service API Reference\n  <Rule> \n    <ID>TransitionAfterBecomingNonCurrent</ID> \n    <Filter> \n       <Prefix>documents/</Prefix> \n    </Filter> \n    <Status>Enabled</Status> \n    <NoncurrentVersionTransition> \n      <NoncurrentDays>30</NoncurrentDays> \n      <StorageClass>GLACIER</StorageClass> \n    </NoncurrentVersionTransition> \n  </Rule>\n</LifeCycleConfiguration> \n          \nExample\nThe following is a sample PUT /?lifecycle  request that adds the preceding lifecycle \ncon\ufb01guration to the examplebucket  bucket.\nPUT /?lifecycle HTTP/1.1\nHost: examplebucket.s3.<Region>.amazonaws.com  \nx-amz-date: Wed, 14 May 2014 02:21:48 GMT\nContent-MD5: 96rxH9mDqVNKkaZDddgnw==\nAuthorization: authorization string\nContent-Length: 598\n<LifeCycleConfiguration> \n  <Rule> \n    <ID>DeleteAfterBecomingNonCurrent</ID> \n    <Filter> \n       <Prefix>logs/</Prefix> \n    </Filter> \n    <Status>Enabled</Status> \n    <NoncurrentVersionExpiration> \n      <NoncurrentDays>1</NoncurrentDays> \n    </NoncurrentVersionExpiration> \n  </Rule> \n  <Rule> \n    <ID>TransitionSoonAfterBecomingNonCurrent</ID> \n    <Filter> \n       <Prefix>documents/</Prefix> \n    </Filter> \nAmazon S3 API Version 2006-03-01 550Amazon Simple Storage Service API Reference\n    <Status>Enabled</Status> \n    <NoncurrentVersionTransition> \n      <NoncurrentDays>0</NoncurrentDays> \n      <StorageClass>GLACIER</StorageClass> \n    </NoncurrentVersionTransition> \n  </Rule>\n</LifeCycleConfiguration> \n          \nSample Response\nThis example illustrates one usage of PutBucketLifecycleCon\ufb01guration.\nHTTP/1.1 200 OK\nx-amz-id-2: aXQ+KbIrmMmoO//3bMdDTw/CnjArwje+J49Hf+j44yRb/VmbIkgIO5A+PT98Cp/6k07hf\n+LD2mY=\nx-amz-request-id: 02D7EC4C10381EB1\nDate: Wed, 14 May 2014 02:21:50 GMT\nContent-Length: 0\nServer: AmazonS3 \n          \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 551Amazon Simple Storage Service API Reference\nPutBucketLogging\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nSet the logging parameters for a bucket and to specify permissions for who can view and modify \nthe logging parameters.", "All logs are saved to buckets in the same AWS Region as the source bucket. \nTo set the logging status of a bucket, you must be the bucket owner.\nThe bucket owner is automatically granted FULL_CONTROL to all logs.", "You use the Grantee\nrequest element to grant access to other people.", "The Permissions  request element speci\ufb01es the \nkind of access the grantee has to the logs.\nImportant\nIf the target bucket for log delivery uses the bucket owner enforced setting for S3 \nObject Ownership, you can't use the Grantee request element to grant access to others.", "\nPermissions can only be granted using policies.", "For more information, see Permissions for \nserver access log delivery in the Amazon S3 User Guide .\nGrantee Values\nYou can specify the person (grantee) to whom you're assigning access rights (by using request \nelements) in the following ways:\n\u2022By the person's ID:\n<Grantee xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-\ninstance\" xsi:type=\"CanonicalUser\"><ID><>ID<></\nID><DisplayName><>GranteesEmail<></DisplayName> </Grantee>\nDisplayName  is optional and ignored in the request.\n\u2022By Email address:\nAmazon S3 API Version 2006-03-01 552Amazon Simple Storage Service API Reference\n<Grantee xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" \nxsi:type=\"AmazonCustomerByEmail\"><EmailAddress><>Grantees@email.com<></\nEmailAddress></Grantee>\nThe grantee is resolved to the CanonicalUser  and, in a response to a GETObjectAcl\nrequest, appears as the CanonicalUser.\n\u2022By URI:\n<Grantee xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" \nxsi:type=\"Group\"><URI><>http://acs.amazonaws.com/groups/global/\nAuthenticatedUsers<></URI></Grantee>\nTo enable logging, you use LoggingEnabled  and its children request elements. To disable \nlogging, you use an empty BucketLoggingStatus  request element:\n<BucketLoggingStatus xmlns=\"http://doc.s3.amazonaws.com/2006-03-01\" />\nFor more information about server access logging, see Server Access Logging in the Amazon S3 \nUser Guide .\nFor more information about creating a bucket, see CreateBucket. For more information about \nreturning the logging status of a bucket, see GetBucketLogging.\nThe following operations are related to PutBucketLogging :\n\u2022PutObject\n\u2022DeleteBucket\n\u2022CreateBucket\n\u2022GetBucketLogging\nRequest Syntax\nPUT /?logging HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nContent-MD5: ContentMD5\nx-amz-sdk-checksum-algorithm: ChecksumAlgorithm\nx-amz-expected-bucket-owner: ExpectedBucketOwner\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\nAmazon S3 API Version 2006-03-01 553Amazon Simple Storage Service API Reference\n<BucketLoggingStatus  xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n   <LoggingEnabled > \n      <TargetBucket >string</TargetBucket > \n      <TargetGrants > \n         <Grant> \n            < Grantee> \n               < DisplayName >string</DisplayName > \n               < EmailAddress >string</EmailAddress > \n               < ID>string</ID> \n               < xsi:type >string</xsi:type > \n               < URI>string</URI> \n            </ Grantee> \n            < Permission >string</Permission > \n         </Grant> \n      </ TargetGrants > \n      <TargetObjectKeyFormat > \n         < PartitionedPrefix > \n            < PartitionDateSource >string</PartitionDateSource > \n         </ PartitionedPrefix > \n         < SimplePrefix > \n         </ SimplePrefix > \n      </ TargetObjectKeyFormat > \n      <TargetPrefix >string</TargetPrefix > \n   </LoggingEnabled >\n</BucketLoggingStatus >\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe name of the bucket for which to set the logging parameters.\nRequired: Yes\nContent-MD5\nThe MD5 hash of the PutBucketLogging  request body.\nFor requests made using the AWS Command Line Interface (CLI) or AWS SDKs, this \ufb01eld is \ncalculated automatically.\nAmazon S3 API Version 2006-03-01 554Amazon Simple Storage Service API Reference\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match \nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nx-amz-sdk-checksum-algorithm\nIndicates the algorithm used to create the checksum for the object when you use the SDK.", "This \nheader will not provide any additional functionality if you don't use the SDK.", "When you send \nthis header, there must be a corresponding x-amz-checksum  or x-amz-trailer  header sent.", "\nOtherwise, Amazon S3 fails the request with the HTTP status code 400 Bad Request . For \nmore information, see Checking object integrity in the Amazon S3 User Guide .\nIf you provide an individual checksum, Amazon S3 ignores any provided ChecksumAlgorithm\nparameter.\nValid Values: CRC32 | CRC32C | SHA1 | SHA256\nRequest Body\nThe request accepts the following data in XML format.\nBucketLoggingStatus\nRoot level tag for the BucketLoggingStatus parameters.\nRequired: Yes\nLoggingEnabled\nDescribes where logs are stored and the pre\ufb01x that Amazon S3 assigns to all log object keys for \na bucket. For more information, see PUT Bucket logging in the Amazon S3 API Reference.\nType: LoggingEnabled  data type\nRequired: No\nResponse Syntax\nHTTP/1.1 200\nAmazon S3 API Version 2006-03-01 555Amazon Simple Storage Service API Reference\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\nExamples\nSample Request\nThis request enables logging and gives the grantee of the bucket READ access to the logs.\nBuckets that use the bucket owner enforced setting for Object Ownership to disable ACLs don't \nsupport target grants. For more information, see Permissions for server access log delivery in the\nAmazon S3 User Guide .\nPUT ?logging HTTP/1.1\nHost: quotes.s3.<Region>.amazonaws.com\nContent-Length: 214\nDate: Wed, 25 Nov 2009 12:00:00 GMT\nAuthorization: authorization string\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<BucketLoggingStatus xmlns=\"http://doc.s3.amazonaws.com/2006-03-01\"> \n  <LoggingEnabled> \n    <TargetBucket>mybucketlogs</TargetBucket> \n    <TargetPrefix>mybucket-access_log-/</TargetPrefix> \n    <TargetGrants> \n      <Grant> \n        <Grantee xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" \n          xsi:type=\"AmazonCustomerByEmail\"> \n          <EmailAddress>user@company.com</EmailAddress> \n        </Grantee> \n        <Permission>READ</Permission> \n      </Grant> \n    </TargetGrants> \n  </LoggingEnabled>\n</BucketLoggingStatus> \n          \nSample Response\nThis example illustrates one usage of PutBucketLogging.\nAmazon S3 API Version 2006-03-01 556Amazon Simple Storage Service API Reference\nHTTP/1.1 200 OK\nx-amz-id-2: YgIPIfBiKa2bj0KMg95r/0zo3emzU4dzsD4rcKCHQUAdQkf3ShJTOOpXUueF6QKo\nx-amz-request-id: 236A8905248E5A01\nDate: Wed, 01 Mar  2006 12:00:00 GMT \n          \nSample Request: Disabling logging\nThis request disables logging on the bucket quotes .\nPUT ?logging HTTP/1.1\nHost: quotes.s3.<Region>.amazonaws.com\nContent-Length: 214\nDate: Wed, 25 Nov 2009 12:00:00 GMT\nAuthorization: authorization string\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<BucketLoggingStatus xmlns=\"http://doc.s3.amazonaws.com/2006-03-01\" /> \n          \nSample Response\nThis example illustrates one usage of PutBucketLogging.\nHTTP/1.1 200 OK\nx-amz-id-2: YgIPIfBiKa2bj0KMg95r/0zo3emzU4dzsD4rcKCHQUAdQkf3ShJTOOpXUueF6QKo\nx-amz-request-id: 236A8905248E5A01\nDate: Wed, 01 Mar  2006 12:00:00 GMT \n          \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\nAmazon S3 API Version 2006-03-01 557Amazon Simple Storage Service API Reference\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 558Amazon Simple Storage Service API Reference\nPutBucketMetricsCon\ufb01guration\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nSets a metrics con\ufb01guration (speci\ufb01ed by the metrics con\ufb01guration ID) for the bucket.", "You can have \nup to 1,000 metrics con\ufb01gurations per bucket. If you're updating an existing metrics con\ufb01guration, \nnote that this is a full replacement of the existing metrics con\ufb01guration.", "If you don't include the \nelements you want to keep, they are erased.\nTo use this operation, you must have permissions to perform the\ns3:PutMetricsConfiguration  action.", "The bucket owner has this permission by default. The \nbucket owner can grant this permission to others.", "For more information about permissions, see\nPermissions Related to Bucket Subresource Operations and Managing Access Permissions to Your \nAmazon S3 Resources.\nFor information about CloudWatch request metrics for Amazon S3, see Monitoring Metrics with \nAmazon CloudWatch.\nThe following operations are related to PutBucketMetricsConfiguration :\n\u2022DeleteBucketMetricsCon\ufb01guration\n\u2022GetBucketMetricsCon\ufb01guration\n\u2022ListBucketMetricsCon\ufb01gurations\nPutBucketMetricsConfiguration  has the following special error:\n\u2022Error code: TooManyConfigurations\n\u2022Description: You are attempting to create a new con\ufb01guration but have already reached the \n1,000-con\ufb01guration limit.\n\u2022HTTP Status Code: HTTP 400 Bad Request\nRequest Syntax\nPUT /?metrics&id= Id HTTP/1.1\nAmazon S3 API Version 2006-03-01 559Amazon Simple Storage Service API Reference\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<MetricsConfiguration  xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n   <Id>string</Id> \n   <Filter> \n      <AccessPointArn >string</AccessPointArn > \n      <And> \n         < AccessPointArn >string</AccessPointArn > \n         < Prefix>string</Prefix> \n         < Tag> \n            < Key>string</Key> \n            < Value>string</Value> \n         </ Tag> \n         ... \n      </ And> \n      <Prefix>string</Prefix> \n      <Tag> \n         < Key>string</Key> \n         < Value>string</Value> \n      </ Tag> \n   </Filter>\n</MetricsConfiguration >\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe name of the bucket for which the metrics con\ufb01guration is set.\nRequired: Yes\nid\nThe ID used to identify the metrics con\ufb01guration.", "The ID has a 64 character limit and can only \ncontain letters, numbers, periods, dashes, and underscores.\nRequired: Yes\nAmazon S3 API Version 2006-03-01 560Amazon Simple Storage Service API Reference\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner.", "If the account ID that you provide does not match \nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nRequest Body\nThe request accepts the following data in XML format.\nMetricsCon\ufb01guration\nRoot level tag for the MetricsCon\ufb01guration parameters.\nRequired: Yes\nFilter\nSpeci\ufb01es a metrics con\ufb01guration \ufb01lter. The metrics con\ufb01guration will only include objects \nthat meet the \ufb01lter's criteria. A \ufb01lter must be a pre\ufb01x, an object tag, an access point ARN, or a \nconjunction (MetricsAndOperator).\nType: MetricsFilter  data type\nRequired: No\nId\nThe ID used to identify the metrics con\ufb01guration.", "The ID has a 64 character limit and can only \ncontain letters, numbers, periods, dashes, and underscores.\nType: String\nRequired: Yes\nResponse Syntax\nHTTP/1.1 200\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\nAmazon S3 API Version 2006-03-01 561Amazon Simple Storage Service API Reference\nExamples\nFirst Sample Request\nPut a metric con\ufb01guration that enables metrics for an entire bucket.\nPUT /?metrics&id=EntireBucket HTTP/1.1\nHost: examplebucket.s3.<Region>.amazonaws.com\nx-amz-date: Thu, 15 Nov 2016 00:17:21 GMT\nAuthorization: signatureValue\nContent-Length: 159\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<MetricsConfiguration xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n    <Id>EntireBucket</Id>\n</MetricsConfiguration> \n          \nFirst Sample Response\nThis example illustrates one usage of PutBucketMetricsCon\ufb01guration.\nHTTP/1.1 204 No Content\nx-amz-id-2: ITnGT1y4REXAMPLEPi4hklTXouTf0hccUjo0iCPEXAMPLEutBj3M7fPGlWO2SEWp\nx-amz-request-id: 51991EXAMPLE5321\nDate: Thu, 15 Nov 2016 00:17:22 GMT\nServer: AmazonS3 \n             \nSecond Sample Request\nPut a metrics con\ufb01guration that enables metrics for objects that start with a particular pre\ufb01x and \nalso have speci\ufb01c tags applied.\nPUT /?metrics&id=ImportantBlueDocuments HTTP/1.1\nHost: examplebucket.s3.<Region>.amazonaws.com\nx-amz-date: Thu, 15 Nov 2016 00:17:29 GMT\nAuthorization: signatureValue\nContent-Length: 480\nAmazon S3 API Version 2006-03-01 562Amazon Simple Storage Service API Reference\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<MetricsConfiguration xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n    <Id>ImportantBlueDocuments</Id> \n    <Filter> \n        <And> \n            <Prefix>documents/</Prefix> \n            <Tag> \n                <Key>priority</Key> \n                <Value>high</Value> \n            </Tag> \n            <Tag> \n                <Key>class</Key> \n                <Value>blue</Value> \n            </Tag> \n        </And> \n    </Filter>\n</MetricsConfiguration> \n          \nSecond Sample Response\nThis example illustrates one usage of PutBucketMetricsCon\ufb01guration.\nHTTP/1.1 204 No Content\nx-amz-id-2: ITnGT1y4REXAMPLEPi4hklTXouTf0hccUjo0iCPEXAMPLEutBj3M7fPGlWO2SEWp\nx-amz-request-id: 51991EXAMPLE5321\nDate: Thu, 15 Nov 2016 00:17:29 GMT\nServer: AmazonS3 \n             \nThird Sample Request\nPut a metrics con\ufb01guration that enables metrics for a speci\ufb01c access point.\nPUT /?metrics&id=ImportantDocumentsAccessPoint HTTP/1.1\nHost: examplebucket.s3.<Region>.amazonaws.com\nx-amz-date: Thu, 26 Aug 2021 00:17:29 GMT\nAuthorization: signatureValue\nContent-Length: 480\nAmazon S3 API Version 2006-03-01 563Amazon Simple Storage Service API Reference\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<MetricsConfiguration xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n    <Id>ImportantDocumentsAccessPoint</Id> \n    <Filter> \n        <AccessPointArn>arn:aws:s3:us-west-2:123456789012:accesspoint/test</\nAccessPointArn> \n    </Filter>\n</MetricsConfiguration> \n          \nThirds Sample Response\nThis example illustrates one usage of PutBucketMetricsCon\ufb01guration.\nHTTP/1.1 204 No Content\nx-amz-id-2: ITnGT1y4REXAMPLEPi4hklTXouTf0hccUjo0iCPEXAMPLEutBj3M7fPGlWO2SEWp\nx-amz-request-id: 51991EXAMPLE5321\nDate: Thu, 26 Aug 2021 00:17:29 GMT\nServer: AmazonS3 \n             \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 564Amazon Simple Storage Service API Reference\nPutBucketNoti\ufb01cation\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nNo longer used, see the PutBucketNoti\ufb01cationCon\ufb01guration operation.\nRequest Syntax\nPUT /?notification HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nContent-MD5: ContentMD5\nx-amz-sdk-checksum-algorithm: ChecksumAlgorithm\nx-amz-expected-bucket-owner: ExpectedBucketOwner\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<NotificationConfiguration  xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n   <TopicConfiguration > \n      <Event>string</Event> \n      <Event>string</Event> \n      ...", "\n      <Id>string</Id> \n      <Topic>string</Topic> \n   </TopicConfiguration > \n   <QueueConfiguration > \n      <Event>string</Event> \n      <Event>string</Event> \n      ... \n      <Id>string</Id> \n      <Queue>string</Queue> \n   </QueueConfiguration > \n   <CloudFunctionConfiguration > \n      <CloudFunction >string</CloudFunction > \n      <Event>string</Event> \n      <Event>string</Event> \n      ...", "\n      <Id>string</Id> \n      <InvocationRole >string</InvocationRole > \n   </CloudFunctionConfiguration >\n</NotificationConfiguration >\nAmazon S3 API Version 2006-03-01 565Amazon Simple Storage Service API Reference\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe name of the bucket.\nRequired: Yes\nContent-MD5\nThe MD5 hash of the PutPublicAccessBlock  request body.\nFor requests made using the AWS Command Line Interface (CLI) or AWS SDKs, this \ufb01eld is \ncalculated automatically.\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match \nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nx-amz-sdk-checksum-algorithm\nIndicates the algorithm used to create the checksum for the object when you use the SDK.", "This \nheader will not provide any additional functionality if you don't use the SDK.", "When you send \nthis header, there must be a corresponding x-amz-checksum  or x-amz-trailer  header sent.", "\nOtherwise, Amazon S3 fails the request with the HTTP status code 400 Bad Request . For \nmore information, see Checking object integrity in the Amazon S3 User Guide .\nIf you provide an individual checksum, Amazon S3 ignores any provided ChecksumAlgorithm\nparameter.\nValid Values: CRC32 | CRC32C | SHA1 | SHA256\nRequest Body\nThe request accepts the following data in XML format.\nNoti\ufb01cationCon\ufb01guration\nRoot level tag for the Noti\ufb01cationCon\ufb01guration parameters.\nAmazon S3 API Version 2006-03-01 566Amazon Simple Storage Service API Reference\nRequired: Yes\nCloudFunctionCon\ufb01guration\nContainer for specifying the AWS Lambda noti\ufb01cation con\ufb01guration.\nType: CloudFunctionCon\ufb01guration data type\nRequired: No\nQueueCon\ufb01guration\nThis data type is deprecated. This data type speci\ufb01es the con\ufb01guration for publishing messages \nto an Amazon Simple Queue Service (Amazon SQS) queue when Amazon S3 detects speci\ufb01ed \nevents.\nType: QueueCon\ufb01gurationDeprecated data type\nRequired: No\nTopicCon\ufb01guration\nThis data type is deprecated. A container for specifying the con\ufb01guration for publication of \nmessages to an Amazon Simple Noti\ufb01cation Service (Amazon SNS) topic when Amazon S3 \ndetects speci\ufb01ed events.\nType: TopicCon\ufb01gurationDeprecated data type\nRequired: No\nResponse Syntax\nHTTP/1.1 200\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\nAmazon S3 API Version 2006-03-01 567Amazon Simple Storage Service API Reference\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 568Amazon Simple Storage Service API Reference\nPutBucketNoti\ufb01cationCon\ufb01guration\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nEnables noti\ufb01cations of speci\ufb01ed events for a bucket.", "For more information about event \nnoti\ufb01cations, see Con\ufb01guring Event Noti\ufb01cations.\nUsing this API, you can replace an existing noti\ufb01cation con\ufb01guration.", "The con\ufb01guration is an XML \n\ufb01le that de\ufb01nes the event types that you want Amazon S3 to publish and the destination where \nyou want Amazon S3 to publish an event noti\ufb01cation when it detects an event of the speci\ufb01ed \ntype.\nBy default, your bucket has no event noti\ufb01cations con\ufb01gured. That is, the noti\ufb01cation con\ufb01guration \nwill be an empty NotificationConfiguration .\n<NotificationConfiguration>\n</NotificationConfiguration>\nThis action replaces the existing noti\ufb01cation con\ufb01guration with the con\ufb01guration you include in the \nrequest body.\nAfter Amazon S3 receives this request, it \ufb01rst veri\ufb01es that any Amazon Simple Noti\ufb01cation Service \n(Amazon SNS) or Amazon Simple Queue Service (Amazon SQS) destination exists, and that the \nbucket owner has permission to publish to it by sending a test noti\ufb01cation. In the case of AWS \nLambda destinations, Amazon S3 veri\ufb01es that the Lambda function permissions grant Amazon \nS3 permission to invoke the function from the Amazon S3 bucket. For more information, see\nCon\ufb01guring Noti\ufb01cations for Amazon S3 Events.\nYou can disable noti\ufb01cations by adding the empty Noti\ufb01cationCon\ufb01guration element.\nFor more information about the number of event noti\ufb01cation con\ufb01gurations that you can create \nper bucket, see Amazon S3 service quotas in  AWS General Reference.\nBy default, only the bucket owner can con\ufb01gure noti\ufb01cations on a bucket. However, bucket owners \ncan use a bucket policy to grant permission to other users to set this con\ufb01guration with the \nrequired s3:PutBucketNotification  permission.\nAmazon S3 API Version 2006-03-01 569Amazon Simple Storage Service API Reference\nNote\nThe PUT noti\ufb01cation is an atomic operation.", "For example, suppose your noti\ufb01cation \ncon\ufb01guration includes SNS topic, SQS queue, and Lambda function con\ufb01gurations.", "When \nyou send a PUT request with this con\ufb01guration, Amazon S3 sends test messages to your \nSNS topic. If the message fails, the entire PUT action will fail, and Amazon S3 will not add \nthe con\ufb01guration to your bucket.\nIf the con\ufb01guration in the request body includes only one TopicConfiguration  specifying only \nthe s3:ReducedRedundancyLostObject  event type, the response will also include the x-amz-\nsns-test-message-id  header containing the message ID of the test noti\ufb01cation sent to the \ntopic.\nThe following action is related to PutBucketNotificationConfiguration :\n\u2022GetBucketNoti\ufb01cationCon\ufb01guration\nRequest Syntax\nPUT /?notification HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nx-amz-skip-destination-validation: SkipDestinationValidation\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<NotificationConfiguration  xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n   <TopicConfiguration > \n      <Event>string</Event> \n      ...", "\n      <Filter> \n         < S3Key> \n            < FilterRule > \n               < Name>string</Name> \n               < Value>string</Value> \n            </ FilterRule > \n            ... \n         </ S3Key> \n      </ Filter> \n      <Id>string</Id> \n      <Topic>string</Topic> \n   </TopicConfiguration > \nAmazon S3 API Version 2006-03-01 570Amazon Simple Storage Service API Reference\n   ...", "\n   <QueueConfiguration > \n      <Event>string</Event> \n      ...", "\n      <Filter> \n         < S3Key> \n            < FilterRule > \n               < Name>string</Name> \n               < Value>string</Value> \n            </ FilterRule > \n            ... \n         </ S3Key> \n      </ Filter> \n      <Id>string</Id> \n      <Queue>string</Queue> \n   </QueueConfiguration > \n   ...", "\n   <CloudFunctionConfiguration > \n      <Event>string</Event> \n      ...", "\n      <Filter> \n         < S3Key> \n            < FilterRule > \n               < Name>string</Name> \n               < Value>string</Value> \n            </ FilterRule > \n            ... \n         </ S3Key> \n      </ Filter> \n      <Id>string</Id> \n      <CloudFunction >string</CloudFunction > \n   </CloudFunctionConfiguration > \n   ... \n   <EventBridgeConfiguration > \n   </EventBridgeConfiguration >\n</NotificationConfiguration >\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe name of the bucket.\nAmazon S3 API Version 2006-03-01 571Amazon Simple Storage Service API Reference\nRequired: Yes\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match \nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nx-amz-skip-destination-validation\nSkips validation of Amazon SQS, Amazon SNS, and AWS Lambda destinations. True or false \nvalue.\nRequest Body\nThe request accepts the following data in XML format.\nNoti\ufb01cationCon\ufb01guration\nRoot level tag for the Noti\ufb01cationCon\ufb01guration parameters.\nRequired: Yes\nCloudFunctionCon\ufb01guration\nDescribes the AWS Lambda functions to invoke and the events for which to invoke them.\nType: Array of LambdaFunctionCon\ufb01guration data types\nRequired: No\nEventBridgeCon\ufb01guration\nEnables delivery of events to Amazon EventBridge.\nType: EventBridgeCon\ufb01guration data type\nRequired: No\nQueueCon\ufb01guration\nThe Amazon Simple Queue Service queues to publish messages to and the events for which to \npublish messages.\nType: Array of QueueCon\ufb01guration  data types\nAmazon S3 API Version 2006-03-01 572Amazon Simple Storage Service API Reference\nRequired: No\nTopicCon\ufb01guration\nThe topic to which noti\ufb01cations are sent and the events for which noti\ufb01cations are generated.\nType: Array of TopicCon\ufb01guration data types\nRequired: No\nResponse Syntax\nHTTP/1.1 200\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\nExamples\nExample 1: Con\ufb01gure noti\ufb01cation to invoke a cloud function in Lambda\nThe following noti\ufb01cation con\ufb01guration includes CloudFunctionCon\ufb01guration, which identi\ufb01es the \nevent type for which Amazon S3 can invoke a cloud function and the name of the cloud function to \ninvoke.\n<NotificationConfiguration> \n  <CloudFunctionConfiguration> \n    <Id>ObjectCreatedEvents</Id> \n    <CloudFunction>arn:aws:lambda:us-west-2:35667example:function:CreateThumbnail</\nCloudFunction> \n    <Event>s3:ObjectCreated:*</Event> \n  </CloudFunctionConfiguration>\n</NotificationConfiguration> \n          \nExample\nThe following PUT uploads the noti\ufb01cation con\ufb01guration. The action replaces the existing \nnoti\ufb01cation con\ufb01guration.\nAmazon S3 API Version 2006-03-01 573Amazon Simple Storage Service API Reference\nPUT http://s3.<Region>.amazonaws.com/examplebucket?notification= HTTP/1.1\nUser-Agent: s3curl 2.0\nHost: s3.amazonaws.com\nPragma: no-cache\nAccept: */*\nProxy-Connection: Keep-Alive\nAuthorization: authorization string\nDate: Mon, 13 Oct 2014 23:14:52 +0000\nContent-Length: length\n[request body] \n          \nSample Response\nThis example illustrates one usage of PutBucketNoti\ufb01cationCon\ufb01guration.\nHTTP/1.1 200 OK\nx-amz-id-2: 8+FlwagBSoT2qpMaGlfCUkRkFR5W3OeS7UhhoBb17j+kqvpS2cSFlgJ5coLd53d2\nx-amz-request-id: E5BA4600A3937335\nDate: Fri, 31 Oct 2014 01:49:50 GMT\nContent-Length: 0\nServer: AmazonS3 \n          \nExample 2: Con\ufb01gure a noti\ufb01cation with multiple destinations\nThe following noti\ufb01cation con\ufb01guration includes the topic and queue con\ufb01gurations:\n\u2022A topic con\ufb01guration identifying an SNS topic for Amazon S3 to publish events of the\ns3:ReducedRedundancyLostObject  type.\n\u2022A queue con\ufb01guration identifying an SQS queue for Amazon S3 to publish events of the\ns3:ObjectCreated:*  type.\n<NotificationConfiguration> \n  <TopicConfiguration> \nAmazon S3 API Version 2006-03-01 574Amazon Simple Storage Service API Reference\n    <Topic>arn:aws:sns:us-east-1:356671443308:s3notificationtopic2</Topic> \n    <Event>s3:ReducedRedundancyLostObject</Event> \n  </TopicConfiguration> \n  <QueueConfiguration> \n    <Queue>arn:aws:sqs:us-east-1:356671443308:s3notificationqueue</Queue> \n    <Event>s3:ObjectCreated:*</Event> \n  </QueueConfiguration>\n</NotificationConfiguration> \n          \nExample\nThe following PUT request against the noti\ufb01cation subresource of the examplebucket  bucket \nsends the preceding noti\ufb01cation con\ufb01guration in the request body. The action replaces the existing \nnoti\ufb01cation con\ufb01guration on the bucket.\nPUT http://s3.<Region>.amazonaws.com/examplebucket?notification= HTTP/1.1\nUser-Agent: s3curl 2.0\nHost: s3.amazonaws.com\nPragma: no-cache\nAccept: */*\nProxy-Connection: Keep-Alive\nAuthorization: authorization string\nDate: Mon, 13 Oct 2014 22:58:43 +0000\nContent-Length: 391\nExpect: 100-continue \n          \nExample 3: Con\ufb01gure a noti\ufb01cation with object key name \ufb01ltering\nThe following noti\ufb01cation con\ufb01guration contains a queue con\ufb01guration identifying an Amazon \nSQS queue for Amazon S3 to publish events to of the s3:ObjectCreated:Put  type.", "The events \nwill be published whenever an object that has a pre\ufb01x of images/  and a .jpg  su\ufb03x is PUT to a \nbucket.", "For more examples of noti\ufb01cation con\ufb01gurations that use \ufb01ltering, see Con\ufb01guring Event \nNoti\ufb01cations .\n<NotificationConfiguration> \n  <QueueConfiguration> \nAmazon S3 API Version 2006-03-01 575Amazon Simple Storage Service API Reference\n      <Id>1</Id> \n      <Filter> \n          <S3Key> \n              <FilterRule> \n                  <Name>prefix</Name> \n                  <Value>images/</Value> \n              </FilterRule> \n              <FilterRule> \n                  <Name>suffix</Name> \n                  <Value>.jpg</Value> \n              </FilterRule> \n          </S3Key> \n     </Filter> \n     <Queue>arn:aws:sqs:us-west-2:444455556666:s3notificationqueue</Queue> \n     <Event>s3:ObjectCreated:Put</Event> \n  </QueueConfiguration>\n</NotificationConfiguration> \n          \nExample\nThe following PUT request against the noti\ufb01cation subresource of the examplebucket  bucket \nsends the preceding noti\ufb01cation con\ufb01guration in the request body. The action replaces the existing \nnoti\ufb01cation con\ufb01guration on the bucket.\nPUT http://s3.<Region>.amazonaws.com/examplebucket?notification= HTTP/1.1\nUser-Agent: s3curl 2.0\nHost: s3.amazonaws.com\nPragma: no-cache\nAccept: */*\nProxy-Connection: Keep-Alive\nAuthorization: authorization string\nDate: Mon, 13 Oct 2014 22:58:43 +0000\nContent-Length: length\nExpect: 100-continue \n          \nSample Response\nThis example illustrates one usage of PutBucketNoti\ufb01cationCon\ufb01guration.\nAmazon S3 API Version 2006-03-01 576Amazon Simple Storage Service API Reference\nHTTP/1.1 200 OK\nx-amz-id-2: SlvJLkfunoAGILZK3KqHSSUq4kwbudkrROmESoHOpDacULy+cxRoR1Svrfoyvg2A\nx-amz-request-id: BB1BA8E12D6A80B7\nDate: Mon, 13 Oct 2014 22:58:44 GMT\nContent-Length: 0\nServer: AmazonS3 \n          \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 577Amazon Simple Storage Service API Reference\nPutBucketOwnershipControls\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nCreates or modi\ufb01es OwnershipControls  for an Amazon S3 bucket. To use this operation, you \nmust have the s3:PutBucketOwnershipControls  permission. For more information about \nAmazon S3 permissions, see Specifying permissions in a policy.\nFor information about Amazon S3 Object Ownership, see Using object ownership.\nThe following operations are related to PutBucketOwnershipControls :\n\u2022GetBucketOwnershipControls\n\u2022DeleteBucketOwnershipControls\nRequest Syntax\nPUT /?ownershipControls HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nContent-MD5: ContentMD5\nx-amz-expected-bucket-owner: ExpectedBucketOwner\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<OwnershipControls  xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n   <Rule> \n      <ObjectOwnership >string</ObjectOwnership > \n   </Rule> \n   ...\n</OwnershipControls >\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe name of the Amazon S3 bucket whose OwnershipControls  you want to set.\nAmazon S3 API Version 2006-03-01 578Amazon Simple Storage Service API Reference\nRequired: Yes\nContent-MD5\nThe MD5 hash of the OwnershipControls  request body.\nFor requests made using the AWS Command Line Interface (CLI) or AWS SDKs, this \ufb01eld is \ncalculated automatically.\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match \nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nRequest Body\nThe request accepts the following data in XML format.\nOwnershipControls\nRoot level tag for the OwnershipControls parameters.\nRequired: Yes\nRule\nThe container element for an ownership control rule.\nType: Array of OwnershipControlsRule data types\nRequired: Yes\nResponse Syntax\nHTTP/1.1 200\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\nAmazon S3 API Version 2006-03-01 579Amazon Simple Storage Service API Reference\nExamples\nSample Request with BucketOwnerEnforced OwnershipControls\nThe following request puts a bucket OwnershipControls  that speci\ufb01es BucketOwnerEnforced.\n          PUT /amzn-s3-demo-bucket?ownershipControls= HTTP/1.1 \n          Host:amzn-s3-demo-bucket.s3.<Region>.amazonaws.com \n          x-amz-date: 20211130T230132Z \n          x-amz-content-sha256: \n bafb46c18574a73704c8227aef060df1c12ea0d964e19b949d06e9f763805fe2 \n          Authorization: authorization string \n          <?xml version=\"1.0\" encoding=\"UTF-8\"?> \n          <OwnershipControls xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n            <Rule> \n              <ObjectOwnership>BucketOwnerEnforced</ObjectOwnership> \n            </Rule> \n          </OwnershipControls> \n         \nSample Response with BucketOwnerEnforced OwnershipControls\nThis example illustrates one usage of PutBucketOwnershipControls.\n          HTTP/1.1 200 OK \n          x-amz-id-2: zkDVX0gbz8oKcjNz7GPz8XhXkhNArHtA8/\nWOf5hyEj6SbisSRdqITZvSuAMik7HK4PY+izDZZI0= \n          x-amz-request-id: BK7Y8M3G7Z0RFRCP \n          Date: Tue, 30 Nov 2021 23:01:33 GMT \n          Content-Length: 0 \n          Server: AmazonS3 \n         \nSample Request with BucketOwnerPreferred OwnershipControls\nThe following request puts a bucket OwnershipControls  that speci\ufb01es BucketOwnerPreferred.\n          PUT /amzn-s3-demo-bucket?ownershipControls= HTTP/1.1 \nAmazon S3 API Version 2006-03-01 580Amazon Simple Storage Service API Reference\n          Host:amzn-s3-demo-bucket.s3.<Region>.amazonaws.com \n          x-amz-date: 20200618T230132Z \n          x-amz-content-sha256: \n bafb46c18574a73704c8227aef060df1c12ea0d964e19b949d06e9f763805fe2 \n          Authorization: authorization string \n          <?xml version=\"1.0\" encoding=\"UTF-8\"?> \n          <OwnershipControls xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n            <Rule> \n              <ObjectOwnership>BucketOwnerPreferred</ObjectOwnership> \n            </Rule> \n          </OwnershipControls> \n         \nSample Response with BucketOwnerPreferred OwnershipControls\nThis example illustrates one usage of PutBucketOwnershipControls.\n          HTTP/1.1 200 OK \n          x-amz-id-2: zkDVX0gbz8oKcjNz7GPz8XhXkhNArHtA8/\nWOf5hyEj6SbisSRdqITZvSuAMik7HK4PY+izDZZI0= \n          x-amz-request-id: BK7Y8M3G7Z0RFRCP \n          Date: Thu, 18 Jun 2020 23:01:33 GMT \n          Content-Length: 0 \n          Server: AmazonS3 \n         \nSample Request with ObjectWriter OwnershipControls\nThe following request puts a bucket OwnershipControls  that speci\ufb01es ObjectWriter.\n          PUT /amzn-s3-demo-bucket?ownershipControls= HTTP/1.1 \n          Host:amzn-s3-demo-bucket.s3.<Region>.amazonaws.com \n          x-amz-date: 20200618T230132Z \n          x-amz-content-sha256: \n bafb46c18574a73704c8227aef060df1c12ea0d964e19b949d06e9f763805fe2 \n          Authorization: authorization string \n          <?xml version=\"1.0\" encoding=\"UTF-8\"?> \n          <OwnershipControls xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n            <Rule> \nAmazon S3 API Version 2006-03-01 581Amazon Simple Storage Service API Reference\n              <ObjectOwnership>ObjectWriter</ObjectOwnership> \n            </Rule> \n          </OwnershipControls> \n         \nSample Response with ObjectWriter OwnershipControls\nThis example illustrates one usage of PutBucketOwnershipControls.\n          HTTP/1.1 200 OK \n          x-amz-id-2: zkDVX0gbz8oKcjNz7GPz8XhXkhNArHtA8/\nWOf5hyEj6SbisSRdqITZvSuAMik7HK4PY+izDZZI0= \n          x-amz-request-id: BK7Y8M3G7Z0RFRCP \n          Date: Thu, 18 Jun 2020 23:01:33 GMT \n          Content-Length: 0 \n          Server: AmazonS3 \n         \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 582Amazon Simple Storage Service API Reference\nPutBucketPolicy\nService: Amazon S3\nApplies an Amazon S3 bucket policy to an Amazon S3 bucket.\nNote\nDirectory buckets  - For directory buckets, you must make requests for this API operation \nto the Regional endpoint.", "These endpoints support path-style requests in the format\nhttps://s3express-control.", "region_code .amazonaws.com/ bucket-name  .", "\nVirtual-hosted-style requests aren't supported.", "For more information, see Regional and \nZonal endpoints in the Amazon S3 User Guide .\nPermissions\nIf you are using an identity other than the root user of the AWS account that owns the bucket, \nthe calling identity must both have the PutBucketPolicy  permissions on the speci\ufb01ed bucket \nand belong to the bucket owner's account in order to use this operation.\nIf you don't have PutBucketPolicy  permissions, Amazon S3 returns a 403 Access Denied\nerror. If you have the correct permissions, but you're not using an identity that belongs to the \nbucket owner's account, Amazon S3 returns a 405 Method Not Allowed  error.\nImportant\nTo ensure that bucket owners don't inadvertently lock themselves out of their \nown buckets, the root principal in a bucket owner's AWS account can perform the\nGetBucketPolicy , PutBucketPolicy , and DeleteBucketPolicy  API actions, \neven if their bucket policy explicitly denies the root principal's access. Bucket owner \nroot principals can only be blocked from performing these API actions by VPC endpoint \npolicies and AWS Organizations policies.\n\u2022General purpose bucket permissions - The s3:PutBucketPolicy  permission is required \nin a policy. For more information about general purpose buckets bucket policies, see Using \nBucket Policies and User Policies in the Amazon S3 User Guide .\n\u2022Directory bucket permissions - To grant access to this API operation, you must have the\ns3express:PutBucketPolicy  permission in an IAM identity-based policy instead of a \nAmazon S3 API Version 2006-03-01 583Amazon Simple Storage Service API Reference\nbucket policy.", "Cross-account access to this API operation isn't supported.", "This operation can \nonly be performed by the AWS account that owns the resource.", "For more information about \ndirectory bucket policies and permissions, see AWS Identity and Access Management (IAM) for \nS3 Express One Zone in the Amazon S3 User Guide .\nExample bucket policies\nGeneral purpose buckets example bucket policies - See Bucket policy examples in the Amazon \nS3 User Guide .\nDirectory bucket example bucket policies - See Example bucket policies for S3 Express One \nZone in the Amazon S3 User Guide .\nHTTP Host header syntax\nDirectory buckets  - The HTTP Host header syntax is s3express-\ncontrol. region.amazonaws.com .\nThe following operations are related to PutBucketPolicy :\n\u2022CreateBucket\n\u2022DeleteBucket\nRequest Syntax\nPUT /?policy HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nContent-MD5: ContentMD5\nx-amz-sdk-checksum-algorithm: ChecksumAlgorithm\nx-amz-confirm-remove-self-bucket-access: ConfirmRemoveSelfBucketAccess\nx-amz-expected-bucket-owner: ExpectedBucketOwner\n{ Policy in JSON format  }\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe name of the bucket.\nAmazon S3 API Version 2006-03-01 584Amazon Simple Storage Service API Reference\nDirectory buckets  - When you use this operation with a directory bucket, \nyou must use path-style requests in the format https://s3express-\ncontrol. region_code .amazonaws.com/ bucket-name  .", "Virtual-hosted-style requests \naren't supported.", "Directory bucket names must be unique in the chosen Availability Zone.", "\nBucket names must also follow the format  bucket_base_name --az_id--x-s3  (for \nexample,  DOC-EXAMPLE-BUCKET --usw2-az1 --x-s3). For information about bucket naming \nrestrictions, see Directory bucket naming rules in the Amazon S3 User Guide\nRequired: Yes\nContent-MD5\nThe MD5 hash of the request body.\nFor requests made using the AWS Command Line Interface (CLI) or AWS SDKs, this \ufb01eld is \ncalculated automatically.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-con\ufb01rm-remove-self-bucket-access\nSet this parameter to true to con\ufb01rm that you want to remove your permissions to change this \nbucket policy in the future.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match \nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nAmazon S3 API Version 2006-03-01 585Amazon Simple Storage Service API Reference\nNote\nFor directory buckets, this header is not supported in this API operation.", "If you specify \nthis header, the request fails with the HTTP status code 501 Not Implemented .\nx-amz-sdk-checksum-algorithm\nIndicates the algorithm used to create the checksum for the object when you use the SDK. \nThis header will not provide any additional functionality if you don't use the SDK.", "When you \nsend this header, there must be a corresponding x-amz-checksum- algorithm   or x-amz-\ntrailer header sent.", "Otherwise, Amazon S3 fails the request with the HTTP status code 400 \nBad Request .\nFor the x-amz-checksum- algorithm   header, replace  algorithm   with the supported \nalgorithm from the following list:\n\u2022CRC32\n\u2022CRC32C\n\u2022SHA1\n\u2022SHA256\nFor more information, see Checking object integrity in the Amazon S3 User Guide .\nIf the individual checksum value you provide through x-amz-checksum- algorithm   doesn't \nmatch the checksum algorithm you set through x-amz-sdk-checksum-algorithm , Amazon \nS3 ignores any provided ChecksumAlgorithm  parameter and uses the checksum algorithm \nthat matches the provided value in x-amz-checksum- algorithm  .\nNote\nFor directory buckets, when you use AWS SDKs, CRC32  is the default checksum \nalgorithm that's used for performance.\nValid Values: CRC32 | CRC32C | SHA1 | SHA256\nAmazon S3 API Version 2006-03-01 586Amazon Simple Storage Service API Reference\nRequest Body\nThe request accepts the following data in JSON format.\nPolicy\nResponse Syntax\nHTTP/1.1 200\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\nExamples\nSample Request for general purpose buckets\nThe following request shows the PUT individual policy request for the bucket.\nPUT /?policy HTTP/1.1\nHost: bucket.s3.<Region>.amazonaws.com   \nDate: Tue, 04 Apr 2010 20:34:56 GMT   \nAuthorization: authorization string\n{\n\"Version\":\"2008-10-17\",\n\"Id\":\"aaaa-bbbb-cccc-dddd\",\n\"Statement\" : [ \n    { \n        \"Effect\":\"Allow\", \n        \"Sid\":\"1\",  \n        \"Principal\" : { \n            \"AWS\":[\"111122223333\",\"444455556666\"] \n        }, \n        \"Action\":[\"s3:*\"], \n        \"Resource\":\"arn:aws:s3:::bucket/*\" \n    } \n ]  \n} \nAmazon S3 API Version 2006-03-01 587Amazon Simple Storage Service API Reference\n         \nSample Response for general purpose buckets\nThis example illustrates one usage of PutBucketPolicy.\nHTTP/1.1 204 No Content   \nx-amz-id-2: Uuag1LuByR5Onimru9SAMPLEAtRPfTaOFg==   \nx-amz-request-id: 656c76696e6727732SAMPLE7374   \nDate: Tue, 04 Apr 2010 20:34:56 GMT   \nConnection: keep-alive   \nServer: AmazonS3   \n          \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 588Amazon Simple Storage Service API Reference\nPutBucketReplication\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nCreates a replication con\ufb01guration or replaces an existing one. For more information, see\nReplication in the Amazon S3 User Guide .\nSpecify the replication con\ufb01guration in the request body. In the replication con\ufb01guration, you \nprovide the name of the destination bucket or buckets where you want Amazon S3 to replicate \nobjects, the IAM role that Amazon S3 can assume to replicate objects on your behalf, and \nother relevant information.", "You can invoke this request for a speci\ufb01c AWS Region by using the\naws:RequestedRegion  condition key.\nA replication con\ufb01guration must include at least one rule, and can contain a maximum of 1,000.", "\nEach rule identi\ufb01es a subset of objects to replicate by \ufb01ltering the objects in the source bucket. To \nchoose additional subsets of objects to replicate, add a rule for each subset.\nTo specify a subset of the objects in the source bucket to apply a replication rule to, add the Filter \nelement as a child of the Rule element.", "You can \ufb01lter objects based on an object key pre\ufb01x, one or \nmore object tags, or both.", "When you add the Filter element in the con\ufb01guration, you must also add \nthe following elements: DeleteMarkerReplication , Status , and Priority .\nNote\nIf you are using an earlier version of the replication con\ufb01guration, Amazon S3 \nhandles replication of delete markers di\ufb00erently. For more information, see Backward \nCompatibility.\nFor information about enabling versioning on a bucket, see Using Versioning.\nHandling Replication of Encrypted Objects\nBy default, Amazon S3 doesn't replicate objects that are stored at rest using server-\nside encryption with KMS keys. To replicate AWS KMS-encrypted objects, add the \nfollowing: SourceSelectionCriteria , SseKmsEncryptedObjects , Status ,\nAmazon S3 API Version 2006-03-01 589Amazon Simple Storage Service API Reference\nEncryptionConfiguration , and ReplicaKmsKeyID . For information about replication \ncon\ufb01guration, see Replicating Objects Created with SSE Using KMS keys.\nFor information on PutBucketReplication  errors, see List of replication-related error codes\nPermissions\nTo create a PutBucketReplication  request, you must have\ns3:PutReplicationConfiguration  permissions for the bucket.\nBy default, a resource owner, in this case the AWS account that created the bucket, can perform \nthis operation.", "The resource owner can also grant others permissions to perform the operation.", "\nFor more information about permissions, see Specifying Permissions in a Policy and Managing \nAccess Permissions to Your Amazon S3 Resources.\nNote\nTo perform this operation, the user or role performing the action must have the\niam:PassRole permission.\nThe following operations are related to PutBucketReplication :\n\u2022GetBucketReplication\n\u2022DeleteBucketReplication\nRequest Syntax\nPUT /?replication HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nContent-MD5: ContentMD5\nx-amz-sdk-checksum-algorithm: ChecksumAlgorithm\nx-amz-bucket-object-lock-token: Token\nx-amz-expected-bucket-owner: ExpectedBucketOwner\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<ReplicationConfiguration  xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n   <Role>string</Role> \n   <Rule> \n      <DeleteMarkerReplication > \n         < Status>string</Status> \n      </ DeleteMarkerReplication > \nAmazon S3 API Version 2006-03-01 590Amazon Simple Storage Service API Reference\n      <Destination > \n         < AccessControlTranslation > \n            < Owner>string</Owner> \n         </ AccessControlTranslation > \n         < Account>string</Account> \n         < Bucket>string</Bucket> \n         < EncryptionConfiguration > \n            < ReplicaKmsKeyID >string</ReplicaKmsKeyID > \n         </ EncryptionConfiguration > \n         < Metrics> \n            < EventThreshold > \n               < Minutes>integer</Minutes> \n            </ EventThreshold > \n            < Status>string</Status> \n         </ Metrics> \n         < ReplicationTime > \n            < Status>string</Status> \n            < Time> \n               < Minutes>integer</Minutes> \n            </ Time> \n         </ ReplicationTime > \n         < StorageClass >string</StorageClass > \n      </ Destination > \n      <ExistingObjectReplication > \n         < Status>string</Status> \n      </ ExistingObjectReplication > \n      <Filter> \n         < And> \n            < Prefix>string</Prefix> \n            < Tag> \n               < Key>string</Key> \n               < Value>string</Value> \n            </ Tag> \n            ... \n         </ And> \n         < Prefix>string</Prefix> \n         < Tag> \n            < Key>string</Key> \n            < Value>string</Value> \n         </ Tag> \n      </ Filter> \n      <ID>string</ID> \n      <Prefix>string</Prefix> \n      <Priority >integer</Priority > \nAmazon S3 API Version 2006-03-01 591Amazon Simple Storage Service API Reference\n      <SourceSelectionCriteria > \n         < ReplicaModifications > \n            < Status>string</Status> \n         </ ReplicaModifications > \n         < SseKmsEncryptedObjects > \n            < Status>string</Status> \n         </ SseKmsEncryptedObjects > \n      </ SourceSelectionCriteria > \n      <Status>string</Status> \n   </Rule> \n   ...\n</ReplicationConfiguration >\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe name of the bucket\nRequired: Yes\nContent-MD5\nThe base64-encoded 128-bit MD5 digest of the data.", "You must use this header as a message \nintegrity check to verify that the request body was not corrupted in transit.", "For more \ninformation, see RFC 1864.\nFor requests made using the AWS Command Line Interface (CLI) or AWS SDKs, this \ufb01eld is \ncalculated automatically.\nx-amz-bucket-object-lock-token\nA token to allow Object Lock to be enabled for an existing bucket.\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match \nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nx-amz-sdk-checksum-algorithm\nIndicates the algorithm used to create the checksum for the object when you use the SDK.", "This \nheader will not provide any additional functionality if you don't use the SDK.", "When you send \nAmazon S3 API Version 2006-03-01 592Amazon Simple Storage Service API Reference\nthis header, there must be a corresponding x-amz-checksum  or x-amz-trailer  header sent. \nOtherwise, Amazon S3 fails the request with the HTTP status code 400 Bad Request . For \nmore information, see Checking object integrity in the Amazon S3 User Guide .\nIf you provide an individual checksum, Amazon S3 ignores any provided ChecksumAlgorithm\nparameter.\nValid Values: CRC32 | CRC32C | SHA1 | SHA256\nRequest Body\nThe request accepts the following data in XML format.\nReplicationCon\ufb01guration\nRoot level tag for the ReplicationCon\ufb01guration parameters.\nRequired: Yes\nRole\nThe Amazon Resource Name (ARN) of the AWS Identity and Access Management (IAM) role \nthat Amazon S3 assumes when replicating objects. For more information, see How to Set Up \nReplication in the Amazon S3 User Guide .\nType: String\nRequired: Yes\nRule\nA container for one or more replication rules. A replication con\ufb01guration must have at least one \nrule and can contain a maximum of 1,000 rules.\nType: Array of ReplicationRule data types\nRequired: Yes\nResponse Syntax\nHTTP/1.1 200\nAmazon S3 API Version 2006-03-01 593Amazon Simple Storage Service API Reference\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\nExamples\nSample Request: Add a replication con\ufb01guration\nThe following is a sample PUT request that creates a replication subresource on the speci\ufb01ed \nbucket and saves the replication con\ufb01guration in it.", "The replication con\ufb01guration speci\ufb01es a rule to \nreplicate objects to the DOC-EXAMPLE-BUCKET  bucket.", "The rule includes a \ufb01lter to replicate only \nthe objects created with the key name pre\ufb01x TaxDocs and that have two speci\ufb01c tags.\nAfter you add a replication con\ufb01guration to your bucket, Amazon S3 assumes the AWS Identity and \nAccess Management (IAM) role speci\ufb01ed in the con\ufb01guration to replicate objects on behalf of the \nbucket owner.", "The bucket owner is the AWS account that created the bucket.\nFiltering using the <Filter> element is supported in the latest XML con\ufb01guration.", "If you are using an \nearlier version of the XML con\ufb01guration, you can \ufb01lter only on key pre\ufb01x.", "In that case, you add the \n<Pre\ufb01x> element as a child of the <Rule>.\nFor more examples of replication con\ufb01guration, see Replication Con\ufb01guration Overview in the\nAmazon S3 User Guide.\nPUT /?replication HTTP/1.1\nHost: examplebucket.s3.<Region>.amazonaws.com  \nDate: Wed, 11 Feb 2015 02:11:21 GMT\nContent-MD5: q6yJDlIkcBaGGfb3QLY69A==\nAuthorization: authorization string\nContent-Length: length\n<ReplicationConfiguration> \n  <Role>arn:aws:iam::35667example:role/CrossRegionReplicationRoleForS3</Role> \n  <Rule> \n    <ID>rule1</ID> \n    <Status>Enabled</Status> \n    <Priority>1</Priority> \n    <DeleteMarkerReplication> \n       <Status>Disabled</Status> \n    </DeleteMarkerReplication> \n    <Filter> \n       <And> \nAmazon S3 API Version 2006-03-01 594Amazon Simple Storage Service API Reference\n           <Prefix>TaxDocs</Prefix> \n           <Tag> \n             <Key>key1</Key> \n             <Value>value1</Value> \n           </Tag> \n           <Tag> \n             <Key>key1</Key> \n             <Value>value1</Value> \n           </Tag> \n       </And> \n    </Filter> \n    <Destination> \n      <Bucket>arn:aws:s3:::DOC-EXAMPLE-BUCKET</Bucket> \n    </Destination> \n  </Rule>\n</ReplicationConfiguration> \n          \nSample Response\nThis example illustrates one usage of PutBucketReplication.\nHTTP/1.1 200 OK\nx-amz-id-2: r+qR7+nhXtJDDIJ0JJYcd+1j5nM/rUFiiiZ/fNbDOsd3JUE8NWMLNHXmvPfwMpdc\nx-amz-request-id: 9E26D08072A8EF9E\nDate: Wed, 11 Feb 2015 02:11:22 GMT\nContent-Length: 0\nServer: AmazonS3 \n          \nSample Request: Add a Replication Con\ufb01guration with Amazon S3 Replication Time Control \nEnabled\nYou can use S3 Replication Time Control (S3 RTC) to replicate your data in the same AWS Region \nor across di\ufb00erent AWS Regions in a predictable time frame. S3 RTC replicates 99.99 percent of \nnew objects stored in Amazon S3 within 15 minutes. For more information, see Replicating objects \nusing Replication Time Control.\nPUT /?replication HTTP/1.1\nHost: examplebucket.s3.<Region>.amazonaws.com  \nAmazon S3 API Version 2006-03-01 595Amazon Simple Storage Service API Reference\nDate: Wed, 11 Feb 2015 02:11:21 GMT\nContent-MD5: q6yJDlIkcBaGGfb3QLY69A==\nAuthorization: authorization string\nContent-Length: length\nx-amz-bucket-object-lock-token: Token\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<ReplicationConfiguration> \n  <Role>arn:aws:iam::35667example:role/CrossRegionReplicationRoleForS3</Role> \n  <Rule> \n    <ID>rule1</ID> \n    <Status>Enabled</Status> \n    <Priority>1</Priority> \n    <Filter> \n       <And> \n           <Prefix>TaxDocs</Prefix> \n           <Tag> \n             <Key>key1</Key> \n             <Value>value1</Value> \n           </Tag> \n           <Tag> \n             <Key>key1</Key> \n             <Value>value1</Value> \n           </Tag> \n       </And> \n    </Filter> \n    <Destination> \n      <Bucket>arn:aws:s3:::DOC-EXAMPLE-BUCKET</Bucket> \n      <Metrics> \n         <Status>Enabled</Status> \n         <EventThreshold> \n            <Minutes>15</Minutes> \n         </EventThreshold> \n      </Metrics> \n      <ReplicationTime> \n         <Status>Enabled</Status> \n         <Time> \n            <Minutes>15</Minutes> \n         </Time> \n      </ReplicationTime>            \n    </Destination> \n  </Rule>\n</ReplicationConfiguration> \nAmazon S3 API Version 2006-03-01 596Amazon Simple Storage Service API Reference\n         \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 597Amazon Simple Storage Service API Reference\nPutBucketRequestPayment\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nSets the request payment con\ufb01guration for a bucket.", "By default, the bucket owner pays for \ndownloads from the bucket. This con\ufb01guration parameter enables the bucket owner (only) to \nspecify that the person requesting the download will be charged for the download.", "For more \ninformation, see Requester Pays Buckets.\nThe following operations are related to PutBucketRequestPayment :\n\u2022CreateBucket\n\u2022GetBucketRequestPayment\nRequest Syntax\nPUT /?requestPayment HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nContent-MD5: ContentMD5\nx-amz-sdk-checksum-algorithm: ChecksumAlgorithm\nx-amz-expected-bucket-owner: ExpectedBucketOwner\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<RequestPaymentConfiguration  xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n   <Payer>string</Payer>\n</RequestPaymentConfiguration >\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe bucket name.\nRequired: Yes\nAmazon S3 API Version 2006-03-01 598Amazon Simple Storage Service API Reference\nContent-MD5\nThe base64-encoded 128-bit MD5 digest of the data.", "You must use this header as a message \nintegrity check to verify that the request body was not corrupted in transit.", "For more \ninformation, see RFC 1864.\nFor requests made using the AWS Command Line Interface (CLI) or AWS SDKs, this \ufb01eld is \ncalculated automatically.\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match \nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nx-amz-sdk-checksum-algorithm\nIndicates the algorithm used to create the checksum for the object when you use the SDK.", "This \nheader will not provide any additional functionality if you don't use the SDK.", "When you send \nthis header, there must be a corresponding x-amz-checksum  or x-amz-trailer  header sent.", "\nOtherwise, Amazon S3 fails the request with the HTTP status code 400 Bad Request . For \nmore information, see Checking object integrity in the Amazon S3 User Guide .\nIf you provide an individual checksum, Amazon S3 ignores any provided ChecksumAlgorithm\nparameter.\nValid Values: CRC32 | CRC32C | SHA1 | SHA256\nRequest Body\nThe request accepts the following data in XML format.\nRequestPaymentCon\ufb01guration\nRoot level tag for the RequestPaymentCon\ufb01guration parameters.\nRequired: Yes\nPayer\nSpeci\ufb01es who pays for the download and request fees.\nType: String\nAmazon S3 API Version 2006-03-01 599Amazon Simple Storage Service API Reference\nValid Values: Requester | BucketOwner\nRequired: Yes\nResponse Syntax\nHTTP/1.1 200\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\nExamples\nSample Request\nThis request creates a Requester Pays bucket named colorpictures .\nPUT ?requestPayment HTTP/1.1\nHost: colorpictures.s3.<Region>.amazonaws.com\nContent-Length: 173\nDate: Wed, 01 Mar  2006 12:00:00 GMT\nAuthorization: authorization string\n<RequestPaymentConfiguration xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n  <Payer>Requester</Payer>\n</RequestPaymentConfiguration> \n          \nSample Response\nDelete the metric con\ufb01guration with a speci\ufb01ed ID, which disables the CloudWatch metrics with the\nExampleMetrics  value for the FilterId  dimension.\nHTTP/1.1 200 OK\nx-amz-id-2: YgIPIfBiKa2bj0KMg95r/0zo3emzU4dzsD4rcKCHQUAdQkf3ShJTOOpXUueF6QKo\nx-amz-request-id: 236A8905248E5A01\nDate: Wed, 01 Mar  2006 12:00:00 GMT\nAmazon S3 API Version 2006-03-01 600Amazon Simple Storage Service API Reference\nLocation: /colorpictures\nContent-Length: 0\nConnection: close\nServer: AmazonS3 \n          \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 601Amazon Simple Storage Service API Reference\nPutBucketTagging\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nSets the tags for a bucket.\nUse tags to organize your AWS bill to re\ufb02ect your own cost structure.", "To do this, sign up to get \nyour AWS account bill with tag key values included.", "Then, to see the cost of combined resources, \norganize your billing information according to resources with the same tag key values. For example, \nyou can tag several resources with a speci\ufb01c application name, and then organize your billing \ninformation to see the total cost of that application across several services.", "For more information, \nsee Cost Allocation and Tagging and Using Cost Allocation in Amazon S3 Bucket Tags.\nNote\nWhen this operation sets the tags for a bucket, it will overwrite any current tags the bucket \nalready has. You cannot use this operation to add tags to an existing list of tags.\nTo use this operation, you must have permissions to perform the s3:PutBucketTagging  action.", "\nThe bucket owner has this permission by default and can grant this permission to others.", "For more \ninformation about permissions, see Permissions Related to Bucket Subresource Operations and\nManaging Access Permissions to Your Amazon S3 Resources.\nPutBucketTagging  has the following special errors. For more Amazon S3 errors see, Error \nResponses.\n\u2022InvalidTag  - The tag provided was not a valid tag.", "This error can occur if the tag did not pass \ninput validation.", "For more information, see Using Cost Allocation in Amazon S3 Bucket Tags.\n\u2022MalformedXML  - The XML provided does not match the schema.\n\u2022OperationAborted  - A con\ufb02icting conditional action is currently in progress against this \nresource. Please try again.\n\u2022InternalError  - The service was unable to apply the provided tag to the bucket.\nAmazon S3 API Version 2006-03-01 602Amazon Simple Storage Service API Reference\nThe following operations are related to PutBucketTagging :\n\u2022GetBucketTagging\n\u2022DeleteBucketTagging\nRequest Syntax\nPUT /?tagging HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nContent-MD5: ContentMD5\nx-amz-sdk-checksum-algorithm: ChecksumAlgorithm\nx-amz-expected-bucket-owner: ExpectedBucketOwner\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<Tagging xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n   <TagSet> \n      <Tag> \n         < Key>string</Key> \n         < Value>string</Value> \n      </Tag> \n   </TagSet>\n</Tagging>\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe bucket name.\nRequired: Yes\nContent-MD5\nThe base64-encoded 128-bit MD5 digest of the data.", "You must use this header as a message \nintegrity check to verify that the request body was not corrupted in transit.", "For more \ninformation, see RFC 1864.\nFor requests made using the AWS Command Line Interface (CLI) or AWS SDKs, this \ufb01eld is \ncalculated automatically.\nAmazon S3 API Version 2006-03-01 603Amazon Simple Storage Service API Reference\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match \nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nx-amz-sdk-checksum-algorithm\nIndicates the algorithm used to create the checksum for the object when you use the SDK.", "This \nheader will not provide any additional functionality if you don't use the SDK.", "When you send \nthis header, there must be a corresponding x-amz-checksum  or x-amz-trailer  header sent.", "\nOtherwise, Amazon S3 fails the request with the HTTP status code 400 Bad Request . For \nmore information, see Checking object integrity in the Amazon S3 User Guide .\nIf you provide an individual checksum, Amazon S3 ignores any provided ChecksumAlgorithm\nparameter.\nValid Values: CRC32 | CRC32C | SHA1 | SHA256\nRequest Body\nThe request accepts the following data in XML format.\nTagging\nRoot level tag for the Tagging parameters.\nRequired: Yes\nTagSet\nA collection for a set of tags\nType: Array of Tag data types\nRequired: Yes\nResponse Syntax\nHTTP/1.1 200\nAmazon S3 API Version 2006-03-01 604Amazon Simple Storage Service API Reference\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\nExamples\nSample Request: Add tag set to a bucket\nThe following request adds a tag set to the existing examplebucket  bucket.\nPUT ?tagging HTTP/1.1\nHost: examplebucket.s3.<Region>.amazonaws.com\nContent-Length: 1660\nx-amz-date: Thu, 12 Apr 2012 20:04:21 GMT\nAuthorization: authorization string\n<Tagging> \n  <TagSet> \n    <Tag> \n      <Key>Project</Key> \n      <Value>Project One</Value> \n    </Tag> \n    <Tag> \n      <Key>User</Key> \n      <Value>jsmith</Value> \n    </Tag> \n  </TagSet>\n</Tagging> \n          \nSample Response\nThis example illustrates one usage of PutBucketTagging.\nHTTP/1.1 204 No Content\nx-amz-id-2: YgIPIfBiKa2bj0KMgUAdQkf3ShJTOOpXUueF6QKo\nx-amz-request-id: 236A8905248E5A01\nDate: Wed, 01 Oct  2012 12:00:00 GMT \n          \nAmazon S3 API Version 2006-03-01 605Amazon Simple Storage Service API Reference\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 606Amazon Simple Storage Service API Reference\nPutBucketVersioning\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nNote\nWhen you enable versioning on a bucket for the \ufb01rst time, it might take a short amount of \ntime for the change to be fully propagated. We recommend that you wait for 15 minutes \nafter enabling versioning before issuing write operations (PUT or DELETE) on objects in the \nbucket.\nSets the versioning state of an existing bucket.\nYou can set the versioning state with one of the following values:\nEnabled\u2014Enables versioning for the objects in the bucket. All objects added to the bucket receive \na unique version ID.\nSuspended \u2014Disables versioning for the objects in the bucket. All objects added to the bucket \nreceive the version ID null.\nIf the versioning state has never been set on a bucket, it has no versioning state; a\nGetBucketVersioning request does not return a versioning state value.\nIn order to enable MFA Delete, you must be the bucket owner. If you are the bucket owner and \nwant to enable MFA Delete in the bucket versioning con\ufb01guration, you must include the x-amz-\nmfa request  header and the Status  and the MfaDelete  request elements in a request to set \nthe versioning state of the bucket.\nImportant\nIf you have an object expiration lifecycle con\ufb01guration in your non-versioned bucket \nand you want to maintain the same permanent delete behavior when you enable \nversioning, you must add a noncurrent expiration policy.", "The noncurrent expiration \nAmazon S3 API Version 2006-03-01 607Amazon Simple Storage Service API Reference\nlifecycle con\ufb01guration will manage the deletes of the noncurrent object versions in the \nversion-enabled bucket. (A version-enabled bucket maintains one current and zero or more \nnoncurrent object versions.) For more information, see Lifecycle and Versioning.\nThe following operations are related to PutBucketVersioning :\n\u2022CreateBucket\n\u2022DeleteBucket\n\u2022GetBucketVersioning\nRequest Syntax\nPUT /?versioning HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nContent-MD5: ContentMD5\nx-amz-sdk-checksum-algorithm: ChecksumAlgorithm\nx-amz-mfa: MFA\nx-amz-expected-bucket-owner: ExpectedBucketOwner\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<VersioningConfiguration  xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n   <MfaDelete >string</MfaDelete > \n   <Status>string</Status>\n</VersioningConfiguration >\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe bucket name.\nRequired: Yes\nContent-MD5\n>The base64-encoded 128-bit MD5 digest of the data.", "You must use this header as a message \nintegrity check to verify that the request body was not corrupted in transit.", "For more \ninformation, see RFC 1864.\nAmazon S3 API Version 2006-03-01 608Amazon Simple Storage Service API Reference\nFor requests made using the AWS Command Line Interface (CLI) or AWS SDKs, this \ufb01eld is \ncalculated automatically.\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner.", "If the account ID that you provide does not match \nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nx-amz-mfa\nThe concatenation of the authentication device's serial number, a space, and the value that is \ndisplayed on your authentication device.\nx-amz-sdk-checksum-algorithm\nIndicates the algorithm used to create the checksum for the object when you use the SDK.", "This \nheader will not provide any additional functionality if you don't use the SDK.", "When you send \nthis header, there must be a corresponding x-amz-checksum  or x-amz-trailer  header sent.", "\nOtherwise, Amazon S3 fails the request with the HTTP status code 400 Bad Request . For \nmore information, see Checking object integrity in the Amazon S3 User Guide .\nIf you provide an individual checksum, Amazon S3 ignores any provided ChecksumAlgorithm\nparameter.\nValid Values: CRC32 | CRC32C | SHA1 | SHA256\nRequest Body\nThe request accepts the following data in XML format.\nVersioningCon\ufb01guration\nRoot level tag for the VersioningCon\ufb01guration parameters.\nRequired: Yes\nMFADelete\nSpeci\ufb01es whether MFA delete is enabled in the bucket versioning con\ufb01guration.", "This element is \nonly returned if the bucket has been con\ufb01gured with MFA delete.", "If the bucket has never been \nso con\ufb01gured, this element is not returned.\nType: String\nAmazon S3 API Version 2006-03-01 609Amazon Simple Storage Service API Reference\nValid Values: Enabled | Disabled\nRequired: No\nStatus\nThe versioning state of the bucket.\nType: String\nValid Values: Enabled | Suspended\nRequired: No\nResponse Syntax\nHTTP/1.1 200\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\nExamples\nSample Request\nThe following request enables versioning for the speci\ufb01ed bucket.\nPUT /?versioning HTTP/1.1\nHost: bucket.s3.<Region>.amazonaws.com\nDate: Wed, 01 Mar  2006 12:00:00 GMT\nAuthorization: authorization string\nContent-Type: text/plain\nContent-Length: 124 \n  \n<VersioningConfiguration xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\">  \n  <Status>Enabled</Status>  \n</VersioningConfiguration> \n          \nSample Response\nThis example illustrates one usage of PutBucketVersioning.\nAmazon S3 API Version 2006-03-01 610Amazon Simple Storage Service API Reference\nHTTP/1.1 200 OK\nx-amz-id-2: YgIPIfBiKa2bj0KMg95r/0zo3emzU4dzsD4rcKCHQUAdQkf3ShJTOOpXUueF6QKo\nx-amz-request-id: 236A8905248E5A01\nDate: Wed, 01 Mar  2006 12:00:00 GMT3 \n          \nSample Request\nThe following request suspends versioning for the speci\ufb01ed bucket.\nPUT /?versioning HTTP/1.1\nHost: bucket.s3.<Region>.amazonaws.com\nDate: Wed, 12 Oct 2009 17:50:00 GMT\nAuthorization: authorization string\nContent-Type: text/plain\nContent-Length: 124 \n  \n<VersioningConfiguration xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\">  \n   <Status>Suspended</Status>  \n</VersioningConfiguration> \n          \nSample Response\nThis example illustrates one usage of PutBucketVersioning.\nHTTP/1.1 200 OK\nx-amz-id-2: YgIPIfBiKa2bj0KMg95r/0zo3emzU4dzsD4rcKCHQUAdQkf3ShJTOOpXUueF6QKo\nx-amz-request-id: 236A8905248E5A01\nDate: Wed, 01 Mar  2006 12:00:00 GMT \n          \nSample Request\nThe following request enables versioning and MFA Delete on a bucket. Note the space between\n[SerialNumber]  and [TokenCode]  and that you must include Status whenever you use\nMfaDelete .\nAmazon S3 API Version 2006-03-01 611Amazon Simple Storage Service API Reference\nPUT /?versioning HTTP/1.1\nHost: bucket.s3.<Region>.amazonaws.com\nDate: Wed, 12 Oct 2009 17:50:00 GMT\nx-amz-mfa:[SerialNumber] [TokenCode]\nAuthorization: authorization string\nContent-Type: text/plain\nContent-Length: 124 \n  \n<VersioningConfiguration xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\">  \n   <Status>Enabled</Status>  \n   <MfaDelete>Enabled</MfaDelete>\n</VersioningConfiguration> \n          \nSample Response\nThis example illustrates one usage of PutBucketVersioning.\nHTTPS/1.1 200 OK\nx-amz-id-2: YgIPIfBiKa2bj0KMg95r/0zo3emzU4dzsD4rcKCHQUAdQkf3ShJTOOpXUueF6QKo\nx-amz-request-id: 236A8905248E5A01\nDate: Wed, 01 Mar  2006 12:00:00 GMT\nLocation: /colorpictures\nContent-Length: 0\nConnection: close\nServer: AmazonS3 \n          \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\nAmazon S3 API Version 2006-03-01 612Amazon Simple Storage Service API Reference\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 613Amazon Simple Storage Service API Reference\nPutBucketWebsite\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nSets the con\ufb01guration of the website that is speci\ufb01ed in the website subresource.", "To con\ufb01gure \na bucket as a website, you can add this subresource on the bucket with website con\ufb01guration \ninformation such as the \ufb01le name of the index document and any redirect rules.", "For more \ninformation, see Hosting Websites on Amazon S3.\nThis PUT action requires the S3:PutBucketWebsite  permission. By default, only the bucket \nowner can con\ufb01gure the website attached to a bucket; however, bucket owners can allow \nother users to set the website con\ufb01guration by writing a bucket policy that grants them the\nS3:PutBucketWebsite  permission.\nTo redirect all website requests sent to the bucket's website endpoint, you add a website \ncon\ufb01guration with the following elements.", "Because all requests are sent to another website, you \ndon't need to provide index document name for the bucket.\n\u2022WebsiteConfiguration\n\u2022RedirectAllRequestsTo\n\u2022HostName\n\u2022Protocol\nIf you want granular control over redirects, you can use the following elements to add routing rules \nthat describe conditions for redirecting requests and information about the redirect destination. In \nthis case, the website con\ufb01guration must provide an index document for the bucket, because some \nrequests might not be redirected.\n\u2022WebsiteConfiguration\n\u2022IndexDocument\n\u2022Suffix\n\u2022ErrorDocument\nAmazon S3 API Version 2006-03-01 614Amazon Simple Storage Service API Reference\n\u2022Key\n\u2022RoutingRules\n\u2022RoutingRule\n\u2022Condition\n\u2022HttpErrorCodeReturnedEquals\n\u2022KeyPrefixEquals\n\u2022Redirect\n\u2022Protocol\n\u2022HostName\n\u2022ReplaceKeyPrefixWith\n\u2022ReplaceKeyWith\n\u2022HttpRedirectCode\nAmazon S3 has a limitation of 50 routing rules per website con\ufb01guration.", "If you require more than \n50 routing rules, you can use object redirect.", "For more information, see Con\ufb01guring an Object \nRedirect in the Amazon S3 User Guide .\nThe maximum request length is limited to 128 KB.\nRequest Syntax\nPUT /?website HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nContent-MD5: ContentMD5\nx-amz-sdk-checksum-algorithm: ChecksumAlgorithm\nx-amz-expected-bucket-owner: ExpectedBucketOwner\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<WebsiteConfiguration  xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n   <ErrorDocument > \n      <Key>string</Key> \n   </ErrorDocument > \n   <IndexDocument > \n      <Suffix>string</Suffix> \n   </IndexDocument > \n   <RedirectAllRequestsTo > \n      <HostName >string</HostName > \nAmazon S3 API Version 2006-03-01 615Amazon Simple Storage Service API Reference\n      <Protocol >string</Protocol > \n   </RedirectAllRequestsTo > \n   <RoutingRules > \n      <RoutingRule> \n         < Condition > \n            < HttpErrorCodeReturnedEquals >string</HttpErrorCodeReturnedEquals > \n            < KeyPrefixEquals >string</KeyPrefixEquals > \n         </ Condition > \n         < Redirect > \n            < HostName >string</HostName > \n            < HttpRedirectCode >string</HttpRedirectCode > \n            < Protocol >string</Protocol > \n            < ReplaceKeyPrefixWith >string</ReplaceKeyPrefixWith > \n            < ReplaceKeyWith >string</ReplaceKeyWith > \n         </ Redirect > \n      </RoutingRule> \n   </RoutingRules >\n</WebsiteConfiguration >\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe bucket name.\nRequired: Yes\nContent-MD5\nThe base64-encoded 128-bit MD5 digest of the data.", "You must use this header as a message \nintegrity check to verify that the request body was not corrupted in transit.", "For more \ninformation, see RFC 1864.\nFor requests made using the AWS Command Line Interface (CLI) or AWS SDKs, this \ufb01eld is \ncalculated automatically.\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match \nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nAmazon S3 API Version 2006-03-01 616Amazon Simple Storage Service API Reference\nx-amz-sdk-checksum-algorithm\nIndicates the algorithm used to create the checksum for the object when you use the SDK.", "This \nheader will not provide any additional functionality if you don't use the SDK.", "When you send \nthis header, there must be a corresponding x-amz-checksum  or x-amz-trailer  header sent.", "\nOtherwise, Amazon S3 fails the request with the HTTP status code 400 Bad Request . For \nmore information, see Checking object integrity in the Amazon S3 User Guide .\nIf you provide an individual checksum, Amazon S3 ignores any provided ChecksumAlgorithm\nparameter.\nValid Values: CRC32 | CRC32C | SHA1 | SHA256\nRequest Body\nThe request accepts the following data in XML format.\nWebsiteCon\ufb01guration\nRoot level tag for the WebsiteCon\ufb01guration parameters.\nRequired: Yes\nErrorDocument\nThe name of the error document for the website.\nType: ErrorDocument data type\nRequired: No\nIndexDocument\nThe name of the index document for the website.\nType: IndexDocument  data type\nRequired: No\nRedirectAllRequestsTo\nThe redirect behavior for every request to this bucket's website endpoint.\nAmazon S3 API Version 2006-03-01 617Amazon Simple Storage Service API Reference\nImportant\nIf you specify this property, you can't specify any other property.\nType: RedirectAllRequestsTo data type\nRequired: No\nRoutingRules\nRules that de\ufb01ne when a redirect is applied and the redirect behavior.\nType: Array of RoutingRule data types\nRequired: No\nResponse Syntax\nHTTP/1.1 200\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\nExamples\nExample 1: Con\ufb01gure bucket as a website (add website con\ufb01guration)\nThe following request con\ufb01gures a bucket example.com as a website.", "The con\ufb01guration in the \nrequest speci\ufb01es index.html as the index document.", "It also speci\ufb01es the optional error document, \nSomeErrorDocument.html.\nPUT ?website HTTP/1.1\nHost: example.com.s3.<Region>.amazonaws.com\nContent-Length: 256\nDate: Thu, 27 Jan 2011 12:00:00 GMT\nAuthorization: signatureValue\n<WebsiteConfiguration xmlns='http://s3.amazonaws.com/doc/2006-03-01/'> \nAmazon S3 API Version 2006-03-01 618Amazon Simple Storage Service API Reference\n    <IndexDocument> \n        <Suffix>index.html</Suffix> \n    </IndexDocument> \n    <ErrorDocument> \n        <Key>SomeErrorDocument.html</Key> \n    </ErrorDocument>\n</WebsiteConfiguration> \n          \nSample Response\nThis example illustrates one usage of PutBucketWebsite.\nHTTP/1.1 200 OK\nx-amz-id-2: YgIPIfBiKa2bj0KMgUAdQkf3ShJTOOpXUueF6QKo\nx-amz-request-id: 80CD4368BD211111\nDate: Thu, 27 Jan 2011 00:00:00 GMT\nContent-Length: 0\nServer: AmazonS3 \n          \nExample 2: Con\ufb01gure bucket as a website but redirect all requests\nThe following request con\ufb01gures a bucket www.example.com  as a website. However, the \ncon\ufb01guration speci\ufb01es that all GET requests for the www.example.com bucket's website endpoint \nwill be redirected to host example.com. This redirect can be useful when you want to serve \nrequests for both http://www.example.com  and http://example.com , but you want to \nmaintain the website content in only one bucket, in this case, example.com .\nPUT ?website HTTP/1.1\nHost: www.example.com.s3.<Region>.amazonaws.com\nContent-Length: length-value\nDate: Thu, 27 Jan 2011 12:00:00 GMT\nAuthorization: signatureValue\n<WebsiteConfiguration xmlns='http://s3.amazonaws.com/doc/2006-03-01/'> \n   <RedirectAllRequestsTo> \n      <HostName>example.com</HostName> \n    </RedirectAllRequestsTo>\n</WebsiteConfiguration> \nAmazon S3 API Version 2006-03-01 619Amazon Simple Storage Service API Reference\n         \nExample 3: Con\ufb01gure bucket as a website and specify optional redirection rules\nExample 1 is the simplest website con\ufb01guration.", "It con\ufb01gures a bucket as a website by providing \nonly an index document and an error document.", "You can further customize the website \ncon\ufb01guration by adding routing rules that redirect requests for one or more objects.", "For example, \nsuppose that your bucket contained the following objects:\n\u2022index.html\n\u2022docs/article1.html\n\u2022docs/article2.html\nIf you decided to rename the folder from docs/  to documents/ , you would need to redirect \nrequests for pre\ufb01x /docs  to documents/ . For example, a request for docs/article1.html will need \nto be redirected to documents/article1.html.\nIn this case, you update the website con\ufb01guration and add a routing rule as shown in the following \nrequest.\nPUT ?website HTTP/1.1\nHost: www.example.com.s3.<Region>.amazonaws.com\nContent-Length: length-value\nDate: Thu, 27 Jan 2011 12:00:00 GMT\nAuthorization: signatureValue\n<WebsiteConfiguration xmlns='http://s3.amazonaws.com/doc/2006-03-01/'> \n  <IndexDocument> \n    <Suffix>index.html</Suffix> \n  </IndexDocument> \n  <ErrorDocument> \n    <Key>Error.html</Key> \n  </ErrorDocument> \n  <RoutingRules> \n    <RoutingRule> \n    <Condition> \n      <KeyPrefixEquals>docs/</KeyPrefixEquals> \n    </Condition> \n    <Redirect> \nAmazon S3 API Version 2006-03-01 620Amazon Simple Storage Service API Reference\n      <ReplaceKeyPrefixWith>documents/</ReplaceKeyPrefixWith> \n    </Redirect> \n    </RoutingRule> \n  </RoutingRules>\n</WebsiteConfiguration> \n          \nExample 4: Con\ufb01gure a bucket as a website and redirect errors\nYou can use a routing rule to specify a condition that checks for a speci\ufb01c HTTP error code.", "When \na page request results in this error, you can optionally reroute requests. For example, you might \nroute requests to another host and optionally process the error.", "The routing rule in the following \nrequests redirects requests to an EC2 instance in the event of an HTTP error 404.", "For illustration, \nthe redirect also inserts an object key pre\ufb01x report-404/  in the redirect. For example, if you \nrequest a page ExamplePage.html  and it results in an HTTP 404 error, the request is routed to a \npage report-404/testPage.html  on the speci\ufb01ed EC2 instance. If there is no routing rule and \nthe HTTP error 404 occurred, then Error.html  would be returned.\nPUT ?website HTTP/1.1\nHost: www.example.com.s3.<Region>.amazonaws.com\nContent-Length: 580\nDate: Thu, 27 Jan 2011 12:00:00 GMT\nAuthorization: signatureValue\n<WebsiteConfiguration xmlns='http://s3.amazonaws.com/doc/2006-03-01/'> \n  <IndexDocument> \n    <Suffix>index.html</Suffix> \n  </IndexDocument> \n  <ErrorDocument> \n    <Key>Error.html</Key> \n  </ErrorDocument> \n  <RoutingRules> \n    <RoutingRule> \n    <Condition> \n      <HttpErrorCodeReturnedEquals>404</HttpErrorCodeReturnedEquals > \n    </Condition> \n    <Redirect> \n      <HostName>ec2-11-22-333-44.compute-1.amazonaws.com</HostName> \n      <ReplaceKeyPrefixWith>report-404/</ReplaceKeyPrefixWith> \n    </Redirect> \nAmazon S3 API Version 2006-03-01 621Amazon Simple Storage Service API Reference\n    </RoutingRule> \n  </RoutingRules>\n</WebsiteConfiguration> \n          \nExample 5: Con\ufb01gure a bucket as a website and redirect folder requests to a page\nSuppose you have the following pages in your bucket:\n\u2022images/photo1.jpg\n\u2022images/photo2.jpg\n\u2022images/photo3.jpg\nNow you want to route requests for all pages with the images/ pre\ufb01x to go to a single page, \nerrorpage.html. You can add a website con\ufb01guration to your bucket with the routing rule shown in \nthe following request.\nPUT ?website HTTP/1.1\nHost: www.example.com.s3.<Region>.amazonaws.com\nContent-Length: 481\nDate: Thu, 27 Jan 2011 12:00:00 GMT\nAuthorization: signatureValue\n<WebsiteConfiguration xmlns='http://s3.amazonaws.com/doc/2006-03-01/'> \n  <IndexDocument> \n    <Suffix>index.html</Suffix> \n  </IndexDocument> \n  <ErrorDocument> \n    <Key>Error.html</Key> \n  </ErrorDocument> \n  <RoutingRules> \n    <RoutingRule> \n    <Condition> \n      <KeyPrefixEquals>images/</KeyPrefixEquals> \n    </Condition> \n    <Redirect> \n      <ReplaceKeyWith>errorpage.html</ReplaceKeyWith> \n    </Redirect> \n    </RoutingRule> \nAmazon S3 API Version 2006-03-01 622Amazon Simple Storage Service API Reference\n  </RoutingRules>\n</WebsiteConfiguration> \n          \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 623Amazon Simple Storage Service API Reference\nPutObject\nService: Amazon S3\nAdds an object to a bucket.\nNote\n\u2022Amazon S3 never adds partial objects; if you receive a success response, Amazon S3 \nadded the entire object to the bucket.", "You cannot use PutObject  to only update a \nsingle piece of metadata for an existing object.", "You must put the entire object with \nupdated metadata if you want to update some values.\n\u2022If your bucket uses the bucket owner enforced setting for Object Ownership, ACLs are \ndisabled and no longer a\ufb00ect permissions. All objects written to the bucket by any \naccount will be owned by the bucket owner.\n\u2022Directory buckets - For directory buckets, you must make requests for this API operation \nto the Zonal endpoint.", "These endpoints support virtual-hosted-style requests in the \nformat https:// bucket_name .s3express- az_id.region.amazonaws.com/ key-\nname .", "Path-style requests are not supported.", "For more information, see Regional and \nZonal endpoints in the Amazon S3 User Guide .\nAmazon S3 is a distributed system.", "If it receives multiple write requests for the same object \nsimultaneously, it overwrites all but the last object written.", "However, Amazon S3 provides features \nthat can modify this behavior:\n\u2022S3 Object Lock - To prevent objects from being deleted or overwritten, you can use Amazon S3 \nObject Lock in the Amazon S3 User Guide .\nNote\nThis functionality is not supported for directory buckets.\n\u2022S3 Versioning - When you enable versioning for a bucket, if Amazon S3 receives multiple write \nrequests for the same object simultaneously, it stores all versions of the objects. For each write \nrequest that is made to the same object, Amazon S3 automatically generates a unique version \nID of that object being stored in Amazon S3.", "You can retrieve, replace, or delete any version of \nthe object.", "For more information about versioning, see Adding Objects to Versioning-Enabled \nAmazon S3 API Version 2006-03-01 624Amazon Simple Storage Service API Reference\nBuckets in the Amazon S3 User Guide . For information about returning the versioning state of a \nbucket, see GetBucketVersioning.\nNote\nThis functionality is not supported for directory buckets.\nPermissions\n\u2022General purpose bucket permissions - The following permissions are required in your \npolicies when your PutObject  request includes speci\ufb01c headers.\n\u2022s3:PutObject   - To successfully complete the PutObject  request, you must always have \nthe s3:PutObject  permission on a bucket to add an object to it.\n\u2022s3:PutObjectAcl   - To successfully change the objects ACL of your PutObject  request, \nyou must have the s3:PutObjectAcl .\n\u2022s3:PutObjectTagging   - To successfully set the tag-set with your PutObject  request, \nyou must have the s3:PutObjectTagging .\n\u2022Directory bucket permissions - To grant access to this API operation on a directory \nbucket, we recommend that you use the CreateSession  API operation for session-based \nauthorization. Speci\ufb01cally, you grant the s3express:CreateSession  permission to the \ndirectory bucket in a bucket policy or an IAM identity-based policy.", "Then, you make the\nCreateSession  API call on the bucket to obtain a session token. With the session token in \nyour request header, you can make API requests to this operation. After the session token \nexpires, you make another CreateSession  API call to generate a new session token for \nuse. AWS CLI or SDKs create session and refresh the session token automatically to avoid \nservice interruptions when a session expires.", "For more information about authorization, see\nCreateSession .\nIf the object is encrypted with SSE-KMS, you must also have the kms:GenerateDataKey  and\nkms:Decrypt  permissions in IAM identity-based policies and AWS KMS key policies for the \nAWS KMS key.\nData integrity with Content-MD5\n\u2022General purpose bucket - To ensure that data is not corrupted traversing the network, use \nthe Content-MD5  header.", "When you use this header, Amazon S3 checks the object against \nthe provided MD5 value and, if they do not match, Amazon S3 returns an error. Alternatively, \nAmazon S3 API Version 2006-03-01 625Amazon Simple Storage Service API Reference\nwhen the object's ETag is its MD5 digest, you can calculate the MD5 while putting the object \nto Amazon S3 and compare the returned ETag to the calculated MD5 value.\n\u2022Directory bucket - This functionality is not supported for directory buckets.\nHTTP Host header syntax\nDirectory buckets  - The HTTP Host header syntax is \nBucket_name .s3express- az_id.region.amazonaws.com .\nFor more information about related Amazon S3 APIs, see the following:\n\u2022CopyObject\n\u2022DeleteObject\nRequest Syntax\nPUT /Key+ HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-acl: ACL\nCache-Control: CacheControl\nContent-Disposition: ContentDisposition\nContent-Encoding: ContentEncoding\nContent-Language: ContentLanguage\nContent-Length: ContentLength\nContent-MD5: ContentMD5\nContent-Type: ContentType\nx-amz-sdk-checksum-algorithm: ChecksumAlgorithm\nx-amz-checksum-crc32: ChecksumCRC32\nx-amz-checksum-crc32c: ChecksumCRC32C\nx-amz-checksum-sha1: ChecksumSHA1\nx-amz-checksum-sha256: ChecksumSHA256\nExpires: Expires\nIf-None-Match: IfNoneMatch\nx-amz-grant-full-control: GrantFullControl\nx-amz-grant-read: GrantRead\nx-amz-grant-read-acp: GrantReadACP\nx-amz-grant-write-acp: GrantWriteACP\nx-amz-server-side-encryption: ServerSideEncryption\nx-amz-storage-class: StorageClass\nx-amz-website-redirect-location: WebsiteRedirectLocation\nx-amz-server-side-encryption-customer-algorithm: SSECustomerAlgorithm\nAmazon S3 API Version 2006-03-01 626Amazon Simple Storage Service API Reference\nx-amz-server-side-encryption-customer-key: SSECustomerKey\nx-amz-server-side-encryption-customer-key-MD5: SSECustomerKeyMD5\nx-amz-server-side-encryption-aws-kms-key-id: SSEKMSKeyId\nx-amz-server-side-encryption-context: SSEKMSEncryptionContext\nx-amz-server-side-encryption-bucket-key-enabled: BucketKeyEnabled\nx-amz-request-payer: RequestPayer\nx-amz-tagging: Tagging\nx-amz-object-lock-mode: ObjectLockMode\nx-amz-object-lock-retain-until-date: ObjectLockRetainUntilDate\nx-amz-object-lock-legal-hold: ObjectLockLegalHoldStatus\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nBody\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe bucket name to which the PUT action was initiated.\nDirectory buckets - When you use this operation with a directory \nbucket, you must use virtual-hosted-style requests in the format \nBucket_name .s3express- az_id.region.amazonaws.com .", "Path-style requests are not \nsupported.", "Directory bucket names must be unique in the chosen Availability Zone.", "Bucket \nnames must follow the format  bucket_base_name --az-id--x-s3  (for example,  DOC-\nEXAMPLE-BUCKET --usw2-az1 --x-s3). For information about bucket naming restrictions, see\nDirectory bucket naming rules in the Amazon S3 User Guide .\nAccess points - When you use this action with an access point, you must provide the alias of the \naccess point in place of the bucket name or specify the access point ARN.", "When using the access \npoint ARN, you must direct requests to the access point hostname.", "The access point hostname \ntakes the form AccessPointName-AccountId .s3-accesspoint.Region.amazonaws.com.", "When using \nthis action with an access point through the AWS SDKs, you provide the access point ARN in \nplace of the bucket name. For more information about access point ARNs, see Using access \npoints  in the Amazon S3 User Guide .\nNote\nAccess points and Object Lambda access points are not supported by directory buckets.\nAmazon S3 API Version 2006-03-01 627Amazon Simple Storage Service API Reference\nS3 on Outposts  - When you use this action with Amazon S3 on Outposts, you must direct \nrequests to the S3 on Outposts hostname. The S3 on Outposts hostname takes the form \nAccessPointName -AccountId .outpostID .s3-outposts.", "Region.amazonaws.com .", "\nWhen you use this action with S3 on Outposts through the AWS SDKs, you provide the Outposts \naccess point ARN in place of the bucket name. For more information about S3 on Outposts \nARNs, see What is S3 on Outposts?", "in the Amazon S3 User Guide .\nRequired: Yes\nCache-Control\nCan be used to specify caching behavior along the request/reply chain.", "For more information, \nsee http://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html#sec14.9.\nContent-Disposition\nSpeci\ufb01es presentational information for the object. For more information, see https://www.rfc-\neditor.org/rfc/rfc6266#section-4.\nContent-Encoding\nSpeci\ufb01es what content encodings have been applied to the object and thus what decoding \nmechanisms must be applied to obtain the media-type referenced by the Content-Type header \n\ufb01eld. For more information, see https://www.rfc-editor.org/rfc/rfc9110.html#\ufb01eld.content-\nencoding.\nContent-Language\nThe language the content is in.\nContent-Length\nSize of the body in bytes.", "This parameter is useful when the size of the body cannot be \ndetermined automatically.", "For more information, see https://www.rfc-editor.org/rfc/ \nrfc9110.html#name-content-length.\nContent-MD5\nThe base64-encoded 128-bit MD5 digest of the message (without the headers) according to \nRFC 1864. This header can be used as a message integrity check to verify that the data is the \nsame data that was originally sent.", "Although it is optional, we recommend using the Content-\nMD5 mechanism as an end-to-end integrity check.", "For more information about REST request \nauthentication, see REST Authentication .\nAmazon S3 API Version 2006-03-01 628Amazon Simple Storage Service API Reference\nNote\nThe Content-MD5  or x-amz-sdk-checksum-algorithm  header is required for any \nrequest to upload an object with a retention period con\ufb01gured using Amazon S3 Object \nLock. For more information, see Uploading objects to an Object Lock enabled bucket  in \nthe Amazon S3 User Guide .\nNote\nThis functionality is not supported for directory buckets.\nContent-Type\nA standard MIME type describing the format of the contents.", "For more information, see https:// \nwww.rfc-editor.org/rfc/rfc9110.html#name-content-type.\nExpires\nThe date and time at which the object is no longer cacheable. For more information, see\nhttps://www.rfc-editor.org/rfc/rfc7234#section-5.3.\nIf-None-Match\nUploads the object only if the object key name does not already exist in the bucket speci\ufb01ed.", "\nOtherwise, Amazon S3 returns a 412 Precondition Failed  error.\nIf a con\ufb02icting operation occurs during the upload S3 returns a 409 \nConditionalRequestConflict  response. On a 409 failure you should retry the upload.\nExpects the '*' (asterisk) character.\nFor more information about conditional requests, see RFC 7232, or Conditional requests in the\nAmazon S3 User Guide .\nKey\nObject key for which the PUT action was initiated.\nLength Constraints: Minimum length of 1.\nRequired: Yes\nAmazon S3 API Version 2006-03-01 629Amazon Simple Storage Service API Reference\nx-amz-acl\nThe canned ACL to apply to the object. For more information, see Canned ACL in the Amazon S3 \nUser Guide .\nWhen adding a new object, you can use headers to grant ACL-based permissions to individual \nAWS accounts or to prede\ufb01ned groups de\ufb01ned by Amazon S3.", "These permissions are then \nadded to the ACL on the object.", "By default, all objects are private.", "Only the owner has full \naccess control.", "For more information, see Access Control List (ACL) Overview and Managing \nACLs Using the REST API in the Amazon S3 User Guide .\nIf the bucket that you're uploading objects to uses the bucket owner enforced setting for \nS3 Object Ownership, ACLs are disabled and no longer a\ufb00ect permissions.", "Buckets that use \nthis setting only accept PUT requests that don't specify an ACL or PUT requests that specify \nbucket owner full control ACLs, such as the bucket-owner-full-control  canned ACL or an \nequivalent form of this ACL expressed in the XML format.", "PUT requests that contain other ACLs \n(for example, custom grants to certain AWS accounts) fail and return a 400 error with the error \ncode AccessControlListNotSupported .", "For more information, see  Controlling ownership \nof objects and disabling ACLs in the Amazon S3 User Guide .\nNote\n\u2022This functionality is not supported for directory buckets.\n\u2022This functionality is not supported for Amazon S3 on Outposts.\nValid Values: private | public-read | public-read-write | authenticated-read \n| aws-exec-read | bucket-owner-read | bucket-owner-full-control\nx-amz-checksum-crc32\nThis header can be used as a data integrity check to verify that the data received is the same \ndata that was originally sent.", "This header speci\ufb01es the base64-encoded, 32-bit CRC-32 \nchecksum of the object.", "For more information, see Checking object integrity in the Amazon S3 \nUser Guide .\nx-amz-checksum-crc32c\nThis header can be used as a data integrity check to verify that the data received is the same \ndata that was originally sent. This header speci\ufb01es the base64-encoded, 32-bit CRC-32C \nAmazon S3 API Version 2006-03-01 630Amazon Simple Storage Service API Reference\nchecksum of the object. For more information, see Checking object integrity in the Amazon S3 \nUser Guide .\nx-amz-checksum-sha1\nThis header can be used as a data integrity check to verify that the data received is the same \ndata that was originally sent.", "This header speci\ufb01es the base64-encoded, 160-bit SHA-1 digest \nof the object.", "For more information, see Checking object integrity in the Amazon S3 User Guide .\nx-amz-checksum-sha256\nThis header can be used as a data integrity check to verify that the data received is the same \ndata that was originally sent.", "This header speci\ufb01es the base64-encoded, 256-bit SHA-256 digest \nof the object.", "For more information, see Checking object integrity in the Amazon S3 User Guide .\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match \nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nx-amz-grant-full-control\nGives the grantee READ, READ_ACP, and WRITE_ACP permissions on the object.\nNote\n\u2022This functionality is not supported for directory buckets.\n\u2022This functionality is not supported for Amazon S3 on Outposts.\nx-amz-grant-read\nAllows grantee to read the object data and its metadata.\nNote\n\u2022This functionality is not supported for directory buckets.\n\u2022This functionality is not supported for Amazon S3 on Outposts.\nAmazon S3 API Version 2006-03-01 631Amazon Simple Storage Service API Reference\nx-amz-grant-read-acp\nAllows grantee to read the object ACL.\nNote\n\u2022This functionality is not supported for directory buckets.\n\u2022This functionality is not supported for Amazon S3 on Outposts.\nx-amz-grant-write-acp\nAllows grantee to write the ACL for the applicable object.\nNote\n\u2022This functionality is not supported for directory buckets.\n\u2022This functionality is not supported for Amazon S3 on Outposts.\nx-amz-object-lock-legal-hold\nSpeci\ufb01es whether a legal hold will be applied to this object. For more information about S3 \nObject Lock, see Object Lock in the Amazon S3 User Guide .\nNote\nThis functionality is not supported for directory buckets.\nValid Values: ON | OFF\nx-amz-object-lock-mode\nThe Object Lock mode that you want to apply to this object.\nNote\nThis functionality is not supported for directory buckets.\nAmazon S3 API Version 2006-03-01 632Amazon Simple Storage Service API Reference\nValid Values: GOVERNANCE | COMPLIANCE\nx-amz-object-lock-retain-until-date\nThe date and time when you want this object's Object Lock to expire.", "Must be formatted as a \ntimestamp parameter.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-request-payer\nCon\ufb01rms that the requester knows that they will be charged for the request. Bucket owners \nneed not specify this parameter in their requests.", "If either the source or destination S3 \nbucket has Requester Pays enabled, the requester will pay for corresponding charges to copy \nthe object. For information about downloading objects from Requester Pays buckets, see\nDownloading Objects in Requester Pays Buckets in the Amazon S3 User Guide .\nNote\nThis functionality is not supported for directory buckets.\nValid Values: requester\nx-amz-sdk-checksum-algorithm\nIndicates the algorithm used to create the checksum for the object when you use the SDK.", "\nThis header will not provide any additional functionality if you don't use the SDK.", "When you \nsend this header, there must be a corresponding x-amz-checksum- algorithm   or x-amz-\ntrailer header sent.", "Otherwise, Amazon S3 fails the request with the HTTP status code 400 \nBad Request .\nFor the x-amz-checksum- algorithm   header, replace  algorithm   with the supported \nalgorithm from the following list:\n\u2022CRC32\n\u2022CRC32C\n\u2022SHA1\nAmazon S3 API Version 2006-03-01 633Amazon Simple Storage Service API Reference\n\u2022SHA256\nFor more information, see Checking object integrity in the Amazon S3 User Guide .\nIf the individual checksum value you provide through x-amz-checksum- algorithm   doesn't \nmatch the checksum algorithm you set through x-amz-sdk-checksum-algorithm , Amazon \nS3 ignores any provided ChecksumAlgorithm  parameter and uses the checksum algorithm \nthat matches the provided value in x-amz-checksum- algorithm  .\nNote\nThe Content-MD5  or x-amz-sdk-checksum-algorithm  header is required for any \nrequest to upload an object with a retention period con\ufb01gured using Amazon S3 Object \nLock. For more information, see Uploading objects to an Object Lock enabled bucket  in \nthe Amazon S3 User Guide .\nFor directory buckets, when you use AWS SDKs, CRC32 is the default checksum algorithm that's \nused for performance.\nValid Values: CRC32 | CRC32C | SHA1 | SHA256\nx-amz-server-side-encryption\nThe server-side encryption algorithm that was used when you store this object in Amazon S3 \n(for example, AES256 , aws:kms , aws:kms:dsse ).\n\u2022General purpose buckets  - You have four mutually exclusive options to protect data \nusing server-side encryption in Amazon S3, depending on how you choose to manage the \nencryption keys. Speci\ufb01cally, the encryption key options are Amazon S3 managed keys (SSE-\nS3), AWS KMS keys (SSE-KMS or DSSE-KMS), and customer-provided keys (SSE-C). Amazon \nS3 encrypts data with server-side encryption by using Amazon S3 managed keys (SSE-S3) \nby default. You can optionally tell Amazon S3 to encrypt data at rest by using server-side \nencryption with other key options. For more information, see Using Server-Side Encryption in \nthe Amazon S3 User Guide .\n\u2022Directory buckets  - For directory buckets, there are only two supported options for server-\nside encryption: server-side encryption with Amazon S3 managed keys (SSE-S3) (AES256 ) \nand server-side encryption with AWS KMS keys (SSE-KMS) (aws:kms). We recommend that \nthe bucket's default encryption uses the desired encryption con\ufb01guration and you don't \noverride the bucket default encryption in your CreateSession  requests or PUT object \nAmazon S3 API Version 2006-03-01 634Amazon Simple Storage Service API Reference\nrequests.", "Then, new objects are automatically encrypted with the desired encryption settings.", "\nFor more information, see Protecting data with server-side encryption in the Amazon S3 User \nGuide .", "For more information about the encryption overriding behaviors in directory buckets, \nsee Specifying server-side encryption with AWS KMS for new object uploads.\nIn the Zonal endpoint API calls (except CopyObject and UploadPartCopy) using the REST API, \nthe encryption request headers must match the encryption settings that are speci\ufb01ed in the\nCreateSession  request. You can't override the values of the encryption settings (x-amz-\nserver-side-encryption , x-amz-server-side-encryption-aws-kms-key-id , x-\namz-server-side-encryption-context , and x-amz-server-side-encryption-\nbucket-key-enabled ) that are speci\ufb01ed in the CreateSession  request. You don't need \nto explicitly specify these encryption settings values in Zonal endpoint API calls, and Amazon \nS3 will use the encryption settings values from the CreateSession  request to protect new \nobjects in the directory bucket.\nNote\nWhen you use the CLI or the AWS SDKs, for CreateSession , the session token \nrefreshes automatically to avoid service interruptions when a session expires. The \nCLI or the AWS SDKs use the bucket's default encryption con\ufb01guration for the\nCreateSession  request. It's not supported to override the encryption settings \nvalues in the CreateSession  request.", "So in the Zonal endpoint API calls (except\nCopyObject and UploadPartCopy), the encryption request headers must match the \ndefault encryption con\ufb01guration of the directory bucket.\nValid Values: AES256 | aws:kms | aws:kms:dsse\nx-amz-server-side-encryption-aws-kms-key-id\nSpeci\ufb01es the AWS KMS key ID (Key ID, Key ARN, or Key Alias) to use for object encryption. If the \nKMS key doesn't exist in the same account that's issuing the command, you must use the full \nKey ARN not the Key ID.\nGeneral purpose buckets - If you specify x-amz-server-side-encryption  with aws:kms\nor aws:kms:dsse , this header speci\ufb01es the ID (Key ID, Key ARN, or Key Alias) of the AWS KMS \nkey to use. If you specify x-amz-server-side-encryption:aws:kms  or x-amz-server-\nside-encryption:aws:kms:dsse , but do not provide x-amz-server-side-encryption-\naws-kms-key-id , Amazon S3 uses the AWS managed key (aws/s3) to protect the data.\nAmazon S3 API Version 2006-03-01 635Amazon Simple Storage Service API Reference\nDirectory buckets - If you specify x-amz-server-side-encryption  with aws:kms , the \nx-amz-server-side-encryption-aws-kms-key-id  header is implicitly assigned the \nID of the AWS KMS symmetric encryption customer managed key that's con\ufb01gured for your \ndirectory bucket's default encryption setting. If you want to specify the  x-amz-server-\nside-encryption-aws-kms-key-id  header explicitly, you can only specify it with the ID \n(Key ID or Key ARN) of the AWS KMS customer managed key that's con\ufb01gured for your directory \nbucket's default encryption setting.", "Otherwise, you get an HTTP 400 Bad Request  error.", "Only \nuse the key ID or key ARN.", "The key alias format of the KMS key isn't supported.", "Your SSE-KMS \ncon\ufb01guration can only support 1 customer managed key per directory bucket for the lifetime of \nthe bucket.", "The AWS managed key (aws/s3) isn't supported.\nx-amz-server-side-encryption-bucket-key-enabled\nSpeci\ufb01es whether Amazon S3 should use an S3 Bucket Key for object encryption with server-\nside encryption using AWS Key Management Service (AWS KMS) keys (SSE-KMS).\nGeneral purpose buckets - Setting this header to true causes Amazon S3 to use an S3 Bucket \nKey for object encryption with SSE-KMS. Also, specifying this header with a PUT action doesn't \na\ufb00ect bucket-level settings for S3 Bucket Key.\nDirectory buckets - S3 Bucket Keys are always enabled for GET and PUT operations in a \ndirectory bucket and can\u2019t be disabled. S3 Bucket Keys aren't supported, when you copy SSE-\nKMS encrypted objects from general purpose buckets to directory buckets, from directory \nbuckets to general purpose buckets, or between directory buckets, through CopyObject,\nUploadPartCopy, the Copy operation in Batch Operations, or the import jobs. In this case, \nAmazon S3 makes a call to AWS KMS every time a copy request is made for a KMS-encrypted \nobject.\nx-amz-server-side-encryption-context\nSpeci\ufb01es the AWS KMS Encryption Context as an additional encryption context to use for \nobject encryption.", "The value of this header is a Base64-encoded string of a UTF-8 encoded \nJSON, which contains the encryption context as key-value pairs.", "This value is stored as object \nmetadata and automatically gets passed on to AWS KMS for future GetObject  operations on \nthis object.\nGeneral purpose buckets - This value must be explicitly added during CopyObject  operations \nif you want an additional encryption context for your object.", "For more information, see\nEncryption context in the Amazon S3 User Guide .\nAmazon S3 API Version 2006-03-01 636Amazon Simple Storage Service API Reference\nDirectory buckets - You can optionally provide an explicit encryption context value. The value \nmust match the default encryption context - the bucket Amazon Resource Name (ARN).", "An \nadditional encryption context value is not supported.\nx-amz-server-side-encryption-customer-algorithm\nSpeci\ufb01es the algorithm to use when encrypting the object (for example, AES256 ).\nNote\nThis functionality is not supported for directory buckets.\nx-amz-server-side-encryption-customer-key\nSpeci\ufb01es the customer-provided encryption key for Amazon S3 to use in encrypting data. \nThis value is used to store the object and then it is discarded; Amazon S3 does not store the \nencryption key.", "The key must be appropriate for use with the algorithm speci\ufb01ed in the x-amz-\nserver-side-encryption-customer-algorithm  header.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-server-side-encryption-customer-key-MD5\nSpeci\ufb01es the 128-bit MD5 digest of the encryption key according to RFC 1321.", "Amazon S3 uses \nthis header for a message integrity check to ensure that the encryption key was transmitted \nwithout error.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-storage-class\nBy default, Amazon S3 uses the STANDARD Storage Class to store newly created objects.", "\nThe STANDARD storage class provides high durability and high availability.", "Depending on \nAmazon S3 API Version 2006-03-01 637Amazon Simple Storage Service API Reference\nperformance needs, you can specify a di\ufb00erent Storage Class. For more information, see\nStorage Classes  in the Amazon S3 User Guide .\nNote\n\u2022For directory buckets, only the S3 Express One Zone storage class is supported to \nstore newly created objects.\n\u2022Amazon S3 on Outposts only uses the OUTPOSTS Storage Class.\nValid Values: STANDARD | REDUCED_REDUNDANCY | STANDARD_IA | ONEZONE_IA | \nINTELLIGENT_TIERING | GLACIER | DEEP_ARCHIVE | OUTPOSTS | GLACIER_IR | \nSNOW | EXPRESS_ONEZONE\nx-amz-tagging\nThe tag-set for the object.", "The tag-set must be encoded as URL Query parameters.", "(For \nexample, \"Key1=Value1\")\nNote\nThis functionality is not supported for directory buckets.\nx-amz-website-redirect-location\nIf the bucket is con\ufb01gured as a website, redirects requests for this object to another object in \nthe same bucket or to an external URL.", "Amazon S3 stores the value of this header in the object \nmetadata. For information about object metadata, see Object Key and Metadata in the Amazon \nS3 User Guide .\nIn the following example, the request header sets the redirect to an object (anotherPage.html) \nin the same bucket:\nx-amz-website-redirect-location: /anotherPage.html\nIn the following example, the request header sets the object redirect to another website:\nx-amz-website-redirect-location: http://www.example.com/\nAmazon S3 API Version 2006-03-01 638Amazon Simple Storage Service API Reference\nFor more information about website hosting in Amazon S3, see Hosting Websites on Amazon S3\nand How to Con\ufb01gure Website Page Redirects in the Amazon S3 User Guide .\nNote\nThis functionality is not supported for directory buckets.\nRequest Body\nThe request accepts the following binary data.\nBody\nResponse Syntax\nHTTP/1.1 200\nx-amz-expiration: Expiration\nETag: ETag\nx-amz-checksum-crc32: ChecksumCRC32\nx-amz-checksum-crc32c: ChecksumCRC32C\nx-amz-checksum-sha1: ChecksumSHA1\nx-amz-checksum-sha256: ChecksumSHA256\nx-amz-server-side-encryption: ServerSideEncryption\nx-amz-version-id: VersionId\nx-amz-server-side-encryption-customer-algorithm: SSECustomerAlgorithm\nx-amz-server-side-encryption-customer-key-MD5: SSECustomerKeyMD5\nx-amz-server-side-encryption-aws-kms-key-id: SSEKMSKeyId\nx-amz-server-side-encryption-context: SSEKMSEncryptionContext\nx-amz-server-side-encryption-bucket-key-enabled: BucketKeyEnabled\nx-amz-request-charged: RequestCharged\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe response returns the following HTTP headers.\nETag\nEntity tag for the uploaded object.\nAmazon S3 API Version 2006-03-01 639Amazon Simple Storage Service API Reference\nGeneral purpose buckets  - To ensure that data is not corrupted traversing the network, for \nobjects where the ETag is the MD5 digest of the object, you can calculate the MD5 while putting \nan object to Amazon S3 and compare the returned ETag to the calculated MD5 value.\nDirectory buckets  - The ETag for the object in a directory bucket isn't the MD5 digest of the \nobject.\nx-amz-checksum-crc32\nThe base64-encoded, 32-bit CRC-32 checksum of the object.", "This will only be present if it was \nuploaded with the object. When you use an API operation on an object that was uploaded using \nmultipart uploads, this value may not be a direct checksum value of the full object. Instead, \nit's a calculation based on the checksum values of each individual part.", "For more information \nabout how checksums are calculated with multipart uploads, see  Checking object integrity in \nthe Amazon S3 User Guide .\nx-amz-checksum-crc32c\nThe base64-encoded, 32-bit CRC-32C checksum of the object.", "This will only be present if it was \nuploaded with the object. When you use an API operation on an object that was uploaded using \nmultipart uploads, this value may not be a direct checksum value of the full object. Instead, \nit's a calculation based on the checksum values of each individual part.", "For more information \nabout how checksums are calculated with multipart uploads, see  Checking object integrity in \nthe Amazon S3 User Guide .\nx-amz-checksum-sha1\nThe base64-encoded, 160-bit SHA-1 digest of the object.", "This will only be present if it was \nuploaded with the object. When you use the API operation on an object that was uploaded \nusing multipart uploads, this value may not be a direct checksum value of the full object.", "\nInstead, it's a calculation based on the checksum values of each individual part.", "For more \ninformation about how checksums are calculated with multipart uploads, see  Checking object \nintegrity in the Amazon S3 User Guide .\nx-amz-checksum-sha256\nThe base64-encoded, 256-bit SHA-256 digest of the object.", "This will only be present if it was \nuploaded with the object. When you use an API operation on an object that was uploaded using \nmultipart uploads, this value may not be a direct checksum value of the full object. Instead, \nit's a calculation based on the checksum values of each individual part.", "For more information \nabout how checksums are calculated with multipart uploads, see  Checking object integrity in \nthe Amazon S3 User Guide .\nAmazon S3 API Version 2006-03-01 640Amazon Simple Storage Service API Reference\nx-amz-expiration\nIf the expiration is con\ufb01gured for the object (see PutBucketLifecycleCon\ufb01guration) in the\nAmazon S3 User Guide , the response includes this header.", "It includes the expiry-date  and\nrule-id key-value pairs that provide information about object expiration.", "The value of the\nrule-id is URL-encoded.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-request-charged\nIf present, indicates that the requester was successfully charged for the request.\nNote\nThis functionality is not supported for directory buckets.\nValid Values: requester\nx-amz-server-side-encryption\nThe server-side encryption algorithm used when you store this object in Amazon S3.\nValid Values: AES256 | aws:kms | aws:kms:dsse\nx-amz-server-side-encryption-aws-kms-key-id\nIf present, indicates the ID of the KMS key that was used for object encryption.\nx-amz-server-side-encryption-bucket-key-enabled\nIndicates whether the uploaded object uses an S3 Bucket Key for server-side encryption with \nAWS Key Management Service (AWS KMS) keys (SSE-KMS).\nx-amz-server-side-encryption-context\nIf present, indicates the AWS KMS Encryption Context to use for object encryption. The value \nof this header is a Base64-encoded string of a UTF-8 encoded JSON, which contains the \nAmazon S3 API Version 2006-03-01 641Amazon Simple Storage Service API Reference\nencryption context as key-value pairs. This value is stored as object metadata and automatically \ngets passed on to AWS KMS for future GetObject  operations on this object.\nx-amz-server-side-encryption-customer-algorithm\nIf server-side encryption with a customer-provided encryption key was requested, the response \nwill include this header to con\ufb01rm the encryption algorithm that's used.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-server-side-encryption-customer-key-MD5\nIf server-side encryption with a customer-provided encryption key was requested, the \nresponse will include this header to provide the round-trip message integrity veri\ufb01cation of the \ncustomer-provided encryption key.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-version-id\nVersion ID of the object.\nIf you enable versioning for a bucket, Amazon S3 automatically generates a unique version \nID for the object being stored.", "Amazon S3 returns this ID in the response. When you enable \nversioning for a bucket, if Amazon S3 receives multiple write requests for the same object \nsimultaneously, it stores all of the objects. For more information about versioning, see Adding \nObjects to Versioning-Enabled Buckets in the Amazon S3 User Guide . For information about \nreturning the versioning state of a bucket, see GetBucketVersioning.\nNote\nThis functionality is not supported for directory buckets.\nAmazon S3 API Version 2006-03-01 642Amazon Simple Storage Service API Reference\nExamples\nExample 1 for general purpose buckets: Upload an object\nThe following request stores the my-image.jpg  \ufb01le in the myBucket  bucket.\nPUT /my-image.jpg HTTP/1.1\nHost: myBucket.s3.<Region>.amazonaws.com\nDate: Wed, 12 Oct 2009 17:50:00 GMT\nAuthorization: authorization string\nContent-Type: text/plain\nContent-Length: 11434\nx-amz-meta-author: Janet\nExpect: 100-continue\n[11434 bytes of object data] \n          \nSample Response for general purpose buckets: Versioning suspended\nThis example illustrates one usage of PutObject.\nHTTP/1.1 100 Continue\nHTTP/1.1 200 OK\nx-amz-id-2: LriYPLdmOdAiIfgSm/F1YsViT1LW94/xUQxMsF7xiEb1a0wiIOIxl+zbwZ163pt7\nx-amz-request-id: 0A49CE4060975EAC\nDate: Wed, 12 Oct 2009 17:50:00 GMT\nETag: \"1b2cf535f27731c974343645a3985328\"\nContent-Length: 0\nConnection: close\nServer: AmazonS3 \n          \nSample Response for general purpose buckets: Expiration rule created using lifecycle \ncon\ufb01guration\nIf an expiration rule that was created on the bucket using lifecycle con\ufb01guration applies to \nthe object, you get a response with an x-amz-expiration  header, as shown in the following \nresponse. For more information, see Transitioning Objects: General Considerations.\nAmazon S3 API Version 2006-03-01 643Amazon Simple Storage Service API Reference\nHTTP/1.1 100 Continue\nHTTP/1.1 200 OK\nx-amz-id-2: LriYPLdmOdAiIfgSm/F1YsViT1LW94/xUQxMsF7xiEb1a0wiIOIxl+zbwZ163pt7\nx-amz-request-id: 0A49CE4060975EAC\nDate: Wed, 12 Oct 2009 17:50:00 GMT\nx-amz-expiration: expiry-date=\"Fri, 23 Dec 2012 00:00:00 GMT\", rule-id=\"1\"\nETag: \"1b2cf535f27731c974343645a3985328\"\nContent-Length: 0\nConnection: close\nServer: AmazonS3 \n          \nSample Response for general purpose buckets: Versioning enabled\nIf the bucket has versioning enabled, the response includes the x-amz-version-id  header.\nHTTP/1.1 100 Continue\nHTTP/1.1 200 OK\nx-amz-id-2: LriYPLdmOdAiIfgSm/F1YsViT1LW94/xUQxMsF7xiEb1a0wiIOIxl+zbwZ163pt7\nx-amz-request-id: 0A49CE4060975EAC\nx-amz-version-id: 43jfkodU8493jnFJD9fjj3HHNVfdsQUIFDNsidf038jfdsjGFDSIRp\nDate: Wed, 12 Oct 2009 17:50:00 GMT\nETag: \"fbacf535f27731c9771645a39863328\"\nContent-Length: 0\nConnection: close\nServer: AmazonS3 \n          \nExample 2 for general purpose buckets: Specifying the Reduced Redundancy Storage Class\nThe following request stores the image, my-image.jpg , in the myBucket  bucket. The request \nspeci\ufb01es the x-amz-storage-class  header to request that the object is stored using the \nREDUCED_REDUNDANCY storage class.\nPUT /my-image.jpg HTTP/1.1\nHost: myBucket.s3.<Region>.amazonaws.com\nAmazon S3 API Version 2006-03-01 644Amazon Simple Storage Service API Reference\nDate: Wed, 12 Oct 2009 17:50:00 GMT\nAuthorization: authorization string\nContent-Type: image/jpeg\nContent-Length: 11434\nExpect: 100-continue\nx-amz-storage-class: REDUCED_REDUNDANCY \n          \nSample Response for general purpose buckets\nThis example illustrates one usage of PutObject.\nHTTP/1.1 100 Continue\nHTTP/1.1 200 OK\nx-amz-id-2: LriYPLdmOdAiIfgSm/F1YsViT1LW94/xUQxMsF7xiEb1a0wiIOIxl+zbwZ163pt7\nx-amz-request-id: 0A49CE4060975EAC\nDate: Wed, 12 Oct 2009 17:50:00 GMT\nETag: \"1b2cf535f27731c974343645a3985328\"\nContent-Length: 0\nConnection: close\nServer: AmazonS3 \n          \nExample 3 for general purpose buckets: Uploading an object and specifying access permissions \nexplicitly\nThe following request stores the TestObject.txt  \ufb01le in the myBucket  bucket. The request \nspeci\ufb01es various ACL headers to grant permission to AWS accounts that are speci\ufb01ed with a \ncanonical user ID and an email address.\nPUT TestObject.txt HTTP/1.1\nHost: myBucket.s3.<Region>.amazonaws.com\nx-amz-date: Fri, 13 Apr 2012 05:40:14 GMT\nAuthorization: authorization string\nx-amz-grant-write-acp: id=8a6925ce4adf588a4532142d3f74dd8c71fa124ExampleCanonicalUserID\nx-amz-grant-full-control: emailAddress=\"ExampleUser@amazon.com\"\nx-amz-grant-write: emailAddress=\"ExampleUser1@amazon.com\", \n emailAddress=\"ExampleUser2@amazon.com\"\nContent-Length: 300\nAmazon S3 API Version 2006-03-01 645Amazon Simple Storage Service API Reference\nExpect: 100-continue\nConnection: Keep-Alive\n...Object data in the body... \n          \nSample Response for general purpose buckets\nThis example illustrates one usage of PutObject.\nHTTP/1.1 200 OK\nx-amz-id-2: RUxG2sZJUfS+ezeAS2i0Xj6w/ST6xqF/8pFNHjTjTrECW56SCAUWGg+7QLVoj1GH\nx-amz-request-id: 8D017A90827290BA\nDate: Fri, 13 Apr 2012 05:40:25 GMT\nETag: \"dd038b344cf9553547f8b395a814b274\"\nContent-Length: 0\nServer: AmazonS3 \n          \nExample 4 for general purpose buckets: Using a canned ACL to set access permissions\nThe following request stores the TestObject.txt  \ufb01le in the myBucket bucket. The request uses \nan x-amz-acl  header to specify a canned ACL that grants READ permission to the public.\nPUT TestObject.txt HTTP/1.1\nHost: myBucket.s3.<Region>.amazonaws.com\nx-amz-date: Fri, 13 Apr 2012 05:54:57 GMT\nx-amz-acl: public-read\nAuthorization: authorization string\nContent-Length: 300\nExpect: 100-continue\nConnection: Keep-Alive\n...Object data in the body... \n          \nSample Response for general purpose buckets\nThis example illustrates one usage of PutObject.\nAmazon S3 API Version 2006-03-01 646Amazon Simple Storage Service API Reference\nHTTP/1.1 200 OK\nx-amz-id-2: Yd6PSJxJFQeTYJ/3dDO7miqJfVMXXW0S2Hijo3WFs4bz6oe2QCVXasxXLZdMfASd\nx-amz-request-id: 80DF413BB3D28A25\nDate: Fri, 13 Apr 2012 05:54:59 GMT\nETag: \"dd038b344cf9553547f8b395a814b274\"\nContent-Length: 0\nServer: AmazonS3 \n          \nExample 5 for general purpose buckets: Upload an object (Request server-side encryption using \na customer-provided encryption key)\nThis example of an upload object requests server-side encryption and provides an encryption key.\nPUT /example-object HTTP/1.1\nHost: example-bucket.s3.<Region>.amazonaws.com    \nAccept: */*    \nAuthorization:authorization string    \nDate: Wed, 28 May 2014 19:31:11 +0000    \nx-amz-server-side-encryption-customer-key:g0lCfA3Dv40jZz5SQJ1ZukLRFqtI5WorC/8SEEXAMPLE  \n   \nx-amz-server-side-encryption-customer-key-MD5:ZjQrne1X/iTcskbY2example    \nx-amz-server-side-encryption-customer-algorithm:AES256     \n          \nSample Response for general purpose buckets\nIn the response, Amazon S3 returns the encryption algorithm and MD5 of the encryption key that \nyou speci\ufb01ed when uploading the object. The ETag that is returned is not the MD5 of the object.\nHTTP/1.1 200 OK    \nx-amz-id-2: 7qoYGN7uMuFuYS6m7a4lszH6in+hccE+4DXPmDZ7C9KqucjnZC1gI5mshai6fbMG    \nx-amz-request-id: 06437EDD40C407C7    \nDate: Wed, 28 May 2014 19:31:12 GMT    \nx-amz-server-side-encryption-customer-algorithm: AES256    \nx-amz-server-side-encryption-customer-key-MD5: ZjQrne1X/iTcskbY2example    \nETag: \"ae89237c20e759c5f479ece02c642f59\"       \n          \nAmazon S3 API Version 2006-03-01 647Amazon Simple Storage Service API Reference\nExample 6 for general purpose buckets: Upload an object and specify tags\nThis example of an upload object request speci\ufb01es the optional x-amz-tagging  header to add \ntags to the object.\nAfter the object is created, Amazon S3 stores the speci\ufb01ed object tags in the tagging subresource \nthat is associated with the object. For more information about tagging, see Object Tagging and \nAccess Control Policies in the Amazon S3 User Guide .\nPUT /example-object HTTP/1.1\nHost: example-bucket.s3.<Region>.amazonaws.com    \nAccept: */*    \nAuthorization:authorization string    \nDate: Thu, 22 Sep 2016 21:58:13 GMT    \nx-amz-tagging: tag1=value1&tag2=value2\n[...", "bytes of object data]    \n          \nSample Response for general purpose buckets\nThis example illustrates one usage of PutObject.\nHTTP/1.1 200 OK    \nx-amz-id-2: 7qoYGN7uMuFuYS6m7a4lszH6in+hccE+4DXPmDZ7C9KqucjnZC1gI5mshai6fbMG    \nx-amz-request-id: 06437EDD40C407C7    \nDate: Thu, 22 Sep 2016 21:58:17 GMT    \n          \nExample 7 for general purpose buckets: Upload an object and specify the checksum algorithm\nThis example of an upload object request speci\ufb01es the additional checksum algorithm to use to \nverify the content of the object. For more information about using additional checksums, see \nChecking object integrity in the Amazon S3 User Guide .\nPUT /example-object HTTP/1.1\nHost: example-bucket.s3.<Region>.amazonaws.com\nx-amz-date: Mon, 22 Mar 2021 23:00:00 GMT\nAmazon S3 API Version 2006-03-01 648Amazon Simple Storage Service API Reference\nAuthorization: authorization string\nContent-Length: 268435456\nx-amz-checksum-sha256: 0ea4be78f6c3948588172edc6d8789ffe3cec461f385e0ac447e581731c429b5\n[268435456 bytes of object data in the body] \n          \nSample Response for general purpose buckets\nThis example illustrates one usage of PutObject.\nHTTP/1.1 200 OK\nx-amz-id-2: 7qoYGN7uMuFuYS6m7a4lszH6in+hccE+4DXPmDZ7C9KqucjnZC1gI5mshai6fbMG\nx-amz-request-id: 49CFA2051300FBE9\nDate: Mon, 22 Mar 2021 23:00:12 GMT \n          \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 649Amazon Simple Storage Service API Reference\nPutObjectAcl\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nUses the acl subresource to set the access control list (ACL) permissions for a new or existing \nobject in an S3 bucket.", "You must have the WRITE_ACP  permission to set the ACL of an object. For \nmore information, see What permissions can I grant?", "in the Amazon S3 User Guide .\nThis functionality is not supported for Amazon S3 on Outposts.\nDepending on your application needs, you can choose to set the ACL on an object using either the \nrequest body or the headers.", "For example, if you have an existing application that updates a bucket \nACL using the request body, you can continue to use that approach.", "For more information, see\nAccess Control List (ACL) Overview in the Amazon S3 User Guide .\nImportant\nIf your bucket uses the bucket owner enforced setting for S3 Object Ownership, ACLs \nare disabled and no longer a\ufb00ect permissions.", "You must use policies to grant access to \nyour bucket and the objects in it.", "Requests to set ACLs or update ACLs fail and return \nthe AccessControlListNotSupported  error code. Requests to read ACLs are still \nsupported.", "For more information, see Controlling object ownership in the Amazon S3 User \nGuide .\nPermissions\nYou can set access permissions using one of the following methods:\n\u2022Specify a canned ACL with the x-amz-acl  request header. Amazon S3 supports a set of \nprede\ufb01ned ACLs, known as canned ACLs.", "Each canned ACL has a prede\ufb01ned set of grantees \nand permissions. Specify the canned ACL name as the value of x-amz-ac l.", "If you use this \nheader, you cannot use other access control-speci\ufb01c headers in your request.", "For more \ninformation, see Canned ACL.\nAmazon S3 API Version 2006-03-01 650Amazon Simple Storage Service API Reference\n\u2022Specify access permissions explicitly with the x-amz-grant-read , x-amz-grant-read-\nacp, x-amz-grant-write-acp , and x-amz-grant-full-control  headers. When using \nthese headers, you specify explicit access permissions and grantees (AWS accounts or Amazon \nS3 groups) who will receive the permission.", "If you use these ACL-speci\ufb01c headers, you cannot \nuse x-amz-acl  header to set a canned ACL.", "These parameters map to the set of permissions \nthat Amazon S3 supports in an ACL.", "For more information, see Access Control List (ACL) \nOverview.\nYou specify each grantee as a type=value pair, where the type is one of the following:\n\u2022id \u2013 if the value speci\ufb01ed is the canonical user ID of an AWS account\n\u2022uri \u2013 if you are granting permissions to a prede\ufb01ned group\n\u2022emailAddress  \u2013 if the value speci\ufb01ed is the email address of an AWS account\nNote\nUsing email addresses to specify a grantee is only supported in the following AWS \nRegions:\n\u2022US East (N.", "Virginia)\n\u2022US West (N.", "California)\n\u2022US West (Oregon)\n\u2022Asia Paci\ufb01c (Singapore)\n\u2022Asia Paci\ufb01c (Sydney)\n\u2022Asia Paci\ufb01c (Tokyo)\n\u2022Europe (Ireland)\n\u2022South America (S\u00e3o Paulo)\nFor a list of all the Amazon S3 supported Regions and endpoints, see Regions and \nEndpoints  in the AWS General Reference.\nFor example, the following x-amz-grant-read  header grants list objects permission to the \ntwo AWS accounts identi\ufb01ed by their email addresses.\nx-amz-grant-read: emailAddress=\"xyz@amazon.com\", \nemailAddress=\"abc@amazon.com\"\nYou can use either a canned ACL or specify access permissions explicitly. You cannot do both.Amazon S3 API Version 2006-03-01 651Amazon Simple Storage Service API Reference\nGrantee Values\nYou can specify the person (grantee) to whom you're assigning access rights (using request \nelements) in the following ways:\n\u2022By the person's ID:\n<Grantee xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-\ninstance\" xsi:type=\"CanonicalUser\"><ID><>ID<></\nID><DisplayName><>GranteesEmail<></DisplayName> </Grantee>\nDisplayName is optional and ignored in the request.\n\u2022By URI:\n<Grantee xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" \nxsi:type=\"Group\"><URI><>http://acs.amazonaws.com/groups/global/\nAuthenticatedUsers<></URI></Grantee>\n\u2022By Email address:\n<Grantee xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" \nxsi:type=\"AmazonCustomerByEmail\"><EmailAddress><>Grantees@email.com<></\nEmailAddress>lt;/Grantee>\nThe grantee is resolved to the CanonicalUser and, in a response to a GET Object acl request, \nappears as the CanonicalUser.\nNote\nUsing email addresses to specify a grantee is only supported in the following AWS \nRegions:\n\u2022US East (N.", "Virginia)\n\u2022US West (N.", "California)\n\u2022US West (Oregon)\n\u2022Asia Paci\ufb01c (Singapore)\n\u2022Asia Paci\ufb01c (Sydney)\n\u2022Asia Paci\ufb01c (Tokyo)\n\u2022Europe (Ireland)\n\u2022South America (S\u00e3o Paulo)\nAmazon S3 API Version 2006-03-01 652Amazon Simple Storage Service API Reference\nFor a list of all the Amazon S3 supported Regions and endpoints, see Regions and \nEndpoints  in the AWS General Reference.\nVersioning\nThe ACL of an object is set at the object version level.", "By default, PUT sets the ACL of the \ncurrent version of an object.", "To set the ACL of a di\ufb00erent version, use the versionId\nsubresource.\nThe following operations are related to PutObjectAcl :\n\u2022CopyObject\n\u2022GetObject\nRequest Syntax\nPUT /{Key+}?acl&versionId= VersionId  HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-acl: ACL\nContent-MD5: ContentMD5\nx-amz-sdk-checksum-algorithm: ChecksumAlgorithm\nx-amz-grant-full-control: GrantFullControl\nx-amz-grant-read: GrantRead\nx-amz-grant-read-acp: GrantReadACP\nx-amz-grant-write: GrantWrite\nx-amz-grant-write-acp: GrantWriteACP\nx-amz-request-payer: RequestPayer\nx-amz-expected-bucket-owner: ExpectedBucketOwner\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<AccessControlPolicy  xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n   <AccessControlList > \n      <Grant> \n         < Grantee> \n            < DisplayName >string</DisplayName > \n            < EmailAddress >string</EmailAddress > \n            < ID>string</ID> \n            < xsi:type >string</xsi:type > \n            < URI>string</URI> \n         </ Grantee> \n         < Permission >string</Permission > \n      </Grant> \nAmazon S3 API Version 2006-03-01 653Amazon Simple Storage Service API Reference\n   </AccessControlList > \n   <Owner> \n      <DisplayName >string</DisplayName > \n      <ID>string</ID> \n   </Owner>\n</AccessControlPolicy >\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe bucket name that contains the object to which you want to attach the ACL.\nAccess points - When you use this action with an access point, you must provide the alias of the \naccess point in place of the bucket name or specify the access point ARN.", "When using the access \npoint ARN, you must direct requests to the access point hostname.", "The access point hostname \ntakes the form AccessPointName-AccountId .s3-accesspoint.Region.amazonaws.com.", "When using \nthis action with an access point through the AWS SDKs, you provide the access point ARN in \nplace of the bucket name.", "For more information about access point ARNs, see Using access \npoints  in the Amazon S3 User Guide .\nS3 on Outposts  - When you use this action with Amazon S3 on Outposts, you must direct \nrequests to the S3 on Outposts hostname. The S3 on Outposts hostname takes the form \nAccessPointName -AccountId .outpostID .s3-outposts.", "Region.amazonaws.com .", "\nWhen you use this action with S3 on Outposts through the AWS SDKs, you provide the Outposts \naccess point ARN in place of the bucket name. For more information about S3 on Outposts \nARNs, see What is S3 on Outposts?", "in the Amazon S3 User Guide .\nRequired: Yes\nContent-MD5\nThe base64-encoded 128-bit MD5 digest of the data.", "This header must be used as a message \nintegrity check to verify that the request body was not corrupted in transit.", "For more \ninformation, go to RFC 1864.>\nFor requests made using the AWS Command Line Interface (CLI) or AWS SDKs, this \ufb01eld is \ncalculated automatically.\nAmazon S3 API Version 2006-03-01 654Amazon Simple Storage Service API Reference\nKey\nKey for which the PUT action was initiated.\nLength Constraints: Minimum length of 1.\nRequired: Yes\nversionId\nVersion ID used to reference a speci\ufb01c version of the object.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-acl\nThe canned ACL to apply to the object. For more information, see Canned ACL.\nValid Values: private | public-read | public-read-write | authenticated-read \n| aws-exec-read | bucket-owner-read | bucket-owner-full-control\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match \nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nx-amz-grant-full-control\nAllows grantee the read, write, read ACP, and write ACP permissions on the bucket.\nThis functionality is not supported for Amazon S3 on Outposts.\nx-amz-grant-read\nAllows grantee to list the objects in the bucket.\nThis functionality is not supported for Amazon S3 on Outposts.\nx-amz-grant-read-acp\nAllows grantee to read the bucket ACL.\nAmazon S3 API Version 2006-03-01 655Amazon Simple Storage Service API Reference\nThis functionality is not supported for Amazon S3 on Outposts.\nx-amz-grant-write\nAllows grantee to create new objects in the bucket.\nFor the bucket and object owners of existing objects, also allows deletions and overwrites of \nthose objects.\nx-amz-grant-write-acp\nAllows grantee to write the ACL for the applicable bucket.\nThis functionality is not supported for Amazon S3 on Outposts.\nx-amz-request-payer\nCon\ufb01rms that the requester knows that they will be charged for the request. Bucket owners \nneed not specify this parameter in their requests.", "If either the source or destination S3 \nbucket has Requester Pays enabled, the requester will pay for corresponding charges to copy \nthe object. For information about downloading objects from Requester Pays buckets, see\nDownloading Objects in Requester Pays Buckets in the Amazon S3 User Guide .\nNote\nThis functionality is not supported for directory buckets.\nValid Values: requester\nx-amz-sdk-checksum-algorithm\nIndicates the algorithm used to create the checksum for the object when you use the SDK.", "This \nheader will not provide any additional functionality if you don't use the SDK.", "When you send \nthis header, there must be a corresponding x-amz-checksum  or x-amz-trailer  header sent.", "\nOtherwise, Amazon S3 fails the request with the HTTP status code 400 Bad Request . For \nmore information, see Checking object integrity in the Amazon S3 User Guide .\nIf you provide an individual checksum, Amazon S3 ignores any provided ChecksumAlgorithm\nparameter.\nValid Values: CRC32 | CRC32C | SHA1 | SHA256\nAmazon S3 API Version 2006-03-01 656Amazon Simple Storage Service API Reference\nRequest Body\nThe request accepts the following data in XML format.\nAccessControlPolicy\nRoot level tag for the AccessControlPolicy parameters.\nRequired: Yes\nGrants\nA list of grants.\nType: Array of Grant  data types\nRequired: No\nOwner\nContainer for the bucket owner's display name and ID.\nType: Owner  data type\nRequired: No\nResponse Syntax\nHTTP/1.1 200\nx-amz-request-charged: RequestCharged\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe response returns the following HTTP headers.\nx-amz-request-charged\nIf present, indicates that the requester was successfully charged for the request.\nNote\nThis functionality is not supported for directory buckets.\nAmazon S3 API Version 2006-03-01 657Amazon Simple Storage Service API Reference\nValid Values: requester\nErrors\nNoSuchKey\nThe speci\ufb01ed key does not exist.\nHTTP Status Code: 404\nExamples\nSample Request\nThe following request grants access permission to an existing object.", "The request speci\ufb01es the ACL \nin the body.", "In addition to granting full control to the object owner, the XML speci\ufb01es full control \nto an AWS account identi\ufb01ed by its canonical user ID.\nPUT /my-image.jpg?acl HTTP/1.1\nHost: bucket.s3.<Region>.amazonaws.com\nDate: Wed, 28 Oct 2009 22:32:00 GMT\nAuthorization: authorization string\nContent-Length: 124\n<AccessControlPolicy> \n  <Owner> \n    <ID>75aa57f09aa0c8caeab4f8c24e99d10f8e7faeebf76c078efc7c6caea54ba06a</ID> \n    <DisplayName>CustomersName@amazon.com</DisplayName> \n  </Owner> \n  <AccessControlList> \n    <Grant> \n      <Grantee xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" \n xsi:type=\"CanonicalUser\"> \n        <ID>75aa57f09aa0c8caeab4f8c24e99d10f8e7faeeExampleCanonicalUserID</ID> \n        <DisplayName>CustomerName@amazon.com</DisplayName> \n      </Grantee> \n      <Permission>FULL_CONTROL</Permission> \n    </Grant> \n  </AccessControlList>\n</AccessControlPolicy> \n          \nAmazon S3 API Version 2006-03-01 658Amazon Simple Storage Service API Reference\nSample Response\nThe following shows a sample response when versioning on the bucket is enabled.\nHTTP/1.1 200 OK\nx-amz-id-2: eftixk72aD6Ap51T9AS1ed4OpIszj7UDNEHGran\nx-amz-request-id: 318BC8BC148832E5\nx-amz-version-id: 3/L4kqtJlcpXrof3vjVBH40Nr8X8gdRQBpUMLUo\nDate: Wed, 28 Oct 2009 22:32:00 GMT\nLast-Modified: Sun, 1 Jan 2006 12:00:00 GMT\nContent-Length: 0\nConnection: close\nServer: AmazonS3 \n          \nSample Request: Setting the ACL of a speci\ufb01ed object version\nThe following request sets the ACL on the speci\ufb01ed version of the object.\nPUT /my-image.jpg?acl&versionId=3HL4kqtJlcpXroDTDmJ+rmSpXd3dIbrHY+MTRCxf3vjVBH40Nrjfkd \n HTTP/1.1\nHost: bucket.s3.<Region>.amazonaws.com\nDate: Wed, 28 Oct 2009 22:32:00 GMT\nAuthorization: authorization string\nContent-Length: 124 \n  \n<AccessControlPolicy> \n  <Owner> \n    <ID>75aa57f09aa0c8caeab4f8c24e99d10f8e7faeebf76c078efc7c6caea54ba06a</ID> \n    <DisplayName>mtd@amazon.com</DisplayName> \n  </Owner> \n  <AccessControlList> \n    <Grant> \n      <Grantee xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" \n xsi:type=\"CanonicalUser\"> \n        <ID>75aa57f09aa0c8caeab4f8c24e99d10f8e7faeebf76c078efc7c6caea54ba06a</ID> \n        <DisplayName>mtd@amazon.com</DisplayName> \n      </Grantee> \n      <Permission>FULL_CONTROL</Permission> \n    </Grant> \n  </AccessControlList>\nAmazon S3 API Version 2006-03-01 659Amazon Simple Storage Service API Reference\n</AccessControlPolicy> \n          \nSample Response\nThis example illustrates one usage of PutObjectAcl.\nHTTP/1.1 200 OK\nx-amz-id-2: eftixk72aD6Ap51u8yU9AS1ed4OpIszj7UDNEHGran\nx-amz-request-id: 318BC8BC148832E5\nx-amz-version-id: 3/L4kqtJlcpXro3vjVBH40Nr8X8gdRQBpUMLUo\nDate: Wed, 28 Oct 2009 22:32:00 GMT\nLast-Modified: Sun, 1 Jan 2006 12:00:00 GMT\nContent-Length: 0\nConnection: close\nServer: AmazonS3 \n          \nSample Request: Access permissions speci\ufb01ed using headers\nThe following request sets the ACL on the speci\ufb01ed version of the object.\nPUT ExampleObject.txt?acl HTTP/1.1\nHost: examplebucket.s3.<Region>.amazonaws.com\nx-amz-acl: public-read\nAccept: */*\nAuthorization: authorization string\nHost: s3.amazonaws.com\nConnection: Keep-Alive \n          \nSample Response\nThis example illustrates one usage of PutObjectAcl.\nHTTP/1.1 200 OK\nx-amz-id-2: w5YegkbG6ZDsje4WK56RWPxNQHIQ0CjrjyRVFZhEJI9E3kbabXnBO9w5G7Dmxsgk\nx-amz-request-id: C13B2827BD8455B1\nDate: Sun, 29 Apr 2012 23:24:12 GMT\nAmazon S3 API Version 2006-03-01 660Amazon Simple Storage Service API Reference\nContent-Length: 0\nServer: AmazonS3 \n          \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 661Amazon Simple Storage Service API Reference\nPutObjectLegalHold\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nApplies a legal hold con\ufb01guration to the speci\ufb01ed object. For more information, see Locking \nObjects.\nThis functionality is not supported for Amazon S3 on Outposts.\nRequest Syntax\nPUT /{Key+}?legal-hold&versionId= VersionId  HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-request-payer: RequestPayer\nContent-MD5: ContentMD5\nx-amz-sdk-checksum-algorithm: ChecksumAlgorithm\nx-amz-expected-bucket-owner: ExpectedBucketOwner\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<LegalHold  xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n   <Status>string</Status>\n</LegalHold >\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe bucket name containing the object that you want to place a legal hold on.\nAccess points - When you use this action with an access point, you must provide the alias of the \naccess point in place of the bucket name or specify the access point ARN.", "When using the access \npoint ARN, you must direct requests to the access point hostname.", "The access point hostname \ntakes the form AccessPointName-AccountId .s3-accesspoint.Region.amazonaws.com.", "When using \nthis action with an access point through the AWS SDKs, you provide the access point ARN in \nplace of the bucket name. For more information about access point ARNs, see Using access \npoints  in the Amazon S3 User Guide .\nAmazon S3 API Version 2006-03-01 662Amazon Simple Storage Service API Reference\nRequired: Yes\nContent-MD5\nThe MD5 hash for the request body.\nFor requests made using the AWS Command Line Interface (CLI) or AWS SDKs, this \ufb01eld is \ncalculated automatically.\nKey\nThe key name for the object that you want to place a legal hold on.\nLength Constraints: Minimum length of 1.\nRequired: Yes\nversionId\nThe version ID of the object that you want to place a legal hold on.\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner.", "If the account ID that you provide does not match \nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nx-amz-request-payer\nCon\ufb01rms that the requester knows that they will be charged for the request. Bucket owners \nneed not specify this parameter in their requests.", "If either the source or destination S3 \nbucket has Requester Pays enabled, the requester will pay for corresponding charges to copy \nthe object. For information about downloading objects from Requester Pays buckets, see\nDownloading Objects in Requester Pays Buckets in the Amazon S3 User Guide .\nNote\nThis functionality is not supported for directory buckets.\nValid Values: requester\nx-amz-sdk-checksum-algorithm\nIndicates the algorithm used to create the checksum for the object when you use the SDK.", "This \nheader will not provide any additional functionality if you don't use the SDK.", "When you send \nAmazon S3 API Version 2006-03-01 663Amazon Simple Storage Service API Reference\nthis header, there must be a corresponding x-amz-checksum  or x-amz-trailer  header sent. \nOtherwise, Amazon S3 fails the request with the HTTP status code 400 Bad Request . For \nmore information, see Checking object integrity in the Amazon S3 User Guide .\nIf you provide an individual checksum, Amazon S3 ignores any provided ChecksumAlgorithm\nparameter.\nValid Values: CRC32 | CRC32C | SHA1 | SHA256\nRequest Body\nThe request accepts the following data in XML format.\nLegalHold\nRoot level tag for the LegalHold parameters.\nRequired: Yes\nStatus\nIndicates whether the speci\ufb01ed object has a legal hold in place.\nType: String\nValid Values: ON | OFF\nRequired: No\nResponse Syntax\nHTTP/1.1 200\nx-amz-request-charged: RequestCharged\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe response returns the following HTTP headers.\nx-amz-request-charged\nIf present, indicates that the requester was successfully charged for the request.\nAmazon S3 API Version 2006-03-01 664Amazon Simple Storage Service API Reference\nNote\nThis functionality is not supported for directory buckets.\nValid Values: requester\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 665Amazon Simple Storage Service API Reference\nPutObjectLockCon\ufb01guration\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nPlaces an Object Lock con\ufb01guration on the speci\ufb01ed bucket.", "The rule speci\ufb01ed in the Object Lock \ncon\ufb01guration will be applied by default to every new object placed in the speci\ufb01ed bucket. For \nmore information, see Locking Objects.\nNote\n\u2022The DefaultRetention  settings require both a mode and a period.\n\u2022The DefaultRetention  period can be either Days  or Years but you must select one.", "\nYou cannot specify Days  and Years  at the same time.\n\u2022You can enable Object Lock for new or existing buckets. For more information, see\nCon\ufb01guring Object Lock.\nRequest Syntax\nPUT /?object-lock HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-request-payer: RequestPayer\nx-amz-bucket-object-lock-token: Token\nContent-MD5: ContentMD5\nx-amz-sdk-checksum-algorithm: ChecksumAlgorithm\nx-amz-expected-bucket-owner: ExpectedBucketOwner\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<ObjectLockConfiguration  xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n   <ObjectLockEnabled >string</ObjectLockEnabled > \n   <Rule> \n      <DefaultRetention > \n         < Days>integer</Days> \n         < Mode>string</Mode> \n         < Years>integer</Years> \n      </ DefaultRetention > \nAmazon S3 API Version 2006-03-01 666Amazon Simple Storage Service API Reference\n   </Rule>\n</ObjectLockConfiguration >\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe bucket whose Object Lock con\ufb01guration you want to create or replace.\nRequired: Yes\nContent-MD5\nThe MD5 hash for the request body.\nFor requests made using the AWS Command Line Interface (CLI) or AWS SDKs, this \ufb01eld is \ncalculated automatically.\nx-amz-bucket-object-lock-token\nA token to allow Object Lock to be enabled for an existing bucket.\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match \nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nx-amz-request-payer\nCon\ufb01rms that the requester knows that they will be charged for the request. Bucket owners \nneed not specify this parameter in their requests.", "If either the source or destination S3 \nbucket has Requester Pays enabled, the requester will pay for corresponding charges to copy \nthe object. For information about downloading objects from Requester Pays buckets, see\nDownloading Objects in Requester Pays Buckets in the Amazon S3 User Guide .\nNote\nThis functionality is not supported for directory buckets.\nValid Values: requester\nAmazon S3 API Version 2006-03-01 667Amazon Simple Storage Service API Reference\nx-amz-sdk-checksum-algorithm\nIndicates the algorithm used to create the checksum for the object when you use the SDK.", "This \nheader will not provide any additional functionality if you don't use the SDK.", "When you send \nthis header, there must be a corresponding x-amz-checksum  or x-amz-trailer  header sent.", "\nOtherwise, Amazon S3 fails the request with the HTTP status code 400 Bad Request . For \nmore information, see Checking object integrity in the Amazon S3 User Guide .\nIf you provide an individual checksum, Amazon S3 ignores any provided ChecksumAlgorithm\nparameter.\nValid Values: CRC32 | CRC32C | SHA1 | SHA256\nRequest Body\nThe request accepts the following data in XML format.\nObjectLockCon\ufb01guration\nRoot level tag for the ObjectLockCon\ufb01guration parameters.\nRequired: Yes\nObjectLockEnabled\nIndicates whether this bucket has an Object Lock con\ufb01guration enabled. Enable\nObjectLockEnabled  when you apply ObjectLockConfiguration  to a bucket.\nType: String\nValid Values: Enabled\nRequired: No\nRule\nSpeci\ufb01es the Object Lock rule for the speci\ufb01ed object. Enable the this rule when you apply\nObjectLockConfiguration  to a bucket. Bucket settings require both a mode and a period.", "\nThe period can be either Days  or Years but you must select one.", "You cannot specify Days  and\nYears  at the same time.\nType: ObjectLockRule data type\nAmazon S3 API Version 2006-03-01 668Amazon Simple Storage Service API Reference\nRequired: No\nResponse Syntax\nHTTP/1.1 200\nx-amz-request-charged: RequestCharged\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe response returns the following HTTP headers.\nx-amz-request-charged\nIf present, indicates that the requester was successfully charged for the request.\nNote\nThis functionality is not supported for directory buckets.\nValid Values: requester\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\nAmazon S3 API Version 2006-03-01 669Amazon Simple Storage Service API Reference\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 670Amazon Simple Storage Service API Reference\nPutObjectRetention\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nPlaces an Object Retention con\ufb01guration on an object.", "For more information, see Locking Objects.", "\nUsers or accounts require the s3:PutObjectRetention  permission in order to place an Object \nRetention con\ufb01guration on objects. Bypassing a Governance Retention con\ufb01guration requires the\ns3:BypassGovernanceRetention  permission.\nThis functionality is not supported for Amazon S3 on Outposts.\nRequest Syntax\nPUT /{Key+}?retention&versionId= VersionId  HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-request-payer: RequestPayer\nx-amz-bypass-governance-retention: BypassGovernanceRetention\nContent-MD5: ContentMD5\nx-amz-sdk-checksum-algorithm: ChecksumAlgorithm\nx-amz-expected-bucket-owner: ExpectedBucketOwner\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<Retention  xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n   <Mode>string</Mode> \n   <RetainUntilDate >timestamp </RetainUntilDate >\n</Retention >\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe bucket name that contains the object you want to apply this Object Retention \ncon\ufb01guration to.\nAccess points - When you use this action with an access point, you must provide the alias of the \naccess point in place of the bucket name or specify the access point ARN. When using the access \nAmazon S3 API Version 2006-03-01 671Amazon Simple Storage Service API Reference\npoint ARN, you must direct requests to the access point hostname. The access point hostname \ntakes the form AccessPointName-AccountId .s3-accesspoint.Region.amazonaws.com.", "When using \nthis action with an access point through the AWS SDKs, you provide the access point ARN in \nplace of the bucket name. For more information about access point ARNs, see Using access \npoints  in the Amazon S3 User Guide .\nRequired: Yes\nContent-MD5\nThe MD5 hash for the request body.\nFor requests made using the AWS Command Line Interface (CLI) or AWS SDKs, this \ufb01eld is \ncalculated automatically.\nKey\nThe key name for the object that you want to apply this Object Retention con\ufb01guration to.\nLength Constraints: Minimum length of 1.\nRequired: Yes\nversionId\nThe version ID for the object that you want to apply this Object Retention con\ufb01guration to.\nx-amz-bypass-governance-retention\nIndicates whether this action should bypass Governance-mode restrictions.\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match \nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nx-amz-request-payer\nCon\ufb01rms that the requester knows that they will be charged for the request. Bucket owners \nneed not specify this parameter in their requests.", "If either the source or destination S3 \nbucket has Requester Pays enabled, the requester will pay for corresponding charges to copy \nthe object. For information about downloading objects from Requester Pays buckets, see\nDownloading Objects in Requester Pays Buckets in the Amazon S3 User Guide .\nAmazon S3 API Version 2006-03-01 672Amazon Simple Storage Service API Reference\nNote\nThis functionality is not supported for directory buckets.\nValid Values: requester\nx-amz-sdk-checksum-algorithm\nIndicates the algorithm used to create the checksum for the object when you use the SDK.", "This \nheader will not provide any additional functionality if you don't use the SDK.", "When you send \nthis header, there must be a corresponding x-amz-checksum  or x-amz-trailer  header sent.", "\nOtherwise, Amazon S3 fails the request with the HTTP status code 400 Bad Request . For \nmore information, see Checking object integrity in the Amazon S3 User Guide .\nIf you provide an individual checksum, Amazon S3 ignores any provided ChecksumAlgorithm\nparameter.\nValid Values: CRC32 | CRC32C | SHA1 | SHA256\nRequest Body\nThe request accepts the following data in XML format.\nRetention\nRoot level tag for the Retention parameters.\nRequired: Yes\nMode\nIndicates the Retention mode for the speci\ufb01ed object.\nType: String\nValid Values: GOVERNANCE | COMPLIANCE\nRequired: No\nRetainUntilDate\nThe date on which this Object Lock Retention will expire.\nAmazon S3 API Version 2006-03-01 673Amazon Simple Storage Service API Reference\nType: Timestamp\nRequired: No\nResponse Syntax\nHTTP/1.1 200\nx-amz-request-charged: RequestCharged\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe response returns the following HTTP headers.\nx-amz-request-charged\nIf present, indicates that the requester was successfully charged for the request.\nNote\nThis functionality is not supported for directory buckets.\nValid Values: requester\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\nAmazon S3 API Version 2006-03-01 674Amazon Simple Storage Service API Reference\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 675Amazon Simple Storage Service API Reference\nPutObjectTagging\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nSets the supplied tag-set to an object that already exists in a bucket.", "A tag is a key-value pair. For \nmore information, see Object Tagging.\nYou can associate tags with an object by sending a PUT request against the tagging subresource \nthat is associated with the object. You can retrieve tags by sending a GET request. For more \ninformation, see GetObjectTagging.\nFor tagging-related restrictions related to characters and encodings, see Tag Restrictions.", "Note that \nAmazon S3 limits the maximum number of tags to 10 tags per object.\nTo use this operation, you must have permission to perform the s3:PutObjectTagging  action.", "\nBy default, the bucket owner has this permission and can grant this permission to others.\nTo put tags of any other version, use the versionId  query parameter.", "You also need permission \nfor the s3:PutObjectVersionTagging  action.\nPutObjectTagging  has the following special errors. For more Amazon S3 errors see, Error \nResponses.\n\u2022InvalidTag  - The tag provided was not a valid tag.", "This error can occur if the tag did not pass \ninput validation. For more information, see Object Tagging.\n\u2022MalformedXML  - The XML provided does not match the schema.\n\u2022OperationAborted  - A con\ufb02icting conditional action is currently in progress against this \nresource.", "Please try again.\n\u2022InternalError  - The service was unable to apply the provided tag to the object.\nThe following operations are related to PutObjectTagging :\n\u2022GetObjectTagging\n\u2022DeleteObjectTagging\nAmazon S3 API Version 2006-03-01 676Amazon Simple Storage Service API Reference\nRequest Syntax\nPUT /{Key+}?tagging&versionId= VersionId  HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nContent-MD5: ContentMD5\nx-amz-sdk-checksum-algorithm: ChecksumAlgorithm\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nx-amz-request-payer: RequestPayer\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<Tagging xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n   <TagSet> \n      <Tag> \n         < Key>string</Key> \n         < Value>string</Value> \n      </Tag> \n   </TagSet>\n</Tagging>\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe bucket name containing the object.\nAccess points - When you use this action with an access point, you must provide the alias of the \naccess point in place of the bucket name or specify the access point ARN.", "When using the access \npoint ARN, you must direct requests to the access point hostname.", "The access point hostname \ntakes the form AccessPointName-AccountId .s3-accesspoint.Region.amazonaws.com.", "When using \nthis action with an access point through the AWS SDKs, you provide the access point ARN in \nplace of the bucket name.", "For more information about access point ARNs, see Using access \npoints  in the Amazon S3 User Guide .\nS3 on Outposts  - When you use this action with Amazon S3 on Outposts, you must direct \nrequests to the S3 on Outposts hostname. The S3 on Outposts hostname takes the form \nAccessPointName -AccountId .outpostID .s3-outposts.", "Region.amazonaws.com .", "\nWhen you use this action with S3 on Outposts through the AWS SDKs, you provide the Outposts \naccess point ARN in place of the bucket name. For more information about S3 on Outposts \nARNs, see What is S3 on Outposts?", "in the Amazon S3 User Guide .\nRequired: Yes\nAmazon S3 API Version 2006-03-01 677Amazon Simple Storage Service API Reference\nContent-MD5\nThe MD5 hash for the request body.\nFor requests made using the AWS Command Line Interface (CLI) or AWS SDKs, this \ufb01eld is \ncalculated automatically.\nKey\nName of the object key.\nLength Constraints: Minimum length of 1.\nRequired: Yes\nversionId\nThe versionId of the object that the tag-set will be added to.\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner.", "If the account ID that you provide does not match \nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nx-amz-request-payer\nCon\ufb01rms that the requester knows that they will be charged for the request. Bucket owners \nneed not specify this parameter in their requests.", "If either the source or destination S3 \nbucket has Requester Pays enabled, the requester will pay for corresponding charges to copy \nthe object. For information about downloading objects from Requester Pays buckets, see\nDownloading Objects in Requester Pays Buckets in the Amazon S3 User Guide .\nNote\nThis functionality is not supported for directory buckets.\nValid Values: requester\nx-amz-sdk-checksum-algorithm\nIndicates the algorithm used to create the checksum for the object when you use the SDK.", "This \nheader will not provide any additional functionality if you don't use the SDK.", "When you send \nAmazon S3 API Version 2006-03-01 678Amazon Simple Storage Service API Reference\nthis header, there must be a corresponding x-amz-checksum  or x-amz-trailer  header sent. \nOtherwise, Amazon S3 fails the request with the HTTP status code 400 Bad Request . For \nmore information, see Checking object integrity in the Amazon S3 User Guide .\nIf you provide an individual checksum, Amazon S3 ignores any provided ChecksumAlgorithm\nparameter.\nValid Values: CRC32 | CRC32C | SHA1 | SHA256\nRequest Body\nThe request accepts the following data in XML format.\nTagging\nRoot level tag for the Tagging parameters.\nRequired: Yes\nTagSet\nA collection for a set of tags\nType: Array of Tag data types\nRequired: Yes\nResponse Syntax\nHTTP/1.1 200\nx-amz-version-id: VersionId\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe response returns the following HTTP headers.\nx-amz-version-id\nThe versionId of the object the tag-set was added to.\nAmazon S3 API Version 2006-03-01 679Amazon Simple Storage Service API Reference\nExamples\nSample Request: Add tag set to an object\nThe following request adds a tag set to the existing object object-key in the examplebucket\nbucket.\nPUT object-key?tagging HTTP/1.1\nHost: examplebucket.s3.<Region>.amazonaws.com\nContent-Length: length\nContent-MD5: pUNXr/BjKK5G2UKExample==\nx-amz-date: 20160923T001956Z\nAuthorization: authorization string\n<Tagging> \n   <TagSet> \n      <Tag> \n         <Key>tag1</Key> \n         <Value>val1</Value> \n      </Tag> \n      <Tag> \n         <Key>tag2</Key> \n         <Value>val2</Value> \n      </Tag> \n   </TagSet>\n</Tagging> \n          \nSample Response\nThis example illustrates one usage of PutObjectTagging.\nHTTP/1.1 200 OK\nx-amz-id-2: YgIPIfBiKa2bj0KMgUAdQkf3ShJTOOpXUueF6QKo\nx-amz-request-id: 236A8905248E5A01\nDate: Fri, 23 Sep 2016 00:20:19 GMT \n          \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\nAmazon S3 API Version 2006-03-01 680Amazon Simple Storage Service API Reference\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 681Amazon Simple Storage Service API Reference\nPutPublicAccessBlock\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nCreates or modi\ufb01es the PublicAccessBlock  con\ufb01guration for an Amazon S3 bucket.", "To use \nthis operation, you must have the s3:PutBucketPublicAccessBlock  permission. For more \ninformation about Amazon S3 permissions, see Specifying Permissions in a Policy.\nImportant\nWhen Amazon S3 evaluates the PublicAccessBlock  con\ufb01guration for a bucket or an \nobject, it checks the PublicAccessBlock  con\ufb01guration for both the bucket (or the bucket \nthat contains the object) and the bucket owner's account. If the PublicAccessBlock\ncon\ufb01gurations are di\ufb00erent between the bucket and the account, Amazon S3 uses the most \nrestrictive combination of the bucket-level and account-level settings.\nFor more information about when Amazon S3 considers a bucket or an object public, see The \nMeaning of \"Public\".\nThe following operations are related to PutPublicAccessBlock :\n\u2022GetPublicAccessBlock\n\u2022DeletePublicAccessBlock\n\u2022GetBucketPolicyStatus\n\u2022Using Amazon S3 Block Public Access\nRequest Syntax\nPUT /?publicAccessBlock HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nContent-MD5: ContentMD5\nx-amz-sdk-checksum-algorithm: ChecksumAlgorithm\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nAmazon S3 API Version 2006-03-01 682Amazon Simple Storage Service API Reference\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<PublicAccessBlockConfiguration  xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n   <BlockPublicAcls >boolean</BlockPublicAcls > \n   <IgnorePublicAcls >boolean</IgnorePublicAcls > \n   <BlockPublicPolicy >boolean</BlockPublicPolicy > \n   <RestrictPublicBuckets >boolean</RestrictPublicBuckets >\n</PublicAccessBlockConfiguration >\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe name of the Amazon S3 bucket whose PublicAccessBlock  con\ufb01guration you want to \nset.\nRequired: Yes\nContent-MD5\nThe MD5 hash of the PutPublicAccessBlock  request body.\nFor requests made using the AWS Command Line Interface (CLI) or AWS SDKs, this \ufb01eld is \ncalculated automatically.\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match \nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nx-amz-sdk-checksum-algorithm\nIndicates the algorithm used to create the checksum for the object when you use the SDK.", "This \nheader will not provide any additional functionality if you don't use the SDK.", "When you send \nthis header, there must be a corresponding x-amz-checksum  or x-amz-trailer  header sent.", "\nOtherwise, Amazon S3 fails the request with the HTTP status code 400 Bad Request . For \nmore information, see Checking object integrity in the Amazon S3 User Guide .\nIf you provide an individual checksum, Amazon S3 ignores any provided ChecksumAlgorithm\nparameter.\nValid Values: CRC32 | CRC32C | SHA1 | SHA256\nAmazon S3 API Version 2006-03-01 683Amazon Simple Storage Service API Reference\nRequest Body\nThe request accepts the following data in XML format.\nPublicAccessBlockCon\ufb01guration\nRoot level tag for the PublicAccessBlockCon\ufb01guration parameters.\nRequired: Yes\nBlockPublicAcls\nSpeci\ufb01es whether Amazon S3 should block public access control lists (ACLs) for this bucket and \nobjects in this bucket. Setting this element to TRUE causes the following behavior:\n\u2022PUT Bucket ACL and PUT Object ACL calls fail if the speci\ufb01ed ACL is public.\n\u2022PUT Object calls fail if the request includes a public ACL.\n\u2022PUT Bucket calls fail if the request includes a public ACL.\nEnabling this setting doesn't a\ufb00ect existing policies or ACLs.\nType: Boolean\nRequired: No\nBlockPublicPolicy\nSpeci\ufb01es whether Amazon S3 should block public bucket policies for this bucket. Setting this \nelement to TRUE causes Amazon S3 to reject calls to PUT Bucket policy if the speci\ufb01ed bucket \npolicy allows public access.\nEnabling this setting doesn't a\ufb00ect existing bucket policies.\nType: Boolean\nRequired: No\nIgnorePublicAcls\nSpeci\ufb01es whether Amazon S3 should ignore public ACLs for this bucket and objects in this \nbucket. Setting this element to TRUE causes Amazon S3 to ignore all public ACLs on this bucket \nand objects in this bucket.\nEnabling this setting doesn't a\ufb00ect the persistence of any existing ACLs and doesn't prevent \nnew public ACLs from being set.\nAmazon S3 API Version 2006-03-01 684Amazon Simple Storage Service API Reference\nType: Boolean\nRequired: No\nRestrictPublicBuckets\nSpeci\ufb01es whether Amazon S3 should restrict public bucket policies for this bucket. Setting this \nelement to TRUE restricts access to this bucket to only AWS service principals and authorized \nusers within this account if the bucket has a public policy.\nEnabling this setting doesn't a\ufb00ect previously stored bucket policies, except that public and \ncross-account access within any public bucket policy, including non-public delegation to speci\ufb01c \naccounts, is blocked.\nType: Boolean\nRequired: No\nResponse Syntax\nHTTP/1.1 200\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\nExamples\nFirst Sample Request\nThe following request puts a bucket PublicAccessBlock  con\ufb01guration that rejects public ACLs.\nPUT /?publicAccessBlock HTTP/1.1\nHost: <bucket-name>.s3.<Region>.amazonaws.com\nx-amz-date: <Thu, 15 Nov 2016 00:17:21 GMT>\nAuthorization: <signatureValue>\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<PublicAccessBlockConfiguration xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n      <BlockPublicAcls>TRUE</BlockPublicAcls>  \n      <IgnorePublicAcls>FALSE</IgnorePublicAcls>  \n      <BlockPublicPolicy>FALSE</BlockPublicPolicy>  \nAmazon S3 API Version 2006-03-01 685Amazon Simple Storage Service API Reference\n      <RestrictPublicBuckets>FALSE</RestrictPublicBuckets>\n</PublicAccessBlockConfiguration> \n          \nFirst Sample Response\nThis example illustrates one usage of PutPublicAccessBlock.\nHTTP/1.1 200 OK\nx-amz-id-2: ITnGT1y4REXAMPLEPi4hklTXouTf0hccUjo0iCPEXAMPLEutBj3M7fPGlWO2SEWp\nx-amz-request-id: 51991EXAMPLE5321\nDate: Thu, 15 Nov 2016 00:17:22 GMT\nServer: AmazonS3\nContent-Length: 0 \n          \nSecond Sample Request\nThe following request puts a bucket PublicAccessBlock con\ufb01guration that ignores public ACLs and \nrestricts access to public buckets.\nPUT /?publicAccessBlock HTTP/1.1\nHost: <bucket-name>.s3.<Region>.amazonaws.com\nx-amz-date: <Thu, 15 Nov 2016 00:17:21 GMT>\nAuthorization: <signatureValue>\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<PublicAccessBlockConfiguration xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n      <BlockPublicAcls>FALSE</BlockPublicAcls>  \n      <IgnorePublicAcls>TRUE</IgnorePublicAcls>  \n      <BlockPublicPolicy>FALSE</BlockPublicPolicy>  \n      <RestrictPublicBuckets>TRUE</RestrictPublicBuckets>\n</PublicAccessBlockConfiguration> \n          \nSecond Sample Response\nThis example illustrates one usage of PutPublicAccessBlock.\nAmazon S3 API Version 2006-03-01 686Amazon Simple Storage Service API Reference\nHTTP/1.1 200 OK\nx-amz-id-2: ITnGT1y4REXAMPLEPi4hklTXouTf0hccUjo0iCPEXAMPLEutBj3M7fPGlWO2SEWp\nx-amz-request-id: 51991EXAMPLE5321\nDate: Thu, 15 Nov 2016 00:17:22 GMT\nServer: AmazonS3\nContent-Length: 0 \n          \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 687Amazon Simple Storage Service API Reference\nRestoreObject\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nRestores an archived copy of an object back into Amazon S3\nThis functionality is not supported for Amazon S3 on Outposts.\nThis action performs the following types of requests:\n\u2022restore an archive  - Restore an archived object\nFor more information about the S3 structure in the request body, see the following:\n\u2022PutObject\n\u2022Managing Access with ACLs in the Amazon S3 User Guide\n\u2022Protecting Data Using Server-Side Encryption in the Amazon S3 User Guide\nPermissions\nTo use this operation, you must have permissions to perform the s3:RestoreObject  action. \nThe bucket owner has this permission by default and can grant this permission to others.", "\nFor more information about permissions, see Permissions Related to Bucket Subresource \nOperations  and Managing Access Permissions to Your Amazon S3 Resources in the Amazon S3 \nUser Guide .\nRestoring objects\nObjects that you archive to the S3 Glacier Flexible Retrieval Flexible Retrieval or S3 Glacier Deep \nArchive storage class, and S3 Intelligent-Tiering Archive or S3 Intelligent-Tiering Deep Archive \ntiers, are not accessible in real time. For objects in the S3 Glacier Flexible Retrieval Flexible \nRetrieval or S3 Glacier Deep Archive storage classes, you must \ufb01rst initiate a restore request, \nand then wait until a temporary copy of the object is available. If you want a permanent copy \nof the object, create a copy of it in the Amazon S3 Standard storage class in your S3 bucket. \nTo access an archived object, you must restore the object for the duration (number of days) \nAmazon S3 API Version 2006-03-01 688Amazon Simple Storage Service API Reference\nthat you specify. For objects in the Archive Access or Deep Archive Access tiers of S3 Intelligent-\nTiering, you must \ufb01rst initiate a restore request, and then wait until the object is moved into the \nFrequent Access tier.\nTo restore a speci\ufb01c object version, you can provide a version ID. If you don't provide a version \nID, Amazon S3 restores the current version.\nWhen restoring an archived object, you can specify one of the following data access tier options \nin the Tier element of the request body:\n\u2022Expedited  - Expedited retrievals allow you to quickly access your data stored in the S3 \nGlacier Flexible Retrieval Flexible Retrieval storage class or S3 Intelligent-Tiering Archive \ntier when occasional urgent requests for restoring archives are required.", "For all but the \nlargest archived objects (250 MB+), data accessed using Expedited retrievals is typically \nmade available within 1\u20135 minutes. Provisioned capacity ensures that retrieval capacity \nfor Expedited retrievals is available when you need it.", "Expedited retrievals and provisioned \ncapacity are not available for objects stored in the S3 Glacier Deep Archive storage class or S3 \nIntelligent-Tiering Deep Archive tier.\n\u2022Standard  - Standard retrievals allow you to access any of your archived objects within \nseveral hours.", "This is the default option for retrieval requests that do not specify the retrieval \noption.", "Standard retrievals typically \ufb01nish within 3\u20135 hours for objects stored in the S3 \nGlacier Flexible Retrieval Flexible Retrieval storage class or S3 Intelligent-Tiering Archive tier. \nThey typically \ufb01nish within 12 hours for objects stored in the S3 Glacier Deep Archive storage \nclass or S3 Intelligent-Tiering Deep Archive tier. Standard retrievals are free for objects stored \nin S3 Intelligent-Tiering.\n\u2022Bulk - Bulk retrievals free for objects stored in the S3 Glacier Flexible Retrieval and S3 \nIntelligent-Tiering storage classes, enabling you to retrieve large amounts, even petabytes, \nof data at no cost. Bulk retrievals typically \ufb01nish within 5\u201312 hours for objects stored in the \nS3 Glacier Flexible Retrieval Flexible Retrieval storage class or S3 Intelligent-Tiering Archive \ntier. Bulk retrievals are also the lowest-cost retrieval option when restoring objects from S3 \nGlacier Deep Archive. They typically \ufb01nish within 48 hours for objects stored in the S3 Glacier \nDeep Archive storage class or S3 Intelligent-Tiering Deep Archive tier.\nFor more information about archive retrieval options and provisioned capacity for Expedited\ndata access, see Restoring Archived Objects in the Amazon S3 User Guide .\nYou can use Amazon S3 restore speed upgrade to change the restore speed to a faster speed \nwhile it is in progress. For more information, see  Upgrading the speed of an in-progress restore\nin the Amazon S3 User Guide .\nAmazon S3 API Version 2006-03-01 689Amazon Simple Storage Service API Reference\nTo get the status of object restoration, you can send a HEAD request.", "Operations return the\nx-amz-restore  header, which provides information about the restoration status, in the \nresponse.", "You can use Amazon S3 event noti\ufb01cations to notify you when a restore is initiated \nor completed. For more information, see Con\ufb01guring Amazon S3 Event Noti\ufb01cations in the\nAmazon S3 User Guide .\nAfter restoring an archived object, you can update the restoration period by reissuing the \nrequest with a new period. Amazon S3 updates the restoration period relative to the current \ntime and charges only for the request-there are no data transfer charges. You cannot update \nthe restoration period when Amazon S3 is actively processing your current restore request for \nthe object.\nIf your bucket has a lifecycle con\ufb01guration with a rule that includes an expiration action, the \nobject expiration overrides the life span that you specify in a restore request. For example, \nif you restore an object copy for 10 days, but the object is scheduled to expire in 3 days, \nAmazon S3 deletes the object in 3 days. For more information about lifecycle con\ufb01guration, see\nPutBucketLifecycleCon\ufb01guration and Object Lifecycle Management in Amazon S3 User Guide .\nResponses\nA successful action returns either the 200 OK  or 202 Accepted  status code.\n\u2022If the object is not previously restored, then Amazon S3 returns 202 Accepted  in the \nresponse.\n\u2022If the object is previously restored, Amazon S3 returns 200 OK in the response.\n\u2022Special errors:\n\u2022Code: RestoreAlreadyInProgress\n\u2022Cause: Object restore is already in progress.\n\u2022HTTP Status Code: 409 Con\ufb02ict\n\u2022SOAP Fault Code Pre\ufb01x: Client\n\u2022\u2022Code: GlacierExpeditedRetrievalNotAvailable\n\u2022Cause: expedited retrievals are currently not available.", "Try again later. (Returned if there is \ninsu\ufb03cient capacity to process the Expedited request.", "This error applies only to Expedited \nretrievals and not to S3 Standard or Bulk retrievals.)\n\u2022HTTP Status Code: 503\n\u2022SOAP Fault Code Pre\ufb01x: N/A\nAmazon S3 API Version 2006-03-01 690Amazon Simple Storage Service API Reference\nThe following operations are related to RestoreObject :\n\u2022PutBucketLifecycleCon\ufb01guration\n\u2022GetBucketNoti\ufb01cationCon\ufb01guration\nRequest Syntax\nPOST /{Key+}?restore&versionId= VersionId  HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-request-payer: RequestPayer\nx-amz-sdk-checksum-algorithm: ChecksumAlgorithm\nx-amz-expected-bucket-owner: ExpectedBucketOwner\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<RestoreRequest  xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n   <Days>integer</Days> \n   <GlacierJobParameters > \n      <Tier>string</Tier> \n   </GlacierJobParameters > \n   <Type>string</Type> \n   <Tier>string</Tier> \n   <Description >string</Description > \n   <SelectParameters > \n      <Expression >string</Expression > \n      <ExpressionType >string</ExpressionType > \n      <InputSerialization > \n         < CompressionType >string</CompressionType > \n         < CSV> \n            < AllowQuotedRecordDelimiter >boolean</AllowQuotedRecordDelimiter > \n            < Comments >string</Comments > \n            < FieldDelimiter >string</FieldDelimiter > \n            < FileHeaderInfo >string</FileHeaderInfo > \n            < QuoteCharacter >string</QuoteCharacter > \n            < QuoteEscapeCharacter >string</QuoteEscapeCharacter > \n            < RecordDelimiter >string</RecordDelimiter > \n         </ CSV> \n         < JSON> \n            < Type>string</Type> \n         </ JSON> \n         < Parquet> \n         </ Parquet> \n      </ InputSerialization > \n      <OutputSerialization > \nAmazon S3 API Version 2006-03-01 691Amazon Simple Storage Service API Reference\n         < CSV> \n            < FieldDelimiter >string</FieldDelimiter > \n            < QuoteCharacter >string</QuoteCharacter > \n            < QuoteEscapeCharacter >string</QuoteEscapeCharacter > \n            < QuoteFields >string</QuoteFields > \n            < RecordDelimiter >string</RecordDelimiter > \n         </ CSV> \n         < JSON> \n            < RecordDelimiter >string</RecordDelimiter > \n         </ JSON> \n      </ OutputSerialization > \n   </SelectParameters > \n   <OutputLocation > \n      <S3> \n         < AccessControlList > \n            <Grant> \n               < Grantee> \n                  < DisplayName >string</DisplayName > \n                  < EmailAddress >string</EmailAddress > \n                  < ID>string</ID> \n                  < xsi:type >string</xsi:type > \n                  < URI>string</URI> \n               </ Grantee> \n               < Permission >string</Permission > \n            </Grant> \n         </ AccessControlList > \n         < BucketName >string</BucketName > \n         < CannedACL >string</CannedACL > \n         < Encryption > \n            < EncryptionType >string</EncryptionType > \n            < KMSContext >string</KMSContext > \n            < KMSKeyId >string</KMSKeyId > \n         </ Encryption > \n         < Prefix>string</Prefix> \n         < StorageClass >string</StorageClass > \n         < Tagging> \n            < TagSet> \n               <Tag> \n                  < Key>string</Key> \n                  < Value>string</Value> \n               </Tag> \n            </ TagSet> \n         </ Tagging> \n         < UserMetadata > \nAmazon S3 API Version 2006-03-01 692Amazon Simple Storage Service API Reference\n            <MetadataEntry> \n               < Name>string</Name> \n               < Value>string</Value> \n            </MetadataEntry> \n         </ UserMetadata > \n      </ S3> \n   </OutputLocation >\n</RestoreRequest >\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe bucket name containing the object to restore.\nAccess points - When you use this action with an access point, you must provide the alias of the \naccess point in place of the bucket name or specify the access point ARN.", "When using the access \npoint ARN, you must direct requests to the access point hostname.", "The access point hostname \ntakes the form AccessPointName-AccountId .s3-accesspoint.Region.amazonaws.com.", "When using \nthis action with an access point through the AWS SDKs, you provide the access point ARN in \nplace of the bucket name.", "For more information about access point ARNs, see Using access \npoints  in the Amazon S3 User Guide .\nS3 on Outposts  - When you use this action with Amazon S3 on Outposts, you must direct \nrequests to the S3 on Outposts hostname. The S3 on Outposts hostname takes the form \nAccessPointName -AccountId .outpostID .s3-outposts.", "Region.amazonaws.com .", "\nWhen you use this action with S3 on Outposts through the AWS SDKs, you provide the Outposts \naccess point ARN in place of the bucket name. For more information about S3 on Outposts \nARNs, see What is S3 on Outposts?", "in the Amazon S3 User Guide .\nRequired: Yes\nKey\nObject key for which the action was initiated.\nLength Constraints: Minimum length of 1.\nRequired: Yes\nAmazon S3 API Version 2006-03-01 693Amazon Simple Storage Service API Reference\nversionId\nVersionId used to reference a speci\ufb01c version of the object.\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner.", "If the account ID that you provide does not match \nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nx-amz-request-payer\nCon\ufb01rms that the requester knows that they will be charged for the request. Bucket owners \nneed not specify this parameter in their requests.", "If either the source or destination S3 \nbucket has Requester Pays enabled, the requester will pay for corresponding charges to copy \nthe object. For information about downloading objects from Requester Pays buckets, see\nDownloading Objects in Requester Pays Buckets in the Amazon S3 User Guide .\nNote\nThis functionality is not supported for directory buckets.\nValid Values: requester\nx-amz-sdk-checksum-algorithm\nIndicates the algorithm used to create the checksum for the object when you use the SDK.", "This \nheader will not provide any additional functionality if you don't use the SDK.", "When you send \nthis header, there must be a corresponding x-amz-checksum  or x-amz-trailer  header sent.", "\nOtherwise, Amazon S3 fails the request with the HTTP status code 400 Bad Request . For \nmore information, see Checking object integrity in the Amazon S3 User Guide .\nIf you provide an individual checksum, Amazon S3 ignores any provided ChecksumAlgorithm\nparameter.\nValid Values: CRC32 | CRC32C | SHA1 | SHA256\nRequest Body\nThe request accepts the following data in XML format.\nAmazon S3 API Version 2006-03-01 694Amazon Simple Storage Service API Reference\nRestoreRequest\nRoot level tag for the RestoreRequest parameters.\nRequired: Yes\nDays\nLifetime of the active copy in days.", "Do not use with restores that specify OutputLocation .\nThe Days element is required for regular restores, and must not be provided for select requests.\nType: Integer\nRequired: No\nDescription\nThe optional description for the job.\nType: String\nRequired: No\nGlacierJobParameters\nS3 Glacier related parameters pertaining to this job. Do not use with restores that specify\nOutputLocation .\nType: GlacierJobParameters data type\nRequired: No\nOutputLocation\nDescribes the location where the restore job's output is stored.\nType: OutputLocation  data type\nRequired: No\nSelectParameters\nDescribes the parameters for Select job types.\nType: SelectParameters data type\nRequired: No\nAmazon S3 API Version 2006-03-01 695Amazon Simple Storage Service API Reference\nTier\nRetrieval tier at which the restore will be processed.\nType: String\nValid Values: Standard | Bulk | Expedited\nRequired: No\nType\nType of restore request.\nType: String\nValid Values: SELECT\nRequired: No\nResponse Syntax\nHTTP/1.1 200\nx-amz-request-charged: RequestCharged\nx-amz-restore-output-path: RestoreOutputPath\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe response returns the following HTTP headers.\nx-amz-request-charged\nIf present, indicates that the requester was successfully charged for the request.\nNote\nThis functionality is not supported for directory buckets.\nValid Values: requester\nAmazon S3 API Version 2006-03-01 696Amazon Simple Storage Service API Reference\nx-amz-restore-output-path\nIndicates the path in the provided S3 output location where Select results will be restored to.\nErrors\nObjectAlreadyInActiveTierError\nThis action is not allowed against this storage tier.\nHTTP Status Code: 403\nExamples\nExample: Restore an object for 2 days using the expedited retrieval option\nThe following restore request restores a copy of the photo1.jpg  object from S3 Glacier for a \nperiod of two days using the expedited retrieval option.\nPOST /photo1.jpg?restore HTTP/1.1\nHost: examplebucket.dummy value\nDate: Mon, 22 Oct 2012 01:49:52 GMT\nAuthorization: authorization string\nContent-Length: content length\n<RestoreRequest> \n  <Days>2</Days> \n  <GlacierJobParameters> \n    <Tier>Expedited</Tier> \n  </GlacierJobParameters>\n</RestoreRequest> \n          \nSample response\nIf the examplebucket  does not have a restored copy of the object, Amazon S3 returns the \nfollowing 202 Accepted  response.\nAmazon S3 API Version 2006-03-01 697Amazon Simple Storage Service API Reference\nNote\nIf a copy of the object is already restored, Amazon S3 returns a 200 OK response, and \nupdates only the restored copy's expiry time.\nHTTP/1.1 202 Accepted\nx-amz-id-2: GFihv3y6+kE7KG11GEkQhU7/2/cHR3Yb2fCb2S04nxI423Dqwg2XiQ0B/\nUZlzYQvPiBlZNRcovw=\nx-amz-request-id: 9F341CD3C4BA79E0\nDate: Sat, 20 Oct 2012 23:54:05 GMT\nContent-Length: 0\nServer: AmazonS3 \n          \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 698Amazon Simple Storage Service API Reference\nSelectObjectContent\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nThis action \ufb01lters the contents of an Amazon S3 object based on a simple structured query \nlanguage (SQL) statement.", "In the request, along with the SQL expression, you must also specify a \ndata serialization format (JSON, CSV, or Apache Parquet) of the object.", "Amazon S3 uses this format \nto parse object data into records, and returns only records that match the speci\ufb01ed SQL expression. \nYou must also specify the data serialization format for the response.\nThis functionality is not supported for Amazon S3 on Outposts.\nFor more information about Amazon S3 Select, see Selecting Content from Objects and SELECT \nCommand  in the Amazon S3 User Guide .\nPermissions\nYou must have the s3:GetObject  permission for this operation.\u00a0Amazon S3 Select does \nnot support anonymous access. For more information about permissions, see Specifying \nPermissions in a Policy in the Amazon S3 User Guide .\nObject Data Formats\nYou can use Amazon S3 Select to query objects that have the following format properties:\n\u2022CSV, JSON, and Parquet - Objects must be in CSV, JSON, or Parquet format.\n\u2022UTF-8  - UTF-8 is the only encoding type Amazon S3 Select supports.\n\u2022GZIP or BZIP2  - CSV and JSON \ufb01les can be compressed using GZIP or BZIP2. GZIP and BZIP2 \nare the only compression formats that Amazon S3 Select supports for CSV and JSON \ufb01les. \nAmazon S3 Select supports columnar compression for Parquet using GZIP or Snappy. Amazon \nS3 Select does not support whole-object compression for Parquet objects.\n\u2022Server-side encryption - Amazon S3 Select supports querying objects that are protected with \nserver-side encryption.\nFor objects that are encrypted with customer-provided encryption keys (SSE-C), you must \nuse HTTPS, and you must use the headers that are documented in the GetObject. For more \nAmazon S3 API Version 2006-03-01 699Amazon Simple Storage Service API Reference\ninformation about SSE-C, see Server-Side Encryption (Using Customer-Provided Encryption \nKeys) in the Amazon S3 User Guide .\nFor objects that are encrypted with Amazon S3 managed keys (SSE-S3) and AWS KMS keys \n(SSE-KMS), server-side encryption is handled transparently, so you don't need to specify \nanything. For more information about server-side encryption, including SSE-S3 and SSE-KMS, \nsee Protecting Data Using Server-Side Encryption in the Amazon S3 User Guide .\nWorking with the Response Body\nGiven the response size is unknown, Amazon S3 Select streams the response as a series of \nmessages and includes a Transfer-Encoding  header with chunked  as its value in the \nresponse.", "For more information, see Appendix: SelectObjectContent Response.\nGetObject Support\nThe SelectObjectContent  action does not support the following GetObject  functionality.", "\nFor more information, see GetObject.\n\u2022Range: Although you can specify a scan range for an Amazon S3 Select request (see\nSelectObjectContentRequest - ScanRange in the request parameters), you cannot specify the \nrange of bytes of an object to return.\n\u2022The GLACIER , DEEP_ARCHIVE , and REDUCED_REDUNDANCY  storage classes, or the\nARCHIVE_ACCESS  and DEEP_ARCHIVE_ACCESS  access tiers of the INTELLIGENT_TIERING\nstorage class: You cannot query objects in the GLACIER , DEEP_ARCHIVE , or\nREDUCED_REDUNDANCY  storage classes, nor objects in the ARCHIVE_ACCESS  or\nDEEP_ARCHIVE_ACCESS  access tiers of the INTELLIGENT_TIERING  storage class. For more \ninformation about storage classes, see Using Amazon S3 storage classes in the Amazon S3 \nUser Guide .\nSpecial Errors\nFor a list of special errors for this operation, see List of SELECT Object Content Error Codes\nThe following operations are related to SelectObjectContent :\n\u2022GetObject\n\u2022GetBucketLifecycleCon\ufb01guration\n\u2022PutBucketLifecycleCon\ufb01guration\nAmazon S3 API Version 2006-03-01 700Amazon Simple Storage Service API Reference\nRequest Syntax\nPOST /{Key+}?select&select-type=2 HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-server-side-encryption-customer-algorithm: SSECustomerAlgorithm\nx-amz-server-side-encryption-customer-key: SSECustomerKey\nx-amz-server-side-encryption-customer-key-MD5: SSECustomerKeyMD5\nx-amz-expected-bucket-owner: ExpectedBucketOwner\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<SelectObjectContentRequest  xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n   <Expression >string</Expression > \n   <ExpressionType >string</ExpressionType > \n   <RequestProgress > \n      <Enabled>boolean</Enabled> \n   </RequestProgress > \n   <InputSerialization > \n      <CompressionType >string</CompressionType > \n      <CSV> \n         < AllowQuotedRecordDelimiter >boolean</AllowQuotedRecordDelimiter > \n         < Comments >string</Comments > \n         < FieldDelimiter >string</FieldDelimiter > \n         < FileHeaderInfo >string</FileHeaderInfo > \n         < QuoteCharacter >string</QuoteCharacter > \n         < QuoteEscapeCharacter >string</QuoteEscapeCharacter > \n         < RecordDelimiter >string</RecordDelimiter > \n      </ CSV> \n      <JSON> \n         < Type>string</Type> \n      </ JSON> \n      <Parquet> \n      </ Parquet> \n   </InputSerialization > \n   <OutputSerialization > \n      <CSV> \n         < FieldDelimiter >string</FieldDelimiter > \n         < QuoteCharacter >string</QuoteCharacter > \n         < QuoteEscapeCharacter >string</QuoteEscapeCharacter > \n         < QuoteFields >string</QuoteFields > \n         < RecordDelimiter >string</RecordDelimiter > \n      </ CSV> \n      <JSON> \n         < RecordDelimiter >string</RecordDelimiter > \n      </ JSON> \n   </OutputSerialization > \nAmazon S3 API Version 2006-03-01 701Amazon Simple Storage Service API Reference\n   <ScanRange > \n      <End>long</End> \n      <Start>long</Start> \n   </ScanRange >\n</SelectObjectContentRequest >\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe S3 bucket.\nRequired: Yes\nKey\nThe object key.\nLength Constraints: Minimum length of 1.\nRequired: Yes\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match \nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nx-amz-server-side-encryption-customer-algorithm\nThe server-side encryption (SSE) algorithm used to encrypt the object.", "This parameter is needed \nonly when the object was created using a checksum algorithm.", "For more information, see\nProtecting data using SSE-C keys in the Amazon S3 User Guide .\nx-amz-server-side-encryption-customer-key\nThe server-side encryption (SSE) customer managed key.", "This parameter is needed only when \nthe object was created using a checksum algorithm.", "For more information, see Protecting data \nusing SSE-C keys in the Amazon S3 User Guide .\nAmazon S3 API Version 2006-03-01 702Amazon Simple Storage Service API Reference\nx-amz-server-side-encryption-customer-key-MD5\nThe MD5 server-side encryption (SSE) customer managed key.", "This parameter is needed only \nwhen the object was created using a checksum algorithm.", "For more information, see Protecting \ndata using SSE-C keys in the Amazon S3 User Guide .\nRequest Body\nThe request accepts the following data in XML format.\nSelectObjectContentRequest\nRoot level tag for the SelectObjectContentRequest parameters.\nRequired: Yes\nExpression\nThe expression that is used to query the object.\nType: String\nRequired: Yes\nExpressionType\nThe type of the provided expression (for example, SQL).\nType: String\nValid Values: SQL\nRequired: Yes\nInputSerialization\nDescribes the format of the data in the object that is being queried.\nType: InputSerialization  data type\nRequired: Yes\nOutputSerialization\nDescribes the format of the data that you want Amazon S3 to return in response.\nType: OutputSerialization  data type\nAmazon S3 API Version 2006-03-01 703Amazon Simple Storage Service API Reference\nRequired: Yes\nRequestProgress\nSpeci\ufb01es if periodic request progress information should be enabled.\nType: RequestProgress data type\nRequired: No\nScanRange\nSpeci\ufb01es the byte range of the object to get the records from.", "A record is processed when its \n\ufb01rst byte is contained by the range.", "This parameter is optional, but when speci\ufb01ed, it must not \nbe empty.", "See RFC 2616, Section 14.35.1 about how to specify the start and end of the range.\nScanRange may be used in the following ways:\n\u2022<scanrange><start>50</start><end>100</end></scanrange>  - process only the \nrecords starting between the bytes 50 and 100 (inclusive, counting from zero)\n\u2022<scanrange><start>50</start></scanrange>  - process only the records starting after \nthe byte 50\n\u2022<scanrange><end>50</end></scanrange>  - process only the records within the last 50 \nbytes of the \ufb01le.\nType: ScanRange  data type\nRequired: No\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<Payload> \n   <Records> \n      <Payload>blob</Payload> \n   </Records> \n   <Stats> \n      <Details> \n         < BytesProcessed >long</BytesProcessed > \n         < BytesReturned >long</BytesReturned > \n         < BytesScanned >long</BytesScanned > \n      </ Details> \nAmazon S3 API Version 2006-03-01 704Amazon Simple Storage Service API Reference\n   </Stats> \n   <Progress > \n      <Details> \n         < BytesProcessed >long</BytesProcessed > \n         < BytesReturned >long</BytesReturned > \n         < BytesScanned >long</BytesScanned > \n      </ Details> \n   </Progress > \n   <Cont> \n   </Cont> \n   <End> \n   </End>\n</Payload>\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nPayload\nRoot level tag for the Payload parameters.\nRequired: Yes\nCont\nThe Continuation Event.\nType: ContinuationEvent data type\nEnd\nThe End Event.\nType: EndEvent data type\nProgress\nThe Progress Event.\nType: ProgressEvent data type\nRecords\nThe Records Event.\nAmazon S3 API Version 2006-03-01 705Amazon Simple Storage Service API Reference\nType: RecordsEvent data type\nStats\nThe Stats Event.\nType: StatsEvent data type\nExamples\nExample 1: CSV object\nThe following select request retrieves all records from an object with data stored in CSV format. \nThe OutputSerialization element directs Amazon S3 to return results in CSV.\nYou can try di\ufb00erent queries in the Expression  element:\n\u2022Assuming that you are not using column headers, you can identify columns using positional \nheaders:\nSELECT s._1, s._2 FROM S3Object s WHERE s._3 > 100\n\u2022If you have column headers and you set the FileHeaderInfo  to Use, you can identify columns \nby name in the expression:\nSELECT s.Id, s.FirstName, s.SSN FROM S3Object s\n\u2022You can specify functions in the SQL expression:\nSELECT count(*) FROM S3Object s WHERE s._1 < 1\nPOST /exampleobject.csv?select&select-type=2 HTTP/1.1\nHost: examplebucket.s3.<Region>.amazonaws.com\nDate: Tue, 17 Oct 2017 01:49:52 GMT\nAuthorization: authorization string\nContent-Length: content length\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<SelectRequest> \n    <Expression>Select * from S3Object</Expression> \n    <ExpressionType>SQL</ExpressionType> \nAmazon S3 API Version 2006-03-01 706Amazon Simple Storage Service API Reference\n    <InputSerialization> \n        <CompressionType>GZIP</CompressionType> \n        <CSV> \n            <FileHeaderInfo>IGNORE</FileHeaderInfo> \n            <RecordDelimiter>\\n</RecordDelimiter> \n            <FieldDelimiter>,</FieldDelimiter> \n            <QuoteCharacter>\"</QuoteCharacter> \n            <QuoteEscapeCharacter>\"</QuoteEscapeCharacter> \n            <Comments>#</Comments> \n        </CSV> \n    </InputSerialization> \n    <OutputSerialization> \n        <CSV> \n            <QuoteFields>ASNEEDED</QuoteFields> \n            <RecordDelimiter>\\n</RecordDelimiter> \n            <FieldDelimiter>,</FieldDelimiter> \n            <QuoteCharacter>\"</QuoteCharacter> \n            <QuoteEscapeCharacter>\"</QuoteEscapeCharacter> \n        </CSV>                                \n    </OutputSerialization>\n</SelectRequest>  \n          \nExample\nThe following is a sample response.\nHTTP/1.1 200 OK\nx-amz-id-2: GFihv3y6+kE7KG11GEkQhU7/2/cHR3Yb2fCb2S04nxI423Dqwg2XiQ0B/\nUZlzYQvPiBlZNRcovw=\nx-amz-request-id: 9F341CD3C4BA79E0\nDate: Tue, 17 Oct 2017 23:54:05 GMT\nA series of messages \n          \nExample 2: JSON object\nThe following select request retrieves all records from an object with data stored in JSON format. \nThe OutputSerialization directs Amazon S3 to return results in CSV.\nYou can try di\ufb00erent queries in the Expression  element:\nAmazon S3 API Version 2006-03-01 707Amazon Simple Storage Service API Reference\n\u2022You can \ufb01lter by string comparison using record keys:\nSELECT s.country, s.city from S3Object s where s.city = 'Seattle'\n\u2022You can specify functions in the SQL expression:\nSELECT count(*) FROM S3Object s\nPOST /exampleobject.json?select&select-type=2 HTTP/1.1\nHost: examplebucket.s3.<Region>.amazonaws.com\nDate: Tue, 17 Oct 2017 01:49:52 GMT\nAuthorization: authorization string\nContent-Length: content length\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<SelectRequest> \n    <Expression>Select * from S3Object</Expression> \n    <ExpressionType>SQL</ExpressionType> \n    <InputSerialization> \n        <CompressionType>GZIP</CompressionType> \n        <JSON> \n            <Type>DOCUMENT</Type> \n        </JSON> \n    </InputSerialization> \n    <OutputSerialization> \n        <CSV> \n            <QuoteFields>ASNEEDED</QuoteFields> \n            <RecordDelimiter>\\n</RecordDelimiter> \n            <FieldDelimiter>,</FieldDelimiter> \n            <QuoteCharacter>\"</QuoteCharacter> \n            <QuoteEscapeCharacter>\"</QuoteEscapeCharacter> \n        </CSV>                                \n    </OutputSerialization>\n</SelectRequest>  \n          \nExample\nThe following is a sample response.\nAmazon S3 API Version 2006-03-01 708Amazon Simple Storage Service API Reference\nHTTP/1.1 200 OK\nx-amz-id-2: GFihv3y6+kE7KG11GEkQhU7/2/cHR3Yb2fCb2S04nxI423Dqwg2XiQ0B/\nUZlzYQvPiBlZNRcovw=\nx-amz-request-id: 9F341CD3C4BA79E0\nDate: Tue, 17 Oct 2017 23:54:05 GMT\nA series of messages \n          \nExample 3: Parquet object\n\u2022The InputSerialization  element describes the format of the data in the object that is being \nqueried. It must specify CSV, JSON , or Parquet .\n\u2022The OutputSerialization  element describes the format of the data that you want Amazon \nS3 to return in response to the query.", "It must specify CSV, JSON.", "Amazon S3 doesn't support \noutputting data in the Parquet  format.\n\u2022The format of the InputSerialization  doesn't need to match the format of the\nOutputSerialization . So, for example, you can specify JSON  in the InputSerialization\nand CSV in the OutputSerialization .\nPOST /exampleobject.parquet?select&select-type=2 HTTP/1.1\nHost: examplebucket.s3.<Region>.amazonaws.com\nDate: Tue, 17 Oct 2017 01:49:52 GMT\nAuthorization: authorization string\nContent-Length: content length\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<SelectRequest> \n    <Expression>Select * from S3Object</Expression> \n    <ExpressionType>SQL</ExpressionType> \n    <InputSerialization> \n        <CompressionType>NONE</CompressionType> \n        <Parquet> \n        </Parquet> \n    </InputSerialization> \n    <OutputSerialization> \n        <CSV> \n            <QuoteFields>ASNEEDED</QuoteFields> \n            <RecordDelimiter>\\n</RecordDelimiter> \nAmazon S3 API Version 2006-03-01 709Amazon Simple Storage Service API Reference\n            <FieldDelimiter>,</FieldDelimiter> \n            <QuoteCharacter>\"</QuoteCharacter> \n            <QuoteEscapeCharacter>\"</QuoteEscapeCharacter> \n        </CSV> \n    </OutputSerialization>\n</SelectRequest> \n          \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 710Amazon Simple Storage Service API Reference\nUploadPart\nService: Amazon S3\nUploads a part in a multipart upload.\nNote\nIn this operation, you provide new data as a part of an object in your request. However, \nyou have an option to specify your existing Amazon S3 object as a data source for the part \nyou are uploading.", "To upload a part from an existing object, you use the UploadPartCopy\noperation.\nYou must initiate a multipart upload (see CreateMultipartUpload) before you can upload any part.", "\nIn response to your initiate request, Amazon S3 returns an upload ID, a unique identi\ufb01er that you \nmust include in your upload part request.\nPart numbers can be any number from 1 to 10,000, inclusive.", "A part number uniquely identi\ufb01es \na part and also de\ufb01nes its position within the object being created.", "If you upload a new part \nusing the same part number that was used with a previous part, the previously uploaded part is \noverwritten.\nFor information about maximum and minimum part sizes and other multipart upload \nspeci\ufb01cations, see Multipart upload limits in the Amazon S3 User Guide .\nNote\nAfter you initiate multipart upload and upload one or more parts, you must either \ncomplete or abort multipart upload in order to stop getting charged for storage of the \nuploaded parts. Only after you either complete or abort multipart upload, Amazon S3 frees \nup the parts storage and stops charging you for the parts storage.\nFor more information on multipart uploads, go to Multipart Upload Overview in the Amazon S3 \nUser Guide .\nAmazon S3 API Version 2006-03-01 711Amazon Simple Storage Service API Reference\nNote\nDirectory buckets - For directory buckets, you must make requests for this API operation \nto the Zonal endpoint. These endpoints support virtual-hosted-style requests in the format\nhttps:// bucket_name .s3express- az_id.region.amazonaws.com/ key-name\n.", "Path-style requests are not supported.", "For more information, see Regional and Zonal \nendpoints  in the Amazon S3 User Guide .\nPermissions\n\u2022General purpose bucket permissions - To perform a multipart upload with encryption \nusing an AWS Key Management Service key, the requester must have permission to the\nkms:Decrypt  and kms:GenerateDataKey  actions on the key.", "The requester must also have \npermissions for the kms:GenerateDataKey  action for the CreateMultipartUpload  API.", "\nThen, the requester needs permissions for the kms:Decrypt  action on the UploadPart  and\nUploadPartCopy  APIs.\nThese permissions are required because Amazon S3 must decrypt and read data from the \nencrypted \ufb01le parts before it completes the multipart upload. For more information about \nKMS permissions, see Protecting data using server-side encryption with AWS KMS in the\nAmazon S3 User Guide .", "For information about the permissions required to use the multipart \nupload API, see Multipart upload and permissions and Multipart upload API and permissions\nin the Amazon S3 User Guide .\n\u2022Directory bucket permissions - To grant access to this API operation on a directory \nbucket, we recommend that you use the CreateSession  API operation for session-based \nauthorization. Speci\ufb01cally, you grant the s3express:CreateSession  permission to the \ndirectory bucket in a bucket policy or an IAM identity-based policy.", "Then, you make the\nCreateSession  API call on the bucket to obtain a session token. With the session token in \nyour request header, you can make API requests to this operation. After the session token \nexpires, you make another CreateSession  API call to generate a new session token for \nuse. AWS CLI or SDKs create session and refresh the session token automatically to avoid \nservice interruptions when a session expires.", "For more information about authorization, see\nCreateSession .\nIf the object is encrypted with SSE-KMS, you must also have the kms:GenerateDataKey  and\nkms:Decrypt  permissions in IAM identity-based policies and AWS KMS key policies for the \nAWS KMS key.\nAmazon S3 API Version 2006-03-01 712Amazon Simple Storage Service API Reference\nData integrity\nGeneral purpose bucket - To ensure that data is not corrupted traversing the network, specify \nthe Content-MD5  header in the upload part request.", "Amazon S3 checks the part data against \nthe provided MD5 value. If they do not match, Amazon S3 returns an error. If the upload \nrequest is signed with Signature Version 4, then AWS S3 uses the x-amz-content-sha256\nheader as a checksum instead of Content-MD5 .", "For more information see Authenticating \nRequests: Using the Authorization Header (AWS Signature Version 4).\nNote\nDirectory buckets - MD5 is not supported by directory buckets.", "You can use checksum \nalgorithms to check object integrity.\nEncryption\n\u2022General purpose bucket - Server-side encryption is for data encryption at rest.", "Amazon S3 \nencrypts your data as it writes it to disks in its data centers and decrypts it when you access it. \nYou have mutually exclusive options to protect data using server-side encryption in Amazon \nS3, depending on how you choose to manage the encryption keys. Speci\ufb01cally, the encryption \nkey options are Amazon S3 managed keys (SSE-S3), AWS KMS keys (SSE-KMS), and Customer-\nProvided Keys (SSE-C). Amazon S3 encrypts data with server-side encryption using Amazon \nS3 managed keys (SSE-S3) by default. You can optionally tell Amazon S3 to encrypt data \nat rest using server-side encryption with other key options. The option you use depends on \nwhether you want to use KMS keys (SSE-KMS) or provide your own encryption key (SSE-C).\nServer-side encryption is supported by the S3 Multipart Upload operations. Unless you are \nusing a customer-provided encryption key (SSE-C), you don't need to specify the encryption \nparameters in each UploadPart request. Instead, you only need to specify the server-side \nencryption parameters in the initial Initiate Multipart request. For more information, see\nCreateMultipartUpload.\nIf you request server-side encryption using a customer-provided encryption key (SSE-C) in \nyour initiate multipart upload request, you must provide identical encryption information in \neach part upload using the following request headers.\n\u2022x-amz-server-side-encryption-customer-algorithm\n\u2022x-amz-server-side-encryption-customer-key\nAmazon S3 API Version 2006-03-01 713Amazon Simple Storage Service API Reference\n\u2022x-amz-server-side-encryption-customer-key-MD5\nFor more information, see Using Server-Side Encryption in the Amazon S3 User Guide .\n\u2022Directory buckets  - For directory buckets, there are only two supported options for server-\nside encryption: server-side encryption with Amazon S3 managed keys (SSE-S3) (AES256 ) \nand server-side encryption with AWS KMS keys (SSE-KMS) (aws:kms ).\nSpecial errors\n\u2022Error Code: NoSuchUpload\n\u2022Description: The speci\ufb01ed multipart upload does not exist.", "The upload ID might be invalid, \nor the multipart upload might have been aborted or completed.\n\u2022HTTP Status Code: 404 Not Found\n\u2022SOAP Fault Code Pre\ufb01x: Client\nHTTP Host header syntax\nDirectory buckets  - The HTTP Host header syntax is \nBucket_name .s3express- az_id.region.amazonaws.com .\nThe following operations are related to UploadPart :\n\u2022CreateMultipartUpload\n\u2022CompleteMultipartUpload\n\u2022AbortMultipartUpload\n\u2022ListParts\n\u2022ListMultipartUploads\nRequest Syntax\nPUT /Key+?partNumber= PartNumber &uploadId= UploadId  HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nContent-Length: ContentLength\nContent-MD5: ContentMD5\nx-amz-sdk-checksum-algorithm: ChecksumAlgorithm\nx-amz-checksum-crc32: ChecksumCRC32\nx-amz-checksum-crc32c: ChecksumCRC32C\nx-amz-checksum-sha1: ChecksumSHA1\nx-amz-checksum-sha256: ChecksumSHA256\nAmazon S3 API Version 2006-03-01 714Amazon Simple Storage Service API Reference\nx-amz-server-side-encryption-customer-algorithm: SSECustomerAlgorithm\nx-amz-server-side-encryption-customer-key: SSECustomerKey\nx-amz-server-side-encryption-customer-key-MD5: SSECustomerKeyMD5\nx-amz-request-payer: RequestPayer\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nBody\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe name of the bucket to which the multipart upload was initiated.\nDirectory buckets - When you use this operation with a directory \nbucket, you must use virtual-hosted-style requests in the format \nBucket_name .s3express- az_id.region.amazonaws.com .", "Path-style requests are not \nsupported.", "Directory bucket names must be unique in the chosen Availability Zone.", "Bucket \nnames must follow the format  bucket_base_name --az-id--x-s3  (for example,  DOC-\nEXAMPLE-BUCKET --usw2-az1 --x-s3). For information about bucket naming restrictions, see\nDirectory bucket naming rules in the Amazon S3 User Guide .\nAccess points - When you use this action with an access point, you must provide the alias of the \naccess point in place of the bucket name or specify the access point ARN.", "When using the access \npoint ARN, you must direct requests to the access point hostname.", "The access point hostname \ntakes the form AccessPointName-AccountId .s3-accesspoint.Region.amazonaws.com.", "When using \nthis action with an access point through the AWS SDKs, you provide the access point ARN in \nplace of the bucket name. For more information about access point ARNs, see Using access \npoints  in the Amazon S3 User Guide .\nNote\nAccess points and Object Lambda access points are not supported by directory buckets.\nS3 on Outposts  - When you use this action with Amazon S3 on Outposts, you must direct \nrequests to the S3 on Outposts hostname. The S3 on Outposts hostname takes the form \nAccessPointName -AccountId .outpostID .s3-outposts.", "Region.amazonaws.com .", "\nAmazon S3 API Version 2006-03-01 715Amazon Simple Storage Service API Reference\nWhen you use this action with S3 on Outposts through the AWS SDKs, you provide the Outposts \naccess point ARN in place of the bucket name. For more information about S3 on Outposts \nARNs, see What is S3 on Outposts?", "in the Amazon S3 User Guide .\nRequired: Yes\nContent-Length\nSize of the body in bytes.", "This parameter is useful when the size of the body cannot be \ndetermined automatically.\nContent-MD5\nThe base64-encoded 128-bit MD5 digest of the part data.", "This parameter is auto-populated \nwhen using the command from the CLI.", "This parameter is required if object lock parameters are \nspeci\ufb01ed.\nNote\nThis functionality is not supported for directory buckets.\nKey\nObject key for which the multipart upload was initiated.\nLength Constraints: Minimum length of 1.\nRequired: Yes\npartNumber\nPart number of part being uploaded. This is a positive integer between 1 and 10,000.\nRequired: Yes\nuploadId\nUpload ID identifying the multipart upload whose part is being uploaded.\nRequired: Yes\nx-amz-checksum-crc32\nThis header can be used as a data integrity check to verify that the data received is the same \ndata that was originally sent.", "This header speci\ufb01es the base64-encoded, 32-bit CRC-32 \nAmazon S3 API Version 2006-03-01 716Amazon Simple Storage Service API Reference\nchecksum of the object. For more information, see Checking object integrity in the Amazon S3 \nUser Guide .\nx-amz-checksum-crc32c\nThis header can be used as a data integrity check to verify that the data received is the same \ndata that was originally sent.", "This header speci\ufb01es the base64-encoded, 32-bit CRC-32C \nchecksum of the object.", "For more information, see Checking object integrity in the Amazon S3 \nUser Guide .\nx-amz-checksum-sha1\nThis header can be used as a data integrity check to verify that the data received is the same \ndata that was originally sent.", "This header speci\ufb01es the base64-encoded, 160-bit SHA-1 digest \nof the object.", "For more information, see Checking object integrity in the Amazon S3 User Guide .\nx-amz-checksum-sha256\nThis header can be used as a data integrity check to verify that the data received is the same \ndata that was originally sent.", "This header speci\ufb01es the base64-encoded, 256-bit SHA-256 digest \nof the object.", "For more information, see Checking object integrity in the Amazon S3 User Guide .\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner.", "If the account ID that you provide does not match \nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nx-amz-request-payer\nCon\ufb01rms that the requester knows that they will be charged for the request. Bucket owners \nneed not specify this parameter in their requests.", "If either the source or destination S3 \nbucket has Requester Pays enabled, the requester will pay for corresponding charges to copy \nthe object. For information about downloading objects from Requester Pays buckets, see\nDownloading Objects in Requester Pays Buckets in the Amazon S3 User Guide .\nNote\nThis functionality is not supported for directory buckets.\nValid Values: requester\nAmazon S3 API Version 2006-03-01 717Amazon Simple Storage Service API Reference\nx-amz-sdk-checksum-algorithm\nIndicates the algorithm used to create the checksum for the object when you use the SDK.", "This \nheader will not provide any additional functionality if you don't use the SDK.", "When you send \nthis header, there must be a corresponding x-amz-checksum  or x-amz-trailer  header sent.", "\nOtherwise, Amazon S3 fails the request with the HTTP status code 400 Bad Request . For \nmore information, see Checking object integrity in the Amazon S3 User Guide .\nIf you provide an individual checksum, Amazon S3 ignores any provided ChecksumAlgorithm\nparameter.\nThis checksum algorithm must be the same for all parts and it match the checksum value \nsupplied in the CreateMultipartUpload  request.\nValid Values: CRC32 | CRC32C | SHA1 | SHA256\nx-amz-server-side-encryption-customer-algorithm\nSpeci\ufb01es the algorithm to use when encrypting the object (for example, AES256).\nNote\nThis functionality is not supported for directory buckets.\nx-amz-server-side-encryption-customer-key\nSpeci\ufb01es the customer-provided encryption key for Amazon S3 to use in encrypting data. \nThis value is used to store the object and then it is discarded; Amazon S3 does not store the \nencryption key.", "The key must be appropriate for use with the algorithm speci\ufb01ed in the x-\namz-server-side-encryption-customer-algorithm header .", "This must be the same \nencryption key speci\ufb01ed in the initiate multipart upload request.\nNote\nThis functionality is not supported for directory buckets.\nAmazon S3 API Version 2006-03-01 718Amazon Simple Storage Service API Reference\nx-amz-server-side-encryption-customer-key-MD5\nSpeci\ufb01es the 128-bit MD5 digest of the encryption key according to RFC 1321. Amazon S3 uses \nthis header for a message integrity check to ensure that the encryption key was transmitted \nwithout error.\nNote\nThis functionality is not supported for directory buckets.\nRequest Body\nThe request accepts the following binary data.\nBody\nResponse Syntax\nHTTP/1.1 200\nx-amz-server-side-encryption: ServerSideEncryption\nETag: ETag\nx-amz-checksum-crc32: ChecksumCRC32\nx-amz-checksum-crc32c: ChecksumCRC32C\nx-amz-checksum-sha1: ChecksumSHA1\nx-amz-checksum-sha256: ChecksumSHA256\nx-amz-server-side-encryption-customer-algorithm: SSECustomerAlgorithm\nx-amz-server-side-encryption-customer-key-MD5: SSECustomerKeyMD5\nx-amz-server-side-encryption-aws-kms-key-id: SSEKMSKeyId\nx-amz-server-side-encryption-bucket-key-enabled: BucketKeyEnabled\nx-amz-request-charged: RequestCharged\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe response returns the following HTTP headers.\nETag\nEntity tag for the uploaded object.\nAmazon S3 API Version 2006-03-01 719Amazon Simple Storage Service API Reference\nx-amz-checksum-crc32\nThe base64-encoded, 32-bit CRC-32 checksum of the object.", "This will only be present if it was \nuploaded with the object. When you use an API operation on an object that was uploaded using \nmultipart uploads, this value may not be a direct checksum value of the full object. Instead, \nit's a calculation based on the checksum values of each individual part.", "For more information \nabout how checksums are calculated with multipart uploads, see  Checking object integrity in \nthe Amazon S3 User Guide .\nx-amz-checksum-crc32c\nThe base64-encoded, 32-bit CRC-32C checksum of the object.", "This will only be present if it was \nuploaded with the object. When you use an API operation on an object that was uploaded using \nmultipart uploads, this value may not be a direct checksum value of the full object. Instead, \nit's a calculation based on the checksum values of each individual part.", "For more information \nabout how checksums are calculated with multipart uploads, see  Checking object integrity in \nthe Amazon S3 User Guide .\nx-amz-checksum-sha1\nThe base64-encoded, 160-bit SHA-1 digest of the object.", "This will only be present if it was \nuploaded with the object. When you use the API operation on an object that was uploaded \nusing multipart uploads, this value may not be a direct checksum value of the full object.", "\nInstead, it's a calculation based on the checksum values of each individual part.", "For more \ninformation about how checksums are calculated with multipart uploads, see  Checking object \nintegrity in the Amazon S3 User Guide .\nx-amz-checksum-sha256\nThe base64-encoded, 256-bit SHA-256 digest of the object.", "This will only be present if it was \nuploaded with the object. When you use an API operation on an object that was uploaded using \nmultipart uploads, this value may not be a direct checksum value of the full object. Instead, \nit's a calculation based on the checksum values of each individual part.", "For more information \nabout how checksums are calculated with multipart uploads, see  Checking object integrity in \nthe Amazon S3 User Guide .\nx-amz-request-charged\nIf present, indicates that the requester was successfully charged for the request.\nAmazon S3 API Version 2006-03-01 720Amazon Simple Storage Service API Reference\nNote\nThis functionality is not supported for directory buckets.\nValid Values: requester\nx-amz-server-side-encryption\nThe server-side encryption algorithm used when you store this object in Amazon S3 (for \nexample, AES256 , aws:kms ).\nValid Values: AES256 | aws:kms | aws:kms:dsse\nx-amz-server-side-encryption-aws-kms-key-id\nIf present, indicates the ID of the KMS key that was used for object encryption.\nx-amz-server-side-encryption-bucket-key-enabled\nIndicates whether the multipart upload uses an S3 Bucket Key for server-side encryption with \nAWS Key Management Service (AWS KMS) keys (SSE-KMS).\nx-amz-server-side-encryption-customer-algorithm\nIf server-side encryption with a customer-provided encryption key was requested, the response \nwill include this header to con\ufb01rm the encryption algorithm that's used.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-server-side-encryption-customer-key-MD5\nIf server-side encryption with a customer-provided encryption key was requested, the \nresponse will include this header to provide the round-trip message integrity veri\ufb01cation of the \ncustomer-provided encryption key.\nNote\nThis functionality is not supported for directory buckets.\nAmazon S3 API Version 2006-03-01 721Amazon Simple Storage Service API Reference\nExamples\nSample Request for general purpose buckets\nThe following PUT request uploads a part (part number 1) in a multipart upload. The request \nincludes the upload ID that you get in response to your Initiate Multipart Upload request.\nPUT /my-movie.m2ts?\npartNumber=1&uploadId=VCVsb2FkIElEIGZvciBlbZZpbmcncyBteS1tb3ZpZS5tMnRzIHVwbG9hZR \n HTTP/1.1\nHost: example-bucket.s3.<Region>.amazonaws.com\nDate:  Mon, 1 Nov 2010 20:34:56 GMT\nContent-Length: 10485760\nContent-MD5: pUNXr/BjKK5G2UKvaRRrOA==\nAuthorization: authorization string\n***part data omitted*** \n          \nSample Response for general purpose buckets\nThe response includes the ETag header. You need to retain this value for use when you send the \nComplete Multipart Upload request.\nHTTP/1.1 200 OK\nx-amz-id-2: Vvag1LuByRx9e6j5Onimru9pO4ZVKnJ2Qz7/C1NPcfTWAtRPfTaOFg==\nx-amz-request-id: 656c76696e6727732072657175657374\nDate:  Mon, 1 Nov 2010 20:34:56 GMT\nETag: \"b54357faf0632cce46e942fa68356b38\"\nContent-Length: 0\nConnection: keep-alive\nServer: AmazonS3 \n          \nExample for general purpose buckets: Upload a part with an encryption key in the request for \nserver-side encryption\nIf you initiated a multipart upload with a request to save an object using server-side encryption \nwith a customer-provided encryption key, each part upload must also include the same set of \nencryption-speci\ufb01c headers as shown in the following example request.\nAmazon S3 API Version 2006-03-01 722Amazon Simple Storage Service API Reference\nPUT /example-object?\npartNumber=1&uploadId=EXAMPLEJZ6e0YupT2h66iePQCc9IEbYbDUy4RTpMeoSMLPRp8Z5o1u8feSRonpvnWsKKG35tI2LB9VDPiCgTy.Gq2VxQLYjrue4Nq.NBdqI- \n HTTP/1.1\nHost: example-bucket.s3.<Region>.amazonaws.com\nAuthorization: authorization string    \nDate: Wed, 28 May 2014 19:40:11 +0000    \nx-amz-server-side-encryption-customer-key: g0lCfA3Dv40jZz5SQJ1ZukLRFqtI5WorC/8SEEXAMPLE \n    \nx-amz-server-side-encryption-customer-key-MD5: ZjQrne1X/iTcskbY2example    \nx-amz-server-side-encryption-customer-algorithm: AES256    \n          \nExample for general purpose buckets\nIn the response, Amazon S3 returns encryption-speci\ufb01c headers providing the encryption algorithm \nused and MD5 digest of the encryption key you provided in the request.\nHTTP/1.1 100 Continue   HTTP/1.1 200 OK\nx-amz-id-2: Zn8bf8aEFQ+kBnGPBc/JaAf9SoWM68QDPS9+SyFwkIZOHUG2BiRLZi5oXw4cOCEt\nx-amz-request-id: 5A37448A37622243\nDate: Wed, 28 May 2014 19:40:12 GMT\nETag: \"7e10e7d25dc4581d89b9285be5f384fd\"\nx-amz-server-side-encryption-customer-algorithm: AES256\nx-amz-server-side-encryption-customer-key-MD5: ZjQrne1X/iTcskbY2example     \n          \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\nAmazon S3 API Version 2006-03-01 723Amazon Simple Storage Service API Reference\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 724Amazon Simple Storage Service API Reference\nUploadPartCopy\nService: Amazon S3\nUploads a part by copying data from an existing object as data source. To specify the data source, \nyou add the request header x-amz-copy-source  in your request.", "To specify a byte range, you \nadd the request header x-amz-copy-source-range  in your request.\nFor information about maximum and minimum part sizes and other multipart upload \nspeci\ufb01cations, see Multipart upload limits in the Amazon S3 User Guide .\nNote\nInstead of copying data from an existing object as part data, you might use the UploadPart\naction to upload new data as a part of an object in your request.\nYou must initiate a multipart upload before you can upload any part. In response to your initiate \nrequest, Amazon S3 returns the upload ID, a unique identi\ufb01er that you must include in your upload \npart request.\nFor conceptual information about multipart uploads, see Uploading Objects Using Multipart \nUpload  in the Amazon S3 User Guide .", "For information about copying objects using a single atomic \naction vs.", "a multipart upload, see Operations on Objects in the Amazon S3 User Guide .\nNote\nDirectory buckets - For directory buckets, you must make requests for this API operation \nto the Zonal endpoint. These endpoints support virtual-hosted-style requests in the format\nhttps:// bucket_name .s3express- az_id.region.amazonaws.com/ key-name\n.", "Path-style requests are not supported.", "For more information, see Regional and Zonal \nendpoints  in the Amazon S3 User Guide .\nAuthentication and authorization\nAll UploadPartCopy  requests must be authenticated and signed by using IAM credentials \n(access key ID and secret access key for the IAM identities).", "All headers with the x-amz-\npre\ufb01x, including x-amz-copy-source , must be signed.", "For more information, see REST \nAuthentication .\nAmazon S3 API Version 2006-03-01 725Amazon Simple Storage Service API Reference\nDirectory buckets - You must use IAM credentials to authenticate and authorize your access \nto the UploadPartCopy  API operation, instead of using the temporary security credentials \nthrough the CreateSession  API operation.\nAWS CLI or SDKs handles authentication and authorization on your behalf.\nPermissions\nYou must have READ access to the source object and WRITE access to the destination bucket.\n\u2022General purpose bucket permissions - You must have the permissions in a policy based \non the bucket types of your source bucket and destination bucket in an UploadPartCopy\noperation.\n\u2022If the source object is in a general purpose bucket, you must have the  s3:GetObject  \npermission to read the source object that is being copied.\n\u2022If the destination bucket is a general purpose bucket, you must have the  s3:PutObject  \npermission to write the object copy to the destination bucket.\n\u2022To perform a multipart upload with encryption using an AWS Key Management \nService key, the requester must have permission to the kms:Decrypt  and\nkms:GenerateDataKey  actions on the key.", "The requester must also have permissions \nfor the kms:GenerateDataKey  action for the CreateMultipartUpload  API. Then, \nthe requester needs permissions for the kms:Decrypt  action on the UploadPart  and\nUploadPartCopy  APIs.", "These permissions are required because Amazon S3 must decrypt \nand read data from the encrypted \ufb01le parts before it completes the multipart upload. For \nmore information about KMS permissions, see Protecting data using server-side encryption \nwith AWS KMS in the Amazon S3 User Guide .", "For information about the permissions \nrequired to use the multipart upload API, see Multipart upload and permissions and\nMultipart upload API and permissions in the Amazon S3 User Guide .\n\u2022Directory bucket permissions - You must have permissions in a bucket policy or an \nIAM identity-based policy based on the source and destination bucket types in an\nUploadPartCopy  operation.\n\u2022If the source object that you want to copy is in a directory bucket, you must have the \ns3express:CreateSession   permission in the Action element of a policy to read the \nobject.", "By default, the session is in the ReadWrite  mode.", "If you want to restrict the access, \nyou can explicitly set the s3express:SessionMode  condition key to ReadOnly  on the \ncopy source bucket.\n\u2022If the copy destination is a directory bucket, you must have the \ns3express:CreateSession   permission in the Action element of a policy to write the \nAmazon S3 API Version 2006-03-01 726Amazon Simple Storage Service API Reference\nobject to the destination. The s3express:SessionMode  condition key cannot be set to\nReadOnly  on the copy destination.\nIf the object is encrypted with SSE-KMS, you must also have the kms:GenerateDataKey  and\nkms:Decrypt  permissions in IAM identity-based policies and AWS KMS key policies for the \nAWS KMS key.\nFor example policies, see Example bucket policies for S3 Express One Zone and AWS Identity \nand Access Management (IAM) identity-based policies for S3 Express One Zone in the Amazon \nS3 User Guide .\nEncryption\n\u2022General purpose buckets  - For information about using server-side encryption with \ncustomer-provided encryption keys with the UploadPartCopy  operation, see CopyObject\nand UploadPart.\n\u2022Directory buckets  - For directory buckets, there are only two supported options for server-\nside encryption: server-side encryption with Amazon S3 managed keys (SSE-S3) (AES256 ) \nand server-side encryption with AWS KMS keys (SSE-KMS) (aws:kms). For more information, \nsee Protecting data with server-side encryption in the Amazon S3 User Guide .\nNote\nFor directory buckets, when you perform a CreateMultipartUpload  operation \nand an UploadPartCopy  operation, the request headers you provide in the\nCreateMultipartUpload  request must match the default encryption con\ufb01guration \nof the destination bucket.\nS3 Bucket Keys aren't supported, when you copy SSE-KMS encrypted objects from general \npurpose buckets to directory buckets, from directory buckets to general purpose buckets, or \nbetween directory buckets, through UploadPartCopy. In this case, Amazon S3 makes a call to \nAWS KMS every time a copy request is made for a KMS-encrypted object.\nSpecial errors\n\u2022Error Code: NoSuchUpload\n\u2022Description: The speci\ufb01ed multipart upload does not exist. The upload ID might be invalid, \nor the multipart upload might have been aborted or completed.\n\u2022HTTP Status Code: 404 Not Found\nAmazon S3 API Version 2006-03-01 727Amazon Simple Storage Service API Reference\n\u2022Error Code: InvalidRequest\n\u2022Description: The speci\ufb01ed copy source is not supported as a byte-range copy source.\n\u2022HTTP Status Code: 400 Bad Request\nHTTP Host header syntax\nDirectory buckets  - The HTTP Host header syntax is \nBucket_name .s3express- az_id.region.amazonaws.com .\nThe following operations are related to UploadPartCopy :\n\u2022CreateMultipartUpload\n\u2022UploadPart\n\u2022CompleteMultipartUpload\n\u2022AbortMultipartUpload\n\u2022ListParts\n\u2022ListMultipartUploads\nRequest Syntax\nPUT /Key+?partNumber= PartNumber &uploadId= UploadId  HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-copy-source: CopySource\nx-amz-copy-source-if-match: CopySourceIfMatch\nx-amz-copy-source-if-modified-since: CopySourceIfModifiedSince\nx-amz-copy-source-if-none-match: CopySourceIfNoneMatch\nx-amz-copy-source-if-unmodified-since: CopySourceIfUnmodifiedSince\nx-amz-copy-source-range: CopySourceRange\nx-amz-server-side-encryption-customer-algorithm: SSECustomerAlgorithm\nx-amz-server-side-encryption-customer-key: SSECustomerKey\nx-amz-server-side-encryption-customer-key-MD5: SSECustomerKeyMD5\nx-amz-copy-source-server-side-encryption-customer-\nalgorithm: CopySourceSSECustomerAlgorithm\nx-amz-copy-source-server-side-encryption-customer-key: CopySourceSSECustomerKey\nx-amz-copy-source-server-side-encryption-customer-key-MD5: CopySourceSSECustomerKeyMD5\nx-amz-request-payer: RequestPayer\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nx-amz-source-expected-bucket-owner: ExpectedSourceBucketOwner\nAmazon S3 API Version 2006-03-01 728Amazon Simple Storage Service API Reference\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe bucket name.\nDirectory buckets - When you use this operation with a directory \nbucket, you must use virtual-hosted-style requests in the format \nBucket_name .s3express- az_id.region.amazonaws.com .", "Path-style requests are not \nsupported.", "Directory bucket names must be unique in the chosen Availability Zone.", "Bucket \nnames must follow the format  bucket_base_name --az-id--x-s3  (for example,  DOC-\nEXAMPLE-BUCKET --usw2-az1 --x-s3). For information about bucket naming restrictions, see\nDirectory bucket naming rules in the Amazon S3 User Guide .\nAccess points - When you use this action with an access point, you must provide the alias of the \naccess point in place of the bucket name or specify the access point ARN.", "When using the access \npoint ARN, you must direct requests to the access point hostname.", "The access point hostname \ntakes the form AccessPointName-AccountId .s3-accesspoint.Region.amazonaws.com.", "When using \nthis action with an access point through the AWS SDKs, you provide the access point ARN in \nplace of the bucket name. For more information about access point ARNs, see Using access \npoints  in the Amazon S3 User Guide .\nNote\nAccess points and Object Lambda access points are not supported by directory buckets.\nS3 on Outposts  - When you use this action with Amazon S3 on Outposts, you must direct \nrequests to the S3 on Outposts hostname. The S3 on Outposts hostname takes the form \nAccessPointName -AccountId .outpostID .s3-outposts.", "Region.amazonaws.com .", "\nWhen you use this action with S3 on Outposts through the AWS SDKs, you provide the Outposts \naccess point ARN in place of the bucket name. For more information about S3 on Outposts \nARNs, see What is S3 on Outposts?", "in the Amazon S3 User Guide .\nRequired: Yes\nKey\nObject key for which the multipart upload was initiated.\nAmazon S3 API Version 2006-03-01 729Amazon Simple Storage Service API Reference\nLength Constraints: Minimum length of 1.\nRequired: Yes\npartNumber\nPart number of part being copied.", "This is a positive integer between 1 and 10,000.\nRequired: Yes\nuploadId\nUpload ID identifying the multipart upload whose part is being copied.\nRequired: Yes\nx-amz-copy-source\nSpeci\ufb01es the source object for the copy operation.", "You specify the value in one of two formats, \ndepending on whether you want to access the source object through an access point:\n\u2022For objects not accessed through an access point, specify the name of the source bucket and \nkey of the source object, separated by a slash (/).", "For example, to copy the object reports/\njanuary.pdf  from the bucket awsexamplebucket , use awsexamplebucket/reports/\njanuary.pdf .", "The value must be URL-encoded.\n\u2022For objects accessed through access points, specify the Amazon Resource \nName (ARN) of the object as accessed through the access point, in the format\narn:aws:s3:<Region>:<account-id>:accesspoint/<access-point-name>/\nobject/<key> . For example, to copy the object reports/january.pdf  through access \npoint my-access-point  owned by account 123456789012  in Region us-west-2 , use the \nURL encoding of arn:aws:s3:us-west-2:123456789012:accesspoint/my-access-\npoint/object/reports/january.pdf .", "The value must be URL encoded.\nNote\n\u2022Amazon S3 supports copy operations using Access points only when the source and \ndestination buckets are in the same AWS Region.\n\u2022Access points are not supported by directory buckets.\nAlternatively, for objects accessed through Amazon S3 on Outposts, specify the ARN of \nthe object as accessed in the format arn:aws:s3-outposts:<Region>:<account-\nAmazon S3 API Version 2006-03-01 730Amazon Simple Storage Service API Reference\nid>:outpost/<outpost-id>/object/<key> . For example, to copy the object\nreports/january.pdf  through outpost my-outpost  owned by account 123456789012\nin Region us-west-2 , use the URL encoding of arn:aws:s3-outposts:us-\nwest-2:123456789012:outpost/my-outpost/object/reports/january.pdf .", "The \nvalue must be URL-encoded.\nIf your bucket has versioning enabled, you could have multiple versions of the same \nobject.", "By default, x-amz-copy-source  identi\ufb01es the current version of the source \nobject to copy.", "To copy a speci\ufb01c version of the source object to copy, append ?\nversionId=<version-id>  to the x-amz-copy-source  request header (for \nexample, x-amz-copy-source: /awsexamplebucket/reports/january.pdf?\nversionId=QUpfdndhfd8438MNFDN93jdnJFkdmqnh893 ).\nIf the current version is a delete marker and you don't specify a versionId in the x-amz-copy-\nsource request header, Amazon S3 returns a 404 Not Found  error, because the object does \nnot exist. If you specify versionId in the x-amz-copy-source  and the versionId is a delete \nmarker, Amazon S3 returns an HTTP 400 Bad Request  error, because you are not allowed to \nspecify a delete marker as a version for the x-amz-copy-source .\nNote\nDirectory buckets - S3 Versioning isn't enabled and supported for directory buckets.\nPattern: \\/.+\\/.+\nRequired: Yes\nx-amz-copy-source-if-match\nCopies the object if its entity tag (ETag) matches the speci\ufb01ed tag.\nIf both of the x-amz-copy-source-if-match  and x-amz-copy-source-if-unmodified-\nsince headers are present in the request as follows:\nx-amz-copy-source-if-match  condition evaluates to true , and;\nx-amz-copy-source-if-unmodified-since  condition evaluates to false ;\nAmazon S3 returns 200 OK and copies the data.\nAmazon S3 API Version 2006-03-01 731Amazon Simple Storage Service API Reference\nx-amz-copy-source-if-modi\ufb01ed-since\nCopies the object if it has been modi\ufb01ed since the speci\ufb01ed time.\nIf both of the x-amz-copy-source-if-none-match  and x-amz-copy-source-if-\nmodified-since  headers are present in the request as follows:\nx-amz-copy-source-if-none-match  condition evaluates to false , and;\nx-amz-copy-source-if-modified-since  condition evaluates to true ;\nAmazon S3 returns 412 Precondition Failed  response code.\nx-amz-copy-source-if-none-match\nCopies the object if its entity tag (ETag) is di\ufb00erent than the speci\ufb01ed ETag.\nIf both of the x-amz-copy-source-if-none-match  and x-amz-copy-source-if-\nmodified-since  headers are present in the request as follows:\nx-amz-copy-source-if-none-match  condition evaluates to false , and;\nx-amz-copy-source-if-modified-since  condition evaluates to true ;\nAmazon S3 returns 412 Precondition Failed  response code.\nx-amz-copy-source-if-unmodi\ufb01ed-since\nCopies the object if it hasn't been modi\ufb01ed since the speci\ufb01ed time.\nIf both of the x-amz-copy-source-if-match  and x-amz-copy-source-if-unmodified-\nsince headers are present in the request as follows:\nx-amz-copy-source-if-match  condition evaluates to true , and;\nx-amz-copy-source-if-unmodified-since  condition evaluates to false ;\nAmazon S3 returns 200 OK and copies the data.\nx-amz-copy-source-range\nThe range of bytes to copy from the source object.", "The range value must use the form \nbytes=\ufb01rst-last, where the \ufb01rst and last are the zero-based byte o\ufb00sets to copy. For example, \nbytes=0-9 indicates that you want to copy the \ufb01rst 10 bytes of the source.", "You can copy a range \nonly if the source object is greater than 5 MB.\nAmazon S3 API Version 2006-03-01 732Amazon Simple Storage Service API Reference\nx-amz-copy-source-server-side-encryption-customer-algorithm\nSpeci\ufb01es the algorithm to use when decrypting the source object (for example, AES256 ).\nNote\nThis functionality is not supported when the source object is in a directory bucket.\nx-amz-copy-source-server-side-encryption-customer-key\nSpeci\ufb01es the customer-provided encryption key for Amazon S3 to use to decrypt the source \nobject. The encryption key provided in this header must be one that was used when the source \nobject was created.\nNote\nThis functionality is not supported when the source object is in a directory bucket.\nx-amz-copy-source-server-side-encryption-customer-key-MD5\nSpeci\ufb01es the 128-bit MD5 digest of the encryption key according to RFC 1321.", "Amazon S3 uses \nthis header for a message integrity check to ensure that the encryption key was transmitted \nwithout error.\nNote\nThis functionality is not supported when the source object is in a directory bucket.\nx-amz-expected-bucket-owner\nThe account ID of the expected destination bucket owner.", "If the account ID that you provide \ndoes not match the actual owner of the destination bucket, the request fails with the HTTP \nstatus code 403 Forbidden  (access denied).\nx-amz-request-payer\nCon\ufb01rms that the requester knows that they will be charged for the request. Bucket owners \nneed not specify this parameter in their requests.", "If either the source or destination S3 \nAmazon S3 API Version 2006-03-01 733Amazon Simple Storage Service API Reference\nbucket has Requester Pays enabled, the requester will pay for corresponding charges to copy \nthe object. For information about downloading objects from Requester Pays buckets, see\nDownloading Objects in Requester Pays Buckets in the Amazon S3 User Guide .\nNote\nThis functionality is not supported for directory buckets.\nValid Values: requester\nx-amz-server-side-encryption-customer-algorithm\nSpeci\ufb01es the algorithm to use when encrypting the object (for example, AES256).\nNote\nThis functionality is not supported when the destination bucket is a directory bucket.\nx-amz-server-side-encryption-customer-key\nSpeci\ufb01es the customer-provided encryption key for Amazon S3 to use in encrypting data. \nThis value is used to store the object and then it is discarded; Amazon S3 does not store the \nencryption key.", "The key must be appropriate for use with the algorithm speci\ufb01ed in the x-\namz-server-side-encryption-customer-algorithm  header. This must be the same \nencryption key speci\ufb01ed in the initiate multipart upload request.\nNote\nThis functionality is not supported when the destination bucket is a directory bucket.\nx-amz-server-side-encryption-customer-key-MD5\nSpeci\ufb01es the 128-bit MD5 digest of the encryption key according to RFC 1321.", "Amazon S3 uses \nthis header for a message integrity check to ensure that the encryption key was transmitted \nwithout error.\nAmazon S3 API Version 2006-03-01 734Amazon Simple Storage Service API Reference\nNote\nThis functionality is not supported when the destination bucket is a directory bucket.\nx-amz-source-expected-bucket-owner\nThe account ID of the expected source bucket owner. If the account ID that you provide does not \nmatch the actual owner of the source bucket, the request fails with the HTTP status code 403 \nForbidden  (access denied).\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\nx-amz-copy-source-version-id: CopySourceVersionId\nx-amz-server-side-encryption: ServerSideEncryption\nx-amz-server-side-encryption-customer-algorithm: SSECustomerAlgorithm\nx-amz-server-side-encryption-customer-key-MD5: SSECustomerKeyMD5\nx-amz-server-side-encryption-aws-kms-key-id: SSEKMSKeyId\nx-amz-server-side-encryption-bucket-key-enabled: BucketKeyEnabled\nx-amz-request-charged: RequestCharged\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<CopyPartResult > \n   <ETag>string</ETag> \n   <LastModified >timestamp </LastModified > \n   <ChecksumCRC32 >string</ChecksumCRC32 > \n   <ChecksumCRC32C >string</ChecksumCRC32C > \n   <ChecksumSHA1 >string</ChecksumSHA1 > \n   <ChecksumSHA256 >string</ChecksumSHA256 >\n</CopyPartResult >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe response returns the following HTTP headers.\nAmazon S3 API Version 2006-03-01 735Amazon Simple Storage Service API Reference\nx-amz-copy-source-version-id\nThe version of the source object that was copied, if you have enabled versioning on the source \nbucket.\nNote\nThis functionality is not supported when the source object is in a directory bucket.\nx-amz-request-charged\nIf present, indicates that the requester was successfully charged for the request.\nNote\nThis functionality is not supported for directory buckets.\nValid Values: requester\nx-amz-server-side-encryption\nThe server-side encryption algorithm used when you store this object in Amazon S3 (for \nexample, AES256 , aws:kms ).\nValid Values: AES256 | aws:kms | aws:kms:dsse\nx-amz-server-side-encryption-aws-kms-key-id\nIf present, indicates the ID of the KMS key that was used for object encryption.\nx-amz-server-side-encryption-bucket-key-enabled\nIndicates whether the multipart upload uses an S3 Bucket Key for server-side encryption with \nAWS Key Management Service (AWS KMS) keys (SSE-KMS).\nx-amz-server-side-encryption-customer-algorithm\nIf server-side encryption with a customer-provided encryption key was requested, the response \nwill include this header to con\ufb01rm the encryption algorithm that's used.\nAmazon S3 API Version 2006-03-01 736Amazon Simple Storage Service API Reference\nNote\nThis functionality is not supported for directory buckets.\nx-amz-server-side-encryption-customer-key-MD5\nIf server-side encryption with a customer-provided encryption key was requested, the \nresponse will include this header to provide the round-trip message integrity veri\ufb01cation of the \ncustomer-provided encryption key.\nNote\nThis functionality is not supported for directory buckets.\nThe following data is returned in XML format by the service.\nCopyPartResult\nRoot level tag for the CopyPartResult parameters.\nRequired: Yes\nChecksumCRC32\nThe base64-encoded, 32-bit CRC-32 checksum of the object.", "This will only be present if it was \nuploaded with the object. When you use an API operation on an object that was uploaded using \nmultipart uploads, this value may not be a direct checksum value of the full object. Instead, \nit's a calculation based on the checksum values of each individual part.", "For more information \nabout how checksums are calculated with multipart uploads, see  Checking object integrity in \nthe Amazon S3 User Guide .\nType: String\nChecksumCRC32C\nThe base64-encoded, 32-bit CRC-32C checksum of the object.", "This will only be present if it was \nuploaded with the object. When you use an API operation on an object that was uploaded using \nmultipart uploads, this value may not be a direct checksum value of the full object. Instead, \nit's a calculation based on the checksum values of each individual part.", "For more information \nAmazon S3 API Version 2006-03-01 737Amazon Simple Storage Service API Reference\nabout how checksums are calculated with multipart uploads, see  Checking object integrity in \nthe Amazon S3 User Guide .\nType: String\nChecksumSHA1\nThe base64-encoded, 160-bit SHA-1 digest of the object.", "This will only be present if it was \nuploaded with the object. When you use the API operation on an object that was uploaded \nusing multipart uploads, this value may not be a direct checksum value of the full object.", "\nInstead, it's a calculation based on the checksum values of each individual part.", "For more \ninformation about how checksums are calculated with multipart uploads, see  Checking object \nintegrity in the Amazon S3 User Guide .\nType: String\nChecksumSHA256\nThe base64-encoded, 256-bit SHA-256 digest of the object.", "This will only be present if it was \nuploaded with the object. When you use an API operation on an object that was uploaded using \nmultipart uploads, this value may not be a direct checksum value of the full object. Instead, \nit's a calculation based on the checksum values of each individual part.", "For more information \nabout how checksums are calculated with multipart uploads, see  Checking object integrity in \nthe Amazon S3 User Guide .\nType: String\nETag\nEntity tag of the object.\nType: String\nLastModi\ufb01ed\nDate and time at which the object was uploaded.\nType: Timestamp\nAmazon S3 API Version 2006-03-01 738Amazon Simple Storage Service API Reference\nExamples\nSample Request for general purpose buckets\nThe following PUT request uploads a part (part number 2) in a multipart upload.", "The request \nspeci\ufb01es a byte range from an existing object as the source of this upload. The request includes the \nupload ID that you get in response to your Initiate Multipart Upload request.\nPUT /newobject?\npartNumber=2&uploadId=VCVsb2FkIElEIGZvciBlbZZpbmcncyBteS1tb3ZpZS5tMnRzIHVwbG9hZR \n HTTP/1.1\nHost: target-bucket.s3.<Region>.amazonaws.com\nDate:  Mon, 11 Apr 2011 20:34:56 GMT\nx-amz-copy-source: /source-bucket/sourceobject\nx-amz-copy-source-range:bytes=500-6291456\nAuthorization: authorization string \n          \nSample Response for general purpose buckets\nThe response includes the ETag value. You need to retain this value to use when you send the \nComplete Multipart Upload request.\nHTTP/1.1 200 OK\nx-amz-id-2: Vvag1LuByRx9e6j5Onimru9pO4ZVKnJ2Qz7/C1NPcfTWAtRPfTaOFg==\nx-amz-request-id: 656c76696e6727732072657175657374\nDate:  Mon, 11 Apr 2011 20:34:56 GMT\nServer: AmazonS3  \n<CopyPartResult> \n   <LastModified>2011-04-11T20:34:56.000Z</LastModified> \n   <ETag>\"9b2cf535f27731c974343645a3985328\"</ETag>\n</CopyPartResult> \n          \nSample Request for general purpose buckets\nThe following PUT request uploads a part (part number 2) in a multipart upload.", "The request does \nnot specify the optional byte range header, but requests the entire source object copy as part \nAmazon S3 API Version 2006-03-01 739Amazon Simple Storage Service API Reference\n2. The request includes the upload ID that you got in response to your Initiate Multipart Upload \nrequest.\nPUT /newobject?\npartNumber=2&uploadId=VCVsb2FkIElEIGZvciBlbZZpbmcncyBteS1tb3ZpZS5tMnRzIHVwbG9hZR \n HTTP/1.1\nHost: target-bucket.s3.<Region>.amazonaws.com\nDate:  Mon, 11 Apr 2011 20:34:56 GMT\nx-amz-copy-source: /source-bucket/sourceobject?versionId=3/L4kqtJlcpXroDTDmJ\n+rmSpXd3dIbrHY+MTRCxf3vjVBH40Nr8X8gdRQBpUMLUo\nAuthorization: authorization string \n          \nSample Response for general purpose buckets\nThe response includes the ETag value. You need to retain this value to use when you send the \nComplete Multipart Upload request.\nHTTP/1.1 200 OK\nx-amz-id-2: Vvag1LuByRx9e6j5Onimru9pO4ZVKnJ2Qz7/C1NPcfTWAtRPfTaOFg==\nx-amz-request-id: 656c76696e6727732072657175657374\nx-amz-copy-source-version-id: 3/L4kqtJlcpXroDTDmJ+rmSpXd3dIbrHY\n+MTRCxf3vjVBH40Nr8X8gdRQBpUMLUo\nDate:  Mon, 11 Apr 2011 20:34:56 GMT\nServer: AmazonS3  \n<CopyPartResult> \n   <LastModified>2011-04-11T20:34:56.000Z</LastModified> \n   <ETag>\"9b2cf535f27731c974343645a3985328\"</ETag>\n</CopyPartResult> \n          \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\nAmazon S3 API Version 2006-03-01 740Amazon Simple Storage Service API Reference\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 741Amazon Simple Storage Service API Reference\nWriteGetObjectResponse\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nPasses transformed objects to a GetObject  operation when using Object Lambda access points.", "\nFor information about Object Lambda access points, see Transforming objects with Object Lambda \naccess points in the Amazon S3 User Guide .\nThis operation supports metadata that can be returned by GetObject, in addition to\nRequestRoute , RequestToken , StatusCode , ErrorCode , and ErrorMessage .", "The GetObject\nresponse metadata is supported so that the WriteGetObjectResponse  caller, typically an AWS \nLambda function, can provide the same metadata when it internally invokes GetObject . When\nWriteGetObjectResponse  is called by a customer-owned Lambda function, the metadata \nreturned to the end user GetObject  call might di\ufb00er from what Amazon S3 would normally \nreturn.\nYou can include any number of metadata headers.", "When including a metadata header, it should be \nprefaced with x-amz-meta . For example, x-amz-meta-my-custom-header: MyCustomValue .", "\nThe primary use case for this is to forward GetObject  metadata.\nAWS provides some prebuilt Lambda functions that you can use with S3 Object Lambda to detect \nand redact personally identi\ufb01able information (PII) and decompress S3 objects.", "These Lambda \nfunctions are available in the AWS Serverless Application Repository, and can be selected through \nthe AWS Management Console when you create your Object Lambda access point.\nExample 1: PII Access Control - This Lambda function uses Amazon Comprehend, a natural \nlanguage processing (NLP) service using machine learning to \ufb01nd insights and relationships in text.", "\nIt automatically detects personally identi\ufb01able information (PII) such as names, addresses, dates, \ncredit card numbers, and social security numbers from documents in your Amazon S3 bucket.\nExample 2: PII Redaction - This Lambda function uses Amazon Comprehend, a natural language \nprocessing (NLP) service using machine learning to \ufb01nd insights and relationships in text. It \nautomatically redacts personally identi\ufb01able information (PII) such as names, addresses, dates, \ncredit card numbers, and social security numbers from documents in your Amazon S3 bucket.\nAmazon S3 API Version 2006-03-01 742Amazon Simple Storage Service API Reference\nExample 3: Decompression - The Lambda function S3ObjectLambdaDecompression, is equipped to \ndecompress objects stored in S3 in one of six compressed \ufb01le formats including bzip2, gzip, snappy, \nzlib, zstandard and ZIP.\nFor information on how to view and use these functions, see Using AWS built Lambda functions in \nthe Amazon S3 User Guide .\nRequest Syntax\nPOST /WriteGetObjectResponse HTTP/1.1\nHost: s3.amazonaws.com\nx-amz-request-route: RequestRoute\nx-amz-request-token: RequestToken\nx-amz-fwd-status: StatusCode\nx-amz-fwd-error-code: ErrorCode\nx-amz-fwd-error-message: ErrorMessage\nx-amz-fwd-header-accept-ranges: AcceptRanges\nx-amz-fwd-header-Cache-Control: CacheControl\nx-amz-fwd-header-Content-Disposition: ContentDisposition\nx-amz-fwd-header-Content-Encoding: ContentEncoding\nx-amz-fwd-header-Content-Language: ContentLanguage\nContent-Length: ContentLength\nx-amz-fwd-header-Content-Range: ContentRange\nx-amz-fwd-header-Content-Type: ContentType\nx-amz-fwd-header-x-amz-checksum-crc32: ChecksumCRC32\nx-amz-fwd-header-x-amz-checksum-crc32c: ChecksumCRC32C\nx-amz-fwd-header-x-amz-checksum-sha1: ChecksumSHA1\nx-amz-fwd-header-x-amz-checksum-sha256: ChecksumSHA256\nx-amz-fwd-header-x-amz-delete-marker: DeleteMarker\nx-amz-fwd-header-ETag: ETag\nx-amz-fwd-header-Expires: Expires\nx-amz-fwd-header-x-amz-expiration: Expiration\nx-amz-fwd-header-Last-Modified: LastModified\nx-amz-fwd-header-x-amz-missing-meta: MissingMeta\nx-amz-fwd-header-x-amz-object-lock-mode: ObjectLockMode\nx-amz-fwd-header-x-amz-object-lock-legal-hold: ObjectLockLegalHoldStatus\nx-amz-fwd-header-x-amz-object-lock-retain-until-date: ObjectLockRetainUntilDate\nx-amz-fwd-header-x-amz-mp-parts-count: PartsCount\nx-amz-fwd-header-x-amz-replication-status: ReplicationStatus\nx-amz-fwd-header-x-amz-request-charged: RequestCharged\nx-amz-fwd-header-x-amz-restore: Restore\nx-amz-fwd-header-x-amz-server-side-encryption: ServerSideEncryption\nx-amz-fwd-header-x-amz-server-side-encryption-customer-algorithm: SSECustomerAlgorithm\nAmazon S3 API Version 2006-03-01 743Amazon Simple Storage Service API Reference\nx-amz-fwd-header-x-amz-server-side-encryption-aws-kms-key-id: SSEKMSKeyId\nx-amz-fwd-header-x-amz-server-side-encryption-customer-key-MD5: SSECustomerKeyMD5\nx-amz-fwd-header-x-amz-storage-class: StorageClass\nx-amz-fwd-header-x-amz-tagging-count: TagCount\nx-amz-fwd-header-x-amz-version-id: VersionId\nx-amz-fwd-header-x-amz-server-side-encryption-bucket-key-enabled: BucketKeyEnabled\nBody\nURI Request Parameters\nThe request uses the following URI parameters.\nContent-Length\nThe size of the content body in bytes.\nx-amz-fwd-error-code\nA string that uniquely identi\ufb01es an error condition.", "Returned in the <Code> tag of the error XML \nresponse for a corresponding GetObject  call.", "Cannot be used with a successful StatusCode\nheader or when the transformed object is provided in the body.", "All error codes from S3 are \nsentence-cased.", "The regular expression (regex) value is \"^[A-Z][a-zA-Z]+$\" .\nx-amz-fwd-error-message\nContains a generic description of the error condition.", "Returned in the <Message> tag of the \nerror XML response for a corresponding GetObject  call.", "Cannot be used with a successful\nStatusCode  header or when the transformed object is provided in body.\nx-amz-fwd-header-accept-ranges\nIndicates that a range of bytes was speci\ufb01ed.\nx-amz-fwd-header-Cache-Control\nSpeci\ufb01es caching behavior along the request/reply chain.\nx-amz-fwd-header-Content-Disposition\nSpeci\ufb01es presentational information for the object.\nx-amz-fwd-header-Content-Encoding\nSpeci\ufb01es what content encodings have been applied to the object and thus what decoding \nmechanisms must be applied to obtain the media-type referenced by the Content-Type header \n\ufb01eld.\nAmazon S3 API Version 2006-03-01 744Amazon Simple Storage Service API Reference\nx-amz-fwd-header-Content-Language\nThe language the content is in.\nx-amz-fwd-header-Content-Range\nThe portion of the object returned in the response.\nx-amz-fwd-header-Content-Type\nA standard MIME type describing the format of the object data.\nx-amz-fwd-header-ETag\nAn opaque identi\ufb01er assigned by a web server to a speci\ufb01c version of a resource found at a URL.\nx-amz-fwd-header-Expires\nThe date and time at which the object is no longer cacheable.\nx-amz-fwd-header-Last-Modi\ufb01ed\nThe date and time that the object was last modi\ufb01ed.\nx-amz-fwd-header-x-amz-checksum-crc32\nThis header can be used as a data integrity check to verify that the data received is the same \ndata that was originally sent.", "This speci\ufb01es the base64-encoded, 32-bit CRC-32 checksum of \nthe object returned by the Object Lambda function.", "This may not match the checksum for the \nobject stored in Amazon S3. Amazon S3 will perform validation of the checksum values only \nwhen the original GetObject  request required checksum validation. For more information \nabout checksums, see Checking object integrity in the Amazon S3 User Guide .\nOnly one checksum header can be speci\ufb01ed at a time.", "If you supply multiple checksum headers, \nthis request will fail.\nx-amz-fwd-header-x-amz-checksum-crc32c\nThis header can be used as a data integrity check to verify that the data received is the same \ndata that was originally sent. This speci\ufb01es the base64-encoded, 32-bit CRC-32C checksum of \nthe object returned by the Object Lambda function.", "This may not match the checksum for the \nobject stored in Amazon S3. Amazon S3 will perform validation of the checksum values only \nwhen the original GetObject  request required checksum validation. For more information \nabout checksums, see Checking object integrity in the Amazon S3 User Guide .\nAmazon S3 API Version 2006-03-01 745Amazon Simple Storage Service API Reference\nOnly one checksum header can be speci\ufb01ed at a time.", "If you supply multiple checksum headers, \nthis request will fail.\nx-amz-fwd-header-x-amz-checksum-sha1\nThis header can be used as a data integrity check to verify that the data received is the same \ndata that was originally sent.", "This speci\ufb01es the base64-encoded, 160-bit SHA-1 digest of the \nobject returned by the Object Lambda function.", "This may not match the checksum for the \nobject stored in Amazon S3. Amazon S3 will perform validation of the checksum values only \nwhen the original GetObject  request required checksum validation. For more information \nabout checksums, see Checking object integrity in the Amazon S3 User Guide .\nOnly one checksum header can be speci\ufb01ed at a time.", "If you supply multiple checksum headers, \nthis request will fail.\nx-amz-fwd-header-x-amz-checksum-sha256\nThis header can be used as a data integrity check to verify that the data received is the same \ndata that was originally sent.", "This speci\ufb01es the base64-encoded, 256-bit SHA-256 digest of \nthe object returned by the Object Lambda function.", "This may not match the checksum for the \nobject stored in Amazon S3. Amazon S3 will perform validation of the checksum values only \nwhen the original GetObject  request required checksum validation. For more information \nabout checksums, see Checking object integrity in the Amazon S3 User Guide .\nOnly one checksum header can be speci\ufb01ed at a time. If you supply multiple checksum headers, \nthis request will fail.\nx-amz-fwd-header-x-amz-delete-marker\nSpeci\ufb01es whether an object stored in Amazon S3 is (true ) or is not ( false) a delete marker.\nx-amz-fwd-header-x-amz-expiration\nIf the object expiration is con\ufb01gured (see PUT Bucket lifecycle), the response includes this \nheader.", "It includes the expiry-date  and rule-id key-value pairs that provide the object \nexpiration information.", "The value of the rule-id is URL-encoded.\nx-amz-fwd-header-x-amz-missing-meta\nSet to the number of metadata entries not returned in x-amz-meta  headers.", "This can happen \nif you create metadata using an API like SOAP that supports more \ufb02exible metadata than the \nREST API.", "For example, using SOAP, you can create metadata whose values are not legal HTTP \nheaders.\nAmazon S3 API Version 2006-03-01 746Amazon Simple Storage Service API Reference\nx-amz-fwd-header-x-amz-mp-parts-count\nThe count of parts this object has.\nx-amz-fwd-header-x-amz-object-lock-legal-hold\nIndicates whether an object stored in Amazon S3 has an active legal hold.\nValid Values: ON | OFF\nx-amz-fwd-header-x-amz-object-lock-mode\nIndicates whether an object stored in Amazon S3 has Object Lock enabled. For more \ninformation about S3 Object Lock, see Object Lock.\nValid Values: GOVERNANCE | COMPLIANCE\nx-amz-fwd-header-x-amz-object-lock-retain-until-date\nThe date and time when Object Lock is con\ufb01gured to expire.\nx-amz-fwd-header-x-amz-replication-status\nIndicates if request involves bucket that is either a source or destination in a Replication rule. \nFor more information about S3 Replication, see Replication.\nValid Values: COMPLETE | PENDING | FAILED | REPLICA | COMPLETED\nx-amz-fwd-header-x-amz-request-charged\nIf present, indicates that the requester was successfully charged for the request.\nNote\nThis functionality is not supported for directory buckets.\nValid Values: requester\nx-amz-fwd-header-x-amz-restore\nProvides information about object restoration operation and expiration time of the restored \nobject copy.\nx-amz-fwd-header-x-amz-server-side-encryption\nThe server-side encryption algorithm used when storing requested object in Amazon S3 (for \nexample, AES256, aws:kms ).\nAmazon S3 API Version 2006-03-01 747Amazon Simple Storage Service API Reference\nValid Values: AES256 | aws:kms | aws:kms:dsse\nx-amz-fwd-header-x-amz-server-side-encryption-aws-kms-key-id\nIf present, speci\ufb01es the ID (Key ID, Key ARN, or Key Alias) of the AWS Key Management Service \n(AWS KMS) symmetric encryption customer managed key that was used for stored in Amazon \nS3 object.\nx-amz-fwd-header-x-amz-server-side-encryption-bucket-key-enabled\nIndicates whether the object stored in Amazon S3 uses an S3 bucket key for server-side \nencryption with AWS KMS (SSE-KMS).\nx-amz-fwd-header-x-amz-server-side-encryption-customer-algorithm\nEncryption algorithm used if server-side encryption with a customer-provided encryption key \nwas speci\ufb01ed for object stored in Amazon S3.\nx-amz-fwd-header-x-amz-server-side-encryption-customer-key-MD5\n128-bit MD5 digest of customer-provided encryption key used in Amazon S3 to encrypt data \nstored in S3.", "For more information, see Protecting data using server-side encryption with \ncustomer-provided encryption keys (SSE-C).\nx-amz-fwd-header-x-amz-storage-class\nProvides storage class information of the object.", "Amazon S3 returns this header for all objects \nexcept for S3 Standard storage class objects.\nFor more information, see Storage Classes .\nValid Values: STANDARD | REDUCED_REDUNDANCY | STANDARD_IA | ONEZONE_IA | \nINTELLIGENT_TIERING | GLACIER | DEEP_ARCHIVE | OUTPOSTS | GLACIER_IR | \nSNOW | EXPRESS_ONEZONE\nx-amz-fwd-header-x-amz-tagging-count\nThe number of tags, if any, on the object.\nx-amz-fwd-header-x-amz-version-id\nAn ID used to reference a speci\ufb01c version of the object.\nx-amz-fwd-status\nThe integer status code for an HTTP response of a corresponding GetObject  request. The \nfollowing is a list of status codes.\nAmazon S3 API Version 2006-03-01 748Amazon Simple Storage Service API Reference\n\u2022200 - OK\n\u2022206 - Partial Content\n\u2022304 - Not Modified\n\u2022400 - Bad Request\n\u2022401 - Unauthorized\n\u2022403 - Forbidden\n\u2022404 - Not Found\n\u2022405 - Method Not Allowed\n\u2022409 - Conflict\n\u2022411 - Length Required\n\u2022412 - Precondition Failed\n\u2022416 - Range Not Satisfiable\n\u2022500 - Internal Server Error\n\u2022503 - Service Unavailable\nx-amz-request-route\nRoute pre\ufb01x to the HTTP URL generated.\nRequired: Yes\nx-amz-request-token\nA single use encrypted token that maps WriteGetObjectResponse  to the end user\nGetObject  request.\nRequired: Yes\nRequest Body\nThe request accepts the following binary data.\nBody\nResponse Syntax\nHTTP/1.1 200\nAmazon S3 API Version 2006-03-01 749Amazon Simple Storage Service API Reference\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\nExamples\nSample Response\nThe following illustrates a sample response.\n             HTTP/1.1 200 OK \n             x-amz-request-id: 19684529-d1aa-413e-9382-9ff490962d12 \n             Date: Wed, 24 Feb 2021 10:57:53 GMT \n             Content-Length: 0\nSample Request\nThe following illustrates a sample request from a POST.\n             POST /WriteGetObjectResponse HTTP/1.1 \n             Host: <RequestRoute>.s3-object-lambda.<Region>.amazonaws.com \n             x-amz-request-token: <RequestToken> \n             Authorization: authorization string \n             Content-Type: text/plain \n             Content-Length: 16 \n             [16 bytes of object data]\nSample Error Response\nThe following response returns a ValidationError  error because the RequestToken could not be \ndecrypted.\n            <?xml version=\"1.0\" encoding=\"UTF-8\"?> \n            <Error> \n            <Code>ValidationError</Code> \n            <Message>Invalid token</Message> \n            <RequestId>fcd2cd5e-def0-4001-8030-1fd1d61d2c9d</RequestId> \n            </Error>\nAmazon S3 API Version 2006-03-01 750Amazon Simple Storage Service API Reference\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control\nThe following actions are supported by Amazon S3 Control:\n\u2022AssociateAccessGrantsIdentityCenter\n\u2022CreateAccessGrant\n\u2022CreateAccessGrantsInstance\n\u2022CreateAccessGrantsLocation\n\u2022CreateAccessPoint\n\u2022CreateAccessPointForObjectLambda\n\u2022CreateBucket\n\u2022CreateJob\n\u2022CreateMultiRegionAccessPoint\n\u2022CreateStorageLensGroup\n\u2022DeleteAccessGrant\n\u2022DeleteAccessGrantsInstance\n\u2022DeleteAccessGrantsInstanceResourcePolicy\n\u2022DeleteAccessGrantsLocation\nAmazon S3 Control API Version 2006-03-01 751Amazon Simple Storage Service API Reference\n\u2022DeleteAccessPoint\n\u2022DeleteAccessPointForObjectLambda\n\u2022DeleteAccessPointPolicy\n\u2022DeleteAccessPointPolicyForObjectLambda\n\u2022DeleteBucket\n\u2022DeleteBucketLifecycleCon\ufb01guration\n\u2022DeleteBucketPolicy\n\u2022DeleteBucketReplication\n\u2022DeleteBucketTagging\n\u2022DeleteJobTagging\n\u2022DeleteMultiRegionAccessPoint\n\u2022DeletePublicAccessBlock\n\u2022DeleteStorageLensCon\ufb01guration\n\u2022DeleteStorageLensCon\ufb01gurationTagging\n\u2022DeleteStorageLensGroup\n\u2022DescribeJob\n\u2022DescribeMultiRegionAccessPointOperation\n\u2022DissociateAccessGrantsIdentityCenter\n\u2022GetAccessGrant\n\u2022GetAccessGrantsInstance\n\u2022GetAccessGrantsInstanceForPre\ufb01x\n\u2022GetAccessGrantsInstanceResourcePolicy\n\u2022GetAccessGrantsLocation\n\u2022GetAccessPoint\n\u2022GetAccessPointCon\ufb01gurationForObjectLambda\n\u2022GetAccessPointForObjectLambda\n\u2022GetAccessPointPolicy\n\u2022GetAccessPointPolicyForObjectLambda\n\u2022GetAccessPointPolicyStatus\n\u2022GetAccessPointPolicyStatusForObjectLambda\nAmazon S3 Control API Version 2006-03-01 752Amazon Simple Storage Service API Reference\n\u2022GetBucket\n\u2022GetBucketLifecycleCon\ufb01guration\n\u2022GetBucketPolicy\n\u2022GetBucketReplication\n\u2022GetBucketTagging\n\u2022GetBucketVersioning\n\u2022GetDataAccess\n\u2022GetJobTagging\n\u2022GetMultiRegionAccessPoint\n\u2022GetMultiRegionAccessPointPolicy\n\u2022GetMultiRegionAccessPointPolicyStatus\n\u2022GetMultiRegionAccessPointRoutes\n\u2022GetPublicAccessBlock\n\u2022GetStorageLensCon\ufb01guration\n\u2022GetStorageLensCon\ufb01gurationTagging\n\u2022GetStorageLensGroup\n\u2022ListAccessGrants\n\u2022ListAccessGrantsInstances\n\u2022ListAccessGrantsLocations\n\u2022ListAccessPoints\n\u2022ListAccessPointsForObjectLambda\n\u2022ListCallerAccessGrants\n\u2022ListJobs\n\u2022ListMultiRegionAccessPoints\n\u2022ListRegionalBuckets\n\u2022ListStorageLensCon\ufb01gurations\n\u2022ListStorageLensGroups\n\u2022ListTagsForResource\n\u2022PutAccessGrantsInstanceResourcePolicy\n\u2022PutAccessPointCon\ufb01gurationForObjectLambda\nAmazon S3 Control API Version 2006-03-01 753Amazon Simple Storage Service API Reference\n\u2022PutAccessPointPolicy\n\u2022PutAccessPointPolicyForObjectLambda\n\u2022PutBucketLifecycleCon\ufb01guration\n\u2022PutBucketPolicy\n\u2022PutBucketReplication\n\u2022PutBucketTagging\n\u2022PutBucketVersioning\n\u2022PutJobTagging\n\u2022PutMultiRegionAccessPointPolicy\n\u2022PutPublicAccessBlock\n\u2022PutStorageLensCon\ufb01guration\n\u2022PutStorageLensCon\ufb01gurationTagging\n\u2022SubmitMultiRegionAccessPointRoutes\n\u2022TagResource\n\u2022UntagResource\n\u2022UpdateAccessGrantsLocation\n\u2022UpdateJobPriority\n\u2022UpdateJobStatus\n\u2022UpdateStorageLensGroup\nAmazon S3 Control API Version 2006-03-01 754Amazon Simple Storage Service API Reference\nAssociateAccessGrantsIdentityCenter\nService: Amazon S3 Control\nAssociate your S3 Access Grants instance with an AWS IAM Identity Center instance.", "Use this action \nif you want to create access grants for users or groups from your corporate identity directory. \nFirst, you must add your corporate identity directory to AWS IAM Identity Center.", "Then, you can \nassociate this IAM Identity Center instance with your S3 Access Grants instance.\nPermissions\nYou must have the s3:AssociateAccessGrantsIdentityCenter  permission to use this \noperation.\nAdditional Permissions\nYou must also have the following permissions: sso:CreateApplication ,\nsso:PutApplicationGrant , and sso:PutApplicationAuthenticationMethod .\nRequest Syntax\nPOST /v20180820/accessgrantsinstance/identitycenter HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<AssociateAccessGrantsIdentityCenterRequest  xmlns=\"http://awss3control.amazonaws.com/\ndoc/2018-08-20/\"> \n   <IdentityCenterArn >string</IdentityCenterArn >\n</AssociateAccessGrantsIdentityCenterRequest >\nURI Request Parameters\nThe request uses the following URI parameters.\nx-amz-account-id\nThe AWS account ID of the S3 Access Grants instance.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nAmazon S3 Control API Version 2006-03-01 755Amazon Simple Storage Service API Reference\nRequest Body\nThe request accepts the following data in XML format.\nAssociateAccessGrantsIdentityCenterRequest\nRoot level tag for the AssociateAccessGrantsIdentityCenterRequest parameters.\nRequired: Yes\nIdentityCenterArn\nThe Amazon Resource Name (ARN) of the AWS IAM Identity Center instance that you are \nassociating with your S3 Access Grants instance.", "An IAM Identity Center instance is your \ncorporate identity directory that you added to the IAM Identity Center.", "You can use the\nListInstances API operation to retrieve a list of your Identity Center instances and their ARNs.\nType: String\nLength Constraints: Minimum length of 10.", "Maximum length of 1224.\nPattern: arn:[^:]+:sso::(\\d{12}){0,1}:instance/.*$\nRequired: Yes\nResponse Syntax\nHTTP/1.1 200\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\nAmazon S3 Control API Version 2006-03-01 756Amazon Simple Storage Service API Reference\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 757Amazon Simple Storage Service API Reference\nCreateAccessGrant\nService: Amazon S3 Control\nCreates an access grant that gives a grantee access to your S3 data.", "The grantee can be an IAM user \nor role or a directory user, or group.", "Before you can create a grant, you must have an S3 Access \nGrants instance in the same Region as the S3 data. You can create an S3 Access Grants instance \nusing the CreateAccessGrantsInstance. You must also have registered at least one S3 data location \nin your S3 Access Grants instance using CreateAccessGrantsLocation.\nPermissions\nYou must have the s3:CreateAccessGrant  permission to use this operation.\nAdditional Permissions\nFor any directory identity - sso:DescribeInstance  and sso:DescribeApplication\nFor directory users - identitystore:DescribeUser\nFor directory groups - identitystore:DescribeGroup\nRequest Syntax\nPOST /v20180820/accessgrantsinstance/grant HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<CreateAccessGrantRequest  xmlns=\"http://awss3control.amazonaws.com/doc/2018-08-20/\"> \n   <AccessGrantsLocationId >string</AccessGrantsLocationId > \n   <AccessGrantsLocationConfiguration > \n      <S3SubPrefix >string</S3SubPrefix > \n   </AccessGrantsLocationConfiguration > \n   <Grantee> \n      <GranteeIdentifier >string</GranteeIdentifier > \n      <GranteeType >string</GranteeType > \n   </Grantee> \n   <Permission >string</Permission > \n   <ApplicationArn >string</ApplicationArn > \n   <S3PrefixType >string</S3PrefixType > \n   <Tags> \n      <Tag> \n         < Key>string</Key> \nAmazon S3 Control API Version 2006-03-01 758Amazon Simple Storage Service API Reference\n         < Value>string</Value> \n      </Tag> \n   </Tags>\n</CreateAccessGrantRequest >\nURI Request Parameters\nThe request uses the following URI parameters.\nx-amz-account-id\nThe AWS account ID of the S3 Access Grants instance.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request accepts the following data in XML format.\nCreateAccessGrantRequest\nRoot level tag for the CreateAccessGrantRequest parameters.\nRequired: Yes\nAccessGrantsLocationCon\ufb01guration\nThe con\ufb01guration options of the grant location. The grant location is the S3 path to the data to \nwhich you are granting access. It contains the S3SubPrefix  \ufb01eld.", "The grant scope is the result \nof appending the subpre\ufb01x to the location scope of the registered location.\nType: AccessGrantsLocationCon\ufb01guration data type\nRequired: No\nAccessGrantsLocationId\nThe ID of the registered location to which you are granting access.", "S3 Access Grants assigns \nthis ID when you register the location. S3 Access Grants assigns the ID default  to the default \nlocation s3:// and assigns an auto-generated ID to other locations that you register.\nAmazon S3 Control API Version 2006-03-01 759Amazon Simple Storage Service API Reference\nIf you are passing the default location, you cannot create an access grant for the entire \ndefault location.", "You must also specify a bucket or a bucket and pre\ufb01x in the Subprefix  \ufb01eld.\nType: String\nLength Constraints: Minimum length of 1.", "Maximum length of 64.\nPattern: [a-zA-Z0-9\\-]+\nRequired: Yes\nApplicationArn\nThe Amazon Resource Name (ARN) of an AWS IAM Identity Center application associated with \nyour Identity Center instance.", "If an application ARN is included in the request to create an \naccess grant, the grantee can only access the S3 data through this application.\nType: String\nLength Constraints: Minimum length of 10.", "Maximum length of 1224.\nPattern: arn:[^:]+:sso::\\d{12}:application/.*$\nRequired: No\nGrantee\nThe user, group, or role to which you are granting access.", "You can grant access to an IAM user \nor role.", "If you have added your corporate directory to AWS IAM Identity Center and associated \nyour Identity Center instance with your S3 Access Grants instance, the grantee can also be a \ncorporate directory user or group.\nType: Grantee  data type\nRequired: Yes\nPermission\nThe type of access that you are granting to your S3 data, which can be set to one of the \nfollowing values:\n\u2022READ \u2013 Grant read-only access to the S3 data.\n\u2022WRITE \u2013 Grant write-only access to the S3 data.\n\u2022READWRITE  \u2013 Grant both read and write access to the S3 data.\nAmazon S3 Control API Version 2006-03-01 760Amazon Simple Storage Service API Reference\nType: String\nValid Values: READ | WRITE | READWRITE\nRequired: Yes\nS3Pre\ufb01xType\nThe type of S3SubPrefix .", "The only possible value is Object. Pass this value if the access grant \nscope is an object. Do not pass this value if the access grant scope is a bucket or a bucket and a \npre\ufb01x.\nType: String\nValid Values: Object\nRequired: No\nTags\nThe AWS resource tags that you are adding to the access grant.", "Each tag is a label consisting of \na user-de\ufb01ned key and value. Tags can help you manage, identify, organize, search for, and \ufb01lter \nresources.\nType: Array of Tag data types\nArray Members: Minimum number of 0 items.", "Maximum number of 50 items.\nRequired: No\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<CreateAccessGrantResult > \n   <CreatedAt >timestamp </CreatedAt > \n   <AccessGrantId >string</AccessGrantId > \n   <AccessGrantArn >string</AccessGrantArn > \n   <Grantee> \n      <GranteeIdentifier >string</GranteeIdentifier > \n      <GranteeType >string</GranteeType > \n   </Grantee> \n   <AccessGrantsLocationId >string</AccessGrantsLocationId > \n   <AccessGrantsLocationConfiguration > \nAmazon S3 Control API Version 2006-03-01 761Amazon Simple Storage Service API Reference\n      <S3SubPrefix >string</S3SubPrefix > \n   </AccessGrantsLocationConfiguration > \n   <Permission >string</Permission > \n   <ApplicationArn >string</ApplicationArn > \n   <GrantScope >string</GrantScope >\n</CreateAccessGrantResult >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nCreateAccessGrantResult\nRoot level tag for the CreateAccessGrantResult parameters.\nRequired: Yes\nAccessGrantArn\nThe Amazon Resource Name (ARN) of the access grant.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 2048.\nPattern: arn:[a-z\\-]+:s3:[a-z0-9\\-]+:\\d{12}:access\\-grants\\/grant/[a-zA-\nZ0-9\\-]+\nAccessGrantId\nThe ID of the access grant. S3 Access Grants auto-generates this ID when you create the access \ngrant.\nType: String\nLength Constraints: Minimum length of 1.", "Maximum length of 64.\nPattern: [a-zA-Z0-9\\-]+\nAccessGrantsLocationCon\ufb01guration\nThe con\ufb01guration options of the grant location.", "The grant location is the S3 path to the data to \nwhich you are granting access.\nAmazon S3 Control API Version 2006-03-01 762Amazon Simple Storage Service API Reference\nType: AccessGrantsLocationCon\ufb01guration data type\nAccessGrantsLocationId\nThe ID of the registered location to which you are granting access. S3 Access Grants assigns \nthis ID when you register the location. S3 Access Grants assigns the ID default  to the default \nlocation s3:// and assigns an auto-generated ID to other locations that you register.\nType: String\nLength Constraints: Minimum length of 1.", "Maximum length of 64.\nPattern: [a-zA-Z0-9\\-]+\nApplicationArn\nThe Amazon Resource Name (ARN) of an AWS IAM Identity Center application associated with \nyour Identity Center instance.", "If the grant includes an application ARN, the grantee can only \naccess the S3 data through this application.\nType: String\nLength Constraints: Minimum length of 10.", "Maximum length of 1224.\nPattern: arn:[^:]+:sso::\\d{12}:application/.*$\nCreatedAt\nThe date and time when you created the access grant.\nType: Timestamp\nGrantee\nThe user, group, or role to which you are granting access. You can grant access to an IAM user \nor role.", "If you have added your corporate directory to AWS IAM Identity Center and associated \nyour Identity Center instance with your S3 Access Grants instance, the grantee can also be a \ncorporate directory user or group.\nType: Grantee  data type\nGrantScope\nThe S3 path of the data to which you are granting access.", "It is the result of appending the\nSubprefix  to the location scope.\nAmazon S3 Control API Version 2006-03-01 763Amazon Simple Storage Service API Reference\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 2000.\nPattern: ^.+$\nPermission\nThe type of access that you are granting to your S3 data, which can be set to one of the \nfollowing values:\n\u2022READ \u2013 Grant read-only access to the S3 data.\n\u2022WRITE \u2013 Grant write-only access to the S3 data.\n\u2022READWRITE  \u2013 Grant both read and write access to the S3 data.\nType: String\nValid Values: READ | WRITE | READWRITE\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 764Amazon Simple Storage Service API Reference\nCreateAccessGrantsInstance\nService: Amazon S3 Control\nCreates an S3 Access Grants instance, which serves as a logical grouping for access grants. You can \ncreate one S3 Access Grants instance per Region per account.\nPermissions\nYou must have the s3:CreateAccessGrantsInstance  permission to use this operation.\nAdditional Permissions\nTo associate an IAM Identity Center instance with your S3 Access Grants instance, \nyou must also have the sso:DescribeInstance , sso:CreateApplication ,\nsso:PutApplicationGrant , and sso:PutApplicationAuthenticationMethod\npermissions.\nRequest Syntax\nPOST /v20180820/accessgrantsinstance HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<CreateAccessGrantsInstanceRequest  xmlns=\"http://awss3control.amazonaws.com/\ndoc/2018-08-20/\"> \n   <IdentityCenterArn >string</IdentityCenterArn > \n   <Tags> \n      <Tag> \n         < Key>string</Key> \n         < Value>string</Value> \n      </Tag> \n   </Tags>\n</CreateAccessGrantsInstanceRequest >\nURI Request Parameters\nThe request uses the following URI parameters.\nx-amz-account-id\nThe AWS account ID of the S3 Access Grants instance.\nAmazon S3 Control API Version 2006-03-01 765Amazon Simple Storage Service API Reference\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request accepts the following data in XML format.\nCreateAccessGrantsInstanceRequest\nRoot level tag for the CreateAccessGrantsInstanceRequest parameters.\nRequired: Yes\nIdentityCenterArn\nIf you would like to associate your S3 Access Grants instance with an AWS IAM Identity Center \ninstance, use this \ufb01eld to pass the Amazon Resource Name (ARN) of the AWS IAM Identity \nCenter instance that you are associating with your S3 Access Grants instance.", "An IAM Identity \nCenter instance is your corporate identity directory that you added to the IAM Identity Center.", "\nYou can use the ListInstances API operation to retrieve a list of your Identity Center instances \nand their ARNs.\nType: String\nLength Constraints: Minimum length of 10.", "Maximum length of 1224.\nPattern: arn:[^:]+:sso::(\\d{12}){0,1}:instance/.*$\nRequired: No\nTags\nThe AWS resource tags that you are adding to the S3 Access Grants instance.", "Each tag is a label \nconsisting of a user-de\ufb01ned key and value. Tags can help you manage, identify, organize, search \nfor, and \ufb01lter resources.\nType: Array of Tag data types\nArray Members: Minimum number of 0 items.", "Maximum number of 50 items.\nRequired: No\nAmazon S3 Control API Version 2006-03-01 766Amazon Simple Storage Service API Reference\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<CreateAccessGrantsInstanceResult > \n   <CreatedAt >timestamp </CreatedAt > \n   <AccessGrantsInstanceId >string</AccessGrantsInstanceId > \n   <AccessGrantsInstanceArn >string</AccessGrantsInstanceArn > \n   <IdentityCenterArn >string</IdentityCenterArn > \n   <IdentityCenterInstanceArn >string</IdentityCenterInstanceArn > \n   <IdentityCenterApplicationArn >string</IdentityCenterApplicationArn >\n</CreateAccessGrantsInstanceResult >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nCreateAccessGrantsInstanceResult\nRoot level tag for the CreateAccessGrantsInstanceResult parameters.\nRequired: Yes\nAccessGrantsInstanceArn\nThe Amazon Resource Name (ARN) of the AWS IAM Identity Center instance that you are \nassociating with your S3 Access Grants instance.", "An IAM Identity Center instance is your \ncorporate identity directory that you added to the IAM Identity Center. You can use the\nListInstances API operation to retrieve a list of your Identity Center instances and their ARNs.\nType: String\nLength Constraints: Minimum length of 1.", "Maximum length of 2048.\nPattern: arn:[a-z\\-]+:s3:[a-z0-9\\-]+:\\d{12}:access\\-grants\\/[a-zA-Z0-9\\-]+\nAccessGrantsInstanceId\nThe ID of the S3 Access Grants instance.", "The ID is default.", "You can have one S3 Access Grants \ninstance per Region per account.\nType: String\nAmazon S3 Control API Version 2006-03-01 767Amazon Simple Storage Service API Reference\nLength Constraints: Minimum length of 1. Maximum length of 64.\nPattern: [a-zA-Z0-9\\-]+\nCreatedAt\nThe date and time when you created the S3 Access Grants instance.\nType: Timestamp\nIdentityCenterApplicationArn\nIf you associated your S3 Access Grants instance with an AWS IAM Identity Center instance, this \n\ufb01eld returns the Amazon Resource Name (ARN) of the IAM Identity Center instance application; \na subresource of the original Identity Center instance. S3 Access Grants creates this Identity \nCenter application for the speci\ufb01c S3 Access Grants instance.\nType: String\nLength Constraints: Minimum length of 10. Maximum length of 1224.\nPattern: arn:[^:]+:sso::\\d{12}:application/.*$\nIdentityCenterArn\nThis parameter has been deprecated.\nIf you associated your S3 Access Grants instance with an AWS IAM Identity Center instance, this \n\ufb01eld returns the Amazon Resource Name (ARN) of the IAM Identity Center instance application; \na subresource of the original Identity Center instance. S3 Access Grants creates this Identity \nCenter application for the speci\ufb01c S3 Access Grants instance.\nType: String\nLength Constraints: Minimum length of 10. Maximum length of 1224.\nPattern: arn:[^:]+:sso::(\\d{12}){0,1}:instance/.*$\nIdentityCenterInstanceArn\nThe Amazon Resource Name (ARN) of the AWS IAM Identity Center instance that you are \nassociating with your S3 Access Grants instance.", "An IAM Identity Center instance is your \ncorporate identity directory that you added to the IAM Identity Center.", "You can use the\nListInstances API operation to retrieve a list of your Identity Center instances and their ARNs.\nAmazon S3 Control API Version 2006-03-01 768Amazon Simple Storage Service API Reference\nType: String\nLength Constraints: Minimum length of 10. Maximum length of 1224.\nPattern: arn:[^:]+:sso::(\\d{12}){0,1}:instance/.*$\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 769Amazon Simple Storage Service API Reference\nCreateAccessGrantsLocation\nService: Amazon S3 Control\nThe S3 data location that you would like to register in your S3 Access Grants instance. Your S3 \ndata must be in the same Region as your S3 Access Grants instance. The location can be one of the \nfollowing:\n\u2022The default S3 location s3://\n\u2022A bucket - S3://<bucket-name>\n\u2022A bucket and pre\ufb01x - S3://<bucket-name>/<prefix>\nWhen you register a location, you must include the IAM role that has permission to manage the \nS3 location that you are registering. Give S3 Access Grants permission to assume this role using a \npolicy.", "S3 Access Grants assumes this role to manage access to the location and to vend temporary \ncredentials to grantees or client applications.\nPermissions\nYou must have the s3:CreateAccessGrantsLocation  permission to use this operation.\nAdditional Permissions\nYou must also have the following permission for the speci\ufb01ed IAM role: iam:PassRole\nRequest Syntax\nPOST /v20180820/accessgrantsinstance/location HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<CreateAccessGrantsLocationRequest  xmlns=\"http://awss3control.amazonaws.com/\ndoc/2018-08-20/\"> \n   <LocationScope >string</LocationScope > \n   <IAMRoleArn >string</IAMRoleArn > \n   <Tags> \n      <Tag> \n         < Key>string</Key> \n         < Value>string</Value> \n      </Tag> \n   </Tags>\nAmazon S3 Control API Version 2006-03-01 770Amazon Simple Storage Service API Reference\n</CreateAccessGrantsLocationRequest >\nURI Request Parameters\nThe request uses the following URI parameters.\nx-amz-account-id\nThe AWS account ID of the S3 Access Grants instance.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request accepts the following data in XML format.\nCreateAccessGrantsLocationRequest\nRoot level tag for the CreateAccessGrantsLocationRequest parameters.\nRequired: Yes\nIAMRoleArn\nThe Amazon Resource Name (ARN) of the IAM role for the registered location. S3 Access Grants \nassumes this role to manage access to the registered location.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 2048.\nPattern: arn:[^:]+:iam::\\d{12}:role/.*\nRequired: Yes\nLocationScope\nThe S3 path to the location that you are registering.", "The location scope can be the default S3 \nlocation s3://, the S3 path to a bucket s3://<bucket> , or the S3 path to a bucket and pre\ufb01x\nAmazon S3 Control API Version 2006-03-01 771Amazon Simple Storage Service API Reference\ns3://<bucket>/<prefix> . A pre\ufb01x in S3 is a string of characters at the beginning of an \nobject key name used to organize the objects that you store in your S3 buckets.", "For example, \nobject key names that start with the engineering/  pre\ufb01x or object key names that start with \nthe marketing/campaigns/  pre\ufb01x.\nType: String\nLength Constraints: Minimum length of 1.", "Maximum length of 2000.\nPattern: ^.+$\nRequired: Yes\nTags\nThe AWS resource tags that you are adding to the S3 Access Grants location.", "Each tag is a label \nconsisting of a user-de\ufb01ned key and value. Tags can help you manage, identify, organize, search \nfor, and \ufb01lter resources.\nType: Array of Tag data types\nArray Members: Minimum number of 0 items.", "Maximum number of 50 items.\nRequired: No\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<CreateAccessGrantsLocationResult > \n   <CreatedAt >timestamp </CreatedAt > \n   <AccessGrantsLocationId >string</AccessGrantsLocationId > \n   <AccessGrantsLocationArn >string</AccessGrantsLocationArn > \n   <LocationScope >string</LocationScope > \n   <IAMRoleArn >string</IAMRoleArn >\n</CreateAccessGrantsLocationResult >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nAmazon S3 Control API Version 2006-03-01 772Amazon Simple Storage Service API Reference\nCreateAccessGrantsLocationResult\nRoot level tag for the CreateAccessGrantsLocationResult parameters.\nRequired: Yes\nAccessGrantsLocationArn\nThe Amazon Resource Name (ARN) of the location you are registering.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 2048.\nPattern: arn:[a-z\\-]+:s3:[a-z0-9\\-]+:\\d{12}:access\\-grants\\/location/[a-zA-\nZ0-9\\-]+\nAccessGrantsLocationId\nThe ID of the registered location to which you are granting access. S3 Access Grants assigns \nthis ID when you register the location. S3 Access Grants assigns the ID default  to the default \nlocation s3:// and assigns an auto-generated ID to other locations that you register.\nType: String\nLength Constraints: Minimum length of 1.", "Maximum length of 64.\nPattern: [a-zA-Z0-9\\-]+\nCreatedAt\nThe date and time when you registered the location.\nType: Timestamp\nIAMRoleArn\nThe Amazon Resource Name (ARN) of the IAM role for the registered location.", "S3 Access Grants \nassumes this role to manage access to the registered location.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 2048.\nPattern: arn:[^:]+:iam::\\d{12}:role/.*\nAmazon S3 Control API Version 2006-03-01 773Amazon Simple Storage Service API Reference\nLocationScope\nThe S3 URI path to the location that you are registering. The location scope can be the default \nS3 location s3://, the S3 path to a bucket, or the S3 path to a bucket and pre\ufb01x. A pre\ufb01x \nin S3 is a string of characters at the beginning of an object key name used to organize the \nobjects that you store in your S3 buckets.", "For example, object key names that start with the\nengineering/  pre\ufb01x or object key names that start with the marketing/campaigns/  pre\ufb01x.\nType: String\nLength Constraints: Minimum length of 1.", "Maximum length of 2000.\nPattern: ^.+$\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 774Amazon Simple Storage Service API Reference\nCreateAccessPoint\nService: Amazon S3 Control\nNote\nThis operation is not supported by directory buckets.\nCreates an access point and associates it with the speci\ufb01ed bucket. For more information, see\nManaging Data Access with Amazon S3 Access Points in the Amazon S3 User Guide .\nNote\nS3 on Outposts only supports VPC-style access points.\nFor more information, see  Accessing Amazon S3 on Outposts using virtual private cloud \n(VPC) only access points in the Amazon S3 User Guide .\nAll Amazon S3 on Outposts REST API requests for this action require an additional parameter of\nx-amz-outpost-id  to be passed with the request. In addition, you must use an S3 on Outposts \nendpoint hostname pre\ufb01x instead of s3-control . For an example of the request syntax for \nAmazon S3 on Outposts that uses the S3 on Outposts endpoint hostname pre\ufb01x and the x-amz-\noutpost-id  derived by using the access point ARN, see the Examples  section.\nThe following actions are related to CreateAccessPoint :\n\u2022GetAccessPoint\n\u2022DeleteAccessPoint\n\u2022ListAccessPoints\nRequest Syntax\nPUT /v20180820/accesspoint/ name HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<CreateAccessPointRequest  xmlns=\"http://awss3control.amazonaws.com/doc/2018-08-20/\"> \nAmazon S3 Control API Version 2006-03-01 775Amazon Simple Storage Service API Reference\n   <Bucket>string</Bucket> \n   <VpcConfiguration > \n      <VpcId>string</VpcId> \n   </VpcConfiguration > \n   <PublicAccessBlockConfiguration > \n      <BlockPublicAcls >boolean</BlockPublicAcls > \n      <BlockPublicPolicy >boolean</BlockPublicPolicy > \n      <IgnorePublicAcls >boolean</IgnorePublicAcls > \n      <RestrictPublicBuckets >boolean</RestrictPublicBuckets > \n   </PublicAccessBlockConfiguration > \n   <BucketAccountId >string</BucketAccountId >\n</CreateAccessPointRequest >\nURI Request Parameters\nThe request uses the following URI parameters.\nname\nThe name you want to assign to this access point.\nLength Constraints: Minimum length of 3. Maximum length of 255.\nRequired: Yes\nx-amz-account-id\nThe AWS account ID for the account that owns the speci\ufb01ed access point.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request accepts the following data in XML format.\nCreateAccessPointRequest\nRoot level tag for the CreateAccessPointRequest parameters.\nRequired: Yes\nAmazon S3 Control API Version 2006-03-01 776Amazon Simple Storage Service API Reference\nBucket\nThe name of the bucket that you want to associate this access point with.\nFor using this parameter with Amazon S3 on Outposts with the REST API, you must specify the \nname and the x-amz-outpost-id as well.\nFor using this parameter with S3 on Outposts with the AWS SDK and CLI, you must specify the \nARN of the bucket accessed in the format arn:aws:s3-outposts:<Region>:<account-\nid>:outpost/<outpost-id>/bucket/<my-bucket-name> . For example, to access \nthe bucket reports through Outpost my-outpost  owned by account 123456789012\nin Region us-west-2 , use the URL encoding of arn:aws:s3-outposts:us-\nwest-2:123456789012:outpost/my-outpost/bucket/reports .", "The value must be URL \nencoded.\nType: String\nLength Constraints: Minimum length of 3.", "Maximum length of 255.\nRequired: Yes\nBucketAccountId\nThe AWS account ID associated with the S3 bucket associated with this access point.\nFor same account access point when your bucket and access point belong to the same account \nowner, the BucketAccountId  is not required. For cross-account access point when your bucket \nand access point are not in the same account, the BucketAccountId  is required.\nType: String\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: No\nPublicAccessBlockCon\ufb01guration\nThe PublicAccessBlock  con\ufb01guration that you want to apply to the access point.\nType: PublicAccessBlockCon\ufb01guration data type\nRequired: No\nAmazon S3 Control API Version 2006-03-01 777Amazon Simple Storage Service API Reference\nVpcCon\ufb01guration\nIf you include this \ufb01eld, Amazon S3 restricts access to this access point to requests from the \nspeci\ufb01ed virtual private cloud (VPC).\nNote\nThis is required for creating an access point for Amazon S3 on Outposts buckets.\nType: VpcCon\ufb01guration data type\nRequired: No\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<CreateAccessPointResult > \n   <AccessPointArn >string</AccessPointArn > \n   <Alias>string</Alias>\n</CreateAccessPointResult >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nCreateAccessPointResult\nRoot level tag for the CreateAccessPointResult parameters.\nRequired: Yes\nAccessPointArn\nThe ARN of the access point.\nNote\nThis is only supported by Amazon S3 on Outposts.\nAmazon S3 Control API Version 2006-03-01 778Amazon Simple Storage Service API Reference\nType: String\nLength Constraints: Minimum length of 4. Maximum length of 128.\nAlias\nThe name or alias of the access point.\nType: String\nLength Constraints: Maximum length of 63.\nPattern: ^[0-9a-z\\\\-]{63}\nExamples\nSample request for creating an access point for an Amazon S3 on Outposts bucket\nThis request creates an access point for S3 on Outposts bucket.\n            PUT /v20180820/accesspoint/example-access-point HTTP/1.1 \n            Host:s3-outposts.<Region>.amazonaws.com \n            x-amz-account-id: example-account-id \n            x-amz-outpost-id: op-01ac5d28a6a232904 \n            <?xml version=\"1.0\" encoding=\"UTF-8\"?> \n               <CreateAccessPointRequest xmlns=\"http://awss3control.amazonaws.com/\ndoc/2018-08-20/\"> \n                  <Bucket>example-outpost-bucket </Bucket> \n               </CreateAccessPointRequest> \n          \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\nAmazon S3 Control API Version 2006-03-01 779Amazon Simple Storage Service API Reference\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 780Amazon Simple Storage Service API Reference\nCreateAccessPointForObjectLambda\nService: Amazon S3 Control\nNote\nThis operation is not supported by directory buckets.\nCreates an Object Lambda Access Point. For more information, see Transforming objects with \nObject Lambda Access Points in the Amazon S3 User Guide .\nThe following actions are related to CreateAccessPointForObjectLambda :\n\u2022DeleteAccessPointForObjectLambda\n\u2022GetAccessPointForObjectLambda\n\u2022ListAccessPointsForObjectLambda\nRequest Syntax\nPUT /v20180820/accesspointforobjectlambda/ name HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<CreateAccessPointForObjectLambdaRequest  xmlns=\"http://awss3control.amazonaws.com/\ndoc/2018-08-20/\"> \n   <Configuration > \n      <AllowedFeatures > \n         <AllowedFeature> string</AllowedFeature> \n      </ AllowedFeatures > \n      <CloudWatchMetricsEnabled >boolean</CloudWatchMetricsEnabled > \n      <SupportingAccessPoint >string</SupportingAccessPoint > \n      <TransformationConfigurations > \n         <TransformationConfiguration> \n            < Actions> \n               <Action> string</Action> \n            </ Actions> \n            < ContentTransformation > \n               < AwsLambda > \n                  < FunctionArn >string</FunctionArn > \n                  < FunctionPayload >string</FunctionPayload > \n               </ AwsLambda > \nAmazon S3 Control API Version 2006-03-01 781Amazon Simple Storage Service API Reference\n            </ ContentTransformation > \n         </TransformationConfiguration> \n      </ TransformationConfigurations > \n   </Configuration >\n</CreateAccessPointForObjectLambdaRequest >\nURI Request Parameters\nThe request uses the following URI parameters.\nname\nThe name you want to assign to this Object Lambda Access Point.\nLength Constraints: Minimum length of 3. Maximum length of 45.\nPattern: ^[a-z0-9]([a-z0-9\\-]*[a-z0-9])?$\nRequired: Yes\nx-amz-account-id\nThe AWS account ID for owner of the speci\ufb01ed Object Lambda Access Point.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request accepts the following data in XML format.\nCreateAccessPointForObjectLambdaRequest\nRoot level tag for the CreateAccessPointForObjectLambdaRequest parameters.\nRequired: Yes\nCon\ufb01guration\nObject Lambda Access Point con\ufb01guration as a JSON document.\nAmazon S3 Control API Version 2006-03-01 782Amazon Simple Storage Service API Reference\nType: ObjectLambdaCon\ufb01guration data type\nRequired: Yes\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<CreateAccessPointForObjectLambdaResult > \n   <ObjectLambdaAccessPointArn >string</ObjectLambdaAccessPointArn > \n   <Alias> \n      <Status>string</Status> \n      <Value>string</Value> \n   </Alias>\n</CreateAccessPointForObjectLambdaResult >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nCreateAccessPointForObjectLambdaResult\nRoot level tag for the CreateAccessPointForObjectLambdaResult parameters.\nRequired: Yes\nAlias\nThe alias of the Object Lambda Access Point.\nType: ObjectLambdaAccessPointAlias data type\nObjectLambdaAccessPointArn\nSpeci\ufb01es the ARN for the Object Lambda Access Point.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 2048.\nPattern: arn:[^:]+:s3-object-lambda:[^:]*:\\d{12}:accesspoint/.*\nAmazon S3 Control API Version 2006-03-01 783Amazon Simple Storage Service API Reference\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 784Amazon Simple Storage Service API Reference\nCreateBucket\nService: Amazon S3 Control\nNote\nThis action creates an Amazon S3 on Outposts bucket. To create an S3 bucket, see Create \nBucket in the Amazon S3 API Reference.\nCreates a new Outposts bucket.", "By creating the bucket, you become the bucket owner.", "To create an \nOutposts bucket, you must have S3 on Outposts. For more information, see Using Amazon S3 on \nOutposts  in Amazon S3 User Guide .\nNot every string is an acceptable bucket name. For information on bucket naming restrictions, see\nWorking with Amazon S3 Buckets.\nS3 on Outposts buckets support:\n\u2022Tags\n\u2022LifecycleCon\ufb01gurations for deleting expired objects\nFor a complete list of restrictions and Amazon S3 feature limitations on S3 on Outposts, see \nAmazon S3 on Outposts Restrictions and Limitations.\nFor an example of the request syntax for Amazon S3 on Outposts that uses the S3 on Outposts \nendpoint hostname pre\ufb01x and x-amz-outpost-id  in your API request, see the Examples  section.\nThe following actions are related to CreateBucket  for Amazon S3 on Outposts:\n\u2022PutObject\n\u2022GetBucket\n\u2022DeleteBucket\n\u2022CreateAccessPoint\n\u2022PutAccessPointPolicy\nRequest Syntax\nPUT /v20180820/bucket/ name HTTP/1.1\nAmazon S3 Control API Version 2006-03-01 785Amazon Simple Storage Service API Reference\nHost: Bucket.s3-control.amazonaws.com\nx-amz-acl: ACL\nx-amz-grant-full-control: GrantFullControl\nx-amz-grant-read: GrantRead\nx-amz-grant-read-acp: GrantReadACP\nx-amz-grant-write: GrantWrite\nx-amz-grant-write-acp: GrantWriteACP\nx-amz-bucket-object-lock-enabled: ObjectLockEnabledForBucket\nx-amz-outpost-id: OutpostId\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<CreateBucketConfiguration  xmlns=\"http://awss3control.amazonaws.com/doc/2018-08-20/\"> \n   <LocationConstraint >string</LocationConstraint >\n</CreateBucketConfiguration >\nURI Request Parameters\nThe request uses the following URI parameters.\nname\nThe name of the bucket.\nLength Constraints: Minimum length of 3. Maximum length of 255.\nRequired: Yes\nx-amz-acl\nThe canned ACL to apply to the bucket.\nNote\nThis is not supported by Amazon S3 on Outposts buckets.\nValid Values: private | public-read | public-read-write | authenticated-read\nx-amz-bucket-object-lock-enabled\nSpeci\ufb01es whether you want S3 Object Lock to be enabled for the new bucket.\nNote\nThis is not supported by Amazon S3 on Outposts buckets.\nAmazon S3 Control API Version 2006-03-01 786Amazon Simple Storage Service API Reference\nx-amz-grant-full-control\nAllows grantee the read, write, read ACP, and write ACP permissions on the bucket.\nNote\nThis is not supported by Amazon S3 on Outposts buckets.\nx-amz-grant-read\nAllows grantee to list the objects in the bucket.\nNote\nThis is not supported by Amazon S3 on Outposts buckets.\nx-amz-grant-read-acp\nAllows grantee to read the bucket ACL.\nNote\nThis is not supported by Amazon S3 on Outposts buckets.\nx-amz-grant-write\nAllows grantee to create, overwrite, and delete any object in the bucket.\nNote\nThis is not supported by Amazon S3 on Outposts buckets.\nx-amz-grant-write-acp\nAllows grantee to write the ACL for the applicable bucket.\nAmazon S3 Control API Version 2006-03-01 787Amazon Simple Storage Service API Reference\nNote\nThis is not supported by Amazon S3 on Outposts buckets.\nx-amz-outpost-id\nThe ID of the Outposts where the bucket is being created.\nNote\nThis ID is required by Amazon S3 on Outposts buckets.\nLength Constraints: Minimum length of 1.", "Maximum length of 64.\nRequest Body\nThe request accepts the following data in XML format.\nCreateBucketCon\ufb01guration\nRoot level tag for the CreateBucketCon\ufb01guration parameters.\nRequired: Yes\nLocationConstraint\nSpeci\ufb01es the Region where the bucket will be created.", "If you are creating a bucket on the US \nEast (N. Virginia) Region (us-east-1), you do not need to specify the location.\nNote\nThis is not supported by Amazon S3 on Outposts buckets.\nType: String\nValid Values: EU | eu-west-1 | us-west-1 | us-west-2 | ap-south-1 | ap-\nsoutheast-1 | ap-southeast-2 | ap-northeast-1 | sa-east-1 | cn-north-1 | \neu-central-1\nAmazon S3 Control API Version 2006-03-01 788Amazon Simple Storage Service API Reference\nRequired: No\nResponse Syntax\nHTTP/1.1 200\nLocation: Location\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<CreateBucketResult > \n   <BucketArn >string</BucketArn >\n</CreateBucketResult >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe response returns the following HTTP headers.\nLocation\nThe location of the bucket.\nThe following data is returned in XML format by the service.\nCreateBucketResult\nRoot level tag for the CreateBucketResult parameters.\nRequired: Yes\nBucketArn\nThe Amazon Resource Name (ARN) of the bucket.\nFor using this parameter with Amazon S3 on Outposts with the REST API, you must specify the \nname and the x-amz-outpost-id as well.\nFor using this parameter with S3 on Outposts with the AWS SDK and CLI, you must specify the \nARN of the bucket accessed in the format arn:aws:s3-outposts:<Region>:<account-\nid>:outpost/<outpost-id>/bucket/<my-bucket-name> . For example, to access \nthe bucket reports through Outpost my-outpost  owned by account 123456789012\nin Region us-west-2 , use the URL encoding of arn:aws:s3-outposts:us-\nAmazon S3 Control API Version 2006-03-01 789Amazon Simple Storage Service API Reference\nwest-2:123456789012:outpost/my-outpost/bucket/reports .", "The value must be URL \nencoded.\nType: String\nLength Constraints: Minimum length of 4.", "Maximum length of 128.\nErrors\nBucketAlreadyExists\nThe requested Outposts bucket name is not available. The bucket namespace is shared by all \nusers of the AWS Outposts in this Region. Select a di\ufb00erent name and try again.\nHTTP Status Code: 400\nBucketAlreadyOwnedByYou\nThe Outposts bucket you tried to create already exists, and you own it.\nHTTP Status Code: 400\nExamples\nSample request to create an Amazon S3 on Outposts bucket\nThis request creates an Outposts bucket named example-outpost-bucket .\n            PUT /v20180820/bucket/example-outpost-bucket/  HTTP/1.1 \n            Host:s3-outposts.<Region>.amazonaws.com \n            x-amz-outpost-id: op-01ac5d28a6a232904 \n            Content-Length:  \n            Date: Wed, 01 Mar  2006 12:00:00 GMT \n            Authorization: authorization string \n          \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\nAmazon S3 Control API Version 2006-03-01 790Amazon Simple Storage Service API Reference\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 791Amazon Simple Storage Service API Reference\nCreateJob\nService: Amazon S3 Control\nThis operation creates an S3 Batch Operations job.\nYou can use S3 Batch Operations to perform large-scale batch actions on Amazon S3 objects. \nBatch Operations can run a single action on lists of Amazon S3 objects that you specify. For more \ninformation, see S3 Batch Operations  in the Amazon S3 User Guide .\nPermissions\nFor information about permissions required to use the Batch Operations, see Granting \npermissions for S3 Batch Operations  in the Amazon S3 User Guide .\nRelated actions include:\n\u2022DescribeJob\n\u2022ListJobs\n\u2022UpdateJobPriority\n\u2022UpdateJobStatus\n\u2022JobOperation\nRequest Syntax\nPOST /v20180820/jobs HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<CreateJobRequest  xmlns=\"http://awss3control.amazonaws.com/doc/2018-08-20/\"> \n   <ConfirmationRequired >boolean</ConfirmationRequired > \n   <Operation > \n      <LambdaInvoke > \n         < FunctionArn >string</FunctionArn > \n         < InvocationSchemaVersion >string</InvocationSchemaVersion > \n         < UserArguments > \n            <entry> \n               <key> string</key> \n               <value> string</value> \n            </entry> \nAmazon S3 Control API Version 2006-03-01 792Amazon Simple Storage Service API Reference\n         </ UserArguments > \n      </ LambdaInvoke > \n      <S3DeleteObjectTagging > \n      </ S3DeleteObjectTagging > \n      <S3InitiateRestoreObject > \n         < ExpirationInDays >integer</ExpirationInDays > \n         < GlacierJobTier >string</GlacierJobTier > \n      </ S3InitiateRestoreObject > \n      <S3PutObjectAcl > \n         < AccessControlPolicy > \n            < AccessControlList > \n               < Grants> \n                  <S3Grant> \n                     < Grantee> \n                        < DisplayName >string</DisplayName > \n                        < Identifier >string</Identifier > \n                        < TypeIdentifier >string</TypeIdentifier > \n                     </ Grantee> \n                     < Permission >string</Permission > \n                  </S3Grant> \n               </ Grants> \n               < Owner> \n                  < DisplayName >string</DisplayName > \n                  < ID>string</ID> \n               </ Owner> \n            </ AccessControlList > \n            < CannedAccessControlList >string</CannedAccessControlList > \n         </ AccessControlPolicy > \n      </ S3PutObjectAcl > \n      <S3PutObjectCopy > \n         < AccessControlGrants > \n            <S3Grant> \n               < Grantee> \n                  < DisplayName >string</DisplayName > \n                  < Identifier >string</Identifier > \n                  < TypeIdentifier >string</TypeIdentifier > \n               </ Grantee> \n               < Permission >string</Permission > \n            </S3Grant> \n         </ AccessControlGrants > \n         < BucketKeyEnabled >boolean</BucketKeyEnabled > \n         < CannedAccessControlList >string</CannedAccessControlList > \n         < ChecksumAlgorithm >string</ChecksumAlgorithm > \n         < MetadataDirective >string</MetadataDirective > \nAmazon S3 Control API Version 2006-03-01 793Amazon Simple Storage Service API Reference\n         < ModifiedSinceConstraint >timestamp </ModifiedSinceConstraint > \n         < NewObjectMetadata > \n            < CacheControl >string</CacheControl > \n            < ContentDisposition >string</ContentDisposition > \n            < ContentEncoding >string</ContentEncoding > \n            < ContentLanguage >string</ContentLanguage > \n            < ContentLength >long</ContentLength > \n            < ContentMD5 >string</ContentMD5 > \n            < ContentType >string</ContentType > \n            < HttpExpiresDate >timestamp </HttpExpiresDate > \n            < RequesterCharged >boolean</RequesterCharged > \n            < SSEAlgorithm >string</SSEAlgorithm > \n            < UserMetadata > \n               <entry> \n                  <key> string</key> \n                  <value> string</value> \n               </entry> \n            </ UserMetadata > \n         </ NewObjectMetadata > \n         < NewObjectTagging > \n            <S3Tag> \n               < Key>string</Key> \n               < Value>string</Value> \n            </S3Tag> \n         </ NewObjectTagging > \n         < ObjectLockLegalHoldStatus >string</ObjectLockLegalHoldStatus > \n         < ObjectLockMode >string</ObjectLockMode > \n         < ObjectLockRetainUntilDate >timestamp </ObjectLockRetainUntilDate > \n         < RedirectLocation >string</RedirectLocation > \n         < RequesterPays >boolean</RequesterPays > \n         < SSEAwsKmsKeyId >string</SSEAwsKmsKeyId > \n         < StorageClass >string</StorageClass > \n         < TargetKeyPrefix >string</TargetKeyPrefix > \n         < TargetResource >string</TargetResource > \n         < UnModifiedSinceConstraint >timestamp </UnModifiedSinceConstraint > \n      </ S3PutObjectCopy > \n      <S3PutObjectLegalHold > \n         < LegalHold > \n            < Status>string</Status> \n         </ LegalHold > \n      </ S3PutObjectLegalHold > \n      <S3PutObjectRetention > \n         < BypassGovernanceRetention >boolean</BypassGovernanceRetention > \n         < Retention > \nAmazon S3 Control API Version 2006-03-01 794Amazon Simple Storage Service API Reference\n            < Mode>string</Mode> \n            < RetainUntilDate >timestamp </RetainUntilDate > \n         </ Retention > \n      </ S3PutObjectRetention > \n      <S3PutObjectTagging > \n         < TagSet> \n            <S3Tag> \n               < Key>string</Key> \n               < Value>string</Value> \n            </S3Tag> \n         </ TagSet> \n      </ S3PutObjectTagging > \n      <S3ReplicateObject > \n      </ S3ReplicateObject > \n   </Operation > \n   <Report> \n      <Bucket>string</Bucket> \n      <Enabled>boolean</Enabled> \n      <Format>string</Format> \n      <Prefix>string</Prefix> \n      <ReportScope >string</ReportScope > \n   </Report> \n   <ClientRequestToken >string</ClientRequestToken > \n   <Manifest > \n      <Location > \n         < ETag>string</ETag> \n         < ObjectArn >string</ObjectArn > \n         < ObjectVersionId >string</ObjectVersionId > \n      </ Location > \n      <Spec> \n         < Fields> \n            <member> string</member> \n         </ Fields> \n         < Format>string</Format> \n      </ Spec> \n   </Manifest > \n   <Description >string</Description > \n   <Priority >integer</Priority > \n   <RoleArn>string</RoleArn> \n   <Tags> \n      <S3Tag> \n         < Key>string</Key> \n         < Value>string</Value> \n      </S3Tag> \nAmazon S3 Control API Version 2006-03-01 795Amazon Simple Storage Service API Reference\n   </Tags> \n   <ManifestGenerator > \n      <S3JobManifestGenerator > \n         < EnableManifestOutput >boolean</EnableManifestOutput > \n         < ExpectedBucketOwner >string</ExpectedBucketOwner > \n         < Filter> \n            < CreatedAfter >timestamp </CreatedAfter > \n            < CreatedBefore >timestamp </CreatedBefore > \n            < EligibleForReplication >boolean</EligibleForReplication > \n            < KeyNameConstraint > \n               < MatchAnyPrefix > \n                  <member> string</member> \n               </ MatchAnyPrefix > \n               < MatchAnySubstring > \n                  <member> string</member> \n               </ MatchAnySubstring > \n               < MatchAnySuffix > \n                  <member> string</member> \n               </ MatchAnySuffix > \n            </ KeyNameConstraint > \n            < MatchAnyStorageClass > \n               <member> string</member> \n            </ MatchAnyStorageClass > \n            < ObjectReplicationStatuses > \n               <member> string</member> \n            </ ObjectReplicationStatuses > \n            < ObjectSizeGreaterThanBytes >long</ObjectSizeGreaterThanBytes > \n            < ObjectSizeLessThanBytes >long</ObjectSizeLessThanBytes > \n         </ Filter> \n         < ManifestOutputLocation > \n            < Bucket>string</Bucket> \n            < ExpectedManifestBucketOwner >string</ExpectedManifestBucketOwner > \n            < ManifestEncryption > \n               < SSE-KMS> \n                  < KeyId>string</KeyId> \n               </ SSE-KMS> \n               < SSE-S3> \n               </ SSE-S3> \n            </ ManifestEncryption > \n            < ManifestFormat >string</ManifestFormat > \n            < ManifestPrefix >string</ManifestPrefix > \n         </ ManifestOutputLocation > \n         < SourceBucket >string</SourceBucket > \n      </ S3JobManifestGenerator > \nAmazon S3 Control API Version 2006-03-01 796Amazon Simple Storage Service API Reference\n   </ManifestGenerator >\n</CreateJobRequest >\nURI Request Parameters\nThe request uses the following URI parameters.\nx-amz-account-id\nThe AWS account ID that creates the job.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request accepts the following data in XML format.\nCreateJobRequest\nRoot level tag for the CreateJobRequest parameters.\nRequired: Yes\nClientRequestToken\nAn idempotency token to ensure that you don't accidentally submit the same request twice.", "You \ncan use any string up to the maximum length.\nType: String\nLength Constraints: Minimum length of 1.", "Maximum length of 64.\nRequired: Yes\nCon\ufb01rmationRequired\nIndicates whether con\ufb01rmation is required before Amazon S3 runs the job. Con\ufb01rmation is only \nrequired for jobs created through the Amazon S3 console.\nType: Boolean\nAmazon S3 Control API Version 2006-03-01 797Amazon Simple Storage Service API Reference\nRequired: No\nDescription\nA description for this job.", "You can use any string within the permitted length.", "Descriptions don't \nneed to be unique and can be used for multiple jobs.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 256.\nRequired: No\nManifest\nCon\ufb01guration parameters for the manifest.\nType: JobManifest  data type\nRequired: No\nManifestGenerator\nThe attribute container for the ManifestGenerator details. Jobs must be created with either a \nmanifest \ufb01le or a ManifestGenerator, but not both.\nType: JobManifestGenerator  data type\nNote: This object is a Union. Only one member of this object can be speci\ufb01ed or returned.\nRequired: No\nOperation\nThe action that you want this job to perform on every object listed in the manifest.", "For more \ninformation about the available actions, see Operations  in the Amazon S3 User Guide .\nType: JobOperation  data type\nRequired: Yes\nPriority\nThe numerical priority for this job. Higher numbers indicate higher priority.\nType: Integer\nAmazon S3 Control API Version 2006-03-01 798Amazon Simple Storage Service API Reference\nValid Range: Minimum value of 0.", "Maximum value of 2147483647.\nRequired: Yes\nReport\nCon\ufb01guration parameters for the optional job-completion report.\nType: JobReport data type\nRequired: Yes\nRoleArn\nThe Amazon Resource Name (ARN) for the AWS Identity and Access Management (IAM) role that \nBatch Operations will use to run this job's action on every object in the manifest.\nType: String\nLength Constraints: Minimum length of 1.", "Maximum length of 2048.\nPattern: arn:[^:]+:iam::\\d{12}:role/.*\nRequired: Yes\nTags\nA set of tags to associate with the S3 Batch Operations job. This is an optional parameter.\nType: Array of S3Tag data types\nRequired: No\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<CreateJobResult > \n   <JobId>string</JobId>\n</CreateJobResult >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nAmazon S3 Control API Version 2006-03-01 799Amazon Simple Storage Service API Reference\nThe following data is returned in XML format by the service.\nCreateJobResult\nRoot level tag for the CreateJobResult parameters.\nRequired: Yes\nJobId\nThe ID for this job. Amazon S3 generates this ID automatically and returns it after a successful\nCreate Job  request.\nType: String\nLength Constraints: Minimum length of 5.", "Maximum length of 36.\nPattern: [a-zA-Z0-9\\-\\_]+\nErrors\nBadRequestException\nHTTP Status Code: 400\nIdempotencyException\nHTTP Status Code: 400\nInternalServiceException\nHTTP Status Code: 500\nTooManyRequestsException\nHTTP Status Code: 400\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\nAmazon S3 Control API Version 2006-03-01 800Amazon Simple Storage Service API Reference\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 801Amazon Simple Storage Service API Reference\nCreateMultiRegionAccessPoint\nService: Amazon S3 Control\nNote\nThis operation is not supported by directory buckets.\nCreates a Multi-Region Access Point and associates it with the speci\ufb01ed buckets.", "For more \ninformation about creating Multi-Region Access Points, see Creating Multi-Region Access Points in \nthe Amazon S3 User Guide .\nThis action will always be routed to the US West (Oregon) Region. For more information about \nthe restrictions around working with Multi-Region Access Points, see Multi-Region Access Point \nrestrictions and limitations in the Amazon S3 User Guide .\nThis request is asynchronous, meaning that you might receive a response before the command has \ncompleted. When this request provides a response, it provides a token that you can use to monitor \nthe status of the request with DescribeMultiRegionAccessPointOperation .\nThe following actions are related to CreateMultiRegionAccessPoint :\n\u2022DeleteMultiRegionAccessPoint\n\u2022DescribeMultiRegionAccessPointOperation\n\u2022GetMultiRegionAccessPoint\n\u2022ListMultiRegionAccessPoints\nRequest Syntax\nPOST /v20180820/async-requests/mrap/create HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<CreateMultiRegionAccessPointRequest  xmlns=\"http://awss3control.amazonaws.com/\ndoc/2018-08-20/\"> \n   <ClientToken >string</ClientToken > \n   <Details> \n      <Name>string</Name> \n      <PublicAccessBlock > \nAmazon S3 Control API Version 2006-03-01 802Amazon Simple Storage Service API Reference\n         < BlockPublicAcls >boolean</BlockPublicAcls > \n         < BlockPublicPolicy >boolean</BlockPublicPolicy > \n         < IgnorePublicAcls >boolean</IgnorePublicAcls > \n         < RestrictPublicBuckets >boolean</RestrictPublicBuckets > \n      </ PublicAccessBlock > \n      <Regions> \n         <Region> \n            < Bucket>string</Bucket> \n            < BucketAccountId >string</BucketAccountId > \n         </Region> \n      </ Regions> \n   </Details>\n</CreateMultiRegionAccessPointRequest >\nURI Request Parameters\nThe request uses the following URI parameters.\nx-amz-account-id\nThe AWS account ID for the owner of the Multi-Region Access Point. The owner of the Multi-\nRegion Access Point also must own the underlying buckets.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request accepts the following data in XML format.\nCreateMultiRegionAccessPointRequest\nRoot level tag for the CreateMultiRegionAccessPointRequest parameters.\nRequired: Yes\nClientToken\nAn idempotency token used to identify the request and guarantee that requests are unique.\nType: String\nAmazon S3 Control API Version 2006-03-01 803Amazon Simple Storage Service API Reference\nLength Constraints: Maximum length of 64.\nPattern: \\S+\nRequired: Yes\nDetails\nA container element containing details about the Multi-Region Access Point.\nType: CreateMultiRegionAccessPointInput data type\nRequired: Yes\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<CreateMultiRegionAccessPointResult > \n   <RequestTokenARN >string</RequestTokenARN >\n</CreateMultiRegionAccessPointResult >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nCreateMultiRegionAccessPointResult\nRoot level tag for the CreateMultiRegionAccessPointResult parameters.\nRequired: Yes\nRequestTokenARN\nThe request token associated with the request.", "You can use this token with\nDescribeMultiRegionAccessPointOperation to determine the status of asynchronous requests.\nType: String\nLength Constraints: Minimum length of 1.", "Maximum length of 1024.\nPattern: arn:.+\nAmazon S3 Control API Version 2006-03-01 804Amazon Simple Storage Service API Reference\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 805Amazon Simple Storage Service API Reference\nCreateStorageLensGroup\nService: Amazon S3 Control\nCreates a new S3 Storage Lens group and associates it with the speci\ufb01ed AWS account ID. An S3 \nStorage Lens group is a custom grouping of objects based on pre\ufb01x, su\ufb03x, object tags, object size, \nobject age, or a combination of these \ufb01lters. For each Storage Lens group that you\u2019ve created, you \ncan also optionally add AWS resource tags. For more information about S3 Storage Lens groups, \nsee Working with S3 Storage Lens groups.\nTo use this operation, you must have the permission to perform the\ns3:CreateStorageLensGroup  action. If you\u2019re trying to create a Storage Lens group with AWS \nresource tags, you must also have permission to perform the s3:TagResource  action. For more \ninformation about the required Storage Lens Groups permissions, see Setting account permissions \nto use S3 Storage Lens groups.\nFor information about Storage Lens groups errors, see List of Amazon S3 Storage Lens error codes.\nRequest Syntax\nPOST /v20180820/storagelensgroup HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<CreateStorageLensGroupRequest  xmlns=\"http://awss3control.amazonaws.com/\ndoc/2018-08-20/\"> \n   <StorageLensGroup > \n      <Filter> \n         < And> \n            < MatchAnyPrefix > \n               <Prefix> string</Prefix> \n            </ MatchAnyPrefix > \n            < MatchAnySuffix > \n               <Suffix> string</Suffix> \n            </ MatchAnySuffix > \n            < MatchAnyTag > \n               <Tag> \n                  < Key>string</Key> \n                  < Value>string</Value> \n               </Tag> \n            </ MatchAnyTag > \n            < MatchObjectAge > \n               < DaysGreaterThan >integer</DaysGreaterThan > \nAmazon S3 Control API Version 2006-03-01 806Amazon Simple Storage Service API Reference\n               < DaysLessThan >integer</DaysLessThan > \n            </ MatchObjectAge > \n            < MatchObjectSize > \n               < BytesGreaterThan >long</BytesGreaterThan > \n               < BytesLessThan >long</BytesLessThan > \n            </ MatchObjectSize > \n         </ And> \n         < MatchAnyPrefix > \n            <Prefix> string</Prefix> \n         </ MatchAnyPrefix > \n         < MatchAnySuffix > \n            <Suffix> string</Suffix> \n         </ MatchAnySuffix > \n         < MatchAnyTag > \n            <Tag> \n               < Key>string</Key> \n               < Value>string</Value> \n            </Tag> \n         </ MatchAnyTag > \n         < MatchObjectAge > \n            < DaysGreaterThan >integer</DaysGreaterThan > \n            < DaysLessThan >integer</DaysLessThan > \n         </ MatchObjectAge > \n         < MatchObjectSize > \n            < BytesGreaterThan >long</BytesGreaterThan > \n            < BytesLessThan >long</BytesLessThan > \n         </ MatchObjectSize > \n         < Or> \n            < MatchAnyPrefix > \n               <Prefix> string</Prefix> \n            </ MatchAnyPrefix > \n            < MatchAnySuffix > \n               <Suffix> string</Suffix> \n            </ MatchAnySuffix > \n            < MatchAnyTag > \n               <Tag> \n                  < Key>string</Key> \n                  < Value>string</Value> \n               </Tag> \n            </ MatchAnyTag > \n            < MatchObjectAge > \n               < DaysGreaterThan >integer</DaysGreaterThan > \n               < DaysLessThan >integer</DaysLessThan > \n            </ MatchObjectAge > \nAmazon S3 Control API Version 2006-03-01 807Amazon Simple Storage Service API Reference\n            < MatchObjectSize > \n               < BytesGreaterThan >long</BytesGreaterThan > \n               < BytesLessThan >long</BytesLessThan > \n            </ MatchObjectSize > \n         </ Or> \n      </ Filter> \n      <Name>string</Name> \n      <StorageLensGroupArn >string</StorageLensGroupArn > \n   </StorageLensGroup > \n   <Tags> \n      <Tag> \n         < Key>string</Key> \n         < Value>string</Value> \n      </Tag> \n   </Tags>\n</CreateStorageLensGroupRequest >\nURI Request Parameters\nThe request uses the following URI parameters.\nx-amz-account-id\nThe AWS account ID that the Storage Lens group is created from and associated with.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request accepts the following data in XML format.\nCreateStorageLensGroupRequest\nRoot level tag for the CreateStorageLensGroupRequest parameters.\nRequired: Yes\nStorageLensGroup\nThe Storage Lens group con\ufb01guration.\nAmazon S3 Control API Version 2006-03-01 808Amazon Simple Storage Service API Reference\nType: StorageLensGroup data type\nRequired: Yes\nTags\nThe AWS resource tags that you're adding to your Storage Lens group.", "This parameter is \noptional.\nType: Array of Tag data types\nArray Members: Minimum number of 0 items.", "Maximum number of 50 items.\nRequired: No\nResponse Syntax\nHTTP/1.1 204\nResponse Elements\nIf the action is successful, the service sends back an HTTP 204 response with an empty HTTP body.\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 809Amazon Simple Storage Service API Reference\nDeleteAccessGrant\nService: Amazon S3 Control\nDeletes the access grant from the S3 Access Grants instance. You cannot undo an access grant \ndeletion and the grantee will no longer have access to the S3 data.\nPermissions\nYou must have the s3:DeleteAccessGrant  permission to use this operation.\nRequest Syntax\nDELETE /v20180820/accessgrantsinstance/grant/ id HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nid\nThe ID of the access grant. S3 Access Grants auto-generates this ID when you create the access \ngrant.\nLength Constraints: Minimum length of 1. Maximum length of 64.\nPattern: [a-zA-Z0-9\\-]+\nRequired: Yes\nx-amz-account-id\nThe AWS account ID of the S3 Access Grants instance.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nAmazon S3 Control API Version 2006-03-01 810Amazon Simple Storage Service API Reference\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 811Amazon Simple Storage Service API Reference\nDeleteAccessGrantsInstance\nService: Amazon S3 Control\nDeletes your S3 Access Grants instance. You must \ufb01rst delete the access grants and locations before \nS3 Access Grants can delete the instance.", "See DeleteAccessGrant and DeleteAccessGrantsLocation.", "\nIf you have associated an IAM Identity Center instance with your S3 Access Grants instance, you \nmust \ufb01rst dissassociate the Identity Center instance from the S3 Access Grants instance before \nyou can delete the S3 Access Grants instance. See AssociateAccessGrantsIdentityCenter and\nDissociateAccessGrantsIdentityCenter.\nPermissions\nYou must have the s3:DeleteAccessGrantsInstance  permission to use this operation.\nRequest Syntax\nDELETE /v20180820/accessgrantsinstance HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nx-amz-account-id\nThe AWS account ID of the S3 Access Grants instance.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\nAmazon S3 Control API Version 2006-03-01 812Amazon Simple Storage Service API Reference\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 813Amazon Simple Storage Service API Reference\nDeleteAccessGrantsInstanceResourcePolicy\nService: Amazon S3 Control\nDeletes the resource policy of the S3 Access Grants instance. The resource policy is used to manage \ncross-account access to your S3 Access Grants instance. By deleting the resource policy, you delete \nany cross-account permissions to your S3 Access Grants instance.\nPermissions\nYou must have the s3:DeleteAccessGrantsInstanceResourcePolicy  permission to use \nthis operation.\nRequest Syntax\nDELETE /v20180820/accessgrantsinstance/resourcepolicy HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nx-amz-account-id\nThe AWS account ID of the S3 Access Grants instance.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\nAmazon S3 Control API Version 2006-03-01 814Amazon Simple Storage Service API Reference\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 815Amazon Simple Storage Service API Reference\nDeleteAccessGrantsLocation\nService: Amazon S3 Control\nDeregisters a location from your S3 Access Grants instance. You can only delete a location \nregistration from an S3 Access Grants instance if there are no grants associated with this location.", "\nSee Delete a grant  for information on how to delete grants.", "You need to have at least one \nregistered location in your S3 Access Grants instance in order to create access grants.\nPermissions\nYou must have the s3:DeleteAccessGrantsLocation  permission to use this operation.\nRequest Syntax\nDELETE /v20180820/accessgrantsinstance/location/ id HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nid\nThe ID of the registered location that you are deregistering from your S3 Access Grants instance. \nS3 Access Grants assigned this ID when you registered the location. S3 Access Grants assigns the \nID default  to the default location s3://  and assigns an auto-generated ID to other locations \nthat you register.\nLength Constraints: Minimum length of 1. Maximum length of 64.\nPattern: [a-zA-Z0-9\\-]+\nRequired: Yes\nx-amz-account-id\nThe AWS account ID of the S3 Access Grants instance.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nAmazon S3 Control API Version 2006-03-01 816Amazon Simple Storage Service API Reference\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 817Amazon Simple Storage Service API Reference\nDeleteAccessPoint\nService: Amazon S3 Control\nNote\nThis operation is not supported by directory buckets.\nDeletes the speci\ufb01ed access point.\nAll Amazon S3 on Outposts REST API requests for this action require an additional parameter of\nx-amz-outpost-id  to be passed with the request. In addition, you must use an S3 on Outposts \nendpoint hostname pre\ufb01x instead of s3-control . For an example of the request syntax for \nAmazon S3 on Outposts that uses the S3 on Outposts endpoint hostname pre\ufb01x and the x-amz-\noutpost-id  derived by using the access point ARN, see the Examples  section.\nThe following actions are related to DeleteAccessPoint :\n\u2022CreateAccessPoint\n\u2022GetAccessPoint\n\u2022ListAccessPoints\nRequest Syntax\nDELETE /v20180820/accesspoint/ name HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nname\nThe name of the access point you want to delete.\nFor using this parameter with Amazon S3 on Outposts with the REST API, you must specify the \nname and the x-amz-outpost-id as well.\nAmazon S3 Control API Version 2006-03-01 818Amazon Simple Storage Service API Reference\nFor using this parameter with S3 on Outposts with the AWS SDK and CLI, you \nmust specify the ARN of the access point accessed in the format arn:aws:s3-\noutposts:<Region>:<account-id>:outpost/<outpost-id>/accesspoint/<my-\naccesspoint-name> . For example, to access the access point reports-ap  through \nOutpost my-outpost  owned by account 123456789012  in Region us-west-2 , use the URL \nencoding of arn:aws:s3-outposts:us-west-2:123456789012:outpost/my-outpost/\naccesspoint/reports-ap .", "The value must be URL encoded.\nLength Constraints: Minimum length of 3.", "Maximum length of 255.\nRequired: Yes\nx-amz-account-id\nThe AWS account ID for the account that owns the speci\ufb01ed access point.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\nExamples\nDeleteAccessPoint syntax for Amazon S3 on Outposts\nThe following request deletes the access point of the speci\ufb01ed Outpost.\n           DELETE  /v20180820/accesspoint/example-access-point  HTTP/1.1 \nAmazon S3 Control API Version 2006-03-01 819Amazon Simple Storage Service API Reference\n           Host: s3-outposts.<Region>.amazonaws.com \n           Date: Wed, 28 Oct 2020 22:32:00 GMT \n           x-amz-account-id: example-account-id \n           x-amz-outpost-id: op-01ac5d28a6a232904 \n           Authorization: authorization string \n          \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 820Amazon Simple Storage Service API Reference\nDeleteAccessPointForObjectLambda\nService: Amazon S3 Control\nNote\nThis operation is not supported by directory buckets.\nDeletes the speci\ufb01ed Object Lambda Access Point.\nThe following actions are related to DeleteAccessPointForObjectLambda :\n\u2022CreateAccessPointForObjectLambda\n\u2022GetAccessPointForObjectLambda\n\u2022ListAccessPointsForObjectLambda\nRequest Syntax\nDELETE /v20180820/accesspointforobjectlambda/ name HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nname\nThe name of the access point you want to delete.\nLength Constraints: Minimum length of 3. Maximum length of 45.\nPattern: ^[a-z0-9]([a-z0-9\\-]*[a-z0-9])?$\nRequired: Yes\nx-amz-account-id\nThe account ID for the account that owns the speci\ufb01ed Object Lambda Access Point.\nLength Constraints: Maximum length of 64.\nAmazon S3 Control API Version 2006-03-01 821Amazon Simple Storage Service API Reference\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 822Amazon Simple Storage Service API Reference\nDeleteAccessPointPolicy\nService: Amazon S3 Control\nNote\nThis operation is not supported by directory buckets.\nDeletes the access point policy for the speci\ufb01ed access point.\nAll Amazon S3 on Outposts REST API requests for this action require an additional parameter of\nx-amz-outpost-id  to be passed with the request. In addition, you must use an S3 on Outposts \nendpoint hostname pre\ufb01x instead of s3-control . For an example of the request syntax for \nAmazon S3 on Outposts that uses the S3 on Outposts endpoint hostname pre\ufb01x and the x-amz-\noutpost-id  derived by using the access point ARN, see the Examples  section.\nThe following actions are related to DeleteAccessPointPolicy :\n\u2022PutAccessPointPolicy\n\u2022GetAccessPointPolicy\nRequest Syntax\nDELETE /v20180820/accesspoint/ name/policy HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nname\nThe name of the access point whose policy you want to delete.\nFor using this parameter with Amazon S3 on Outposts with the REST API, you must specify the \nname and the x-amz-outpost-id as well.\nFor using this parameter with S3 on Outposts with the AWS SDK and CLI, you \nmust specify the ARN of the access point accessed in the format arn:aws:s3-\nAmazon S3 Control API Version 2006-03-01 823Amazon Simple Storage Service API Reference\noutposts:<Region>:<account-id>:outpost/<outpost-id>/accesspoint/<my-\naccesspoint-name> . For example, to access the access point reports-ap  through \nOutpost my-outpost  owned by account 123456789012  in Region us-west-2 , use the URL \nencoding of arn:aws:s3-outposts:us-west-2:123456789012:outpost/my-outpost/\naccesspoint/reports-ap .", "The value must be URL encoded.\nLength Constraints: Minimum length of 3.", "Maximum length of 255.\nRequired: Yes\nx-amz-account-id\nThe account ID for the account that owns the speci\ufb01ed access point.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\nExamples\nSample request syntax for using the DeleteAccessPointPolicy action with Amazon S3 on \nOutposts access point\nThis example illustrates one usage of DeleteAccessPointPolicy.\n           DELETE  /v20180820/accesspoint/example-access-point/policy  HTTP/1.1 \n           Host: s3-outposts.<Region>.amazonaws.com \nAmazon S3 Control API Version 2006-03-01 824Amazon Simple Storage Service API Reference\n           Date: Wed, 28 Oct 2020 22:32:00 GMT \n           Authorization: authorization string \n           x-amz-account-id: example-account-id \n           x-amz-outpost-id: op-01ac5d28a6a232904 \n          \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 825Amazon Simple Storage Service API Reference\nDeleteAccessPointPolicyForObjectLambda\nService: Amazon S3 Control\nNote\nThis operation is not supported by directory buckets.\nRemoves the resource policy for an Object Lambda Access Point.\nThe following actions are related to DeleteAccessPointPolicyForObjectLambda :\n\u2022GetAccessPointPolicyForObjectLambda\n\u2022PutAccessPointPolicyForObjectLambda\nRequest Syntax\nDELETE /v20180820/accesspointforobjectlambda/ name/policy HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nname\nThe name of the Object Lambda Access Point you want to delete the policy for.\nLength Constraints: Minimum length of 3. Maximum length of 45.\nPattern: ^[a-z0-9]([a-z0-9\\-]*[a-z0-9])?$\nRequired: Yes\nx-amz-account-id\nThe account ID for the account that owns the speci\ufb01ed Object Lambda Access Point.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nAmazon S3 Control API Version 2006-03-01 826Amazon Simple Storage Service API Reference\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 827Amazon Simple Storage Service API Reference\nDeleteBucket\nService: Amazon S3 Control\nNote\nThis action deletes an Amazon S3 on Outposts bucket.", "To delete an S3 bucket, see\nDeleteBucket in the Amazon S3 API Reference.\nDeletes the Amazon S3 on Outposts bucket.", "All objects (including all object versions and delete \nmarkers) in the bucket must be deleted before the bucket itself can be deleted.", "For more \ninformation, see Using Amazon S3 on Outposts in Amazon S3 User Guide .\nAll Amazon S3 on Outposts REST API requests for this action require an additional parameter of\nx-amz-outpost-id  to be passed with the request. In addition, you must use an S3 on Outposts \nendpoint hostname pre\ufb01x instead of s3-control . For an example of the request syntax for \nAmazon S3 on Outposts that uses the S3 on Outposts endpoint hostname pre\ufb01x and the x-amz-\noutpost-id  derived by using the access point ARN, see the Examples  section.\nRelated Resources\n\u2022CreateBucket\n\u2022GetBucket\n\u2022DeleteObject\nRequest Syntax\nDELETE /v20180820/bucket/ name HTTP/1.1\nHost: Bucket.s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nname\nSpeci\ufb01es the bucket being deleted.\nAmazon S3 Control API Version 2006-03-01 828Amazon Simple Storage Service API Reference\nFor using this parameter with Amazon S3 on Outposts with the REST API, you must specify the \nname and the x-amz-outpost-id as well.\nFor using this parameter with S3 on Outposts with the AWS SDK and CLI, you must specify the \nARN of the bucket accessed in the format arn:aws:s3-outposts:<Region>:<account-\nid>:outpost/<outpost-id>/bucket/<my-bucket-name> . For example, to access \nthe bucket reports through Outpost my-outpost  owned by account 123456789012\nin Region us-west-2 , use the URL encoding of arn:aws:s3-outposts:us-\nwest-2:123456789012:outpost/my-outpost/bucket/reports .", "The value must be URL \nencoded.\nLength Constraints: Minimum length of 3.", "Maximum length of 255.\nRequired: Yes\nx-amz-account-id\nThe account ID that owns the Outposts bucket.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\nExamples\nSample request to delete an Amazon S3 on Outposts bucket\nThis request deletes the Outposts bucket named example-outpost-bucket .\nAmazon S3 Control API Version 2006-03-01 829Amazon Simple Storage Service API Reference\nDELETE /v20180820/bucket/example-outpost-bucket/ HTTP/1.1\nHost: s3-outposts.<Region>.amazonaws.com\nx-amz-outpost-id: op-01ac5d28a6a232904\nx-amz-account-id:example-account-id\nDate: Wed, 01 Mar  2006 12:00:00 GMT\nAuthorization: authorization string \n          \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 830Amazon Simple Storage Service API Reference\nDeleteBucketLifecycleCon\ufb01guration\nService: Amazon S3 Control\nNote\nThis action deletes an Amazon S3 on Outposts bucket's lifecycle con\ufb01guration. To delete \nan S3 bucket's lifecycle con\ufb01guration, see DeleteBucketLifecycle in the Amazon S3 API \nReference.\nDeletes the lifecycle con\ufb01guration from the speci\ufb01ed Outposts bucket. Amazon S3 on Outposts \nremoves all the lifecycle con\ufb01guration rules in the lifecycle subresource associated with the bucket. \nYour objects never expire, and Amazon S3 on Outposts no longer automatically deletes any objects \non the basis of rules contained in the deleted lifecycle con\ufb01guration. For more information, see\nUsing Amazon S3 on Outposts in Amazon S3 User Guide .\nTo use this operation, you must have permission to perform the s3-\noutposts:PutLifecycleConfiguration  action. By default, the bucket owner has this \npermission and the Outposts bucket owner can grant this permission to others.\nAll Amazon S3 on Outposts REST API requests for this action require an additional parameter of\nx-amz-outpost-id  to be passed with the request. In addition, you must use an S3 on Outposts \nendpoint hostname pre\ufb01x instead of s3-control . For an example of the request syntax for \nAmazon S3 on Outposts that uses the S3 on Outposts endpoint hostname pre\ufb01x and the x-amz-\noutpost-id  derived by using the access point ARN, see the Examples  section.\nFor more information about object expiration, see Elements to Describe Lifecycle Actions.\nRelated actions include:\n\u2022PutBucketLifecycleCon\ufb01guration\n\u2022GetBucketLifecycleCon\ufb01guration\nRequest Syntax\nDELETE /v20180820/bucket/ name/lifecycleconfiguration HTTP/1.1\nHost: Bucket.s3-control.amazonaws.com\nx-amz-account-id: AccountId\nAmazon S3 Control API Version 2006-03-01 831Amazon Simple Storage Service API Reference\nURI Request Parameters\nThe request uses the following URI parameters.\nname\nSpeci\ufb01es the bucket.\nFor using this parameter with Amazon S3 on Outposts with the REST API, you must specify the \nname and the x-amz-outpost-id as well.\nFor using this parameter with S3 on Outposts with the AWS SDK and CLI, you must specify the \nARN of the bucket accessed in the format arn:aws:s3-outposts:<Region>:<account-\nid>:outpost/<outpost-id>/bucket/<my-bucket-name> . For example, to access \nthe bucket reports through Outpost my-outpost  owned by account 123456789012\nin Region us-west-2 , use the URL encoding of arn:aws:s3-outposts:us-\nwest-2:123456789012:outpost/my-outpost/bucket/reports .", "The value must be URL \nencoded.\nLength Constraints: Minimum length of 3.", "Maximum length of 255.\nRequired: Yes\nx-amz-account-id\nThe account ID of the lifecycle con\ufb01guration to delete.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\nAmazon S3 Control API Version 2006-03-01 832Amazon Simple Storage Service API Reference\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\nExamples\nSample request to delete the lifecycle con\ufb01guration of an Amazon S3 on Outposts bucket\nThis example illustrates one usage of DeleteBucketLifecycleCon\ufb01guration.\n                  DELETE /v20180820/bucket/example-outpost-bucket/\nlifecycleconfiguration HTTP/1.1 \n                  Host: s3-outposts.<Region>.amazonaws.com  \n                  x-amz-outpost-id: op-01ac5d28a6a232904 \n                  x-amz-account-id:example-account-id \n                \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 833Amazon Simple Storage Service API Reference\nDeleteBucketPolicy\nService: Amazon S3 Control\nNote\nThis action deletes an Amazon S3 on Outposts bucket policy. To delete an S3 bucket policy, \nsee DeleteBucketPolicy in the Amazon S3 API Reference.\nThis implementation of the DELETE action uses the policy subresource to delete the policy \nof a speci\ufb01ed Amazon S3 on Outposts bucket. If you are using an identity other than the \nroot user of the AWS account that owns the bucket, the calling identity must have the s3-\noutposts:DeleteBucketPolicy  permissions on the speci\ufb01ed Outposts bucket and belong \nto the bucket owner's account to use this action. For more information, see Using Amazon S3 on \nOutposts  in Amazon S3 User Guide .\nIf you don't have DeleteBucketPolicy  permissions, Amazon S3 returns a 403 Access Denied\nerror. If you have the correct permissions, but you're not using an identity that belongs to the \nbucket owner's account, Amazon S3 returns a 405 Method Not Allowed  error.\nImportant\nAs a security precaution, the root user of the AWS account that owns a bucket can always \nuse this action, even if the policy explicitly denies the root user the ability to perform this \naction.\nFor more information about bucket policies, see Using Bucket Policies and User Policies.\nAll Amazon S3 on Outposts REST API requests for this action require an additional parameter of\nx-amz-outpost-id  to be passed with the request. In addition, you must use an S3 on Outposts \nendpoint hostname pre\ufb01x instead of s3-control . For an example of the request syntax for \nAmazon S3 on Outposts that uses the S3 on Outposts endpoint hostname pre\ufb01x and the x-amz-\noutpost-id  derived by using the access point ARN, see the Examples  section.\nThe following actions are related to DeleteBucketPolicy :\n\u2022GetBucketPolicy\n\u2022PutBucketPolicy\nAmazon S3 Control API Version 2006-03-01 834Amazon Simple Storage Service API Reference\nRequest Syntax\nDELETE /v20180820/bucket/ name/policy HTTP/1.1\nHost: Bucket.s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nname\nSpeci\ufb01es the bucket.\nFor using this parameter with Amazon S3 on Outposts with the REST API, you must specify the \nname and the x-amz-outpost-id as well.\nFor using this parameter with S3 on Outposts with the AWS SDK and CLI, you must specify the \nARN of the bucket accessed in the format arn:aws:s3-outposts:<Region>:<account-\nid>:outpost/<outpost-id>/bucket/<my-bucket-name> . For example, to access \nthe bucket reports through Outpost my-outpost  owned by account 123456789012\nin Region us-west-2 , use the URL encoding of arn:aws:s3-outposts:us-\nwest-2:123456789012:outpost/my-outpost/bucket/reports .", "The value must be URL \nencoded.\nLength Constraints: Minimum length of 3.", "Maximum length of 255.\nRequired: Yes\nx-amz-account-id\nThe account ID of the Outposts bucket.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nAmazon S3 Control API Version 2006-03-01 835Amazon Simple Storage Service API Reference\nResponse Syntax\nHTTP/1.1 200\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\nExamples\nSample request for deleting a bucket policy for an Amazon S3 on Outposts bucket\nThis example illustrates one usage of DeleteBucketPolicy.\n            DELETE v20180820/bucket/example-outpost-bucket/policy  HTTP/1.1 \n            Host: s3-outposts.<Region>.amazonaws.com   \n            x-amz-account-id: example-account-id \n            x-amz-outpost-id: op-01ac5d28a6a232904 \n             \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 836Amazon Simple Storage Service API Reference\nDeleteBucketReplication\nService: Amazon S3 Control\nNote\nThis operation deletes an Amazon S3 on Outposts bucket's replication con\ufb01guration. To \ndelete an S3 bucket's replication con\ufb01guration, see DeleteBucketReplication in the Amazon \nS3 API Reference.\nDeletes the replication con\ufb01guration from the speci\ufb01ed S3 on Outposts bucket.\nTo use this operation, you must have permissions to perform the s3-\noutposts:PutReplicationConfiguration  action.", "The Outposts bucket owner has this \npermission by default and can grant it to others.", "For more information about permissions, see\nSetting up IAM with S3 on Outposts and Managing access to S3 on Outposts buckets in the\nAmazon S3 User Guide .\nNote\nIt can take a while to propagate PUT or DELETE requests for a replication con\ufb01guration \nto all S3 on Outposts systems.", "Therefore, the replication con\ufb01guration that's returned \nby a GET request soon after a PUT or DELETE request might return a more recent result \nthan what's on the Outpost. If an Outpost is o\ufb04ine, the delay in updating the replication \ncon\ufb01guration on that Outpost can be signi\ufb01cant.\nAll Amazon S3 on Outposts REST API requests for this action require an additional parameter of\nx-amz-outpost-id  to be passed with the request. In addition, you must use an S3 on Outposts \nendpoint hostname pre\ufb01x instead of s3-control . For an example of the request syntax for \nAmazon S3 on Outposts that uses the S3 on Outposts endpoint hostname pre\ufb01x and the x-amz-\noutpost-id  derived by using the access point ARN, see the Examples  section.\nFor information about S3 replication on Outposts con\ufb01guration, see Replicating objects for S3 on \nOutposts  in the Amazon S3 User Guide .\nThe following operations are related to DeleteBucketReplication :\n\u2022PutBucketReplication\nAmazon S3 Control API Version 2006-03-01 837Amazon Simple Storage Service API Reference\n\u2022GetBucketReplication\nRequest Syntax\nDELETE /v20180820/bucket/ name/replication HTTP/1.1\nHost: Bucket.s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nname\nSpeci\ufb01es the S3 on Outposts bucket to delete the replication con\ufb01guration for.\nFor using this parameter with Amazon S3 on Outposts with the REST API, you must specify the \nname and the x-amz-outpost-id as well.\nFor using this parameter with S3 on Outposts with the AWS SDK and CLI, you must specify the \nARN of the bucket accessed in the format arn:aws:s3-outposts:<Region>:<account-\nid>:outpost/<outpost-id>/bucket/<my-bucket-name> . For example, to access \nthe bucket reports through Outpost my-outpost  owned by account 123456789012\nin Region us-west-2 , use the URL encoding of arn:aws:s3-outposts:us-\nwest-2:123456789012:outpost/my-outpost/bucket/reports .", "The value must be URL \nencoded.\nLength Constraints: Minimum length of 3.", "Maximum length of 255.\nRequired: Yes\nx-amz-account-id\nThe AWS account ID of the Outposts bucket to delete the replication con\ufb01guration for.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nAmazon S3 Control API Version 2006-03-01 838Amazon Simple Storage Service API Reference\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\nExamples\nSample Request\nThe following DELETE request deletes the replication  subresource from the speci\ufb01ed S3 on \nOutposts bucket. This request removes the replication con\ufb01guration that is set for the bucket.\nDELETE /v20180820/bucket/example-outpost-bucket/replication HTTP/1.1\nHost: s3-outposts.<Region>.amazonaws.com  \nx-amz-outpost-id: op-01ac5d28a6a232904\nx-amz-account-id:example-account-id \n                \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\nAmazon S3 Control API Version 2006-03-01 839Amazon Simple Storage Service API Reference\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 840Amazon Simple Storage Service API Reference\nDeleteBucketTagging\nService: Amazon S3 Control\nNote\nThis action deletes an Amazon S3 on Outposts bucket's tags. To delete an S3 bucket tags, \nsee DeleteBucketTagging in the Amazon S3 API Reference.\nDeletes the tags from the Outposts bucket. For more information, see Using Amazon S3 on \nOutposts  in Amazon S3 User Guide .\nTo use this action, you must have permission to perform the PutBucketTagging  action. By \ndefault, the bucket owner has this permission and can grant this permission to others.\nAll Amazon S3 on Outposts REST API requests for this action require an additional parameter of\nx-amz-outpost-id  to be passed with the request. In addition, you must use an S3 on Outposts \nendpoint hostname pre\ufb01x instead of s3-control . For an example of the request syntax for \nAmazon S3 on Outposts that uses the S3 on Outposts endpoint hostname pre\ufb01x and the x-amz-\noutpost-id  derived by using the access point ARN, see the Examples  section.\nThe following actions are related to DeleteBucketTagging :\n\u2022GetBucketTagging\n\u2022PutBucketTagging\nRequest Syntax\nDELETE /v20180820/bucket/ name/tagging HTTP/1.1\nHost: Bucket.s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nname\nThe bucket ARN that has the tag set to be removed.\nAmazon S3 Control API Version 2006-03-01 841Amazon Simple Storage Service API Reference\nFor using this parameter with Amazon S3 on Outposts with the REST API, you must specify the \nname and the x-amz-outpost-id as well.\nFor using this parameter with S3 on Outposts with the AWS SDK and CLI, you must specify the \nARN of the bucket accessed in the format arn:aws:s3-outposts:<Region>:<account-\nid>:outpost/<outpost-id>/bucket/<my-bucket-name> . For example, to access \nthe bucket reports through Outpost my-outpost  owned by account 123456789012\nin Region us-west-2 , use the URL encoding of arn:aws:s3-outposts:us-\nwest-2:123456789012:outpost/my-outpost/bucket/reports .", "The value must be URL \nencoded.\nLength Constraints: Minimum length of 3.", "Maximum length of 255.\nRequired: Yes\nx-amz-account-id\nThe AWS account ID of the Outposts bucket tag set to be removed.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 204\nResponse Elements\nIf the action is successful, the service sends back an HTTP 204 response with an empty HTTP body.\nExamples\nSample request to delete tags for Amazon S3 on Outposts bucket\nThe following DELETE request deletes the tag set from the Outposts bucket example-outpost-\nbucket .\nAmazon S3 Control API Version 2006-03-01 842Amazon Simple Storage Service API Reference\n            DELETE v20180820/bucket/example-outpost-bucket/tagging HTTP/1.1 \n            Host: s3-outposts.<Region>.amazonaws.com  \n            x-amz-account-id: example-account-id \n            x-amz-outpost-id: op-01ac5d28a6a232904 \n            Date: Wed, 14 Dec 2020 05:37:16 GMT \n            Authorization: signatureValue  \n          \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 843Amazon Simple Storage Service API Reference\nDeleteJobTagging\nService: Amazon S3 Control\nRemoves the entire tag set from the speci\ufb01ed S3 Batch Operations job.\nPermissions\nTo use the DeleteJobTagging  operation, you must have permission to perform the\ns3:DeleteJobTagging  action.", "For more information, see Controlling access and labeling jobs \nusing tags  in the Amazon S3 User Guide .\nRelated actions include:\n\u2022CreateJob\n\u2022GetJobTagging\n\u2022PutJobTagging\nRequest Syntax\nDELETE /v20180820/jobs/ id/tagging HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nid\nThe ID for the S3 Batch Operations job whose tags you want to delete.\nLength Constraints: Minimum length of 5. Maximum length of 36.\nPattern: [a-zA-Z0-9\\-\\_]+\nRequired: Yes\nx-amz-account-id\nThe AWS account ID associated with the S3 Batch Operations job.\nAmazon S3 Control API Version 2006-03-01 844Amazon Simple Storage Service API Reference\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\nErrors\nInternalServiceException\nHTTP Status Code: 500\nNotFoundException\nHTTP Status Code: 400\nTooManyRequestsException\nHTTP Status Code: 400\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\nAmazon S3 Control API Version 2006-03-01 845Amazon Simple Storage Service API Reference\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 846Amazon Simple Storage Service API Reference\nDeleteMultiRegionAccessPoint\nService: Amazon S3 Control\nNote\nThis operation is not supported by directory buckets.\nDeletes a Multi-Region Access Point.", "This action does not delete the buckets associated with the \nMulti-Region Access Point, only the Multi-Region Access Point itself.\nThis action will always be routed to the US West (Oregon) Region.", "For more information about \nthe restrictions around working with Multi-Region Access Points, see Multi-Region Access Point \nrestrictions and limitations in the Amazon S3 User Guide .\nThis request is asynchronous, meaning that you might receive a response before the command has \ncompleted. When this request provides a response, it provides a token that you can use to monitor \nthe status of the request with DescribeMultiRegionAccessPointOperation .\nThe following actions are related to DeleteMultiRegionAccessPoint :\n\u2022CreateMultiRegionAccessPoint\n\u2022DescribeMultiRegionAccessPointOperation\n\u2022GetMultiRegionAccessPoint\n\u2022ListMultiRegionAccessPoints\nRequest Syntax\nPOST /v20180820/async-requests/mrap/delete HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<DeleteMultiRegionAccessPointRequest  xmlns=\"http://awss3control.amazonaws.com/\ndoc/2018-08-20/\"> \n   <ClientToken >string</ClientToken > \n   <Details> \n      <Name>string</Name> \n   </Details>\n</DeleteMultiRegionAccessPointRequest >\nAmazon S3 Control API Version 2006-03-01 847Amazon Simple Storage Service API Reference\nURI Request Parameters\nThe request uses the following URI parameters.\nx-amz-account-id\nThe AWS account ID for the owner of the Multi-Region Access Point.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request accepts the following data in XML format.\nDeleteMultiRegionAccessPointRequest\nRoot level tag for the DeleteMultiRegionAccessPointRequest parameters.\nRequired: Yes\nClientToken\nAn idempotency token used to identify the request and guarantee that requests are unique.\nType: String\nLength Constraints: Maximum length of 64.\nPattern: \\S+\nRequired: Yes\nDetails\nA container element containing details about the Multi-Region Access Point.\nType: DeleteMultiRegionAccessPointInput data type\nRequired: Yes\nAmazon S3 Control API Version 2006-03-01 848Amazon Simple Storage Service API Reference\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<DeleteMultiRegionAccessPointResult > \n   <RequestTokenARN >string</RequestTokenARN >\n</DeleteMultiRegionAccessPointResult >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nDeleteMultiRegionAccessPointResult\nRoot level tag for the DeleteMultiRegionAccessPointResult parameters.\nRequired: Yes\nRequestTokenARN\nThe request token associated with the request.", "You can use this token with\nDescribeMultiRegionAccessPointOperation to determine the status of asynchronous requests.\nType: String\nLength Constraints: Minimum length of 1.", "Maximum length of 1024.\nPattern: arn:.+\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\nAmazon S3 Control API Version 2006-03-01 849Amazon Simple Storage Service API Reference\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 850Amazon Simple Storage Service API Reference\nDeletePublicAccessBlock\nService: Amazon S3 Control\nNote\nThis operation is not supported by directory buckets.\nRemoves the PublicAccessBlock  con\ufb01guration for an AWS account. For more information, see \nUsing Amazon S3 block public access.\nRelated actions include:\n\u2022GetPublicAccessBlock\n\u2022PutPublicAccessBlock\nRequest Syntax\nDELETE /v20180820/configuration/publicAccessBlock HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nx-amz-account-id\nThe account ID for the AWS account whose PublicAccessBlock  con\ufb01guration you want to \nremove.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nAmazon S3 Control API Version 2006-03-01 851Amazon Simple Storage Service API Reference\nResponse Syntax\nHTTP/1.1 200\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 852Amazon Simple Storage Service API Reference\nDeleteStorageLensCon\ufb01guration\nService: Amazon S3 Control\nNote\nThis operation is not supported by directory buckets.\nDeletes the Amazon S3 Storage Lens con\ufb01guration. For more information about S3 Storage Lens, \nsee Assessing your storage activity and usage with Amazon S3 Storage Lens  in the Amazon S3 User \nGuide .\nNote\nTo use this action, you must have permission to perform the\ns3:DeleteStorageLensConfiguration  action. For more information, see Setting \npermissions to use Amazon S3 Storage Lens in the Amazon S3 User Guide .\nRequest Syntax\nDELETE /v20180820/storagelens/ storagelensid  HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nstoragelensid\nThe ID of the S3 Storage Lens con\ufb01guration.\nLength Constraints: Minimum length of 1. Maximum length of 64.\nPattern: [a-zA-Z0-9\\-\\_\\.]+\nRequired: Yes\nx-amz-account-id\nThe account ID of the requester.\nAmazon S3 Control API Version 2006-03-01 853Amazon Simple Storage Service API Reference\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 854Amazon Simple Storage Service API Reference\nDeleteStorageLensCon\ufb01gurationTagging\nService: Amazon S3 Control\nNote\nThis operation is not supported by directory buckets.\nDeletes the Amazon S3 Storage Lens con\ufb01guration tags. For more information about S3 Storage \nLens, see Assessing your storage activity and usage with Amazon S3 Storage Lens  in the Amazon \nS3 User Guide .\nNote\nTo use this action, you must have permission to perform the\ns3:DeleteStorageLensConfigurationTagging  action. For more information, see\nSetting permissions to use Amazon S3 Storage Lens in the Amazon S3 User Guide .\nRequest Syntax\nDELETE /v20180820/storagelens/ storagelensid /tagging HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nstoragelensid\nThe ID of the S3 Storage Lens con\ufb01guration.\nLength Constraints: Minimum length of 1. Maximum length of 64.\nPattern: [a-zA-Z0-9\\-\\_\\.]+\nRequired: Yes\nx-amz-account-id\nThe account ID of the requester.\nAmazon S3 Control API Version 2006-03-01 855Amazon Simple Storage Service API Reference\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 856Amazon Simple Storage Service API Reference\nDeleteStorageLensGroup\nService: Amazon S3 Control\nDeletes an existing S3 Storage Lens group.\nTo use this operation, you must have the permission to perform the\ns3:DeleteStorageLensGroup  action. For more information about the required Storage Lens \nGroups permissions, see Setting account permissions to use S3 Storage Lens groups.\nFor information about Storage Lens groups errors, see List of Amazon S3 Storage Lens error codes.\nRequest Syntax\nDELETE /v20180820/storagelensgroup/ name HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nname\nThe name of the Storage Lens group that you're trying to delete.\nLength Constraints: Minimum length of 1. Maximum length of 64.\nPattern: [a-zA-Z0-9\\-\\_]+\nRequired: Yes\nx-amz-account-id\nThe AWS account ID used to create the Storage Lens group that you're trying to delete.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nAmazon S3 Control API Version 2006-03-01 857Amazon Simple Storage Service API Reference\nResponse Syntax\nHTTP/1.1 204\nResponse Elements\nIf the action is successful, the service sends back an HTTP 204 response with an empty HTTP body.\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 858Amazon Simple Storage Service API Reference\nDescribeJob\nService: Amazon S3 Control\nRetrieves the con\ufb01guration parameters and status for a Batch Operations job.", "For more \ninformation, see S3 Batch Operations  in the Amazon S3 User Guide .\nPermissions\nTo use the DescribeJob  operation, you must have permission to perform the\ns3:DescribeJob  action.\nRelated actions include:\n\u2022CreateJob\n\u2022ListJobs\n\u2022UpdateJobPriority\n\u2022UpdateJobStatus\nRequest Syntax\nGET /v20180820/jobs/ id HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nid\nThe ID for the job whose information you want to retrieve.\nLength Constraints: Minimum length of 5. Maximum length of 36.\nPattern: [a-zA-Z0-9\\-\\_]+\nRequired: Yes\nx-amz-account-id\nThe AWS account ID associated with the S3 Batch Operations job.\nAmazon S3 Control API Version 2006-03-01 859Amazon Simple Storage Service API Reference\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<DescribeJobResult > \n   <Job> \n      <ConfirmationRequired >boolean</ConfirmationRequired > \n      <CreationTime >timestamp </CreationTime > \n      <Description >string</Description > \n      <FailureReasons > \n         <JobFailure> \n            < FailureCode >string</FailureCode > \n            < FailureReason >string</FailureReason > \n         </JobFailure> \n      </ FailureReasons > \n      <GeneratedManifestDescriptor > \n         < Format>string</Format> \n         < Location > \n            < ETag>string</ETag> \n            < ObjectArn >string</ObjectArn > \n            < ObjectVersionId >string</ObjectVersionId > \n         </ Location > \n      </ GeneratedManifestDescriptor > \n      <JobArn>string</JobArn> \n      <JobId>string</JobId> \n      <Manifest > \n         < Location > \n            < ETag>string</ETag> \n            < ObjectArn >string</ObjectArn > \n            < ObjectVersionId >string</ObjectVersionId > \n         </ Location > \n         < Spec> \n            < Fields> \nAmazon S3 Control API Version 2006-03-01 860Amazon Simple Storage Service API Reference\n               <member> string</member> \n            </ Fields> \n            < Format>string</Format> \n         </ Spec> \n      </ Manifest > \n      <ManifestGenerator > \n         < S3JobManifestGenerator > \n            < EnableManifestOutput >boolean</EnableManifestOutput > \n            < ExpectedBucketOwner >string</ExpectedBucketOwner > \n            < Filter> \n               < CreatedAfter >timestamp </CreatedAfter > \n               < CreatedBefore >timestamp </CreatedBefore > \n               < EligibleForReplication >boolean</EligibleForReplication > \n               < KeyNameConstraint > \n                  < MatchAnyPrefix > \n                     <member> string</member> \n                  </ MatchAnyPrefix > \n                  < MatchAnySubstring > \n                     <member> string</member> \n                  </ MatchAnySubstring > \n                  < MatchAnySuffix > \n                     <member> string</member> \n                  </ MatchAnySuffix > \n               </ KeyNameConstraint > \n               < MatchAnyStorageClass > \n                  <member> string</member> \n               </ MatchAnyStorageClass > \n               < ObjectReplicationStatuses > \n                  <member> string</member> \n               </ ObjectReplicationStatuses > \n               < ObjectSizeGreaterThanBytes >long</ObjectSizeGreaterThanBytes > \n               < ObjectSizeLessThanBytes >long</ObjectSizeLessThanBytes > \n            </ Filter> \n            < ManifestOutputLocation > \n               < Bucket>string</Bucket> \n               < ExpectedManifestBucketOwner >string</ExpectedManifestBucketOwner > \n               < ManifestEncryption > \n                  < SSE-KMS> \n                     < KeyId>string</KeyId> \n                  </ SSE-KMS> \n                  < SSE-S3> \n                  </ SSE-S3> \n               </ ManifestEncryption > \n               < ManifestFormat >string</ManifestFormat > \nAmazon S3 Control API Version 2006-03-01 861Amazon Simple Storage Service API Reference\n               < ManifestPrefix >string</ManifestPrefix > \n            </ ManifestOutputLocation > \n            < SourceBucket >string</SourceBucket > \n         </ S3JobManifestGenerator > \n      </ ManifestGenerator > \n      <Operation > \n         < LambdaInvoke > \n            < FunctionArn >string</FunctionArn > \n            < InvocationSchemaVersion >string</InvocationSchemaVersion > \n            < UserArguments > \n               <entry> \n                  <key> string</key> \n                  <value> string</value> \n               </entry> \n            </ UserArguments > \n         </ LambdaInvoke > \n         < S3DeleteObjectTagging > \n         </ S3DeleteObjectTagging > \n         < S3InitiateRestoreObject > \n            < ExpirationInDays >integer</ExpirationInDays > \n            < GlacierJobTier >string</GlacierJobTier > \n         </ S3InitiateRestoreObject > \n         < S3PutObjectAcl > \n            < AccessControlPolicy > \n               < AccessControlList > \n                  < Grants> \n                     <S3Grant> \n                        < Grantee> \n                           < DisplayName >string</DisplayName > \n                           < Identifier >string</Identifier > \n                           < TypeIdentifier >string</TypeIdentifier > \n                        </ Grantee> \n                        < Permission >string</Permission > \n                     </S3Grant> \n                  </ Grants> \n                  < Owner> \n                     < DisplayName >string</DisplayName > \n                     < ID>string</ID> \n                  </ Owner> \n               </ AccessControlList > \n               < CannedAccessControlList >string</CannedAccessControlList > \n            </ AccessControlPolicy > \n         </ S3PutObjectAcl > \n         < S3PutObjectCopy > \nAmazon S3 Control API Version 2006-03-01 862Amazon Simple Storage Service API Reference\n            < AccessControlGrants > \n               <S3Grant> \n                  < Grantee> \n                     < DisplayName >string</DisplayName > \n                     < Identifier >string</Identifier > \n                     < TypeIdentifier >string</TypeIdentifier > \n                  </ Grantee> \n                  < Permission >string</Permission > \n               </S3Grant> \n            </ AccessControlGrants > \n            < BucketKeyEnabled >boolean</BucketKeyEnabled > \n            < CannedAccessControlList >string</CannedAccessControlList > \n            < ChecksumAlgorithm >string</ChecksumAlgorithm > \n            < MetadataDirective >string</MetadataDirective > \n            < ModifiedSinceConstraint >timestamp </ModifiedSinceConstraint > \n            < NewObjectMetadata > \n               < CacheControl >string</CacheControl > \n               < ContentDisposition >string</ContentDisposition > \n               < ContentEncoding >string</ContentEncoding > \n               < ContentLanguage >string</ContentLanguage > \n               < ContentLength >long</ContentLength > \n               < ContentMD5 >string</ContentMD5 > \n               < ContentType >string</ContentType > \n               < HttpExpiresDate >timestamp </HttpExpiresDate > \n               < RequesterCharged >boolean</RequesterCharged > \n               < SSEAlgorithm >string</SSEAlgorithm > \n               < UserMetadata > \n                  <entry> \n                     <key> string</key> \n                     <value> string</value> \n                  </entry> \n               </ UserMetadata > \n            </ NewObjectMetadata > \n            < NewObjectTagging > \n               <S3Tag> \n                  < Key>string</Key> \n                  < Value>string</Value> \n               </S3Tag> \n            </ NewObjectTagging > \n            < ObjectLockLegalHoldStatus >string</ObjectLockLegalHoldStatus > \n            < ObjectLockMode >string</ObjectLockMode > \n            < ObjectLockRetainUntilDate >timestamp </ObjectLockRetainUntilDate > \n            < RedirectLocation >string</RedirectLocation > \n            < RequesterPays >boolean</RequesterPays > \nAmazon S3 Control API Version 2006-03-01 863Amazon Simple Storage Service API Reference\n            < SSEAwsKmsKeyId >string</SSEAwsKmsKeyId > \n            < StorageClass >string</StorageClass > \n            < TargetKeyPrefix >string</TargetKeyPrefix > \n            < TargetResource >string</TargetResource > \n            < UnModifiedSinceConstraint >timestamp </UnModifiedSinceConstraint > \n         </ S3PutObjectCopy > \n         < S3PutObjectLegalHold > \n            < LegalHold > \n               < Status>string</Status> \n            </ LegalHold > \n         </ S3PutObjectLegalHold > \n         < S3PutObjectRetention > \n            < BypassGovernanceRetention >boolean</BypassGovernanceRetention > \n            < Retention > \n               < Mode>string</Mode> \n               < RetainUntilDate >timestamp </RetainUntilDate > \n            </ Retention > \n         </ S3PutObjectRetention > \n         < S3PutObjectTagging > \n            < TagSet> \n               <S3Tag> \n                  < Key>string</Key> \n                  < Value>string</Value> \n               </S3Tag> \n            </ TagSet> \n         </ S3PutObjectTagging > \n         < S3ReplicateObject > \n         </ S3ReplicateObject > \n      </ Operation > \n      <Priority >integer</Priority > \n      <ProgressSummary > \n         < NumberOfTasksFailed >long</NumberOfTasksFailed > \n         < NumberOfTasksSucceeded >long</NumberOfTasksSucceeded > \n         < Timers> \n            < ElapsedTimeInActiveSeconds >long</ElapsedTimeInActiveSeconds > \n         </ Timers> \n         < TotalNumberOfTasks >long</TotalNumberOfTasks > \n      </ ProgressSummary > \n      <Report> \n         < Bucket>string</Bucket> \n         < Enabled>boolean</Enabled> \n         < Format>string</Format> \n         < Prefix>string</Prefix> \n         < ReportScope >string</ReportScope > \nAmazon S3 Control API Version 2006-03-01 864Amazon Simple Storage Service API Reference\n      </ Report> \n      <RoleArn>string</RoleArn> \n      <Status>string</Status> \n      <StatusUpdateReason >string</StatusUpdateReason > \n      <SuspendedCause >string</SuspendedCause > \n      <SuspendedDate >timestamp </SuspendedDate > \n      <TerminationDate >timestamp </TerminationDate > \n   </Job>\n</DescribeJobResult >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nDescribeJobResult\nRoot level tag for the DescribeJobResult parameters.\nRequired: Yes\nJob\nContains the con\ufb01guration parameters and status for the job speci\ufb01ed in the Describe Job\nrequest.\nType: JobDescriptor  data type\nErrors\nBadRequestException\nHTTP Status Code: 400\nInternalServiceException\nHTTP Status Code: 500\nNotFoundException\nHTTP Status Code: 400\nAmazon S3 Control API Version 2006-03-01 865Amazon Simple Storage Service API Reference\nTooManyRequestsException\nHTTP Status Code: 400\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 866Amazon Simple Storage Service API Reference\nDescribeMultiRegionAccessPointOperation\nService: Amazon S3 Control\nNote\nThis operation is not supported by directory buckets.\nRetrieves the status of an asynchronous request to manage a Multi-Region Access Point. For more \ninformation about managing Multi-Region Access Points and how asynchronous requests work, see\nUsing Multi-Region Access Points in the Amazon S3 User Guide .\nThe following actions are related to GetMultiRegionAccessPoint :\n\u2022CreateMultiRegionAccessPoint\n\u2022DeleteMultiRegionAccessPoint\n\u2022GetMultiRegionAccessPoint\n\u2022ListMultiRegionAccessPoints\nRequest Syntax\nGET /v20180820/async-requests/mrap/ request_token+  HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nrequest_token\nThe request token associated with the request you want to know about.", "This request token is \nreturned as part of the response when you make an asynchronous request. You provide this \ntoken to query about the status of the asynchronous action.\nLength Constraints: Minimum length of 1.", "Maximum length of 1024.\nPattern: arn:.+\nAmazon S3 Control API Version 2006-03-01 867Amazon Simple Storage Service API Reference\nRequired: Yes\nx-amz-account-id\nThe AWS account ID for the owner of the Multi-Region Access Point.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<DescribeMultiRegionAccessPointOperationResult > \n   <AsyncOperation > \n      <CreationTime >timestamp </CreationTime > \n      <Operation >string</Operation > \n      <RequestParameters > \n         < CreateMultiRegionAccessPointRequest > \n            < Name>string</Name> \n            < PublicAccessBlock > \n               < BlockPublicAcls >boolean</BlockPublicAcls > \n               < BlockPublicPolicy >boolean</BlockPublicPolicy > \n               < IgnorePublicAcls >boolean</IgnorePublicAcls > \n               < RestrictPublicBuckets >boolean</RestrictPublicBuckets > \n            </ PublicAccessBlock > \n            < Regions> \n               <Region> \n                  < Bucket>string</Bucket> \n                  < BucketAccountId >string</BucketAccountId > \n               </Region> \n            </ Regions> \n         </ CreateMultiRegionAccessPointRequest > \n         < DeleteMultiRegionAccessPointRequest > \n            < Name>string</Name> \n         </ DeleteMultiRegionAccessPointRequest > \nAmazon S3 Control API Version 2006-03-01 868Amazon Simple Storage Service API Reference\n         < PutMultiRegionAccessPointPolicyRequest > \n            < Name>string</Name> \n            < Policy>string</Policy> \n         </ PutMultiRegionAccessPointPolicyRequest > \n      </ RequestParameters > \n      <RequestStatus >string</RequestStatus > \n      <RequestTokenARN >string</RequestTokenARN > \n      <ResponseDetails > \n         < ErrorDetails > \n            < Code>string</Code> \n            < Message>string</Message> \n            < RequestId >string</RequestId > \n            < Resource >string</Resource > \n         </ ErrorDetails > \n         < MultiRegionAccessPointDetails > \n            < Regions> \n               <Region> \n                  < Name>string</Name> \n                  < RequestStatus >string</RequestStatus > \n               </Region> \n            </ Regions> \n         </ MultiRegionAccessPointDetails > \n      </ ResponseDetails > \n   </AsyncOperation >\n</DescribeMultiRegionAccessPointOperationResult >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nDescribeMultiRegionAccessPointOperationResult\nRoot level tag for the DescribeMultiRegionAccessPointOperationResult parameters.\nRequired: Yes\nAsyncOperation\nA container element containing the details of the asynchronous operation.\nType: AsyncOperation  data type\nAmazon S3 Control API Version 2006-03-01 869Amazon Simple Storage Service API Reference\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 870Amazon Simple Storage Service API Reference\nDissociateAccessGrantsIdentityCenter\nService: Amazon S3 Control\nDissociates the AWS IAM Identity Center instance from the S3 Access Grants instance.\nPermissions\nYou must have the s3:DissociateAccessGrantsIdentityCenter  permission to use this \noperation.\nAdditional Permissions\nYou must have the sso:DeleteApplication  permission to use this operation.\nRequest Syntax\nDELETE /v20180820/accessgrantsinstance/identitycenter HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nx-amz-account-id\nThe AWS account ID of the S3 Access Grants instance.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\nAmazon S3 Control API Version 2006-03-01 871Amazon Simple Storage Service API Reference\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 872Amazon Simple Storage Service API Reference\nGetAccessGrant\nService: Amazon S3 Control\nGet the details of an access grant from your S3 Access Grants instance.\nPermissions\nYou must have the s3:GetAccessGrant  permission to use this operation.\nRequest Syntax\nGET /v20180820/accessgrantsinstance/grant/ id HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nid\nThe ID of the access grant.", "S3 Access Grants auto-generates this ID when you create the access \ngrant.\nLength Constraints: Minimum length of 1. Maximum length of 64.\nPattern: [a-zA-Z0-9\\-]+\nRequired: Yes\nx-amz-account-id\nThe AWS account ID of the S3 Access Grants instance.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nAmazon S3 Control API Version 2006-03-01 873Amazon Simple Storage Service API Reference\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<GetAccessGrantResult > \n   <CreatedAt >timestamp </CreatedAt > \n   <AccessGrantId >string</AccessGrantId > \n   <AccessGrantArn >string</AccessGrantArn > \n   <Grantee> \n      <GranteeIdentifier >string</GranteeIdentifier > \n      <GranteeType >string</GranteeType > \n   </Grantee> \n   <Permission >string</Permission > \n   <AccessGrantsLocationId >string</AccessGrantsLocationId > \n   <AccessGrantsLocationConfiguration > \n      <S3SubPrefix >string</S3SubPrefix > \n   </AccessGrantsLocationConfiguration > \n   <GrantScope >string</GrantScope > \n   <ApplicationArn >string</ApplicationArn >\n</GetAccessGrantResult >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nGetAccessGrantResult\nRoot level tag for the GetAccessGrantResult parameters.\nRequired: Yes\nAccessGrantArn\nThe Amazon Resource Name (ARN) of the access grant.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 2048.\nPattern: arn:[a-z\\-]+:s3:[a-z0-9\\-]+:\\d{12}:access\\-grants\\/grant/[a-zA-\nZ0-9\\-]+\nAmazon S3 Control API Version 2006-03-01 874Amazon Simple Storage Service API Reference\nAccessGrantId\nThe ID of the access grant. S3 Access Grants auto-generates this ID when you create the access \ngrant.\nType: String\nLength Constraints: Minimum length of 1.", "Maximum length of 64.\nPattern: [a-zA-Z0-9\\-]+\nAccessGrantsLocationCon\ufb01guration\nThe con\ufb01guration options of the grant location.", "The grant location is the S3 path to the data to \nwhich you are granting access.\nType: AccessGrantsLocationCon\ufb01guration data type\nAccessGrantsLocationId\nThe ID of the registered location to which you are granting access. S3 Access Grants assigns \nthis ID when you register the location. S3 Access Grants assigns the ID default  to the default \nlocation s3:// and assigns an auto-generated ID to other locations that you register.\nType: String\nLength Constraints: Minimum length of 1.", "Maximum length of 64.\nPattern: [a-zA-Z0-9\\-]+\nApplicationArn\nThe Amazon Resource Name (ARN) of an AWS IAM Identity Center application associated with \nyour Identity Center instance.", "If the grant includes an application ARN, the grantee can only \naccess the S3 data through this application.\nType: String\nLength Constraints: Minimum length of 10. Maximum length of 1224.\nPattern: arn:[^:]+:sso::\\d{12}:application/.*$\nCreatedAt\nThe date and time when you created the access grant.\nAmazon S3 Control API Version 2006-03-01 875Amazon Simple Storage Service API Reference\nType: Timestamp\nGrantee\nThe user, group, or role to which you are granting access.", "You can grant access to an IAM user \nor role.", "If you have added a corporate directory to AWS IAM Identity Center and associated this \nIdentity Center instance with the S3 Access Grants instance, the grantee can also be a corporate \ndirectory user or group.\nType: Grantee  data type\nGrantScope\nThe S3 path of the data to which you are granting access.", "It is the result of appending the\nSubprefix  to the location scope.\nType: String\nLength Constraints: Minimum length of 1.", "Maximum length of 2000.\nPattern: ^.+$\nPermission\nThe type of permission that was granted in the access grant.", "Can be one of the following values:\n\u2022READ \u2013 Grant read-only access to the S3 data.\n\u2022WRITE \u2013 Grant write-only access to the S3 data.\n\u2022READWRITE  \u2013 Grant both read and write access to the S3 data.\nType: String\nValid Values: READ | WRITE | READWRITE\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\nAmazon S3 Control API Version 2006-03-01 876Amazon Simple Storage Service API Reference\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 877Amazon Simple Storage Service API Reference\nGetAccessGrantsInstance\nService: Amazon S3 Control\nRetrieves the S3 Access Grants instance for a Region in your account.\nPermissions\nYou must have the s3:GetAccessGrantsInstance  permission to use this operation.\nNote\nGetAccessGrantsInstance  is not supported for cross-account access. You can only call \nthe API from the account that owns the S3 Access Grants instance.\nRequest Syntax\nGET /v20180820/accessgrantsinstance HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nx-amz-account-id\nThe AWS account ID of the S3 Access Grants instance.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nAmazon S3 Control API Version 2006-03-01 878Amazon Simple Storage Service API Reference\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<GetAccessGrantsInstanceResult > \n   <AccessGrantsInstanceArn >string</AccessGrantsInstanceArn > \n   <AccessGrantsInstanceId >string</AccessGrantsInstanceId > \n   <IdentityCenterArn >string</IdentityCenterArn > \n   <IdentityCenterInstanceArn >string</IdentityCenterInstanceArn > \n   <IdentityCenterApplicationArn >string</IdentityCenterApplicationArn > \n   <CreatedAt >timestamp </CreatedAt >\n</GetAccessGrantsInstanceResult >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nGetAccessGrantsInstanceResult\nRoot level tag for the GetAccessGrantsInstanceResult parameters.\nRequired: Yes\nAccessGrantsInstanceArn\nThe Amazon Resource Name (ARN) of the S3 Access Grants instance.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 2048.\nPattern: arn:[a-z\\-]+:s3:[a-z0-9\\-]+:\\d{12}:access\\-grants\\/[a-zA-Z0-9\\-]+\nAccessGrantsInstanceId\nThe ID of the S3 Access Grants instance.", "The ID is default.", "You can have one S3 Access Grants \ninstance per Region per account.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 64.\nPattern: [a-zA-Z0-9\\-]+\nAmazon S3 Control API Version 2006-03-01 879Amazon Simple Storage Service API Reference\nCreatedAt\nThe date and time when you created the S3 Access Grants instance.\nType: Timestamp\nIdentityCenterApplicationArn\nIf you associated your S3 Access Grants instance with an AWS IAM Identity Center instance, this \n\ufb01eld returns the Amazon Resource Name (ARN) of the IAM Identity Center instance application; \na subresource of the original Identity Center instance. S3 Access Grants creates this Identity \nCenter application for the speci\ufb01c S3 Access Grants instance.\nType: String\nLength Constraints: Minimum length of 10. Maximum length of 1224.\nPattern: arn:[^:]+:sso::\\d{12}:application/.*$\nIdentityCenterArn\nThis parameter has been deprecated.\nIf you associated your S3 Access Grants instance with an AWS IAM Identity Center instance, this \n\ufb01eld returns the Amazon Resource Name (ARN) of the IAM Identity Center instance application; \na subresource of the original Identity Center instance. S3 Access Grants creates this Identity \nCenter application for the speci\ufb01c S3 Access Grants instance.\nType: String\nLength Constraints: Minimum length of 10. Maximum length of 1224.\nPattern: arn:[^:]+:sso::(\\d{12}){0,1}:instance/.*$\nIdentityCenterInstanceArn\nThe Amazon Resource Name (ARN) of the AWS IAM Identity Center instance that you are \nassociating with your S3 Access Grants instance.", "An IAM Identity Center instance is your \ncorporate identity directory that you added to the IAM Identity Center.", "You can use the\nListInstances API operation to retrieve a list of your Identity Center instances and their ARNs.\nType: String\nLength Constraints: Minimum length of 10.", "Maximum length of 1224.\nAmazon S3 Control API Version 2006-03-01 880Amazon Simple Storage Service API Reference\nPattern: arn:[^:]+:sso::(\\d{12}){0,1}:instance/.*$\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 881Amazon Simple Storage Service API Reference\nGetAccessGrantsInstanceForPre\ufb01x\nService: Amazon S3 Control\nRetrieve the S3 Access Grants instance that contains a particular pre\ufb01x.\nPermissions\nYou must have the s3:GetAccessGrantsInstanceForPrefix  permission for the caller \naccount to use this operation.\nAdditional Permissions\nThe pre\ufb01x owner account must grant you the following permissions to their S3 Access Grants \ninstance: s3:GetAccessGrantsInstanceForPrefix .\nRequest Syntax\nGET /v20180820/accessgrantsinstance/prefix?s3prefix= S3Prefix  HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\ns3pre\ufb01x\nThe S3 pre\ufb01x of the access grants that you would like to retrieve.\nLength Constraints: Minimum length of 1. Maximum length of 2000.\nPattern: ^.+$\nRequired: Yes\nx-amz-account-id\nThe ID of the AWS account that is making this request.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nAmazon S3 Control API Version 2006-03-01 882Amazon Simple Storage Service API Reference\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<GetAccessGrantsInstanceForPrefixResult > \n   <AccessGrantsInstanceArn >string</AccessGrantsInstanceArn > \n   <AccessGrantsInstanceId >string</AccessGrantsInstanceId >\n</GetAccessGrantsInstanceForPrefixResult >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nGetAccessGrantsInstanceForPre\ufb01xResult\nRoot level tag for the GetAccessGrantsInstanceForPre\ufb01xResult parameters.\nRequired: Yes\nAccessGrantsInstanceArn\nThe Amazon Resource Name (ARN) of the S3 Access Grants instance.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 2048.\nPattern: arn:[a-z\\-]+:s3:[a-z0-9\\-]+:\\d{12}:access\\-grants\\/[a-zA-Z0-9\\-]+\nAccessGrantsInstanceId\nThe ID of the S3 Access Grants instance.", "The ID is default.", "You can have one S3 Access Grants \ninstance per Region per account.\nType: String\nAmazon S3 Control API Version 2006-03-01 883Amazon Simple Storage Service API Reference\nLength Constraints: Minimum length of 1. Maximum length of 64.\nPattern: [a-zA-Z0-9\\-]+\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 884Amazon Simple Storage Service API Reference\nGetAccessGrantsInstanceResourcePolicy\nService: Amazon S3 Control\nReturns the resource policy of the S3 Access Grants instance.\nPermissions\nYou must have the s3:GetAccessGrantsInstanceResourcePolicy  permission to use this \noperation.\nRequest Syntax\nGET /v20180820/accessgrantsinstance/resourcepolicy HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nx-amz-account-id\nThe AWS account ID of the S3 Access Grants instance.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<GetAccessGrantsInstanceResourcePolicyResult > \n   <Policy>string</Policy> \n   <Organization >string</Organization > \nAmazon S3 Control API Version 2006-03-01 885Amazon Simple Storage Service API Reference\n   <CreatedAt >timestamp </CreatedAt >\n</GetAccessGrantsInstanceResourcePolicyResult >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nGetAccessGrantsInstanceResourcePolicyResult\nRoot level tag for the GetAccessGrantsInstanceResourcePolicyResult parameters.\nRequired: Yes\nCreatedAt\nThe date and time when you created the S3 Access Grants instance resource policy.\nType: Timestamp\nOrganization\nThe Organization of the resource policy of the S3 Access Grants instance.\nType: String\nLength Constraints: Minimum length of 12. Maximum length of 34.\nPattern: ^o-[a-z0-9]{10,32}$\nPolicy\nThe resource policy of the S3 Access Grants instance.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 350000.\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\nAmazon S3 Control API Version 2006-03-01 886Amazon Simple Storage Service API Reference\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 887Amazon Simple Storage Service API Reference\nGetAccessGrantsLocation\nService: Amazon S3 Control\nRetrieves the details of a particular location registered in your S3 Access Grants instance.\nPermissions\nYou must have the s3:GetAccessGrantsLocation  permission to use this operation.\nRequest Syntax\nGET /v20180820/accessgrantsinstance/location/ id HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nid\nThe ID of the registered location that you are retrieving. S3 Access Grants assigns this ID when \nyou register the location. S3 Access Grants assigns the ID default  to the default location\ns3:// and assigns an auto-generated ID to other locations that you register.\nLength Constraints: Minimum length of 1. Maximum length of 64.\nPattern: [a-zA-Z0-9\\-]+\nRequired: Yes\nx-amz-account-id\nThe AWS account ID of the S3 Access Grants instance.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nAmazon S3 Control API Version 2006-03-01 888Amazon Simple Storage Service API Reference\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<GetAccessGrantsLocationResult > \n   <CreatedAt >timestamp </CreatedAt > \n   <AccessGrantsLocationId >string</AccessGrantsLocationId > \n   <AccessGrantsLocationArn >string</AccessGrantsLocationArn > \n   <LocationScope >string</LocationScope > \n   <IAMRoleArn >string</IAMRoleArn >\n</GetAccessGrantsLocationResult >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nGetAccessGrantsLocationResult\nRoot level tag for the GetAccessGrantsLocationResult parameters.\nRequired: Yes\nAccessGrantsLocationArn\nThe Amazon Resource Name (ARN) of the registered location.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 2048.\nPattern: arn:[a-z\\-]+:s3:[a-z0-9\\-]+:\\d{12}:access\\-grants\\/location/[a-zA-\nZ0-9\\-]+\nAccessGrantsLocationId\nThe ID of the registered location to which you are granting access. S3 Access Grants assigns \nthis ID when you register the location. S3 Access Grants assigns the ID default  to the default \nlocation s3:// and assigns an auto-generated ID to other locations that you register.\nAmazon S3 Control API Version 2006-03-01 889Amazon Simple Storage Service API Reference\nType: String\nLength Constraints: Minimum length of 1.", "Maximum length of 64.\nPattern: [a-zA-Z0-9\\-]+\nCreatedAt\nThe date and time when you registered the location.\nType: Timestamp\nIAMRoleArn\nThe Amazon Resource Name (ARN) of the IAM role for the registered location.", "S3 Access Grants \nassumes this role to manage access to the registered location.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 2048.\nPattern: arn:[^:]+:iam::\\d{12}:role/.*\nLocationScope\nThe S3 URI path to the registered location. The location scope can be the default S3 location\ns3://, the S3 path to a bucket, or the S3 path to a bucket and pre\ufb01x. A pre\ufb01x in S3 is a string \nof characters at the beginning of an object key name used to organize the objects that you \nstore in your S3 buckets.", "For example, object key names that start with the engineering/\npre\ufb01x or object key names that start with the marketing/campaigns/  pre\ufb01x.\nType: String\nLength Constraints: Minimum length of 1.", "Maximum length of 2000.\nPattern: ^.+$\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\nAmazon S3 Control API Version 2006-03-01 890Amazon Simple Storage Service API Reference\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 891Amazon Simple Storage Service API Reference\nGetAccessPoint\nService: Amazon S3 Control\nNote\nThis operation is not supported by directory buckets.\nReturns con\ufb01guration information about the speci\ufb01ed access point.\nAll Amazon S3 on Outposts REST API requests for this action require an additional parameter of\nx-amz-outpost-id  to be passed with the request. In addition, you must use an S3 on Outposts \nendpoint hostname pre\ufb01x instead of s3-control . For an example of the request syntax for \nAmazon S3 on Outposts that uses the S3 on Outposts endpoint hostname pre\ufb01x and the x-amz-\noutpost-id  derived by using the access point ARN, see the Examples  section.\nThe following actions are related to GetAccessPoint :\n\u2022CreateAccessPoint\n\u2022DeleteAccessPoint\n\u2022ListAccessPoints\nRequest Syntax\nGET /v20180820/accesspoint/ name HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nname\nThe name of the access point whose con\ufb01guration information you want to retrieve.\nFor using this parameter with Amazon S3 on Outposts with the REST API, you must specify the \nname and the x-amz-outpost-id as well.\nAmazon S3 Control API Version 2006-03-01 892Amazon Simple Storage Service API Reference\nFor using this parameter with S3 on Outposts with the AWS SDK and CLI, you \nmust specify the ARN of the access point accessed in the format arn:aws:s3-\noutposts:<Region>:<account-id>:outpost/<outpost-id>/accesspoint/<my-\naccesspoint-name> . For example, to access the access point reports-ap  through \nOutpost my-outpost  owned by account 123456789012  in Region us-west-2 , use the URL \nencoding of arn:aws:s3-outposts:us-west-2:123456789012:outpost/my-outpost/\naccesspoint/reports-ap .", "The value must be URL encoded.\nLength Constraints: Minimum length of 3.", "Maximum length of 255.\nRequired: Yes\nx-amz-account-id\nThe AWS account ID for the account that owns the speci\ufb01ed access point.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<GetAccessPointResult > \n   <Name>string</Name> \n   <Bucket>string</Bucket> \n   <NetworkOrigin >string</NetworkOrigin > \n   <VpcConfiguration > \n      <VpcId>string</VpcId> \n   </VpcConfiguration > \n   <PublicAccessBlockConfiguration > \n      <BlockPublicAcls >boolean</BlockPublicAcls > \n      <BlockPublicPolicy >boolean</BlockPublicPolicy > \n      <IgnorePublicAcls >boolean</IgnorePublicAcls > \n      <RestrictPublicBuckets >boolean</RestrictPublicBuckets > \nAmazon S3 Control API Version 2006-03-01 893Amazon Simple Storage Service API Reference\n   </PublicAccessBlockConfiguration > \n   <CreationDate >timestamp </CreationDate > \n   <Alias>string</Alias> \n   <AccessPointArn >string</AccessPointArn > \n   <Endpoints > \n      <entry> \n         <key> string</key> \n         <value> string</value> \n      </entry> \n   </Endpoints > \n   <BucketAccountId >string</BucketAccountId >\n</GetAccessPointResult >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nGetAccessPointResult\nRoot level tag for the GetAccessPointResult parameters.\nRequired: Yes\nAccessPointArn\nThe ARN of the access point.\nType: String\nLength Constraints: Minimum length of 4. Maximum length of 128.\nAlias\nThe name or alias of the access point.\nType: String\nLength Constraints: Maximum length of 63.\nPattern: ^[0-9a-z\\\\-]{63}\nBucket\nThe name of the bucket associated with the speci\ufb01ed access point.\nAmazon S3 Control API Version 2006-03-01 894Amazon Simple Storage Service API Reference\nType: String\nLength Constraints: Minimum length of 3. Maximum length of 255.\nBucketAccountId\nThe AWS account ID associated with the S3 bucket associated with this access point.\nType: String\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nCreationDate\nThe date and time when the speci\ufb01ed access point was created.\nType: Timestamp\nEndpoints\nThe VPC endpoint for the access point.\nType: String to string map\nKey Length Constraints: Minimum length of 1.", "Maximum length of 64.\nValue Length Constraints: Minimum length of 1.", "Maximum length of 1024.\nName\nThe name of the speci\ufb01ed access point.\nType: String\nLength Constraints: Minimum length of 3. Maximum length of 255.\nNetworkOrigin\nIndicates whether this access point allows access from the public internet. If\nVpcConfiguration  is speci\ufb01ed for this access point, then NetworkOrigin  is VPC, and the \naccess point doesn't allow access from the public internet.", "Otherwise, NetworkOrigin  is\nInternet , and the access point allows access from the public internet, subject to the access \npoint and bucket access policies.\nAmazon S3 Control API Version 2006-03-01 895Amazon Simple Storage Service API Reference\nThis will always be true for an Amazon S3 on Outposts access point\nType: String\nValid Values: Internet | VPC\nPublicAccessBlockCon\ufb01guration\nThe PublicAccessBlock  con\ufb01guration that you want to apply to this Amazon S3 account.", "\nYou can enable the con\ufb01guration options in any combination.", "For more information about when \nAmazon S3 considers a bucket or object public, see The Meaning of \"Public\" in the Amazon S3 \nUser Guide .\nThis data type is not supported for Amazon S3 on Outposts.\nType: PublicAccessBlockCon\ufb01guration data type\nVpcCon\ufb01guration\nContains the virtual private cloud (VPC) con\ufb01guration for the speci\ufb01ed access point.\nNote\nThis element is empty if this access point is an Amazon S3 on Outposts access point that \nis used by other AWS services.\nType: VpcCon\ufb01guration data type\nExamples\nSample request syntax for getting an Amazon S3 on Outposts access point\nThe following request returns the access point of the speci\ufb01ed S3 on Outposts access point.\n           GET /v20180820/accesspoint/example-access-point HTTP/1.1 \n           Host: s3-outposts.<Region>.amazonaws.com \n           Date: Wed, 28 Oct 2020 22:32:00 GMT \n           Authorization: authorization string \n           x-amz-account-id: example-account-id \n           x-amz-outpost-id: op-01ac5d28a6a232904 \nAmazon S3 Control API Version 2006-03-01 896Amazon Simple Storage Service API Reference\n         \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 897Amazon Simple Storage Service API Reference\nGetAccessPointCon\ufb01gurationForObjectLambda\nService: Amazon S3 Control\nNote\nThis operation is not supported by directory buckets.\nReturns con\ufb01guration for an Object Lambda Access Point.\nThe following actions are related to GetAccessPointConfigurationForObjectLambda :\n\u2022PutAccessPointCon\ufb01gurationForObjectLambda\nRequest Syntax\nGET /v20180820/accesspointforobjectlambda/ name/configuration HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nname\nThe name of the Object Lambda Access Point you want to return the con\ufb01guration for.\nLength Constraints: Minimum length of 3. Maximum length of 45.\nPattern: ^[a-z0-9]([a-z0-9\\-]*[a-z0-9])?$\nRequired: Yes\nx-amz-account-id\nThe account ID for the account that owns the speci\ufb01ed Object Lambda Access Point.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nAmazon S3 Control API Version 2006-03-01 898Amazon Simple Storage Service API Reference\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<GetAccessPointConfigurationForObjectLambdaResult > \n   <Configuration > \n      <AllowedFeatures > \n         <AllowedFeature> string</AllowedFeature> \n      </ AllowedFeatures > \n      <CloudWatchMetricsEnabled >boolean</CloudWatchMetricsEnabled > \n      <SupportingAccessPoint >string</SupportingAccessPoint > \n      <TransformationConfigurations > \n         <TransformationConfiguration> \n            < Actions> \n               <Action> string</Action> \n            </ Actions> \n            < ContentTransformation > \n               < AwsLambda > \n                  < FunctionArn >string</FunctionArn > \n                  < FunctionPayload >string</FunctionPayload > \n               </ AwsLambda > \n            </ ContentTransformation > \n         </TransformationConfiguration> \n      </ TransformationConfigurations > \n   </Configuration >\n</GetAccessPointConfigurationForObjectLambdaResult >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nGetAccessPointCon\ufb01gurationForObjectLambdaResult\nRoot level tag for the GetAccessPointCon\ufb01gurationForObjectLambdaResult parameters.\nAmazon S3 Control API Version 2006-03-01 899Amazon Simple Storage Service API Reference\nRequired: Yes\nCon\ufb01guration\nObject Lambda Access Point con\ufb01guration document.\nType: ObjectLambdaCon\ufb01guration data type\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 900Amazon Simple Storage Service API Reference\nGetAccessPointForObjectLambda\nService: Amazon S3 Control\nNote\nThis operation is not supported by directory buckets.\nReturns con\ufb01guration information about the speci\ufb01ed Object Lambda Access Point\nThe following actions are related to GetAccessPointForObjectLambda :\n\u2022CreateAccessPointForObjectLambda\n\u2022DeleteAccessPointForObjectLambda\n\u2022ListAccessPointsForObjectLambda\nRequest Syntax\nGET /v20180820/accesspointforobjectlambda/ name HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nname\nThe name of the Object Lambda Access Point.\nLength Constraints: Minimum length of 3. Maximum length of 45.\nPattern: ^[a-z0-9]([a-z0-9\\-]*[a-z0-9])?$\nRequired: Yes\nx-amz-account-id\nThe account ID for the account that owns the speci\ufb01ed Object Lambda Access Point.\nLength Constraints: Maximum length of 64.\nAmazon S3 Control API Version 2006-03-01 901Amazon Simple Storage Service API Reference\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<GetAccessPointForObjectLambdaResult > \n   <Name>string</Name> \n   <PublicAccessBlockConfiguration > \n      <BlockPublicAcls >boolean</BlockPublicAcls > \n      <BlockPublicPolicy >boolean</BlockPublicPolicy > \n      <IgnorePublicAcls >boolean</IgnorePublicAcls > \n      <RestrictPublicBuckets >boolean</RestrictPublicBuckets > \n   </PublicAccessBlockConfiguration > \n   <CreationDate >timestamp </CreationDate > \n   <Alias> \n      <Status>string</Status> \n      <Value>string</Value> \n   </Alias>\n</GetAccessPointForObjectLambdaResult >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nGetAccessPointForObjectLambdaResult\nRoot level tag for the GetAccessPointForObjectLambdaResult parameters.\nRequired: Yes\nAlias\nThe alias of the Object Lambda Access Point.\nType: ObjectLambdaAccessPointAlias data type\nAmazon S3 Control API Version 2006-03-01 902Amazon Simple Storage Service API Reference\nCreationDate\nThe date and time when the speci\ufb01ed Object Lambda Access Point was created.\nType: Timestamp\nName\nThe name of the Object Lambda Access Point.\nType: String\nLength Constraints: Minimum length of 3.", "Maximum length of 45.\nPattern: ^[a-z0-9]([a-z0-9\\-]*[a-z0-9])?$\nPublicAccessBlockCon\ufb01guration\nCon\ufb01guration to block all public access.", "This setting is turned on and can not be edited.\nType: PublicAccessBlockCon\ufb01guration data type\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 903Amazon Simple Storage Service API Reference\nGetAccessPointPolicy\nService: Amazon S3 Control\nNote\nThis operation is not supported by directory buckets.\nReturns the access point policy associated with the speci\ufb01ed access point.\nThe following actions are related to GetAccessPointPolicy :\n\u2022PutAccessPointPolicy\n\u2022DeleteAccessPointPolicy\nRequest Syntax\nGET /v20180820/accesspoint/ name/policy HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nname\nThe name of the access point whose policy you want to retrieve.\nFor using this parameter with Amazon S3 on Outposts with the REST API, you must specify the \nname and the x-amz-outpost-id as well.\nFor using this parameter with S3 on Outposts with the AWS SDK and CLI, you \nmust specify the ARN of the access point accessed in the format arn:aws:s3-\noutposts:<Region>:<account-id>:outpost/<outpost-id>/accesspoint/<my-\naccesspoint-name> . For example, to access the access point reports-ap  through \nOutpost my-outpost  owned by account 123456789012  in Region us-west-2 , use the URL \nencoding of arn:aws:s3-outposts:us-west-2:123456789012:outpost/my-outpost/\naccesspoint/reports-ap .", "The value must be URL encoded.\nAmazon S3 Control API Version 2006-03-01 904Amazon Simple Storage Service API Reference\nLength Constraints: Minimum length of 3.", "Maximum length of 255.\nRequired: Yes\nx-amz-account-id\nThe account ID for the account that owns the speci\ufb01ed access point.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<GetAccessPointPolicyResult > \n   <Policy>string</Policy>\n</GetAccessPointPolicyResult >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nGetAccessPointPolicyResult\nRoot level tag for the GetAccessPointPolicyResult parameters.\nRequired: Yes\nPolicy\nThe access point policy associated with the speci\ufb01ed access point.\nType: String\nAmazon S3 Control API Version 2006-03-01 905Amazon Simple Storage Service API Reference\nExamples\nSample request\nThe following request returns the access point of the speci\ufb01ed Amazon S3 on Outposts.\n           GET /v20180820/accesspoint/example-access-point/policy  HTTP/1.1 \n           Host: s3-outposts.<Region>.amazonaws.com \n           Date: Wed, 28 Oct 2020 22:32:00 GMT \n           Authorization: authorization string \n           x-amz-account-id: 123456789012 \n           x-amz-outpost-id: op-123456 \n          \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 906Amazon Simple Storage Service API Reference\nGetAccessPointPolicyForObjectLambda\nService: Amazon S3 Control\nNote\nThis operation is not supported by directory buckets.\nReturns the resource policy for an Object Lambda Access Point.\nThe following actions are related to GetAccessPointPolicyForObjectLambda :\n\u2022DeleteAccessPointPolicyForObjectLambda\n\u2022PutAccessPointPolicyForObjectLambda\nRequest Syntax\nGET /v20180820/accesspointforobjectlambda/ name/policy HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nname\nThe name of the Object Lambda Access Point.\nLength Constraints: Minimum length of 3. Maximum length of 45.\nPattern: ^[a-z0-9]([a-z0-9\\-]*[a-z0-9])?$\nRequired: Yes\nx-amz-account-id\nThe account ID for the account that owns the speci\ufb01ed Object Lambda Access Point.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nAmazon S3 Control API Version 2006-03-01 907Amazon Simple Storage Service API Reference\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<GetAccessPointPolicyForObjectLambdaResult > \n   <Policy>string</Policy>\n</GetAccessPointPolicyForObjectLambdaResult >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nGetAccessPointPolicyForObjectLambdaResult\nRoot level tag for the GetAccessPointPolicyForObjectLambdaResult parameters.\nRequired: Yes\nPolicy\nObject Lambda Access Point resource policy document.\nType: String\nExamples\nSample resource policy\nThe following illustrates a sample resource policy.\n{ \n    \"Version\" : \"2008-10-17\", \n    \"Statement\":[{ \n        \"Sid\": \"Grant account 123456789012 GetObject access\", \nAmazon S3 Control API Version 2006-03-01 908Amazon Simple Storage Service API Reference\n        \"Effect\":\"Allow\", \n        \"Principal\" : { \n            \"AWS\": \"arn:aws:iam::123456789012:root\" \n        }, \n        \"Action\":[\"s3-object-lambda:GetObject\"], \n        \"Resource\":[\"arn:aws:s3-object-lambda:us-east-1:123456789012:accesspoint/my-\nobject-lambda-ap\"] \n        }, \n        { \n        \"Sid\": \"Grant account 444455556666 GetObject access\", \n        \"Effect\":\"Allow\", \n        \"Principal\" : { \n            \"AWS\": \"arn:aws:iam::444455556666:root\" \n        }, \n        \"Action\":[\"s3-object-lambda:GetObject\"], \n        \"Resource\":[\"arn:aws:s3-object-lambda:us-east-1:123456789012:accesspoint/my-\nobject-lambda-ap\"] \n        } \n    ]\n}\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 909Amazon Simple Storage Service API Reference\nGetAccessPointPolicyStatus\nService: Amazon S3 Control\nNote\nThis operation is not supported by directory buckets.\nIndicates whether the speci\ufb01ed access point currently has a policy that allows public access. For \nmore information about public access through access points, see Managing Data Access with \nAmazon S3 access points in the Amazon S3 User Guide .\nRequest Syntax\nGET /v20180820/accesspoint/ name/policyStatus HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nname\nThe name of the access point whose policy status you want to retrieve.\nLength Constraints: Minimum length of 3. Maximum length of 255.\nRequired: Yes\nx-amz-account-id\nThe account ID for the account that owns the speci\ufb01ed access point.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nAmazon S3 Control API Version 2006-03-01 910Amazon Simple Storage Service API Reference\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<GetAccessPointPolicyStatusResult > \n   <PolicyStatus > \n      <IsPublic >boolean</IsPublic > \n   </PolicyStatus >\n</GetAccessPointPolicyStatusResult >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nGetAccessPointPolicyStatusResult\nRoot level tag for the GetAccessPointPolicyStatusResult parameters.\nRequired: Yes\nPolicyStatus\nIndicates the current policy status of the speci\ufb01ed access point.\nType: PolicyStatus data type\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\nAmazon S3 Control API Version 2006-03-01 911Amazon Simple Storage Service API Reference\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 912Amazon Simple Storage Service API Reference\nGetAccessPointPolicyStatusForObjectLambda\nService: Amazon S3 Control\nNote\nThis operation is not supported by directory buckets.\nReturns the status of the resource policy associated with an Object Lambda Access Point.\nRequest Syntax\nGET /v20180820/accesspointforobjectlambda/ name/policyStatus HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nname\nThe name of the Object Lambda Access Point.\nLength Constraints: Minimum length of 3. Maximum length of 45.\nPattern: ^[a-z0-9]([a-z0-9\\-]*[a-z0-9])?$\nRequired: Yes\nx-amz-account-id\nThe account ID for the account that owns the speci\ufb01ed Object Lambda Access Point.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nAmazon S3 Control API Version 2006-03-01 913Amazon Simple Storage Service API Reference\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<GetAccessPointPolicyStatusForObjectLambdaResult > \n   <PolicyStatus > \n      <IsPublic >boolean</IsPublic > \n   </PolicyStatus >\n</GetAccessPointPolicyStatusForObjectLambdaResult >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nGetAccessPointPolicyStatusForObjectLambdaResult\nRoot level tag for the GetAccessPointPolicyStatusForObjectLambdaResult parameters.\nRequired: Yes\nPolicyStatus\nIndicates whether this access point policy is public. For more information about how Amazon \nS3 evaluates policies to determine whether they are public, see The Meaning of \"Public\" in the\nAmazon S3 User Guide .\nType: PolicyStatus data type\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\nAmazon S3 Control API Version 2006-03-01 914Amazon Simple Storage Service API Reference\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 915Amazon Simple Storage Service API Reference\nGetBucket\nService: Amazon S3 Control\nGets an Amazon S3 on Outposts bucket. For more information, see  Using Amazon S3 on Outposts\nin the Amazon S3 User Guide .\nIf you are using an identity other than the root user of the AWS account that owns the Outposts \nbucket, the calling identity must have the s3-outposts:GetBucket  permissions on the speci\ufb01ed \nOutposts bucket and belong to the Outposts bucket owner's account in order to use this action. \nOnly users from Outposts bucket owner account with the right permissions can perform actions on \nan Outposts bucket.\nIf you don't have s3-outposts:GetBucket  permissions or you're not using an identity that \nbelongs to the bucket owner's account, Amazon S3 returns a 403 Access Denied  error.\nThe following actions are related to GetBucket  for Amazon S3 on Outposts:\nAll Amazon S3 on Outposts REST API requests for this action require an additional parameter of\nx-amz-outpost-id  to be passed with the request. In addition, you must use an S3 on Outposts \nendpoint hostname pre\ufb01x instead of s3-control . For an example of the request syntax for \nAmazon S3 on Outposts that uses the S3 on Outposts endpoint hostname pre\ufb01x and the x-amz-\noutpost-id  derived by using the access point ARN, see the Examples  section.\n\u2022PutObject\n\u2022CreateBucket\n\u2022DeleteBucket\nRequest Syntax\nGET /v20180820/bucket/ name HTTP/1.1\nHost: Bucket.s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nname\nSpeci\ufb01es the bucket.\nAmazon S3 Control API Version 2006-03-01 916Amazon Simple Storage Service API Reference\nFor using this parameter with Amazon S3 on Outposts with the REST API, you must specify the \nname and the x-amz-outpost-id as well.\nFor using this parameter with S3 on Outposts with the AWS SDK and CLI, you must specify the \nARN of the bucket accessed in the format arn:aws:s3-outposts:<Region>:<account-\nid>:outpost/<outpost-id>/bucket/<my-bucket-name> . For example, to access \nthe bucket reports through Outpost my-outpost  owned by account 123456789012\nin Region us-west-2 , use the URL encoding of arn:aws:s3-outposts:us-\nwest-2:123456789012:outpost/my-outpost/bucket/reports .", "The value must be URL \nencoded.\nLength Constraints: Minimum length of 3.", "Maximum length of 255.\nRequired: Yes\nx-amz-account-id\nThe AWS account ID of the Outposts bucket.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<GetBucketResult > \n   <Bucket>string</Bucket> \n   <PublicAccessBlockEnabled >boolean</PublicAccessBlockEnabled > \n   <CreationDate >timestamp </CreationDate >\n</GetBucketResult >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nAmazon S3 Control API Version 2006-03-01 917Amazon Simple Storage Service API Reference\nThe following data is returned in XML format by the service.\nGetBucketResult\nRoot level tag for the GetBucketResult parameters.\nRequired: Yes\nBucket\nThe Outposts bucket requested.\nType: String\nLength Constraints: Minimum length of 3. Maximum length of 255.\nCreationDate\nThe creation date of the Outposts bucket.\nType: Timestamp\nPublicAccessBlockEnabled\nType: Boolean\nExamples\nSample request for getting Amazon S3 on Outposts bucket\nThis example illustrates one usage of GetBucket.\nGET /v20180820/bucket/example-outpost-bucket/ HTTP/1.1\nHost: s3-outposts.<Region>.amazonaws.com   \n            x-amz-account-id: example-account-id \n            x-amz-outpost-id: op-01ac5d28a6a232904 \n            x-amz-Date: 20200928T203757Z \n            Authorization: authorization string \n             \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\nAmazon S3 Control API Version 2006-03-01 918Amazon Simple Storage Service API Reference\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 919Amazon Simple Storage Service API Reference\nGetBucketLifecycleCon\ufb01guration\nService: Amazon S3 Control\nNote\nThis action gets an Amazon S3 on Outposts bucket's lifecycle con\ufb01guration. To get an S3 \nbucket's lifecycle con\ufb01guration, see GetBucketLifecycleCon\ufb01guration in the Amazon S3 API \nReference.\nReturns the lifecycle con\ufb01guration information set on the Outposts bucket. For more information, \nsee Using Amazon S3 on Outposts and for information about lifecycle con\ufb01guration, see  Object \nLifecycle Management in Amazon S3 User Guide .\nTo use this action, you must have permission to perform the s3-\noutposts:GetLifecycleConfiguration  action.", "The Outposts bucket owner has this \npermission, by default. The bucket owner can grant this permission to others.", "For more information \nabout permissions, see Permissions Related to Bucket Subresource Operations and Managing \nAccess Permissions to Your Amazon S3 Resources.\nAll Amazon S3 on Outposts REST API requests for this action require an additional parameter of\nx-amz-outpost-id  to be passed with the request. In addition, you must use an S3 on Outposts \nendpoint hostname pre\ufb01x instead of s3-control . For an example of the request syntax for \nAmazon S3 on Outposts that uses the S3 on Outposts endpoint hostname pre\ufb01x and the x-amz-\noutpost-id  derived by using the access point ARN, see the Examples  section.\nGetBucketLifecycleConfiguration  has the following special error:\n\u2022Error code: NoSuchLifecycleConfiguration\n\u2022Description: The lifecycle con\ufb01guration does not exist.\n\u2022HTTP Status Code: 404 Not Found\n\u2022SOAP Fault Code Pre\ufb01x: Client\nThe following actions are related to GetBucketLifecycleConfiguration :\n\u2022PutBucketLifecycleCon\ufb01guration\n\u2022DeleteBucketLifecycleCon\ufb01guration\nAmazon S3 Control API Version 2006-03-01 920Amazon Simple Storage Service API Reference\nRequest Syntax\nGET /v20180820/bucket/ name/lifecycleconfiguration HTTP/1.1\nHost: Bucket.s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nname\nThe Amazon Resource Name (ARN) of the bucket.\nFor using this parameter with Amazon S3 on Outposts with the REST API, you must specify the \nname and the x-amz-outpost-id as well.\nFor using this parameter with S3 on Outposts with the AWS SDK and CLI, you must specify the \nARN of the bucket accessed in the format arn:aws:s3-outposts:<Region>:<account-\nid>:outpost/<outpost-id>/bucket/<my-bucket-name> . For example, to access \nthe bucket reports through Outpost my-outpost  owned by account 123456789012\nin Region us-west-2 , use the URL encoding of arn:aws:s3-outposts:us-\nwest-2:123456789012:outpost/my-outpost/bucket/reports .", "The value must be URL \nencoded.\nLength Constraints: Minimum length of 3.", "Maximum length of 255.\nRequired: Yes\nx-amz-account-id\nThe AWS account ID of the Outposts bucket.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nAmazon S3 Control API Version 2006-03-01 921Amazon Simple Storage Service API Reference\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<GetBucketLifecycleConfigurationResult > \n   <Rules> \n      <Rule> \n         < AbortIncompleteMultipartUpload > \n            < DaysAfterInitiation >integer</DaysAfterInitiation > \n         </ AbortIncompleteMultipartUpload > \n         < Expiration > \n            < Date>timestamp </Date> \n            < Days>integer</Days> \n            < ExpiredObjectDeleteMarker >boolean</ExpiredObjectDeleteMarker > \n         </ Expiration > \n         < Filter> \n            < And> \n               < ObjectSizeGreaterThan >long</ObjectSizeGreaterThan > \n               < ObjectSizeLessThan >long</ObjectSizeLessThan > \n               < Prefix>string</Prefix> \n               < Tags> \n                  <S3Tag> \n                     < Key>string</Key> \n                     < Value>string</Value> \n                  </S3Tag> \n               </ Tags> \n            </ And> \n            < ObjectSizeGreaterThan >long</ObjectSizeGreaterThan > \n            < ObjectSizeLessThan >long</ObjectSizeLessThan > \n            < Prefix>string</Prefix> \n            < Tag> \n               < Key>string</Key> \n               < Value>string</Value> \n            </ Tag> \n         </ Filter> \n         < ID>string</ID> \n         < NoncurrentVersionExpiration > \n            < NewerNoncurrentVersions >integer</NewerNoncurrentVersions > \n            < NoncurrentDays >integer</NoncurrentDays > \n         </ NoncurrentVersionExpiration > \n         < NoncurrentVersionTransitions > \n            <NoncurrentVersionTransition> \n               < NoncurrentDays >integer</NoncurrentDays > \n               < StorageClass >string</StorageClass > \nAmazon S3 Control API Version 2006-03-01 922Amazon Simple Storage Service API Reference\n            </NoncurrentVersionTransition> \n         </ NoncurrentVersionTransitions > \n         < Status>string</Status> \n         < Transitions > \n            <Transition> \n               < Date>timestamp </Date> \n               < Days>integer</Days> \n               < StorageClass >string</StorageClass > \n            </Transition> \n         </ Transitions > \n      </Rule> \n   </Rules>\n</GetBucketLifecycleConfigurationResult >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nGetBucketLifecycleCon\ufb01gurationResult\nRoot level tag for the GetBucketLifecycleCon\ufb01gurationResult parameters.\nRequired: Yes\nRules\nContainer for the lifecycle rule of the Outposts bucket.\nType: Array of LifecycleRule data types\nExamples\nSample request to get the lifecycle con\ufb01guration of the Amazon S3 on Outposts bucket\nThe following example shows how to get the lifecycle con\ufb01guration of the Outposts bucket.\n            GET /v20180820/bucket/example-outpost-bucket/lifecycleconfiguration \n HTTP/1.1 \n            Host: s3-outposts.<Region>.amazonaws.com  \n            x-amz-account-id: example-account-id \nAmazon S3 Control API Version 2006-03-01 923Amazon Simple Storage Service API Reference\n            x-amz-outpost-id: op-01ac5d28a6a232904 \n            x-amz-date: Thu, 15 Nov 2012 00:17:21 GMT \n            Authorization: signatureValue \n          \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 924Amazon Simple Storage Service API Reference\nGetBucketPolicy\nService: Amazon S3 Control\nNote\nThis action gets a bucket policy for an Amazon S3 on Outposts bucket.", "To get a policy for \nan S3 bucket, see GetBucketPolicy in the Amazon S3 API Reference.\nReturns the policy of a speci\ufb01ed Outposts bucket. For more information, see Using Amazon S3 on \nOutposts  in the Amazon S3 User Guide .\nIf you are using an identity other than the root user of the AWS account that owns the bucket, the \ncalling identity must have the GetBucketPolicy  permissions on the speci\ufb01ed bucket and belong \nto the bucket owner's account in order to use this action.\nOnly users from Outposts bucket owner account with the right permissions can perform actions \non an Outposts bucket. If you don't have s3-outposts:GetBucketPolicy  permissions or \nyou're not using an identity that belongs to the bucket owner's account, Amazon S3 returns a 403 \nAccess Denied  error.\nImportant\nAs a security precaution, the root user of the AWS account that owns a bucket can always \nuse this action, even if the policy explicitly denies the root user the ability to perform this \naction.\nFor more information about bucket policies, see Using Bucket Policies and User Policies.\nAll Amazon S3 on Outposts REST API requests for this action require an additional parameter of\nx-amz-outpost-id  to be passed with the request. In addition, you must use an S3 on Outposts \nendpoint hostname pre\ufb01x instead of s3-control . For an example of the request syntax for \nAmazon S3 on Outposts that uses the S3 on Outposts endpoint hostname pre\ufb01x and the x-amz-\noutpost-id  derived by using the access point ARN, see the Examples  section.\nThe following actions are related to GetBucketPolicy :\n\u2022GetObject\nAmazon S3 Control API Version 2006-03-01 925Amazon Simple Storage Service API Reference\n\u2022PutBucketPolicy\n\u2022DeleteBucketPolicy\nRequest Syntax\nGET /v20180820/bucket/ name/policy HTTP/1.1\nHost: Bucket.s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nname\nSpeci\ufb01es the bucket.\nFor using this parameter with Amazon S3 on Outposts with the REST API, you must specify the \nname and the x-amz-outpost-id as well.\nFor using this parameter with S3 on Outposts with the AWS SDK and CLI, you must specify the \nARN of the bucket accessed in the format arn:aws:s3-outposts:<Region>:<account-\nid>:outpost/<outpost-id>/bucket/<my-bucket-name> . For example, to access \nthe bucket reports through Outpost my-outpost  owned by account 123456789012\nin Region us-west-2 , use the URL encoding of arn:aws:s3-outposts:us-\nwest-2:123456789012:outpost/my-outpost/bucket/reports .", "The value must be URL \nencoded.\nLength Constraints: Minimum length of 3.", "Maximum length of 255.\nRequired: Yes\nx-amz-account-id\nThe AWS account ID of the Outposts bucket.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nAmazon S3 Control API Version 2006-03-01 926Amazon Simple Storage Service API Reference\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<GetBucketPolicyResult > \n   <Policy>string</Policy>\n</GetBucketPolicyResult >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nGetBucketPolicyResult\nRoot level tag for the GetBucketPolicyResult parameters.\nRequired: Yes\nPolicy\nThe policy of the Outposts bucket.\nType: String\nExamples\nSample GetBucketPolicy request for an Amazon S3 on Outposts bucket\nThe following request gets the policy of the speci\ufb01ed Outposts bucket example-outpost-\nbucket .\n           GET /v20180820/bucket/example-outpost-bucket/policy HTTP/1.1 \n           Host: s3-outposts.<Region>.amazonaws.com \n           Date: Wed, 28 Oct 2009 22:32:00 GMT \n           Authorization: authorization string \n           x-amz-account-id: example-account-id \nAmazon S3 Control API Version 2006-03-01 927Amazon Simple Storage Service API Reference\n           x-amz-outpost-id: op-01ac5d28a6a232904 \n          \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 928Amazon Simple Storage Service API Reference\nGetBucketReplication\nService: Amazon S3 Control\nNote\nThis operation gets an Amazon S3 on Outposts bucket's replication con\ufb01guration. To get \nan S3 bucket's replication con\ufb01guration, see GetBucketReplication in the Amazon S3 API \nReference.\nReturns the replication con\ufb01guration of an S3 on Outposts bucket. For more information about \nS3 on Outposts, see Using Amazon S3 on Outposts in the Amazon S3 User Guide . For information \nabout S3 replication on Outposts con\ufb01guration, see Replicating objects for S3 on Outposts in the\nAmazon S3 User Guide .\nNote\nIt can take a while to propagate PUT or DELETE requests for a replication con\ufb01guration \nto all S3 on Outposts systems. Therefore, the replication con\ufb01guration that's returned \nby a GET request soon after a PUT or DELETE request might return a more recent result \nthan what's on the Outpost. If an Outpost is o\ufb04ine, the delay in updating the replication \ncon\ufb01guration on that Outpost can be signi\ufb01cant.\nThis action requires permissions for the s3-outposts:GetReplicationConfiguration  action.", "\nThe Outposts bucket owner has this permission by default and can grant it to others.", "For more \ninformation about permissions, see Setting up IAM with S3 on Outposts and Managing access to S3 \non Outposts bucket in the Amazon S3 User Guide .\nAll Amazon S3 on Outposts REST API requests for this action require an additional parameter of\nx-amz-outpost-id  to be passed with the request. In addition, you must use an S3 on Outposts \nendpoint hostname pre\ufb01x instead of s3-control . For an example of the request syntax for \nAmazon S3 on Outposts that uses the S3 on Outposts endpoint hostname pre\ufb01x and the x-amz-\noutpost-id  derived by using the access point ARN, see the Examples  section.\nIf you include the Filter element in a replication con\ufb01guration, you must also include the\nDeleteMarkerReplication , Status , and Priority  elements. The response also returns those \nelements.\nAmazon S3 Control API Version 2006-03-01 929Amazon Simple Storage Service API Reference\nFor information about S3 on Outposts replication failure reasons, see Replication failure reasons in \nthe Amazon S3 User Guide .\nThe following operations are related to GetBucketReplication :\n\u2022PutBucketReplication\n\u2022DeleteBucketReplication\nRequest Syntax\nGET /v20180820/bucket/ name/replication HTTP/1.1\nHost: Bucket.s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nname\nSpeci\ufb01es the bucket to get the replication information for.\nFor using this parameter with Amazon S3 on Outposts with the REST API, you must specify the \nname and the x-amz-outpost-id as well.\nFor using this parameter with S3 on Outposts with the AWS SDK and CLI, you must specify the \nARN of the bucket accessed in the format arn:aws:s3-outposts:<Region>:<account-\nid>:outpost/<outpost-id>/bucket/<my-bucket-name> . For example, to access \nthe bucket reports through Outpost my-outpost  owned by account 123456789012\nin Region us-west-2 , use the URL encoding of arn:aws:s3-outposts:us-\nwest-2:123456789012:outpost/my-outpost/bucket/reports .", "The value must be URL \nencoded.\nLength Constraints: Minimum length of 3.", "Maximum length of 255.\nRequired: Yes\nx-amz-account-id\nThe AWS account ID of the Outposts bucket.\nAmazon S3 Control API Version 2006-03-01 930Amazon Simple Storage Service API Reference\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<GetBucketReplicationResult > \n   <ReplicationConfiguration > \n      <Role>string</Role> \n      <Rules> \n         <Rule> \n            < Bucket>string</Bucket> \n            < DeleteMarkerReplication > \n               < Status>string</Status> \n            </ DeleteMarkerReplication > \n            < Destination > \n               < AccessControlTranslation > \n                  < Owner>string</Owner> \n               </ AccessControlTranslation > \n               < Account>string</Account> \n               < Bucket>string</Bucket> \n               < EncryptionConfiguration > \n                  < ReplicaKmsKeyID >string</ReplicaKmsKeyID > \n               </ EncryptionConfiguration > \n               < Metrics> \n                  < EventThreshold > \n                     < Minutes>integer</Minutes> \n                  </ EventThreshold > \n                  < Status>string</Status> \n               </ Metrics> \n               < ReplicationTime > \n                  < Status>string</Status> \n                  < Time> \n                     < Minutes>integer</Minutes> \n                  </ Time> \nAmazon S3 Control API Version 2006-03-01 931Amazon Simple Storage Service API Reference\n               </ ReplicationTime > \n               < StorageClass >string</StorageClass > \n            </ Destination > \n            < ExistingObjectReplication > \n               < Status>string</Status> \n            </ ExistingObjectReplication > \n            < Filter> \n               < And> \n                  < Prefix>string</Prefix> \n                  < Tags> \n                     <S3Tag> \n                        < Key>string</Key> \n                        < Value>string</Value> \n                     </S3Tag> \n                  </ Tags> \n               </ And> \n               < Prefix>string</Prefix> \n               < Tag> \n                  < Key>string</Key> \n                  < Value>string</Value> \n               </ Tag> \n            </ Filter> \n            < ID>string</ID> \n            < Prefix>string</Prefix> \n            < Priority >integer</Priority > \n            < SourceSelectionCriteria > \n               < ReplicaModifications > \n                  < Status>string</Status> \n               </ ReplicaModifications > \n               < SseKmsEncryptedObjects > \n                  < Status>string</Status> \n               </ SseKmsEncryptedObjects > \n            </ SourceSelectionCriteria > \n            < Status>string</Status> \n         </Rule> \n      </ Rules> \n   </ReplicationConfiguration >\n</GetBucketReplicationResult >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nAmazon S3 Control API Version 2006-03-01 932Amazon Simple Storage Service API Reference\nGetBucketReplicationResult\nRoot level tag for the GetBucketReplicationResult parameters.\nRequired: Yes\nReplicationCon\ufb01guration\nA container for one or more replication rules.", "A replication con\ufb01guration must have at least one \nrule and you can add up to 100 rules.", "The maximum size of a replication con\ufb01guration is 128 \nKB.\nType: ReplicationCon\ufb01guration data type\nExamples\nSample request to get the replication con\ufb01guration of an Amazon S3 on Outposts bucket\nThe following example shows how to get the replication con\ufb01guration of an Outposts bucket.\nGET /v20180820/bucket/example-outpost-bucket/replication HTTP/1.1\nHost: s3-outposts.<Region>.amazonaws.com  \nx-amz-account-id: example-account-id\nx-amz-outpost-id: op-01ac5d28a6a232904\nAuthorization: signatureValue \n          \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\nAmazon S3 Control API Version 2006-03-01 933Amazon Simple Storage Service API Reference\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 934Amazon Simple Storage Service API Reference\nGetBucketTagging\nService: Amazon S3 Control\nNote\nThis action gets an Amazon S3 on Outposts bucket's tags. To get an S3 bucket tags, see\nGetBucketTagging in the Amazon S3 API Reference.\nReturns the tag set associated with the Outposts bucket. For more information, see Using Amazon \nS3 on Outposts  in the Amazon S3 User Guide .\nTo use this action, you must have permission to perform the GetBucketTagging  action. By \ndefault, the bucket owner has this permission and can grant this permission to others.\nGetBucketTagging  has the following special error:\n\u2022Error code: NoSuchTagSetError\n\u2022Description: There is no tag set associated with the bucket.\nAll Amazon S3 on Outposts REST API requests for this action require an additional parameter of\nx-amz-outpost-id  to be passed with the request. In addition, you must use an S3 on Outposts \nendpoint hostname pre\ufb01x instead of s3-control . For an example of the request syntax for \nAmazon S3 on Outposts that uses the S3 on Outposts endpoint hostname pre\ufb01x and the x-amz-\noutpost-id  derived by using the access point ARN, see the Examples  section.\nThe following actions are related to GetBucketTagging :\n\u2022PutBucketTagging\n\u2022DeleteBucketTagging\nRequest Syntax\nGET /v20180820/bucket/ name/tagging HTTP/1.1\nHost: Bucket.s3-control.amazonaws.com\nx-amz-account-id: AccountId\nAmazon S3 Control API Version 2006-03-01 935Amazon Simple Storage Service API Reference\nURI Request Parameters\nThe request uses the following URI parameters.\nname\nSpeci\ufb01es the bucket.\nFor using this parameter with Amazon S3 on Outposts with the REST API, you must specify the \nname and the x-amz-outpost-id as well.\nFor using this parameter with S3 on Outposts with the AWS SDK and CLI, you must specify the \nARN of the bucket accessed in the format arn:aws:s3-outposts:<Region>:<account-\nid>:outpost/<outpost-id>/bucket/<my-bucket-name> . For example, to access \nthe bucket reports through Outpost my-outpost  owned by account 123456789012\nin Region us-west-2 , use the URL encoding of arn:aws:s3-outposts:us-\nwest-2:123456789012:outpost/my-outpost/bucket/reports .", "The value must be URL \nencoded.\nLength Constraints: Minimum length of 3.", "Maximum length of 255.\nRequired: Yes\nx-amz-account-id\nThe AWS account ID of the Outposts bucket.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\nAmazon S3 Control API Version 2006-03-01 936Amazon Simple Storage Service API Reference\n<GetBucketTaggingResult > \n   <TagSet> \n      <S3Tag> \n         < Key>string</Key> \n         < Value>string</Value> \n      </S3Tag> \n   </TagSet>\n</GetBucketTaggingResult >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nGetBucketTaggingResult\nRoot level tag for the GetBucketTaggingResult parameters.\nRequired: Yes\nTagSet\nThe tags set of the Outposts bucket.\nType: Array of S3Tag data types\nExamples\nAmazon S3 on Outposts request example for getting a tag set for an Outposts bucket\nThe following request gets the tag set of the speci\ufb01ed Outposts bucket example-outpost-\nbucket .\n            GET /v20180820/bucket/example-outpost-bucket/tagging HTTP/1.1 \n            Host: s3-outposts.<Region>.amazonaws.com \n            x-amz-date: Wed, 28 Oct 2020 22:32:00 GMT \n            x-amz-account-id: example-account-id \n            x-amz-outpost-id: op-01ac5d28a6a232904 \n            Authorization: authorization string \n          \nAmazon S3 Control API Version 2006-03-01 937Amazon Simple Storage Service API Reference\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 938Amazon Simple Storage Service API Reference\nGetBucketVersioning\nService: Amazon S3 Control\nNote\nThis operation returns the versioning state for S3 on Outposts buckets only. To return the \nversioning state for an S3 bucket, see GetBucketVersioning in the Amazon S3 API Reference.\nReturns the versioning state for an S3 on Outposts bucket. With S3 Versioning, you can save \nmultiple distinct copies of your objects and recover from unintended user actions and application \nfailures.\nIf you've never set versioning on your bucket, it has no versioning state. In that case, the\nGetBucketVersioning  request does not return a versioning state value.\nFor more information about versioning, see Versioning in the Amazon S3 User Guide .\nAll Amazon S3 on Outposts REST API requests for this action require an additional parameter of\nx-amz-outpost-id  to be passed with the request. In addition, you must use an S3 on Outposts \nendpoint hostname pre\ufb01x instead of s3-control . For an example of the request syntax for \nAmazon S3 on Outposts that uses the S3 on Outposts endpoint hostname pre\ufb01x and the x-amz-\noutpost-id  derived by using the access point ARN, see the Examples  section.\nThe following operations are related to GetBucketVersioning  for S3 on Outposts.\n\u2022PutBucketVersioning\n\u2022PutBucketLifecycleCon\ufb01guration\n\u2022GetBucketLifecycleCon\ufb01guration\nRequest Syntax\nGET /v20180820/bucket/ name/versioning HTTP/1.1\nHost: Bucket.s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nAmazon S3 Control API Version 2006-03-01 939Amazon Simple Storage Service API Reference\nname\nThe S3 on Outposts bucket to return the versioning state for.\nLength Constraints: Minimum length of 3. Maximum length of 255.\nRequired: Yes\nx-amz-account-id\nThe AWS account ID of the S3 on Outposts bucket.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<GetBucketVersioningResult > \n   <Status>string</Status> \n   <MfaDelete >string</MfaDelete >\n</GetBucketVersioningResult >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nGetBucketVersioningResult\nRoot level tag for the GetBucketVersioningResult parameters.\nRequired: Yes\nAmazon S3 Control API Version 2006-03-01 940Amazon Simple Storage Service API Reference\nMFADelete\nSpeci\ufb01es whether MFA delete is enabled in the bucket versioning con\ufb01guration.", "This element is \nreturned only if the bucket has been con\ufb01gured with MFA delete. If MFA delete has never been \ncon\ufb01gured for the bucket, this element is not returned.\nType: String\nValid Values: Enabled | Disabled\nStatus\nThe versioning state of the S3 on Outposts bucket.\nType: String\nValid Values: Enabled | Suspended\nExamples\nSample GetBucketVersioning request on an S3 on Outposts bucket\nThis request returns the versioning state for an S3 on Outposts bucket that's named example-\noutpost-bucket .\n            GET /v20180820/bucket/example-outpost-bucket/?versioning HTTP/1.1 \n            Host:s3-outposts. region-code .amazonaws.com \n            x-amz-account-id: example-account-id \n            x-amz-outpost-id: op-01ac5d28a6a232904 \n            x-amz-date: Wed, 25 May  2022 00:14:21 GMT \n            Authorization: signatureValue \n          \nSample GetBucketVersioning response on a versioning-enabled S3 on Outposts bucket\nIf you enabled versioning on a bucket, the response is:\n     <VersioningConfiguration xmlns=\"http://awss3control.amazonaws.com/\ndoc/2018-08-20/\"> \n        <Status>Enabled</Status> \nAmazon S3 Control API Version 2006-03-01 941Amazon Simple Storage Service API Reference\n     </VersioningConfiguration> \n         \nSample GetBucketVersioning response on a versioning-suspended bucket\nIf you suspended versioning on a bucket, the response is:\n     <VersioningConfiguration xmlns=\"http://awss3control.amazonaws.com/\ndoc/2018-08-20/\"> \n        <Status>Suspended</Status> \n     </VersioningConfiguration> \n      \nSample GetBucketVersioning response if you have never enabled versioning.\nIf you have never enabled versioning on a bucket, the response is:\n     <VersioningConfiguration xmlns=\"http://awss3control.amazonaws.com/\ndoc/2018-08-20/\"> \n      \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 942Amazon Simple Storage Service API Reference\nGetDataAccess\nService: Amazon S3 Control\nReturns a temporary access credential from S3 Access Grants to the grantee or client application. \nThe temporary credential is an AWS STS token that grants them access to the S3 data.\nPermissions\nYou must have the s3:GetDataAccess  permission to use this operation.\nAdditional Permissions\nThe IAM role that S3 Access Grants assumes must have the following permissions speci\ufb01ed in \nthe trust policy when registering the location: sts:AssumeRole , for directory users or groups\nsts:SetContext , and for IAM users or roles sts:SetSourceIdentity .\nRequest Syntax\nGET /v20180820/accessgrantsinstance/dataaccess?\ndurationSeconds= DurationSeconds &permission= Permission &privilege= Privilege &target= Target&targetType= TargetType\n HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\ndurationSeconds\nThe session duration, in seconds, of the temporary access credential that S3 Access Grants \nvends to the grantee or client application.", "The default value is 1 hour, but the grantee can \nspecify a range from 900 seconds (15 minutes) up to 43200 seconds (12 hours). If the grantee \nrequests a value higher than this maximum, the operation fails.\nValid Range: Minimum value of 900.", "Maximum value of 43200.\npermission\nThe type of permission granted to your S3 data, which can be set to one of the following \nvalues:\n\u2022READ \u2013 Grant read-only access to the S3 data.\nAmazon S3 Control API Version 2006-03-01 943Amazon Simple Storage Service API Reference\n\u2022WRITE \u2013 Grant write-only access to the S3 data.\n\u2022READWRITE  \u2013 Grant both read and write access to the S3 data.\nValid Values: READ | WRITE | READWRITE\nRequired: Yes\nprivilege\nThe scope of the temporary access credential that S3 Access Grants vends to the grantee or \nclient application.\n\u2022Default \u2013 The scope of the returned temporary access token is the scope of the grant that is \nclosest to the target scope.\n\u2022Minimal \u2013 The scope of the returned temporary access token is the same as the requested \ntarget scope as long as the requested scope is the same as or a subset of the grant scope.\nValid Values: Minimal | Default\ntarget\nThe S3 URI path of the data to which you are requesting temporary access credentials. If the \nrequesting account has an access grant for this data, S3 Access Grants vends temporary access \ncredentials in the response.\nLength Constraints: Minimum length of 1.", "Maximum length of 2000.\nPattern: ^.+$\nRequired: Yes\ntargetType\nThe type of Target .", "The only possible value is Object. Pass this value if the target data that \nyou would like to access is a path to an object.", "Do not pass this value if the target data is a \nbucket or a bucket and a pre\ufb01x.\nValid Values: Object\nx-amz-account-id\nThe AWS account ID of the S3 Access Grants instance.\nLength Constraints: Maximum length of 64.\nAmazon S3 Control API Version 2006-03-01 944Amazon Simple Storage Service API Reference\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<GetDataAccessResult > \n   <Credentials > \n      <AccessKeyId >string</AccessKeyId > \n      <Expiration >timestamp </Expiration > \n      <SecretAccessKey >string</SecretAccessKey > \n      <SessionToken >string</SessionToken > \n   </Credentials > \n   <MatchedGrantTarget >string</MatchedGrantTarget >\n</GetDataAccessResult >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nGetDataAccessResult\nRoot level tag for the GetDataAccessResult parameters.\nRequired: Yes\nCredentials\nThe temporary credential token that S3 Access Grants vends.\nType: Credentials data type\nMatchedGrantTarget\nThe S3 URI path of the data to which you are being granted temporary access credentials.\nAmazon S3 Control API Version 2006-03-01 945Amazon Simple Storage Service API Reference\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 2000.\nPattern: ^.+$\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 946Amazon Simple Storage Service API Reference\nGetJobTagging\nService: Amazon S3 Control\nReturns the tags on an S3 Batch Operations job.\nPermissions\nTo use the GetJobTagging  operation, you must have permission to perform the\ns3:GetJobTagging  action. For more information, see Controlling access and labeling jobs \nusing tags  in the Amazon S3 User Guide .\nRelated actions include:\n\u2022CreateJob\n\u2022PutJobTagging\n\u2022DeleteJobTagging\nRequest Syntax\nGET /v20180820/jobs/ id/tagging HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nid\nThe ID for the S3 Batch Operations job whose tags you want to retrieve.\nLength Constraints: Minimum length of 5. Maximum length of 36.\nPattern: [a-zA-Z0-9\\-\\_]+\nRequired: Yes\nx-amz-account-id\nThe AWS account ID associated with the S3 Batch Operations job.\nLength Constraints: Maximum length of 64.\nAmazon S3 Control API Version 2006-03-01 947Amazon Simple Storage Service API Reference\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<GetJobTaggingResult > \n   <Tags> \n      <S3Tag> \n         < Key>string</Key> \n         < Value>string</Value> \n      </S3Tag> \n   </Tags>\n</GetJobTaggingResult >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nGetJobTaggingResult\nRoot level tag for the GetJobTaggingResult parameters.\nRequired: Yes\nTags\nThe set of tags associated with the S3 Batch Operations job.\nType: Array of S3Tag data types\nErrors\nInternalServiceException\nAmazon S3 Control API Version 2006-03-01 948Amazon Simple Storage Service API Reference\nHTTP Status Code: 500\nNotFoundException\nHTTP Status Code: 400\nTooManyRequestsException\nHTTP Status Code: 400\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 949Amazon Simple Storage Service API Reference\nGetMultiRegionAccessPoint\nService: Amazon S3 Control\nNote\nThis operation is not supported by directory buckets.\nReturns con\ufb01guration information about the speci\ufb01ed Multi-Region Access Point.\nThis action will always be routed to the US West (Oregon) Region. For more information about \nthe restrictions around working with Multi-Region Access Points, see Multi-Region Access Point \nrestrictions and limitations in the Amazon S3 User Guide .\nThe following actions are related to GetMultiRegionAccessPoint :\n\u2022CreateMultiRegionAccessPoint\n\u2022DeleteMultiRegionAccessPoint\n\u2022DescribeMultiRegionAccessPointOperation\n\u2022ListMultiRegionAccessPoints\nRequest Syntax\nGET /v20180820/mrap/instances/ name+ HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nname\nThe name of the Multi-Region Access Point whose con\ufb01guration information you want to \nreceive.", "The name of the Multi-Region Access Point is di\ufb00erent from the alias.", "For more \ninformation about the distinction between the name and the alias of an Multi-Region Access \nPoint, see Rules for naming Amazon S3 Multi-Region Access Points in the Amazon S3 User \nGuide .\nAmazon S3 Control API Version 2006-03-01 950Amazon Simple Storage Service API Reference\nLength Constraints: Maximum length of 50.\nPattern: ^[a-z0-9][-a-z0-9]{1,48}[a-z0-9]$\nRequired: Yes\nx-amz-account-id\nThe AWS account ID for the owner of the Multi-Region Access Point.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<GetMultiRegionAccessPointResult > \n   <AccessPoint > \n      <Alias>string</Alias> \n      <CreatedAt >timestamp </CreatedAt > \n      <Name>string</Name> \n      <PublicAccessBlock > \n         < BlockPublicAcls >boolean</BlockPublicAcls > \n         < BlockPublicPolicy >boolean</BlockPublicPolicy > \n         < IgnorePublicAcls >boolean</IgnorePublicAcls > \n         < RestrictPublicBuckets >boolean</RestrictPublicBuckets > \n      </ PublicAccessBlock > \n      <Regions> \n         <Region> \n            < Bucket>string</Bucket> \n            < BucketAccountId >string</BucketAccountId > \n            < Region>string</Region> \n         </Region> \n      </ Regions> \n      <Status>string</Status> \n   </AccessPoint >\nAmazon S3 Control API Version 2006-03-01 951Amazon Simple Storage Service API Reference\n</GetMultiRegionAccessPointResult >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nGetMultiRegionAccessPointResult\nRoot level tag for the GetMultiRegionAccessPointResult parameters.\nRequired: Yes\nAccessPoint\nA container element containing the details of the requested Multi-Region Access Point.\nType: MultiRegionAccessPointReport data type\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 952Amazon Simple Storage Service API Reference\nGetMultiRegionAccessPointPolicy\nService: Amazon S3 Control\nNote\nThis operation is not supported by directory buckets.\nReturns the access control policy of the speci\ufb01ed Multi-Region Access Point.\nThis action will always be routed to the US West (Oregon) Region. For more information about \nthe restrictions around working with Multi-Region Access Points, see Multi-Region Access Point \nrestrictions and limitations in the Amazon S3 User Guide .\nThe following actions are related to GetMultiRegionAccessPointPolicy :\n\u2022GetMultiRegionAccessPointPolicyStatus\n\u2022PutMultiRegionAccessPointPolicy\nRequest Syntax\nGET /v20180820/mrap/instances/ name+/policy HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nname\nSpeci\ufb01es the Multi-Region Access Point.", "The name of the Multi-Region Access Point is di\ufb00erent \nfrom the alias.", "For more information about the distinction between the name and the alias of \nan Multi-Region Access Point, see Rules for naming Amazon S3 Multi-Region Access Points in \nthe Amazon S3 User Guide .\nLength Constraints: Maximum length of 50.\nPattern: ^[a-z0-9][-a-z0-9]{1,48}[a-z0-9]$\nAmazon S3 Control API Version 2006-03-01 953Amazon Simple Storage Service API Reference\nRequired: Yes\nx-amz-account-id\nThe AWS account ID for the owner of the Multi-Region Access Point.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<GetMultiRegionAccessPointPolicyResult > \n   <Policy> \n      <Established > \n         < Policy>string</Policy> \n      </ Established > \n      <Proposed > \n         < Policy>string</Policy> \n      </ Proposed > \n   </Policy>\n</GetMultiRegionAccessPointPolicyResult >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nGetMultiRegionAccessPointPolicyResult\nRoot level tag for the GetMultiRegionAccessPointPolicyResult parameters.\nRequired: Yes\nAmazon S3 Control API Version 2006-03-01 954Amazon Simple Storage Service API Reference\nPolicy\nThe policy associated with the speci\ufb01ed Multi-Region Access Point.\nType: MultiRegionAccessPointPolicyDocument data type\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 955Amazon Simple Storage Service API Reference\nGetMultiRegionAccessPointPolicyStatus\nService: Amazon S3 Control\nNote\nThis operation is not supported by directory buckets.\nIndicates whether the speci\ufb01ed Multi-Region Access Point has an access control policy that allows \npublic access.\nThis action will always be routed to the US West (Oregon) Region. For more information about \nthe restrictions around working with Multi-Region Access Points, see Multi-Region Access Point \nrestrictions and limitations in the Amazon S3 User Guide .\nThe following actions are related to GetMultiRegionAccessPointPolicyStatus :\n\u2022GetMultiRegionAccessPointPolicy\n\u2022PutMultiRegionAccessPointPolicy\nRequest Syntax\nGET /v20180820/mrap/instances/ name+/policystatus HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nname\nSpeci\ufb01es the Multi-Region Access Point.", "The name of the Multi-Region Access Point is di\ufb00erent \nfrom the alias.", "For more information about the distinction between the name and the alias of \nan Multi-Region Access Point, see Rules for naming Amazon S3 Multi-Region Access Points in \nthe Amazon S3 User Guide .\nLength Constraints: Maximum length of 50.\nPattern: ^[a-z0-9][-a-z0-9]{1,48}[a-z0-9]$\nAmazon S3 Control API Version 2006-03-01 956Amazon Simple Storage Service API Reference\nRequired: Yes\nx-amz-account-id\nThe AWS account ID for the owner of the Multi-Region Access Point.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<GetMultiRegionAccessPointPolicyStatusResult > \n   <Established > \n      <IsPublic >boolean</IsPublic > \n   </Established >\n</GetMultiRegionAccessPointPolicyStatusResult >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nGetMultiRegionAccessPointPolicyStatusResult\nRoot level tag for the GetMultiRegionAccessPointPolicyStatusResult parameters.\nRequired: Yes\nEstablished\nIndicates whether this access point policy is public. For more information about how Amazon \nS3 evaluates policies to determine whether they are public, see The Meaning of \"Public\" in the\nAmazon S3 User Guide .\nAmazon S3 Control API Version 2006-03-01 957Amazon Simple Storage Service API Reference\nType: PolicyStatus data type\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 958Amazon Simple Storage Service API Reference\nGetMultiRegionAccessPointRoutes\nService: Amazon S3 Control\nNote\nThis operation is not supported by directory buckets.\nReturns the routing con\ufb01guration for a Multi-Region Access Point, indicating which Regions are \nactive or passive.\nTo obtain routing control changes and failover requests, use the Amazon S3 failover control \ninfrastructure endpoints in these \ufb01ve AWS Regions:\n\u2022us-east-1\n\u2022us-west-2\n\u2022ap-southeast-2\n\u2022ap-northeast-1\n\u2022eu-west-1\nRequest Syntax\nGET /v20180820/mrap/instances/ mrap+/routes HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nmrap\nThe Multi-Region Access Point ARN.\nLength Constraints: Maximum length of 200.\nPattern: ^[a-zA-Z0-9\\:.-]{3,200}$\nRequired: Yes\nAmazon S3 Control API Version 2006-03-01 959Amazon Simple Storage Service API Reference\nx-amz-account-id\nThe AWS account ID for the owner of the Multi-Region Access Point.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<GetMultiRegionAccessPointRoutesResult > \n   <Mrap>string</Mrap> \n   <Routes> \n      <Route> \n         < Bucket>string</Bucket> \n         < Region>string</Region> \n         < TrafficDialPercentage >integer</TrafficDialPercentage > \n      </Route> \n   </Routes>\n</GetMultiRegionAccessPointRoutesResult >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nGetMultiRegionAccessPointRoutesResult\nRoot level tag for the GetMultiRegionAccessPointRoutesResult parameters.\nRequired: Yes\nMrap\nThe Multi-Region Access Point ARN.\nAmazon S3 Control API Version 2006-03-01 960Amazon Simple Storage Service API Reference\nType: String\nLength Constraints: Maximum length of 200.\nPattern: ^[a-zA-Z0-9\\:.-]{3,200}$\nRoutes\nThe di\ufb00erent routes that make up the route con\ufb01guration. Active routes return a value of 100, \nand passive routes return a value of 0.\nType: Array of MultiRegionAccessPointRoute data types\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 961Amazon Simple Storage Service API Reference\nGetPublicAccessBlock\nService: Amazon S3 Control\nNote\nThis operation is not supported by directory buckets.\nRetrieves the PublicAccessBlock  con\ufb01guration for an AWS account. For more information, see \nUsing Amazon S3 block public access.\nRelated actions include:\n\u2022DeletePublicAccessBlock\n\u2022PutPublicAccessBlock\nRequest Syntax\nGET /v20180820/configuration/publicAccessBlock HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nx-amz-account-id\nThe account ID for the AWS account whose PublicAccessBlock  con\ufb01guration you want to \nretrieve.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nAmazon S3 Control API Version 2006-03-01 962Amazon Simple Storage Service API Reference\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<PublicAccessBlockConfiguration > \n   <BlockPublicAcls >boolean</BlockPublicAcls > \n   <IgnorePublicAcls >boolean</IgnorePublicAcls > \n   <BlockPublicPolicy >boolean</BlockPublicPolicy > \n   <RestrictPublicBuckets >boolean</RestrictPublicBuckets >\n</PublicAccessBlockConfiguration >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nPublicAccessBlockCon\ufb01guration\nRoot level tag for the PublicAccessBlockCon\ufb01guration parameters.\nRequired: Yes\nBlockPublicAcls\nSpeci\ufb01es whether Amazon S3 should block public access control lists (ACLs) for buckets in this \naccount. Setting this element to TRUE causes the following behavior:\n\u2022PutBucketAcl  and PutObjectAcl  calls fail if the speci\ufb01ed ACL is public.\n\u2022PUT Object calls fail if the request includes a public ACL.\n\u2022PUT Bucket calls fail if the request includes a public ACL.\nEnabling this setting doesn't a\ufb00ect existing policies or ACLs.\nThis property is not supported for Amazon S3 on Outposts.\nType: Boolean\nBlockPublicPolicy\nSpeci\ufb01es whether Amazon S3 should block public bucket policies for buckets in this account. \nSetting this element to TRUE causes Amazon S3 to reject calls to PUT Bucket policy if the \nspeci\ufb01ed bucket policy allows public access.\nAmazon S3 Control API Version 2006-03-01 963Amazon Simple Storage Service API Reference\nEnabling this setting doesn't a\ufb00ect existing bucket policies.\nThis property is not supported for Amazon S3 on Outposts.\nType: Boolean\nIgnorePublicAcls\nSpeci\ufb01es whether Amazon S3 should ignore public ACLs for buckets in this account. Setting this \nelement to TRUE causes Amazon S3 to ignore all public ACLs on buckets in this account and any \nobjects that they contain.\nEnabling this setting doesn't a\ufb00ect the persistence of any existing ACLs and doesn't prevent \nnew public ACLs from being set.\nThis property is not supported for Amazon S3 on Outposts.\nType: Boolean\nRestrictPublicBuckets\nSpeci\ufb01es whether Amazon S3 should restrict public bucket policies for buckets in this account. \nSetting this element to TRUE restricts access to buckets with public policies to only AWS service \nprincipals and authorized users within this account.\nEnabling this setting doesn't a\ufb00ect previously stored bucket policies, except that public and \ncross-account access within any public bucket policy, including non-public delegation to speci\ufb01c \naccounts, is blocked.\nThis property is not supported for Amazon S3 on Outposts.\nType: Boolean\nErrors\nNoSuchPublicAccessBlockCon\ufb01guration\nAmazon S3 throws this exception if you make a GetPublicAccessBlock  request against an \naccount that doesn't have a PublicAccessBlockConfiguration  set.\nHTTP Status Code: 404\nAmazon S3 Control API Version 2006-03-01 964Amazon Simple Storage Service API Reference\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 965Amazon Simple Storage Service API Reference\nGetStorageLensCon\ufb01guration\nService: Amazon S3 Control\nNote\nThis operation is not supported by directory buckets.\nGets the Amazon S3 Storage Lens con\ufb01guration. For more information, see Assessing your storage \nactivity and usage with Amazon S3 Storage Lens  in the Amazon S3 User Guide . For a complete list \nof S3 Storage Lens metrics, see S3 Storage Lens metrics glossary in the Amazon S3 User Guide .\nNote\nTo use this action, you must have permission to perform the\ns3:GetStorageLensConfiguration  action. For more information, see Setting \npermissions to use Amazon S3 Storage Lens in the Amazon S3 User Guide .\nRequest Syntax\nGET /v20180820/storagelens/ storagelensid  HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nstoragelensid\nThe ID of the Amazon S3 Storage Lens con\ufb01guration.\nLength Constraints: Minimum length of 1.", "Maximum length of 64.\nPattern: [a-zA-Z0-9\\-\\_\\.]+\nRequired: Yes\nx-amz-account-id\nThe account ID of the requester.\nAmazon S3 Control API Version 2006-03-01 966Amazon Simple Storage Service API Reference\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<StorageLensConfiguration > \n   <Id>string</Id> \n   <AccountLevel > \n      <ActivityMetrics > \n         < IsEnabled >boolean</IsEnabled > \n      </ ActivityMetrics > \n      <AdvancedCostOptimizationMetrics > \n         < IsEnabled >boolean</IsEnabled > \n      </ AdvancedCostOptimizationMetrics > \n      <AdvancedDataProtectionMetrics > \n         < IsEnabled >boolean</IsEnabled > \n      </ AdvancedDataProtectionMetrics > \n      <BucketLevel > \n         < ActivityMetrics > \n            < IsEnabled >boolean</IsEnabled > \n         </ ActivityMetrics > \n         < AdvancedCostOptimizationMetrics > \n            < IsEnabled >boolean</IsEnabled > \n         </ AdvancedCostOptimizationMetrics > \n         < AdvancedDataProtectionMetrics > \n            < IsEnabled >boolean</IsEnabled > \n         </ AdvancedDataProtectionMetrics > \n         < DetailedStatusCodesMetrics > \n            < IsEnabled >boolean</IsEnabled > \n         </ DetailedStatusCodesMetrics > \n         < PrefixLevel > \n            < StorageMetrics > \n               < IsEnabled >boolean</IsEnabled > \n               < SelectionCriteria > \nAmazon S3 Control API Version 2006-03-01 967Amazon Simple Storage Service API Reference\n                  < Delimiter >string</Delimiter > \n                  < MaxDepth >integer</MaxDepth > \n                  < MinStorageBytesPercentage >double</MinStorageBytesPercentage > \n               </ SelectionCriteria > \n            </ StorageMetrics > \n         </ PrefixLevel > \n      </ BucketLevel > \n      <DetailedStatusCodesMetrics > \n         < IsEnabled >boolean</IsEnabled > \n      </ DetailedStatusCodesMetrics > \n      <StorageLensGroupLevel > \n         < SelectionCriteria > \n            < Exclude> \n               <Arn> string</Arn> \n            </ Exclude> \n            < Include> \n               <Arn> string</Arn> \n            </ Include> \n         </ SelectionCriteria > \n      </ StorageLensGroupLevel > \n   </AccountLevel > \n   <Include> \n      <Buckets> \n         <Arn> string</Arn> \n      </ Buckets> \n      <Regions> \n         <Region> string</Region> \n      </ Regions> \n   </Include> \n   <Exclude> \n      <Buckets> \n         <Arn> string</Arn> \n      </ Buckets> \n      <Regions> \n         <Region> string</Region> \n      </ Regions> \n   </Exclude> \n   <DataExport > \n      <CloudWatchMetrics > \n         < IsEnabled >boolean</IsEnabled > \n      </ CloudWatchMetrics > \n      <S3BucketDestination > \n         < AccountId >string</AccountId > \n         < Arn>string</Arn> \nAmazon S3 Control API Version 2006-03-01 968Amazon Simple Storage Service API Reference\n         < Encryption > \n            < SSE-KMS> \n               < KeyId>string</KeyId> \n            </ SSE-KMS> \n            < SSE-S3> \n            </ SSE-S3> \n         </ Encryption > \n         < Format>string</Format> \n         < OutputSchemaVersion >string</OutputSchemaVersion > \n         < Prefix>string</Prefix> \n      </ S3BucketDestination > \n   </DataExport > \n   <IsEnabled >boolean</IsEnabled > \n   <AwsOrg> \n      <Arn>string</Arn> \n   </AwsOrg> \n   <StorageLensArn >string</StorageLensArn >\n</StorageLensConfiguration >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nStorageLensCon\ufb01guration\nRoot level tag for the StorageLensCon\ufb01guration parameters.\nRequired: Yes\nAccountLevel\nA container for all the account-level con\ufb01gurations of your S3 Storage Lens con\ufb01guration.\nType: AccountLevel data type\nAwsOrg\nA container for the AWS organization for this S3 Storage Lens con\ufb01guration.\nType: StorageLensAwsOrg data type\nAmazon S3 Control API Version 2006-03-01 969Amazon Simple Storage Service API Reference\nDataExport\nA container to specify the properties of your S3 Storage Lens metrics export including, the \ndestination, schema and format.\nType: StorageLensDataExport data type\nExclude\nA container for what is excluded in this con\ufb01guration.", "This container can only be valid if there is \nno Include container submitted, and it's not empty.\nType: Exclude data type\nId\nA container for the Amazon S3 Storage Lens con\ufb01guration ID.\nType: String\nLength Constraints: Minimum length of 1.", "Maximum length of 64.\nPattern: [a-zA-Z0-9\\-\\_\\.]+\nInclude\nA container for what is included in this con\ufb01guration.", "This container can only be valid if there is \nno Exclude container submitted, and it's not empty.\nType: Include  data type\nIsEnabled\nA container for whether the S3 Storage Lens con\ufb01guration is enabled.\nType: Boolean\nStorageLensArn\nThe Amazon Resource Name (ARN) of the S3 Storage Lens con\ufb01guration. This property is read-\nonly and follows the following format:  arn:aws:s3: us-east-1 :example-account-\nid:storage-lens/ your-dashboard-name\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 1024.\nAmazon S3 Control API Version 2006-03-01 970Amazon Simple Storage Service API Reference\nPattern: arn:[a-z\\-]+:s3:[a-z0-9\\-]+:\\d{12}:storage\\-lens\\/.*\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 971Amazon Simple Storage Service API Reference\nGetStorageLensCon\ufb01gurationTagging\nService: Amazon S3 Control\nNote\nThis operation is not supported by directory buckets.\nGets the tags of Amazon S3 Storage Lens con\ufb01guration. For more information about S3 Storage \nLens, see Assessing your storage activity and usage with Amazon S3 Storage Lens  in the Amazon \nS3 User Guide .\nNote\nTo use this action, you must have permission to perform the\ns3:GetStorageLensConfigurationTagging  action. For more information, see Setting \npermissions to use Amazon S3 Storage Lens in the Amazon S3 User Guide .\nRequest Syntax\nGET /v20180820/storagelens/ storagelensid /tagging HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nstoragelensid\nThe ID of the Amazon S3 Storage Lens con\ufb01guration.\nLength Constraints: Minimum length of 1. Maximum length of 64.\nPattern: [a-zA-Z0-9\\-\\_\\.]+\nRequired: Yes\nx-amz-account-id\nThe account ID of the requester.\nAmazon S3 Control API Version 2006-03-01 972Amazon Simple Storage Service API Reference\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<GetStorageLensConfigurationTaggingResult > \n   <Tags> \n      <Tag> \n         < Key>string</Key> \n         < Value>string</Value> \n      </Tag> \n   </Tags>\n</GetStorageLensConfigurationTaggingResult >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nGetStorageLensCon\ufb01gurationTaggingResult\nRoot level tag for the GetStorageLensCon\ufb01gurationTaggingResult parameters.\nRequired: Yes\nTags\nThe tags of S3 Storage Lens con\ufb01guration requested.\nType: Array of StorageLensTag data types\nAmazon S3 Control API Version 2006-03-01 973Amazon Simple Storage Service API Reference\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 974Amazon Simple Storage Service API Reference\nGetStorageLensGroup\nService: Amazon S3 Control\nRetrieves the Storage Lens group con\ufb01guration details.\nTo use this operation, you must have the permission to perform the s3:GetStorageLensGroup\naction. For more information about the required Storage Lens Groups permissions, see Setting \naccount permissions to use S3 Storage Lens groups.\nFor information about Storage Lens groups errors, see List of Amazon S3 Storage Lens error codes.\nRequest Syntax\nGET /v20180820/storagelensgroup/ name HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nname\nThe name of the Storage Lens group that you're trying to retrieve the con\ufb01guration details for.\nLength Constraints: Minimum length of 1. Maximum length of 64.\nPattern: [a-zA-Z0-9\\-\\_]+\nRequired: Yes\nx-amz-account-id\nThe AWS account ID associated with the Storage Lens group that you're trying to retrieve the \ndetails for.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nAmazon S3 Control API Version 2006-03-01 975Amazon Simple Storage Service API Reference\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<StorageLensGroup > \n   <Name>string</Name> \n   <Filter> \n      <And> \n         < MatchAnyPrefix > \n            <Prefix> string</Prefix> \n         </ MatchAnyPrefix > \n         < MatchAnySuffix > \n            <Suffix> string</Suffix> \n         </ MatchAnySuffix > \n         < MatchAnyTag > \n            <Tag> \n               < Key>string</Key> \n               < Value>string</Value> \n            </Tag> \n         </ MatchAnyTag > \n         < MatchObjectAge > \n            < DaysGreaterThan >integer</DaysGreaterThan > \n            < DaysLessThan >integer</DaysLessThan > \n         </ MatchObjectAge > \n         < MatchObjectSize > \n            < BytesGreaterThan >long</BytesGreaterThan > \n            < BytesLessThan >long</BytesLessThan > \n         </ MatchObjectSize > \n      </ And> \n      <MatchAnyPrefix > \n         <Prefix> string</Prefix> \n      </ MatchAnyPrefix > \n      <MatchAnySuffix > \n         <Suffix> string</Suffix> \n      </ MatchAnySuffix > \n      <MatchAnyTag > \n         <Tag> \n            < Key>string</Key> \n            < Value>string</Value> \n         </Tag> \nAmazon S3 Control API Version 2006-03-01 976Amazon Simple Storage Service API Reference\n      </ MatchAnyTag > \n      <MatchObjectAge > \n         < DaysGreaterThan >integer</DaysGreaterThan > \n         < DaysLessThan >integer</DaysLessThan > \n      </ MatchObjectAge > \n      <MatchObjectSize > \n         < BytesGreaterThan >long</BytesGreaterThan > \n         < BytesLessThan >long</BytesLessThan > \n      </ MatchObjectSize > \n      <Or> \n         < MatchAnyPrefix > \n            <Prefix> string</Prefix> \n         </ MatchAnyPrefix > \n         < MatchAnySuffix > \n            <Suffix> string</Suffix> \n         </ MatchAnySuffix > \n         < MatchAnyTag > \n            <Tag> \n               < Key>string</Key> \n               < Value>string</Value> \n            </Tag> \n         </ MatchAnyTag > \n         < MatchObjectAge > \n            < DaysGreaterThan >integer</DaysGreaterThan > \n            < DaysLessThan >integer</DaysLessThan > \n         </ MatchObjectAge > \n         < MatchObjectSize > \n            < BytesGreaterThan >long</BytesGreaterThan > \n            < BytesLessThan >long</BytesLessThan > \n         </ MatchObjectSize > \n      </ Or> \n   </Filter> \n   <StorageLensGroupArn >string</StorageLensGroupArn >\n</StorageLensGroup >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nStorageLensGroup\nRoot level tag for the StorageLensGroup parameters.\nAmazon S3 Control API Version 2006-03-01 977Amazon Simple Storage Service API Reference\nRequired: Yes\nFilter\nSets the criteria for the Storage Lens group data that is displayed.", "For multiple \ufb01lter conditions, \nthe AND or OR logical operator is used.\nType: StorageLensGroupFilter data type\nName\nContains the name of the Storage Lens group.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 64.\nPattern: [a-zA-Z0-9\\-\\_]+\nStorageLensGroupArn\nContains the Amazon Resource Name (ARN) of the Storage Lens group.", "This property is read-\nonly.\nType: String\nLength Constraints: Minimum length of 4.", "Maximum length of 1024.\nPattern: arn:[a-z\\-]+:s3:[a-z0-9\\-]+:\\d{12}:storage\\-lens\\-group\\/.*\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\nAmazon S3 Control API Version 2006-03-01 978Amazon Simple Storage Service API Reference\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 979Amazon Simple Storage Service API Reference\nListAccessGrants\nService: Amazon S3 Control\nReturns the list of access grants in your S3 Access Grants instance.\nPermissions\nYou must have the s3:ListAccessGrants  permission to use this operation.\nRequest Syntax\nGET /v20180820/accessgrantsinstance/grants?\napplication_arn= ApplicationArn &granteeidentifier= GranteeIdentifier &granteetype= GranteeType &grantscope= GrantScope &maxResults= MaxResults &nextToken= NextToken &permission= Permission\n HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\napplication_arn\nThe Amazon Resource Name (ARN) of an AWS IAM Identity Center application associated with \nyour Identity Center instance. If the grant includes an application ARN, the grantee can only \naccess the S3 data through this application.\nLength Constraints: Minimum length of 10.", "Maximum length of 1224.\nPattern: arn:[^:]+:sso::\\d{12}:application/.*$\ngranteeidenti\ufb01er\nThe unique identifer of the Grantee.", "If the grantee type is IAM, the identi\ufb01er is the \nIAM Amazon Resource Name (ARN) of the user or role.", "If the grantee type is a directory \nuser or group, the identi\ufb01er is 128-bit universally unique identi\ufb01er (UUID) in the format\na1b2c3d4-5678-90ab-cdef-EXAMPLE11111 .", "You can obtain this UUID from your AWS IAM \nIdentity Center instance.\ngranteetype\nThe type of the grantee to which access has been granted.", "It can be one of the following values:\nAmazon S3 Control API Version 2006-03-01 980Amazon Simple Storage Service API Reference\n\u2022IAM - An IAM user or role.\n\u2022DIRECTORY_USER  - Your corporate directory user. You can use this option if you have added \nyour corporate identity directory to IAM Identity Center and associated the IAM Identity \nCenter instance with your S3 Access Grants instance.\n\u2022DIRECTORY_GROUP  - Your corporate directory group. You can use this option if you have \nadded your corporate identity directory to IAM Identity Center and associated the IAM \nIdentity Center instance with your S3 Access Grants instance.\nValid Values: DIRECTORY_USER | DIRECTORY_GROUP | IAM\ngrantscope\nThe S3 path of the data to which you are granting access.", "It is the result of appending the\nSubprefix  to the location scope.\nLength Constraints: Minimum length of 1.", "Maximum length of 2000.\nPattern: ^.+$\nmaxResults\nThe maximum number of access grants that you would like returned in the List Access \nGrants response.", "If the results include the pagination token NextToken , make another call \nusing the NextToken  to determine if there are more results.\nValid Range: Minimum value of 0. Maximum value of 1000.\nnextToken\nA pagination token to request the next page of results.", "Pass this value into a subsequent List \nAccess Grants  request in order to retrieve the next page of results.\npermission\nThe type of permission granted to your S3 data, which can be set to one of the following \nvalues:\n\u2022READ \u2013 Grant read-only access to the S3 data.\n\u2022WRITE \u2013 Grant write-only access to the S3 data.\n\u2022READWRITE  \u2013 Grant both read and write access to the S3 data.\nValid Values: READ | WRITE | READWRITE\nAmazon S3 Control API Version 2006-03-01 981Amazon Simple Storage Service API Reference\nx-amz-account-id\nThe AWS account ID of the S3 Access Grants instance.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<ListAccessGrantsResult > \n   <NextToken >string</NextToken > \n   <AccessGrantsList > \n      <AccessGrant> \n         < AccessGrantArn >string</AccessGrantArn > \n         < AccessGrantId >string</AccessGrantId > \n         < AccessGrantsLocationConfiguration > \n            < S3SubPrefix >string</S3SubPrefix > \n         </ AccessGrantsLocationConfiguration > \n         < AccessGrantsLocationId >string</AccessGrantsLocationId > \n         < ApplicationArn >string</ApplicationArn > \n         < CreatedAt >timestamp </CreatedAt > \n         < Grantee> \n            < GranteeIdentifier >string</GranteeIdentifier > \n            < GranteeType >string</GranteeType > \n         </ Grantee> \n         < GrantScope >string</GrantScope > \n         < Permission >string</Permission > \n      </AccessGrant> \n   </AccessGrantsList >\n</ListAccessGrantsResult >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nAmazon S3 Control API Version 2006-03-01 982Amazon Simple Storage Service API Reference\nThe following data is returned in XML format by the service.\nListAccessGrantsResult\nRoot level tag for the ListAccessGrantsResult parameters.\nRequired: Yes\nAccessGrantsList\nA container for a list of grants in an S3 Access Grants instance.\nType: Array of ListAccessGrantEntry data types\nNextToken\nA pagination token to request the next page of results. Pass this value into a subsequent List \nAccess Grants  request in order to retrieve the next page of results.\nType: String\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 983Amazon Simple Storage Service API Reference\nListAccessGrantsInstances\nService: Amazon S3 Control\nReturns a list of S3 Access Grants instances. An S3 Access Grants instance serves as a logical \ngrouping for your individual access grants. You can only have one S3 Access Grants instance per \nRegion per account.\nPermissions\nYou must have the s3:ListAccessGrantsInstances  permission to use this operation.\nRequest Syntax\nGET /v20180820/accessgrantsinstances?maxResults= MaxResults &nextToken= NextToken  HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nmaxResults\nThe maximum number of access grants that you would like returned in the List Access \nGrants response.", "If the results include the pagination token NextToken , make another call \nusing the NextToken  to determine if there are more results.\nValid Range: Minimum value of 0. Maximum value of 1000.\nnextToken\nA pagination token to request the next page of results.", "Pass this value into a subsequent List \nAccess Grants Instances  request in order to retrieve the next page of results.\nx-amz-account-id\nThe AWS account ID of the S3 Access Grants instance.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nAmazon S3 Control API Version 2006-03-01 984Amazon Simple Storage Service API Reference\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<ListAccessGrantsInstancesResult > \n   <NextToken >string</NextToken > \n   <AccessGrantsInstancesList > \n      <AccessGrantsInstance> \n         < AccessGrantsInstanceArn >string</AccessGrantsInstanceArn > \n         < AccessGrantsInstanceId >string</AccessGrantsInstanceId > \n         < CreatedAt >timestamp </CreatedAt > \n         < IdentityCenterApplicationArn >string</IdentityCenterApplicationArn > \n         < IdentityCenterArn >string</IdentityCenterArn > \n         < IdentityCenterInstanceArn >string</IdentityCenterInstanceArn > \n      </AccessGrantsInstance> \n   </AccessGrantsInstancesList >\n</ListAccessGrantsInstancesResult >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nListAccessGrantsInstancesResult\nRoot level tag for the ListAccessGrantsInstancesResult parameters.\nRequired: Yes\nAccessGrantsInstancesList\nA container for a list of S3 Access Grants instances.\nType: Array of ListAccessGrantsInstanceEntry data types\nNextToken\nA pagination token to request the next page of results. Pass this value into a subsequent List \nAccess Grants Instances  request in order to retrieve the next page of results.\nAmazon S3 Control API Version 2006-03-01 985Amazon Simple Storage Service API Reference\nType: String\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 986Amazon Simple Storage Service API Reference\nListAccessGrantsLocations\nService: Amazon S3 Control\nReturns a list of the locations registered in your S3 Access Grants instance.\nPermissions\nYou must have the s3:ListAccessGrantsLocations  permission to use this operation.\nRequest Syntax\nGET /v20180820/accessgrantsinstance/locations?\nlocationscope= LocationScope &maxResults= MaxResults &nextToken= NextToken  HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nlocationscope\nThe S3 path to the location that you are registering. The location scope can be the default S3 \nlocation s3://, the S3 path to a bucket s3://<bucket> , or the S3 path to a bucket and pre\ufb01x\ns3://<bucket>/<prefix> . A pre\ufb01x in S3 is a string of characters at the beginning of an \nobject key name used to organize the objects that you store in your S3 buckets.", "For example, \nobject key names that start with the engineering/  pre\ufb01x or object key names that start with \nthe marketing/campaigns/  pre\ufb01x.\nLength Constraints: Minimum length of 1.", "Maximum length of 2000.\nPattern: ^.+$\nmaxResults\nThe maximum number of access grants that you would like returned in the List Access \nGrants response.", "If the results include the pagination token NextToken , make another call \nusing the NextToken  to determine if there are more results.\nValid Range: Minimum value of 0.", "Maximum value of 1000.\nAmazon S3 Control API Version 2006-03-01 987Amazon Simple Storage Service API Reference\nnextToken\nA pagination token to request the next page of results. Pass this value into a subsequent List \nAccess Grants Locations  request in order to retrieve the next page of results.\nx-amz-account-id\nThe AWS account ID of the S3 Access Grants instance.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<ListAccessGrantsLocationsResult > \n   <NextToken >string</NextToken > \n   <AccessGrantsLocationsList > \n      <AccessGrantsLocation> \n         < AccessGrantsLocationArn >string</AccessGrantsLocationArn > \n         < AccessGrantsLocationId >string</AccessGrantsLocationId > \n         < CreatedAt >timestamp </CreatedAt > \n         < IAMRoleArn >string</IAMRoleArn > \n         < LocationScope >string</LocationScope > \n      </AccessGrantsLocation> \n   </AccessGrantsLocationsList >\n</ListAccessGrantsLocationsResult >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nAmazon S3 Control API Version 2006-03-01 988Amazon Simple Storage Service API Reference\nListAccessGrantsLocationsResult\nRoot level tag for the ListAccessGrantsLocationsResult parameters.\nRequired: Yes\nAccessGrantsLocationsList\nA container for a list of registered locations in an S3 Access Grants instance.\nType: Array of ListAccessGrantsLocationsEntry data types\nNextToken\nA pagination token to request the next page of results. Pass this value into a subsequent List \nAccess Grants Locations  request in order to retrieve the next page of results.\nType: String\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 989Amazon Simple Storage Service API Reference\nListAccessPoints\nService: Amazon S3 Control\nNote\nThis operation is not supported by directory buckets.\nReturns a list of the access points that are owned by the current account that's associated with \nthe speci\ufb01ed bucket.", "You can retrieve up to 1000 access points per call.", "If the speci\ufb01ed bucket has \nmore than 1,000 access points (or the number speci\ufb01ed in maxResults , whichever is less), the \nresponse will include a continuation token that you can use to list the additional access points.\nAll Amazon S3 on Outposts REST API requests for this action require an additional parameter of\nx-amz-outpost-id  to be passed with the request. In addition, you must use an S3 on Outposts \nendpoint hostname pre\ufb01x instead of s3-control . For an example of the request syntax for \nAmazon S3 on Outposts that uses the S3 on Outposts endpoint hostname pre\ufb01x and the x-amz-\noutpost-id  derived by using the access point ARN, see the Examples  section.\nThe following actions are related to ListAccessPoints :\n\u2022CreateAccessPoint\n\u2022DeleteAccessPoint\n\u2022GetAccessPoint\nRequest Syntax\nGET /v20180820/accesspoint?bucket= Bucket&maxResults= MaxResults &nextToken= NextToken\n HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nbucket\nThe name of the bucket whose associated access points you want to list.\nAmazon S3 Control API Version 2006-03-01 990Amazon Simple Storage Service API Reference\nFor using this parameter with Amazon S3 on Outposts with the REST API, you must specify the \nname and the x-amz-outpost-id as well.\nFor using this parameter with S3 on Outposts with the AWS SDK and CLI, you must specify the \nARN of the bucket accessed in the format arn:aws:s3-outposts:<Region>:<account-\nid>:outpost/<outpost-id>/bucket/<my-bucket-name> . For example, to access \nthe bucket reports through Outpost my-outpost  owned by account 123456789012\nin Region us-west-2 , use the URL encoding of arn:aws:s3-outposts:us-\nwest-2:123456789012:outpost/my-outpost/bucket/reports .", "The value must be URL \nencoded.\nLength Constraints: Minimum length of 3.", "Maximum length of 255.\nmaxResults\nThe maximum number of access points that you want to include in the list. If the speci\ufb01ed \nbucket has more than this number of access points, then the response will include a \ncontinuation token in the NextToken  \ufb01eld that you can use to retrieve the next page of access \npoints.\nValid Range: Minimum value of 0.", "Maximum value of 1000.\nnextToken\nA continuation token.", "If a previous call to ListAccessPoints  returned a continuation token \nin the NextToken  \ufb01eld, then providing that value here causes Amazon S3 to retrieve the next \npage of results.\nLength Constraints: Minimum length of 1. Maximum length of 1024.\nx-amz-account-id\nThe AWS account ID for the account that owns the speci\ufb01ed access points.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nAmazon S3 Control API Version 2006-03-01 991Amazon Simple Storage Service API Reference\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<ListAccessPointsResult > \n   <AccessPointList > \n      <AccessPoint> \n         < AccessPointArn >string</AccessPointArn > \n         < Alias>string</Alias> \n         < Bucket>string</Bucket> \n         < BucketAccountId >string</BucketAccountId > \n         < Name>string</Name> \n         < NetworkOrigin >string</NetworkOrigin > \n         < VpcConfiguration > \n            < VpcId>string</VpcId> \n         </ VpcConfiguration > \n      </AccessPoint> \n   </AccessPointList > \n   <NextToken >string</NextToken >\n</ListAccessPointsResult >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nListAccessPointsResult\nRoot level tag for the ListAccessPointsResult parameters.\nRequired: Yes\nAccessPointList\nContains identi\ufb01cation and con\ufb01guration information for one or more access points associated \nwith the speci\ufb01ed bucket.\nType: Array of AccessPoint data types\nNextToken\nIf the speci\ufb01ed bucket has more access points than can be returned in one call to this API, \nthis \ufb01eld contains a continuation token that you can provide in subsequent calls to this API to \nretrieve additional access points.\nAmazon S3 Control API Version 2006-03-01 992Amazon Simple Storage Service API Reference\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 1024.\nExamples\nSample request syntax for ListAccessPoints for Amazon S3 on Outposts\nThe following request returns a list access points of the speci\ufb01ed Amazon S3 on Outposts bucket\nexample-outpost-bucket .\n           GET /v20180820/accesspoint?Bucket=example-outpost-\nbucket&MaxResults=MaxResults&NextToken=NextToken HTTP/1.1 \n           Host: s3-outposts.<Region>.amazonaws.com \n           Date: Wed, 28 Oct 2020 22:32:00 GMT \n           Authorization: authorization string \n           x-amz-account-id: example-account-id \n           x-amz-outpost-id: op-01ac5d28a6a232904 \n          \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 993Amazon Simple Storage Service API Reference\nListAccessPointsForObjectLambda\nService: Amazon S3 Control\nNote\nThis operation is not supported by directory buckets.\nReturns some or all (up to 1,000) access points associated with the Object Lambda Access Point per \ncall. If there are more access points than what can be returned in one call, the response will include \na continuation token that you can use to list the additional access points.\nThe following actions are related to ListAccessPointsForObjectLambda :\n\u2022CreateAccessPointForObjectLambda\n\u2022DeleteAccessPointForObjectLambda\n\u2022GetAccessPointForObjectLambda\nRequest Syntax\nGET /v20180820/accesspointforobjectlambda?maxResults= MaxResults &nextToken= NextToken\n HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nmaxResults\nThe maximum number of access points that you want to include in the list.", "The response may \ncontain fewer access points but will never contain more. If there are more than this number of \naccess points, then the response will include a continuation token in the NextToken  \ufb01eld that \nyou can use to retrieve the next page of access points.\nValid Range: Minimum value of 0.", "Maximum value of 1000.\nAmazon S3 Control API Version 2006-03-01 994Amazon Simple Storage Service API Reference\nnextToken\nIf the list has more access points than can be returned in one call to this API, this \ufb01eld contains \na continuation token that you can provide in subsequent calls to this API to retrieve additional \naccess points.\nLength Constraints: Minimum length of 1. Maximum length of 1024.\nx-amz-account-id\nThe account ID for the account that owns the speci\ufb01ed Object Lambda Access Point.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<ListAccessPointsForObjectLambdaResult > \n   <ObjectLambdaAccessPointList > \n      <ObjectLambdaAccessPoint> \n         < Alias> \n            < Status>string</Status> \n            < Value>string</Value> \n         </ Alias> \n         < Name>string</Name> \n         < ObjectLambdaAccessPointArn >string</ObjectLambdaAccessPointArn > \n      </ObjectLambdaAccessPoint> \n   </ObjectLambdaAccessPointList > \n   <NextToken >string</NextToken >\n</ListAccessPointsForObjectLambdaResult >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nAmazon S3 Control API Version 2006-03-01 995Amazon Simple Storage Service API Reference\nThe following data is returned in XML format by the service.\nListAccessPointsForObjectLambdaResult\nRoot level tag for the ListAccessPointsForObjectLambdaResult parameters.\nRequired: Yes\nNextToken\nIf the list has more access points than can be returned in one call to this API, this \ufb01eld contains \na continuation token that you can provide in subsequent calls to this API to retrieve additional \naccess points.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 1024.\nObjectLambdaAccessPointList\nReturns list of Object Lambda Access Points.\nType: Array of ObjectLambdaAccessPoint data types\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 996Amazon Simple Storage Service API Reference\nListCallerAccessGrants\nService: Amazon S3 Control\nUse this API to list the access grants that grant the caller access to Amazon S3 data through S3 \nAccess Grants.", "The caller (grantee) can be an AWS Identity and Access Management (IAM) identity \nor AWS Identity Center corporate directory identity.", "You must pass the AWS account of the S3 \ndata owner (grantor) in the request. You can, optionally, narrow the results by GrantScope , using \na fragment of the data's S3 path, and S3 Access Grants will return only the grants with a path \nthat contains the path fragment.", "You can also pass the AllowedByApplication  \ufb01lter in the \nrequest, which returns only the grants authorized for applications, whether the application is the \ncaller's Identity Center application or any other application (ALL).", "For more information, see List \nthe caller's access grants in the Amazon S3 User Guide .\nPermissions\nYou must have the s3:ListCallerAccessGrants  permission to use this operation.\nRequest Syntax\nGET /v20180820/accessgrantsinstance/caller/grants?\nallowedByApplication= AllowedByApplication &grantscope= GrantScope &maxResults= MaxResults &nextToken= NextToken\n HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nallowedByApplication\nIf this optional parameter is passed in the request, a \ufb01lter is applied to the results. The results \nwill include only the access grants for the caller's Identity Center application or for any other \napplications ( ALL).\ngrantscope\nThe S3 path of the data that you would like to access. Must start with s3://. You can \noptionally pass only the beginning characters of a path, and S3 Access Grants will search for all \napplicable grants for the path fragment.\nAmazon S3 Control API Version 2006-03-01 997Amazon Simple Storage Service API Reference\nLength Constraints: Minimum length of 1.", "Maximum length of 2000.\nPattern: ^.+$\nmaxResults\nThe maximum number of access grants that you would like returned in the List Caller \nAccess Grants  response.", "If the results include the pagination token NextToken , make \nanother call using the NextToken  to determine if there are more results.\nValid Range: Minimum value of 0. Maximum value of 1000.\nnextToken\nA pagination token to request the next page of results.", "Pass this value into a subsequent List \nCaller Access Grants  request in order to retrieve the next page of results.\nx-amz-account-id\nThe AWS account ID of the S3 Access Grants instance.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<ListCallerAccessGrantsResult > \n   <NextToken >string</NextToken > \n   <CallerAccessGrantsList > \n      <AccessGrant> \n         < ApplicationArn >string</ApplicationArn > \n         < GrantScope >string</GrantScope > \n         < Permission >string</Permission > \n      </AccessGrant> \n   </CallerAccessGrantsList >\nAmazon S3 Control API Version 2006-03-01 998Amazon Simple Storage Service API Reference\n</ListCallerAccessGrantsResult >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nListCallerAccessGrantsResult\nRoot level tag for the ListCallerAccessGrantsResult parameters.\nRequired: Yes\nCallerAccessGrantsList\nA list of the caller's access grants that were created using S3 Access Grants and that grant the \ncaller access to the S3 data of the AWS account ID that was speci\ufb01ed in the request.\nType: Array of ListCallerAccessGrantsEntry data types\nNextToken\nA pagination token that you can use to request the next page of results. Pass this value into \na subsequent List Caller Access Grants  request in order to retrieve the next page of \nresults.\nType: String\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\nAmazon S3 Control API Version 2006-03-01 999Amazon Simple Storage Service API Reference\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1000Amazon Simple Storage Service API Reference\nListJobs\nService: Amazon S3 Control\nLists current S3 Batch Operations jobs as well as the jobs that have ended within the last 90 days \nfor the AWS account making the request. For more information, see S3 Batch Operations  in the\nAmazon S3 User Guide .\nPermissions\nTo use the ListJobs  operation, you must have permission to perform the s3:ListJobs\naction.\nRelated actions include:\n\u2022CreateJob\n\u2022DescribeJob\n\u2022UpdateJobPriority\n\u2022UpdateJobStatus\nRequest Syntax\nGET /v20180820/jobs?jobStatuses= JobStatuses &maxResults= MaxResults &nextToken= NextToken\n HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\njobStatuses\nThe List Jobs  request returns jobs that match the statuses listed in this element.\nValid Values: Active | Cancelled | Cancelling | Complete | Completing \n| Failed | Failing | New | Paused | Pausing | Preparing | Ready | \nSuspended\nAmazon S3 Control API Version 2006-03-01 1001Amazon Simple Storage Service API Reference\nmaxResults\nThe maximum number of jobs that Amazon S3 will include in the List Jobs  response.", "If there \nare more jobs than this number, the response will include a pagination token in the NextToken\n\ufb01eld to enable you to retrieve the next page of results.\nValid Range: Minimum value of 0.", "Maximum value of 1000.\nnextToken\nA pagination token to request the next page of results.", "Use the token that Amazon S3 returned \nin the NextToken  element of the ListJobsResult  from the previous List Jobs  request.\nLength Constraints: Minimum length of 1. Maximum length of 1024.\nPattern: ^[A-Za-z0-9\\+\\:\\/\\=\\?\\#-_]+$\nx-amz-account-id\nThe AWS account ID associated with the S3 Batch Operations job.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<ListJobsResult > \n   <NextToken >string</NextToken > \n   <Jobs> \n      <JobListDescriptor> \n         < CreationTime >timestamp </CreationTime > \n         < Description >string</Description > \n         < JobId>string</JobId> \nAmazon S3 Control API Version 2006-03-01 1002Amazon Simple Storage Service API Reference\n         < Operation >string</Operation > \n         < Priority >integer</Priority > \n         < ProgressSummary > \n            < NumberOfTasksFailed >long</NumberOfTasksFailed > \n            < NumberOfTasksSucceeded >long</NumberOfTasksSucceeded > \n            < Timers> \n               < ElapsedTimeInActiveSeconds >long</ElapsedTimeInActiveSeconds > \n            </ Timers> \n            < TotalNumberOfTasks >long</TotalNumberOfTasks > \n         </ ProgressSummary > \n         < Status>string</Status> \n         < TerminationDate >timestamp </TerminationDate > \n      </JobListDescriptor> \n   </Jobs>\n</ListJobsResult >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nListJobsResult\nRoot level tag for the ListJobsResult parameters.\nRequired: Yes\nJobs\nThe list of current jobs and jobs that have ended within the last 30 days.\nType: Array of JobListDescriptor  data types\nNextToken\nIf the List Jobs  request produced more than the maximum number of results, you can pass \nthis value into a subsequent List Jobs  request in order to retrieve the next page of results.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 1024.\nPattern: ^[A-Za-z0-9\\+\\:\\/\\=\\?\\#-_]+$\nAmazon S3 Control API Version 2006-03-01 1003Amazon Simple Storage Service API Reference\nErrors\nInternalServiceException\nHTTP Status Code: 500\nInvalidNextTokenException\nHTTP Status Code: 400\nInvalidRequestException\nHTTP Status Code: 400\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1004Amazon Simple Storage Service API Reference\nListMultiRegionAccessPoints\nService: Amazon S3 Control\nNote\nThis operation is not supported by directory buckets.\nReturns a list of the Multi-Region Access Points currently associated with the speci\ufb01ed AWS \naccount.", "Each call can return up to 100 Multi-Region Access Points, the maximum number of Multi-\nRegion Access Points that can be associated with a single account.\nThis action will always be routed to the US West (Oregon) Region.", "For more information about \nthe restrictions around working with Multi-Region Access Points, see Multi-Region Access Point \nrestrictions and limitations in the Amazon S3 User Guide .\nThe following actions are related to ListMultiRegionAccessPoint :\n\u2022CreateMultiRegionAccessPoint\n\u2022DeleteMultiRegionAccessPoint\n\u2022DescribeMultiRegionAccessPointOperation\n\u2022GetMultiRegionAccessPoint\nRequest Syntax\nGET /v20180820/mrap/instances?maxResults= MaxResults &nextToken= NextToken  HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nmaxResults\nNot currently used.", "Do not use this parameter.\nValid Range: Minimum value of 0.", "Maximum value of 1000.\nAmazon S3 Control API Version 2006-03-01 1005Amazon Simple Storage Service API Reference\nnextToken\nNot currently used.", "Do not use this parameter.\nLength Constraints: Minimum length of 1. Maximum length of 1024.\nx-amz-account-id\nThe AWS account ID for the owner of the Multi-Region Access Point.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<ListMultiRegionAccessPointsResult > \n   <AccessPoints > \n      <AccessPoint> \n         < Alias>string</Alias> \n         < CreatedAt >timestamp </CreatedAt > \n         < Name>string</Name> \n         < PublicAccessBlock > \n            < BlockPublicAcls >boolean</BlockPublicAcls > \n            < BlockPublicPolicy >boolean</BlockPublicPolicy > \n            < IgnorePublicAcls >boolean</IgnorePublicAcls > \n            < RestrictPublicBuckets >boolean</RestrictPublicBuckets > \n         </ PublicAccessBlock > \n         < Regions> \n            <Region> \n               < Bucket>string</Bucket> \n               < BucketAccountId >string</BucketAccountId > \n               < Region>string</Region> \n            </Region> \n         </ Regions> \n         < Status>string</Status> \nAmazon S3 Control API Version 2006-03-01 1006Amazon Simple Storage Service API Reference\n      </AccessPoint> \n   </AccessPoints > \n   <NextToken >string</NextToken >\n</ListMultiRegionAccessPointsResult >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nListMultiRegionAccessPointsResult\nRoot level tag for the ListMultiRegionAccessPointsResult parameters.\nRequired: Yes\nAccessPoints\nThe list of Multi-Region Access Points associated with the user.\nType: Array of MultiRegionAccessPointReport data types\nNextToken\nIf the speci\ufb01ed bucket has more Multi-Region Access Points than can be returned in one call to \nthis action, this \ufb01eld contains a continuation token. You can use this token tin subsequent calls \nto this action to retrieve additional Multi-Region Access Points.\nType: String\nLength Constraints: Minimum length of 1.", "Maximum length of 1024.\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\nAmazon S3 Control API Version 2006-03-01 1007Amazon Simple Storage Service API Reference\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1008Amazon Simple Storage Service API Reference\nListRegionalBuckets\nService: Amazon S3 Control\nNote\nThis operation is not supported by directory buckets.\nReturns a list of all Outposts buckets in an Outpost that are owned by the authenticated sender of \nthe request. For more information, see Using Amazon S3 on Outposts in the Amazon S3 User Guide .\nFor an example of the request syntax for Amazon S3 on Outposts that uses the S3 on Outposts \nendpoint hostname pre\ufb01x and x-amz-outpost-id  in your request, see the Examples  section.\nRequest Syntax\nGET /v20180820/bucket?maxResults= MaxResults &nextToken= NextToken  HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nx-amz-outpost-id: OutpostId\nURI Request Parameters\nThe request uses the following URI parameters.\nmaxResults\nValid Range: Minimum value of 0.", "Maximum value of 1000.\nnextToken\nLength Constraints: Minimum length of 1.", "Maximum length of 1024.\nx-amz-account-id\nThe AWS account ID of the Outposts bucket.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nAmazon S3 Control API Version 2006-03-01 1009Amazon Simple Storage Service API Reference\nx-amz-outpost-id\nThe ID of the AWS Outposts resource.\nNote\nThis ID is required by Amazon S3 on Outposts buckets.\nLength Constraints: Minimum length of 1. Maximum length of 64.\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<ListRegionalBucketsResult > \n   <RegionalBucketList > \n      <RegionalBucket> \n         < Bucket>string</Bucket> \n         < BucketArn >string</BucketArn > \n         < CreationDate >timestamp </CreationDate > \n         < OutpostId >string</OutpostId > \n         < PublicAccessBlockEnabled >boolean</PublicAccessBlockEnabled > \n      </RegionalBucket> \n   </RegionalBucketList > \n   <NextToken >string</NextToken >\n</ListRegionalBucketsResult >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nListRegionalBucketsResult\nRoot level tag for the ListRegionalBucketsResult parameters.\nAmazon S3 Control API Version 2006-03-01 1010Amazon Simple Storage Service API Reference\nRequired: Yes\nNextToken\nNextToken  is sent when isTruncated  is true, which means there are more buckets that \ncan be listed. The next list requests to Amazon S3 can be continued with this NextToken .\nNextToken  is obfuscated and is not a real key.\nType: String\nLength Constraints: Minimum length of 1.", "Maximum length of 1024.\nRegionalBucketList\nType: Array of RegionalBucket data types\nExamples\nSample request to list an account's Outposts buckets\nThis request lists regional buckets.\n            GET /v20180820/bucket HTTP /1.1             \n            Host:s3-outposts.us-west-2.amazonaws.com \n            Content-Length: 0 \n            x-amz-outpost-id: op-01ac5d28a6a232904 \n            x-amz-account-id: example-account-id \n            Date: Wed, 01 Mar  2006 12:00:00 GMT \n            Authorization: authorization string \n          \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\nAmazon S3 Control API Version 2006-03-01 1011Amazon Simple Storage Service API Reference\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1012Amazon Simple Storage Service API Reference\nListStorageLensCon\ufb01gurations\nService: Amazon S3 Control\nNote\nThis operation is not supported by directory buckets.\nGets a list of Amazon S3 Storage Lens con\ufb01gurations.", "For more information about S3 Storage Lens, \nsee Assessing your storage activity and usage with Amazon S3 Storage Lens  in the Amazon S3 User \nGuide .\nNote\nTo use this action, you must have permission to perform the\ns3:ListStorageLensConfigurations  action. For more information, see Setting \npermissions to use Amazon S3 Storage Lens in the Amazon S3 User Guide .\nRequest Syntax\nGET /v20180820/storagelens?nextToken= NextToken  HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nnextToken\nA pagination token to request the next page of results.\nx-amz-account-id\nThe account ID of the requester.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nAmazon S3 Control API Version 2006-03-01 1013Amazon Simple Storage Service API Reference\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<ListStorageLensConfigurationsResult > \n   <NextToken >string</NextToken > \n   <StorageLensConfigurationList > \n      <HomeRegion >string</HomeRegion > \n      <Id>string</Id> \n      <IsEnabled >boolean</IsEnabled > \n      <StorageLensArn >string</StorageLensArn > \n   </StorageLensConfigurationList > \n   ...\n</ListStorageLensConfigurationsResult >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nListStorageLensCon\ufb01gurationsResult\nRoot level tag for the ListStorageLensCon\ufb01gurationsResult parameters.\nRequired: Yes\nNextToken\nIf the request produced more than the maximum number of S3 Storage Lens con\ufb01guration \nresults, you can pass this value into a subsequent request to retrieve the next page of results.\nType: String\nStorageLensCon\ufb01gurationList\nA list of S3 Storage Lens con\ufb01gurations.\nAmazon S3 Control API Version 2006-03-01 1014Amazon Simple Storage Service API Reference\nType: Array of ListStorageLensCon\ufb01gurationEntry data types\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1015Amazon Simple Storage Service API Reference\nListStorageLensGroups\nService: Amazon S3 Control\nLists all the Storage Lens groups in the speci\ufb01ed home Region.\nTo use this operation, you must have the permission to perform the\ns3:ListStorageLensGroups  action. For more information about the required Storage Lens \nGroups permissions, see Setting account permissions to use S3 Storage Lens groups.\nFor information about Storage Lens groups errors, see List of Amazon S3 Storage Lens error codes.\nRequest Syntax\nGET /v20180820/storagelensgroup?nextToken= NextToken  HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nnextToken\nThe token for the next set of results, or null if there are no more results.\nx-amz-account-id\nThe AWS account ID that owns the Storage Lens groups.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\nAmazon S3 Control API Version 2006-03-01 1016Amazon Simple Storage Service API Reference\n<ListStorageLensGroupsResult > \n   <NextToken >string</NextToken > \n   <StorageLensGroupList > \n      <HomeRegion >string</HomeRegion > \n      <Name>string</Name> \n      <StorageLensGroupArn >string</StorageLensGroupArn > \n   </StorageLensGroupList > \n   ...\n</ListStorageLensGroupsResult >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nListStorageLensGroupsResult\nRoot level tag for the ListStorageLensGroupsResult parameters.\nRequired: Yes\nNextToken\nIf NextToken  is returned, there are more Storage Lens groups results available.", "The value of\nNextToken  is a unique pagination token for each page. Make the call again using the returned \ntoken to retrieve the next page.", "Keep all other arguments unchanged.", "Each pagination token \nexpires after 24 hours.\nType: String\nStorageLensGroupList\nThe list of Storage Lens groups that exist in the speci\ufb01ed home Region.\nType: Array of ListStorageLensGroupEntry data types\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\nAmazon S3 Control API Version 2006-03-01 1017Amazon Simple Storage Service API Reference\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1018Amazon Simple Storage Service API Reference\nListTagsForResource\nService: Amazon S3 Control\nThis operation allows you to list all the AWS resource tags for a speci\ufb01ed resource.", "Each tag is a \nlabel consisting of a user-de\ufb01ned key and value.", "Tags can help you manage, identify, organize, \nsearch for, and \ufb01lter resources.\nPermissions\nYou must have the s3:ListTagsForResource  permission to use this operation.\nNote\nThis operation is only supported for S3 Storage Lens groups and for S3 Access Grants. The \ntagged resource can be an S3 Storage Lens group or S3 Access Grants instance, registered \nlocation, or grant.\nFor more information about the required Storage Lens Groups permissions, see Setting account \npermissions to use S3 Storage Lens groups.\nFor information about S3 Tagging errors, see List of Amazon S3 Tagging error codes.\nRequest Syntax\nGET /v20180820/tags/ resourceArn+  HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nresourceArn\nThe Amazon Resource Name (ARN) of the S3 resource that you want to list the tags for. The \ntagged resource can be an S3 Storage Lens group or S3 Access Grants instance, registered \nlocation, or grant.\nLength Constraints: Maximum length of 1011.\nAmazon S3 Control API Version 2006-03-01 1019Amazon Simple Storage Service API Reference\nPattern: arn:[^:]+:s3:[^:].*\nRequired: Yes\nx-amz-account-id\nThe AWS account ID of the resource owner.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<ListTagsForResourceResult > \n   <Tags> \n      <Tag> \n         < Key>string</Key> \n         < Value>string</Value> \n      </Tag> \n   </Tags>\n</ListTagsForResourceResult >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nListTagsForResourceResult\nRoot level tag for the ListTagsForResourceResult parameters.\nRequired: Yes\nAmazon S3 Control API Version 2006-03-01 1020Amazon Simple Storage Service API Reference\nTags\nThe AWS resource tags that are associated with the resource.\nType: Array of Tag data types\nArray Members: Minimum number of 0 items. Maximum number of 50 items.\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1021Amazon Simple Storage Service API Reference\nPutAccessGrantsInstanceResourcePolicy\nService: Amazon S3 Control\nUpdates the resource policy of the S3 Access Grants instance.\nPermissions\nYou must have the s3:PutAccessGrantsInstanceResourcePolicy  permission to use this \noperation.\nRequest Syntax\nPUT /v20180820/accessgrantsinstance/resourcepolicy HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<PutAccessGrantsInstanceResourcePolicyRequest  xmlns=\"http://awss3control.amazonaws.com/\ndoc/2018-08-20/\"> \n   <Policy>string</Policy> \n   <Organization >string</Organization >\n</PutAccessGrantsInstanceResourcePolicyRequest >\nURI Request Parameters\nThe request uses the following URI parameters.\nx-amz-account-id\nThe AWS account ID of the S3 Access Grants instance.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request accepts the following data in XML format.\nAmazon S3 Control API Version 2006-03-01 1022Amazon Simple Storage Service API Reference\nPutAccessGrantsInstanceResourcePolicyRequest\nRoot level tag for the PutAccessGrantsInstanceResourcePolicyRequest parameters.\nRequired: Yes\nOrganization\nThe Organization of the resource policy of the S3 Access Grants instance.\nType: String\nLength Constraints: Minimum length of 12. Maximum length of 34.\nPattern: ^o-[a-z0-9]{10,32}$\nRequired: No\nPolicy\nThe resource policy of the S3 Access Grants instance that you are updating.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 350000.\nRequired: Yes\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<PutAccessGrantsInstanceResourcePolicyResult > \n   <Policy>string</Policy> \n   <Organization >string</Organization > \n   <CreatedAt >timestamp </CreatedAt >\n</PutAccessGrantsInstanceResourcePolicyResult >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nAmazon S3 Control API Version 2006-03-01 1023Amazon Simple Storage Service API Reference\nPutAccessGrantsInstanceResourcePolicyResult\nRoot level tag for the PutAccessGrantsInstanceResourcePolicyResult parameters.\nRequired: Yes\nCreatedAt\nThe date and time when you created the S3 Access Grants instance resource policy.\nType: Timestamp\nOrganization\nThe Organization of the resource policy of the S3 Access Grants instance.\nType: String\nLength Constraints: Minimum length of 12. Maximum length of 34.\nPattern: ^o-[a-z0-9]{10,32}$\nPolicy\nThe updated resource policy of the S3 Access Grants instance.\nType: String\nLength Constraints: Minimum length of 1.", "Maximum length of 350000.\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\nAmazon S3 Control API Version 2006-03-01 1024Amazon Simple Storage Service API Reference\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1025Amazon Simple Storage Service API Reference\nPutAccessPointCon\ufb01gurationForObjectLambda\nService: Amazon S3 Control\nNote\nThis operation is not supported by directory buckets.\nReplaces con\ufb01guration for an Object Lambda Access Point.\nThe following actions are related to PutAccessPointConfigurationForObjectLambda :\n\u2022GetAccessPointCon\ufb01gurationForObjectLambda\nRequest Syntax\nPUT /v20180820/accesspointforobjectlambda/ name/configuration HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<PutAccessPointConfigurationForObjectLambdaRequest  xmlns=\"http://\nawss3control.amazonaws.com/doc/2018-08-20/\"> \n   <Configuration > \n      <AllowedFeatures > \n         <AllowedFeature> string</AllowedFeature> \n      </ AllowedFeatures > \n      <CloudWatchMetricsEnabled >boolean</CloudWatchMetricsEnabled > \n      <SupportingAccessPoint >string</SupportingAccessPoint > \n      <TransformationConfigurations > \n         <TransformationConfiguration> \n            < Actions> \n               <Action> string</Action> \n            </ Actions> \n            < ContentTransformation > \n               < AwsLambda > \n                  < FunctionArn >string</FunctionArn > \n                  < FunctionPayload >string</FunctionPayload > \n               </ AwsLambda > \n            </ ContentTransformation > \n         </TransformationConfiguration> \n      </ TransformationConfigurations > \n   </Configuration >\nAmazon S3 Control API Version 2006-03-01 1026Amazon Simple Storage Service API Reference\n</PutAccessPointConfigurationForObjectLambdaRequest >\nURI Request Parameters\nThe request uses the following URI parameters.\nname\nThe name of the Object Lambda Access Point.\nLength Constraints: Minimum length of 3. Maximum length of 45.\nPattern: ^[a-z0-9]([a-z0-9\\-]*[a-z0-9])?$\nRequired: Yes\nx-amz-account-id\nThe account ID for the account that owns the speci\ufb01ed Object Lambda Access Point.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request accepts the following data in XML format.\nPutAccessPointCon\ufb01gurationForObjectLambdaRequest\nRoot level tag for the PutAccessPointCon\ufb01gurationForObjectLambdaRequest parameters.\nRequired: Yes\nCon\ufb01guration\nObject Lambda Access Point con\ufb01guration document.\nType: ObjectLambdaCon\ufb01guration data type\nRequired: Yes\nAmazon S3 Control API Version 2006-03-01 1027Amazon Simple Storage Service API Reference\nResponse Syntax\nHTTP/1.1 200\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1028Amazon Simple Storage Service API Reference\nPutAccessPointPolicy\nService: Amazon S3 Control\nNote\nThis operation is not supported by directory buckets.\nAssociates an access policy with the speci\ufb01ed access point.", "Each access point can have only one \npolicy, so a request made to this API replaces any existing policy associated with the speci\ufb01ed \naccess point.\nAll Amazon S3 on Outposts REST API requests for this action require an additional parameter of\nx-amz-outpost-id  to be passed with the request. In addition, you must use an S3 on Outposts \nendpoint hostname pre\ufb01x instead of s3-control . For an example of the request syntax for \nAmazon S3 on Outposts that uses the S3 on Outposts endpoint hostname pre\ufb01x and the x-amz-\noutpost-id  derived by using the access point ARN, see the Examples  section.\nThe following actions are related to PutAccessPointPolicy :\n\u2022GetAccessPointPolicy\n\u2022DeleteAccessPointPolicy\nRequest Syntax\nPUT /v20180820/accesspoint/ name/policy HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<PutAccessPointPolicyRequest  xmlns=\"http://awss3control.amazonaws.com/doc/2018-08-20/\"> \n   <Policy>string</Policy>\n</PutAccessPointPolicyRequest >\nURI Request Parameters\nThe request uses the following URI parameters.\nname\nThe name of the access point that you want to associate with the speci\ufb01ed policy.\nAmazon S3 Control API Version 2006-03-01 1029Amazon Simple Storage Service API Reference\nFor using this parameter with Amazon S3 on Outposts with the REST API, you must specify the \nname and the x-amz-outpost-id as well.\nFor using this parameter with S3 on Outposts with the AWS SDK and CLI, you \nmust specify the ARN of the access point accessed in the format arn:aws:s3-\noutposts:<Region>:<account-id>:outpost/<outpost-id>/accesspoint/<my-\naccesspoint-name> . For example, to access the access point reports-ap  through \nOutpost my-outpost  owned by account 123456789012  in Region us-west-2 , use the URL \nencoding of arn:aws:s3-outposts:us-west-2:123456789012:outpost/my-outpost/\naccesspoint/reports-ap .", "The value must be URL encoded.\nLength Constraints: Minimum length of 3.", "Maximum length of 255.\nRequired: Yes\nx-amz-account-id\nThe AWS account ID for owner of the bucket associated with the speci\ufb01ed access point.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request accepts the following data in XML format.\nPutAccessPointPolicyRequest\nRoot level tag for the PutAccessPointPolicyRequest parameters.\nRequired: Yes\nPolicy\nThe policy that you want to apply to the speci\ufb01ed access point. For more information about \naccess point policies, see Managing data access with Amazon S3 access points in the Amazon S3 \nUser Guide .\nType: String\nAmazon S3 Control API Version 2006-03-01 1030Amazon Simple Storage Service API Reference\nRequired: Yes\nResponse Syntax\nHTTP/1.1 200\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\nExamples\nSample request syntax for the PutAccessPointPolicy action for Amazon S3 on Outposts access \npoint\nThis example illustrates one usage of PutAccessPointPolicy.\n           PUT /v20180820/accesspoint/example-access-point/policy HTTP/1.1 \n           Host: s3-outposts.<Region>.amazonaws.com \n           Date: Wed, 28 Oct 2020 22:32:00 GMT \n           Authorization: authorization string \n           x-amz-account-id: example-account-id \n           x-amz-outpost-id: op-01ac5d28a6a232904 \n           <?xml version=\"1.0\" encoding=\"UTF-8\"?> \n               <PutAccessPointPolicyRequest xmlns=\"http://awss3control.amazonaws.com/\ndoc/2018-08-20/\"> \n                  <Policy>\n{ \n   \"Version\":\"2012-10-17\", \n   \"Id\":\"AccessPointPolicy-for-example-access-point\", \n   \"Statement\":[ \n      { \n         \"Sid\":\"st1\", \n         \"Effect\":\"Allow\", \n         \"Principal\":{ \n            \"AWS\":\"example-account-id\" \n         }, \n         \"Action\":\"s3-outposts:*\", \n         \"Resource\":\"arn:aws:s3-outposts:your-Region:example-account-id:outpost/\nop-01ac5d28a6a232904/accesspoint/example-access-point \n      } \nAmazon S3 Control API Version 2006-03-01 1031Amazon Simple Storage Service API Reference\n   ]\n} \n                  </Policy> \n               </PutAccessPointPolicyRequest> \n          \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1032Amazon Simple Storage Service API Reference\nPutAccessPointPolicyForObjectLambda\nService: Amazon S3 Control\nNote\nThis operation is not supported by directory buckets.\nCreates or replaces resource policy for an Object Lambda Access Point. For an example policy, see\nCreating Object Lambda Access Points in the Amazon S3 User Guide .\nThe following actions are related to PutAccessPointPolicyForObjectLambda :\n\u2022DeleteAccessPointPolicyForObjectLambda\n\u2022GetAccessPointPolicyForObjectLambda\nRequest Syntax\nPUT /v20180820/accesspointforobjectlambda/ name/policy HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<PutAccessPointPolicyForObjectLambdaRequest  xmlns=\"http://awss3control.amazonaws.com/\ndoc/2018-08-20/\"> \n   <Policy>string</Policy>\n</PutAccessPointPolicyForObjectLambdaRequest >\nURI Request Parameters\nThe request uses the following URI parameters.\nname\nThe name of the Object Lambda Access Point.\nLength Constraints: Minimum length of 3. Maximum length of 45.\nPattern: ^[a-z0-9]([a-z0-9\\-]*[a-z0-9])?$\nRequired: Yes\nAmazon S3 Control API Version 2006-03-01 1033Amazon Simple Storage Service API Reference\nx-amz-account-id\nThe account ID for the account that owns the speci\ufb01ed Object Lambda Access Point.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request accepts the following data in XML format.\nPutAccessPointPolicyForObjectLambdaRequest\nRoot level tag for the PutAccessPointPolicyForObjectLambdaRequest parameters.\nRequired: Yes\nPolicy\nObject Lambda Access Point resource policy document.\nType: String\nRequired: Yes\nResponse Syntax\nHTTP/1.1 200\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\nExamples\nSample resource policy\nThe following illustrates a sample resource policy.\n{ \nAmazon S3 Control API Version 2006-03-01 1034Amazon Simple Storage Service API Reference\n    \"Version\" : \"2008-10-17\", \n    \"Statement\":[{ \n        \"Sid\": \"Grant account 123456789012 GetObject access\", \n        \"Effect\":\"Allow\", \n        \"Principal\" : { \n            \"AWS\": \"arn:aws:iam::123456789012:root\" \n        }, \n        \"Action\":[\"s3-object-lambda:GetObject\"], \n        \"Resource\":[\"arn:aws:s3-object-lambda:us-east-1:123456789012:accesspoint/my-\nobject-lambda-ap\"] \n        }, \n        { \n        \"Sid\": \"Grant account 444455556666 GetObject access\", \n        \"Effect\":\"Allow\", \n        \"Principal\" : { \n            \"AWS\": \"arn:aws:iam::444455556666:root\" \n        }, \n        \"Action\":[\"s3-object-lambda:GetObject\"], \n        \"Resource\":[\"arn:aws:s3-object-lambda:us-east-1:123456789012:accesspoint/my-\nobject-lambda-ap\"] \n        } \n    ]\n}\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1035Amazon Simple Storage Service API Reference\nPutBucketLifecycleCon\ufb01guration\nService: Amazon S3 Control\nNote\nThis action puts a lifecycle con\ufb01guration to an Amazon S3 on Outposts bucket.", "To put a \nlifecycle con\ufb01guration to an S3 bucket, see PutBucketLifecycleCon\ufb01guration in the Amazon \nS3 API Reference.\nCreates a new lifecycle con\ufb01guration for the S3 on Outposts bucket or replaces an existing lifecycle \ncon\ufb01guration. Outposts buckets only support lifecycle con\ufb01gurations that delete/expire objects \nafter a certain period of time and abort incomplete multipart uploads.\nAll Amazon S3 on Outposts REST API requests for this action require an additional parameter of\nx-amz-outpost-id  to be passed with the request. In addition, you must use an S3 on Outposts \nendpoint hostname pre\ufb01x instead of s3-control . For an example of the request syntax for \nAmazon S3 on Outposts that uses the S3 on Outposts endpoint hostname pre\ufb01x and the x-amz-\noutpost-id  derived by using the access point ARN, see the Examples  section.\nThe following actions are related to PutBucketLifecycleConfiguration :\n\u2022GetBucketLifecycleCon\ufb01guration\n\u2022DeleteBucketLifecycleCon\ufb01guration\nRequest Syntax\nPUT /v20180820/bucket/ name/lifecycleconfiguration HTTP/1.1\nHost: Bucket.s3-control.amazonaws.com\nx-amz-account-id: AccountId\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<LifecycleConfiguration  xmlns=\"http://awss3control.amazonaws.com/doc/2018-08-20/\"> \n   <Rules> \n      <Rule> \n         < AbortIncompleteMultipartUpload > \n            < DaysAfterInitiation >integer</DaysAfterInitiation > \n         </ AbortIncompleteMultipartUpload > \n         < Expiration > \n            < Date>timestamp </Date> \nAmazon S3 Control API Version 2006-03-01 1036Amazon Simple Storage Service API Reference\n            < Days>integer</Days> \n            < ExpiredObjectDeleteMarker >boolean</ExpiredObjectDeleteMarker > \n         </ Expiration > \n         < Filter> \n            < And> \n               < ObjectSizeGreaterThan >long</ObjectSizeGreaterThan > \n               < ObjectSizeLessThan >long</ObjectSizeLessThan > \n               < Prefix>string</Prefix> \n               < Tags> \n                  <S3Tag> \n                     < Key>string</Key> \n                     < Value>string</Value> \n                  </S3Tag> \n               </ Tags> \n            </ And> \n            < ObjectSizeGreaterThan >long</ObjectSizeGreaterThan > \n            < ObjectSizeLessThan >long</ObjectSizeLessThan > \n            < Prefix>string</Prefix> \n            < Tag> \n               < Key>string</Key> \n               < Value>string</Value> \n            </ Tag> \n         </ Filter> \n         < ID>string</ID> \n         < NoncurrentVersionExpiration > \n            < NewerNoncurrentVersions >integer</NewerNoncurrentVersions > \n            < NoncurrentDays >integer</NoncurrentDays > \n         </ NoncurrentVersionExpiration > \n         < NoncurrentVersionTransitions > \n            <NoncurrentVersionTransition> \n               < NoncurrentDays >integer</NoncurrentDays > \n               < StorageClass >string</StorageClass > \n            </NoncurrentVersionTransition> \n         </ NoncurrentVersionTransitions > \n         < Status>string</Status> \n         < Transitions > \n            <Transition> \n               < Date>timestamp </Date> \n               < Days>integer</Days> \n               < StorageClass >string</StorageClass > \n            </Transition> \n         </ Transitions > \n      </Rule> \n   </Rules>\nAmazon S3 Control API Version 2006-03-01 1037Amazon Simple Storage Service API Reference\n</LifecycleConfiguration >\nURI Request Parameters\nThe request uses the following URI parameters.\nname\nThe name of the bucket for which to set the con\ufb01guration.\nLength Constraints: Minimum length of 3. Maximum length of 255.\nRequired: Yes\nx-amz-account-id\nThe AWS account ID of the Outposts bucket.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request accepts the following data in XML format.\nLifecycleCon\ufb01guration\nRoot level tag for the LifecycleCon\ufb01guration parameters.\nRequired: Yes\nRules\nA lifecycle rule for individual objects in an Outposts bucket.\nType: Array of LifecycleRule data types\nRequired: No\nResponse Syntax\nHTTP/1.1 200\nAmazon S3 Control API Version 2006-03-01 1038Amazon Simple Storage Service API Reference\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\nExamples\nSample PutBucketLifecycleCon\ufb01guration request on an Amazon S3 on Outposts bucket\nThis request puts a lifecycle con\ufb01guration on an Outposts bucket named example-outpost-\nbucket .\n            PUT /v20180820/bucket/example-outpost-bucket/lifecycleconfiguration \n HTTP/1.1 \n            Host:s3-outposts.<Region>.amazonaws.com \n            x-amz-account-id: example-account-id \n            x-amz-outpost-id: op-01ac5d28a6a232904 \n            Content-Length: 0 \n            Date: Wed, 01 Mar  2006 12:00:00 GMT \n            Content-MD5: q6yJDlIkcBaGGfb3QLY69A== \n            Authorization: authorization string \n            Content-Length: 214 \n             \n            <LifecycleConfiguration> \n              <Rule> \n                <ID>id2</ID> \n                <Filter> \n                   <Prefix>logs/</Prefix> \n                </Filter> \n                <Status>Enabled</Status> \n                <Expiration> \n                  <Days>365</Days> \n                </Expiration> \n              </Rule> \n            </LifecycleConfiguration> \n          \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\nAmazon S3 Control API Version 2006-03-01 1039Amazon Simple Storage Service API Reference\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1040Amazon Simple Storage Service API Reference\nPutBucketPolicy\nService: Amazon S3 Control\nNote\nThis action puts a bucket policy to an Amazon S3 on Outposts bucket. To put a policy on an \nS3 bucket, see PutBucketPolicy in the Amazon S3 API Reference.\nApplies an Amazon S3 bucket policy to an Outposts bucket. For more information, see Using \nAmazon S3 on Outposts in the Amazon S3 User Guide .\nIf you are using an identity other than the root user of the AWS account that owns the Outposts \nbucket, the calling identity must have the PutBucketPolicy  permissions on the speci\ufb01ed \nOutposts bucket and belong to the bucket owner's account in order to use this action.\nIf you don't have PutBucketPolicy  permissions, Amazon S3 returns a 403 Access Denied\nerror. If you have the correct permissions, but you're not using an identity that belongs to the \nbucket owner's account, Amazon S3 returns a 405 Method Not Allowed  error.\nImportant\nAs a security precaution, the root user of the AWS account that owns a bucket can always \nuse this action, even if the policy explicitly denies the root user the ability to perform this \naction.\nFor more information about bucket policies, see Using Bucket Policies and User Policies.\nAll Amazon S3 on Outposts REST API requests for this action require an additional parameter of\nx-amz-outpost-id  to be passed with the request. In addition, you must use an S3 on Outposts \nendpoint hostname pre\ufb01x instead of s3-control . For an example of the request syntax for \nAmazon S3 on Outposts that uses the S3 on Outposts endpoint hostname pre\ufb01x and the x-amz-\noutpost-id  derived by using the access point ARN, see the Examples  section.\nThe following actions are related to PutBucketPolicy :\n\u2022GetBucketPolicy\n\u2022DeleteBucketPolicy\nAmazon S3 Control API Version 2006-03-01 1041Amazon Simple Storage Service API Reference\nRequest Syntax\nPUT /v20180820/bucket/ name/policy HTTP/1.1\nHost: Bucket.s3-control.amazonaws.com\nx-amz-account-id: AccountId\nx-amz-confirm-remove-self-bucket-access: ConfirmRemoveSelfBucketAccess\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<PutBucketPolicyRequest  xmlns=\"http://awss3control.amazonaws.com/doc/2018-08-20/\"> \n   <Policy>string</Policy>\n</PutBucketPolicyRequest >\nURI Request Parameters\nThe request uses the following URI parameters.\nname\nSpeci\ufb01es the bucket.\nFor using this parameter with Amazon S3 on Outposts with the REST API, you must specify the \nname and the x-amz-outpost-id as well.\nFor using this parameter with S3 on Outposts with the AWS SDK and CLI, you must specify the \nARN of the bucket accessed in the format arn:aws:s3-outposts:<Region>:<account-\nid>:outpost/<outpost-id>/bucket/<my-bucket-name> . For example, to access \nthe bucket reports through Outpost my-outpost  owned by account 123456789012\nin Region us-west-2 , use the URL encoding of arn:aws:s3-outposts:us-\nwest-2:123456789012:outpost/my-outpost/bucket/reports .", "The value must be URL \nencoded.\nLength Constraints: Minimum length of 3.", "Maximum length of 255.\nRequired: Yes\nx-amz-account-id\nThe AWS account ID of the Outposts bucket.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nAmazon S3 Control API Version 2006-03-01 1042Amazon Simple Storage Service API Reference\nx-amz-con\ufb01rm-remove-self-bucket-access\nSet this parameter to true to con\ufb01rm that you want to remove your permissions to change this \nbucket policy in the future.\nNote\nThis is not supported by Amazon S3 on Outposts buckets.\nRequest Body\nThe request accepts the following data in XML format.\nPutBucketPolicyRequest\nRoot level tag for the PutBucketPolicyRequest parameters.\nRequired: Yes\nPolicy\nThe bucket policy as a JSON document.\nType: String\nRequired: Yes\nResponse Syntax\nHTTP/1.1 200\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\nExamples\nSample request for putting a bucket policy in an Amazon S3 on Outposts bucket\nThe following request shows the PUT an individual policy request for the Outposts bucket\nexample-outpost-bucket .\nAmazon S3 Control API Version 2006-03-01 1043Amazon Simple Storage Service API Reference\nPUT v20180820/bucket/example-outpost-bucket/policy HTTP/1.1\nHost: s3-outposts.<Region>.amazonaws.com   \nDate: Tue, 04 Apr 2010 20:34:56 GMT   \nAuthorization: authorization string\nx-amz-account-id: example-account-id\nx-amz-outpost-id: op-01ac5d28a6a232904\n{ \n   \"Version\":\"2012-10-17\", \n   \"Id\":\"exampleS3OnOutpostBucketPolicy\", \n   \"Statement\":[ \n      { \n         \"Sid\":\"st1\", \n         \"Effect\":\"Allow\", \n         \"Principal\":{ \n            \"AWS\":\"example-account-id\" \n         }, \n         \"Action\":\"s3-outposts:*\", \n         \"Resource\":\"arn:aws:s3-outposts:<your-region>:example-account-id:outpost/\nop-01ac5d28a6a232904/bucket/example-outpost-bucket\" \n      } \n   ]\n} \n          \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\nAmazon S3 Control API Version 2006-03-01 1044Amazon Simple Storage Service API Reference\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1045Amazon Simple Storage Service API Reference\nPutBucketReplication\nService: Amazon S3 Control\nNote\nThis action creates an Amazon S3 on Outposts bucket's replication con\ufb01guration. To create \nan S3 bucket's replication con\ufb01guration, see PutBucketReplication in the Amazon S3 API \nReference.\nCreates a replication con\ufb01guration or replaces an existing one. For information about S3 replication \non Outposts con\ufb01guration, see Replicating objects for S3 on Outposts in the Amazon S3 User \nGuide .\nNote\nIt can take a while to propagate PUT or DELETE requests for a replication con\ufb01guration \nto all S3 on Outposts systems. Therefore, the replication con\ufb01guration that's returned \nby a GET request soon after a PUT or DELETE request might return a more recent result \nthan what's on the Outpost. If an Outpost is o\ufb04ine, the delay in updating the replication \ncon\ufb01guration on that Outpost can be signi\ufb01cant.\nSpecify the replication con\ufb01guration in the request body.", "In the replication con\ufb01guration, you \nprovide the following information:\n\u2022The name of the destination bucket or buckets where you want S3 on Outposts to replicate \nobjects\n\u2022The AWS Identity and Access Management (IAM) role that S3 on Outposts can assume to \nreplicate objects on your behalf\n\u2022Other relevant information, such as replication rules\nA replication con\ufb01guration must include at least one rule and can contain a maximum of 100.", "Each \nrule identi\ufb01es a subset of objects to replicate by \ufb01ltering the objects in the source Outposts bucket. \nTo choose additional subsets of objects to replicate, add a rule for each subset.\nTo specify a subset of the objects in the source Outposts bucket to apply a replication rule to, add \nthe Filter  element as a child of the Rule element.", "You can \ufb01lter objects based on an object key \nAmazon S3 Control API Version 2006-03-01 1046Amazon Simple Storage Service API Reference\npre\ufb01x, one or more object tags, or both.", "When you add the Filter element in the con\ufb01guration, \nyou must also add the following elements: DeleteMarkerReplication , Status , and Priority .\nUsing PutBucketReplication  on Outposts requires that both the source and destination \nbuckets must have versioning enabled.", "For information about enabling versioning on a bucket, see\nManaging S3 Versioning for your S3 on Outposts bucket.\nFor information about S3 on Outposts replication failure reasons, see Replication failure reasons in \nthe Amazon S3 User Guide .\nHandling Replication of Encrypted Objects\nOutposts buckets are encrypted at all times. All the objects in the source Outposts bucket are \nencrypted and can be replicated. Also, all the replicas in the destination Outposts bucket are \nencrypted with the same encryption key as the objects in the source Outposts bucket.\nPermissions\nTo create a PutBucketReplication  request, you must have s3-\noutposts:PutReplicationConfiguration  permissions for the bucket. The Outposts bucket \nowner has this permission by default and can grant it to others.", "For more information about \npermissions, see Setting up IAM with S3 on Outposts and Managing access to S3 on Outposts \nbuckets.\nNote\nTo perform this operation, the user or role must also have the iam:CreateRole  and\niam:PassRole  permissions. For more information, see Granting a user permissions to pass \na role to an AWS service.\nAll Amazon S3 on Outposts REST API requests for this action require an additional parameter of\nx-amz-outpost-id  to be passed with the request. In addition, you must use an S3 on Outposts \nendpoint hostname pre\ufb01x instead of s3-control . For an example of the request syntax for \nAmazon S3 on Outposts that uses the S3 on Outposts endpoint hostname pre\ufb01x and the x-amz-\noutpost-id  derived by using the access point ARN, see the Examples  section.\nThe following operations are related to PutBucketReplication :\n\u2022GetBucketReplication\nAmazon S3 Control API Version 2006-03-01 1047Amazon Simple Storage Service API Reference\n\u2022DeleteBucketReplication\nRequest Syntax\nPUT /v20180820/bucket/ name/replication HTTP/1.1\nHost: Bucket.s3-control.amazonaws.com\nx-amz-account-id: AccountId\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<ReplicationConfiguration  xmlns=\"http://awss3control.amazonaws.com/doc/2018-08-20/\"> \n   <Role>string</Role> \n   <Rules> \n      <Rule> \n         < Bucket>string</Bucket> \n         < DeleteMarkerReplication > \n            < Status>string</Status> \n         </ DeleteMarkerReplication > \n         < Destination > \n            < AccessControlTranslation > \n               < Owner>string</Owner> \n            </ AccessControlTranslation > \n            < Account>string</Account> \n            < Bucket>string</Bucket> \n            < EncryptionConfiguration > \n               < ReplicaKmsKeyID >string</ReplicaKmsKeyID > \n            </ EncryptionConfiguration > \n            < Metrics> \n               < EventThreshold > \n                  < Minutes>integer</Minutes> \n               </ EventThreshold > \n               < Status>string</Status> \n            </ Metrics> \n            < ReplicationTime > \n               < Status>string</Status> \n               < Time> \n                  < Minutes>integer</Minutes> \n               </ Time> \n            </ ReplicationTime > \n            < StorageClass >string</StorageClass > \n         </ Destination > \n         < ExistingObjectReplication > \n            < Status>string</Status> \n         </ ExistingObjectReplication > \n         < Filter> \nAmazon S3 Control API Version 2006-03-01 1048Amazon Simple Storage Service API Reference\n            < And> \n               < Prefix>string</Prefix> \n               < Tags> \n                  <S3Tag> \n                     < Key>string</Key> \n                     < Value>string</Value> \n                  </S3Tag> \n               </ Tags> \n            </ And> \n            < Prefix>string</Prefix> \n            < Tag> \n               < Key>string</Key> \n               < Value>string</Value> \n            </ Tag> \n         </ Filter> \n         < ID>string</ID> \n         < Prefix>string</Prefix> \n         < Priority >integer</Priority > \n         < SourceSelectionCriteria > \n            < ReplicaModifications > \n               < Status>string</Status> \n            </ ReplicaModifications > \n            < SseKmsEncryptedObjects > \n               < Status>string</Status> \n            </ SseKmsEncryptedObjects > \n         </ SourceSelectionCriteria > \n         < Status>string</Status> \n      </Rule> \n   </Rules>\n</ReplicationConfiguration >\nURI Request Parameters\nThe request uses the following URI parameters.\nname\nSpeci\ufb01es the S3 on Outposts bucket to set the con\ufb01guration for.\nFor using this parameter with Amazon S3 on Outposts with the REST API, you must specify the \nname and the x-amz-outpost-id as well.\nFor using this parameter with S3 on Outposts with the AWS SDK and CLI, you must specify the \nARN of the bucket accessed in the format arn:aws:s3-outposts:<Region>:<account-\nAmazon S3 Control API Version 2006-03-01 1049Amazon Simple Storage Service API Reference\nid>:outpost/<outpost-id>/bucket/<my-bucket-name> . For example, to access \nthe bucket reports through Outpost my-outpost  owned by account 123456789012\nin Region us-west-2 , use the URL encoding of arn:aws:s3-outposts:us-\nwest-2:123456789012:outpost/my-outpost/bucket/reports .", "The value must be URL \nencoded.\nLength Constraints: Minimum length of 3.", "Maximum length of 255.\nRequired: Yes\nx-amz-account-id\nThe AWS account ID of the Outposts bucket.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request accepts the following data in XML format.\nReplicationCon\ufb01guration\nRoot level tag for the ReplicationCon\ufb01guration parameters.\nRequired: Yes\nRole\nThe Amazon Resource Name (ARN) of the AWS Identity and Access Management (IAM) role \nthat S3 on Outposts assumes when replicating objects. For information about S3 replication on \nOutposts con\ufb01guration, see Setting up replication in the Amazon S3 User Guide .\nType: String\nRequired: Yes\nRules\nA container for one or more replication rules. A replication con\ufb01guration must have at least one \nrule and can contain an array of 100 rules at the most.\nAmazon S3 Control API Version 2006-03-01 1050Amazon Simple Storage Service API Reference\nType: Array of ReplicationRule data types\nRequired: Yes\nResponse Syntax\nHTTP/1.1 200\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\nExamples\nSample Request: Add a replication con\ufb01guration to an Amazon S3 on Outposts bucket\nThe following sample PUT request creates a replication subresource on the speci\ufb01ed Outposts \nbucket named example-outpost-bucket  and saves the replication con\ufb01guration in it. The \nreplication con\ufb01guration speci\ufb01es a rule to replicate objects to the example-outpost-bucket\nbucket. The rule includes a \ufb01lter to replicate only the objects that are created with the key name \npre\ufb01x TaxDocs and that have two speci\ufb01c tags.\nAfter you add a replication con\ufb01guration to your Outposts bucket, S3 on Outposts assumes the \nAWS Identity and Access Management (IAM) role that's speci\ufb01ed in the con\ufb01guration to replicate \nobjects on behalf of the Outposts bucket owner. The bucket owner is the AWS account that created \nthe Outposts bucket.\nFiltering by using the Filter element is supported in the latest XML con\ufb01guration. The earlier \nversion of the XML con\ufb01guration isn't supported.\nFor more examples of S3 replication on Outposts con\ufb01guration, see Creating replication rules on \nOutposts  in the Amazon S3 User Guide .\nPUT /v20180820/bucket/example-outpost-bucket/replication HTTP/1.1\nHost:s3-outposts.<Region>.amazonaws.com\nx-amz-account-id: example-account-id\nx-amz-outpost-id: op-01ac5d28a6a232904\nAuthorization: authorization string\nAmazon S3 Control API Version 2006-03-01 1051Amazon Simple Storage Service API Reference\n<ReplicationConfiguration> \n  <Role>arn:aws:iam::35667example:role/ReplicationRoleForS3Outposts</Role> \n  <Rules> \n   <Rule> \n      <Bucket>arn:aws:s3-outposts:us-east-1:example-account-id:outpost/SOURCE-OUTPOST-\nID/accesspoint/SOURCE-OUTPOSTS-BUCKET-ACCESS-POINT</Bucket> \n      <ID>rule1</ID> \n      <Status>Enabled</Status> \n      <Priority>1</Priority> \n      <DeleteMarkerReplication> \n         <Status>Disabled</Status> \n      </DeleteMarkerReplication> \n      <Filter> \n         <And> \n            <Prefix>TaxDocs</Prefix> \n            <Tag> \n               <Key>key1</Key> \n               <Value>value1</Value> \n            </Tag> \n            <Tag> \n               <Key>key2</Key> \n               <Value>value2</Value> \n            </Tag> \n         </And> \n      </Filter> \n      <Destination> \n         <Bucket>arn:aws:s3-outposts:us-east-1:example-account-id:outpost/DESTINATION-\nOUTPOST-ID/accesspoint/DESTINATION-OUTPOSTS-BUCKET-ACCESS-POINT</Bucket> \n      </Destination> \n   </Rule> \n  </Rules>  \n</ReplicationConfiguration> \n          \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\nAmazon S3 Control API Version 2006-03-01 1052Amazon Simple Storage Service API Reference\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1053Amazon Simple Storage Service API Reference\nPutBucketTagging\nService: Amazon S3 Control\nNote\nThis action puts tags on an Amazon S3 on Outposts bucket. To put tags on an S3 bucket, \nsee PutBucketTagging in the Amazon S3 API Reference.\nSets the tags for an S3 on Outposts bucket. For more information, see Using Amazon S3 on \nOutposts  in the Amazon S3 User Guide .\nUse tags to organize your AWS bill to re\ufb02ect your own cost structure. To do this, sign up to get \nyour AWS account bill with tag key values included.", "Then, to see the cost of combined resources, \norganize your billing information according to resources with the same tag key values. For example, \nyou can tag several resources with a speci\ufb01c application name, and then organize your billing \ninformation to see the total cost of that application across several services. For more information, \nsee Cost allocation and tagging .\nNote\nWithin a bucket, if you add a tag that has the same key as an existing tag, the new value \noverwrites the old value.", "For more information, see  Using cost allocation in Amazon S3 \nbucket tags.\nTo use this action, you must have permissions to perform the s3-outposts:PutBucketTagging\naction.", "The Outposts bucket owner has this permission by default and can grant this permission to \nothers.", "For more information about permissions, see  Permissions Related to Bucket Subresource \nOperations  and Managing access permissions to your Amazon S3 resources.\nPutBucketTagging  has the following special errors:\n\u2022Error code: InvalidTagError\n\u2022Description: The tag provided was not a valid tag.", "This error can occur if the tag did not pass \ninput validation.", "For information about tag restrictions, see  User-De\ufb01ned Tag Restrictions and\nAWS-Generated Cost Allocation Tag Restrictions.\n\u2022Error code: MalformedXMLError\nAmazon S3 Control API Version 2006-03-01 1054Amazon Simple Storage Service API Reference\n\u2022Description: The XML provided does not match the schema.\n\u2022Error code: OperationAbortedError\n\u2022Description: A con\ufb02icting conditional action is currently in progress against this resource. Try \nagain.\n\u2022Error code: InternalError\n\u2022Description: The service was unable to apply the provided tag to the bucket.\nAll Amazon S3 on Outposts REST API requests for this action require an additional parameter of\nx-amz-outpost-id  to be passed with the request. In addition, you must use an S3 on Outposts \nendpoint hostname pre\ufb01x instead of s3-control . For an example of the request syntax for \nAmazon S3 on Outposts that uses the S3 on Outposts endpoint hostname pre\ufb01x and the x-amz-\noutpost-id  derived by using the access point ARN, see the Examples  section.\nThe following actions are related to PutBucketTagging :\n\u2022GetBucketTagging\n\u2022DeleteBucketTagging\nRequest Syntax\nPUT /v20180820/bucket/ name/tagging HTTP/1.1\nHost: Bucket.s3-control.amazonaws.com\nx-amz-account-id: AccountId\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<Tagging xmlns=\"http://awss3control.amazonaws.com/doc/2018-08-20/\"> \n   <TagSet> \n      <S3Tag> \n         < Key>string</Key> \n         < Value>string</Value> \n      </S3Tag> \n   </TagSet>\n</Tagging>\nURI Request Parameters\nThe request uses the following URI parameters.\nAmazon S3 Control API Version 2006-03-01 1055Amazon Simple Storage Service API Reference\nname\nThe Amazon Resource Name (ARN) of the bucket.\nFor using this parameter with Amazon S3 on Outposts with the REST API, you must specify the \nname and the x-amz-outpost-id as well.\nFor using this parameter with S3 on Outposts with the AWS SDK and CLI, you must specify the \nARN of the bucket accessed in the format arn:aws:s3-outposts:<Region>:<account-\nid>:outpost/<outpost-id>/bucket/<my-bucket-name> . For example, to access \nthe bucket reports through Outpost my-outpost  owned by account 123456789012\nin Region us-west-2 , use the URL encoding of arn:aws:s3-outposts:us-\nwest-2:123456789012:outpost/my-outpost/bucket/reports .", "The value must be URL \nencoded.\nLength Constraints: Minimum length of 3.", "Maximum length of 255.\nRequired: Yes\nx-amz-account-id\nThe AWS account ID of the Outposts bucket.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request accepts the following data in XML format.\nTagging\nRoot level tag for the Tagging parameters.\nRequired: Yes\nTagSet\nA collection for a set of tags.\nAmazon S3 Control API Version 2006-03-01 1056Amazon Simple Storage Service API Reference\nType: Array of S3Tag data types\nRequired: Yes\nResponse Syntax\nHTTP/1.1 200\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\nExamples\nSample request: Add tag set to an Amazon S3 on Outposts bucket\nThe following request adds a tag set to the existing example-outpost-bucket  bucket.\nPUT v20180820/bucket/example-outpost-bucket/tagging HTTP/1.1\nHost: s3-outposts.<Region>.amazonaws.com\nContent-Length: 1660\nx-amz-date: Thu, 12 Nov 2020 20:04:21 GMT\nx-amz-account-id: example-account-id\nx-amz-outpost-id: op-01ac5d28a6a232904\nAuthorization: authorization string\n<Tagging> \n  <TagSet> \n    <Tag> \n      <Key>Project</Key> \n      <Value>Project One</Value> \n    </Tag> \n    <Tag> \n      <Key>User</Key> \n      <Value>jsmith</Value> \n    </Tag> \n  </TagSet>\n</Tagging> \n          \nAmazon S3 Control API Version 2006-03-01 1057Amazon Simple Storage Service API Reference\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1058Amazon Simple Storage Service API Reference\nPutBucketVersioning\nService: Amazon S3 Control\nNote\nThis operation sets the versioning state for S3 on Outposts buckets only. To set the \nversioning state for an S3 bucket, see PutBucketVersioning in the Amazon S3 API Reference.\nSets the versioning state for an S3 on Outposts bucket. With S3 Versioning, you can save multiple \ndistinct copies of your objects and recover from unintended user actions and application failures.\nYou can set the versioning state to one of the following:\n\u2022Enabled - Enables versioning for the objects in the bucket.", "All objects added to the bucket \nreceive a unique version ID.\n\u2022Suspended  - Suspends versioning for the objects in the bucket. All objects added to the bucket \nreceive the version ID null .\nIf you've never set versioning on your bucket, it has no versioning state.", "In that case, a \nGetBucketVersioning request does not return a versioning state value.\nWhen you enable S3 Versioning, for each object in your bucket, you have a current version and zero \nor more noncurrent versions. You can con\ufb01gure your bucket S3 Lifecycle rules to expire noncurrent \nversions after a speci\ufb01ed time period. For more information, see  Creating and managing a lifecycle \ncon\ufb01guration for your S3 on Outposts bucket in the Amazon S3 User Guide .\nIf you have an object expiration lifecycle con\ufb01guration in your non-versioned bucket and you want \nto maintain the same permanent delete behavior when you enable versioning, you must add a \nnoncurrent expiration policy. The noncurrent expiration lifecycle con\ufb01guration will manage the \ndeletes of the noncurrent object versions in the version-enabled bucket.", "For more information, see\nVersioning in the Amazon S3 User Guide .\nAll Amazon S3 on Outposts REST API requests for this action require an additional parameter of\nx-amz-outpost-id  to be passed with the request. In addition, you must use an S3 on Outposts \nendpoint hostname pre\ufb01x instead of s3-control . For an example of the request syntax for \nAmazon S3 on Outposts that uses the S3 on Outposts endpoint hostname pre\ufb01x and the x-amz-\noutpost-id  derived by using the access point ARN, see the Examples  section.\nAmazon S3 Control API Version 2006-03-01 1059Amazon Simple Storage Service API Reference\nThe following operations are related to PutBucketVersioning  for S3 on Outposts.\n\u2022GetBucketVersioning\n\u2022PutBucketLifecycleCon\ufb01guration\n\u2022GetBucketLifecycleCon\ufb01guration\nRequest Syntax\nPUT /v20180820/bucket/ name/versioning HTTP/1.1\nHost: Bucket.s3-control.amazonaws.com\nx-amz-account-id: AccountId\nx-amz-mfa: MFA\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<VersioningConfiguration  xmlns=\"http://awss3control.amazonaws.com/doc/2018-08-20/\"> \n   <MfaDelete >string</MfaDelete > \n   <Status>string</Status>\n</VersioningConfiguration >\nURI Request Parameters\nThe request uses the following URI parameters.\nname\nThe S3 on Outposts bucket to set the versioning state for.\nLength Constraints: Minimum length of 3. Maximum length of 255.\nRequired: Yes\nx-amz-account-id\nThe AWS account ID of the S3 on Outposts bucket.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nx-amz-mfa\nThe concatenation of the authentication device's serial number, a space, and the value that is \ndisplayed on your authentication device.\nAmazon S3 Control API Version 2006-03-01 1060Amazon Simple Storage Service API Reference\nRequest Body\nThe request accepts the following data in XML format.\nVersioningCon\ufb01guration\nRoot level tag for the VersioningCon\ufb01guration parameters.\nRequired: Yes\nMFADelete\nSpeci\ufb01es whether MFA delete is enabled or disabled in the bucket versioning con\ufb01guration for \nthe S3 on Outposts bucket.\nType: String\nValid Values: Enabled | Disabled\nRequired: No\nStatus\nSets the versioning state of the S3 on Outposts bucket.\nType: String\nValid Values: Enabled | Suspended\nRequired: No\nResponse Syntax\nHTTP/1.1 200\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\nExamples\nSample PutBucketVersioning request on an Amazon S3 on Outposts bucket\nThis request sets the versioning state on an S3 on Outposts bucket that's named example-\noutpost-bucket .\nAmazon S3 Control API Version 2006-03-01 1061Amazon Simple Storage Service API Reference\n            PUT /v20180820/bucket/example-outpost-bucket/?versioning HTTP/1.1 \n            Host:s3-outposts. region-code .amazonaws.com \n            x-amz-account-id: example-account-id \n            x-amz-outpost-id: op-01ac5d28a6a232904 \n            Content-Length: 0 \n            Date: Wed, 25 May  2022 12:00:00 GMT \n            Content-MD5: q6yJDlIkcBaGGfb3QLY69A== \n            Authorization: authorization string \n            Content-Length: 214 \n             \n           <VersioningConfiguration xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\">  \n            <Status>Enabled</Status>  \n           </VersioningConfiguration> \n          \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1062Amazon Simple Storage Service API Reference\nPutJobTagging\nService: Amazon S3 Control\nSets the supplied tag-set on an S3 Batch Operations job.\nA tag is a key-value pair.", "You can associate S3 Batch Operations tags with any job by sending a PUT \nrequest against the tagging subresource that is associated with the job.", "To modify the existing tag \nset, you can either replace the existing tag set entirely, or make changes within the existing tag set \nby retrieving the existing tag set using GetJobTagging, modify that tag set, and use this operation \nto replace the tag set with the one you modi\ufb01ed.", "For more information, see Controlling access and \nlabeling jobs using tags  in the Amazon S3 User Guide .\nNote\n\u2022If you send this request with an empty tag set, Amazon S3 deletes the existing tag set on \nthe Batch Operations job.", "If you use this method, you are charged for a Tier 1 Request \n(PUT).", "For more information, see Amazon S3 pricing.\n\u2022For deleting existing tags for your Batch Operations job, a DeleteJobTagging request is \npreferred because it achieves the same result without incurring charges.\n\u2022A few things to consider about using tags:\n\u2022Amazon S3 limits the maximum number of tags to 50 tags per job.\n\u2022You can associate up to 50 tags with a job as long as they have unique tag keys.\n\u2022A tag key can be up to 128 Unicode characters in length, and tag values can be up to \n256 Unicode characters in length.\n\u2022The key and values are case sensitive.\n\u2022For tagging-related restrictions related to characters and encodings, see User-De\ufb01ned \nTag Restrictions in the  AWS Billing and Cost Management User Guide.\nPermissions\nTo use the PutJobTagging  operation, you must have permission to perform the\ns3:PutJobTagging  action.\nRelated actions include:\nAmazon S3 Control API Version 2006-03-01 1063Amazon Simple Storage Service API Reference\n\u2022CreateJob\n\u2022GetJobTagging\n\u2022DeleteJobTagging\nRequest Syntax\nPUT /v20180820/jobs/ id/tagging HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<PutJobTaggingRequest  xmlns=\"http://awss3control.amazonaws.com/doc/2018-08-20/\"> \n   <Tags> \n      <S3Tag> \n         < Key>string</Key> \n         < Value>string</Value> \n      </S3Tag> \n   </Tags>\n</PutJobTaggingRequest >\nURI Request Parameters\nThe request uses the following URI parameters.\nid\nThe ID for the S3 Batch Operations job whose tags you want to replace.\nLength Constraints: Minimum length of 5. Maximum length of 36.\nPattern: [a-zA-Z0-9\\-\\_]+\nRequired: Yes\nx-amz-account-id\nThe AWS account ID associated with the S3 Batch Operations job.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nAmazon S3 Control API Version 2006-03-01 1064Amazon Simple Storage Service API Reference\nRequest Body\nThe request accepts the following data in XML format.\nPutJobTaggingRequest\nRoot level tag for the PutJobTaggingRequest parameters.\nRequired: Yes\nTags\nThe set of tags to associate with the S3 Batch Operations job.\nType: Array of S3Tag data types\nRequired: Yes\nResponse Syntax\nHTTP/1.1 200\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\nErrors\nInternalServiceException\nHTTP Status Code: 500\nNotFoundException\nHTTP Status Code: 400\nTooManyRequestsException\nHTTP Status Code: 400\nTooManyTagsException\nAmazon S3 throws this exception if you have too many tags in your tag set.\nAmazon S3 Control API Version 2006-03-01 1065Amazon Simple Storage Service API Reference\nHTTP Status Code: 400\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1066Amazon Simple Storage Service API Reference\nPutMultiRegionAccessPointPolicy\nService: Amazon S3 Control\nNote\nThis operation is not supported by directory buckets.\nAssociates an access control policy with the speci\ufb01ed Multi-Region Access Point.", "Each Multi-Region \nAccess Point can have only one policy, so a request made to this action replaces any existing policy \nthat is associated with the speci\ufb01ed Multi-Region Access Point.\nThis action will always be routed to the US West (Oregon) Region.", "For more information about \nthe restrictions around working with Multi-Region Access Points, see Multi-Region Access Point \nrestrictions and limitations in the Amazon S3 User Guide .\nThe following actions are related to PutMultiRegionAccessPointPolicy :\n\u2022GetMultiRegionAccessPointPolicy\n\u2022GetMultiRegionAccessPointPolicyStatus\nRequest Syntax\nPOST /v20180820/async-requests/mrap/put-policy HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<PutMultiRegionAccessPointPolicyRequest  xmlns=\"http://awss3control.amazonaws.com/\ndoc/2018-08-20/\"> \n   <ClientToken >string</ClientToken > \n   <Details> \n      <Name>string</Name> \n      <Policy>string</Policy> \n   </Details>\n</PutMultiRegionAccessPointPolicyRequest >\nURI Request Parameters\nThe request uses the following URI parameters.\nAmazon S3 Control API Version 2006-03-01 1067Amazon Simple Storage Service API Reference\nx-amz-account-id\nThe AWS account ID for the owner of the Multi-Region Access Point.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request accepts the following data in XML format.\nPutMultiRegionAccessPointPolicyRequest\nRoot level tag for the PutMultiRegionAccessPointPolicyRequest parameters.\nRequired: Yes\nClientToken\nAn idempotency token used to identify the request and guarantee that requests are unique.\nType: String\nLength Constraints: Maximum length of 64.\nPattern: \\S+\nRequired: Yes\nDetails\nA container element containing the details of the policy for the Multi-Region Access Point.\nType: PutMultiRegionAccessPointPolicyInput data type\nRequired: Yes\nResponse Syntax\nHTTP/1.1 200\nAmazon S3 Control API Version 2006-03-01 1068Amazon Simple Storage Service API Reference\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<PutMultiRegionAccessPointPolicyResult > \n   <RequestTokenARN >string</RequestTokenARN >\n</PutMultiRegionAccessPointPolicyResult >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nPutMultiRegionAccessPointPolicyResult\nRoot level tag for the PutMultiRegionAccessPointPolicyResult parameters.\nRequired: Yes\nRequestTokenARN\nThe request token associated with the request.", "You can use this token with\nDescribeMultiRegionAccessPointOperation to determine the status of asynchronous requests.\nType: String\nLength Constraints: Minimum length of 1.", "Maximum length of 1024.\nPattern: arn:.+\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\nAmazon S3 Control API Version 2006-03-01 1069Amazon Simple Storage Service API Reference\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1070Amazon Simple Storage Service API Reference\nPutPublicAccessBlock\nService: Amazon S3 Control\nNote\nThis operation is not supported by directory buckets.\nCreates or modi\ufb01es the PublicAccessBlock  con\ufb01guration for an AWS account. For this \noperation, users must have the s3:PutAccountPublicAccessBlock  permission. For more \ninformation, see  Using Amazon S3 block public access.\nRelated actions include:\n\u2022GetPublicAccessBlock\n\u2022DeletePublicAccessBlock\nRequest Syntax\nPUT /v20180820/configuration/publicAccessBlock HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<PublicAccessBlockConfiguration  xmlns=\"http://awss3control.amazonaws.com/\ndoc/2018-08-20/\"> \n   <BlockPublicAcls >boolean</BlockPublicAcls > \n   <IgnorePublicAcls >boolean</IgnorePublicAcls > \n   <BlockPublicPolicy >boolean</BlockPublicPolicy > \n   <RestrictPublicBuckets >boolean</RestrictPublicBuckets >\n</PublicAccessBlockConfiguration >\nURI Request Parameters\nThe request uses the following URI parameters.\nx-amz-account-id\nThe account ID for the AWS account whose PublicAccessBlock  con\ufb01guration you want to \nset.\nLength Constraints: Maximum length of 64.\nAmazon S3 Control API Version 2006-03-01 1071Amazon Simple Storage Service API Reference\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request accepts the following data in XML format.\nPublicAccessBlockCon\ufb01guration\nRoot level tag for the PublicAccessBlockCon\ufb01guration parameters.\nRequired: Yes\nBlockPublicAcls\nSpeci\ufb01es whether Amazon S3 should block public access control lists (ACLs) for buckets in this \naccount. Setting this element to TRUE causes the following behavior:\n\u2022PutBucketAcl  and PutObjectAcl  calls fail if the speci\ufb01ed ACL is public.\n\u2022PUT Object calls fail if the request includes a public ACL.\n\u2022PUT Bucket calls fail if the request includes a public ACL.\nEnabling this setting doesn't a\ufb00ect existing policies or ACLs.\nThis property is not supported for Amazon S3 on Outposts.\nType: Boolean\nRequired: No\nBlockPublicPolicy\nSpeci\ufb01es whether Amazon S3 should block public bucket policies for buckets in this account. \nSetting this element to TRUE causes Amazon S3 to reject calls to PUT Bucket policy if the \nspeci\ufb01ed bucket policy allows public access.\nEnabling this setting doesn't a\ufb00ect existing bucket policies.\nThis property is not supported for Amazon S3 on Outposts.\nType: Boolean\nRequired: No\nAmazon S3 Control API Version 2006-03-01 1072Amazon Simple Storage Service API Reference\nIgnorePublicAcls\nSpeci\ufb01es whether Amazon S3 should ignore public ACLs for buckets in this account. Setting this \nelement to TRUE causes Amazon S3 to ignore all public ACLs on buckets in this account and any \nobjects that they contain.\nEnabling this setting doesn't a\ufb00ect the persistence of any existing ACLs and doesn't prevent \nnew public ACLs from being set.\nThis property is not supported for Amazon S3 on Outposts.\nType: Boolean\nRequired: No\nRestrictPublicBuckets\nSpeci\ufb01es whether Amazon S3 should restrict public bucket policies for buckets in this account.", "\nSetting this element to TRUE restricts access to buckets with public policies to only AWS service \nprincipals and authorized users within this account.\nEnabling this setting doesn't a\ufb00ect previously stored bucket policies, except that public and \ncross-account access within any public bucket policy, including non-public delegation to speci\ufb01c \naccounts, is blocked.\nThis property is not supported for Amazon S3 on Outposts.\nType: Boolean\nRequired: No\nResponse Syntax\nHTTP/1.1 200\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\nAmazon S3 Control API Version 2006-03-01 1073Amazon Simple Storage Service API Reference\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1074Amazon Simple Storage Service API Reference\nPutStorageLensCon\ufb01guration\nService: Amazon S3 Control\nNote\nThis operation is not supported by directory buckets.\nPuts an Amazon S3 Storage Lens con\ufb01guration. For more information about S3 Storage Lens, see\nWorking with Amazon S3 Storage Lens in the Amazon S3 User Guide . For a complete list of S3 \nStorage Lens metrics, see S3 Storage Lens metrics glossary in the Amazon S3 User Guide .\nNote\nTo use this action, you must have permission to perform the\ns3:PutStorageLensConfiguration  action. For more information, see Setting \npermissions to use Amazon S3 Storage Lens in the Amazon S3 User Guide .\nRequest Syntax\nPUT /v20180820/storagelens/ storagelensid  HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<PutStorageLensConfigurationRequest  xmlns=\"http://awss3control.amazonaws.com/\ndoc/2018-08-20/\"> \n   <StorageLensConfiguration > \n      <AccountLevel > \n         < ActivityMetrics > \n            < IsEnabled >boolean</IsEnabled > \n         </ ActivityMetrics > \n         < AdvancedCostOptimizationMetrics > \n            < IsEnabled >boolean</IsEnabled > \n         </ AdvancedCostOptimizationMetrics > \n         < AdvancedDataProtectionMetrics > \n            < IsEnabled >boolean</IsEnabled > \n         </ AdvancedDataProtectionMetrics > \n         < BucketLevel > \n            < ActivityMetrics > \n               < IsEnabled >boolean</IsEnabled > \nAmazon S3 Control API Version 2006-03-01 1075Amazon Simple Storage Service API Reference\n            </ ActivityMetrics > \n            < AdvancedCostOptimizationMetrics > \n               < IsEnabled >boolean</IsEnabled > \n            </ AdvancedCostOptimizationMetrics > \n            < AdvancedDataProtectionMetrics > \n               < IsEnabled >boolean</IsEnabled > \n            </ AdvancedDataProtectionMetrics > \n            < DetailedStatusCodesMetrics > \n               < IsEnabled >boolean</IsEnabled > \n            </ DetailedStatusCodesMetrics > \n            < PrefixLevel > \n               < StorageMetrics > \n                  < IsEnabled >boolean</IsEnabled > \n                  < SelectionCriteria > \n                     < Delimiter >string</Delimiter > \n                     < MaxDepth >integer</MaxDepth > \n                     < MinStorageBytesPercentage >double</MinStorageBytesPercentage > \n                  </ SelectionCriteria > \n               </ StorageMetrics > \n            </ PrefixLevel > \n         </ BucketLevel > \n         < DetailedStatusCodesMetrics > \n            < IsEnabled >boolean</IsEnabled > \n         </ DetailedStatusCodesMetrics > \n         < StorageLensGroupLevel > \n            < SelectionCriteria > \n               < Exclude> \n                  <Arn> string</Arn> \n               </ Exclude> \n               < Include> \n                  <Arn> string</Arn> \n               </ Include> \n            </ SelectionCriteria > \n         </ StorageLensGroupLevel > \n      </ AccountLevel > \n      <AwsOrg> \n         < Arn>string</Arn> \n      </ AwsOrg> \n      <DataExport > \n         < CloudWatchMetrics > \n            < IsEnabled >boolean</IsEnabled > \n         </ CloudWatchMetrics > \n         < S3BucketDestination > \n            < AccountId >string</AccountId > \nAmazon S3 Control API Version 2006-03-01 1076Amazon Simple Storage Service API Reference\n            < Arn>string</Arn> \n            < Encryption > \n               < SSE-KMS> \n                  < KeyId>string</KeyId> \n               </ SSE-KMS> \n               < SSE-S3> \n               </ SSE-S3> \n            </ Encryption > \n            < Format>string</Format> \n            < OutputSchemaVersion >string</OutputSchemaVersion > \n            < Prefix>string</Prefix> \n         </ S3BucketDestination > \n      </ DataExport > \n      <Exclude> \n         < Buckets> \n            <Arn> string</Arn> \n         </ Buckets> \n         < Regions> \n            <Region> string</Region> \n         </ Regions> \n      </ Exclude> \n      <Id>string</Id> \n      <Include> \n         < Buckets> \n            <Arn> string</Arn> \n         </ Buckets> \n         < Regions> \n            <Region> string</Region> \n         </ Regions> \n      </ Include> \n      <IsEnabled >boolean</IsEnabled > \n      <StorageLensArn >string</StorageLensArn > \n   </StorageLensConfiguration > \n   <Tags> \n      <Tag> \n         < Key>string</Key> \n         < Value>string</Value> \n      </Tag> \n   </Tags>\n</PutStorageLensConfigurationRequest >\nURI Request Parameters\nThe request uses the following URI parameters.\nAmazon S3 Control API Version 2006-03-01 1077Amazon Simple Storage Service API Reference\nstoragelensid\nThe ID of the S3 Storage Lens con\ufb01guration.\nLength Constraints: Minimum length of 1. Maximum length of 64.\nPattern: [a-zA-Z0-9\\-\\_\\.]+\nRequired: Yes\nx-amz-account-id\nThe account ID of the requester.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request accepts the following data in XML format.\nPutStorageLensCon\ufb01gurationRequest\nRoot level tag for the PutStorageLensCon\ufb01gurationRequest parameters.\nRequired: Yes\nStorageLensCon\ufb01guration\nThe S3 Storage Lens con\ufb01guration.\nType: StorageLensCon\ufb01guration  data type\nRequired: Yes\nTags\nThe tag set of the S3 Storage Lens con\ufb01guration.\nNote\nYou can set up to a maximum of 50 tags.\nAmazon S3 Control API Version 2006-03-01 1078Amazon Simple Storage Service API Reference\nType: Array of StorageLensTag data types\nRequired: No\nResponse Syntax\nHTTP/1.1 200\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1079Amazon Simple Storage Service API Reference\nPutStorageLensCon\ufb01gurationTagging\nService: Amazon S3 Control\nNote\nThis operation is not supported by directory buckets.\nPut or replace tags on an existing Amazon S3 Storage Lens con\ufb01guration. For more information \nabout S3 Storage Lens, see Assessing your storage activity and usage with Amazon S3 Storage Lens\nin the Amazon S3 User Guide .\nNote\nTo use this action, you must have permission to perform the\ns3:PutStorageLensConfigurationTagging  action. For more information, see Setting \npermissions to use Amazon S3 Storage Lens in the Amazon S3 User Guide .\nRequest Syntax\nPUT /v20180820/storagelens/ storagelensid /tagging HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<PutStorageLensConfigurationTaggingRequest  xmlns=\"http://awss3control.amazonaws.com/\ndoc/2018-08-20/\"> \n   <Tags> \n      <Tag> \n         < Key>string</Key> \n         < Value>string</Value> \n      </Tag> \n   </Tags>\n</PutStorageLensConfigurationTaggingRequest >\nURI Request Parameters\nThe request uses the following URI parameters.\nAmazon S3 Control API Version 2006-03-01 1080Amazon Simple Storage Service API Reference\nstoragelensid\nThe ID of the S3 Storage Lens con\ufb01guration.\nLength Constraints: Minimum length of 1. Maximum length of 64.\nPattern: [a-zA-Z0-9\\-\\_\\.]+\nRequired: Yes\nx-amz-account-id\nThe account ID of the requester.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request accepts the following data in XML format.\nPutStorageLensCon\ufb01gurationTaggingRequest\nRoot level tag for the PutStorageLensCon\ufb01gurationTaggingRequest parameters.\nRequired: Yes\nTags\nThe tag set of the S3 Storage Lens con\ufb01guration.\nNote\nYou can set up to a maximum of 50 tags.\nType: Array of StorageLensTag data types\nRequired: Yes\nAmazon S3 Control API Version 2006-03-01 1081Amazon Simple Storage Service API Reference\nResponse Syntax\nHTTP/1.1 200\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1082Amazon Simple Storage Service API Reference\nSubmitMultiRegionAccessPointRoutes\nService: Amazon S3 Control\nNote\nThis operation is not supported by directory buckets.\nSubmits an updated route con\ufb01guration for a Multi-Region Access Point.", "This API operation \nupdates the routing status for the speci\ufb01ed Regions from active to passive, or from passive to \nactive. A value of 0 indicates a passive status, which means that tra\ufb03c won't be routed to the \nspeci\ufb01ed Region. A value of 100 indicates an active status, which means that tra\ufb03c will be routed \nto the speci\ufb01ed Region.", "At least one Region must be active at all times.\nWhen the routing con\ufb01guration is changed, any in-progress operations (uploads, copies, deletes, \nand so on) to formerly active Regions will continue to run to their \ufb01nal completion state (success or \nfailure). The routing con\ufb01gurations of any Regions that aren\u2019t speci\ufb01ed remain unchanged.\nNote\nUpdated routing con\ufb01gurations might not be immediately applied.", "It can take up to 2 \nminutes for your changes to take e\ufb00ect.\nTo submit routing control changes and failover requests, use the Amazon S3 failover control \ninfrastructure endpoints in these \ufb01ve AWS Regions:\n\u2022us-east-1\n\u2022us-west-2\n\u2022ap-southeast-2\n\u2022ap-northeast-1\n\u2022eu-west-1\nRequest Syntax\nPATCH /v20180820/mrap/instances/ mrap+/routes HTTP/1.1\nHost: s3-control.amazonaws.com\nAmazon S3 Control API Version 2006-03-01 1083Amazon Simple Storage Service API Reference\nx-amz-account-id: AccountId\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<SubmitMultiRegionAccessPointRoutesRequest  xmlns=\"http://awss3control.amazonaws.com/\ndoc/2018-08-20/\"> \n   <RouteUpdates > \n      <Route> \n         < Bucket>string</Bucket> \n         < Region>string</Region> \n         < TrafficDialPercentage >integer</TrafficDialPercentage > \n      </Route> \n   </RouteUpdates >\n</SubmitMultiRegionAccessPointRoutesRequest >\nURI Request Parameters\nThe request uses the following URI parameters.\nmrap\nThe Multi-Region Access Point ARN.\nLength Constraints: Maximum length of 200.\nPattern: ^[a-zA-Z0-9\\:.-]{3,200}$\nRequired: Yes\nx-amz-account-id\nThe AWS account ID for the owner of the Multi-Region Access Point.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request accepts the following data in XML format.\nSubmitMultiRegionAccessPointRoutesRequest\nRoot level tag for the SubmitMultiRegionAccessPointRoutesRequest parameters.\nAmazon S3 Control API Version 2006-03-01 1084Amazon Simple Storage Service API Reference\nRequired: Yes\nRouteUpdates\nThe di\ufb00erent routes that make up the new route con\ufb01guration. Active routes return a value of\n100, and passive routes return a value of 0.\nType: Array of MultiRegionAccessPointRoute data types\nRequired: Yes\nResponse Syntax\nHTTP/1.1 200\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\nExamples\nSample request for initiating failover\nIn the following example, the request to submit these routing changes to initiate a failover is sent \nto the failover control infrastructure in the us-east-1  Region.", "In this example, the eu-north-1\nRegion is set to active, and the ap-northeast-3  Region is set to passive. In other words, the ap-\nnortheast-3  Region is failed over to the eu-north-1  Region.\nPATCH /v20180820/mrap/instances/<Multi-Region Access Point>/routes HTTP/1.1\nHost: example-account-id.s3-control.us-east-1.amazonaws.com \n             \n<SubmitMultiRegionAccessPointRoutesRequest> \n  <RouteUpdates> \n     <Route> \n      <Region>eu-north-1</Region> \n      <Bucket>example-bucket-eu-north-1</Bucket> \n      <TrafficDialPercentage>100</TrafficDialPercentage> \n     </Route> \n     <Route> \n      <Region>ap-northeast-3</Region> \n      <Bucket>example-bucket-ap-northeast-3</Bucket> \nAmazon S3 Control API Version 2006-03-01 1085Amazon Simple Storage Service API Reference\n      <TrafficDialPercentage>0</TrafficDialPercentage> \n     </Route> \n  </RouteUpdates>\n</SubmitMultiRegionAccessPointRoutesRequest> \n             \nSample request for setting a Region to active status\nThe following request updates the route con\ufb01guration of the eu-north-1  Region to active. The \nrequest is sent to the failover control infrastructure in the eu-west-1  Region.\nPATCH /v20180820/mrap/instances/<Multi-Region Access Point>/routes HTTP/1.1\nHost: example-account-id.s3-control.eu-west-1.amazonaws.com\n<SubmitMultiRegionAccessPointRoutesRequest> \n   <RouteUpdates> \n    <Route> \n      <Region>eu-north-1<Region> \n      <Bucket>example-bucket-eu-north-1</Bucket> \n      <TrafficDialPercentage>100</TrafficDialPercentage> \n    </Route> \n   </RouteUpdates>\n</SubmitMultiRegionAccessPointRoutesRequest> \n    \nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\nAmazon S3 Control API Version 2006-03-01 1086Amazon Simple Storage Service API Reference\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1087Amazon Simple Storage Service API Reference\nTagResource\nService: Amazon S3 Control\nCreates a new AWS resource tag or updates an existing resource tag.", "Each tag is a label consisting \nof a user-de\ufb01ned key and value. Tags can help you manage, identify, organize, search for, and \ufb01lter \nresources.", "You can add up to 50 AWS resource tags for each S3 resource.\nNote\nThis operation is only supported for S3 Storage Lens groups and for S3 Access Grants. The \ntagged resource can be an S3 Storage Lens group or S3 Access Grants instance, registered \nlocation, or grant.\nPermissions\nYou must have the s3:TagResource  permission to use this operation.\nFor more information about the required Storage Lens Groups permissions, see Setting account \npermissions to use S3 Storage Lens groups.\nFor information about S3 Tagging errors, see List of Amazon S3 Tagging error codes.\nRequest Syntax\nPOST /v20180820/tags/ resourceArn+  HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<TagResourceRequest  xmlns=\"http://awss3control.amazonaws.com/doc/2018-08-20/\"> \n   <Tags> \n      <Tag> \n         < Key>string</Key> \n         < Value>string</Value> \n      </Tag> \n   </Tags>\n</TagResourceRequest >\nURI Request Parameters\nThe request uses the following URI parameters.\nAmazon S3 Control API Version 2006-03-01 1088Amazon Simple Storage Service API Reference\nresourceArn\nThe Amazon Resource Name (ARN) of the S3 resource that you're trying to add tags to. The \ntagged resource can be an S3 Storage Lens group or S3 Access Grants instance, registered \nlocation, or grant.\nLength Constraints: Maximum length of 1011.\nPattern: arn:[^:]+:s3:[^:].*\nRequired: Yes\nx-amz-account-id\nThe AWS account ID that created the S3 resource that you're trying to add tags to or the \nrequester's account ID.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request accepts the following data in XML format.\nTagResourceRequest\nRoot level tag for the TagResourceRequest parameters.\nRequired: Yes\nTags\nThe AWS resource tags that you want to add to the speci\ufb01ed S3 resource.\nType: Array of Tag data types\nArray Members: Minimum number of 0 items. Maximum number of 50 items.\nRequired: Yes\nAmazon S3 Control API Version 2006-03-01 1089Amazon Simple Storage Service API Reference\nResponse Syntax\nHTTP/1.1 204\nResponse Elements\nIf the action is successful, the service sends back an HTTP 204 response with an empty HTTP body.\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1090Amazon Simple Storage Service API Reference\nUntagResource\nService: Amazon S3 Control\nThis operation removes the speci\ufb01ed AWS resource tags from an S3 resource.", "Each tag is a label \nconsisting of a user-de\ufb01ned key and value.", "Tags can help you manage, identify, organize, search \nfor, and \ufb01lter resources.\nNote\nThis operation is only supported for S3 Storage Lens groups and for S3 Access Grants. The \ntagged resource can be an S3 Storage Lens group or S3 Access Grants instance, registered \nlocation, or grant.\nPermissions\nYou must have the s3:UntagResource  permission to use this operation.\nFor more information about the required Storage Lens Groups permissions, see Setting account \npermissions to use S3 Storage Lens groups.\nFor information about S3 Tagging errors, see List of Amazon S3 Tagging error codes.\nRequest Syntax\nDELETE /v20180820/tags/ resourceArn+ ?tagKeys= TagKeys HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nresourceArn\nThe Amazon Resource Name (ARN) of the S3 resource that you're trying to remove the tags \nfrom.\nLength Constraints: Maximum length of 1011.\nPattern: arn:[^:]+:s3:[^:].*\nAmazon S3 Control API Version 2006-03-01 1091Amazon Simple Storage Service API Reference\nRequired: Yes\ntagKeys\nThe array of tag key-value pairs that you're trying to remove from of the S3 resource.\nArray Members: Minimum number of 0 items.", "Maximum number of 50 items.\nLength Constraints: Minimum length of 1.", "Maximum length of 128.\nPattern: ^([\\p{L}\\p{Z}\\p{N}_.:/=+\\-@]*)$\nRequired: Yes\nx-amz-account-id\nThe AWS account ID that owns the resource that you're trying to remove the tags from.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 204\nResponse Elements\nIf the action is successful, the service sends back an HTTP 204 response with an empty HTTP body.\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\nAmazon S3 Control API Version 2006-03-01 1092Amazon Simple Storage Service API Reference\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1093Amazon Simple Storage Service API Reference\nUpdateAccessGrantsLocation\nService: Amazon S3 Control\nUpdates the IAM role of a registered location in your S3 Access Grants instance.\nPermissions\nYou must have the s3:UpdateAccessGrantsLocation  permission to use this operation.\nAdditional Permissions\nYou must also have the following permission: iam:PassRole\nRequest Syntax\nPUT /v20180820/accessgrantsinstance/location/ id HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<UpdateAccessGrantsLocationRequest  xmlns=\"http://awss3control.amazonaws.com/\ndoc/2018-08-20/\"> \n   <IAMRoleArn >string</IAMRoleArn >\n</UpdateAccessGrantsLocationRequest >\nURI Request Parameters\nThe request uses the following URI parameters.\nid\nThe ID of the registered location that you are updating.", "S3 Access Grants assigns this ID when \nyou register the location. S3 Access Grants assigns the ID default  to the default location\ns3:// and assigns an auto-generated ID to other locations that you register.\nThe ID of the registered location to which you are granting access. S3 Access Grants assigned \nthis ID when you registered the location. S3 Access Grants assigns the ID default  to the \ndefault location s3:// and assigns an auto-generated ID to other locations that you register.\nIf you are passing the default location, you cannot create an access grant for the entire \ndefault location.", "You must also specify a bucket or a bucket and pre\ufb01x in the Subprefix  \ufb01eld.\nLength Constraints: Minimum length of 1.", "Maximum length of 64.\nAmazon S3 Control API Version 2006-03-01 1094Amazon Simple Storage Service API Reference\nPattern: [a-zA-Z0-9\\-]+\nRequired: Yes\nx-amz-account-id\nThe AWS account ID of the S3 Access Grants instance.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request accepts the following data in XML format.\nUpdateAccessGrantsLocationRequest\nRoot level tag for the UpdateAccessGrantsLocationRequest parameters.\nRequired: Yes\nIAMRoleArn\nThe Amazon Resource Name (ARN) of the IAM role for the registered location. S3 Access Grants \nassumes this role to manage access to the registered location.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 2048.\nPattern: arn:[^:]+:iam::\\d{12}:role/.*\nRequired: Yes\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<UpdateAccessGrantsLocationResult > \n   <CreatedAt >timestamp </CreatedAt > \n   <AccessGrantsLocationId >string</AccessGrantsLocationId > \nAmazon S3 Control API Version 2006-03-01 1095Amazon Simple Storage Service API Reference\n   <AccessGrantsLocationArn >string</AccessGrantsLocationArn > \n   <LocationScope >string</LocationScope > \n   <IAMRoleArn >string</IAMRoleArn >\n</UpdateAccessGrantsLocationResult >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nUpdateAccessGrantsLocationResult\nRoot level tag for the UpdateAccessGrantsLocationResult parameters.\nRequired: Yes\nAccessGrantsLocationArn\nThe Amazon Resource Name (ARN) of the registered location that you are updating.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 2048.\nPattern: arn:[a-z\\-]+:s3:[a-z0-9\\-]+:\\d{12}:access\\-grants\\/location/[a-zA-\nZ0-9\\-]+\nAccessGrantsLocationId\nThe ID of the registered location to which you are granting access. S3 Access Grants assigned \nthis ID when you registered the location. S3 Access Grants assigns the ID default  to the \ndefault location s3:// and assigns an auto-generated ID to other locations that you register.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 64.\nPattern: [a-zA-Z0-9\\-]+\nCreatedAt\nThe date and time when you registered the location.\nType: Timestamp\nAmazon S3 Control API Version 2006-03-01 1096Amazon Simple Storage Service API Reference\nIAMRoleArn\nThe Amazon Resource Name (ARN) of the IAM role of the registered location. S3 Access Grants \nassumes this role to manage access to the registered location.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 2048.\nPattern: arn:[^:]+:iam::\\d{12}:role/.*\nLocationScope\nThe S3 URI path of the location that you are updating.", "You cannot update the scope of the \nregistered location.", "The location scope can be the default S3 location s3:// , the S3 path to a \nbucket s3://<bucket> , or the S3 path to a bucket and pre\ufb01x s3://<bucket>/<prefix> .\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 2000.\nPattern: ^.+$\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1097Amazon Simple Storage Service API Reference\nUpdateJobPriority\nService: Amazon S3 Control\nUpdates an existing S3 Batch Operations job's priority. For more information, see S3 Batch \nOperations  in the Amazon S3 User Guide .\nPermissions\nTo use the UpdateJobPriority  operation, you must have permission to perform the\ns3:UpdateJobPriority  action.\nRelated actions include:\n\u2022CreateJob\n\u2022ListJobs\n\u2022DescribeJob\n\u2022UpdateJobStatus\nRequest Syntax\nPOST /v20180820/jobs/ id/priority?priority= Priority  HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nid\nThe ID for the job whose priority you want to update.\nLength Constraints: Minimum length of 5. Maximum length of 36.\nPattern: [a-zA-Z0-9\\-\\_]+\nRequired: Yes\npriority\nThe priority you want to assign to this job.\nAmazon S3 Control API Version 2006-03-01 1098Amazon Simple Storage Service API Reference\nValid Range: Minimum value of 0. Maximum value of 2147483647.\nRequired: Yes\nx-amz-account-id\nThe AWS account ID associated with the S3 Batch Operations job.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<UpdateJobPriorityResult > \n   <JobId>string</JobId> \n   <Priority >integer</Priority >\n</UpdateJobPriorityResult >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nUpdateJobPriorityResult\nRoot level tag for the UpdateJobPriorityResult parameters.\nRequired: Yes\nJobId\nThe ID for the job whose priority Amazon S3 updated.\nType: String\nAmazon S3 Control API Version 2006-03-01 1099Amazon Simple Storage Service API Reference\nLength Constraints: Minimum length of 5.", "Maximum length of 36.\nPattern: [a-zA-Z0-9\\-\\_]+\nPriority\nThe new priority assigned to the speci\ufb01ed job.\nType: Integer\nValid Range: Minimum value of 0.", "Maximum value of 2147483647.\nErrors\nBadRequestException\nHTTP Status Code: 400\nInternalServiceException\nHTTP Status Code: 500\nNotFoundException\nHTTP Status Code: 400\nTooManyRequestsException\nHTTP Status Code: 400\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\nAmazon S3 Control API Version 2006-03-01 1100Amazon Simple Storage Service API Reference\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1101Amazon Simple Storage Service API Reference\nUpdateJobStatus\nService: Amazon S3 Control\nUpdates the status for the speci\ufb01ed job.", "Use this operation to con\ufb01rm that you want to run a job \nor to cancel an existing job.", "For more information, see S3 Batch Operations  in the Amazon S3 User \nGuide .\nPermissions\nTo use the UpdateJobStatus  operation, you must have permission to perform the\ns3:UpdateJobStatus  action.\nRelated actions include:\n\u2022CreateJob\n\u2022ListJobs\n\u2022DescribeJob\n\u2022UpdateJobStatus\nRequest Syntax\nPOST /v20180820/jobs/ id/status?\nrequestedJobStatus= RequestedJobStatus &statusUpdateReason= StatusUpdateReason  HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nid\nThe ID of the job whose status you want to update.\nLength Constraints: Minimum length of 5. Maximum length of 36.\nPattern: [a-zA-Z0-9\\-\\_]+\nRequired: Yes\nAmazon S3 Control API Version 2006-03-01 1102Amazon Simple Storage Service API Reference\nrequestedJobStatus\nThe status that you want to move the speci\ufb01ed job to.\nValid Values: Cancelled | Ready\nRequired: Yes\nstatusUpdateReason\nA description of the reason why you want to change the speci\ufb01ed job's status.", "This \ufb01eld can be \nany string up to the maximum length.\nLength Constraints: Minimum length of 1.", "Maximum length of 256.\nx-amz-account-id\nThe AWS account ID associated with the S3 Batch Operations job.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<UpdateJobStatusResult > \n   <JobId>string</JobId> \n   <Status>string</Status> \n   <StatusUpdateReason >string</StatusUpdateReason >\n</UpdateJobStatusResult >\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nAmazon S3 Control API Version 2006-03-01 1103Amazon Simple Storage Service API Reference\nUpdateJobStatusResult\nRoot level tag for the UpdateJobStatusResult parameters.\nRequired: Yes\nJobId\nThe ID for the job whose status was updated.\nType: String\nLength Constraints: Minimum length of 5.", "Maximum length of 36.\nPattern: [a-zA-Z0-9\\-\\_]+\nStatus\nThe current status for the speci\ufb01ed job.\nType: String\nValid Values: Active | Cancelled | Cancelling | Complete | Completing \n| Failed | Failing | New | Paused | Pausing | Preparing | Ready | \nSuspended\nStatusUpdateReason\nThe reason that the speci\ufb01ed job's status was updated.\nType: String\nLength Constraints: Minimum length of 1.", "Maximum length of 256.\nErrors\nBadRequestException\nHTTP Status Code: 400\nInternalServiceException\nHTTP Status Code: 500\nAmazon S3 Control API Version 2006-03-01 1104Amazon Simple Storage Service API Reference\nJobStatusException\nHTTP Status Code: 400\nNotFoundException\nHTTP Status Code: 400\nTooManyRequestsException\nHTTP Status Code: 400\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1105Amazon Simple Storage Service API Reference\nUpdateStorageLensGroup\nService: Amazon S3 Control\nUpdates the existing Storage Lens group.\nTo use this operation, you must have the permission to perform the\ns3:UpdateStorageLensGroup  action. For more information about the required Storage Lens \nGroups permissions, see Setting account permissions to use S3 Storage Lens groups.\nFor information about Storage Lens groups errors, see List of Amazon S3 Storage Lens error codes.\nRequest Syntax\nPUT /v20180820/storagelensgroup/ name HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<UpdateStorageLensGroupRequest  xmlns=\"http://awss3control.amazonaws.com/\ndoc/2018-08-20/\"> \n   <StorageLensGroup > \n      <Filter> \n         < And> \n            < MatchAnyPrefix > \n               <Prefix> string</Prefix> \n            </ MatchAnyPrefix > \n            < MatchAnySuffix > \n               <Suffix> string</Suffix> \n            </ MatchAnySuffix > \n            < MatchAnyTag > \n               <Tag> \n                  < Key>string</Key> \n                  < Value>string</Value> \n               </Tag> \n            </ MatchAnyTag > \n            < MatchObjectAge > \n               < DaysGreaterThan >integer</DaysGreaterThan > \n               < DaysLessThan >integer</DaysLessThan > \n            </ MatchObjectAge > \n            < MatchObjectSize > \n               < BytesGreaterThan >long</BytesGreaterThan > \n               < BytesLessThan >long</BytesLessThan > \n            </ MatchObjectSize > \n         </ And> \nAmazon S3 Control API Version 2006-03-01 1106Amazon Simple Storage Service API Reference\n         < MatchAnyPrefix > \n            <Prefix> string</Prefix> \n         </ MatchAnyPrefix > \n         < MatchAnySuffix > \n            <Suffix> string</Suffix> \n         </ MatchAnySuffix > \n         < MatchAnyTag > \n            <Tag> \n               < Key>string</Key> \n               < Value>string</Value> \n            </Tag> \n         </ MatchAnyTag > \n         < MatchObjectAge > \n            < DaysGreaterThan >integer</DaysGreaterThan > \n            < DaysLessThan >integer</DaysLessThan > \n         </ MatchObjectAge > \n         < MatchObjectSize > \n            < BytesGreaterThan >long</BytesGreaterThan > \n            < BytesLessThan >long</BytesLessThan > \n         </ MatchObjectSize > \n         < Or> \n            < MatchAnyPrefix > \n               <Prefix> string</Prefix> \n            </ MatchAnyPrefix > \n            < MatchAnySuffix > \n               <Suffix> string</Suffix> \n            </ MatchAnySuffix > \n            < MatchAnyTag > \n               <Tag> \n                  < Key>string</Key> \n                  < Value>string</Value> \n               </Tag> \n            </ MatchAnyTag > \n            < MatchObjectAge > \n               < DaysGreaterThan >integer</DaysGreaterThan > \n               < DaysLessThan >integer</DaysLessThan > \n            </ MatchObjectAge > \n            < MatchObjectSize > \n               < BytesGreaterThan >long</BytesGreaterThan > \n               < BytesLessThan >long</BytesLessThan > \n            </ MatchObjectSize > \n         </ Or> \n      </ Filter> \n      <Name>string</Name> \nAmazon S3 Control API Version 2006-03-01 1107Amazon Simple Storage Service API Reference\n      <StorageLensGroupArn >string</StorageLensGroupArn > \n   </StorageLensGroup >\n</UpdateStorageLensGroupRequest >\nURI Request Parameters\nThe request uses the following URI parameters.\nname\nThe name of the Storage Lens group that you want to update.\nLength Constraints: Minimum length of 1. Maximum length of 64.\nPattern: [a-zA-Z0-9\\-\\_]+\nRequired: Yes\nx-amz-account-id\nThe AWS account ID of the Storage Lens group owner.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request accepts the following data in XML format.\nUpdateStorageLensGroupRequest\nRoot level tag for the UpdateStorageLensGroupRequest parameters.\nRequired: Yes\nStorageLensGroup\nThe JSON \ufb01le that contains the Storage Lens group con\ufb01guration.\nType: StorageLensGroup data type\nRequired: Yes\nAmazon S3 Control API Version 2006-03-01 1108Amazon Simple Storage Service API Reference\nResponse Syntax\nHTTP/1.1 204\nResponse Elements\nIf the action is successful, the service sends back an HTTP 204 response with an empty HTTP body.\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 on Outposts\nThe following actions are supported by Amazon S3 on Outposts:\n\u2022CreateEndpoint\n\u2022DeleteEndpoint\n\u2022ListEndpoints\n\u2022ListOutpostsWithS3\n\u2022ListSharedEndpoints\nAmazon S3 on Outposts API Version 2006-03-01 1109Amazon Simple Storage Service API Reference\nCreateEndpoint\nService: Amazon S3 on Outposts\nCreates an endpoint and associates it with the speci\ufb01ed Outpost.\nNote\nIt can take up to 5 minutes for this action to \ufb01nish.\nRelated actions include:\n\u2022DeleteEndpoint\n\u2022ListEndpoints\nRequest Syntax\nPOST /S3Outposts/CreateEndpoint HTTP/1.1\nContent-type: application/json\n{ \n   \"AccessType \": \"string\", \n   \"CustomerOwnedIpv4Pool \": \"string\", \n   \"OutpostId \": \"string\", \n   \"SecurityGroupId \": \"string\", \n   \"SubnetId \": \"string\"\n}\nURI Request Parameters\nThe request does not use any URI parameters.\nRequest Body\nThe request accepts the following data in JSON format.\nAccessType\nThe type of access for the network connectivity for the Amazon S3 on Outposts endpoint.", "To \nuse the AWS VPC, choose Private.", "To use the endpoint with an on-premises network, choose\nAmazon S3 on Outposts API Version 2006-03-01 1110Amazon Simple Storage Service API Reference\nCustomerOwnedIp .", "If you choose CustomerOwnedIp , you must also provide the customer-\nowned IP address pool (CoIP pool).\nNote\nPrivate is the default access type value.\nType: String\nValid Values: Private | CustomerOwnedIp\nRequired: No\nCustomerOwnedIpv4Pool\nThe ID of the customer-owned IPv4 address pool (CoIP pool) for the endpoint.", "IP addresses are \nallocated from this pool for the endpoint.\nType: String\nPattern: ^ipv4pool-coip-([0-9a-f]{17})$\nRequired: No\nOutpostId\nThe ID of the AWS Outposts.\nType: String\nPattern: ^(op-[a-f0-9]{17}|\\d{12}|ec2)$\nRequired: Yes\nSecurityGroupId\nThe ID of the security group to use with the endpoint.\nType: String\nPattern: ^sg-([0-9a-f]{8}|[0-9a-f]{17})$\nRequired: Yes\nAmazon S3 on Outposts API Version 2006-03-01 1111Amazon Simple Storage Service API Reference\nSubnetId\nThe ID of the subnet in the selected VPC. The endpoint subnet must belong to the Outpost that \nhas Amazon S3 on Outposts provisioned.\nType: String\nPattern: ^subnet-([0-9a-f]{8}|[0-9a-f]{17})$\nRequired: Yes\nResponse Syntax\nHTTP/1.1 200\nContent-type: application/json\n{ \n   \"EndpointArn \": \"string\"\n}\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in JSON format by the service.\nEndpointArn\nThe Amazon Resource Name (ARN) of the endpoint.\nType: String\nPattern: ^arn:(aws|aws-cn|aws-us-gov|aws-iso|aws-iso-b):s3-outposts:[a-\nz\\-0-9]*:[0-9]{12}:outpost/(op-[a-f0-9]{17}|ec2)/endpoint/[a-zA-Z0-9]\n{19}$\nErrors\nAccessDeniedException\nAccess was denied for this action.\nAmazon S3 on Outposts API Version 2006-03-01 1112Amazon Simple Storage Service API Reference\nHTTP Status Code: 403\nCon\ufb02ictException\nThere was a con\ufb02ict with this action, and it could not be completed.\nHTTP Status Code: 409\nInternalServerException\nThere was an exception with the internal server.\nHTTP Status Code: 500\nOutpostO\ufb04ineException\nThe service link connection to your Outposts home Region is down. Check your connection and \ntry again.\nHTTP Status Code: 400\nResourceNotFoundException\nThe requested resource was not found.\nHTTP Status Code: 404\nThrottlingException\nThe request was denied due to request throttling.\nHTTP Status Code: 429\nValidationException\nThere was an exception validating this data.\nHTTP Status Code: 400\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\nAmazon S3 on Outposts API Version 2006-03-01 1113Amazon Simple Storage Service API Reference\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 on Outposts API Version 2006-03-01 1114Amazon Simple Storage Service API Reference\nDeleteEndpoint\nService: Amazon S3 on Outposts\nDeletes an endpoint.\nNote\nIt can take up to 5 minutes for this action to \ufb01nish.\nRelated actions include:\n\u2022CreateEndpoint\n\u2022ListEndpoints\nRequest Syntax\nDELETE /S3Outposts/DeleteEndpoint?endpointId= EndpointId &outpostId= OutpostId  HTTP/1.1\nURI Request Parameters\nThe request uses the following URI parameters.\nEndpointId\nThe ID of the endpoint.\nPattern: ^[a-zA-Z0-9]{19}$\nRequired: Yes\nOutpostId\nThe ID of the AWS Outposts.\nPattern: ^(op-[a-f0-9]{17}|\\d{12}|ec2)$\nRequired: Yes\nAmazon S3 on Outposts API Version 2006-03-01 1115Amazon Simple Storage Service API Reference\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\nErrors\nAccessDeniedException\nAccess was denied for this action.\nHTTP Status Code: 403\nInternalServerException\nThere was an exception with the internal server.\nHTTP Status Code: 500\nOutpostO\ufb04ineException\nThe service link connection to your Outposts home Region is down. Check your connection and \ntry again.\nHTTP Status Code: 400\nResourceNotFoundException\nThe requested resource was not found.\nHTTP Status Code: 404\nThrottlingException\nThe request was denied due to request throttling.\nHTTP Status Code: 429\nAmazon S3 on Outposts API Version 2006-03-01 1116Amazon Simple Storage Service API Reference\nValidationException\nThere was an exception validating this data.\nHTTP Status Code: 400\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 on Outposts API Version 2006-03-01 1117Amazon Simple Storage Service API Reference\nListEndpoints\nService: Amazon S3 on Outposts\nLists endpoints associated with the speci\ufb01ed Outpost.\nRelated actions include:\n\u2022CreateEndpoint\n\u2022DeleteEndpoint\nRequest Syntax\nGET /S3Outposts/ListEndpoints?maxResults= MaxResults &nextToken= NextToken  HTTP/1.1\nURI Request Parameters\nThe request uses the following URI parameters.\nMaxResults\nThe maximum number of endpoints that will be returned in the response.\nValid Range: Minimum value of 0.", "Maximum value of 100.\nNextToken\nIf a previous response from this operation included a NextToken  value, provide that value here \nto retrieve the next page of results.\nLength Constraints: Minimum length of 1.", "Maximum length of 1024.\nPattern: ^[A-Za-z0-9\\+\\:\\/\\=\\?\\#-_]+$\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\nContent-type: application/json\nAmazon S3 on Outposts API Version 2006-03-01 1118Amazon Simple Storage Service API Reference\n{ \n   \"Endpoints \": [  \n      {  \n         \" AccessType \": \"string\", \n         \" CidrBlock \": \"string\", \n         \" CreationTime \": number, \n         \" CustomerOwnedIpv4Pool \": \"string\", \n         \" EndpointArn \": \"string\", \n         \" FailedReason \": {  \n            \" ErrorCode \": \"string\", \n            \" Message\": \"string\" \n         }, \n         \" NetworkInterfaces \": [  \n            {  \n               \" NetworkInterfaceId \": \"string\" \n            } \n         ], \n         \" OutpostsId \": \"string\", \n         \" SecurityGroupId \": \"string\", \n         \" Status\": \"string\", \n         \" SubnetId \": \"string\", \n         \" VpcId\": \"string\" \n      } \n   ], \n   \"NextToken \": \"string\"\n}\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in JSON format by the service.\nEndpoints\nThe list of endpoints associated with the speci\ufb01ed Outpost.\nType: Array of Endpoint  objects\nNextToken\nIf the number of endpoints associated with the speci\ufb01ed Outpost exceeds MaxResults , you \ncan include this value in subsequent calls to this operation to retrieve more results.\nAmazon S3 on Outposts API Version 2006-03-01 1119Amazon Simple Storage Service API Reference\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 1024.\nPattern: ^[A-Za-z0-9\\+\\:\\/\\=\\?\\#-_]+$\nErrors\nAccessDeniedException\nAccess was denied for this action.\nHTTP Status Code: 403\nInternalServerException\nThere was an exception with the internal server.\nHTTP Status Code: 500\nResourceNotFoundException\nThe requested resource was not found.\nHTTP Status Code: 404\nThrottlingException\nThe request was denied due to request throttling.\nHTTP Status Code: 429\nValidationException\nThere was an exception validating this data.\nHTTP Status Code: 400\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\nAmazon S3 on Outposts API Version 2006-03-01 1120Amazon Simple Storage Service API Reference\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 on Outposts API Version 2006-03-01 1121Amazon Simple Storage Service API Reference\nListOutpostsWithS3\nService: Amazon S3 on Outposts\nLists the Outposts with S3 on Outposts capacity for your AWS account. Includes S3 on Outposts \nthat you have access to as the Outposts owner, or as a shared user from Resource Access Manager \n(RAM).\nRequest Syntax\nGET /S3Outposts/ListOutpostsWithS3?maxResults= MaxResults &nextToken= NextToken  HTTP/1.1\nURI Request Parameters\nThe request uses the following URI parameters.\nMaxResults\nThe maximum number of Outposts to return.", "The limit is 100.\nValid Range: Minimum value of 0.", "Maximum value of 100.\nNextToken\nWhen you can get additional results from the ListOutpostsWithS3  call, a NextToken\nparameter is returned in the output.", "You can then pass in a subsequent command to the\nNextToken  parameter to continue listing additional Outposts.\nLength Constraints: Minimum length of 1.", "Maximum length of 1024.\nPattern: ^[A-Za-z0-9\\+\\:\\/\\=\\?\\#-_]+$\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\nContent-type: application/json\n{ \n   \"NextToken \": \"string\", \nAmazon S3 on Outposts API Version 2006-03-01 1122Amazon Simple Storage Service API Reference\n   \"Outposts \": [  \n      {  \n         \" CapacityInBytes \": number, \n         \" OutpostArn \": \"string\", \n         \" OutpostId \": \"string\", \n         \" OwnerId\": \"string\", \n         \" S3OutpostArn \": \"string\" \n      } \n   ]\n}\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in JSON format by the service.\nNextToken\nReturns a token that you can use to call ListOutpostsWithS3  again and receive additional \nresults, if there are any.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 1024.\nPattern: ^[A-Za-z0-9\\+\\:\\/\\=\\?\\#-_]+$\nOutposts\nReturns the list of Outposts that have the following characteristics:\n\u2022outposts that have S3 provisioned\n\u2022outposts that are Active (not pending any provisioning nor decommissioned)\n\u2022outposts to which the the calling AWS account has access\nType: Array of Outpost  objects\nErrors\nAccessDeniedException\nAccess was denied for this action.\nAmazon S3 on Outposts API Version 2006-03-01 1123Amazon Simple Storage Service API Reference\nHTTP Status Code: 403\nInternalServerException\nThere was an exception with the internal server.\nHTTP Status Code: 500\nThrottlingException\nThe request was denied due to request throttling.\nHTTP Status Code: 429\nValidationException\nThere was an exception validating this data.\nHTTP Status Code: 400\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nAmazon S3 on Outposts API Version 2006-03-01 1124Amazon Simple Storage Service API Reference\nListSharedEndpoints\nService: Amazon S3 on Outposts\nLists all endpoints associated with an Outpost that has been shared by AWS Resource Access \nManager (RAM).\nRelated actions include:\n\u2022CreateEndpoint\n\u2022DeleteEndpoint\nRequest Syntax\nGET /S3Outposts/ListSharedEndpoints?\nmaxResults= MaxResults &nextToken= NextToken &outpostId= OutpostId  HTTP/1.1\nURI Request Parameters\nThe request uses the following URI parameters.\nMaxResults\nThe maximum number of endpoints that will be returned in the response.\nValid Range: Minimum value of 0.", "Maximum value of 100.\nNextToken\nIf a previous response from this operation included a NextToken  value, you can provide that \nvalue here to retrieve the next page of results.\nLength Constraints: Minimum length of 1.", "Maximum length of 1024.\nPattern: ^[A-Za-z0-9\\+\\:\\/\\=\\?\\#-_]+$\nOutpostId\nThe ID of the AWS Outpost.\nPattern: ^(op-[a-f0-9]{17}|\\d{12}|ec2)$\nRequired: Yes\nAmazon S3 on Outposts API Version 2006-03-01 1125Amazon Simple Storage Service API Reference\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\nContent-type: application/json\n{ \n   \"Endpoints \": [  \n      {  \n         \" AccessType \": \"string\", \n         \" CidrBlock \": \"string\", \n         \" CreationTime \": number, \n         \" CustomerOwnedIpv4Pool \": \"string\", \n         \" EndpointArn \": \"string\", \n         \" FailedReason \": {  \n            \" ErrorCode \": \"string\", \n            \" Message\": \"string\" \n         }, \n         \" NetworkInterfaces \": [  \n            {  \n               \" NetworkInterfaceId \": \"string\" \n            } \n         ], \n         \" OutpostsId \": \"string\", \n         \" SecurityGroupId \": \"string\", \n         \" Status\": \"string\", \n         \" SubnetId \": \"string\", \n         \" VpcId\": \"string\" \n      } \n   ], \n   \"NextToken \": \"string\"\n}\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in JSON format by the service.\nAmazon S3 on Outposts API Version 2006-03-01 1126Amazon Simple Storage Service API Reference\nEndpoints\nThe list of endpoints associated with the speci\ufb01ed Outpost that have been shared by AWS \nResource Access Manager (RAM).\nType: Array of Endpoint  objects\nNextToken\nIf the number of endpoints associated with the speci\ufb01ed Outpost exceeds MaxResults , you \ncan include this value in subsequent calls to this operation to retrieve more results.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 1024.\nPattern: ^[A-Za-z0-9\\+\\:\\/\\=\\?\\#-_]+$\nErrors\nAccessDeniedException\nAccess was denied for this action.\nHTTP Status Code: 403\nInternalServerException\nThere was an exception with the internal server.\nHTTP Status Code: 500\nResourceNotFoundException\nThe requested resource was not found.\nHTTP Status Code: 404\nThrottlingException\nThe request was denied due to request throttling.\nHTTP Status Code: 429\nValidationException\nThere was an exception validating this data.\nAmazon S3 on Outposts API Version 2006-03-01 1127Amazon Simple Storage Service API Reference\nHTTP Status Code: 400\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS Command Line Interface\n\u2022AWS SDK for .NET\n\u2022AWS SDK for C++\n\u2022AWS SDK for Go v2\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for JavaScript V3\n\u2022AWS SDK for PHP V3\n\u2022AWS SDK for Python\n\u2022AWS SDK for Ruby V3\nData Types\nThe following data types are supported by Amazon S3:\n\u2022AbortIncompleteMultipartUpload\n\u2022AccelerateCon\ufb01guration\n\u2022AccessControlPolicy\n\u2022AccessControlTranslation\n\u2022AnalyticsAndOperator\n\u2022AnalyticsCon\ufb01guration\n\u2022AnalyticsExportDestination\n\u2022AnalyticsFilter\n\u2022AnalyticsS3BucketDestination\n\u2022Bucket\n\u2022BucketInfo\nData Types API Version 2006-03-01 1128Amazon Simple Storage Service API Reference\n\u2022BucketLifecycleCon\ufb01guration\n\u2022BucketLoggingStatus\n\u2022Checksum\n\u2022CloudFunctionCon\ufb01guration\n\u2022CommonPre\ufb01x\n\u2022CompletedMultipartUpload\n\u2022CompletedPart\n\u2022Condition\n\u2022ContinuationEvent\n\u2022CopyObjectResult\n\u2022CopyPartResult\n\u2022CORSCon\ufb01guration\n\u2022CORSRule\n\u2022CreateBucketCon\ufb01guration\n\u2022CSVInput\n\u2022CSVOutput\n\u2022DefaultRetention\n\u2022Delete\n\u2022DeletedObject\n\u2022DeleteMarkerEntry\n\u2022DeleteMarkerReplication\n\u2022Destination\n\u2022Encryption\n\u2022EncryptionCon\ufb01guration\n\u2022EndEvent\n\u2022Error\n\u2022ErrorDocument\n\u2022EventBridgeCon\ufb01guration\n\u2022ExistingObjectReplication\n\u2022FilterRule\nData Types API Version 2006-03-01 1129Amazon Simple Storage Service API Reference\n\u2022GetObjectAttributesParts\n\u2022GlacierJobParameters\n\u2022Grant\n\u2022Grantee\n\u2022IndexDocument\n\u2022Initiator\n\u2022InputSerialization\n\u2022IntelligentTieringAndOperator\n\u2022IntelligentTieringCon\ufb01guration\n\u2022IntelligentTieringFilter\n\u2022InventoryCon\ufb01guration\n\u2022InventoryDestination\n\u2022InventoryEncryption\n\u2022InventoryFilter\n\u2022InventoryS3BucketDestination\n\u2022InventorySchedule\n\u2022JSONInput\n\u2022JSONOutput\n\u2022LambdaFunctionCon\ufb01guration\n\u2022LifecycleCon\ufb01guration\n\u2022LifecycleExpiration\n\u2022LifecycleRule\n\u2022LifecycleRuleAndOperator\n\u2022LifecycleRuleFilter\n\u2022LocationInfo\n\u2022LoggingEnabled\n\u2022MetadataEntry\n\u2022Metrics\n\u2022MetricsAndOperator\n\u2022MetricsCon\ufb01guration\nData Types API Version 2006-03-01 1130Amazon Simple Storage Service API Reference\n\u2022MetricsFilter\n\u2022MultipartUpload\n\u2022NoncurrentVersionExpiration\n\u2022NoncurrentVersionTransition\n\u2022Noti\ufb01cationCon\ufb01guration\n\u2022Noti\ufb01cationCon\ufb01gurationDeprecated\n\u2022Noti\ufb01cationCon\ufb01gurationFilter\n\u2022Object\n\u2022ObjectIdenti\ufb01er\n\u2022ObjectLockCon\ufb01guration\n\u2022ObjectLockLegalHold\n\u2022ObjectLockRetention\n\u2022ObjectLockRule\n\u2022ObjectPart\n\u2022ObjectVersion\n\u2022OutputLocation\n\u2022OutputSerialization\n\u2022Owner\n\u2022OwnershipControls\n\u2022OwnershipControlsRule\n\u2022ParquetInput\n\u2022Part\n\u2022PartitionedPre\ufb01x\n\u2022PolicyStatus\n\u2022Progress\n\u2022ProgressEvent\n\u2022PublicAccessBlockCon\ufb01guration\n\u2022QueueCon\ufb01guration\n\u2022QueueCon\ufb01gurationDeprecated\n\u2022RecordsEvent\nData Types API Version 2006-03-01 1131Amazon Simple Storage Service API Reference\n\u2022Redirect\n\u2022RedirectAllRequestsTo\n\u2022ReplicaModi\ufb01cations\n\u2022ReplicationCon\ufb01guration\n\u2022ReplicationRule\n\u2022ReplicationRuleAndOperator\n\u2022ReplicationRuleFilter\n\u2022ReplicationTime\n\u2022ReplicationTimeValue\n\u2022RequestPaymentCon\ufb01guration\n\u2022RequestProgress\n\u2022RestoreRequest\n\u2022RestoreStatus\n\u2022RoutingRule\n\u2022Rule\n\u2022S3KeyFilter\n\u2022S3Location\n\u2022ScanRange\n\u2022SelectObjectContentEventStream\n\u2022SelectParameters\n\u2022ServerSideEncryptionByDefault\n\u2022ServerSideEncryptionCon\ufb01guration\n\u2022ServerSideEncryptionRule\n\u2022SessionCredentials\n\u2022SimplePre\ufb01x\n\u2022SourceSelectionCriteria\n\u2022SSEKMS\n\u2022SseKmsEncryptedObjects\n\u2022SSES3\n\u2022Stats\nData Types API Version 2006-03-01 1132Amazon Simple Storage Service API Reference\n\u2022StatsEvent\n\u2022StorageClassAnalysis\n\u2022StorageClassAnalysisDataExport\n\u2022Tag\n\u2022Tagging\n\u2022TargetGrant\n\u2022TargetObjectKeyFormat\n\u2022Tiering\n\u2022TopicCon\ufb01guration\n\u2022TopicCon\ufb01gurationDeprecated\n\u2022Transition\n\u2022VersioningCon\ufb01guration\n\u2022WebsiteCon\ufb01guration\nThe following data types are supported by Amazon S3 Control:\n\u2022AbortIncompleteMultipartUpload\n\u2022AccessControlTranslation\n\u2022AccessGrantsLocationCon\ufb01guration\n\u2022AccessPoint\n\u2022AccountLevel\n\u2022ActivityMetrics\n\u2022AdvancedCostOptimizationMetrics\n\u2022AdvancedDataProtectionMetrics\n\u2022AsyncErrorDetails\n\u2022AsyncOperation\n\u2022AsyncRequestParameters\n\u2022AsyncResponseDetails\n\u2022AwsLambdaTransformation\n\u2022BucketLevel\n\u2022CloudWatchMetrics\nData Types API Version 2006-03-01 1133Amazon Simple Storage Service API Reference\n\u2022CreateBucketCon\ufb01guration\n\u2022CreateMultiRegionAccessPointInput\n\u2022Credentials\n\u2022DeleteMarkerReplication\n\u2022DeleteMultiRegionAccessPointInput\n\u2022Destination\n\u2022DetailedStatusCodesMetrics\n\u2022EncryptionCon\ufb01guration\n\u2022EstablishedMultiRegionAccessPointPolicy\n\u2022Exclude\n\u2022ExistingObjectReplication\n\u2022GeneratedManifestEncryption\n\u2022Grantee\n\u2022Include\n\u2022JobDescriptor\n\u2022JobFailure\n\u2022JobListDescriptor\n\u2022JobManifest\n\u2022JobManifestGenerator\n\u2022JobManifestGeneratorFilter\n\u2022JobManifestLocation\n\u2022JobManifestSpec\n\u2022JobOperation\n\u2022JobProgressSummary\n\u2022JobReport\n\u2022JobTimers\n\u2022KeyNameConstraint\n\u2022LambdaInvokeOperation\n\u2022LifecycleCon\ufb01guration\n\u2022LifecycleExpiration\nData Types API Version 2006-03-01 1134Amazon Simple Storage Service API Reference\n\u2022LifecycleRule\n\u2022LifecycleRuleAndOperator\n\u2022LifecycleRuleFilter\n\u2022ListAccessGrantEntry\n\u2022ListAccessGrantsInstanceEntry\n\u2022ListAccessGrantsLocationsEntry\n\u2022ListCallerAccessGrantsEntry\n\u2022ListStorageLensCon\ufb01gurationEntry\n\u2022ListStorageLensGroupEntry\n\u2022MatchObjectAge\n\u2022MatchObjectSize\n\u2022Metrics\n\u2022MultiRegionAccessPointPolicyDocument\n\u2022MultiRegionAccessPointRegionalResponse\n\u2022MultiRegionAccessPointReport\n\u2022MultiRegionAccessPointRoute\n\u2022MultiRegionAccessPointsAsyncResponse\n\u2022NoncurrentVersionExpiration\n\u2022NoncurrentVersionTransition\n\u2022ObjectLambdaAccessPoint\n\u2022ObjectLambdaAccessPointAlias\n\u2022ObjectLambdaCon\ufb01guration\n\u2022ObjectLambdaContentTransformation\n\u2022ObjectLambdaTransformationCon\ufb01guration\n\u2022PolicyStatus\n\u2022Pre\ufb01xLevel\n\u2022Pre\ufb01xLevelStorageMetrics\n\u2022ProposedMultiRegionAccessPointPolicy\n\u2022PublicAccessBlockCon\ufb01guration\n\u2022PutMultiRegionAccessPointPolicyInput\nData Types API Version 2006-03-01 1135Amazon Simple Storage Service API Reference\n\u2022Region\n\u2022RegionalBucket\n\u2022RegionReport\n\u2022ReplicaModi\ufb01cations\n\u2022ReplicationCon\ufb01guration\n\u2022ReplicationRule\n\u2022ReplicationRuleAndOperator\n\u2022ReplicationRuleFilter\n\u2022ReplicationTime\n\u2022ReplicationTimeValue\n\u2022S3AccessControlList\n\u2022S3AccessControlPolicy\n\u2022S3BucketDestination\n\u2022S3CopyObjectOperation\n\u2022S3DeleteObjectTaggingOperation\n\u2022S3GeneratedManifestDescriptor\n\u2022S3Grant\n\u2022S3Grantee\n\u2022S3InitiateRestoreObjectOperation\n\u2022S3JobManifestGenerator\n\u2022S3ManifestOutputLocation\n\u2022S3ObjectLockLegalHold\n\u2022S3ObjectMetadata\n\u2022S3ObjectOwner\n\u2022S3ReplicateObjectOperation\n\u2022S3Retention\n\u2022S3SetObjectAclOperation\n\u2022S3SetObjectLegalHoldOperation\n\u2022S3SetObjectRetentionOperation\n\u2022S3SetObjectTaggingOperation\nData Types API Version 2006-03-01 1136Amazon Simple Storage Service API Reference\n\u2022S3Tag\n\u2022SelectionCriteria\n\u2022SourceSelectionCriteria\n\u2022SSEKMS\n\u2022SseKmsEncryptedObjects\n\u2022SSEKMSEncryption\n\u2022SSES3\n\u2022SSES3Encryption\n\u2022StorageLensAwsOrg\n\u2022StorageLensCon\ufb01guration\n\u2022StorageLensDataExport\n\u2022StorageLensDataExportEncryption\n\u2022StorageLensGroup\n\u2022StorageLensGroupAndOperator\n\u2022StorageLensGroupFilter\n\u2022StorageLensGroupLevel\n\u2022StorageLensGroupLevelSelectionCriteria\n\u2022StorageLensGroupOrOperator\n\u2022StorageLensTag\n\u2022Tag\n\u2022Tagging\n\u2022Transition\n\u2022VersioningCon\ufb01guration\n\u2022VpcCon\ufb01guration\nThe following data types are supported by Amazon S3 on Outposts:\n\u2022Endpoint\n\u2022FailedReason\n\u2022NetworkInterface\n\u2022Outpost\nData Types API Version 2006-03-01 1137Amazon Simple Storage Service API Reference\nAmazon S3\nThe following data types are supported by Amazon S3:\n\u2022AbortIncompleteMultipartUpload\n\u2022AccelerateCon\ufb01guration\n\u2022AccessControlPolicy\n\u2022AccessControlTranslation\n\u2022AnalyticsAndOperator\n\u2022AnalyticsCon\ufb01guration\n\u2022AnalyticsExportDestination\n\u2022AnalyticsFilter\n\u2022AnalyticsS3BucketDestination\n\u2022Bucket\n\u2022BucketInfo\n\u2022BucketLifecycleCon\ufb01guration\n\u2022BucketLoggingStatus\n\u2022Checksum\n\u2022CloudFunctionCon\ufb01guration\n\u2022CommonPre\ufb01x\n\u2022CompletedMultipartUpload\n\u2022CompletedPart\n\u2022Condition\n\u2022ContinuationEvent\n\u2022CopyObjectResult\n\u2022CopyPartResult\n\u2022CORSCon\ufb01guration\n\u2022CORSRule\n\u2022CreateBucketCon\ufb01guration\n\u2022CSVInput\n\u2022CSVOutput\nAmazon S3 API Version 2006-03-01 1138Amazon Simple Storage Service API Reference\n\u2022DefaultRetention\n\u2022Delete\n\u2022DeletedObject\n\u2022DeleteMarkerEntry\n\u2022DeleteMarkerReplication\n\u2022Destination\n\u2022Encryption\n\u2022EncryptionCon\ufb01guration\n\u2022EndEvent\n\u2022Error\n\u2022ErrorDocument\n\u2022EventBridgeCon\ufb01guration\n\u2022ExistingObjectReplication\n\u2022FilterRule\n\u2022GetObjectAttributesParts\n\u2022GlacierJobParameters\n\u2022Grant\n\u2022Grantee\n\u2022IndexDocument\n\u2022Initiator\n\u2022InputSerialization\n\u2022IntelligentTieringAndOperator\n\u2022IntelligentTieringCon\ufb01guration\n\u2022IntelligentTieringFilter\n\u2022InventoryCon\ufb01guration\n\u2022InventoryDestination\n\u2022InventoryEncryption\n\u2022InventoryFilter\n\u2022InventoryS3BucketDestination\n\u2022InventorySchedule\nAmazon S3 API Version 2006-03-01 1139Amazon Simple Storage Service API Reference\n\u2022JSONInput\n\u2022JSONOutput\n\u2022LambdaFunctionCon\ufb01guration\n\u2022LifecycleCon\ufb01guration\n\u2022LifecycleExpiration\n\u2022LifecycleRule\n\u2022LifecycleRuleAndOperator\n\u2022LifecycleRuleFilter\n\u2022LocationInfo\n\u2022LoggingEnabled\n\u2022MetadataEntry\n\u2022Metrics\n\u2022MetricsAndOperator\n\u2022MetricsCon\ufb01guration\n\u2022MetricsFilter\n\u2022MultipartUpload\n\u2022NoncurrentVersionExpiration\n\u2022NoncurrentVersionTransition\n\u2022Noti\ufb01cationCon\ufb01guration\n\u2022Noti\ufb01cationCon\ufb01gurationDeprecated\n\u2022Noti\ufb01cationCon\ufb01gurationFilter\n\u2022Object\n\u2022ObjectIdenti\ufb01er\n\u2022ObjectLockCon\ufb01guration\n\u2022ObjectLockLegalHold\n\u2022ObjectLockRetention\n\u2022ObjectLockRule\n\u2022ObjectPart\n\u2022ObjectVersion\n\u2022OutputLocation\nAmazon S3 API Version 2006-03-01 1140Amazon Simple Storage Service API Reference\n\u2022OutputSerialization\n\u2022Owner\n\u2022OwnershipControls\n\u2022OwnershipControlsRule\n\u2022ParquetInput\n\u2022Part\n\u2022PartitionedPre\ufb01x\n\u2022PolicyStatus\n\u2022Progress\n\u2022ProgressEvent\n\u2022PublicAccessBlockCon\ufb01guration\n\u2022QueueCon\ufb01guration\n\u2022QueueCon\ufb01gurationDeprecated\n\u2022RecordsEvent\n\u2022Redirect\n\u2022RedirectAllRequestsTo\n\u2022ReplicaModi\ufb01cations\n\u2022ReplicationCon\ufb01guration\n\u2022ReplicationRule\n\u2022ReplicationRuleAndOperator\n\u2022ReplicationRuleFilter\n\u2022ReplicationTime\n\u2022ReplicationTimeValue\n\u2022RequestPaymentCon\ufb01guration\n\u2022RequestProgress\n\u2022RestoreRequest\n\u2022RestoreStatus\n\u2022RoutingRule\n\u2022Rule\n\u2022S3KeyFilter\nAmazon S3 API Version 2006-03-01 1141Amazon Simple Storage Service API Reference\n\u2022S3Location\n\u2022ScanRange\n\u2022SelectObjectContentEventStream\n\u2022SelectParameters\n\u2022ServerSideEncryptionByDefault\n\u2022ServerSideEncryptionCon\ufb01guration\n\u2022ServerSideEncryptionRule\n\u2022SessionCredentials\n\u2022SimplePre\ufb01x\n\u2022SourceSelectionCriteria\n\u2022SSEKMS\n\u2022SseKmsEncryptedObjects\n\u2022SSES3\n\u2022Stats\n\u2022StatsEvent\n\u2022StorageClassAnalysis\n\u2022StorageClassAnalysisDataExport\n\u2022Tag\n\u2022Tagging\n\u2022TargetGrant\n\u2022TargetObjectKeyFormat\n\u2022Tiering\n\u2022TopicCon\ufb01guration\n\u2022TopicCon\ufb01gurationDeprecated\n\u2022Transition\n\u2022VersioningCon\ufb01guration\n\u2022WebsiteCon\ufb01guration\nAmazon S3 API Version 2006-03-01 1142Amazon Simple Storage Service API Reference\nAbortIncompleteMultipartUpload\nService: Amazon S3\nSpeci\ufb01es the days since the initiation of an incomplete multipart upload that Amazon S3 will \nwait before permanently removing all parts of the upload. For more information, see  Aborting \nIncomplete Multipart Uploads Using a Bucket Lifecycle Con\ufb01guration in the Amazon S3 User Guide .\nContents\nDaysAfterInitiation\nSpeci\ufb01es the number of days after which Amazon S3 aborts an incomplete multipart upload.\nType: Integer\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1143Amazon Simple Storage Service API Reference\nAccelerateCon\ufb01guration\nService: Amazon S3\nCon\ufb01gures the transfer acceleration state for an Amazon S3 bucket. For more information, see\nAmazon S3 Transfer Acceleration in the Amazon S3 User Guide .\nContents\nStatus\nSpeci\ufb01es the transfer acceleration status of the bucket.\nType: String\nValid Values: Enabled | Suspended\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1144Amazon Simple Storage Service API Reference\nAccessControlPolicy\nService: Amazon S3\nContains the elements that set the ACL permissions for an object per grantee.\nContents\nGrants\nA list of grants.\nType: Array of Grant  data types\nRequired: No\nOwner\nContainer for the bucket owner's display name and ID.\nType: Owner  data type\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1145Amazon Simple Storage Service API Reference\nAccessControlTranslation\nService: Amazon S3\nA container for information about access control for replicas.\nContents\nOwner\nSpeci\ufb01es the replica ownership. For default and valid values, see PUT bucket replication in the\nAmazon S3 API Reference.\nType: String\nValid Values: Destination\nRequired: Yes\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1146Amazon Simple Storage Service API Reference\nAnalyticsAndOperator\nService: Amazon S3\nA conjunction (logical AND) of predicates, which is used in evaluating a metrics \ufb01lter. The operator \nmust have at least two predicates in any combination, and an object must match all of the \npredicates for the \ufb01lter to apply.\nContents\nPre\ufb01x\nThe pre\ufb01x to use when evaluating an AND predicate: The pre\ufb01x that an object must have to be \nincluded in the metrics results.\nType: String\nRequired: No\nTags\nThe list of tags to use when evaluating an AND predicate.\nType: Array of Tag data types\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1147Amazon Simple Storage Service API Reference\nAnalyticsCon\ufb01guration\nService: Amazon S3\nSpeci\ufb01es the con\ufb01guration and any analyses for the analytics \ufb01lter of an Amazon S3 bucket.\nContents\nId\nThe ID that identi\ufb01es the analytics con\ufb01guration.\nType: String\nRequired: Yes\nStorageClassAnalysis\nContains data related to access patterns to be collected and made available to analyze the \ntradeo\ufb00s between di\ufb00erent storage classes.\nType: StorageClassAnalysis  data type\nRequired: Yes\nFilter\nThe \ufb01lter used to describe a set of objects for analyses.", "A \ufb01lter must have exactly one pre\ufb01x, \none tag, or one conjunction (AnalyticsAndOperator).", "If no \ufb01lter is provided, all objects will be \nconsidered in any analysis.\nType: AnalyticsFilter data type\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1148Amazon Simple Storage Service API Reference\nAmazon S3 API Version 2006-03-01 1149Amazon Simple Storage Service API Reference\nAnalyticsExportDestination\nService: Amazon S3\nWhere to publish the analytics results.\nContents\nS3BucketDestination\nA destination signifying output to an S3 bucket.\nType: AnalyticsS3BucketDestination data type\nRequired: Yes\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1150Amazon Simple Storage Service API Reference\nAnalyticsFilter\nService: Amazon S3\nThe \ufb01lter used to describe a set of objects for analyses.", "A \ufb01lter must have exactly one pre\ufb01x, \none tag, or one conjunction (AnalyticsAndOperator). If no \ufb01lter is provided, all objects will be \nconsidered in any analysis.\nContents\nAnd\nA conjunction (logical AND) of predicates, which is used in evaluating an analytics \ufb01lter.", "The \noperator must have at least two predicates.\nType: AnalyticsAndOperator data type\nRequired: No\nPre\ufb01x\nThe pre\ufb01x to use when evaluating an analytics \ufb01lter.\nType: String\nRequired: No\nTag\nThe tag to use when evaluating an analytics \ufb01lter.\nType: Tag data type\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1151Amazon Simple Storage Service API Reference\nAmazon S3 API Version 2006-03-01 1152Amazon Simple Storage Service API Reference\nAnalyticsS3BucketDestination\nService: Amazon S3\nContains information about where to publish the analytics results.\nContents\nBucket\nThe Amazon Resource Name (ARN) of the bucket to which data is exported.\nType: String\nRequired: Yes\nFormat\nSpeci\ufb01es the \ufb01le format used when exporting data to Amazon S3.\nType: String\nValid Values: CSV\nRequired: Yes\nBucketAccountId\nThe account ID that owns the destination S3 bucket. If no account ID is provided, the owner is \nnot validated before exporting data.\nNote\nAlthough this value is optional, we strongly recommend that you set it to help prevent \nproblems if the destination bucket ownership changes.\nType: String\nRequired: No\nPre\ufb01x\nThe pre\ufb01x to use when exporting data.", "The pre\ufb01x is prepended to all results.\nAmazon S3 API Version 2006-03-01 1153Amazon Simple Storage Service API Reference\nType: String\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1154Amazon Simple Storage Service API Reference\nBucket\nService: Amazon S3\nIn terms of implementation, a Bucket is a resource.\nContents\nBucketRegion\nBucketRegion  indicates the AWS region where the bucket is located.", "If the request contains at \nleast one valid parameter, it is included in the response.\nType: String\nRequired: No\nCreationDate\nDate the bucket was created. This date can change when making changes to your bucket, such \nas editing its bucket policy.\nType: Timestamp\nRequired: No\nName\nThe name of the bucket.\nType: String\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1155Amazon Simple Storage Service API Reference\nBucketInfo\nService: Amazon S3\nSpeci\ufb01es the information about the bucket that will be created. For more information about \ndirectory buckets, see Directory buckets in the Amazon S3 User Guide .\nNote\nThis functionality is only supported by directory buckets.\nContents\nDataRedundancy\nThe number of Availability Zone that's used for redundancy for the bucket.\nType: String\nValid Values: SingleAvailabilityZone\nRequired: No\nType\nThe type of bucket.\nType: String\nValid Values: Directory\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1156Amazon Simple Storage Service API Reference\nAmazon S3 API Version 2006-03-01 1157Amazon Simple Storage Service API Reference\nBucketLifecycleCon\ufb01guration\nService: Amazon S3\nSpeci\ufb01es the lifecycle con\ufb01guration for objects in an Amazon S3 bucket. For more information, see\nObject Lifecycle Management in the Amazon S3 User Guide .\nContents\nRules\nA lifecycle rule for individual objects in an Amazon S3 bucket.\nType: Array of LifecycleRule data types\nRequired: Yes\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1158Amazon Simple Storage Service API Reference\nBucketLoggingStatus\nService: Amazon S3\nContainer for logging status information.\nContents\nLoggingEnabled\nDescribes where logs are stored and the pre\ufb01x that Amazon S3 assigns to all log object keys for \na bucket. For more information, see PUT Bucket logging in the Amazon S3 API Reference.\nType: LoggingEnabled  data type\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1159Amazon Simple Storage Service API Reference\nChecksum\nService: Amazon S3\nContains all the possible checksum or digest values for an object.\nContents\nChecksumCRC32\nThe base64-encoded, 32-bit CRC-32 checksum of the object.", "This will only be present if it was \nuploaded with the object. When you use an API operation on an object that was uploaded using \nmultipart uploads, this value may not be a direct checksum value of the full object. Instead, \nit's a calculation based on the checksum values of each individual part.", "For more information \nabout how checksums are calculated with multipart uploads, see  Checking object integrity in \nthe Amazon S3 User Guide .\nType: String\nRequired: No\nChecksumCRC32C\nThe base64-encoded, 32-bit CRC-32C checksum of the object.", "This will only be present if it was \nuploaded with the object. When you use an API operation on an object that was uploaded using \nmultipart uploads, this value may not be a direct checksum value of the full object. Instead, \nit's a calculation based on the checksum values of each individual part.", "For more information \nabout how checksums are calculated with multipart uploads, see  Checking object integrity in \nthe Amazon S3 User Guide .\nType: String\nRequired: No\nChecksumSHA1\nThe base64-encoded, 160-bit SHA-1 digest of the object.", "This will only be present if it was \nuploaded with the object. When you use the API operation on an object that was uploaded \nusing multipart uploads, this value may not be a direct checksum value of the full object.", "\nInstead, it's a calculation based on the checksum values of each individual part.", "For more \ninformation about how checksums are calculated with multipart uploads, see  Checking object \nintegrity in the Amazon S3 User Guide .\nAmazon S3 API Version 2006-03-01 1160Amazon Simple Storage Service API Reference\nType: String\nRequired: No\nChecksumSHA256\nThe base64-encoded, 256-bit SHA-256 digest of the object.", "This will only be present if it was \nuploaded with the object. When you use an API operation on an object that was uploaded using \nmultipart uploads, this value may not be a direct checksum value of the full object. Instead, \nit's a calculation based on the checksum values of each individual part.", "For more information \nabout how checksums are calculated with multipart uploads, see  Checking object integrity in \nthe Amazon S3 User Guide .\nType: String\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1161Amazon Simple Storage Service API Reference\nCloudFunctionCon\ufb01guration\nService: Amazon S3\nContainer for specifying the AWS Lambda noti\ufb01cation con\ufb01guration.\nContents\nCloudFunction\nLambda cloud function ARN that Amazon S3 can invoke when it detects events of the speci\ufb01ed \ntype.\nType: String\nRequired: No\nEvent\nThis member has been deprecated.\nThe bucket event for which to send noti\ufb01cations.\nType: String\nValid Values: s3:ReducedRedundancyLostObject | s3:ObjectCreated:* | \ns3:ObjectCreated:Put | s3:ObjectCreated:Post | s3:ObjectCreated:Copy \n| s3:ObjectCreated:CompleteMultipartUpload | s3:ObjectRemoved:* | \ns3:ObjectRemoved:Delete | s3:ObjectRemoved:DeleteMarkerCreated | \ns3:ObjectRestore:* | s3:ObjectRestore:Post | s3:ObjectRestore:Completed \n| s3:Replication:* | s3:Replication:OperationFailedReplication | \ns3:Replication:OperationNotTracked | \ns3:Replication:OperationMissedThreshold | \ns3:Replication:OperationReplicatedAfterThreshold | \ns3:ObjectRestore:Delete | s3:LifecycleTransition | \ns3:IntelligentTiering | s3:ObjectAcl:Put | s3:LifecycleExpiration:* | \ns3:LifecycleExpiration:Delete | \ns3:LifecycleExpiration:DeleteMarkerCreated | s3:ObjectTagging:* | \ns3:ObjectTagging:Put | s3:ObjectTagging:Delete\nRequired: No\nAmazon S3 API Version 2006-03-01 1162Amazon Simple Storage Service API Reference\nEvents\nBucket events for which to send noti\ufb01cations.\nType: Array of strings\nValid Values: s3:ReducedRedundancyLostObject | s3:ObjectCreated:* | \ns3:ObjectCreated:Put | s3:ObjectCreated:Post | s3:ObjectCreated:Copy \n| s3:ObjectCreated:CompleteMultipartUpload | s3:ObjectRemoved:* | \ns3:ObjectRemoved:Delete | s3:ObjectRemoved:DeleteMarkerCreated | \ns3:ObjectRestore:* | s3:ObjectRestore:Post | s3:ObjectRestore:Completed \n| s3:Replication:* | s3:Replication:OperationFailedReplication | \ns3:Replication:OperationNotTracked | \ns3:Replication:OperationMissedThreshold | \ns3:Replication:OperationReplicatedAfterThreshold | \ns3:ObjectRestore:Delete | s3:LifecycleTransition | \ns3:IntelligentTiering | s3:ObjectAcl:Put | s3:LifecycleExpiration:* | \ns3:LifecycleExpiration:Delete | \ns3:LifecycleExpiration:DeleteMarkerCreated | s3:ObjectTagging:* | \ns3:ObjectTagging:Put | s3:ObjectTagging:Delete\nRequired: No\nId\nAn optional unique identi\ufb01er for con\ufb01gurations in a noti\ufb01cation con\ufb01guration. If you don't \nprovide one, Amazon S3 will assign an ID.\nType: String\nRequired: No\nInvocationRole\nThe role supporting the invocation of the Lambda function\nType: String\nRequired: No\nAmazon S3 API Version 2006-03-01 1163Amazon Simple Storage Service API Reference\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1164Amazon Simple Storage Service API Reference\nCommonPre\ufb01x\nService: Amazon S3\nContainer for all (if there are any) keys between Pre\ufb01x and the next occurrence of the string \nspeci\ufb01ed by a delimiter.", "CommonPre\ufb01xes lists keys that act like subdirectories in the directory \nspeci\ufb01ed by Pre\ufb01x.", "For example, if the pre\ufb01x is notes/ and the delimiter is a slash (/) as in notes/\nsummer/july, the common pre\ufb01x is notes/summer/.\nContents\nPre\ufb01x\nContainer for the speci\ufb01ed common pre\ufb01x.\nType: String\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1165Amazon Simple Storage Service API Reference\nCompletedMultipartUpload\nService: Amazon S3\nThe container for the completed multipart upload details.\nContents\nParts\nArray of CompletedPart data types.\nIf you do not supply a valid Part with your request, the service sends back an HTTP 400 \nresponse.\nType: Array of CompletedPart data types\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1166Amazon Simple Storage Service API Reference\nCompletedPart\nService: Amazon S3\nDetails of the parts that were uploaded.\nContents\nChecksumCRC32\nThe base64-encoded, 32-bit CRC-32 checksum of the object.", "This will only be present if it was \nuploaded with the object. When you use an API operation on an object that was uploaded using \nmultipart uploads, this value may not be a direct checksum value of the full object. Instead, \nit's a calculation based on the checksum values of each individual part.", "For more information \nabout how checksums are calculated with multipart uploads, see  Checking object integrity in \nthe Amazon S3 User Guide .\nType: String\nRequired: No\nChecksumCRC32C\nThe base64-encoded, 32-bit CRC-32C checksum of the object.", "This will only be present if it was \nuploaded with the object. When you use an API operation on an object that was uploaded using \nmultipart uploads, this value may not be a direct checksum value of the full object. Instead, \nit's a calculation based on the checksum values of each individual part.", "For more information \nabout how checksums are calculated with multipart uploads, see  Checking object integrity in \nthe Amazon S3 User Guide .\nType: String\nRequired: No\nChecksumSHA1\nThe base64-encoded, 160-bit SHA-1 digest of the object.", "This will only be present if it was \nuploaded with the object. When you use the API operation on an object that was uploaded \nusing multipart uploads, this value may not be a direct checksum value of the full object.", "\nInstead, it's a calculation based on the checksum values of each individual part.", "For more \ninformation about how checksums are calculated with multipart uploads, see  Checking object \nintegrity in the Amazon S3 User Guide .\nAmazon S3 API Version 2006-03-01 1167Amazon Simple Storage Service API Reference\nType: String\nRequired: No\nChecksumSHA256\nThe base64-encoded, 256-bit SHA-256 digest of the object.", "This will only be present if it was \nuploaded with the object. When you use an API operation on an object that was uploaded using \nmultipart uploads, this value may not be a direct checksum value of the full object. Instead, \nit's a calculation based on the checksum values of each individual part.", "For more information \nabout how checksums are calculated with multipart uploads, see  Checking object integrity in \nthe Amazon S3 User Guide .\nType: String\nRequired: No\nETag\nEntity tag returned when the part was uploaded.\nType: String\nRequired: No\nPartNumber\nPart number that identi\ufb01es the part.", "This is a positive integer between 1 and 10,000.\nNote\n\u2022General purpose buckets - In CompleteMultipartUpload , when a additional \nchecksum (including x-amz-checksum-crc32 , x-amz-checksum-crc32c , x-\namz-checksum-sha1 , or x-amz-checksum-sha256 ) is applied to each part, \nthe PartNumber  must start at 1 and the part numbers must be consecutive.", "\nOtherwise, Amazon S3 generates an HTTP 400 Bad Request  status code and an\nInvalidPartOrder  error code.\n\u2022Directory buckets - In CompleteMultipartUpload , the PartNumber  must start at \n1 and the part numbers must be consecutive.\nType: Integer\nAmazon S3 API Version 2006-03-01 1168Amazon Simple Storage Service API Reference\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1169Amazon Simple Storage Service API Reference\nCondition\nService: Amazon S3\nA container for describing a condition that must be met for the speci\ufb01ed redirect to apply.", "For \nexample, 1.", "If request is for pages in the /docs folder, redirect to the /documents  folder.", "2.", "If \nrequest results in HTTP error 4xx, redirect request to another host where you might process the \nerror.\nContents\nHttpErrorCodeReturnedEquals\nThe HTTP error code when the redirect is applied. In the event of an error, if the error code \nequals this value, then the speci\ufb01ed redirect is applied.", "Required when parent element\nCondition  is speci\ufb01ed and sibling KeyPrefixEquals  is not speci\ufb01ed.", "If both are speci\ufb01ed, \nthen both must be true for the redirect to be applied.\nType: String\nRequired: No\nKeyPre\ufb01xEquals\nThe object key name pre\ufb01x when the redirect is applied. For example, to redirect requests \nfor ExamplePage.html , the key pre\ufb01x will be ExamplePage.html . To redirect request for \nall pages with the pre\ufb01x docs/, the key pre\ufb01x will be /docs, which identi\ufb01es all objects in \nthe docs/ folder.", "Required when the parent element Condition  is speci\ufb01ed and sibling\nHttpErrorCodeReturnedEquals  is not speci\ufb01ed.", "If both conditions are speci\ufb01ed, both must \nbe true for the redirect to be applied.\nImportant\nReplacement must be made for object keys containing special characters (such as \ncarriage returns) when using XML requests.", "For more information, see  XML related \nobject key constraints.\nType: String\nRequired: No\nAmazon S3 API Version 2006-03-01 1170Amazon Simple Storage Service API Reference\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1171Amazon Simple Storage Service API Reference\nContinuationEvent\nService: Amazon S3\nContents\nThe members of this exception structure are context-dependent.\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1172Amazon Simple Storage Service API Reference\nCopyObjectResult\nService: Amazon S3\nContainer for all response elements.\nContents\nChecksumCRC32\nThe base64-encoded, 32-bit CRC-32 checksum of the object.", "This will only be present if it was \nuploaded with the object.", "For more information, see  Checking object integrity in the Amazon \nS3 User Guide .\nType: String\nRequired: No\nChecksumCRC32C\nThe base64-encoded, 32-bit CRC-32C checksum of the object.", "This will only be present if it was \nuploaded with the object.", "For more information, see  Checking object integrity in the Amazon \nS3 User Guide .\nType: String\nRequired: No\nChecksumSHA1\nThe base64-encoded, 160-bit SHA-1 digest of the object.", "This will only be present if it was \nuploaded with the object.", "For more information, see  Checking object integrity in the Amazon \nS3 User Guide .\nType: String\nRequired: No\nChecksumSHA256\nThe base64-encoded, 256-bit SHA-256 digest of the object.", "This will only be present if it was \nuploaded with the object.", "For more information, see  Checking object integrity in the Amazon \nS3 User Guide .\nType: String\nAmazon S3 API Version 2006-03-01 1173Amazon Simple Storage Service API Reference\nRequired: No\nETag\nReturns the ETag of the new object. The ETag re\ufb02ects only changes to the contents of an object, \nnot its metadata.\nType: String\nRequired: No\nLastModi\ufb01ed\nCreation date of the object.\nType: Timestamp\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1174Amazon Simple Storage Service API Reference\nCopyPartResult\nService: Amazon S3\nContainer for all response elements.\nContents\nChecksumCRC32\nThe base64-encoded, 32-bit CRC-32 checksum of the object.", "This will only be present if it was \nuploaded with the object. When you use an API operation on an object that was uploaded using \nmultipart uploads, this value may not be a direct checksum value of the full object. Instead, \nit's a calculation based on the checksum values of each individual part.", "For more information \nabout how checksums are calculated with multipart uploads, see  Checking object integrity in \nthe Amazon S3 User Guide .\nType: String\nRequired: No\nChecksumCRC32C\nThe base64-encoded, 32-bit CRC-32C checksum of the object.", "This will only be present if it was \nuploaded with the object. When you use an API operation on an object that was uploaded using \nmultipart uploads, this value may not be a direct checksum value of the full object. Instead, \nit's a calculation based on the checksum values of each individual part.", "For more information \nabout how checksums are calculated with multipart uploads, see  Checking object integrity in \nthe Amazon S3 User Guide .\nType: String\nRequired: No\nChecksumSHA1\nThe base64-encoded, 160-bit SHA-1 digest of the object.", "This will only be present if it was \nuploaded with the object. When you use the API operation on an object that was uploaded \nusing multipart uploads, this value may not be a direct checksum value of the full object.", "\nInstead, it's a calculation based on the checksum values of each individual part.", "For more \ninformation about how checksums are calculated with multipart uploads, see  Checking object \nintegrity in the Amazon S3 User Guide .\nAmazon S3 API Version 2006-03-01 1175Amazon Simple Storage Service API Reference\nType: String\nRequired: No\nChecksumSHA256\nThe base64-encoded, 256-bit SHA-256 digest of the object.", "This will only be present if it was \nuploaded with the object. When you use an API operation on an object that was uploaded using \nmultipart uploads, this value may not be a direct checksum value of the full object. Instead, \nit's a calculation based on the checksum values of each individual part.", "For more information \nabout how checksums are calculated with multipart uploads, see  Checking object integrity in \nthe Amazon S3 User Guide .\nType: String\nRequired: No\nETag\nEntity tag of the object.\nType: String\nRequired: No\nLastModi\ufb01ed\nDate and time at which the object was uploaded.\nType: Timestamp\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1176Amazon Simple Storage Service API Reference\nCORSCon\ufb01guration\nService: Amazon S3\nDescribes the cross-origin access con\ufb01guration for objects in an Amazon S3 bucket. For more \ninformation, see Enabling Cross-Origin Resource Sharing in the Amazon S3 User Guide .\nContents\nCORSRules\nA set of origins and methods (cross-origin access that you want to allow). You can add up to 100 \nrules to the con\ufb01guration.\nType: Array of CORSRule data types\nRequired: Yes\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1177Amazon Simple Storage Service API Reference\nCORSRule\nService: Amazon S3\nSpeci\ufb01es a cross-origin access rule for an Amazon S3 bucket.\nContents\nAllowedMethods\nAn HTTP method that you allow the origin to execute.", "Valid values are GET, PUT, HEAD , POST , \nand DELETE .\nType: Array of strings\nRequired: Yes\nAllowedOrigins\nOne or more origins you want customers to be able to access the bucket from.\nType: Array of strings\nRequired: Yes\nAllowedHeaders\nHeaders that are speci\ufb01ed in the Access-Control-Request-Headers  header. These headers \nare allowed in a pre\ufb02ight OPTIONS request.", "In response to any pre\ufb02ight OPTIONS request, \nAmazon S3 returns any requested headers that are allowed.\nType: Array of strings\nRequired: No\nExposeHeaders\nOne or more headers in the response that you want customers to be able to access from their \napplications (for example, from a JavaScript XMLHttpRequest  object).\nType: Array of strings\nRequired: No\nID\nUnique identi\ufb01er for the rule. The value cannot be longer than 255 characters.\nAmazon S3 API Version 2006-03-01 1178Amazon Simple Storage Service API Reference\nType: String\nRequired: No\nMaxAgeSeconds\nThe time in seconds that your browser is to cache the pre\ufb02ight response for the speci\ufb01ed \nresource.\nType: Integer\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1179Amazon Simple Storage Service API Reference\nCreateBucketCon\ufb01guration\nService: Amazon S3\nThe con\ufb01guration information for the bucket.\nContents\nBucket\nSpeci\ufb01es the information about the bucket that will be created.\nNote\nThis functionality is only supported by directory buckets.\nType: BucketInfo data type\nRequired: No\nLocation\nSpeci\ufb01es the location where the bucket will be created.\nFor directory buckets, the location type is Availability Zone.\nNote\nThis functionality is only supported by directory buckets.\nType: LocationInfo  data type\nRequired: No\nLocationConstraint\nSpeci\ufb01es the Region where the bucket will be created.", "You might choose a Region to optimize \nlatency, minimize costs, or address regulatory requirements.", "For example, if you reside in \nEurope, you will probably \ufb01nd it advantageous to create buckets in the Europe (Ireland) Region.", "\nFor more information, see Accessing a bucket in the Amazon S3 User Guide .\nAmazon S3 API Version 2006-03-01 1180Amazon Simple Storage Service API Reference\nIf you don't specify a Region, the bucket is created in the US East (N.", "Virginia) Region (us-east-1) \nby default.\nNote\nThis functionality is not supported for directory buckets.\nType: String\nValid Values: af-south-1 | ap-east-1 | ap-northeast-1 | ap-northeast-2 | ap-\nnortheast-3 | ap-south-1 | ap-south-2 | ap-southeast-1 | ap-southeast-2 \n| ap-southeast-3 | ca-central-1 | cn-north-1 | cn-northwest-1 | EU | eu-\ncentral-1 | eu-north-1 | eu-south-1 | eu-south-2 | eu-west-1 | eu-west-2 \n| eu-west-3 | me-south-1 | sa-east-1 | us-east-2 | us-gov-east-1 | us-\ngov-west-1 | us-west-1 | us-west-2\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1181Amazon Simple Storage Service API Reference\nCSVInput\nService: Amazon S3\nDescribes how an uncompressed comma-separated values (CSV)-formatted input object is \nformatted.\nContents\nAllowQuotedRecordDelimiter\nSpeci\ufb01es that CSV \ufb01eld values may contain quoted record delimiters and such records should be \nallowed.", "Default value is FALSE. Setting this value to TRUE may lower performance.\nType: Boolean\nRequired: No\nComments\nA single character used to indicate that a row should be ignored when the character is present \nat the start of that row. You can specify any character to indicate a comment line.", "The default \ncharacter is #.\nDefault: #\nType: String\nRequired: No\nFieldDelimiter\nA single character used to separate individual \ufb01elds in a record. You can specify an arbitrary \ndelimiter.\nType: String\nRequired: No\nFileHeaderInfo\nDescribes the \ufb01rst line of input.", "Valid values are:\n\u2022NONE: First line is not a header.\nAmazon S3 API Version 2006-03-01 1182Amazon Simple Storage Service API Reference\n\u2022IGNORE: First line is a header, but you can't use the header values to indicate the column \nin an expression.", "You can use column position (such as _1, _2, \u2026) to indicate the column \n(SELECT s._1 FROM OBJECT s ).\n\u2022Use: First line is a header, and you can use the header value to identify a column in an \nexpression (SELECT \"name\" FROM OBJECT ).\nType: String\nValid Values: USE | IGNORE | NONE\nRequired: No\nQuoteCharacter\nA single character used for escaping when the \ufb01eld delimiter is part of the value.", "For example, if \nthe value is a, b, Amazon S3 wraps this \ufb01eld value in quotation marks, as follows: \" a , b \" .\nType: String\nDefault: \"\nAncestors: CSV\nType: String\nRequired: No\nQuoteEscapeCharacter\nA single character used for escaping the quotation mark character inside an already escaped \nvalue.", "For example, the value \"\"\" a , b \"\"\"  is parsed as \" a , b \" .\nType: String\nRequired: No\nRecordDelimiter\nA single character used to separate individual records in the input.", "Instead of the default value, \nyou can specify an arbitrary delimiter.\nType: String\nRequired: No\nAmazon S3 API Version 2006-03-01 1183Amazon Simple Storage Service API Reference\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1184Amazon Simple Storage Service API Reference\nCSVOutput\nService: Amazon S3\nDescribes how uncompressed comma-separated values (CSV)-formatted results are formatted.\nContents\nFieldDelimiter\nThe value used to separate individual \ufb01elds in a record.", "You can specify an arbitrary delimiter.\nType: String\nRequired: No\nQuoteCharacter\nA single character used for escaping when the \ufb01eld delimiter is part of the value.", "For example, if \nthe value is a, b, Amazon S3 wraps this \ufb01eld value in quotation marks, as follows: \" a , b \" .\nType: String\nRequired: No\nQuoteEscapeCharacter\nThe single character used for escaping the quote character inside an already escaped value.\nType: String\nRequired: No\nQuoteFields\nIndicates whether to use quotation marks around output \ufb01elds.\n\u2022ALWAYS: Always use quotation marks for output \ufb01elds.\n\u2022ASNEEDED : Use quotation marks for output \ufb01elds when needed.\nType: String\nValid Values: ALWAYS | ASNEEDED\nRequired: No\nAmazon S3 API Version 2006-03-01 1185Amazon Simple Storage Service API Reference\nRecordDelimiter\nA single character used to separate individual records in the output. Instead of the default \nvalue, you can specify an arbitrary delimiter.\nType: String\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1186Amazon Simple Storage Service API Reference\nDefaultRetention\nService: Amazon S3\nThe container element for optionally specifying the default Object Lock retention settings for new \nobjects placed in the speci\ufb01ed bucket.\nNote\n\u2022The DefaultRetention  settings require both a mode and a period.\n\u2022The DefaultRetention  period can be either Days  or Years but you must select one.", "\nYou cannot specify Days  and Years  at the same time.\nContents\nDays\nThe number of days that you want to specify for the default retention period.", "Must be used \nwith Mode .\nType: Integer\nRequired: No\nMode\nThe default Object Lock retention mode you want to apply to new objects placed in the \nspeci\ufb01ed bucket.", "Must be used with either Days  or Years .\nType: String\nValid Values: GOVERNANCE | COMPLIANCE\nRequired: No\nYears\nThe number of years that you want to specify for the default retention period.", "Must be used \nwith Mode .\nType: Integer\nAmazon S3 API Version 2006-03-01 1187Amazon Simple Storage Service API Reference\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1188Amazon Simple Storage Service API Reference\nDelete\nService: Amazon S3\nContainer for the objects to delete.\nContents\nObjects\nThe object to delete.\nNote\nDirectory buckets - For directory buckets, an object that's composed entirely of \nwhitespace characters is not supported by the DeleteObjects  API operation.", "The \nrequest will receive a 400 Bad Request  error and none of the objects in the request \nwill be deleted.\nType: Array of ObjectIdenti\ufb01er data types\nRequired: Yes\nQuiet\nElement to enable quiet mode for the request.", "When you add this element, you must set its \nvalue to true .\nType: Boolean\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1189Amazon Simple Storage Service API Reference\nAmazon S3 API Version 2006-03-01 1190Amazon Simple Storage Service API Reference\nDeletedObject\nService: Amazon S3\nInformation about the deleted object.\nContents\nDeleteMarker\nIndicates whether the speci\ufb01ed object version that was permanently deleted was (true) or was \nnot (false) a delete marker before deletion. In a simple DELETE, this header indicates whether \n(true) or not (false) the current version of the object is a delete marker.\nNote\nThis functionality is not supported for directory buckets.\nType: Boolean\nRequired: No\nDeleteMarkerVersionId\nThe version ID of the delete marker created as a result of the DELETE operation. If you delete a \nspeci\ufb01c object version, the value returned by this header is the version ID of the object version \ndeleted.\nNote\nThis functionality is not supported for directory buckets.\nType: String\nRequired: No\nKey\nThe name of the deleted object.\nType: String\nAmazon S3 API Version 2006-03-01 1191Amazon Simple Storage Service API Reference\nLength Constraints: Minimum length of 1.\nRequired: No\nVersionId\nThe version ID of the deleted object.\nNote\nThis functionality is not supported for directory buckets.\nType: String\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1192Amazon Simple Storage Service API Reference\nDeleteMarkerEntry\nService: Amazon S3\nInformation about the delete marker.\nContents\nIsLatest\nSpeci\ufb01es whether the object is (true) or is not (false) the latest version of an object.\nType: Boolean\nRequired: No\nKey\nThe object key.\nType: String\nLength Constraints: Minimum length of 1.\nRequired: No\nLastModi\ufb01ed\nDate and time when the object was last modi\ufb01ed.\nType: Timestamp\nRequired: No\nOwner\nThe account that created the delete marker.>\nType: Owner  data type\nRequired: No\nVersionId\nVersion ID of an object.\nType: String\nAmazon S3 API Version 2006-03-01 1193Amazon Simple Storage Service API Reference\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1194Amazon Simple Storage Service API Reference\nDeleteMarkerReplication\nService: Amazon S3\nSpeci\ufb01es whether Amazon S3 replicates delete markers.", "If you specify a Filter in your replication \ncon\ufb01guration, you must also include a DeleteMarkerReplication  element.", "If your Filter\nincludes a Tag element, the DeleteMarkerReplication  Status  must be set to Disabled, \nbecause Amazon S3 does not support replicating delete markers for tag-based rules. For an \nexample con\ufb01guration, see Basic Rule Con\ufb01guration .\nFor more information about delete marker replication, see Basic Rule Con\ufb01guration .\nNote\nIf you are using an earlier version of the replication con\ufb01guration, Amazon S3 \nhandles replication of delete markers di\ufb00erently. For more information, see Backward \nCompatibility.\nContents\nStatus\nIndicates whether to replicate delete markers.\nNote\nIndicates whether to replicate delete markers.\nType: String\nValid Values: Enabled | Disabled\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\nAmazon S3 API Version 2006-03-01 1195Amazon Simple Storage Service API Reference\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1196Amazon Simple Storage Service API Reference\nDestination\nService: Amazon S3\nSpeci\ufb01es information about where to publish analysis or con\ufb01guration results for an Amazon S3 \nbucket and S3 Replication Time Control (S3 RTC).\nContents\nBucket\nThe Amazon Resource Name (ARN) of the bucket where you want Amazon S3 to store the \nresults.\nType: String\nRequired: Yes\nAccessControlTranslation\nSpecify this only in a cross-account scenario (where source and destination bucket owners \nare not the same), and you want to change replica ownership to the AWS account that owns \nthe destination bucket. If this is not speci\ufb01ed in the replication con\ufb01guration, the replicas are \nowned by same AWS account that owns the source object.\nType: AccessControlTranslation data type\nRequired: No\nAccount\nDestination bucket owner account ID. In a cross-account scenario, if you direct Amazon S3 to \nchange replica ownership to the AWS account that owns the destination bucket by specifying \nthe AccessControlTranslation  property, this is the account ID of the destination bucket \nowner. For more information, see Replication Additional Con\ufb01guration: Changing the Replica \nOwner  in the Amazon S3 User Guide .\nType: String\nRequired: No\nEncryptionCon\ufb01guration\nA container that provides information about encryption. If SourceSelectionCriteria  is \nspeci\ufb01ed, you must specify this element.\nAmazon S3 API Version 2006-03-01 1197Amazon Simple Storage Service API Reference\nType: EncryptionCon\ufb01guration data type\nRequired: No\nMetrics\nA container specifying replication metrics-related settings enabling replication metrics and \nevents.\nType: Metrics  data type\nRequired: No\nReplicationTime\nA container specifying S3 Replication Time Control (S3 RTC), including whether S3 RTC is \nenabled and the time when all objects and operations on objects must be replicated. Must be \nspeci\ufb01ed together with a Metrics  block.\nType: ReplicationTime data type\nRequired: No\nStorageClass\nThe storage class to use when replicating objects, such as S3 Standard or reduced redundancy. \nBy default, Amazon S3 uses the storage class of the source object to create the object replica.\nFor valid values, see the StorageClass  element of the PUT Bucket replication action in the\nAmazon S3 API Reference.\nType: String\nValid Values: STANDARD | REDUCED_REDUNDANCY | STANDARD_IA | ONEZONE_IA | \nINTELLIGENT_TIERING | GLACIER | DEEP_ARCHIVE | OUTPOSTS | GLACIER_IR | \nSNOW | EXPRESS_ONEZONE\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\nAmazon S3 API Version 2006-03-01 1198Amazon Simple Storage Service API Reference\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1199Amazon Simple Storage Service API Reference\nEncryption\nService: Amazon S3\nContains the type of server-side encryption used.\nContents\nEncryptionType\nThe server-side encryption algorithm used when storing job results in Amazon S3 (for example, \nAES256, aws:kms ).\nType: String\nValid Values: AES256 | aws:kms | aws:kms:dsse\nRequired: Yes\nKMSContext\nIf the encryption type is aws:kms, this optional value can be used to specify the encryption \ncontext for the restore results.\nType: String\nRequired: No\nKMSKeyId\nIf the encryption type is aws:kms , this optional value speci\ufb01es the ID of the symmetric \nencryption customer managed key to use for encryption of job results. Amazon S3 only \nsupports symmetric encryption KMS keys. For more information, see Asymmetric keys in AWS \nKMS  in the  AWS Key Management Service Developer Guide.\nType: String\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\nAmazon S3 API Version 2006-03-01 1200Amazon Simple Storage Service API Reference\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1201Amazon Simple Storage Service API Reference\nEncryptionCon\ufb01guration\nService: Amazon S3\nSpeci\ufb01es encryption-related information for an Amazon S3 bucket that is a destination for \nreplicated objects.\nNote\nIf you're specifying a customer managed KMS key, we recommend using a fully quali\ufb01ed \nKMS key ARN. If you use a KMS key alias instead, then AWS KMS resolves the key within the \nrequester\u2019s account. This behavior can result in data that's encrypted with a KMS key that \nbelongs to the requester, and not the bucket owner.\nContents\nReplicaKmsKeyID\nSpeci\ufb01es the ID (Key ARN or Alias ARN) of the customer managed AWS KMS key stored in \nAWS Key Management Service (KMS) for the destination bucket.", "Amazon S3 uses this key to \nencrypt replica objects. Amazon S3 only supports symmetric encryption KMS keys. For more \ninformation, see Asymmetric keys in AWS KMS in the  AWS Key Management Service Developer \nGuide .\nType: String\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1202Amazon Simple Storage Service API Reference\nEndEvent\nService: Amazon S3\nA message that indicates the request is complete and no more messages will be sent. You should \nnot assume that the request is complete until the client receives an EndEvent .\nContents\nThe members of this exception structure are context-dependent.\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1203Amazon Simple Storage Service API Reference\nError\nService: Amazon S3\nContainer for all error elements.\nContents\nCode\nThe error code is a string that uniquely identi\ufb01es an error condition.", "It is meant to be read \nand understood by programs that detect and handle errors by type.", "The following is a list of \nAmazon S3 error codes.", "For more information, see Error responses.\n\u2022\u2022Code:  AccessDenied\n\u2022Description:  Access Denied\n\u2022HTTP Status Code: 403 Forbidden\n\u2022SOAP Fault Code Pre\ufb01x: Client\n\u2022\u2022Code:  AccountProblem\n\u2022Description:  There is a problem with your AWS account that prevents the action from \ncompleting successfully. Contact AWS Support for further assistance.\n\u2022HTTP Status Code: 403 Forbidden\n\u2022SOAP Fault Code Pre\ufb01x: Client\n\u2022\u2022Code:  AllAccessDisabled\n\u2022Description:  All access to this Amazon S3 resource has been disabled. Contact AWS Support \nfor further assistance.\n\u2022HTTP Status Code: 403 Forbidden\n\u2022SOAP Fault Code Pre\ufb01x: Client\n\u2022\u2022Code:  AmbiguousGrantByEmailAddress\n\u2022Description:  The email address you provided is associated with more than one account.\n\u2022HTTP Status Code: 400 Bad Request\n\u2022SOAP Fault Code Pre\ufb01x: Client\n\u2022\u2022Code:  AuthorizationHeaderMalformed\n\u2022Description:  The authorization header you provided is invalid.\n\u2022HTTP Status Code: 400 Bad Request\n\u2022HTTP Status Code: N/A\nAmazon S3 API Version 2006-03-01 1204Amazon Simple Storage Service API Reference\n\u2022\u2022Code:  BadDigest\n\u2022Description:  The Content-MD5 you speci\ufb01ed did not match what we received.\n\u2022HTTP Status Code: 400 Bad Request\n\u2022SOAP Fault Code Pre\ufb01x: Client\n\u2022\u2022Code:  BucketAlreadyExists\n\u2022Description:  The requested bucket name is not available.", "The bucket namespace is shared \nby all users of the system. Please select a di\ufb00erent name and try again.\n\u2022HTTP Status Code: 409 Con\ufb02ict\n\u2022SOAP Fault Code Pre\ufb01x: Client\n\u2022\u2022Code:  BucketAlreadyOwnedByYou\n\u2022Description:  The bucket you tried to create already exists, and you own it.", "Amazon S3 \nreturns this error in all AWS Regions except in the North Virginia Region. For legacy \ncompatibility, if you re-create an existing bucket that you already own in the North Virginia \nRegion, Amazon S3 returns 200 OK and resets the bucket access control lists (ACLs).\n\u2022Code:  409 Con\ufb02ict (in all Regions except the North Virginia Region)\n\u2022SOAP Fault Code Pre\ufb01x: Client\n\u2022\u2022Code:  BucketNotEmpty\n\u2022Description:  The bucket you tried to delete is not empty.\n\u2022HTTP Status Code: 409 Con\ufb02ict\n\u2022SOAP Fault Code Pre\ufb01x: Client\n\u2022\u2022Code:  CredentialsNotSupported\n\u2022Description:  This request does not support credentials.\n\u2022HTTP Status Code: 400 Bad Request\n\u2022SOAP Fault Code Pre\ufb01x: Client\n\u2022\u2022Code:  CrossLocationLoggingProhibited\n\u2022Description:  Cross-location logging not allowed. Buckets in one geographic location cannot \nlog information to a bucket in another location.\n\u2022HTTP Status Code: 403 Forbidden\n\u2022SOAP Fault Code Pre\ufb01x: Client\n\u2022\u2022Code:  EntityTooSmall\n\u2022Description:  Your proposed upload is smaller than the minimum allowed object size.Amazon S3 API Version 2006-03-01 1205Amazon Simple Storage Service API Reference\n\u2022HTTP Status Code: 400 Bad Request\n\u2022SOAP Fault Code Pre\ufb01x: Client\n\u2022\u2022Code:  EntityTooLarge\n\u2022Description:  Your proposed upload exceeds the maximum allowed object size.\n\u2022HTTP Status Code: 400 Bad Request\n\u2022SOAP Fault Code Pre\ufb01x: Client\n\u2022\u2022Code:  ExpiredToken\n\u2022Description:  The provided token has expired.\n\u2022HTTP Status Code: 400 Bad Request\n\u2022SOAP Fault Code Pre\ufb01x: Client\n\u2022\u2022Code:  IllegalVersioningCon\ufb01gurationException\n\u2022Description:  Indicates that the versioning con\ufb01guration speci\ufb01ed in the request is invalid.\n\u2022HTTP Status Code: 400 Bad Request\n\u2022SOAP Fault Code Pre\ufb01x: Client\n\u2022\u2022Code:  IncompleteBody\n\u2022Description:  You did not provide the number of bytes speci\ufb01ed by the Content-Length \nHTTP header\n\u2022HTTP Status Code: 400 Bad Request\n\u2022SOAP Fault Code Pre\ufb01x: Client\n\u2022\u2022Code:  IncorrectNumberOfFilesInPostRequest\n\u2022Description:  POST requires exactly one \ufb01le upload per request.\n\u2022HTTP Status Code: 400 Bad Request\n\u2022SOAP Fault Code Pre\ufb01x: Client\n\u2022\u2022Code:  InlineDataTooLarge\n\u2022Description:  Inline data exceeds the maximum allowed size.\n\u2022HTTP Status Code: 400 Bad Request\n\u2022SOAP Fault Code Pre\ufb01x: Client\n\u2022\u2022Code:  InternalError\n\u2022Description:  We encountered an internal error. Please try again.\n\u2022HTTP Status Code: 500 Internal Server ErrorAmazon S3 API Version 2006-03-01 1206Amazon Simple Storage Service API Reference\n\u2022SOAP Fault Code Pre\ufb01x: Server\n\u2022\u2022Code:  InvalidAccessKeyId\n\u2022Description:  The AWS access key ID you provided does not exist in our records.\n\u2022HTTP Status Code: 403 Forbidden\n\u2022SOAP Fault Code Pre\ufb01x: Client\n\u2022\u2022Code:  InvalidAddressingHeader\n\u2022Description:  You must specify the Anonymous role.\n\u2022HTTP Status Code: N/A\n\u2022SOAP Fault Code Pre\ufb01x: Client\n\u2022\u2022Code:  InvalidArgument\n\u2022Description:  Invalid Argument\n\u2022HTTP Status Code: 400 Bad Request\n\u2022SOAP Fault Code Pre\ufb01x: Client\n\u2022\u2022Code:  InvalidBucketName\n\u2022Description:  The speci\ufb01ed bucket is not valid.\n\u2022HTTP Status Code: 400 Bad Request\n\u2022SOAP Fault Code Pre\ufb01x: Client\n\u2022\u2022Code:  InvalidBucketState\n\u2022Description:  The request is not valid with the current state of the bucket.\n\u2022HTTP Status Code: 409 Con\ufb02ict\n\u2022SOAP Fault Code Pre\ufb01x: Client\n\u2022\u2022Code:  InvalidDigest\n\u2022Description:  The Content-MD5 you speci\ufb01ed is not valid.\n\u2022HTTP Status Code: 400 Bad Request\n\u2022SOAP Fault Code Pre\ufb01x: Client\n\u2022\u2022Code:  InvalidEncryptionAlgorithmError\n\u2022Description:  The encryption request you speci\ufb01ed is not valid. The valid value is AES256.\n\u2022HTTP Status Code: 400 Bad Request\n\u2022SOAP Fault Code Pre\ufb01x: Client\n\u2022\u2022Code:  InvalidLocationConstraintAmazon S3 API Version 2006-03-01 1207Amazon Simple Storage Service API Reference\n\u2022Description:  The speci\ufb01ed location constraint is not valid.", "For more information about \nRegions, see How to Select a Region for Your Buckets.\n\u2022HTTP Status Code: 400 Bad Request\n\u2022SOAP Fault Code Pre\ufb01x: Client\n\u2022\u2022Code:  InvalidObjectState\n\u2022Description:  The action is not valid for the current state of the object.\n\u2022HTTP Status Code: 403 Forbidden\n\u2022SOAP Fault Code Pre\ufb01x: Client\n\u2022\u2022Code:  InvalidPart\n\u2022Description:  One or more of the speci\ufb01ed parts could not be found. The part might not \nhave been uploaded, or the speci\ufb01ed entity tag might not have matched the part's entity \ntag.\n\u2022HTTP Status Code: 400 Bad Request\n\u2022SOAP Fault Code Pre\ufb01x: Client\n\u2022\u2022Code:  InvalidPartOrder\n\u2022Description:  The list of parts was not in ascending order. Parts list must be speci\ufb01ed in order \nby part number.\n\u2022HTTP Status Code: 400 Bad Request\n\u2022SOAP Fault Code Pre\ufb01x: Client\n\u2022\u2022Code:  InvalidPayer\n\u2022Description:  All access to this object has been disabled.", "Please contact AWS Support for \nfurther assistance.\n\u2022HTTP Status Code: 403 Forbidden\n\u2022SOAP Fault Code Pre\ufb01x: Client\n\u2022\u2022Code:  InvalidPolicyDocument\n\u2022Description:  The content of the form does not meet the conditions speci\ufb01ed in the policy \ndocument.\n\u2022HTTP Status Code: 400 Bad Request\n\u2022SOAP Fault Code Pre\ufb01x: Client\n\u2022\u2022Code:  InvalidRange\n\u2022Description:  The requested range cannot be satis\ufb01ed.Amazon S3 API Version 2006-03-01 1208Amazon Simple Storage Service API Reference\n\u2022HTTP Status Code: 416 Requested Range Not Satis\ufb01able\n\u2022SOAP Fault Code Pre\ufb01x: Client\n\u2022\u2022Code:  InvalidRequest\n\u2022Description:  Please use AWS4-HMAC-SHA256 .\n\u2022HTTP Status Code: 400 Bad Request\n\u2022Code:  N/A\n\u2022\u2022Code:  InvalidRequest\n\u2022Description:  SOAP requests must be made over an HTTPS connection.\n\u2022HTTP Status Code: 400 Bad Request\n\u2022SOAP Fault Code Pre\ufb01x: Client\n\u2022\u2022Code:  InvalidRequest\n\u2022Description:  Amazon S3 Transfer Acceleration is not supported for buckets with non-DNS \ncompliant names.\n\u2022HTTP Status Code: 400 Bad Request\n\u2022Code:  N/A\n\u2022\u2022Code:  InvalidRequest\n\u2022Description:  Amazon S3 Transfer Acceleration is not supported for buckets with periods (.) \nin their names.\n\u2022HTTP Status Code: 400 Bad Request\n\u2022Code:  N/A\n\u2022\u2022Code:  InvalidRequest\n\u2022Description:  Amazon S3 Transfer Accelerate endpoint only supports virtual style requests.\n\u2022HTTP Status Code: 400 Bad Request\n\u2022Code:  N/A\n\u2022\u2022Code:  InvalidRequest\n\u2022Description:  Amazon S3 Transfer Accelerate is not con\ufb01gured on this bucket.\n\u2022HTTP Status Code: 400 Bad Request\n\u2022Code:  N/A\n\u2022\u2022Code:  InvalidRequest\n\u2022Description:  Amazon S3 Transfer Accelerate is disabled on this bucket.\n\u2022HTTP Status Code: 400 Bad Request\nAmazon S3 API Version 2006-03-01 1209Amazon Simple Storage Service API Reference\n\u2022Code:  N/A\n\u2022\u2022Code:  InvalidRequest\n\u2022Description:  Amazon S3 Transfer Acceleration is not supported on this bucket. Contact AWS \nSupport for more information.\n\u2022HTTP Status Code: 400 Bad Request\n\u2022Code:  N/A\n\u2022\u2022Code:  InvalidRequest\n\u2022Description:  Amazon S3 Transfer Acceleration cannot be enabled on this bucket. Contact \nAWS Support for more information.\n\u2022HTTP Status Code: 400 Bad Request\n\u2022Code:  N/A\n\u2022\u2022Code:  InvalidSecurity\n\u2022Description:  The provided security credentials are not valid.\n\u2022HTTP Status Code: 403 Forbidden\n\u2022SOAP Fault Code Pre\ufb01x: Client\n\u2022\u2022Code:  InvalidSOAPRequest\n\u2022Description:  The SOAP request body is invalid.\n\u2022HTTP Status Code: 400 Bad Request\n\u2022SOAP Fault Code Pre\ufb01x: Client\n\u2022\u2022Code:  InvalidStorageClass\n\u2022Description:  The storage class you speci\ufb01ed is not valid.\n\u2022HTTP Status Code: 400 Bad Request\n\u2022SOAP Fault Code Pre\ufb01x: Client\n\u2022\u2022Code:  InvalidTargetBucketForLogging\n\u2022Description:  The target bucket for logging does not exist, is not owned by you, or does not \nhave the appropriate grants for the log-delivery group.\n\u2022HTTP Status Code: 400 Bad Request\n\u2022SOAP Fault Code Pre\ufb01x: Client\n\u2022\u2022Code:  InvalidToken\n\u2022Description:  The provided token is malformed or otherwise invalid.\n\u2022HTTP Status Code: 400 Bad Request\nAmazon S3 API Version 2006-03-01 1210Amazon Simple Storage Service API Reference\n\u2022SOAP Fault Code Pre\ufb01x: Client\n\u2022\u2022Code:  InvalidURI\n\u2022Description:  Couldn't parse the speci\ufb01ed URI.\n\u2022HTTP Status Code: 400 Bad Request\n\u2022SOAP Fault Code Pre\ufb01x: Client\n\u2022\u2022Code:  KeyTooLongError\n\u2022Description:  Your key is too long.\n\u2022HTTP Status Code: 400 Bad Request\n\u2022SOAP Fault Code Pre\ufb01x: Client\n\u2022\u2022Code:  MalformedACLError\n\u2022Description:  The XML you provided was not well-formed or did not validate against our \npublished schema.\n\u2022HTTP Status Code: 400 Bad Request\n\u2022SOAP Fault Code Pre\ufb01x: Client\n\u2022\u2022Code:  MalformedPOSTRequest\n\u2022Description:  The body of your POST request is not well-formed multipart/form-data.\n\u2022HTTP Status Code: 400 Bad Request\n\u2022SOAP Fault Code Pre\ufb01x: Client\n\u2022\u2022Code:  MalformedXML\n\u2022Description:  This happens when the user sends malformed XML (XML that doesn't conform \nto the published XSD) for the con\ufb01guration. The error message is, \"The XML you provided \nwas not well-formed or did not validate against our published schema.\"\n\u2022HTTP Status Code: 400 Bad Request\n\u2022SOAP Fault Code Pre\ufb01x: Client\n\u2022\u2022Code:  MaxMessageLengthExceeded\n\u2022Description:  Your request was too big.\n\u2022HTTP Status Code: 400 Bad Request\n\u2022SOAP Fault Code Pre\ufb01x: Client\n\u2022\u2022Code:  MaxPostPreDataLengthExceededError\n\u2022Description:  Your POST request \ufb01elds preceding the upload \ufb01le were too large.\n\u2022HTTP Status Code: 400 Bad Request\nAmazon S3 API Version 2006-03-01 1211Amazon Simple Storage Service API Reference\n\u2022SOAP Fault Code Pre\ufb01x: Client\n\u2022\u2022Code:  MetadataTooLarge\n\u2022Description:  Your metadata headers exceed the maximum allowed metadata size.\n\u2022HTTP Status Code: 400 Bad Request\n\u2022SOAP Fault Code Pre\ufb01x: Client\n\u2022\u2022Code:  MethodNotAllowed\n\u2022Description:  The speci\ufb01ed method is not allowed against this resource.\n\u2022HTTP Status Code: 405 Method Not Allowed\n\u2022SOAP Fault Code Pre\ufb01x: Client\n\u2022\u2022Code:  MissingAttachment\n\u2022Description:  A SOAP attachment was expected, but none were found.\n\u2022HTTP Status Code: N/A\n\u2022SOAP Fault Code Pre\ufb01x: Client\n\u2022\u2022Code:  MissingContentLength\n\u2022Description:  You must provide the Content-Length HTTP header.\n\u2022HTTP Status Code: 411 Length Required\n\u2022SOAP Fault Code Pre\ufb01x: Client\n\u2022\u2022Code:  MissingRequestBodyError\n\u2022Description:  This happens when the user sends an empty XML document as a request. The \nerror message is, \"Request body is empty.\"\n\u2022HTTP Status Code: 400 Bad Request\n\u2022SOAP Fault Code Pre\ufb01x: Client\n\u2022\u2022Code:  MissingSecurityElement\n\u2022Description:  The SOAP 1.1 request is missing a security element.\n\u2022HTTP Status Code: 400 Bad Request\n\u2022SOAP Fault Code Pre\ufb01x: Client\n\u2022\u2022Code:  MissingSecurityHeader\n\u2022Description:  Your request is missing a required header.\n\u2022HTTP Status Code: 400 Bad Request\n\u2022SOAP Fault Code Pre\ufb01x: ClientAmazon S3 API Version 2006-03-01 1212Amazon Simple Storage Service API Reference\n\u2022\u2022Code:  NoLoggingStatusForKey\n\u2022Description:  There is no such thing as a logging status subresource for a key.\n\u2022HTTP Status Code: 400 Bad Request\n\u2022SOAP Fault Code Pre\ufb01x: Client\n\u2022\u2022Code:  NoSuchBucket\n\u2022Description:  The speci\ufb01ed bucket does not exist.\n\u2022HTTP Status Code: 404 Not Found\n\u2022SOAP Fault Code Pre\ufb01x: Client\n\u2022\u2022Code:  NoSuchBucketPolicy\n\u2022Description:  The speci\ufb01ed bucket does not have a bucket policy.\n\u2022HTTP Status Code: 404 Not Found\n\u2022SOAP Fault Code Pre\ufb01x: Client\n\u2022\u2022Code:  NoSuchKey\n\u2022Description:  The speci\ufb01ed key does not exist.\n\u2022HTTP Status Code: 404 Not Found\n\u2022SOAP Fault Code Pre\ufb01x: Client\n\u2022\u2022Code:  NoSuchLifecycleCon\ufb01guration\n\u2022Description:  The lifecycle con\ufb01guration does not exist.\n\u2022HTTP Status Code: 404 Not Found\n\u2022SOAP Fault Code Pre\ufb01x: Client\n\u2022\u2022Code:  NoSuchUpload\n\u2022Description:  The speci\ufb01ed multipart upload does not exist. The upload ID might be invalid, \nor the multipart upload might have been aborted or completed.\n\u2022HTTP Status Code: 404 Not Found\n\u2022SOAP Fault Code Pre\ufb01x: Client\n\u2022\u2022Code:  NoSuchVersion\n\u2022Description:  Indicates that the version ID speci\ufb01ed in the request does not match an existing \nversion.\n\u2022HTTP Status Code: 404 Not Found\n\u2022SOAP Fault Code Pre\ufb01x: Client\n\u2022\u2022Code:  NotImplemented\nAmazon S3 API Version 2006-03-01 1213Amazon Simple Storage Service API Reference\n\u2022Description:  A header you provided implies functionality that is not implemented.\n\u2022HTTP Status Code: 501 Not Implemented\n\u2022SOAP Fault Code Pre\ufb01x: Server\n\u2022\u2022Code:  NotSignedUp\n\u2022Description:  Your account is not signed up for the Amazon S3 service. You must sign up \nbefore you can use Amazon S3. You can sign up at the following URL: Amazon S3\n\u2022HTTP Status Code: 403 Forbidden\n\u2022SOAP Fault Code Pre\ufb01x: Client\n\u2022\u2022Code:  OperationAborted\n\u2022Description:  A con\ufb02icting conditional action is currently in progress against this resource.", "\nTry again.\n\u2022HTTP Status Code: 409 Con\ufb02ict\n\u2022SOAP Fault Code Pre\ufb01x: Client\n\u2022\u2022Code:  PermanentRedirect\n\u2022Description:  The bucket you are attempting to access must be addressed using the speci\ufb01ed \nendpoint. Send all future requests to this endpoint.\n\u2022HTTP Status Code: 301 Moved Permanently\n\u2022SOAP Fault Code Pre\ufb01x: Client\n\u2022\u2022Code:  PreconditionFailed\n\u2022Description:  At least one of the preconditions you speci\ufb01ed did not hold.\n\u2022HTTP Status Code: 412 Precondition Failed\n\u2022SOAP Fault Code Pre\ufb01x: Client\n\u2022\u2022Code:  Redirect\n\u2022Description:  Temporary redirect.\n\u2022HTTP Status Code: 307 Moved Temporarily\n\u2022SOAP Fault Code Pre\ufb01x: Client\n\u2022\u2022Code:  RestoreAlreadyInProgress\n\u2022Description:  Object restore is already in progress.\n\u2022HTTP Status Code: 409 Con\ufb02ict\n\u2022SOAP Fault Code Pre\ufb01x: Client\n\u2022\u2022Code:  RequestIsNotMultiPartContent\nAmazon S3 API Version 2006-03-01 1214Amazon Simple Storage Service API Reference\n\u2022Description:  Bucket POST must be of the enclosure-type multipart/form-data.\n\u2022HTTP Status Code: 400 Bad Request\n\u2022SOAP Fault Code Pre\ufb01x: Client\n\u2022\u2022Code:  RequestTimeout\n\u2022Description:  Your socket connection to the server was not read from or written to within the \ntimeout period.\n\u2022HTTP Status Code: 400 Bad Request\n\u2022SOAP Fault Code Pre\ufb01x: Client\n\u2022\u2022Code:  RequestTimeTooSkewed\n\u2022Description:  The di\ufb00erence between the request time and the server's time is too large.\n\u2022HTTP Status Code: 403 Forbidden\n\u2022SOAP Fault Code Pre\ufb01x: Client\n\u2022\u2022Code:  RequestTorrentOfBucketError\n\u2022Description:  Requesting the torrent \ufb01le of a bucket is not permitted.\n\u2022HTTP Status Code: 400 Bad Request\n\u2022SOAP Fault Code Pre\ufb01x: Client\n\u2022\u2022Code:  SignatureDoesNotMatch\n\u2022Description:  The request signature we calculated does not match the signature you \nprovided.", "Check your AWS secret access key and signing method.", "For more information, see\nREST Authentication  and SOAP Authentication for details.\n\u2022HTTP Status Code: 403 Forbidden\n\u2022SOAP Fault Code Pre\ufb01x: Client\n\u2022\u2022Code:  ServiceUnavailable\n\u2022Description:  Service is unable to handle request.\n\u2022HTTP Status Code: 503 Service Unavailable\n\u2022SOAP Fault Code Pre\ufb01x: Server\n\u2022\u2022Code:  SlowDown\n\u2022Description:  Reduce your request rate.\n\u2022HTTP Status Code: 503 Slow Down\n\u2022SOAP Fault Code Pre\ufb01x: Server\n\u2022\u2022Code:  TemporaryRedirect\nAmazon S3 API Version 2006-03-01 1215Amazon Simple Storage Service API Reference\n\u2022Description:  You are being redirected to the bucket while DNS updates.\n\u2022HTTP Status Code: 307 Moved Temporarily\n\u2022SOAP Fault Code Pre\ufb01x: Client\n\u2022\u2022Code:  TokenRefreshRequired\n\u2022Description:  The provided token must be refreshed.\n\u2022HTTP Status Code: 400 Bad Request\n\u2022SOAP Fault Code Pre\ufb01x: Client\n\u2022\u2022Code:  TooManyBuckets\n\u2022Description:  You have attempted to create more buckets than allowed.\n\u2022HTTP Status Code: 400 Bad Request\n\u2022SOAP Fault Code Pre\ufb01x: Client\n\u2022\u2022Code:  UnexpectedContent\n\u2022Description:  This request does not support content.\n\u2022HTTP Status Code: 400 Bad Request\n\u2022SOAP Fault Code Pre\ufb01x: Client\n\u2022\u2022Code:  UnresolvableGrantByEmailAddress\n\u2022Description:  The email address you provided does not match any account on record.\n\u2022HTTP Status Code: 400 Bad Request\n\u2022SOAP Fault Code Pre\ufb01x: Client\n\u2022\u2022Code:  UserKeyMustBeSpeci\ufb01ed\n\u2022Description:  The bucket POST must contain the speci\ufb01ed \ufb01eld name. If it is speci\ufb01ed, check \nthe order of the \ufb01elds.\n\u2022HTTP Status Code: 400 Bad Request\n\u2022SOAP Fault Code Pre\ufb01x: Client\nType: String\nRequired: No\nKey\nThe error key.\nType: String\nAmazon S3 API Version 2006-03-01 1216Amazon Simple Storage Service API Reference\nLength Constraints: Minimum length of 1.\nRequired: No\nMessage\nThe error message contains a generic description of the error condition in English.", "It is intended \nfor a human audience. Simple programs display the message directly to the end user if they \nencounter an error condition they don't know how or don't care to handle.", "Sophisticated \nprograms with more exhaustive error handling and proper internationalization are more likely \nto ignore the error message.\nType: String\nRequired: No\nVersionId\nThe version ID of the error.\nNote\nThis functionality is not supported for directory buckets.\nType: String\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1217Amazon Simple Storage Service API Reference\nErrorDocument\nService: Amazon S3\nThe error information.\nContents\nKey\nThe object key name to use when a 4XX class error occurs.\nImportant\nReplacement must be made for object keys containing special characters (such as \ncarriage returns) when using XML requests. For more information, see  XML related \nobject key constraints.\nType: String\nLength Constraints: Minimum length of 1.\nRequired: Yes\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1218Amazon Simple Storage Service API Reference\nEventBridgeCon\ufb01guration\nService: Amazon S3\nA container for specifying the con\ufb01guration for Amazon EventBridge.\nContents\nThe members of this exception structure are context-dependent.\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1219Amazon Simple Storage Service API Reference\nExistingObjectReplication\nService: Amazon S3\nOptional con\ufb01guration to replicate existing source bucket objects.\nNote\nThis parameter is no longer supported. To replicate existing objects, see Replicating existing \nobjects with S3 Batch Replication in the Amazon S3 User Guide .\nContents\nStatus\nSpeci\ufb01es whether Amazon S3 replicates existing source bucket objects.\nType: String\nValid Values: Enabled | Disabled\nRequired: Yes\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1220Amazon Simple Storage Service API Reference\nFilterRule\nService: Amazon S3\nSpeci\ufb01es the Amazon S3 object key name to \ufb01lter on. An object key name is the name assigned \nto an object in your Amazon S3 bucket.", "You specify whether to \ufb01lter on the su\ufb03x or pre\ufb01x of the \nobject key name. A pre\ufb01x is a speci\ufb01c string of characters at the beginning of an object key name, \nwhich you can use to organize objects. For example, you can start the key names of related objects \nwith a pre\ufb01x, such as 2023-  or engineering/ .", "Then, you can use FilterRule  to \ufb01nd objects in \na bucket with key names that have the same pre\ufb01x. A su\ufb03x is similar to a pre\ufb01x, but it is at the end \nof the object key name instead of at the beginning.\nContents\nName\nThe object key name pre\ufb01x or su\ufb03x identifying one or more objects to which the \ufb01ltering rule \napplies.", "The maximum length is 1,024 characters.", "Overlapping pre\ufb01xes and su\ufb03xes are not \nsupported.", "For more information, see Con\ufb01guring Event Noti\ufb01cations in the Amazon S3 User \nGuide .\nType: String\nValid Values: prefix | suffix\nRequired: No\nValue\nThe value that the \ufb01lter searches for in object key names.\nType: String\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\nAmazon S3 API Version 2006-03-01 1221Amazon Simple Storage Service API Reference\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1222Amazon Simple Storage Service API Reference\nGetObjectAttributesParts\nService: Amazon S3\nA collection of parts associated with a multipart upload.\nContents\nIsTruncated\nIndicates whether the returned list of parts is truncated.", "A value of true  indicates that the list \nwas truncated. A list can be truncated if the number of parts exceeds the limit returned in the\nMaxParts  element.\nType: Boolean\nRequired: No\nMaxParts\nThe maximum number of parts allowed in the response.\nType: Integer\nRequired: No\nNextPartNumberMarker\nWhen a list is truncated, this element speci\ufb01es the last part in the list, as well as the value to \nuse for the PartNumberMarker  request parameter in a subsequent request.\nType: Integer\nRequired: No\nPartNumberMarker\nThe marker for the current part.\nType: Integer\nRequired: No\nParts\nA container for elements related to a particular part.", "A response can contain zero or more\nParts  elements.\nAmazon S3 API Version 2006-03-01 1223Amazon Simple Storage Service API Reference\nNote\n\u2022General purpose buckets - For GetObjectAttributes , if a additional checksum \n(including x-amz-checksum-crc32 , x-amz-checksum-crc32c , x-amz-\nchecksum-sha1 , or x-amz-checksum-sha256 ) isn't applied to the object speci\ufb01ed \nin the request, the response doesn't return Part .\n\u2022Directory buckets - For GetObjectAttributes , no matter whether a additional \nchecksum is applied to the object speci\ufb01ed in the request, the response returns Part .\nType: Array of ObjectPart data types\nRequired: No\nTotalPartsCount\nThe total number of parts.\nType: Integer\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1224Amazon Simple Storage Service API Reference\nGlacierJobParameters\nService: Amazon S3\nContainer for S3 Glacier job parameters.\nContents\nTier\nRetrieval tier at which the restore will be processed.\nType: String\nValid Values: Standard | Bulk | Expedited\nRequired: Yes\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1225Amazon Simple Storage Service API Reference\nGrant\nService: Amazon S3\nContainer for grant information.\nContents\nGrantee\nThe person being granted permissions.\nType: Grantee  data type\nRequired: No\nPermission\nSpeci\ufb01es the permission given to the grantee.\nType: String\nValid Values: FULL_CONTROL | WRITE | WRITE_ACP | READ | READ_ACP\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1226Amazon Simple Storage Service API Reference\nGrantee\nService: Amazon S3\nContainer for the person being granted permissions.\nContents\nType\nType of grantee\nType: String\nValid Values: CanonicalUser | AmazonCustomerByEmail | Group\nRequired: Yes\nDisplayName\nScreen name of the grantee.\nType: String\nRequired: No\nEmailAddress\nEmail address of the grantee.\nNote\nUsing email addresses to specify a grantee is only supported in the following AWS \nRegions:\n\u2022US East (N.", "Virginia)\n\u2022US West (N.", "California)\n\u2022US West (Oregon)\n\u2022Asia Paci\ufb01c (Singapore)\n\u2022Asia Paci\ufb01c (Sydney)\n\u2022Asia Paci\ufb01c (Tokyo)\n\u2022Europe (Ireland)\n\u2022South America (S\u00e3o Paulo)\nAmazon S3 API Version 2006-03-01 1227Amazon Simple Storage Service API Reference\nFor a list of all the Amazon S3 supported Regions and endpoints, see Regions and \nEndpoints  in the AWS General Reference.\nType: String\nRequired: No\nID\nThe canonical user ID of the grantee.\nType: String\nRequired: No\nURI\nURI of the grantee group.\nType: String\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1228Amazon Simple Storage Service API Reference\nIndexDocument\nService: Amazon S3\nContainer for the Suffix  element.\nContents\nSu\ufb03x\nA su\ufb03x that is appended to a request that is for a directory on the website endpoint.", "(For \nexample, if the su\ufb03x is index.html  and you make a request to samplebucket/images/ , the \ndata that is returned will be for the object with the key name images/index.html .) The su\ufb03x \nmust not be empty and must not include a slash character.\nImportant\nReplacement must be made for object keys containing special characters (such as \ncarriage returns) when using XML requests.", "For more information, see  XML related \nobject key constraints.\nType: String\nRequired: Yes\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1229Amazon Simple Storage Service API Reference\nInitiator\nService: Amazon S3\nContainer element that identi\ufb01es who initiated the multipart upload.\nContents\nDisplayName\nName of the Principal.\nNote\nThis functionality is not supported for directory buckets.\nType: String\nRequired: No\nID\nIf the principal is an AWS account, it provides the Canonical User ID. If the principal is an IAM \nUser, it provides a user ARN value.\nNote\nDirectory buckets - If the principal is an AWS account, it provides the AWS account ID. If \nthe principal is an IAM User, it provides a user ARN value.\nType: String\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\nAmazon S3 API Version 2006-03-01 1230Amazon Simple Storage Service API Reference\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1231Amazon Simple Storage Service API Reference\nInputSerialization\nService: Amazon S3\nDescribes the serialization format of the object.\nContents\nCompressionType\nSpeci\ufb01es object's compression format.", "Valid values: NONE, GZIP, BZIP2.", "Default Value: NONE.\nType: String\nValid Values: NONE | GZIP | BZIP2\nRequired: No\nCSV\nDescribes the serialization of a CSV-encoded object.\nType: CSVInput data type\nRequired: No\nJSON\nSpeci\ufb01es JSON as object's input serialization format.\nType: JSONInput data type\nRequired: No\nParquet\nSpeci\ufb01es Parquet as object's input serialization format.\nType: ParquetInput data type\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\nAmazon S3 API Version 2006-03-01 1232Amazon Simple Storage Service API Reference\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1233Amazon Simple Storage Service API Reference\nIntelligentTieringAndOperator\nService: Amazon S3\nA container for specifying S3 Intelligent-Tiering \ufb01lters. The \ufb01lters determine the subset of objects \nto which the rule applies.\nContents\nPre\ufb01x\nAn object key name pre\ufb01x that identi\ufb01es the subset of objects to which the con\ufb01guration \napplies.\nType: String\nRequired: No\nTags\nAll of these tags must exist in the object's tag set in order for the con\ufb01guration to apply.\nType: Array of Tag data types\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1234Amazon Simple Storage Service API Reference\nIntelligentTieringCon\ufb01guration\nService: Amazon S3\nSpeci\ufb01es the S3 Intelligent-Tiering con\ufb01guration for an Amazon S3 bucket.\nFor information about the S3 Intelligent-Tiering storage class, see Storage class for automatically \noptimizing frequently and infrequently accessed objects.\nContents\nId\nThe ID used to identify the S3 Intelligent-Tiering con\ufb01guration.\nType: String\nRequired: Yes\nStatus\nSpeci\ufb01es the status of the con\ufb01guration.\nType: String\nValid Values: Enabled | Disabled\nRequired: Yes\nTierings\nSpeci\ufb01es the S3 Intelligent-Tiering storage class tier of the con\ufb01guration.\nType: Array of Tiering  data types\nRequired: Yes\nFilter\nSpeci\ufb01es a bucket \ufb01lter. The con\ufb01guration only includes objects that meet the \ufb01lter's criteria.\nType: IntelligentTieringFilter  data type\nRequired: No\nAmazon S3 API Version 2006-03-01 1235Amazon Simple Storage Service API Reference\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1236Amazon Simple Storage Service API Reference\nIntelligentTieringFilter\nService: Amazon S3\nThe Filter is used to identify objects that the S3 Intelligent-Tiering con\ufb01guration applies to.\nContents\nAnd\nA conjunction (logical AND) of predicates, which is used in evaluating a metrics \ufb01lter.", "The \noperator must have at least two predicates, and an object must match all of the predicates in \norder for the \ufb01lter to apply.\nType: IntelligentTieringAndOperator  data type\nRequired: No\nPre\ufb01x\nAn object key name pre\ufb01x that identi\ufb01es the subset of objects to which the rule applies.\nImportant\nReplacement must be made for object keys containing special characters (such as \ncarriage returns) when using XML requests.", "For more information, see  XML related \nobject key constraints.\nType: String\nRequired: No\nTag\nA container of a key value name pair.\nType: Tag data type\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\nAmazon S3 API Version 2006-03-01 1237Amazon Simple Storage Service API Reference\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1238Amazon Simple Storage Service API Reference\nInventoryCon\ufb01guration\nService: Amazon S3\nSpeci\ufb01es the inventory con\ufb01guration for an Amazon S3 bucket. For more information, see GET \nBucket inventory in the Amazon S3 API Reference.\nContents\nDestination\nContains information about where to publish the inventory results.\nType: InventoryDestination data type\nRequired: Yes\nId\nThe ID used to identify the inventory con\ufb01guration.\nType: String\nRequired: Yes\nIncludedObjectVersions\nObject versions to include in the inventory list.", "If set to All, the list includes all the object \nversions, which adds the version-related \ufb01elds VersionId , IsLatest , and DeleteMarker  to \nthe list.", "If set to Current, the list does not contain these version-related \ufb01elds.\nType: String\nValid Values: All | Current\nRequired: Yes\nIsEnabled\nSpeci\ufb01es whether the inventory is enabled or disabled. If set to True, an inventory list is \ngenerated.", "If set to False, no inventory list is generated.\nType: Boolean\nRequired: Yes\nAmazon S3 API Version 2006-03-01 1239Amazon Simple Storage Service API Reference\nSchedule\nSpeci\ufb01es the schedule for generating inventory results.\nType: InventorySchedule data type\nRequired: Yes\nFilter\nSpeci\ufb01es an inventory \ufb01lter. The inventory only includes objects that meet the \ufb01lter's criteria.\nType: InventoryFilter data type\nRequired: No\nOptionalFields\nContains the optional \ufb01elds that are included in the inventory results.\nType: Array of strings\nValid Values: Size | LastModifiedDate | StorageClass | ETag | \nIsMultipartUploaded | ReplicationStatus | EncryptionStatus | \nObjectLockRetainUntilDate | ObjectLockMode | ObjectLockLegalHoldStatus \n| IntelligentTieringAccessTier | BucketKeyStatus | ChecksumAlgorithm | \nObjectAccessControlList | ObjectOwner\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1240Amazon Simple Storage Service API Reference\nInventoryDestination\nService: Amazon S3\nSpeci\ufb01es the inventory con\ufb01guration for an Amazon S3 bucket.\nContents\nS3BucketDestination\nContains the bucket name, \ufb01le format, bucket owner (optional), and pre\ufb01x (optional) where \ninventory results are published.\nType: InventoryS3BucketDestination data type\nRequired: Yes\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1241Amazon Simple Storage Service API Reference\nInventoryEncryption\nService: Amazon S3\nContains the type of server-side encryption used to encrypt the inventory results.\nContents\nSSEKMS\nSpeci\ufb01es the use of SSE-KMS to encrypt delivered inventory reports.\nType: SSEKMS data type\nRequired: No\nSSES3\nSpeci\ufb01es the use of SSE-S3 to encrypt delivered inventory reports.\nType: SSES3 data type\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1242Amazon Simple Storage Service API Reference\nInventoryFilter\nService: Amazon S3\nSpeci\ufb01es an inventory \ufb01lter. The inventory only includes objects that meet the \ufb01lter's criteria.\nContents\nPre\ufb01x\nThe pre\ufb01x that an object must have to be included in the inventory results.\nType: String\nRequired: Yes\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1243Amazon Simple Storage Service API Reference\nInventoryS3BucketDestination\nService: Amazon S3\nContains the bucket name, \ufb01le format, bucket owner (optional), and pre\ufb01x (optional) where \ninventory results are published.\nContents\nBucket\nThe Amazon Resource Name (ARN) of the bucket where inventory results will be published.\nType: String\nRequired: Yes\nFormat\nSpeci\ufb01es the output format of the inventory results.\nType: String\nValid Values: CSV | ORC | Parquet\nRequired: Yes\nAccountId\nThe account ID that owns the destination S3 bucket. If no account ID is provided, the owner is \nnot validated before exporting data.\nNote\nAlthough this value is optional, we strongly recommend that you set it to help prevent \nproblems if the destination bucket ownership changes.\nType: String\nRequired: No\nEncryption\nContains the type of server-side encryption used to encrypt the inventory results.\nAmazon S3 API Version 2006-03-01 1244Amazon Simple Storage Service API Reference\nType: InventoryEncryption data type\nRequired: No\nPre\ufb01x\nThe pre\ufb01x that is prepended to all inventory results.\nType: String\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1245Amazon Simple Storage Service API Reference\nInventorySchedule\nService: Amazon S3\nSpeci\ufb01es the schedule for generating inventory results.\nContents\nFrequency\nSpeci\ufb01es how frequently inventory results are produced.\nType: String\nValid Values: Daily | Weekly\nRequired: Yes\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1246Amazon Simple Storage Service API Reference\nJSONInput\nService: Amazon S3\nSpeci\ufb01es JSON as object's input serialization format.\nContents\nType\nThe type of JSON. Valid values: Document, Lines.\nType: String\nValid Values: DOCUMENT | LINES\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1247Amazon Simple Storage Service API Reference\nJSONOutput\nService: Amazon S3\nSpeci\ufb01es JSON as request's output serialization format.\nContents\nRecordDelimiter\nThe value used to separate individual records in the output. If no value is speci\ufb01ed, Amazon S3 \nuses a newline character ('\\n').\nType: String\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1248Amazon Simple Storage Service API Reference\nLambdaFunctionCon\ufb01guration\nService: Amazon S3\nA container for specifying the con\ufb01guration for AWS Lambda noti\ufb01cations.\nContents\nEvents\nThe Amazon S3 bucket event for which to invoke the AWS Lambda function. For more \ninformation, see Supported Event Types in the Amazon S3 User Guide .\nType: Array of strings\nValid Values: s3:ReducedRedundancyLostObject | s3:ObjectCreated:* | \ns3:ObjectCreated:Put | s3:ObjectCreated:Post | s3:ObjectCreated:Copy \n| s3:ObjectCreated:CompleteMultipartUpload | s3:ObjectRemoved:* | \ns3:ObjectRemoved:Delete | s3:ObjectRemoved:DeleteMarkerCreated | \ns3:ObjectRestore:* | s3:ObjectRestore:Post | s3:ObjectRestore:Completed \n| s3:Replication:* | s3:Replication:OperationFailedReplication | \ns3:Replication:OperationNotTracked | \ns3:Replication:OperationMissedThreshold | \ns3:Replication:OperationReplicatedAfterThreshold | \ns3:ObjectRestore:Delete | s3:LifecycleTransition | \ns3:IntelligentTiering | s3:ObjectAcl:Put | s3:LifecycleExpiration:* | \ns3:LifecycleExpiration:Delete | \ns3:LifecycleExpiration:DeleteMarkerCreated | s3:ObjectTagging:* | \ns3:ObjectTagging:Put | s3:ObjectTagging:Delete\nRequired: Yes\nLambdaFunctionArn\nThe Amazon Resource Name (ARN) of the AWS Lambda function that Amazon S3 invokes when \nthe speci\ufb01ed event type occurs.\nType: String\nRequired: Yes\nAmazon S3 API Version 2006-03-01 1249Amazon Simple Storage Service API Reference\nFilter\nSpeci\ufb01es object key name \ufb01ltering rules. For information about key name \ufb01ltering, see\nCon\ufb01guring event noti\ufb01cations using object key name \ufb01ltering in the Amazon S3 User Guide .\nType: Noti\ufb01cationCon\ufb01gurationFilter  data type\nRequired: No\nId\nAn optional unique identi\ufb01er for con\ufb01gurations in a noti\ufb01cation con\ufb01guration. If you don't \nprovide one, Amazon S3 will assign an ID.\nType: String\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1250Amazon Simple Storage Service API Reference\nLifecycleCon\ufb01guration\nService: Amazon S3\nContainer for lifecycle rules. You can add as many as 1000 rules.\nFor more information see, Managing your storage lifecycle in the Amazon S3 User Guide .\nContents\nRules\nSpeci\ufb01es lifecycle con\ufb01guration rules for an Amazon S3 bucket.\nType: Array of Rule  data types\nRequired: Yes\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1251Amazon Simple Storage Service API Reference\nLifecycleExpiration\nService: Amazon S3\nContainer for the expiration for the lifecycle of the object.\nFor more information see, Managing your storage lifecycle in the Amazon S3 User Guide .\nContents\nDate\nIndicates at what date the object is to be moved or deleted.", "The date value must conform to the \nISO 8601 format.", "The time is always midnight UTC.\nType: Timestamp\nRequired: No\nDays\nIndicates the lifetime, in days, of the objects that are subject to the rule.", "The value must be a \nnon-zero positive integer.\nType: Integer\nRequired: No\nExpiredObjectDeleteMarker\nIndicates whether Amazon S3 will remove a delete marker with no noncurrent versions.", "If set to \ntrue, the delete marker will be expired; if set to false the policy takes no action.", "This cannot be \nspeci\ufb01ed with Days or Date in a Lifecycle Expiration Policy.\nType: Boolean\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\nAmazon S3 API Version 2006-03-01 1252Amazon Simple Storage Service API Reference\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1253Amazon Simple Storage Service API Reference\nLifecycleRule\nService: Amazon S3\nA lifecycle rule for individual objects in an Amazon S3 bucket.\nFor more information see, Managing your storage lifecycle in the Amazon S3 User Guide .\nContents\nStatus\nIf 'Enabled', the rule is currently being applied. If 'Disabled', the rule is not currently being \napplied.\nType: String\nValid Values: Enabled | Disabled\nRequired: Yes\nAbortIncompleteMultipartUpload\nSpeci\ufb01es the days since the initiation of an incomplete multipart upload that Amazon S3 will \nwait before permanently removing all parts of the upload. For more information, see  Aborting \nIncomplete Multipart Uploads Using a Bucket Lifecycle Con\ufb01guration in the Amazon S3 User \nGuide .\nType: AbortIncompleteMultipartUpload data type\nRequired: No\nExpiration\nSpeci\ufb01es the expiration for the lifecycle of the object in the form of date, days and, whether the \nobject has a delete marker.\nType: LifecycleExpiration data type\nRequired: No\nFilter\nThe Filter is used to identify objects that a Lifecycle Rule applies to.", "A Filter must have \nexactly one of Prefix , Tag, or And speci\ufb01ed.", "Filter is required if the LifecycleRule  does \nnot contain a Prefix  element.\nAmazon S3 API Version 2006-03-01 1254Amazon Simple Storage Service API Reference\nType: LifecycleRuleFilter data type\nRequired: No\nID\nUnique identi\ufb01er for the rule.", "The value cannot be longer than 255 characters.\nType: String\nRequired: No\nNoncurrentVersionExpiration\nSpeci\ufb01es when noncurrent object versions expire.", "Upon expiration, Amazon S3 permanently \ndeletes the noncurrent object versions. You set this lifecycle con\ufb01guration action on a bucket \nthat has versioning enabled (or suspended) to request that Amazon S3 delete noncurrent object \nversions at a speci\ufb01c period in the object's lifetime.\nType: NoncurrentVersionExpiration data type\nRequired: No\nNoncurrentVersionTransitions\nSpeci\ufb01es the transition rule for the lifecycle rule that describes when noncurrent objects \ntransition to a speci\ufb01c storage class. If your bucket is versioning-enabled (or versioning is \nsuspended), you can set this action to request that Amazon S3 transition noncurrent object \nversions to a speci\ufb01c storage class at a set period in the object's lifetime.\nType: Array of NoncurrentVersionTransition data types\nRequired: No\nPre\ufb01x\nThis member has been deprecated.\nPre\ufb01x identifying one or more objects to which the rule applies. This is no longer used; use\nFilter  instead.\nAmazon S3 API Version 2006-03-01 1255Amazon Simple Storage Service API Reference\nImportant\nReplacement must be made for object keys containing special characters (such as \ncarriage returns) when using XML requests. For more information, see  XML related \nobject key constraints.\nType: String\nRequired: No\nTransitions\nSpeci\ufb01es when an Amazon S3 object transitions to a speci\ufb01ed storage class.\nType: Array of Transition data types\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1256Amazon Simple Storage Service API Reference\nLifecycleRuleAndOperator\nService: Amazon S3\nThis is used in a Lifecycle Rule Filter to apply a logical AND to two or more predicates. The Lifecycle \nRule will apply to any object matching all of the predicates con\ufb01gured inside the And operator.\nContents\nObjectSizeGreaterThan\nMinimum object size to which the rule applies.\nType: Long\nRequired: No\nObjectSizeLessThan\nMaximum object size to which the rule applies.\nType: Long\nRequired: No\nPre\ufb01x\nPre\ufb01x identifying one or more objects to which the rule applies.\nType: String\nRequired: No\nTags\nAll of these tags must exist in the object's tag set in order for the rule to apply.\nType: Array of Tag data types\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\nAmazon S3 API Version 2006-03-01 1257Amazon Simple Storage Service API Reference\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1258Amazon Simple Storage Service API Reference\nLifecycleRuleFilter\nService: Amazon S3\nThe Filter is used to identify objects that a Lifecycle Rule applies to.", "A Filter can have exactly \none of Prefix , Tag, ObjectSizeGreaterThan , ObjectSizeLessThan , or And speci\ufb01ed.", "If the\nFilter element is left empty, the Lifecycle Rule applies to all objects in the bucket.\nContents\nAnd\nThis is used in a Lifecycle Rule Filter to apply a logical AND to two or more predicates. The \nLifecycle Rule will apply to any object matching all of the predicates con\ufb01gured inside the And \noperator.\nType: LifecycleRuleAndOperator data type\nRequired: No\nObjectSizeGreaterThan\nMinimum object size to which the rule applies.\nType: Long\nRequired: No\nObjectSizeLessThan\nMaximum object size to which the rule applies.\nType: Long\nRequired: No\nPre\ufb01x\nPre\ufb01x identifying one or more objects to which the rule applies.\nImportant\nReplacement must be made for object keys containing special characters (such as \ncarriage returns) when using XML requests.", "For more information, see  XML related \nobject key constraints.\nAmazon S3 API Version 2006-03-01 1259Amazon Simple Storage Service API Reference\nType: String\nRequired: No\nTag\nThis tag must exist in the object's tag set in order for the rule to apply.\nType: Tag data type\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1260Amazon Simple Storage Service API Reference\nLocationInfo\nService: Amazon S3\nSpeci\ufb01es the location where the bucket will be created.\nFor directory buckets, the location type is Availability Zone.", "For more information about directory \nbuckets, see Directory buckets in the Amazon S3 User Guide .\nNote\nThis functionality is only supported by directory buckets.\nContents\nName\nThe name of the location where the bucket will be created.\nFor directory buckets, the name of the location is the AZ ID of the Availability Zone where the \nbucket will be created. An example AZ ID value is usw2-az1 .\nType: String\nRequired: No\nType\nThe type of location where the bucket will be created.\nType: String\nValid Values: AvailabilityZone\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\nAmazon S3 API Version 2006-03-01 1261Amazon Simple Storage Service API Reference\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1262Amazon Simple Storage Service API Reference\nLoggingEnabled\nService: Amazon S3\nDescribes where logs are stored and the pre\ufb01x that Amazon S3 assigns to all log object keys for a \nbucket. For more information, see PUT Bucket logging in the Amazon S3 API Reference.\nContents\nTargetBucket\nSpeci\ufb01es the bucket where you want Amazon S3 to store server access logs.", "You can have your \nlogs delivered to any bucket that you own, including the same bucket that is being logged. You \ncan also con\ufb01gure multiple buckets to deliver their logs to the same target bucket. In this case, \nyou should choose a di\ufb00erent TargetPrefix  for each source bucket so that the delivered log \n\ufb01les can be distinguished by key.\nType: String\nRequired: Yes\nTargetPre\ufb01x\nA pre\ufb01x for all log object keys.", "If you store log \ufb01les from multiple Amazon S3 buckets in a single \nbucket, you can use a pre\ufb01x to distinguish which log \ufb01les came from which bucket.\nType: String\nRequired: Yes\nTargetGrants\nContainer for granting information.\nBuckets that use the bucket owner enforced setting for Object Ownership don't support target \ngrants. For more information, see Permissions for server access log delivery in the Amazon S3 \nUser Guide .\nType: Array of TargetGrant data types\nRequired: No\nTargetObjectKeyFormat\nAmazon S3 key format for log objects.\nAmazon S3 API Version 2006-03-01 1263Amazon Simple Storage Service API Reference\nType: TargetObjectKeyFormat data type\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1264Amazon Simple Storage Service API Reference\nMetadataEntry\nService: Amazon S3\nA metadata key-value pair to store with an object.\nContents\nName\nName of the object.\nType: String\nRequired: No\nValue\nValue of the object.\nType: String\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1265Amazon Simple Storage Service API Reference\nMetrics\nService: Amazon S3\nA container specifying replication metrics-related settings enabling replication metrics and events.\nContents\nStatus\nSpeci\ufb01es whether the replication metrics are enabled.\nType: String\nValid Values: Enabled | Disabled\nRequired: Yes\nEventThreshold\nA container specifying the time threshold for emitting the\ns3:Replication:OperationMissedThreshold  event.\nType: ReplicationTimeValue data type\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1266Amazon Simple Storage Service API Reference\nMetricsAndOperator\nService: Amazon S3\nA conjunction (logical AND) of predicates, which is used in evaluating a metrics \ufb01lter. The operator \nmust have at least two predicates, and an object must match all of the predicates in order for the \n\ufb01lter to apply.\nContents\nAccessPointArn\nThe access point ARN used when evaluating an AND predicate.\nType: String\nRequired: No\nPre\ufb01x\nThe pre\ufb01x used when evaluating an AND predicate.\nType: String\nRequired: No\nTags\nThe list of tags used when evaluating an AND predicate.\nType: Array of Tag data types\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1267Amazon Simple Storage Service API Reference\nMetricsCon\ufb01guration\nService: Amazon S3\nSpeci\ufb01es a metrics con\ufb01guration for the CloudWatch request metrics (speci\ufb01ed by the \nmetrics con\ufb01guration ID) from an Amazon S3 bucket.", "If you're updating an existing metrics \ncon\ufb01guration, note that this is a full replacement of the existing metrics con\ufb01guration.", "If \nyou don't include the elements you want to keep, they are erased.", "For more information, see\nPutBucketMetricsCon\ufb01guration.\nContents\nId\nThe ID used to identify the metrics con\ufb01guration.", "The ID has a 64 character limit and can only \ncontain letters, numbers, periods, dashes, and underscores.\nType: String\nRequired: Yes\nFilter\nSpeci\ufb01es a metrics con\ufb01guration \ufb01lter. The metrics con\ufb01guration will only include objects \nthat meet the \ufb01lter's criteria. A \ufb01lter must be a pre\ufb01x, an object tag, an access point ARN, or a \nconjunction (MetricsAndOperator).\nType: MetricsFilter  data type\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1268Amazon Simple Storage Service API Reference\nMetricsFilter\nService: Amazon S3\nSpeci\ufb01es a metrics con\ufb01guration \ufb01lter. The metrics con\ufb01guration only includes objects that meet \nthe \ufb01lter's criteria. A \ufb01lter must be a pre\ufb01x, an object tag, an access point ARN, or a conjunction \n(MetricsAndOperator). For more information, see PutBucketMetricsCon\ufb01guration.\nContents\nAccessPointArn\nThe access point ARN used when evaluating a metrics \ufb01lter.\nType: String\nRequired: No\nAnd\nA conjunction (logical AND) of predicates, which is used in evaluating a metrics \ufb01lter.", "The \noperator must have at least two predicates, and an object must match all of the predicates in \norder for the \ufb01lter to apply.\nType: MetricsAndOperator  data type\nRequired: No\nPre\ufb01x\nThe pre\ufb01x used when evaluating a metrics \ufb01lter.\nType: String\nRequired: No\nTag\nThe tag used when evaluating a metrics \ufb01lter.\nType: Tag data type\nRequired: No\nAmazon S3 API Version 2006-03-01 1269Amazon Simple Storage Service API Reference\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1270Amazon Simple Storage Service API Reference\nMultipartUpload\nService: Amazon S3\nContainer for the MultipartUpload  for the Amazon S3 object.\nContents\nChecksumAlgorithm\nThe algorithm that was used to create a checksum of the object.\nType: String\nValid Values: CRC32 | CRC32C | SHA1 | SHA256\nRequired: No\nInitiated\nDate and time at which the multipart upload was initiated.\nType: Timestamp\nRequired: No\nInitiator\nIdenti\ufb01es who initiated the multipart upload.\nType: Initiator  data type\nRequired: No\nKey\nKey of the object for which the multipart upload was initiated.\nType: String\nLength Constraints: Minimum length of 1.\nRequired: No\nOwner\nSpeci\ufb01es the owner of the object that is part of the multipart upload.\nAmazon S3 API Version 2006-03-01 1271Amazon Simple Storage Service API Reference\nNote\nDirectory buckets - The bucket owner is returned as the object owner for all the \nobjects.\nType: Owner  data type\nRequired: No\nStorageClass\nThe class of storage used to store the object.\nNote\nDirectory buckets - Only the S3 Express One Zone storage class is supported by \ndirectory buckets to store objects.\nType: String\nValid Values: STANDARD | REDUCED_REDUNDANCY | STANDARD_IA | ONEZONE_IA | \nINTELLIGENT_TIERING | GLACIER | DEEP_ARCHIVE | OUTPOSTS | GLACIER_IR | \nSNOW | EXPRESS_ONEZONE\nRequired: No\nUploadId\nUpload ID that identi\ufb01es the multipart upload.\nType: String\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\nAmazon S3 API Version 2006-03-01 1272Amazon Simple Storage Service API Reference\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1273Amazon Simple Storage Service API Reference\nNoncurrentVersionExpiration\nService: Amazon S3\nSpeci\ufb01es when noncurrent object versions expire. Upon expiration, Amazon S3 permanently \ndeletes the noncurrent object versions. You set this lifecycle con\ufb01guration action on a bucket \nthat has versioning enabled (or suspended) to request that Amazon S3 delete noncurrent object \nversions at a speci\ufb01c period in the object's lifetime.\nContents\nNewerNoncurrentVersions\nSpeci\ufb01es how many noncurrent versions Amazon S3 will retain.", "You can specify up to 100 \nnoncurrent versions to retain.", "Amazon S3 will permanently delete any additional noncurrent \nversions beyond the speci\ufb01ed number to retain. For more information about noncurrent \nversions, see Lifecycle con\ufb01guration elements in the Amazon S3 User Guide .\nType: Integer\nRequired: No\nNoncurrentDays\nSpeci\ufb01es the number of days an object is noncurrent before Amazon S3 can perform the \nassociated action.", "The value must be a non-zero positive integer.", "For information about \nthe noncurrent days calculations, see How Amazon S3 Calculates When an Object Became \nNoncurrent in the Amazon S3 User Guide .\nType: Integer\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1274Amazon Simple Storage Service API Reference\nAmazon S3 API Version 2006-03-01 1275Amazon Simple Storage Service API Reference\nNoncurrentVersionTransition\nService: Amazon S3\nContainer for the transition rule that describes when noncurrent objects transition to \nthe STANDARD_IA , ONEZONE_IA , INTELLIGENT_TIERING , GLACIER_IR , GLACIER , or\nDEEP_ARCHIVE  storage class. If your bucket is versioning-enabled (or versioning is suspended), \nyou can set this action to request that Amazon S3 transition noncurrent object versions to \nthe STANDARD_IA , ONEZONE_IA , INTELLIGENT_TIERING , GLACIER_IR , GLACIER , or\nDEEP_ARCHIVE  storage class at a speci\ufb01c period in the object's lifetime.\nContents\nNewerNoncurrentVersions\nSpeci\ufb01es how many noncurrent versions Amazon S3 will retain in the same storage class before \ntransitioning objects.", "You can specify up to 100 noncurrent versions to retain.", "Amazon S3 will \ntransition any additional noncurrent versions beyond the speci\ufb01ed number to retain. For more \ninformation about noncurrent versions, see Lifecycle con\ufb01guration elements in the Amazon S3 \nUser Guide .\nType: Integer\nRequired: No\nNoncurrentDays\nSpeci\ufb01es the number of days an object is noncurrent before Amazon S3 can perform the \nassociated action. For information about the noncurrent days calculations, see How Amazon S3 \nCalculates How Long an Object Has Been Noncurrent in the Amazon S3 User Guide .\nType: Integer\nRequired: No\nStorageClass\nThe class of storage used to store the object.\nType: String\nValid Values: GLACIER | STANDARD_IA | ONEZONE_IA | INTELLIGENT_TIERING | \nDEEP_ARCHIVE | GLACIER_IR\nAmazon S3 API Version 2006-03-01 1276Amazon Simple Storage Service API Reference\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1277Amazon Simple Storage Service API Reference\nNoti\ufb01cationCon\ufb01guration\nService: Amazon S3\nA container for specifying the noti\ufb01cation con\ufb01guration of the bucket. If this element is empty, \nnoti\ufb01cations are turned o\ufb00 for the bucket.\nContents\nEventBridgeCon\ufb01guration\nEnables delivery of events to Amazon EventBridge.\nType: EventBridgeCon\ufb01guration data type\nRequired: No\nLambdaFunctionCon\ufb01gurations\nDescribes the AWS Lambda functions to invoke and the events for which to invoke them.\nType: Array of LambdaFunctionCon\ufb01guration data types\nRequired: No\nQueueCon\ufb01gurations\nThe Amazon Simple Queue Service queues to publish messages to and the events for which to \npublish messages.\nType: Array of QueueCon\ufb01guration  data types\nRequired: No\nTopicCon\ufb01gurations\nThe topic to which noti\ufb01cations are sent and the events for which noti\ufb01cations are generated.\nType: Array of TopicCon\ufb01guration data types\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\nAmazon S3 API Version 2006-03-01 1278Amazon Simple Storage Service API Reference\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1279Amazon Simple Storage Service API Reference\nNoti\ufb01cationCon\ufb01gurationDeprecated\nService: Amazon S3\nContents\nCloudFunctionCon\ufb01guration\nContainer for specifying the AWS Lambda noti\ufb01cation con\ufb01guration.\nType: CloudFunctionCon\ufb01guration data type\nRequired: No\nQueueCon\ufb01guration\nThis data type is deprecated. This data type speci\ufb01es the con\ufb01guration for publishing messages \nto an Amazon Simple Queue Service (Amazon SQS) queue when Amazon S3 detects speci\ufb01ed \nevents.\nType: QueueCon\ufb01gurationDeprecated data type\nRequired: No\nTopicCon\ufb01guration\nThis data type is deprecated. A container for specifying the con\ufb01guration for publication of \nmessages to an Amazon Simple Noti\ufb01cation Service (Amazon SNS) topic when Amazon S3 \ndetects speci\ufb01ed events.\nType: TopicCon\ufb01gurationDeprecated data type\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1280Amazon Simple Storage Service API Reference\nNoti\ufb01cationCon\ufb01gurationFilter\nService: Amazon S3\nSpeci\ufb01es object key name \ufb01ltering rules. For information about key name \ufb01ltering, see Con\ufb01guring \nevent noti\ufb01cations using object key name \ufb01ltering in the Amazon S3 User Guide .\nContents\nKey\nA container for object key name pre\ufb01x and su\ufb03x \ufb01ltering rules.\nType: S3KeyFilter data type\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1281Amazon Simple Storage Service API Reference\nObject\nService: Amazon S3\nAn object consists of data and its descriptive metadata.\nContents\nChecksumAlgorithm\nThe algorithm that was used to create a checksum of the object.\nType: Array of strings\nValid Values: CRC32 | CRC32C | SHA1 | SHA256\nRequired: No\nETag\nThe entity tag is a hash of the object.", "The ETag re\ufb02ects changes only to the contents of an \nobject, not its metadata. The ETag may or may not be an MD5 digest of the object data. \nWhether or not it is depends on how the object was created and how it is encrypted as \ndescribed below:\n\u2022Objects created by the PUT Object, POST Object, or Copy operation, or through the AWS \nManagement Console, and are encrypted by SSE-S3 or plaintext, have ETags that are an MD5 \ndigest of their object data.\n\u2022Objects created by the PUT Object, POST Object, or Copy operation, or through the AWS \nManagement Console, and are encrypted by SSE-C or SSE-KMS, have ETags that are not an \nMD5 digest of their object data.\n\u2022If an object is created by either the Multipart Upload or Part Copy operation, the ETag is not \nan MD5 digest, regardless of the method of encryption. If an object is larger than 16 MB, \nthe AWS Management Console will upload or copy that object as a Multipart Upload, and \ntherefore the ETag will not be an MD5 digest.\nNote\nDirectory buckets - MD5 is not supported by directory buckets.\nType: String\nAmazon S3 API Version 2006-03-01 1282Amazon Simple Storage Service API Reference\nRequired: No\nKey\nThe name that you assign to an object. You use the object key to retrieve the object.\nType: String\nLength Constraints: Minimum length of 1.\nRequired: No\nLastModi\ufb01ed\nCreation date of the object.\nType: Timestamp\nRequired: No\nOwner\nThe owner of the object\nNote\nDirectory buckets - The bucket owner is returned as the object owner.\nType: Owner  data type\nRequired: No\nRestoreStatus\nSpeci\ufb01es the restoration status of an object. Objects in certain storage classes must be restored \nbefore they can be retrieved.", "For more information about these storage classes and how to \nwork with archived objects, see  Working with archived objects in the Amazon S3 User Guide .\nNote\nThis functionality is not supported for directory buckets. Only the S3 Express One Zone \nstorage class is supported by directory buckets to store objects.\nAmazon S3 API Version 2006-03-01 1283Amazon Simple Storage Service API Reference\nType: RestoreStatus data type\nRequired: No\nSize\nSize in bytes of the object\nType: Long\nRequired: No\nStorageClass\nThe class of storage used to store the object.\nNote\nDirectory buckets - Only the S3 Express One Zone storage class is supported by \ndirectory buckets to store objects.\nType: String\nValid Values: STANDARD | REDUCED_REDUNDANCY | GLACIER | STANDARD_IA | \nONEZONE_IA | INTELLIGENT_TIERING | DEEP_ARCHIVE | OUTPOSTS | GLACIER_IR \n| SNOW | EXPRESS_ONEZONE\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1284Amazon Simple Storage Service API Reference\nObjectIdenti\ufb01er\nService: Amazon S3\nObject Identi\ufb01er is unique value to identify objects.\nContents\nKey\nKey name of the object.\nImportant\nReplacement must be made for object keys containing special characters (such as \ncarriage returns) when using XML requests. For more information, see  XML related \nobject key constraints.\nType: String\nLength Constraints: Minimum length of 1.\nRequired: Yes\nVersionId\nVersion ID for the speci\ufb01c version of the object to delete.\nNote\nThis functionality is not supported for directory buckets.\nType: String\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\nAmazon S3 API Version 2006-03-01 1285Amazon Simple Storage Service API Reference\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1286Amazon Simple Storage Service API Reference\nObjectLockCon\ufb01guration\nService: Amazon S3\nThe container element for Object Lock con\ufb01guration parameters.\nContents\nObjectLockEnabled\nIndicates whether this bucket has an Object Lock con\ufb01guration enabled. Enable\nObjectLockEnabled  when you apply ObjectLockConfiguration  to a bucket.\nType: String\nValid Values: Enabled\nRequired: No\nRule\nSpeci\ufb01es the Object Lock rule for the speci\ufb01ed object. Enable the this rule when you apply\nObjectLockConfiguration  to a bucket. Bucket settings require both a mode and a period.", "\nThe period can be either Days  or Years but you must select one.", "You cannot specify Days  and\nYears  at the same time.\nType: ObjectLockRule data type\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1287Amazon Simple Storage Service API Reference\nObjectLockLegalHold\nService: Amazon S3\nA legal hold con\ufb01guration for an object.\nContents\nStatus\nIndicates whether the speci\ufb01ed object has a legal hold in place.\nType: String\nValid Values: ON | OFF\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1288Amazon Simple Storage Service API Reference\nObjectLockRetention\nService: Amazon S3\nA Retention con\ufb01guration for an object.\nContents\nMode\nIndicates the Retention mode for the speci\ufb01ed object.\nType: String\nValid Values: GOVERNANCE | COMPLIANCE\nRequired: No\nRetainUntilDate\nThe date on which this Object Lock Retention will expire.\nType: Timestamp\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1289Amazon Simple Storage Service API Reference\nObjectLockRule\nService: Amazon S3\nThe container element for an Object Lock rule.\nContents\nDefaultRetention\nThe default Object Lock retention mode and period that you want to apply to new objects \nplaced in the speci\ufb01ed bucket.", "Bucket settings require both a mode and a period.", "The period \ncan be either Days  or Years but you must select one.", "You cannot specify Days  and Years  at \nthe same time.\nType: DefaultRetention data type\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1290Amazon Simple Storage Service API Reference\nObjectPart\nService: Amazon S3\nA container for elements related to an individual part.\nContents\nChecksumCRC32\nThis header can be used as a data integrity check to verify that the data received is the same \ndata that was originally sent.", "This header speci\ufb01es the base64-encoded, 32-bit CRC-32 \nchecksum of the object.", "For more information, see Checking object integrity in the Amazon S3 \nUser Guide .\nType: String\nRequired: No\nChecksumCRC32C\nThe base64-encoded, 32-bit CRC-32C checksum of the object.", "This will only be present if it was \nuploaded with the object. When you use an API operation on an object that was uploaded using \nmultipart uploads, this value may not be a direct checksum value of the full object. Instead, \nit's a calculation based on the checksum values of each individual part.", "For more information \nabout how checksums are calculated with multipart uploads, see  Checking object integrity in \nthe Amazon S3 User Guide .\nType: String\nRequired: No\nChecksumSHA1\nThe base64-encoded, 160-bit SHA-1 digest of the object.", "This will only be present if it was \nuploaded with the object. When you use the API operation on an object that was uploaded \nusing multipart uploads, this value may not be a direct checksum value of the full object.", "\nInstead, it's a calculation based on the checksum values of each individual part.", "For more \ninformation about how checksums are calculated with multipart uploads, see  Checking object \nintegrity in the Amazon S3 User Guide .\nType: String\nRequired: No\nAmazon S3 API Version 2006-03-01 1291Amazon Simple Storage Service API Reference\nChecksumSHA256\nThe base64-encoded, 256-bit SHA-256 digest of the object.", "This will only be present if it was \nuploaded with the object. When you use an API operation on an object that was uploaded using \nmultipart uploads, this value may not be a direct checksum value of the full object. Instead, \nit's a calculation based on the checksum values of each individual part.", "For more information \nabout how checksums are calculated with multipart uploads, see  Checking object integrity in \nthe Amazon S3 User Guide .\nType: String\nRequired: No\nPartNumber\nThe part number identifying the part. This value is a positive integer between 1 and 10,000.\nType: Integer\nRequired: No\nSize\nThe size of the uploaded part in bytes.\nType: Long\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1292Amazon Simple Storage Service API Reference\nObjectVersion\nService: Amazon S3\nThe version of an object.\nContents\nChecksumAlgorithm\nThe algorithm that was used to create a checksum of the object.\nType: Array of strings\nValid Values: CRC32 | CRC32C | SHA1 | SHA256\nRequired: No\nETag\nThe entity tag is an MD5 hash of that version of the object.\nType: String\nRequired: No\nIsLatest\nSpeci\ufb01es whether the object is (true) or is not (false) the latest version of an object.\nType: Boolean\nRequired: No\nKey\nThe object key.\nType: String\nLength Constraints: Minimum length of 1.\nRequired: No\nLastModi\ufb01ed\nDate and time when the object was last modi\ufb01ed.\nAmazon S3 API Version 2006-03-01 1293Amazon Simple Storage Service API Reference\nType: Timestamp\nRequired: No\nOwner\nSpeci\ufb01es the owner of the object.\nType: Owner  data type\nRequired: No\nRestoreStatus\nSpeci\ufb01es the restoration status of an object.", "Objects in certain storage classes must be restored \nbefore they can be retrieved.", "For more information about these storage classes and how to \nwork with archived objects, see  Working with archived objects in the Amazon S3 User Guide .\nType: RestoreStatus data type\nRequired: No\nSize\nSize in bytes of the object.\nType: Long\nRequired: No\nStorageClass\nThe class of storage used to store the object.\nType: String\nValid Values: STANDARD\nRequired: No\nVersionId\nVersion ID of an object.\nType: String\nRequired: No\nAmazon S3 API Version 2006-03-01 1294Amazon Simple Storage Service API Reference\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1295Amazon Simple Storage Service API Reference\nOutputLocation\nService: Amazon S3\nDescribes the location where the restore job's output is stored.\nContents\nS3\nDescribes an S3 location that will receive the results of the restore request.\nType: S3Location  data type\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1296Amazon Simple Storage Service API Reference\nOutputSerialization\nService: Amazon S3\nDescribes how results of the Select job are serialized.\nContents\nCSV\nDescribes the serialization of CSV-encoded Select results.\nType: CSVOutput data type\nRequired: No\nJSON\nSpeci\ufb01es JSON as request's output serialization format.\nType: JSONOutput data type\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1297Amazon Simple Storage Service API Reference\nOwner\nService: Amazon S3\nContainer for the owner's display name and ID.\nContents\nDisplayName\nContainer for the display name of the owner.", "This value is only supported in the following AWS \nRegions:\n\u2022US East (N.", "Virginia)\n\u2022US West (N.", "California)\n\u2022US West (Oregon)\n\u2022Asia Paci\ufb01c (Singapore)\n\u2022Asia Paci\ufb01c (Sydney)\n\u2022Asia Paci\ufb01c (Tokyo)\n\u2022Europe (Ireland)\n\u2022South America (S\u00e3o Paulo)\nNote\nThis functionality is not supported for directory buckets.\nType: String\nRequired: No\nID\nContainer for the ID of the owner.\nType: String\nRequired: No\nAmazon S3 API Version 2006-03-01 1298Amazon Simple Storage Service API Reference\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1299Amazon Simple Storage Service API Reference\nOwnershipControls\nService: Amazon S3\nThe container element for a bucket's ownership controls.\nContents\nRules\nThe container element for an ownership control rule.\nType: Array of OwnershipControlsRule data types\nRequired: Yes\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1300Amazon Simple Storage Service API Reference\nOwnershipControlsRule\nService: Amazon S3\nThe container element for an ownership control rule.\nContents\nObjectOwnership\nThe container element for object ownership for a bucket's ownership controls.\nBucketOwnerPreferred  - Objects uploaded to the bucket change ownership to the bucket \nowner if the objects are uploaded with the bucket-owner-full-control  canned ACL.\nObjectWriter  - The uploading account will own the object if the object is uploaded with the\nbucket-owner-full-control  canned ACL.\nBucketOwnerEnforced  - Access control lists (ACLs) are disabled and no longer a\ufb00ect \npermissions. The bucket owner automatically owns and has full control over every object in \nthe bucket. The bucket only accepts PUT requests that don't specify an ACL or specify bucket \nowner full control ACLs (such as the prede\ufb01ned bucket-owner-full-control  canned ACL or \na custom ACL in XML format that grants the same permissions).\nBy default, ObjectOwnership  is set to BucketOwnerEnforced  and ACLs are disabled.", "We \nrecommend keeping ACLs disabled, except in uncommon use cases where you must control \naccess for each object individually.", "For more information about S3 Object Ownership, see\nControlling ownership of objects and disabling ACLs for your bucket in the Amazon S3 User \nGuide .\nNote\nThis functionality is not supported for directory buckets. Directory buckets use the \nbucket owner enforced setting for S3 Object Ownership.\nType: String\nValid Values: BucketOwnerPreferred | ObjectWriter | BucketOwnerEnforced\nRequired: Yes\nAmazon S3 API Version 2006-03-01 1301Amazon Simple Storage Service API Reference\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1302Amazon Simple Storage Service API Reference\nParquetInput\nService: Amazon S3\nContainer for Parquet.\nContents\nThe members of this exception structure are context-dependent.\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1303Amazon Simple Storage Service API Reference\nPart\nService: Amazon S3\nContainer for elements related to a part.\nContents\nChecksumCRC32\nThis header can be used as a data integrity check to verify that the data received is the same \ndata that was originally sent.", "This header speci\ufb01es the base64-encoded, 32-bit CRC-32 \nchecksum of the object.", "For more information, see Checking object integrity in the Amazon S3 \nUser Guide .\nType: String\nRequired: No\nChecksumCRC32C\nThe base64-encoded, 32-bit CRC-32C checksum of the object.", "This will only be present if it was \nuploaded with the object. When you use an API operation on an object that was uploaded using \nmultipart uploads, this value may not be a direct checksum value of the full object. Instead, \nit's a calculation based on the checksum values of each individual part.", "For more information \nabout how checksums are calculated with multipart uploads, see  Checking object integrity in \nthe Amazon S3 User Guide .\nType: String\nRequired: No\nChecksumSHA1\nThe base64-encoded, 160-bit SHA-1 digest of the object.", "This will only be present if it was \nuploaded with the object. When you use the API operation on an object that was uploaded \nusing multipart uploads, this value may not be a direct checksum value of the full object.", "\nInstead, it's a calculation based on the checksum values of each individual part.", "For more \ninformation about how checksums are calculated with multipart uploads, see  Checking object \nintegrity in the Amazon S3 User Guide .\nType: String\nRequired: No\nAmazon S3 API Version 2006-03-01 1304Amazon Simple Storage Service API Reference\nChecksumSHA256\nThis header can be used as a data integrity check to verify that the data received is the same \ndata that was originally sent.", "This header speci\ufb01es the base64-encoded, 256-bit SHA-256 digest \nof the object.", "For more information, see Checking object integrity in the Amazon S3 User Guide .\nType: String\nRequired: No\nETag\nEntity tag returned when the part was uploaded.\nType: String\nRequired: No\nLastModi\ufb01ed\nDate and time at which the part was uploaded.\nType: Timestamp\nRequired: No\nPartNumber\nPart number identifying the part. This is a positive integer between 1 and 10,000.\nType: Integer\nRequired: No\nSize\nSize in bytes of the uploaded part data.\nType: Long\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\nAmazon S3 API Version 2006-03-01 1305Amazon Simple Storage Service API Reference\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1306Amazon Simple Storage Service API Reference\nPartitionedPre\ufb01x\nService: Amazon S3\nAmazon S3 keys for log objects are partitioned in the following format:\n[DestinationPrefix][SourceAccountId]/[SourceRegion]/[SourceBucket]/[YYYY]/\n[MM]/[DD]/[YYYY]-[MM]-[DD]-[hh]-[mm]-[ss]-[UniqueString]\nPartitionedPre\ufb01x defaults to EventTime delivery when server access logs are delivered.\nContents\nPartitionDateSource\nSpeci\ufb01es the partition date source for the partitioned pre\ufb01x.", "PartitionDateSource  can be\nEventTime  or DeliveryTime .\nFor DeliveryTime , the time in the log \ufb01le names corresponds to the delivery time for the log \n\ufb01les.\nFor EventTime , The logs delivered are for a speci\ufb01c day only.", "The year, month, and day \ncorrespond to the day on which the event occurred, and the hour, minutes and seconds are set \nto 00 in the key.\nType: String\nValid Values: EventTime | DeliveryTime\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1307Amazon Simple Storage Service API Reference\nPolicyStatus\nService: Amazon S3\nThe container element for a bucket's policy status.\nContents\nIsPublic\nThe policy status for this bucket.", "TRUE indicates that this bucket is public.", "FALSE  indicates that \nthe bucket is not public.\nType: Boolean\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1308Amazon Simple Storage Service API Reference\nProgress\nService: Amazon S3\nThis data type contains information about progress of an operation.\nContents\nBytesProcessed\nThe current number of uncompressed object bytes processed.\nType: Long\nRequired: No\nBytesReturned\nThe current number of bytes of records payload data returned.\nType: Long\nRequired: No\nBytesScanned\nThe current number of object bytes scanned.\nType: Long\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1309Amazon Simple Storage Service API Reference\nProgressEvent\nService: Amazon S3\nThis data type contains information about the progress event of an operation.\nContents\nDetails\nThe Progress event details.\nType: Progress data type\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1310Amazon Simple Storage Service API Reference\nPublicAccessBlockCon\ufb01guration\nService: Amazon S3\nThe PublicAccessBlock con\ufb01guration that you want to apply to this Amazon S3 bucket.", "You can \nenable the con\ufb01guration options in any combination.", "For more information about when Amazon \nS3 considers a bucket or object public, see The Meaning of \"Public\" in the Amazon S3 User Guide .\nContents\nBlockPublicAcls\nSpeci\ufb01es whether Amazon S3 should block public access control lists (ACLs) for this bucket and \nobjects in this bucket. Setting this element to TRUE causes the following behavior:\n\u2022PUT Bucket ACL and PUT Object ACL calls fail if the speci\ufb01ed ACL is public.\n\u2022PUT Object calls fail if the request includes a public ACL.\n\u2022PUT Bucket calls fail if the request includes a public ACL.\nEnabling this setting doesn't a\ufb00ect existing policies or ACLs.\nType: Boolean\nRequired: No\nBlockPublicPolicy\nSpeci\ufb01es whether Amazon S3 should block public bucket policies for this bucket. Setting this \nelement to TRUE causes Amazon S3 to reject calls to PUT Bucket policy if the speci\ufb01ed bucket \npolicy allows public access.\nEnabling this setting doesn't a\ufb00ect existing bucket policies.\nType: Boolean\nRequired: No\nIgnorePublicAcls\nSpeci\ufb01es whether Amazon S3 should ignore public ACLs for this bucket and objects in this \nbucket. Setting this element to TRUE causes Amazon S3 to ignore all public ACLs on this bucket \nand objects in this bucket.\nEnabling this setting doesn't a\ufb00ect the persistence of any existing ACLs and doesn't prevent \nnew public ACLs from being set.\nAmazon S3 API Version 2006-03-01 1311Amazon Simple Storage Service API Reference\nType: Boolean\nRequired: No\nRestrictPublicBuckets\nSpeci\ufb01es whether Amazon S3 should restrict public bucket policies for this bucket. Setting this \nelement to TRUE restricts access to this bucket to only AWS service principals and authorized \nusers within this account if the bucket has a public policy.\nEnabling this setting doesn't a\ufb00ect previously stored bucket policies, except that public and \ncross-account access within any public bucket policy, including non-public delegation to speci\ufb01c \naccounts, is blocked.\nType: Boolean\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1312Amazon Simple Storage Service API Reference\nQueueCon\ufb01guration\nService: Amazon S3\nSpeci\ufb01es the con\ufb01guration for publishing messages to an Amazon Simple Queue Service (Amazon \nSQS) queue when Amazon S3 detects speci\ufb01ed events.\nContents\nEvents\nA collection of bucket events for which to send noti\ufb01cations\nType: Array of strings\nValid Values: s3:ReducedRedundancyLostObject | s3:ObjectCreated:* | \ns3:ObjectCreated:Put | s3:ObjectCreated:Post | s3:ObjectCreated:Copy \n| s3:ObjectCreated:CompleteMultipartUpload | s3:ObjectRemoved:* | \ns3:ObjectRemoved:Delete | s3:ObjectRemoved:DeleteMarkerCreated | \ns3:ObjectRestore:* | s3:ObjectRestore:Post | s3:ObjectRestore:Completed \n| s3:Replication:* | s3:Replication:OperationFailedReplication | \ns3:Replication:OperationNotTracked | \ns3:Replication:OperationMissedThreshold | \ns3:Replication:OperationReplicatedAfterThreshold | \ns3:ObjectRestore:Delete | s3:LifecycleTransition | \ns3:IntelligentTiering | s3:ObjectAcl:Put | s3:LifecycleExpiration:* | \ns3:LifecycleExpiration:Delete | \ns3:LifecycleExpiration:DeleteMarkerCreated | s3:ObjectTagging:* | \ns3:ObjectTagging:Put | s3:ObjectTagging:Delete\nRequired: Yes\nQueueArn\nThe Amazon Resource Name (ARN) of the Amazon SQS queue to which Amazon S3 publishes a \nmessage when it detects events of the speci\ufb01ed type.\nType: String\nRequired: Yes\nAmazon S3 API Version 2006-03-01 1313Amazon Simple Storage Service API Reference\nFilter\nSpeci\ufb01es object key name \ufb01ltering rules. For information about key name \ufb01ltering, see\nCon\ufb01guring event noti\ufb01cations using object key name \ufb01ltering in the Amazon S3 User Guide .\nType: Noti\ufb01cationCon\ufb01gurationFilter  data type\nRequired: No\nId\nAn optional unique identi\ufb01er for con\ufb01gurations in a noti\ufb01cation con\ufb01guration. If you don't \nprovide one, Amazon S3 will assign an ID.\nType: String\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1314Amazon Simple Storage Service API Reference\nQueueCon\ufb01gurationDeprecated\nService: Amazon S3\nThis data type is deprecated.", "Use QueueCon\ufb01guration  for the same purposes.", "This data type \nspeci\ufb01es the con\ufb01guration for publishing messages to an Amazon Simple Queue Service (Amazon \nSQS) queue when Amazon S3 detects speci\ufb01ed events.\nContents\nEvent\nThis member has been deprecated.\nThe bucket event for which to send noti\ufb01cations.\nType: String\nValid Values: s3:ReducedRedundancyLostObject | s3:ObjectCreated:* | \ns3:ObjectCreated:Put | s3:ObjectCreated:Post | s3:ObjectCreated:Copy \n| s3:ObjectCreated:CompleteMultipartUpload | s3:ObjectRemoved:* | \ns3:ObjectRemoved:Delete | s3:ObjectRemoved:DeleteMarkerCreated | \ns3:ObjectRestore:* | s3:ObjectRestore:Post | s3:ObjectRestore:Completed \n| s3:Replication:* | s3:Replication:OperationFailedReplication | \ns3:Replication:OperationNotTracked | \ns3:Replication:OperationMissedThreshold | \ns3:Replication:OperationReplicatedAfterThreshold | \ns3:ObjectRestore:Delete | s3:LifecycleTransition | \ns3:IntelligentTiering | s3:ObjectAcl:Put | s3:LifecycleExpiration:* | \ns3:LifecycleExpiration:Delete | \ns3:LifecycleExpiration:DeleteMarkerCreated | s3:ObjectTagging:* | \ns3:ObjectTagging:Put | s3:ObjectTagging:Delete\nRequired: No\nEvents\nA collection of bucket events for which to send noti\ufb01cations.\nType: Array of strings\nValid Values: s3:ReducedRedundancyLostObject | s3:ObjectCreated:* | \ns3:ObjectCreated:Put | s3:ObjectCreated:Post | s3:ObjectCreated:Copy \nAmazon S3 API Version 2006-03-01 1315Amazon Simple Storage Service API Reference\n| s3:ObjectCreated:CompleteMultipartUpload | s3:ObjectRemoved:* | \ns3:ObjectRemoved:Delete | s3:ObjectRemoved:DeleteMarkerCreated | \ns3:ObjectRestore:* | s3:ObjectRestore:Post | s3:ObjectRestore:Completed \n| s3:Replication:* | s3:Replication:OperationFailedReplication | \ns3:Replication:OperationNotTracked | \ns3:Replication:OperationMissedThreshold | \ns3:Replication:OperationReplicatedAfterThreshold | \ns3:ObjectRestore:Delete | s3:LifecycleTransition | \ns3:IntelligentTiering | s3:ObjectAcl:Put | s3:LifecycleExpiration:* | \ns3:LifecycleExpiration:Delete | \ns3:LifecycleExpiration:DeleteMarkerCreated | s3:ObjectTagging:* | \ns3:ObjectTagging:Put | s3:ObjectTagging:Delete\nRequired: No\nId\nAn optional unique identi\ufb01er for con\ufb01gurations in a noti\ufb01cation con\ufb01guration. If you don't \nprovide one, Amazon S3 will assign an ID.\nType: String\nRequired: No\nQueue\nThe Amazon Resource Name (ARN) of the Amazon SQS queue to which Amazon S3 publishes a \nmessage when it detects events of the speci\ufb01ed type.\nType: String\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1316Amazon Simple Storage Service API Reference\nAmazon S3 API Version 2006-03-01 1317Amazon Simple Storage Service API Reference\nRecordsEvent\nService: Amazon S3\nThe container for the records event.\nContents\nPayload\nThe byte array of partial, one or more result records. S3 Select doesn't guarantee that a record \nwill be self-contained in one record frame. To ensure continuous streaming of data, S3 Select \nmight split the same record across multiple record frames instead of aggregating the results in \nmemory. Some S3 clients (for example, the AWS SDK for Java) handle this behavior by creating \na ByteStream  out of the response by default.", "Other clients might not handle this behavior \nby default.", "In those cases, you must aggregate the results on the client side and parse the \nresponse.\nType: Base64-encoded binary data object\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1318Amazon Simple Storage Service API Reference\nRedirect\nService: Amazon S3\nSpeci\ufb01es how requests are redirected.", "In the event of an error, you can specify a di\ufb00erent error \ncode to return.\nContents\nHostName\nThe host name to use in the redirect request.\nType: String\nRequired: No\nHttpRedirectCode\nThe HTTP redirect code to use on the response. Not required if one of the siblings is present.\nType: String\nRequired: No\nProtocol\nProtocol to use when redirecting requests.", "The default is the protocol that is used in the original \nrequest.\nType: String\nValid Values: http | https\nRequired: No\nReplaceKeyPre\ufb01xWith\nThe object key pre\ufb01x to use in the redirect request.", "For example, to redirect requests for all \npages with pre\ufb01x docs/ (objects in the docs/  folder) to documents/ , you can set a condition \nblock with KeyPrefixEquals  set to docs/ and in the Redirect set ReplaceKeyPrefixWith\nto /documents .", "Not required if one of the siblings is present.", "Can be present only if\nReplaceKeyWith  is not provided.\nAmazon S3 API Version 2006-03-01 1319Amazon Simple Storage Service API Reference\nImportant\nReplacement must be made for object keys containing special characters (such as \ncarriage returns) when using XML requests.", "For more information, see  XML related \nobject key constraints.\nType: String\nRequired: No\nReplaceKeyWith\nThe speci\ufb01c object key to use in the redirect request.", "For example, redirect request \nto error.html .", "Not required if one of the siblings is present.", "Can be present only if\nReplaceKeyPrefixWith  is not provided.\nImportant\nReplacement must be made for object keys containing special characters (such as \ncarriage returns) when using XML requests.", "For more information, see  XML related \nobject key constraints.\nType: String\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1320Amazon Simple Storage Service API Reference\nRedirectAllRequestsTo\nService: Amazon S3\nSpeci\ufb01es the redirect behavior of all requests to a website endpoint of an Amazon S3 bucket.\nContents\nHostName\nName of the host where requests are redirected.\nType: String\nRequired: Yes\nProtocol\nProtocol to use when redirecting requests. The default is the protocol that is used in the original \nrequest.\nType: String\nValid Values: http | https\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1321Amazon Simple Storage Service API Reference\nReplicaModi\ufb01cations\nService: Amazon S3\nA \ufb01lter that you can specify for selection for modi\ufb01cations on replicas. Amazon S3 doesn't replicate \nreplica modi\ufb01cations by default. In the latest version of replication con\ufb01guration (when Filter  is \nspeci\ufb01ed), you can specify this element and set the status to Enabled to replicate modi\ufb01cations on \nreplicas.\nNote\nIf you don't specify the Filter element, Amazon S3 assumes that the replication \ncon\ufb01guration is the earlier version, V1. In the earlier version, this element is not allowed.\nContents\nStatus\nSpeci\ufb01es whether Amazon S3 replicates modi\ufb01cations on replicas.\nType: String\nValid Values: Enabled | Disabled\nRequired: Yes\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1322Amazon Simple Storage Service API Reference\nReplicationCon\ufb01guration\nService: Amazon S3\nA container for replication rules.", "You can add up to 1,000 rules.", "The maximum size of a replication \ncon\ufb01guration is 2 MB.\nContents\nRole\nThe Amazon Resource Name (ARN) of the AWS Identity and Access Management (IAM) role \nthat Amazon S3 assumes when replicating objects. For more information, see How to Set Up \nReplication in the Amazon S3 User Guide .\nType: String\nRequired: Yes\nRules\nA container for one or more replication rules. A replication con\ufb01guration must have at least one \nrule and can contain a maximum of 1,000 rules.\nType: Array of ReplicationRule data types\nRequired: Yes\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1323Amazon Simple Storage Service API Reference\nReplicationRule\nService: Amazon S3\nSpeci\ufb01es which Amazon S3 objects to replicate and where to store the replicas.\nContents\nDestination\nA container for information about the replication destination and its con\ufb01gurations including \nenabling the S3 Replication Time Control (S3 RTC).\nType: Destination  data type\nRequired: Yes\nStatus\nSpeci\ufb01es whether the rule is enabled.\nType: String\nValid Values: Enabled | Disabled\nRequired: Yes\nDeleteMarkerReplication\nSpeci\ufb01es whether Amazon S3 replicates delete markers.", "If you specify a Filter in your \nreplication con\ufb01guration, you must also include a DeleteMarkerReplication  element.", "If \nyour Filter  includes a Tag element, the DeleteMarkerReplication  Status  must be set to \nDisabled, because Amazon S3 does not support replicating delete markers for tag-based rules. \nFor an example con\ufb01guration, see Basic Rule Con\ufb01guration .\nFor more information about delete marker replication, see Basic Rule Con\ufb01guration .\nNote\nIf you are using an earlier version of the replication con\ufb01guration, Amazon S3 \nhandles replication of delete markers di\ufb00erently. For more information, see Backward \nCompatibility.\nAmazon S3 API Version 2006-03-01 1324Amazon Simple Storage Service API Reference\nType: DeleteMarkerReplication data type\nRequired: No\nExistingObjectReplication\nOptional con\ufb01guration to replicate existing source bucket objects.\nNote\nThis parameter is no longer supported. To replicate existing objects, see Replicating \nexisting objects with S3 Batch Replication in the Amazon S3 User Guide .\nType: ExistingObjectReplication data type\nRequired: No\nFilter\nA \ufb01lter that identi\ufb01es the subset of objects to which the replication rule applies.", "A Filter  must \nspecify exactly one Prefix , Tag, or an And child element.\nType: ReplicationRuleFilter data type\nRequired: No\nID\nA unique identi\ufb01er for the rule.", "The maximum value is 255 characters.\nType: String\nRequired: No\nPre\ufb01x\nThis member has been deprecated.\nAn object key name pre\ufb01x that identi\ufb01es the object or objects to which the rule applies. The \nmaximum pre\ufb01x length is 1,024 characters.", "To include all objects in a bucket, specify an empty \nstring.\nAmazon S3 API Version 2006-03-01 1325Amazon Simple Storage Service API Reference\nImportant\nReplacement must be made for object keys containing special characters (such as \ncarriage returns) when using XML requests.", "For more information, see  XML related \nobject key constraints.\nType: String\nRequired: No\nPriority\nThe priority indicates which rule has precedence whenever two or more replication rules \ncon\ufb02ict.", "Amazon S3 will attempt to replicate objects according to all replication rules.", "However, \nif there are two or more rules with the same destination bucket, then objects will be replicated \naccording to the rule with the highest priority.", "The higher the number, the higher the priority.\nFor more information, see Replication in the Amazon S3 User Guide .\nType: Integer\nRequired: No\nSourceSelectionCriteria\nA container that describes additional \ufb01lters for identifying the source objects that you want \nto replicate.", "You can choose to enable or disable the replication of these objects.", "Currently, \nAmazon S3 supports only the \ufb01lter that you can specify for objects created with server-side \nencryption using a customer managed key stored in AWS Key Management Service (SSE-KMS).\nType: SourceSelectionCriteria data type\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\nAmazon S3 API Version 2006-03-01 1326Amazon Simple Storage Service API Reference\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1327Amazon Simple Storage Service API Reference\nReplicationRuleAndOperator\nService: Amazon S3\nA container for specifying rule \ufb01lters.", "The \ufb01lters determine the subset of objects to which the rule \napplies.", "This element is required only if you specify more than one \ufb01lter.\nFor example:\n\u2022If you specify both a Prefix  and a Tag \ufb01lter, wrap these \ufb01lters in an And tag.\n\u2022If you specify a \ufb01lter based on multiple tags, wrap the Tag elements in an And tag.\nContents\nPre\ufb01x\nAn object key name pre\ufb01x that identi\ufb01es the subset of objects to which the rule applies.\nType: String\nRequired: No\nTags\nAn array of tags containing key and value pairs.\nType: Array of Tag data types\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1328Amazon Simple Storage Service API Reference\nReplicationRuleFilter\nService: Amazon S3\nA \ufb01lter that identi\ufb01es the subset of objects to which the replication rule applies. A Filter  must \nspecify exactly one Prefix , Tag, or an And child element.\nContents\nAnd\nA container for specifying rule \ufb01lters. The \ufb01lters determine the subset of objects to which the \nrule applies. This element is required only if you specify more than one \ufb01lter. For example:\n\u2022If you specify both a Prefix  and a Tag \ufb01lter, wrap these \ufb01lters in an And tag.\n\u2022If you specify a \ufb01lter based on multiple tags, wrap the Tag elements in an And tag.\nType: ReplicationRuleAndOperator data type\nRequired: No\nPre\ufb01x\nAn object key name pre\ufb01x that identi\ufb01es the subset of objects to which the rule applies.\nImportant\nReplacement must be made for object keys containing special characters (such as \ncarriage returns) when using XML requests.", "For more information, see  XML related \nobject key constraints.\nType: String\nRequired: No\nTag\nA container for specifying a tag key and value.\nThe rule applies only to objects that have the tag in their tag set.\nType: Tag data type\nRequired: No\nAmazon S3 API Version 2006-03-01 1329Amazon Simple Storage Service API Reference\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1330Amazon Simple Storage Service API Reference\nReplicationTime\nService: Amazon S3\nA container specifying S3 Replication Time Control (S3 RTC) related information, including whether \nS3 RTC is enabled and the time when all objects and operations on objects must be replicated. \nMust be speci\ufb01ed together with a Metrics  block.\nContents\nStatus\nSpeci\ufb01es whether the replication time is enabled.\nType: String\nValid Values: Enabled | Disabled\nRequired: Yes\nTime\nA container specifying the time by which replication should be complete for all objects and \noperations on objects.\nType: ReplicationTimeValue data type\nRequired: Yes\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1331Amazon Simple Storage Service API Reference\nReplicationTimeValue\nService: Amazon S3\nA container specifying the time value for S3 Replication Time Control (S3 RTC) and replication \nmetrics EventThreshold .\nContents\nMinutes\nContains an integer specifying time in minutes.\nValid value: 15\nType: Integer\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1332Amazon Simple Storage Service API Reference\nRequestPaymentCon\ufb01guration\nService: Amazon S3\nContainer for Payer.\nContents\nPayer\nSpeci\ufb01es who pays for the download and request fees.\nType: String\nValid Values: Requester | BucketOwner\nRequired: Yes\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1333Amazon Simple Storage Service API Reference\nRequestProgress\nService: Amazon S3\nContainer for specifying if periodic QueryProgress  messages should be sent.\nContents\nEnabled\nSpeci\ufb01es whether periodic QueryProgress frames should be sent.", "Valid values: TRUE, FALSE.", "\nDefault value: FALSE.\nType: Boolean\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1334Amazon Simple Storage Service API Reference\nRestoreRequest\nService: Amazon S3\nContainer for restore job parameters.\nContents\nDays\nLifetime of the active copy in days.", "Do not use with restores that specify OutputLocation .\nThe Days element is required for regular restores, and must not be provided for select requests.\nType: Integer\nRequired: No\nDescription\nThe optional description for the job.\nType: String\nRequired: No\nGlacierJobParameters\nS3 Glacier related parameters pertaining to this job. Do not use with restores that specify\nOutputLocation .\nType: GlacierJobParameters data type\nRequired: No\nOutputLocation\nDescribes the location where the restore job's output is stored.\nType: OutputLocation  data type\nRequired: No\nSelectParameters\nDescribes the parameters for Select job types.\nAmazon S3 API Version 2006-03-01 1335Amazon Simple Storage Service API Reference\nType: SelectParameters data type\nRequired: No\nTier\nRetrieval tier at which the restore will be processed.\nType: String\nValid Values: Standard | Bulk | Expedited\nRequired: No\nType\nType of restore request.\nType: String\nValid Values: SELECT\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1336Amazon Simple Storage Service API Reference\nRestoreStatus\nService: Amazon S3\nSpeci\ufb01es the restoration status of an object.", "Objects in certain storage classes must be restored \nbefore they can be retrieved.", "For more information about these storage classes and how to work \nwith archived objects, see  Working with archived objects in the Amazon S3 User Guide .\nNote\nThis functionality is not supported for directory buckets. Only the S3 Express One Zone \nstorage class is supported by directory buckets to store objects.\nContents\nIsRestoreInProgress\nSpeci\ufb01es whether the object is currently being restored.", "If the object restoration is in progress, \nthe header returns the value TRUE. For example:\nx-amz-optional-object-attributes: IsRestoreInProgress=\"true\"\nIf the object restoration has completed, the header returns the value FALSE. For example:\nx-amz-optional-object-attributes: IsRestoreInProgress=\"false\", \nRestoreExpiryDate=\"2012-12-21T00:00:00.000Z\"\nIf the object hasn't been restored, there is no header response.\nType: Boolean\nRequired: No\nRestoreExpiryDate\nIndicates when the restored copy will expire. This value is populated only if the object has \nalready been restored.", "For example:\nx-amz-optional-object-attributes: IsRestoreInProgress=\"false\", \nRestoreExpiryDate=\"2012-12-21T00:00:00.000Z\"\nType: Timestamp\nAmazon S3 API Version 2006-03-01 1337Amazon Simple Storage Service API Reference\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1338Amazon Simple Storage Service API Reference\nRoutingRule\nService: Amazon S3\nSpeci\ufb01es the redirect behavior and when a redirect is applied.", "For more information about routing \nrules, see Con\ufb01guring advanced conditional redirects in the Amazon S3 User Guide .\nContents\nRedirect\nContainer for redirect information.", "You can redirect requests to another host, to another page, \nor with another protocol. In the event of an error, you can specify a di\ufb00erent error code to \nreturn.\nType: Redirect data type\nRequired: Yes\nCondition\nA container for describing a condition that must be met for the speci\ufb01ed redirect to apply. For \nexample, 1.", "If request is for pages in the /docs folder, redirect to the /documents  folder.", "2.", "If \nrequest results in HTTP error 4xx, redirect request to another host where you might process the \nerror.\nType: Condition  data type\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1339Amazon Simple Storage Service API Reference\nRule\nService: Amazon S3\nSpeci\ufb01es lifecycle rules for an Amazon S3 bucket. For more information, see Put Bucket \nLifecycle Con\ufb01guration in the Amazon S3 API Reference.", "For examples, see Put Bucket Lifecycle \nCon\ufb01guration Examples .\nContents\nPre\ufb01x\nObject key pre\ufb01x that identi\ufb01es one or more objects to which this rule applies.\nImportant\nReplacement must be made for object keys containing special characters (such as \ncarriage returns) when using XML requests.", "For more information, see  XML related \nobject key constraints.\nType: String\nRequired: Yes\nStatus\nIf Enabled, the rule is currently being applied.", "If Disabled , the rule is not currently being \napplied.\nType: String\nValid Values: Enabled | Disabled\nRequired: Yes\nAbortIncompleteMultipartUpload\nSpeci\ufb01es the days since the initiation of an incomplete multipart upload that Amazon S3 will \nwait before permanently removing all parts of the upload. For more information, see  Aborting \nIncomplete Multipart Uploads Using a Bucket Lifecycle Con\ufb01guration in the Amazon S3 User \nGuide .\nAmazon S3 API Version 2006-03-01 1340Amazon Simple Storage Service API Reference\nType: AbortIncompleteMultipartUpload data type\nRequired: No\nExpiration\nSpeci\ufb01es the expiration for the lifecycle of the object.\nType: LifecycleExpiration data type\nRequired: No\nID\nUnique identi\ufb01er for the rule.", "The value can't be longer than 255 characters.\nType: String\nRequired: No\nNoncurrentVersionExpiration\nSpeci\ufb01es when noncurrent object versions expire.", "Upon expiration, Amazon S3 permanently \ndeletes the noncurrent object versions. You set this lifecycle con\ufb01guration action on a bucket \nthat has versioning enabled (or suspended) to request that Amazon S3 delete noncurrent object \nversions at a speci\ufb01c period in the object's lifetime.\nType: NoncurrentVersionExpiration data type\nRequired: No\nNoncurrentVersionTransition\nContainer for the transition rule that describes when noncurrent objects transition to \nthe STANDARD_IA , ONEZONE_IA , INTELLIGENT_TIERING , GLACIER_IR , GLACIER , or\nDEEP_ARCHIVE  storage class. If your bucket is versioning-enabled (or versioning is suspended), \nyou can set this action to request that Amazon S3 transition noncurrent object versions to \nthe STANDARD_IA , ONEZONE_IA , INTELLIGENT_TIERING , GLACIER_IR , GLACIER , or\nDEEP_ARCHIVE  storage class at a speci\ufb01c period in the object's lifetime.\nType: NoncurrentVersionTransition data type\nRequired: No\nAmazon S3 API Version 2006-03-01 1341Amazon Simple Storage Service API Reference\nTransition\nSpeci\ufb01es when an object transitions to a speci\ufb01ed storage class. For more information about \nAmazon S3 lifecycle con\ufb01guration rules, see Transitioning Objects Using Amazon S3 Lifecycle in \nthe Amazon S3 User Guide .\nType: Transition data type\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1342Amazon Simple Storage Service API Reference\nS3KeyFilter\nService: Amazon S3\nA container for object key name pre\ufb01x and su\ufb03x \ufb01ltering rules.\nContents\nFilterRules\nA list of containers for the key-value pair that de\ufb01nes the criteria for the \ufb01lter rule.\nType: Array of FilterRule  data types\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1343Amazon Simple Storage Service API Reference\nS3Location\nService: Amazon S3\nDescribes an Amazon S3 location that will receive the results of the restore request.\nContents\nBucketName\nThe name of the bucket where the restore results will be placed.\nType: String\nRequired: Yes\nPre\ufb01x\nThe pre\ufb01x that is prepended to the restore results for this request.\nType: String\nRequired: Yes\nAccessControlList\nA list of grants that control access to the staged results.\nType: Array of Grant  data types\nRequired: No\nCannedACL\nThe canned ACL to apply to the restore results.\nType: String\nValid Values: private | public-read | public-read-write | authenticated-read \n| aws-exec-read | bucket-owner-read | bucket-owner-full-control\nRequired: No\nEncryption\nContains the type of server-side encryption used.\nAmazon S3 API Version 2006-03-01 1344Amazon Simple Storage Service API Reference\nType: Encryption data type\nRequired: No\nStorageClass\nThe class of storage used to store the restore results.\nType: String\nValid Values: STANDARD | REDUCED_REDUNDANCY | STANDARD_IA | ONEZONE_IA | \nINTELLIGENT_TIERING | GLACIER | DEEP_ARCHIVE | OUTPOSTS | GLACIER_IR | \nSNOW | EXPRESS_ONEZONE\nRequired: No\nTagging\nThe tag-set that is applied to the restore results.\nType: Tagging data type\nRequired: No\nUserMetadata\nA list of metadata to store with the restore results in S3.\nType: Array of MetadataEntry data types\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1345Amazon Simple Storage Service API Reference\nScanRange\nService: Amazon S3\nSpeci\ufb01es the byte range of the object to get the records from.", "A record is processed when its \ufb01rst \nbyte is contained by the range.", "This parameter is optional, but when speci\ufb01ed, it must not be \nempty. See RFC 2616, Section 14.35.1 about how to specify the start and end of the range.\nContents\nEnd\nSpeci\ufb01es the end of the byte range. This parameter is optional. Valid values: non-negative \nintegers.", "The default value is one less than the size of the object being queried.", "If only the End \nparameter is supplied, it is interpreted to mean scan the last N bytes of the \ufb01le. For example,\n<scanrange><end>50</end></scanrange>  means scan the last 50 bytes.\nType: Long\nRequired: No\nStart\nSpeci\ufb01es the start of the byte range.", "This parameter is optional. Valid values: non-negative \nintegers. The default value is 0.", "If only start is supplied, it means scan from that point to the \nend of the \ufb01le.", "For example, <scanrange><start>50</start></scanrange>  means scan \nfrom byte 50 until the end of the \ufb01le.\nType: Long\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1346Amazon Simple Storage Service API Reference\nSelectObjectContentEventStream\nService: Amazon S3\nThe container for selecting objects from a content event stream.\nContents\nCont\nThe Continuation Event.\nType: ContinuationEvent data type\nRequired: No\nEnd\nThe End Event.\nType: EndEvent data type\nRequired: No\nProgress\nThe Progress Event.\nType: ProgressEvent data type\nRequired: No\nRecords\nThe Records Event.\nType: RecordsEvent data type\nRequired: No\nStats\nThe Stats Event.\nType: StatsEvent data type\nRequired: No\nAmazon S3 API Version 2006-03-01 1347Amazon Simple Storage Service API Reference\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1348Amazon Simple Storage Service API Reference\nSelectParameters\nService: Amazon S3\nDescribes the parameters for Select job types.\nContents\nExpression\nThe expression that is used to query the object.\nType: String\nRequired: Yes\nExpressionType\nThe type of the provided expression (for example, SQL).\nType: String\nValid Values: SQL\nRequired: Yes\nInputSerialization\nDescribes the serialization format of the object.\nType: InputSerialization  data type\nRequired: Yes\nOutputSerialization\nDescribes how the results of the Select job are serialized.\nType: OutputSerialization  data type\nRequired: Yes\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\nAmazon S3 API Version 2006-03-01 1349Amazon Simple Storage Service API Reference\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1350Amazon Simple Storage Service API Reference\nServerSideEncryptionByDefault\nService: Amazon S3\nDescribes the default server-side encryption to apply to new objects in the bucket.", "If a PUT Object \nrequest doesn't specify any server-side encryption, this default encryption will be applied.", "For more \ninformation, see PutBucketEncryption.\nNote\n\u2022General purpose buckets - If you don't specify a customer managed key at \ncon\ufb01guration, Amazon S3 automatically creates an AWS KMS key (aws/s3) in your AWS \naccount the \ufb01rst time that you add an object encrypted with SSE-KMS to a bucket. By \ndefault, Amazon S3 uses this KMS key for SSE-KMS.\n\u2022Directory buckets - Your SSE-KMS con\ufb01guration can only support 1 customer managed \nkey per directory bucket for the lifetime of the bucket. The AWS managed key (aws/s3 ) \nisn't supported.\n\u2022Directory buckets - For directory buckets, there are only two supported options for \nserver-side encryption: SSE-S3 and SSE-KMS.\nContents\nSSEAlgorithm\nServer-side encryption algorithm to use for the default encryption.\nNote\nFor directory buckets, there are only two supported values for server-side encryption:\nAES256  and aws:kms .\nType: String\nValid Values: AES256 | aws:kms | aws:kms:dsse\nRequired: Yes\nAmazon S3 API Version 2006-03-01 1351Amazon Simple Storage Service API Reference\nKMSMasterKeyID\nAWS Key Management Service (KMS) customer managed key ID to use for the default \nencryption.\nNote\n\u2022General purpose buckets - This parameter is allowed if and only if SSEAlgorithm  is \nset to aws:kms  or aws:kms:dsse .\n\u2022Directory buckets - This parameter is allowed if and only if SSEAlgorithm  is set to\naws:kms .\nYou can specify the key ID, key alias, or the Amazon Resource Name (ARN) of the KMS key.\n\u2022Key ID: 1234abcd-12ab-34cd-56ef-1234567890ab\n\u2022Key ARN: arn:aws:kms:us-\neast-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab\n\u2022Key Alias: alias/alias-name\nIf you are using encryption with cross-account or AWS service operations, you must use a \nfully quali\ufb01ed KMS key ARN. For more information, see Using encryption for cross-account \noperations .\nNote\n\u2022General purpose buckets - If you're specifying a customer managed KMS key, we \nrecommend using a fully quali\ufb01ed KMS key ARN. If you use a KMS key alias instead, \nthen AWS KMS resolves the key within the requester\u2019s account. This behavior can \nresult in data that's encrypted with a KMS key that belongs to the requester, and \nnot the bucket owner. Also, if you use a key ID, you can run into a LogDestination \nundeliverable error when creating a VPC \ufb02ow log.\n\u2022Directory buckets - When you specify an AWS KMS customer managed key for \nencryption in your directory bucket, only use the key ID or key ARN. The key alias \nformat of the KMS key isn't supported.\nAmazon S3 API Version 2006-03-01 1352Amazon Simple Storage Service API Reference\nImportant\nAmazon S3 only supports symmetric encryption KMS keys. For more information, see\nAsymmetric keys in AWS KMS in the  AWS Key Management Service Developer Guide.\nType: String\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1353Amazon Simple Storage Service API Reference\nServerSideEncryptionCon\ufb01guration\nService: Amazon S3\nSpeci\ufb01es the default server-side-encryption con\ufb01guration.\nContents\nRules\nContainer for information about a particular server-side encryption con\ufb01guration rule.\nType: Array of ServerSideEncryptionRule data types\nRequired: Yes\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1354Amazon Simple Storage Service API Reference\nServerSideEncryptionRule\nService: Amazon S3\nSpeci\ufb01es the default server-side encryption con\ufb01guration.\nNote\n\u2022General purpose buckets - If you're specifying a customer managed KMS key, we \nrecommend using a fully quali\ufb01ed KMS key ARN. If you use a KMS key alias instead, then \nAWS KMS resolves the key within the requester\u2019s account. This behavior can result in data \nthat's encrypted with a KMS key that belongs to the requester, and not the bucket owner.\n\u2022Directory buckets - When you specify an AWS KMS customer managed key for \nencryption in your directory bucket, only use the key ID or key ARN. The key alias format \nof the KMS key isn't supported.\nContents\nApplyServerSideEncryptionByDefault\nSpeci\ufb01es the default server-side encryption to apply to new objects in the bucket.", "If a PUT \nObject request doesn't specify any server-side encryption, this default encryption will be \napplied.\nType: ServerSideEncryptionByDefault data type\nRequired: No\nBucketKeyEnabled\nSpeci\ufb01es whether Amazon S3 should use an S3 Bucket Key with server-side encryption using \nKMS (SSE-KMS) for new objects in the bucket.", "Existing objects are not a\ufb00ected.", "Setting the\nBucketKeyEnabled  element to true causes Amazon S3 to use an S3 Bucket Key.\nNote\n\u2022General purpose buckets - By default, S3 Bucket Key is not enabled. For more \ninformation, see Amazon S3 Bucket Keys in the Amazon S3 User Guide .\n\u2022Directory buckets - S3 Bucket Keys are always enabled for GET and PUT operations in \na directory bucket and can\u2019t be disabled. S3 Bucket Keys aren't supported, when you \nAmazon S3 API Version 2006-03-01 1355Amazon Simple Storage Service API Reference\ncopy SSE-KMS encrypted objects from general purpose buckets to directory buckets, \nfrom directory buckets to general purpose buckets, or between directory buckets, \nthrough CopyObject, UploadPartCopy, the Copy operation in Batch Operations, or\nthe import jobs. In this case, Amazon S3 makes a call to AWS KMS every time a copy \nrequest is made for a KMS-encrypted object.\nType: Boolean\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1356Amazon Simple Storage Service API Reference\nSessionCredentials\nService: Amazon S3\nThe established temporary security credentials of the session.\nNote\nDirectory buckets - These session credentials are only supported for the authentication \nand authorization of Zonal endpoint API operations on directory buckets.\nContents\nAccessKeyId\nA unique identi\ufb01er that's associated with a secret access key.", "The access key ID and the secret \naccess key are used together to sign programmatic AWS requests cryptographically.\nType: String\nRequired: Yes\nExpiration\nTemporary security credentials expire after a speci\ufb01ed interval.", "After temporary credentials \nexpire, any calls that you make with those credentials will fail. So you must generate a new set \nof temporary credentials. Temporary credentials cannot be extended or refreshed beyond the \noriginal speci\ufb01ed interval.\nType: Timestamp\nRequired: Yes\nSecretAccessKey\nA key that's used with the access key ID to cryptographically sign programmatic AWS requests.", "\nSigning a request identi\ufb01es the sender and prevents the request from being altered.\nType: String\nRequired: Yes\nAmazon S3 API Version 2006-03-01 1357Amazon Simple Storage Service API Reference\nSessionToken\nA part of the temporary security credentials. The session token is used to validate the \ntemporary security credentials.\nType: String\nRequired: Yes\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1358Amazon Simple Storage Service API Reference\nSimplePre\ufb01x\nService: Amazon S3\nTo use simple format for S3 keys for log objects, set SimplePre\ufb01x to an empty object.\n[DestinationPrefix][YYYY]-[MM]-[DD]-[hh]-[mm]-[ss]-[UniqueString]\nContents\nThe members of this exception structure are context-dependent.\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1359Amazon Simple Storage Service API Reference\nSourceSelectionCriteria\nService: Amazon S3\nA container that describes additional \ufb01lters for identifying the source objects that you want to \nreplicate.", "You can choose to enable or disable the replication of these objects.", "Currently, Amazon \nS3 supports only the \ufb01lter that you can specify for objects created with server-side encryption \nusing a customer managed key stored in AWS Key Management Service (SSE-KMS).\nContents\nReplicaModi\ufb01cations\nA \ufb01lter that you can specify for selections for modi\ufb01cations on replicas. Amazon S3 doesn't \nreplicate replica modi\ufb01cations by default. In the latest version of replication con\ufb01guration \n(when Filter is speci\ufb01ed), you can specify this element and set the status to Enabled  to \nreplicate modi\ufb01cations on replicas.\nNote\nIf you don't specify the Filter element, Amazon S3 assumes that the replication \ncon\ufb01guration is the earlier version, V1. In the earlier version, this element is not allowed\nType: ReplicaModi\ufb01cations data type\nRequired: No\nSseKmsEncryptedObjects\nA container for \ufb01lter information for the selection of Amazon S3 objects encrypted with AWS \nKMS.", "If you include SourceSelectionCriteria  in the replication con\ufb01guration, this element \nis required.\nType: SseKmsEncryptedObjects data type\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\nAmazon S3 API Version 2006-03-01 1360Amazon Simple Storage Service API Reference\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1361Amazon Simple Storage Service API Reference\nSSEKMS\nService: Amazon S3\nSpeci\ufb01es the use of SSE-KMS to encrypt delivered inventory reports.\nContents\nKeyId\nSpeci\ufb01es the ID of the AWS Key Management Service (AWS KMS) symmetric encryption \ncustomer managed key to use for encrypting inventory reports.\nType: String\nRequired: Yes\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1362Amazon Simple Storage Service API Reference\nSseKmsEncryptedObjects\nService: Amazon S3\nA container for \ufb01lter information for the selection of S3 objects encrypted with AWS KMS.\nContents\nStatus\nSpeci\ufb01es whether Amazon S3 replicates objects created with server-side encryption using an \nAWS KMS key stored in AWS Key Management Service.\nType: String\nValid Values: Enabled | Disabled\nRequired: Yes\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1363Amazon Simple Storage Service API Reference\nSSES3\nService: Amazon S3\nSpeci\ufb01es the use of SSE-S3 to encrypt delivered inventory reports.\nContents\nThe members of this exception structure are context-dependent.\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1364Amazon Simple Storage Service API Reference\nStats\nService: Amazon S3\nContainer for the stats details.\nContents\nBytesProcessed\nThe total number of uncompressed object bytes processed.\nType: Long\nRequired: No\nBytesReturned\nThe total number of bytes of records payload data returned.\nType: Long\nRequired: No\nBytesScanned\nThe total number of object bytes scanned.\nType: Long\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1365Amazon Simple Storage Service API Reference\nStatsEvent\nService: Amazon S3\nContainer for the Stats Event.\nContents\nDetails\nThe Stats event details.\nType: Stats  data type\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1366Amazon Simple Storage Service API Reference\nStorageClassAnalysis\nService: Amazon S3\nSpeci\ufb01es data related to access patterns to be collected and made available to analyze the \ntradeo\ufb00s between di\ufb00erent storage classes for an Amazon S3 bucket.\nContents\nDataExport\nSpeci\ufb01es how data related to the storage class analysis for an Amazon S3 bucket should be \nexported.\nType: StorageClassAnalysisDataExport data type\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1367Amazon Simple Storage Service API Reference\nStorageClassAnalysisDataExport\nService: Amazon S3\nContainer for data related to the storage class analysis for an Amazon S3 bucket for export.\nContents\nDestination\nThe place to store the data for an analysis.\nType: AnalyticsExportDestination data type\nRequired: Yes\nOutputSchemaVersion\nThe version of the output schema to use when exporting data. Must be V_1.\nType: String\nValid Values: V_1\nRequired: Yes\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1368Amazon Simple Storage Service API Reference\nTag\nService: Amazon S3\nA container of a key value name pair.\nContents\nKey\nName of the object key.\nType: String\nLength Constraints: Minimum length of 1.\nRequired: Yes\nValue\nValue of the tag.\nType: String\nRequired: Yes\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1369Amazon Simple Storage Service API Reference\nTagging\nService: Amazon S3\nContainer for TagSet  elements.\nContents\nTagSet\nA collection for a set of tags\nType: Array of Tag data types\nRequired: Yes\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1370Amazon Simple Storage Service API Reference\nTargetGrant\nService: Amazon S3\nContainer for granting information.\nBuckets that use the bucket owner enforced setting for Object Ownership don't support target \ngrants. For more information, see Permissions server access log delivery in the Amazon S3 User \nGuide .\nContents\nGrantee\nContainer for the person being granted permissions.\nType: Grantee  data type\nRequired: No\nPermission\nLogging permissions assigned to the grantee for the bucket.\nType: String\nValid Values: FULL_CONTROL | READ | WRITE\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1371Amazon Simple Storage Service API Reference\nTargetObjectKeyFormat\nService: Amazon S3\nAmazon S3 key format for log objects. Only one format, PartitionedPre\ufb01x or SimplePre\ufb01x, is \nallowed.\nContents\nPartitionedPre\ufb01x\nPartitioned S3 key for log objects.\nType: PartitionedPre\ufb01x data type\nRequired: No\nSimplePre\ufb01x\nTo use the simple format for S3 keys for log objects. To specify SimplePre\ufb01x format, set \nSimplePre\ufb01x to {}.\nType: SimplePre\ufb01x data type\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1372Amazon Simple Storage Service API Reference\nTiering\nService: Amazon S3\nThe S3 Intelligent-Tiering storage class is designed to optimize storage costs by automatically \nmoving data to the most cost-e\ufb00ective storage access tier, without additional operational \noverhead.\nContents\nAccessTier\nS3 Intelligent-Tiering access tier. See Storage class for automatically optimizing frequently and \ninfrequently accessed objects for a list of access tiers in the S3 Intelligent-Tiering storage class.\nType: String\nValid Values: ARCHIVE_ACCESS | DEEP_ARCHIVE_ACCESS\nRequired: Yes\nDays\nThe number of consecutive days of no access after which an object will be eligible to be \ntransitioned to the corresponding tier.", "The minimum number of days speci\ufb01ed for Archive \nAccess tier must be at least 90 days and Deep Archive Access tier must be at least 180 days.", "The \nmaximum can be up to 2 years (730 days).\nType: Integer\nRequired: Yes\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1373Amazon Simple Storage Service API Reference\nTopicCon\ufb01guration\nService: Amazon S3\nA container for specifying the con\ufb01guration for publication of messages to an Amazon Simple \nNoti\ufb01cation Service (Amazon SNS) topic when Amazon S3 detects speci\ufb01ed events.\nContents\nEvents\nThe Amazon S3 bucket event about which to send noti\ufb01cations. For more information, see\nSupported Event Types in the Amazon S3 User Guide .\nType: Array of strings\nValid Values: s3:ReducedRedundancyLostObject | s3:ObjectCreated:* | \ns3:ObjectCreated:Put | s3:ObjectCreated:Post | s3:ObjectCreated:Copy \n| s3:ObjectCreated:CompleteMultipartUpload | s3:ObjectRemoved:* | \ns3:ObjectRemoved:Delete | s3:ObjectRemoved:DeleteMarkerCreated | \ns3:ObjectRestore:* | s3:ObjectRestore:Post | s3:ObjectRestore:Completed \n| s3:Replication:* | s3:Replication:OperationFailedReplication | \ns3:Replication:OperationNotTracked | \ns3:Replication:OperationMissedThreshold | \ns3:Replication:OperationReplicatedAfterThreshold | \ns3:ObjectRestore:Delete | s3:LifecycleTransition | \ns3:IntelligentTiering | s3:ObjectAcl:Put | s3:LifecycleExpiration:* | \ns3:LifecycleExpiration:Delete | \ns3:LifecycleExpiration:DeleteMarkerCreated | s3:ObjectTagging:* | \ns3:ObjectTagging:Put | s3:ObjectTagging:Delete\nRequired: Yes\nTopicArn\nThe Amazon Resource Name (ARN) of the Amazon SNS topic to which Amazon S3 publishes a \nmessage when it detects events of the speci\ufb01ed type.\nType: String\nRequired: Yes\nAmazon S3 API Version 2006-03-01 1374Amazon Simple Storage Service API Reference\nFilter\nSpeci\ufb01es object key name \ufb01ltering rules. For information about key name \ufb01ltering, see\nCon\ufb01guring event noti\ufb01cations using object key name \ufb01ltering in the Amazon S3 User Guide .\nType: Noti\ufb01cationCon\ufb01gurationFilter  data type\nRequired: No\nId\nAn optional unique identi\ufb01er for con\ufb01gurations in a noti\ufb01cation con\ufb01guration. If you don't \nprovide one, Amazon S3 will assign an ID.\nType: String\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1375Amazon Simple Storage Service API Reference\nTopicCon\ufb01gurationDeprecated\nService: Amazon S3\nA container for specifying the con\ufb01guration for publication of messages to an Amazon Simple \nNoti\ufb01cation Service (Amazon SNS) topic when Amazon S3 detects speci\ufb01ed events.", "This data type \nis deprecated.", "Use TopicCon\ufb01guration instead.\nContents\nEvent\nThis member has been deprecated.\nBucket event for which to send noti\ufb01cations.\nType: String\nValid Values: s3:ReducedRedundancyLostObject | s3:ObjectCreated:* | \ns3:ObjectCreated:Put | s3:ObjectCreated:Post | s3:ObjectCreated:Copy \n| s3:ObjectCreated:CompleteMultipartUpload | s3:ObjectRemoved:* | \ns3:ObjectRemoved:Delete | s3:ObjectRemoved:DeleteMarkerCreated | \ns3:ObjectRestore:* | s3:ObjectRestore:Post | s3:ObjectRestore:Completed \n| s3:Replication:* | s3:Replication:OperationFailedReplication | \ns3:Replication:OperationNotTracked | \ns3:Replication:OperationMissedThreshold | \ns3:Replication:OperationReplicatedAfterThreshold | \ns3:ObjectRestore:Delete | s3:LifecycleTransition | \ns3:IntelligentTiering | s3:ObjectAcl:Put | s3:LifecycleExpiration:* | \ns3:LifecycleExpiration:Delete | \ns3:LifecycleExpiration:DeleteMarkerCreated | s3:ObjectTagging:* | \ns3:ObjectTagging:Put | s3:ObjectTagging:Delete\nRequired: No\nEvents\nA collection of events related to objects\nType: Array of strings\nValid Values: s3:ReducedRedundancyLostObject | s3:ObjectCreated:* | \ns3:ObjectCreated:Put | s3:ObjectCreated:Post | s3:ObjectCreated:Copy \nAmazon S3 API Version 2006-03-01 1376Amazon Simple Storage Service API Reference\n| s3:ObjectCreated:CompleteMultipartUpload | s3:ObjectRemoved:* | \ns3:ObjectRemoved:Delete | s3:ObjectRemoved:DeleteMarkerCreated | \ns3:ObjectRestore:* | s3:ObjectRestore:Post | s3:ObjectRestore:Completed \n| s3:Replication:* | s3:Replication:OperationFailedReplication | \ns3:Replication:OperationNotTracked | \ns3:Replication:OperationMissedThreshold | \ns3:Replication:OperationReplicatedAfterThreshold | \ns3:ObjectRestore:Delete | s3:LifecycleTransition | \ns3:IntelligentTiering | s3:ObjectAcl:Put | s3:LifecycleExpiration:* | \ns3:LifecycleExpiration:Delete | \ns3:LifecycleExpiration:DeleteMarkerCreated | s3:ObjectTagging:* | \ns3:ObjectTagging:Put | s3:ObjectTagging:Delete\nRequired: No\nId\nAn optional unique identi\ufb01er for con\ufb01gurations in a noti\ufb01cation con\ufb01guration. If you don't \nprovide one, Amazon S3 will assign an ID.\nType: String\nRequired: No\nTopic\nAmazon SNS topic to which Amazon S3 will publish a message to report the speci\ufb01ed events for \nthe bucket.\nType: String\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1377Amazon Simple Storage Service API Reference\nAmazon S3 API Version 2006-03-01 1378Amazon Simple Storage Service API Reference\nTransition\nService: Amazon S3\nSpeci\ufb01es when an object transitions to a speci\ufb01ed storage class. For more information about \nAmazon S3 lifecycle con\ufb01guration rules, see Transitioning Objects Using Amazon S3 Lifecycle in \nthe Amazon S3 User Guide .\nContents\nDate\nIndicates when objects are transitioned to the speci\ufb01ed storage class.", "The date value must be in \nISO 8601 format.", "The time is always midnight UTC.\nType: Timestamp\nRequired: No\nDays\nIndicates the number of days after creation when objects are transitioned to the speci\ufb01ed \nstorage class.", "The value must be a positive integer.\nType: Integer\nRequired: No\nStorageClass\nThe storage class to which you want the object to transition.\nType: String\nValid Values: GLACIER | STANDARD_IA | ONEZONE_IA | INTELLIGENT_TIERING | \nDEEP_ARCHIVE | GLACIER_IR\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\nAmazon S3 API Version 2006-03-01 1379Amazon Simple Storage Service API Reference\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1380Amazon Simple Storage Service API Reference\nVersioningCon\ufb01guration\nService: Amazon S3\nDescribes the versioning state of an Amazon S3 bucket. For more information, see PUT Bucket \nversioning in the Amazon S3 API Reference.\nContents\nMFADelete\nSpeci\ufb01es whether MFA delete is enabled in the bucket versioning con\ufb01guration. This element is \nonly returned if the bucket has been con\ufb01gured with MFA delete.", "If the bucket has never been \nso con\ufb01gured, this element is not returned.\nType: String\nValid Values: Enabled | Disabled\nRequired: No\nStatus\nThe versioning state of the bucket.\nType: String\nValid Values: Enabled | Suspended\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1381Amazon Simple Storage Service API Reference\nWebsiteCon\ufb01guration\nService: Amazon S3\nSpeci\ufb01es website con\ufb01guration parameters for an Amazon S3 bucket.\nContents\nErrorDocument\nThe name of the error document for the website.\nType: ErrorDocument data type\nRequired: No\nIndexDocument\nThe name of the index document for the website.\nType: IndexDocument  data type\nRequired: No\nRedirectAllRequestsTo\nThe redirect behavior for every request to this bucket's website endpoint.\nImportant\nIf you specify this property, you can't specify any other property.\nType: RedirectAllRequestsTo data type\nRequired: No\nRoutingRules\nRules that de\ufb01ne when a redirect is applied and the redirect behavior.\nType: Array of RoutingRule data types\nRequired: No\nAmazon S3 API Version 2006-03-01 1382Amazon Simple Storage Service API Reference\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control\nThe following data types are supported by Amazon S3 Control:\n\u2022AbortIncompleteMultipartUpload\n\u2022AccessControlTranslation\n\u2022AccessGrantsLocationCon\ufb01guration\n\u2022AccessPoint\n\u2022AccountLevel\n\u2022ActivityMetrics\n\u2022AdvancedCostOptimizationMetrics\n\u2022AdvancedDataProtectionMetrics\n\u2022AsyncErrorDetails\n\u2022AsyncOperation\n\u2022AsyncRequestParameters\n\u2022AsyncResponseDetails\n\u2022AwsLambdaTransformation\n\u2022BucketLevel\n\u2022CloudWatchMetrics\n\u2022CreateBucketCon\ufb01guration\n\u2022CreateMultiRegionAccessPointInput\n\u2022Credentials\n\u2022DeleteMarkerReplication\n\u2022DeleteMultiRegionAccessPointInput\nAmazon S3 Control API Version 2006-03-01 1383Amazon Simple Storage Service API Reference\n\u2022Destination\n\u2022DetailedStatusCodesMetrics\n\u2022EncryptionCon\ufb01guration\n\u2022EstablishedMultiRegionAccessPointPolicy\n\u2022Exclude\n\u2022ExistingObjectReplication\n\u2022GeneratedManifestEncryption\n\u2022Grantee\n\u2022Include\n\u2022JobDescriptor\n\u2022JobFailure\n\u2022JobListDescriptor\n\u2022JobManifest\n\u2022JobManifestGenerator\n\u2022JobManifestGeneratorFilter\n\u2022JobManifestLocation\n\u2022JobManifestSpec\n\u2022JobOperation\n\u2022JobProgressSummary\n\u2022JobReport\n\u2022JobTimers\n\u2022KeyNameConstraint\n\u2022LambdaInvokeOperation\n\u2022LifecycleCon\ufb01guration\n\u2022LifecycleExpiration\n\u2022LifecycleRule\n\u2022LifecycleRuleAndOperator\n\u2022LifecycleRuleFilter\n\u2022ListAccessGrantEntry\n\u2022ListAccessGrantsInstanceEntry\nAmazon S3 Control API Version 2006-03-01 1384Amazon Simple Storage Service API Reference\n\u2022ListAccessGrantsLocationsEntry\n\u2022ListCallerAccessGrantsEntry\n\u2022ListStorageLensCon\ufb01gurationEntry\n\u2022ListStorageLensGroupEntry\n\u2022MatchObjectAge\n\u2022MatchObjectSize\n\u2022Metrics\n\u2022MultiRegionAccessPointPolicyDocument\n\u2022MultiRegionAccessPointRegionalResponse\n\u2022MultiRegionAccessPointReport\n\u2022MultiRegionAccessPointRoute\n\u2022MultiRegionAccessPointsAsyncResponse\n\u2022NoncurrentVersionExpiration\n\u2022NoncurrentVersionTransition\n\u2022ObjectLambdaAccessPoint\n\u2022ObjectLambdaAccessPointAlias\n\u2022ObjectLambdaCon\ufb01guration\n\u2022ObjectLambdaContentTransformation\n\u2022ObjectLambdaTransformationCon\ufb01guration\n\u2022PolicyStatus\n\u2022Pre\ufb01xLevel\n\u2022Pre\ufb01xLevelStorageMetrics\n\u2022ProposedMultiRegionAccessPointPolicy\n\u2022PublicAccessBlockCon\ufb01guration\n\u2022PutMultiRegionAccessPointPolicyInput\n\u2022Region\n\u2022RegionalBucket\n\u2022RegionReport\n\u2022ReplicaModi\ufb01cations\n\u2022ReplicationCon\ufb01guration\nAmazon S3 Control API Version 2006-03-01 1385Amazon Simple Storage Service API Reference\n\u2022ReplicationRule\n\u2022ReplicationRuleAndOperator\n\u2022ReplicationRuleFilter\n\u2022ReplicationTime\n\u2022ReplicationTimeValue\n\u2022S3AccessControlList\n\u2022S3AccessControlPolicy\n\u2022S3BucketDestination\n\u2022S3CopyObjectOperation\n\u2022S3DeleteObjectTaggingOperation\n\u2022S3GeneratedManifestDescriptor\n\u2022S3Grant\n\u2022S3Grantee\n\u2022S3InitiateRestoreObjectOperation\n\u2022S3JobManifestGenerator\n\u2022S3ManifestOutputLocation\n\u2022S3ObjectLockLegalHold\n\u2022S3ObjectMetadata\n\u2022S3ObjectOwner\n\u2022S3ReplicateObjectOperation\n\u2022S3Retention\n\u2022S3SetObjectAclOperation\n\u2022S3SetObjectLegalHoldOperation\n\u2022S3SetObjectRetentionOperation\n\u2022S3SetObjectTaggingOperation\n\u2022S3Tag\n\u2022SelectionCriteria\n\u2022SourceSelectionCriteria\n\u2022SSEKMS\n\u2022SseKmsEncryptedObjects\nAmazon S3 Control API Version 2006-03-01 1386Amazon Simple Storage Service API Reference\n\u2022SSEKMSEncryption\n\u2022SSES3\n\u2022SSES3Encryption\n\u2022StorageLensAwsOrg\n\u2022StorageLensCon\ufb01guration\n\u2022StorageLensDataExport\n\u2022StorageLensDataExportEncryption\n\u2022StorageLensGroup\n\u2022StorageLensGroupAndOperator\n\u2022StorageLensGroupFilter\n\u2022StorageLensGroupLevel\n\u2022StorageLensGroupLevelSelectionCriteria\n\u2022StorageLensGroupOrOperator\n\u2022StorageLensTag\n\u2022Tag\n\u2022Tagging\n\u2022Transition\n\u2022VersioningCon\ufb01guration\n\u2022VpcCon\ufb01guration\nAmazon S3 Control API Version 2006-03-01 1387Amazon Simple Storage Service API Reference\nAbortIncompleteMultipartUpload\nService: Amazon S3 Control\nThe container for abort incomplete multipart upload\nContents\nDaysAfterInitiation\nSpeci\ufb01es the number of days after which Amazon S3 aborts an incomplete multipart upload to \nthe Outposts bucket.\nType: Integer\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1388Amazon Simple Storage Service API Reference\nAccessControlTranslation\nService: Amazon S3 Control\nA container for information about access control for replicas.\nNote\nThis is not supported by Amazon S3 on Outposts buckets.\nContents\nOwner\nSpeci\ufb01es the replica ownership.\nType: String\nValid Values: Destination\nRequired: Yes\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1389Amazon Simple Storage Service API Reference\nAccessGrantsLocationCon\ufb01guration\nService: Amazon S3 Control\nThe con\ufb01guration options of the S3 Access Grants location.", "It contains the S3SubPrefix  \ufb01eld. The \ngrant scope, the data to which you are granting access, is the result of appending the Subprefix\n\ufb01eld to the scope of the registered location.\nContents\nS3SubPre\ufb01x\nThe S3SubPrefix  is appended to the location scope creating the grant scope.", "Use this \ufb01eld \nto narrow the scope of the grant to a subset of the location scope.", "This \ufb01eld is required if the \nlocation scope is the default location s3:// because you cannot create a grant for all of your \nS3 data in the Region and must narrow the scope. For example, if the location scope is the \ndefault location s3:// , the S3SubPrefx  can be a <bucket-name>/*, so the full grant scope \npath would be s3://<bucket-name>/* . Or the S3SubPrefx  can be <bucket-name>/\n<prefix-name>* , so the full grant scope path would be or s3://<bucket-name>/<prefix-\nname>* .\nIf the S3SubPrefix  includes a pre\ufb01x, append the wildcard character * after the pre\ufb01x to \nindicate that you want to include all object key names in the bucket that start with that pre\ufb01x.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 2000.\nPattern: ^.+$\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1390Amazon Simple Storage Service API Reference\nAmazon S3 Control API Version 2006-03-01 1391Amazon Simple Storage Service API Reference\nAccessPoint\nService: Amazon S3 Control\nAn access point used to access a bucket.\nContents\nBucket\nThe name of the bucket associated with this access point.\nType: String\nLength Constraints: Minimum length of 3.", "Maximum length of 255.\nRequired: Yes\nName\nThe name of this access point.\nType: String\nLength Constraints: Minimum length of 3. Maximum length of 255.\nRequired: Yes\nNetworkOrigin\nIndicates whether this access point allows access from the public internet. If\nVpcConfiguration  is speci\ufb01ed for this access point, then NetworkOrigin  is VPC, and the \naccess point doesn't allow access from the public internet.", "Otherwise, NetworkOrigin  is\nInternet , and the access point allows access from the public internet, subject to the access \npoint and bucket access policies.\nType: String\nValid Values: Internet | VPC\nRequired: Yes\nAccessPointArn\nThe ARN for the access point.\nAmazon S3 Control API Version 2006-03-01 1392Amazon Simple Storage Service API Reference\nType: String\nLength Constraints: Minimum length of 4. Maximum length of 128.\nRequired: No\nAlias\nThe name or alias of the access point.\nType: String\nLength Constraints: Maximum length of 63.\nPattern: ^[0-9a-z\\\\-]{63}\nRequired: No\nBucketAccountId\nThe AWS account ID associated with the S3 bucket associated with this access point.\nType: String\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: No\nVpcCon\ufb01guration\nThe virtual private cloud (VPC) con\ufb01guration for this access point, if one exists.\nNote\nThis element is empty if this access point is an Amazon S3 on Outposts access point that \nis used by other AWS services.\nType: VpcCon\ufb01guration data type\nRequired: No\nAmazon S3 Control API Version 2006-03-01 1393Amazon Simple Storage Service API Reference\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1394Amazon Simple Storage Service API Reference\nAccountLevel\nService: Amazon S3 Control\nA container element for the account-level Amazon S3 Storage Lens con\ufb01guration.\nFor more information about S3 Storage Lens, see Assessing your storage activity and usage with S3 \nStorage Lens  in the Amazon S3 User Guide . For a complete list of S3 Storage Lens metrics, see S3 \nStorage Lens metrics glossary in the Amazon S3 User Guide .\nContents\nBucketLevel\nA container element for the S3 Storage Lens bucket-level con\ufb01guration.\nType: BucketLevel data type\nRequired: Yes\nActivityMetrics\nA container element for S3 Storage Lens activity metrics.\nType: ActivityMetrics data type\nRequired: No\nAdvancedCostOptimizationMetrics\nA container element for S3 Storage Lens advanced cost-optimization metrics.\nType: AdvancedCostOptimizationMetrics data type\nRequired: No\nAdvancedDataProtectionMetrics\nA container element for S3 Storage Lens advanced data-protection metrics.\nType: AdvancedDataProtectionMetrics data type\nRequired: No\nDetailedStatusCodesMetrics\nA container element for detailed status code metrics.\nAmazon S3 Control API Version 2006-03-01 1395Amazon Simple Storage Service API Reference\nType: DetailedStatusCodesMetrics  data type\nRequired: No\nStorageLensGroupLevel\nA container element for S3 Storage Lens groups metrics.\nType: StorageLensGroupLevel data type\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1396Amazon Simple Storage Service API Reference\nActivityMetrics\nService: Amazon S3 Control\nThe container element for Amazon S3 Storage Lens activity metrics. Activity metrics show details \nabout how your storage is requested, such as requests (for example, All requests, Get requests, Put \nrequests), bytes uploaded or downloaded, and errors.\nFor more information about S3 Storage Lens, see Assessing your storage activity and usage with S3 \nStorage Lens  in the Amazon S3 User Guide . For a complete list of S3 Storage Lens metrics, see S3 \nStorage Lens metrics glossary in the Amazon S3 User Guide .\nContents\nIsEnabled\nA container that indicates whether activity metrics are enabled.\nType: Boolean\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1397Amazon Simple Storage Service API Reference\nAdvancedCostOptimizationMetrics\nService: Amazon S3 Control\nThe container element for Amazon S3 Storage Lens advanced cost-optimization metrics. Advanced \ncost-optimization metrics provide insights that you can use to manage and optimize your storage \ncosts, for example, lifecycle rule counts for transitions, expirations, and incomplete multipart \nuploads.\nFor more information about S3 Storage Lens, see Assessing your storage activity and usage with S3 \nStorage Lens  in the Amazon S3 User Guide . For a complete list of S3 Storage Lens metrics, see S3 \nStorage Lens metrics glossary in the Amazon S3 User Guide .\nContents\nIsEnabled\nA container that indicates whether advanced cost-optimization metrics are enabled.\nType: Boolean\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1398Amazon Simple Storage Service API Reference\nAdvancedDataProtectionMetrics\nService: Amazon S3 Control\nThe container element for Amazon S3 Storage Lens advanced data-protection metrics. Advanced \ndata-protection metrics provide insights that you can use to perform audits and protect your data, \nfor example replication rule counts within and across Regions.\nFor more information about S3 Storage Lens, see Assessing your storage activity and usage with S3 \nStorage Lens  in the Amazon S3 User Guide . For a complete list of S3 Storage Lens metrics, see S3 \nStorage Lens metrics glossary in the Amazon S3 User Guide .\nContents\nIsEnabled\nA container that indicates whether advanced data-protection metrics are enabled.\nType: Boolean\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1399Amazon Simple Storage Service API Reference\nAsyncErrorDetails\nService: Amazon S3 Control\nError details for the failed asynchronous operation.\nContents\nCode\nA string that uniquely identi\ufb01es the error condition.\nType: String\nLength Constraints: Maximum length of 1024.\nRequired: No\nMessage\nA generic description of the error condition in English.\nType: String\nLength Constraints: Maximum length of 1024.\nRequired: No\nRequestId\nThe ID of the request associated with the error.\nType: String\nLength Constraints: Maximum length of 1024.\nRequired: No\nResource\nThe identi\ufb01er of the resource associated with the error.\nType: String\nLength Constraints: Maximum length of 1024.\nRequired: No\nAmazon S3 Control API Version 2006-03-01 1400Amazon Simple Storage Service API Reference\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1401Amazon Simple Storage Service API Reference\nAsyncOperation\nService: Amazon S3 Control\nA container for the information about an asynchronous operation.\nContents\nCreationTime\nThe time that the request was sent to the service.\nType: Timestamp\nRequired: No\nOperation\nThe speci\ufb01c operation for the asynchronous request.\nType: String\nValid Values: CreateMultiRegionAccessPoint | DeleteMultiRegionAccessPoint | \nPutMultiRegionAccessPointPolicy\nRequired: No\nRequestParameters\nThe parameters associated with the request.\nType: AsyncRequestParameters data type\nRequired: No\nRequestStatus\nThe current status of the request.\nType: String\nRequired: No\nRequestTokenARN\nThe request token associated with the request.\nAmazon S3 Control API Version 2006-03-01 1402Amazon Simple Storage Service API Reference\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 1024.\nPattern: arn:.+\nRequired: No\nResponseDetails\nThe details of the response.\nType: AsyncResponseDetails data type\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1403Amazon Simple Storage Service API Reference\nAsyncRequestParameters\nService: Amazon S3 Control\nA container for the request parameters associated with an asynchronous request.\nContents\nCreateMultiRegionAccessPointRequest\nA container of the parameters for a CreateMultiRegionAccessPoint request.\nType: CreateMultiRegionAccessPointInput data type\nRequired: No\nDeleteMultiRegionAccessPointRequest\nA container of the parameters for a DeleteMultiRegionAccessPoint request.\nType: DeleteMultiRegionAccessPointInput data type\nRequired: No\nPutMultiRegionAccessPointPolicyRequest\nA container of the parameters for a PutMultiRegionAccessPoint request.\nType: PutMultiRegionAccessPointPolicyInput data type\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1404Amazon Simple Storage Service API Reference\nAsyncResponseDetails\nService: Amazon S3 Control\nA container for the response details that are returned when querying about an asynchronous \nrequest.\nContents\nErrorDetails\nError details for an asynchronous request.\nType: AsyncErrorDetails data type\nRequired: No\nMultiRegionAccessPointDetails\nThe details for the Multi-Region Access Point.\nType: MultiRegionAccessPointsAsyncResponse data type\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1405Amazon Simple Storage Service API Reference\nAwsLambdaTransformation\nService: Amazon S3 Control\nAWS Lambda function used to transform objects through an Object Lambda Access Point.\nContents\nFunctionArn\nThe Amazon Resource Name (ARN) of the AWS Lambda function.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 1024.\nPattern: (arn:(aws[a-zA-Z-]*)?:lambda:)?([a-z]{2}((-gov)|(-iso(b?)))?-[a-\nz]+-\\d{1}:)?(\\d{12}:)?(function:)?([a-zA-Z0-9-_]+)(:(\\$LATEST|[a-zA-\nZ0-9-_]+))?\nRequired: Yes\nFunctionPayload\nAdditional JSON that provides supplemental data to the Lambda function used to transform \nobjects.\nType: String\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1406Amazon Simple Storage Service API Reference\nBucketLevel\nService: Amazon S3 Control\nA container for the bucket-level con\ufb01guration for Amazon S3 Storage Lens.\nFor more information about S3 Storage Lens, see Assessing your storage activity and usage with S3 \nStorage Lens  in the Amazon S3 User Guide .\nContents\nActivityMetrics\nA container for the bucket-level activity metrics for S3 Storage Lens.\nType: ActivityMetrics data type\nRequired: No\nAdvancedCostOptimizationMetrics\nA container for bucket-level advanced cost-optimization metrics for S3 Storage Lens.\nType: AdvancedCostOptimizationMetrics data type\nRequired: No\nAdvancedDataProtectionMetrics\nA container for bucket-level advanced data-protection metrics for S3 Storage Lens.\nType: AdvancedDataProtectionMetrics data type\nRequired: No\nDetailedStatusCodesMetrics\nA container for bucket-level detailed status code metrics for S3 Storage Lens.\nType: DetailedStatusCodesMetrics  data type\nRequired: No\nPre\ufb01xLevel\nA container for the pre\ufb01x-level metrics for S3 Storage Lens.\nAmazon S3 Control API Version 2006-03-01 1407Amazon Simple Storage Service API Reference\nType: Pre\ufb01xLevel data type\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1408Amazon Simple Storage Service API Reference\nCloudWatchMetrics\nService: Amazon S3 Control\nA container for enabling Amazon CloudWatch publishing for S3 Storage Lens metrics.\nFor more information about publishing S3 Storage Lens metrics to CloudWatch, see Monitor S3 \nStorage Lens metrics in CloudWatch in the Amazon S3 User Guide .\nContents\nIsEnabled\nA container that indicates whether CloudWatch publishing for S3 Storage Lens metrics is \nenabled. A value of true indicates that CloudWatch publishing for S3 Storage Lens metrics is \nenabled.\nType: Boolean\nRequired: Yes\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1409Amazon Simple Storage Service API Reference\nCreateBucketCon\ufb01guration\nService: Amazon S3 Control\nThe container for the bucket con\ufb01guration.\nNote\nThis is not supported by Amazon S3 on Outposts buckets.\nContents\nLocationConstraint\nSpeci\ufb01es the Region where the bucket will be created.", "If you are creating a bucket on the US \nEast (N.", "Virginia) Region (us-east-1), you do not need to specify the location.\nNote\nThis is not supported by Amazon S3 on Outposts buckets.\nType: String\nValid Values: EU | eu-west-1 | us-west-1 | us-west-2 | ap-south-1 | ap-\nsoutheast-1 | ap-southeast-2 | ap-northeast-1 | sa-east-1 | cn-north-1 | \neu-central-1\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1410Amazon Simple Storage Service API Reference\nCreateMultiRegionAccessPointInput\nService: Amazon S3 Control\nA container for the information associated with a CreateMultiRegionAccessPoint request.\nContents\nName\nThe name of the Multi-Region Access Point associated with this request.\nType: String\nLength Constraints: Maximum length of 50.\nPattern: ^[a-z0-9][-a-z0-9]{1,48}[a-z0-9]$\nRequired: Yes\nRegions\nThe buckets in di\ufb00erent Regions that are associated with the Multi-Region Access Point.\nType: Array of Region data types\nRequired: Yes\nPublicAccessBlock\nThe PublicAccessBlock  con\ufb01guration that you want to apply to this Amazon S3 account.", "\nYou can enable the con\ufb01guration options in any combination.", "For more information about when \nAmazon S3 considers a bucket or object public, see The Meaning of \"Public\" in the Amazon S3 \nUser Guide .\nThis data type is not supported for Amazon S3 on Outposts.\nType: PublicAccessBlockCon\ufb01guration data type\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\nAmazon S3 Control API Version 2006-03-01 1411Amazon Simple Storage Service API Reference\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1412Amazon Simple Storage Service API Reference\nCredentials\nService: Amazon S3 Control\nThe AWS Security Token Service temporary credential that S3 Access Grants vends to grantees and \nclient applications.\nContents\nAccessKeyId\nThe unique access key ID of the AWS STS temporary credential that S3 Access Grants vends to \ngrantees and client applications.\nType: String\nRequired: No\nExpiration\nThe expiration date and time of the temporary credential that S3 Access Grants vends to \ngrantees and client applications.\nType: Timestamp\nRequired: No\nSecretAccessKey\nThe secret access key of the AWS STS temporary credential that S3 Access Grants vends to \ngrantees and client applications.\nType: String\nRequired: No\nSessionToken\nThe AWS STS temporary credential that S3 Access Grants vends to grantees and client \napplications.\nType: String\nRequired: No\nAmazon S3 Control API Version 2006-03-01 1413Amazon Simple Storage Service API Reference\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1414Amazon Simple Storage Service API Reference\nDeleteMarkerReplication\nService: Amazon S3 Control\nSpeci\ufb01es whether S3 on Outposts replicates delete markers.", "If you specify a Filter  element in \nyour replication con\ufb01guration, you must also include a DeleteMarkerReplication  element.", "If \nyour Filter  includes a Tag element, the DeleteMarkerReplication  element's Status  child \nelement must be set to Disabled , because S3 on Outposts does not support replicating delete \nmarkers for tag-based rules.\nFor more information about delete marker replication, see How delete operations a\ufb00ect replication\nin the Amazon S3 User Guide .\nContents\nStatus\nIndicates whether to replicate delete markers.\nType: String\nValid Values: Enabled | Disabled\nRequired: Yes\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1415Amazon Simple Storage Service API Reference\nDeleteMultiRegionAccessPointInput\nService: Amazon S3 Control\nA container for the information associated with a DeleteMultiRegionAccessPoint request.\nContents\nName\nThe name of the Multi-Region Access Point associated with this request.\nType: String\nLength Constraints: Maximum length of 50.\nPattern: ^[a-z0-9][-a-z0-9]{1,48}[a-z0-9]$\nRequired: Yes\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1416Amazon Simple Storage Service API Reference\nDestination\nService: Amazon S3 Control\nSpeci\ufb01es information about the replication destination bucket and its settings for an S3 on \nOutposts replication con\ufb01guration.\nContents\nBucket\nThe Amazon Resource Name (ARN) of the access point for the destination bucket where you \nwant S3 on Outposts to store the replication results.\nType: String\nRequired: Yes\nAccessControlTranslation\nSpecify this property only in a cross-account scenario (where the source and destination bucket \nowners are not the same), and you want to change replica ownership to the AWS account that \nowns the destination bucket. If this property is not speci\ufb01ed in the replication con\ufb01guration, the \nreplicas are owned by same AWS account that owns the source object.\nNote\nThis is not supported by Amazon S3 on Outposts buckets.\nType: AccessControlTranslation data type\nRequired: No\nAccount\nThe destination bucket owner's account ID.\nType: String\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nAmazon S3 Control API Version 2006-03-01 1417Amazon Simple Storage Service API Reference\nRequired: No\nEncryptionCon\ufb01guration\nA container that provides information about encryption. If SourceSelectionCriteria  is \nspeci\ufb01ed, you must specify this element.\nNote\nThis is not supported by Amazon S3 on Outposts buckets.\nType: EncryptionCon\ufb01guration data type\nRequired: No\nMetrics\nA container that speci\ufb01es replication metrics-related settings.\nType: Metrics  data type\nRequired: No\nReplicationTime\nA container that speci\ufb01es S3 Replication Time Control (S3 RTC) settings, including whether S3 \nRTC is enabled and the time when all objects and operations on objects must be replicated. \nMust be speci\ufb01ed together with a Metrics  block.\nNote\nThis is not supported by Amazon S3 on Outposts buckets.\nType: ReplicationTime data type\nRequired: No\nStorageClass\nThe storage class to use when replicating objects. All objects stored on S3 on Outposts are \nstored in the OUTPOSTS  storage class. S3 on Outposts uses the OUTPOSTS  storage class to \ncreate the object replicas.\nAmazon S3 Control API Version 2006-03-01 1418Amazon Simple Storage Service API Reference\nNote\nValues other than OUTPOSTS  aren't supported by Amazon S3 on Outposts.\nType: String\nValid Values: STANDARD | REDUCED_REDUNDANCY | STANDARD_IA | ONEZONE_IA | \nINTELLIGENT_TIERING | GLACIER | DEEP_ARCHIVE | OUTPOSTS | GLACIER_IR\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1419Amazon Simple Storage Service API Reference\nDetailedStatusCodesMetrics\nService: Amazon S3 Control\nThe container element for Amazon S3 Storage Lens detailed status code metrics. Detailed status \ncode metrics generate metrics for HTTP status codes, such as 200 OK , 403 Forbidden , 503 \nService Unavailable  and others.\nFor more information about S3 Storage Lens, see Assessing your storage activity and usage with S3 \nStorage Lens  in the Amazon S3 User Guide . For a complete list of S3 Storage Lens metrics, see S3 \nStorage Lens metrics glossary in the Amazon S3 User Guide .\nContents\nIsEnabled\nA container that indicates whether detailed status code metrics are enabled.\nType: Boolean\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1420Amazon Simple Storage Service API Reference\nEncryptionCon\ufb01guration\nService: Amazon S3 Control\nSpeci\ufb01es encryption-related information for an Amazon S3 bucket that is a destination for \nreplicated objects.", "If you're specifying a customer managed KMS key, we recommend using a fully \nquali\ufb01ed KMS key ARN. If you use a KMS key alias instead, then AWS KMS resolves the key within \nthe requester\u2019s account. This behavior can result in data that's encrypted with a KMS key that \nbelongs to the requester, and not the bucket owner.\nNote\nThis is not supported by Amazon S3 on Outposts buckets.\nContents\nReplicaKmsKeyID\nSpeci\ufb01es the ID of the customer managed AWS KMS key that's stored in AWS Key Management \nService (AWS KMS) for the destination bucket.", "This ID is either the Amazon Resource Name \n(ARN) for the KMS key or the alias ARN for the KMS key.", "Amazon S3 uses this KMS key to \nencrypt replica objects. Amazon S3 supports only symmetric encryption KMS keys. For \nmore information, see Symmetric encryption KMS keys in the  AWS Key Management Service \nDeveloper Guide .\nType: String\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1421Amazon Simple Storage Service API Reference\nEstablishedMultiRegionAccessPointPolicy\nService: Amazon S3 Control\nThe last established access control policy for a Multi-Region Access Point.\nWhen you update the policy, the update is \ufb01rst listed as the proposed policy.", "After the update is \n\ufb01nished and all Regions have been updated, the proposed policy is listed as the established policy.", "\nIf both policies have the same version number, the proposed policy is the established policy.\nContents\nPolicy\nThe details of the last established policy.\nType: String\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1422Amazon Simple Storage Service API Reference\nExclude\nService: Amazon S3 Control\nA container for what Amazon S3 Storage Lens will exclude.\nContents\nBuckets\nA container for the S3 Storage Lens bucket excludes.\nType: Array of strings\nLength Constraints: Minimum length of 1. Maximum length of 128.\nPattern: arn:[^:]+:s3:.*\nRequired: No\nRegions\nA container for the S3 Storage Lens Region excludes.\nType: Array of strings\nLength Constraints: Minimum length of 5.", "Maximum length of 30.\nPattern: [a-z0-9\\-]+\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1423Amazon Simple Storage Service API Reference\nExistingObjectReplication\nService: Amazon S3 Control\nAn optional con\ufb01guration to replicate existing source bucket objects.\nNote\nThis is not supported by Amazon S3 on Outposts buckets.\nContents\nStatus\nSpeci\ufb01es whether Amazon S3 replicates existing source bucket objects.\nType: String\nValid Values: Enabled | Disabled\nRequired: Yes\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1424Amazon Simple Storage Service API Reference\nGeneratedManifestEncryption\nService: Amazon S3 Control\nThe encryption con\ufb01guration to use when storing the generated manifest.\nContents\nSSEKMS\nCon\ufb01guration details on how SSE-KMS is used to encrypt generated manifest objects.\nType: SSEKMSEncryption data type\nRequired: No\nSSES3\nSpeci\ufb01es the use of SSE-S3 to encrypt generated manifest objects.\nType: SSES3Encryption data type\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1425Amazon Simple Storage Service API Reference\nGrantee\nService: Amazon S3 Control\nThe user, group, or role to which you are granting access.", "You can grant access to an IAM user or \nrole.", "If you have added your corporate directory to AWS IAM Identity Center and associated your \nIdentity Center instance with your S3 Access Grants instance, the grantee can also be a corporate \ndirectory user or group.\nContents\nGranteeIdenti\ufb01er\nThe unique identi\ufb01er of the Grantee.", "If the grantee type is IAM, the identi\ufb01er is the \nIAM Amazon Resource Name (ARN) of the user or role.", "If the grantee type is a directory \nuser or group, the identi\ufb01er is 128-bit universally unique identi\ufb01er (UUID) in the format\na1b2c3d4-5678-90ab-cdef-EXAMPLE11111 .", "You can obtain this UUID from your AWS IAM \nIdentity Center instance.\nType: String\nRequired: No\nGranteeType\nThe type of the grantee to which access has been granted.", "It can be one of the following values:\n\u2022IAM - An IAM user or role.\n\u2022DIRECTORY_USER  - Your corporate directory user.", "You can use this option if you have added \nyour corporate identity directory to IAM Identity Center and associated the IAM Identity \nCenter instance with your S3 Access Grants instance.\n\u2022DIRECTORY_GROUP  - Your corporate directory group. You can use this option if you have \nadded your corporate identity directory to IAM Identity Center and associated the IAM \nIdentity Center instance with your S3 Access Grants instance.\nType: String\nValid Values: DIRECTORY_USER | DIRECTORY_GROUP | IAM\nRequired: No\nAmazon S3 Control API Version 2006-03-01 1426Amazon Simple Storage Service API Reference\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1427Amazon Simple Storage Service API Reference\nInclude\nService: Amazon S3 Control\nA container for what Amazon S3 Storage Lens con\ufb01guration includes.\nContents\nBuckets\nA container for the S3 Storage Lens bucket includes.\nType: Array of strings\nLength Constraints: Minimum length of 1. Maximum length of 128.\nPattern: arn:[^:]+:s3:.*\nRequired: No\nRegions\nA container for the S3 Storage Lens Region includes.\nType: Array of strings\nLength Constraints: Minimum length of 5.", "Maximum length of 30.\nPattern: [a-z0-9\\-]+\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1428Amazon Simple Storage Service API Reference\nJobDescriptor\nService: Amazon S3 Control\nA container element for the job con\ufb01guration and status information returned by a Describe Job\nrequest.\nContents\nCon\ufb01rmationRequired\nIndicates whether con\ufb01rmation is required before Amazon S3 begins running the speci\ufb01ed job. \nCon\ufb01rmation is required only for jobs created through the Amazon S3 console.\nType: Boolean\nRequired: No\nCreationTime\nA timestamp indicating when this job was created.\nType: Timestamp\nRequired: No\nDescription\nThe description for this job, if one was provided in this job's Create Job  request.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 256.\nRequired: No\nFailureReasons\nIf the speci\ufb01ed job failed, this \ufb01eld contains information describing the failure.\nType: Array of JobFailure data types\nRequired: No\nGeneratedManifestDescriptor\nThe attribute of the JobDescriptor containing details about the job's generated manifest.\nAmazon S3 Control API Version 2006-03-01 1429Amazon Simple Storage Service API Reference\nType: S3GeneratedManifestDescriptor  data type\nRequired: No\nJobArn\nThe Amazon Resource Name (ARN) for this job.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 1024.\nPattern: arn:[^:]+:s3:[a-zA-Z0-9\\-]+:\\d{12}:job\\/.*\nRequired: No\nJobId\nThe ID for the speci\ufb01ed job.\nType: String\nLength Constraints: Minimum length of 5. Maximum length of 36.\nPattern: [a-zA-Z0-9\\-\\_]+\nRequired: No\nManifest\nThe con\ufb01guration information for the speci\ufb01ed job's manifest object.\nType: JobManifest  data type\nRequired: No\nManifestGenerator\nThe manifest generator that was used to generate a job manifest for this job.\nType: JobManifestGenerator  data type\nNote: This object is a Union.", "Only one member of this object can be speci\ufb01ed or returned.\nRequired: No\nAmazon S3 Control API Version 2006-03-01 1430Amazon Simple Storage Service API Reference\nOperation\nThe operation that the speci\ufb01ed job is con\ufb01gured to run on the objects listed in the manifest.\nType: JobOperation  data type\nRequired: No\nPriority\nThe priority of the speci\ufb01ed job.\nType: Integer\nValid Range: Minimum value of 0. Maximum value of 2147483647.\nRequired: No\nProgressSummary\nDescribes the total number of tasks that the speci\ufb01ed job has run, the number of tasks that \nsucceeded, and the number of tasks that failed.\nType: JobProgressSummary data type\nRequired: No\nReport\nContains the con\ufb01guration information for the job-completion report if you requested one in \nthe Create Job  request.\nType: JobReport data type\nRequired: No\nRoleArn\nThe Amazon Resource Name (ARN) for the AWS Identity and Access Management (IAM) role \nassigned to run the tasks for this job.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 2048.\nPattern: arn:[^:]+:iam::\\d{12}:role/.*\nAmazon S3 Control API Version 2006-03-01 1431Amazon Simple Storage Service API Reference\nRequired: No\nStatus\nThe current status of the speci\ufb01ed job.\nType: String\nValid Values: Active | Cancelled | Cancelling | Complete | Completing \n| Failed | Failing | New | Paused | Pausing | Preparing | Ready | \nSuspended\nRequired: No\nStatusUpdateReason\nThe reason for updating the job.\nType: String\nLength Constraints: Minimum length of 1.", "Maximum length of 256.\nRequired: No\nSuspendedCause\nThe reason why the speci\ufb01ed job was suspended.", "A job is only suspended if you create it \nthrough the Amazon S3 console.", "When you create the job, it enters the Suspended  state \nto await con\ufb01rmation before running. After you con\ufb01rm the job, it automatically exits the\nSuspended  state.\nType: String\nLength Constraints: Minimum length of 1.", "Maximum length of 1024.\nRequired: No\nSuspendedDate\nThe timestamp when this job was suspended, if it has been suspended.\nType: Timestamp\nRequired: No\nAmazon S3 Control API Version 2006-03-01 1432Amazon Simple Storage Service API Reference\nTerminationDate\nA timestamp indicating when this job terminated. A job's termination date is the date and time \nwhen it succeeded, failed, or was canceled.\nType: Timestamp\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1433Amazon Simple Storage Service API Reference\nJobFailure\nService: Amazon S3 Control\nIf this job failed, this element indicates why the job failed.\nContents\nFailureCode\nThe failure code, if any, for the speci\ufb01ed job.\nType: String\nLength Constraints: Minimum length of 1.", "Maximum length of 64.\nRequired: No\nFailureReason\nThe failure reason, if any, for the speci\ufb01ed job.\nType: String\nLength Constraints: Minimum length of 1.", "Maximum length of 256.\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1434Amazon Simple Storage Service API Reference\nJobListDescriptor\nService: Amazon S3 Control\nContains the con\ufb01guration and status information for a single job retrieved as part of a job list.\nContents\nCreationTime\nA timestamp indicating when the speci\ufb01ed job was created.\nType: Timestamp\nRequired: No\nDescription\nThe user-speci\ufb01ed description that was included in the speci\ufb01ed job's Create Job  request.\nType: String\nLength Constraints: Minimum length of 1.", "Maximum length of 256.\nRequired: No\nJobId\nThe ID for the speci\ufb01ed job.\nType: String\nLength Constraints: Minimum length of 5.", "Maximum length of 36.\nPattern: [a-zA-Z0-9\\-\\_]+\nRequired: No\nOperation\nThe operation that the speci\ufb01ed job is con\ufb01gured to run on every object listed in the manifest.\nType: String\nValid Values: LambdaInvoke | S3PutObjectCopy | S3PutObjectAcl | \nS3PutObjectTagging | S3DeleteObjectTagging | S3InitiateRestoreObject | \nS3PutObjectLegalHold | S3PutObjectRetention | S3ReplicateObject\nAmazon S3 Control API Version 2006-03-01 1435Amazon Simple Storage Service API Reference\nRequired: No\nPriority\nThe current priority for the speci\ufb01ed job.\nType: Integer\nValid Range: Minimum value of 0.", "Maximum value of 2147483647.\nRequired: No\nProgressSummary\nDescribes the total number of tasks that the speci\ufb01ed job has run, the number of tasks that \nsucceeded, and the number of tasks that failed.\nType: JobProgressSummary data type\nRequired: No\nStatus\nThe speci\ufb01ed job's current status.\nType: String\nValid Values: Active | Cancelled | Cancelling | Complete | Completing \n| Failed | Failing | New | Paused | Pausing | Preparing | Ready | \nSuspended\nRequired: No\nTerminationDate\nA timestamp indicating when the speci\ufb01ed job terminated.", "A job's termination date is the date \nand time when it succeeded, failed, or was canceled.\nType: Timestamp\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\nAmazon S3 Control API Version 2006-03-01 1436Amazon Simple Storage Service API Reference\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1437Amazon Simple Storage Service API Reference\nJobManifest\nService: Amazon S3 Control\nContains the con\ufb01guration information for a job's manifest.\nContents\nLocation\nContains the information required to locate the speci\ufb01ed job's manifest.", "Manifests can't be \nimported from directory buckets.", "For more information, see Directory buckets.\nType: JobManifestLocation  data type\nRequired: Yes\nSpec\nDescribes the format of the speci\ufb01ed job's manifest. If the manifest is in CSV format, also \ndescribes the columns contained within the manifest.\nType: JobManifestSpec  data type\nRequired: Yes\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1438Amazon Simple Storage Service API Reference\nJobManifestGenerator\nService: Amazon S3 Control\nCon\ufb01gures the type of the job's ManifestGenerator.\nContents\nImportant\nThis data type is a UNION, so only one of the following members can be speci\ufb01ed when \nused or returned.\nS3JobManifestGenerator\nThe S3 job ManifestGenerator's con\ufb01guration details.\nType: S3JobManifestGenerator  data type\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1439Amazon Simple Storage Service API Reference\nJobManifestGeneratorFilter\nService: Amazon S3 Control\nThe \ufb01lter used to describe a set of objects for the job's manifest.\nContents\nCreatedAfter\nIf provided, the generated manifest includes only source bucket objects that were created after \nthis time.\nType: Timestamp\nRequired: No\nCreatedBefore\nIf provided, the generated manifest includes only source bucket objects that were created \nbefore this time.\nType: Timestamp\nRequired: No\nEligibleForReplication\nInclude objects in the generated manifest only if they are eligible for replication according to \nthe Replication con\ufb01guration on the source bucket.\nType: Boolean\nRequired: No\nKeyNameConstraint\nIf provided, the generated manifest includes only source bucket objects whose object \nkeys match the string constraints speci\ufb01ed for MatchAnyPrefix , MatchAnySuffix , and\nMatchAnySubstring .\nType: KeyNameConstraint data type\nRequired: No\nAmazon S3 Control API Version 2006-03-01 1440Amazon Simple Storage Service API Reference\nMatchAnyStorageClass\nIf provided, the generated manifest includes only source bucket objects that are stored with the \nspeci\ufb01ed storage class.\nType: Array of strings\nValid Values: STANDARD | STANDARD_IA | ONEZONE_IA | GLACIER | \nINTELLIGENT_TIERING | DEEP_ARCHIVE | GLACIER_IR\nRequired: No\nObjectReplicationStatuses\nIf provided, the generated manifest includes only source bucket objects that have one of the \nspeci\ufb01ed Replication statuses.\nType: Array of strings\nValid Values: COMPLETED | FAILED | REPLICA | NONE\nRequired: No\nObjectSizeGreaterThanBytes\nIf provided, the generated manifest includes only source bucket objects whose \ufb01le size is \ngreater than the speci\ufb01ed number of bytes.\nType: Long\nRequired: No\nObjectSizeLessThanBytes\nIf provided, the generated manifest includes only source bucket objects whose \ufb01le size is less \nthan the speci\ufb01ed number of bytes.\nType: Long\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\nAmazon S3 Control API Version 2006-03-01 1441Amazon Simple Storage Service API Reference\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1442Amazon Simple Storage Service API Reference\nJobManifestLocation\nService: Amazon S3 Control\nContains the information required to locate a manifest object.", "Manifests can't be imported from \ndirectory buckets. For more information, see Directory buckets.\nContents\nETag\nThe ETag for the speci\ufb01ed manifest object.\nType: String\nLength Constraints: Minimum length of 1.", "Maximum length of 1024.\nRequired: Yes\nObjectArn\nThe Amazon Resource Name (ARN) for a manifest object.\nImportant\nWhen you're using XML requests, you must replace special characters (such as carriage \nreturns) in object keys with their equivalent XML entity codes.", "For more information, see\nXML-related object key constraints in the Amazon S3 User Guide .\nType: String\nLength Constraints: Minimum length of 1.", "Maximum length of 2000.\nPattern: arn:[^:]+:s3:.*\nRequired: Yes\nObjectVersionId\nThe optional version ID to identify a speci\ufb01c version of the manifest object.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 2000.\nAmazon S3 Control API Version 2006-03-01 1443Amazon Simple Storage Service API Reference\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1444Amazon Simple Storage Service API Reference\nJobManifestSpec\nService: Amazon S3 Control\nDescribes the format of a manifest. If the manifest is in CSV format, also describes the columns \ncontained within the manifest.\nContents\nFormat\nIndicates which of the available formats the speci\ufb01ed manifest uses.\nType: String\nValid Values: S3BatchOperations_CSV_20180820 | \nS3InventoryReport_CSV_20161130\nRequired: Yes\nFields\nIf the speci\ufb01ed manifest object is in the S3BatchOperations_CSV_20180820  format, this \nelement describes which columns contain the required data.\nType: Array of strings\nValid Values: Ignore | Bucket | Key | VersionId\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1445Amazon Simple Storage Service API Reference\nJobOperation\nService: Amazon S3 Control\nThe operation that you want this job to perform on every object listed in the manifest. For more \ninformation about the available operations, see Operations  in the Amazon S3 User Guide .\nContents\nLambdaInvoke\nDirects the speci\ufb01ed job to invoke an AWS Lambda function on every object in the manifest.\nType: LambdaInvokeOperation data type\nRequired: No\nS3DeleteObjectTagging\nDirects the speci\ufb01ed job to execute a DELETE Object tagging call on every object in the \nmanifest.\nNote\nThis functionality is not supported by directory buckets.\nType: S3DeleteObjectTaggingOperation data type\nRequired: No\nS3InitiateRestoreObject\nDirects the speci\ufb01ed job to initiate restore requests for every archived object in the manifest.\nNote\nThis functionality is not supported by directory buckets.\nType: S3InitiateRestoreObjectOperation data type\nRequired: No\nAmazon S3 Control API Version 2006-03-01 1446Amazon Simple Storage Service API Reference\nS3PutObjectAcl\nDirects the speci\ufb01ed job to run a PutObjectAcl  call on every object in the manifest.\nNote\nThis functionality is not supported by directory buckets.\nType: S3SetObjectAclOperation data type\nRequired: No\nS3PutObjectCopy\nDirects the speci\ufb01ed job to run a PUT Copy object call on every object in the manifest.\nType: S3CopyObjectOperation data type\nRequired: No\nS3PutObjectLegalHold\nContains the con\ufb01guration for an S3 Object Lock legal hold operation that an S3 Batch \nOperations job passes to every object to the underlying PutObjectLegalHold  API operation. \nFor more information, see Using S3 Object Lock legal hold with S3 Batch Operations in the\nAmazon S3 User Guide .\nNote\nThis functionality is not supported by directory buckets.\nType: S3SetObjectLegalHoldOperation data type\nRequired: No\nS3PutObjectRetention\nContains the con\ufb01guration parameters for the Object Lock retention action for an S3 Batch \nOperations job.", "Batch Operations passes every object to the underlying PutObjectRetention\nAPI operation.", "For more information, see Using S3 Object Lock retention with S3 Batch \nOperations  in the Amazon S3 User Guide .\nAmazon S3 Control API Version 2006-03-01 1447Amazon Simple Storage Service API Reference\nNote\nThis functionality is not supported by directory buckets.\nType: S3SetObjectRetentionOperation data type\nRequired: No\nS3PutObjectTagging\nDirects the speci\ufb01ed job to run a PUT Object tagging call on every object in the manifest.\nNote\nThis functionality is not supported by directory buckets.\nType: S3SetObjectTaggingOperation data type\nRequired: No\nS3ReplicateObject\nDirects the speci\ufb01ed job to invoke ReplicateObject  on every object in the job's manifest.\nNote\nThis functionality is not supported by directory buckets.\nType: S3ReplicateObjectOperation data type\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\nAmazon S3 Control API Version 2006-03-01 1448Amazon Simple Storage Service API Reference\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1449Amazon Simple Storage Service API Reference\nJobProgressSummary\nService: Amazon S3 Control\nDescribes the total number of tasks that the speci\ufb01ed job has started, the number of tasks that \nsucceeded, and the number of tasks that failed.\nContents\nNumberOfTasksFailed\nType: Long\nValid Range: Minimum value of 0.\nRequired: No\nNumberOfTasksSucceeded\nType: Long\nValid Range: Minimum value of 0.\nRequired: No\nTimers\nThe JobTimers attribute of a job's progress summary.\nType: JobTimers  data type\nRequired: No\nTotalNumberOfTasks\nType: Long\nValid Range: Minimum value of 0.\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\nAmazon S3 Control API Version 2006-03-01 1450Amazon Simple Storage Service API Reference\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1451Amazon Simple Storage Service API Reference\nJobReport\nService: Amazon S3 Control\nContains the con\ufb01guration parameters for a job-completion report.\nContents\nEnabled\nIndicates whether the speci\ufb01ed job will generate a job-completion report.\nType: Boolean\nRequired: Yes\nBucket\nThe Amazon Resource Name (ARN) for the bucket where speci\ufb01ed job-completion report will be \nstored.\nNote\nDirectory buckets - Directory buckets aren't supported as a location for Batch \nOperations to store job completion reports.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 128.\nPattern: arn:[^:]+:s3:.*\nRequired: No\nFormat\nThe format of the speci\ufb01ed job-completion report.\nType: String\nValid Values: Report_CSV_20180820\nRequired: No\nAmazon S3 Control API Version 2006-03-01 1452Amazon Simple Storage Service API Reference\nPre\ufb01x\nAn optional pre\ufb01x to describe where in the speci\ufb01ed bucket the job-completion report will \nbe stored. Amazon S3 stores the job-completion report at <prefix>/job-<job-id>/\nreport.json .\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 512.\nRequired: No\nReportScope\nIndicates whether the job-completion report will include details of all tasks or only failed tasks.\nType: String\nValid Values: AllTasks | FailedTasksOnly\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1453Amazon Simple Storage Service API Reference\nJobTimers\nService: Amazon S3 Control\nProvides timing details for the job.\nContents\nElapsedTimeInActiveSeconds\nIndicates the elapsed time in seconds the job has been in the Active job state.\nType: Long\nValid Range: Minimum value of 0.\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1454Amazon Simple Storage Service API Reference\nKeyNameConstraint\nService: Amazon S3 Control\nIf provided, the generated manifest includes only source bucket objects whose object \nkeys match the string constraints speci\ufb01ed for MatchAnyPrefix , MatchAnySuffix , and\nMatchAnySubstring .\nContents\nMatchAnyPre\ufb01x\nIf provided, the generated manifest includes objects where the speci\ufb01ed string appears at the \nstart of the object key string.", "Each KeyNameConstraint \ufb01lter accepts an array of strings with a \nlength of 1 string.\nType: Array of strings\nLength Constraints: Minimum length of 1.", "Maximum length of 1024.\nRequired: No\nMatchAnySubstring\nIf provided, the generated manifest includes objects where the speci\ufb01ed string appears \nanywhere within the object key string.", "Each KeyNameConstraint \ufb01lter accepts an array of strings \nwith a length of 1 string.\nType: Array of strings\nLength Constraints: Minimum length of 1.", "Maximum length of 1024.\nRequired: No\nMatchAnySu\ufb03x\nIf provided, the generated manifest includes objects where the speci\ufb01ed string appears at the \nend of the object key string.", "Each KeyNameConstraint \ufb01lter accepts an array of strings with a \nlength of 1 string.\nType: Array of strings\nLength Constraints: Minimum length of 1.", "Maximum length of 1024.\nRequired: No\nAmazon S3 Control API Version 2006-03-01 1455Amazon Simple Storage Service API Reference\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1456Amazon Simple Storage Service API Reference\nLambdaInvokeOperation\nService: Amazon S3 Control\nContains the con\ufb01guration parameters for a Lambda Invoke  operation.\nContents\nFunctionArn\nThe Amazon Resource Name (ARN) for the AWS Lambda function that the speci\ufb01ed job will \ninvoke on every object in the manifest.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 1024.\nPattern: (arn:(aws[a-zA-Z-]*)?:lambda:)?([a-z]{2}((-gov)|(-iso(b?)))?-[a-\nz]+-\\d{1}:)?(\\d{12}:)?(function:)?([a-zA-Z0-9-_]+)(:(\\$LATEST|[a-zA-\nZ0-9-_]+))?\nRequired: No\nInvocationSchemaVersion\nSpeci\ufb01es the schema version for the payload that Batch Operations sends when invoking an \nAWS Lambda function.", "Version 1.0 is the default.", "Version 2.0 is required when you use Batch \nOperations to invoke AWS Lambda functions that act on directory buckets, or if you need to \nspecify UserArguments . For more information, see Automate object processing in Amazon S3 \ndirectory buckets with S3 Batch Operations and AWS Lambda in the  AWS Storage Blog.\nImportant\nEnsure that your AWS Lambda function code expects InvocationSchemaVersion\n2.0 and uses bucket name rather than bucket ARN. If the InvocationSchemaVersion\ndoes not match what your AWS Lambda function expects, your function might not work \nas expected.\nAmazon S3 Control API Version 2006-03-01 1457Amazon Simple Storage Service API Reference\nNote\nDirectory buckets - To initiate AWS Lambda function to perform custom actions on \nobjects in directory buckets, you must specify 2.0.\nType: String\nLength Constraints: Minimum length of 1.", "Maximum length of 64.\nRequired: No\nUserArguments\nKey-value pairs that are passed in the payload that Batch Operations sends when invoking an \nAWS Lambda function. You must specify InvocationSchemaVersion  2.0 for LambdaInvoke\noperations that include UserArguments .", "For more information, see Automate object \nprocessing in Amazon S3 directory buckets with S3 Batch Operations and AWS Lambda in the \nAWS Storage Blog.\nType: String to string map\nMap Entries: Maximum number of 10 items.\nKey Length Constraints: Minimum length of 1. Maximum length of 64.\nValue Length Constraints: Maximum length of 1024.\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1458Amazon Simple Storage Service API Reference\nLifecycleCon\ufb01guration\nService: Amazon S3 Control\nThe container for the Outposts bucket lifecycle con\ufb01guration.\nContents\nRules\nA lifecycle rule for individual objects in an Outposts bucket.\nType: Array of LifecycleRule data types\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1459Amazon Simple Storage Service API Reference\nLifecycleExpiration\nService: Amazon S3 Control\nThe container of the Outposts bucket lifecycle expiration.\nContents\nDate\nIndicates at what date the object is to be deleted.", "Should be in GMT ISO 8601 format.\nType: Timestamp\nRequired: No\nDays\nIndicates the lifetime, in days, of the objects that are subject to the rule.", "The value must be a \nnon-zero positive integer.\nType: Integer\nRequired: No\nExpiredObjectDeleteMarker\nIndicates whether Amazon S3 will remove a delete marker with no noncurrent versions.", "If set to \ntrue, the delete marker will be expired.", "If set to false, the policy takes no action.", "This cannot be \nspeci\ufb01ed with Days or Date in a Lifecycle Expiration Policy.\nType: Boolean\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1460Amazon Simple Storage Service API Reference\nAmazon S3 Control API Version 2006-03-01 1461Amazon Simple Storage Service API Reference\nLifecycleRule\nService: Amazon S3 Control\nThe container for the Outposts bucket lifecycle rule.\nContents\nStatus\nIf 'Enabled', the rule is currently being applied. If 'Disabled', the rule is not currently being \napplied.\nType: String\nValid Values: Enabled | Disabled\nRequired: Yes\nAbortIncompleteMultipartUpload\nSpeci\ufb01es the days since the initiation of an incomplete multipart upload that Amazon S3 waits \nbefore permanently removing all parts of the upload. For more information, see  Aborting \nIncomplete Multipart Uploads Using a Bucket Lifecycle Con\ufb01guration in the Amazon S3 User \nGuide .\nType: AbortIncompleteMultipartUpload data type\nRequired: No\nExpiration\nSpeci\ufb01es the expiration for the lifecycle of the object in the form of date, days and, whether the \nobject has a delete marker.\nType: LifecycleExpiration data type\nRequired: No\nFilter\nThe container for the \ufb01lter of lifecycle rule.\nType: LifecycleRuleFilter data type\nRequired: No\nAmazon S3 Control API Version 2006-03-01 1462Amazon Simple Storage Service API Reference\nID\nUnique identi\ufb01er for the rule.", "The value cannot be longer than 255 characters.\nType: String\nRequired: No\nNoncurrentVersionExpiration\nThe noncurrent version expiration of the lifecycle rule.\nType: NoncurrentVersionExpiration data type\nRequired: No\nNoncurrentVersionTransitions\nSpeci\ufb01es the transition rule for the lifecycle rule that describes when noncurrent objects \ntransition to a speci\ufb01c storage class.", "If your bucket is versioning-enabled (or versioning is \nsuspended), you can set this action to request that Amazon S3 transition noncurrent object \nversions to a speci\ufb01c storage class at a set period in the object's lifetime.\nNote\nThis is not supported by Amazon S3 on Outposts buckets.\nType: Array of NoncurrentVersionTransition data types\nRequired: No\nTransitions\nSpeci\ufb01es when an Amazon S3 object transitions to a speci\ufb01ed storage class.\nNote\nThis is not supported by Amazon S3 on Outposts buckets.\nType: Array of Transition data types\nRequired: No\nAmazon S3 Control API Version 2006-03-01 1463Amazon Simple Storage Service API Reference\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1464Amazon Simple Storage Service API Reference\nLifecycleRuleAndOperator\nService: Amazon S3 Control\nThe container for the Outposts bucket lifecycle rule and operator.\nContents\nObjectSizeGreaterThan\nThe non-inclusive minimum object size for the lifecycle rule.", "Setting this property to 7 means \nthe rule applies to objects with a size that is greater than 7.\nType: Long\nRequired: No\nObjectSizeLessThan\nThe non-inclusive maximum object size for the lifecycle rule.", "Setting this property to 77 means \nthe rule applies to objects with a size that is less than 77.\nType: Long\nRequired: No\nPre\ufb01x\nPre\ufb01x identifying one or more objects to which the rule applies.\nType: String\nRequired: No\nTags\nAll of these tags must exist in the object's tag set in order for the rule to apply.\nType: Array of S3Tag data types\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\nAmazon S3 Control API Version 2006-03-01 1465Amazon Simple Storage Service API Reference\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1466Amazon Simple Storage Service API Reference\nLifecycleRuleFilter\nService: Amazon S3 Control\nThe container for the \ufb01lter of the lifecycle rule.\nContents\nAnd\nThe container for the AND condition for the lifecycle rule.\nType: LifecycleRuleAndOperator data type\nRequired: No\nObjectSizeGreaterThan\nMinimum object size to which the rule applies.\nType: Long\nRequired: No\nObjectSizeLessThan\nMaximum object size to which the rule applies.\nType: Long\nRequired: No\nPre\ufb01x\nPre\ufb01x identifying one or more objects to which the rule applies.\nImportant\nWhen you're using XML requests, you must replace special characters (such as carriage \nreturns) in object keys with their equivalent XML entity codes. For more information, see\nXML-related object key constraints in the Amazon S3 User Guide .\nType: String\nAmazon S3 Control API Version 2006-03-01 1467Amazon Simple Storage Service API Reference\nRequired: No\nTag\nA container for a key-value name pair.\nType: S3Tag data type\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1468Amazon Simple Storage Service API Reference\nListAccessGrantEntry\nService: Amazon S3 Control\nInformation about the access grant.\nContents\nAccessGrantArn\nThe Amazon Resource Name (ARN) of the access grant.\nType: String\nLength Constraints: Minimum length of 1.", "Maximum length of 2048.\nPattern: arn:[a-z\\-]+:s3:[a-z0-9\\-]+:\\d{12}:access\\-grants\\/grant/[a-zA-\nZ0-9\\-]+\nRequired: No\nAccessGrantId\nThe ID of the access grant. S3 Access Grants auto-generates this ID when you create the access \ngrant.\nType: String\nLength Constraints: Minimum length of 1.", "Maximum length of 64.\nPattern: [a-zA-Z0-9\\-]+\nRequired: No\nAccessGrantsLocationCon\ufb01guration\nThe con\ufb01guration options of the grant location.", "The grant location is the S3 path to the data to \nwhich you are granting access.\nType: AccessGrantsLocationCon\ufb01guration data type\nRequired: No\nAmazon S3 Control API Version 2006-03-01 1469Amazon Simple Storage Service API Reference\nAccessGrantsLocationId\nThe ID of the registered location to which you are granting access. S3 Access Grants assigns \nthis ID when you register the location. S3 Access Grants assigns the ID default  to the default \nlocation s3:// and assigns an auto-generated ID to other locations that you register.\nType: String\nLength Constraints: Minimum length of 1.", "Maximum length of 64.\nPattern: [a-zA-Z0-9\\-]+\nRequired: No\nApplicationArn\nThe Amazon Resource Name (ARN) of an AWS IAM Identity Center application associated with \nyour Identity Center instance.", "If the grant includes an application ARN, the grantee can only \naccess the S3 data through this application.\nType: String\nLength Constraints: Minimum length of 10. Maximum length of 1224.\nPattern: arn:[^:]+:sso::\\d{12}:application/.*$\nRequired: No\nCreatedAt\nThe date and time when you created the S3 Access Grants instance.\nType: Timestamp\nRequired: No\nGrantee\nThe user, group, or role to which you are granting access.", "You can grant access to an IAM user \nor role.", "If you have added your corporate directory to AWS IAM Identity Center and associated \nyour Identity Center instance with your S3 Access Grants instance, the grantee can also be a \ncorporate directory user or group.\nType: Grantee  data type\nAmazon S3 Control API Version 2006-03-01 1470Amazon Simple Storage Service API Reference\nRequired: No\nGrantScope\nThe S3 path of the data to which you are granting access.", "It is the result of appending the\nSubprefix  to the location scope.\nType: String\nLength Constraints: Minimum length of 1.", "Maximum length of 2000.\nPattern: ^.+$\nRequired: No\nPermission\nThe type of access granted to your S3 data, which can be set to one of the following values:\n\u2022READ \u2013 Grant read-only access to the S3 data.\n\u2022WRITE \u2013 Grant write-only access to the S3 data.\n\u2022READWRITE  \u2013 Grant both read and write access to the S3 data.\nType: String\nValid Values: READ | WRITE | READWRITE\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1471Amazon Simple Storage Service API Reference\nListAccessGrantsInstanceEntry\nService: Amazon S3 Control\nInformation about the S3 Access Grants instance.\nContents\nAccessGrantsInstanceArn\nThe Amazon Resource Name (ARN) of the S3 Access Grants instance.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 2048.\nPattern: arn:[a-z\\-]+:s3:[a-z0-9\\-]+:\\d{12}:access\\-grants\\/[a-zA-Z0-9\\-]+\nRequired: No\nAccessGrantsInstanceId\nThe ID of the S3 Access Grants instance.", "The ID is default.", "You can have one S3 Access Grants \ninstance per Region per account.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 64.\nPattern: [a-zA-Z0-9\\-]+\nRequired: No\nCreatedAt\nThe date and time when you created the S3 Access Grants instance.\nType: Timestamp\nRequired: No\nIdentityCenterApplicationArn\nIf you associated your S3 Access Grants instance with an AWS IAM Identity Center instance, this \n\ufb01eld returns the Amazon Resource Name (ARN) of the IAM Identity Center instance application; \na subresource of the original Identity Center instance. S3 Access Grants creates this Identity \nCenter application for the speci\ufb01c S3 Access Grants instance.\nAmazon S3 Control API Version 2006-03-01 1472Amazon Simple Storage Service API Reference\nType: String\nLength Constraints: Minimum length of 10. Maximum length of 1224.\nPattern: arn:[^:]+:sso::\\d{12}:application/.*$\nRequired: No\nIdentityCenterArn\nThis member has been deprecated.\nIf you associated your S3 Access Grants instance with an AWS IAM Identity Center instance, this \n\ufb01eld returns the Amazon Resource Name (ARN) of the IAM Identity Center instance application; \na subresource of the original Identity Center instance. S3 Access Grants creates this Identity \nCenter application for the speci\ufb01c S3 Access Grants instance.\nType: String\nLength Constraints: Minimum length of 10. Maximum length of 1224.\nPattern: arn:[^:]+:sso::(\\d{12}){0,1}:instance/.*$\nRequired: No\nIdentityCenterInstanceArn\nThe Amazon Resource Name (ARN) of the AWS IAM Identity Center instance that you are \nassociating with your S3 Access Grants instance.", "An IAM Identity Center instance is your \ncorporate identity directory that you added to the IAM Identity Center.", "You can use the\nListInstances API operation to retrieve a list of your Identity Center instances and their ARNs.\nType: String\nLength Constraints: Minimum length of 10.", "Maximum length of 1224.\nPattern: arn:[^:]+:sso::(\\d{12}){0,1}:instance/.*$\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\nAmazon S3 Control API Version 2006-03-01 1473Amazon Simple Storage Service API Reference\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1474Amazon Simple Storage Service API Reference\nListAccessGrantsLocationsEntry\nService: Amazon S3 Control\nA container for information about the registered location.\nContents\nAccessGrantsLocationArn\nThe Amazon Resource Name (ARN) of the registered location.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 2048.\nPattern: arn:[a-z\\-]+:s3:[a-z0-9\\-]+:\\d{12}:access\\-grants\\/location/[a-zA-\nZ0-9\\-]+\nRequired: No\nAccessGrantsLocationId\nThe ID of the registered location to which you are granting access. S3 Access Grants assigns \nthis ID when you register the location. S3 Access Grants assigns the ID default  to the default \nlocation s3:// and assigns an auto-generated ID to other locations that you register.\nType: String\nLength Constraints: Minimum length of 1.", "Maximum length of 64.\nPattern: [a-zA-Z0-9\\-]+\nRequired: No\nCreatedAt\nThe date and time when you registered the location.\nType: Timestamp\nRequired: No\nIAMRoleArn\nThe Amazon Resource Name (ARN) of the IAM role for the registered location.", "S3 Access Grants \nassumes this role to manage access to the registered location.\nAmazon S3 Control API Version 2006-03-01 1475Amazon Simple Storage Service API Reference\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 2048.\nPattern: arn:[^:]+:iam::\\d{12}:role/.*\nRequired: No\nLocationScope\nThe S3 path to the location that you are registering.", "The location scope can be the default S3 \nlocation s3://, the S3 path to a bucket s3://<bucket> , or the S3 path to a bucket and pre\ufb01x\ns3://<bucket>/<prefix> . A pre\ufb01x in S3 is a string of characters at the beginning of an \nobject key name used to organize the objects that you store in your S3 buckets.", "For example, \nobject key names that start with the engineering/  pre\ufb01x or object key names that start with \nthe marketing/campaigns/  pre\ufb01x.\nType: String\nLength Constraints: Minimum length of 1.", "Maximum length of 2000.\nPattern: ^.+$\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1476Amazon Simple Storage Service API Reference\nListCallerAccessGrantsEntry\nService: Amazon S3 Control\nPart of ListCallerAccessGrantsResult .", "Each entry includes the permission level (READ, \nWRITE, or READWRITE) and the grant scope of the access grant.", "If the grant also includes an \napplication ARN, the grantee can only access the S3 data through this application.\nContents\nApplicationArn\nThe Amazon Resource Name (ARN) of an AWS IAM Identity Center application associated with \nyour Identity Center instance. If the grant includes an application ARN, the grantee can only \naccess the S3 data through this application.\nType: String\nLength Constraints: Minimum length of 10. Maximum length of 1224.\nPattern: arn:[^:]+:sso::\\d{12}:application/.*$\nRequired: No\nGrantScope\nThe S3 path of the data to which you have been granted access.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 2000.\nPattern: ^.+$\nRequired: No\nPermission\nThe type of permission granted, which can be one of the following values:\n\u2022READ - Grants read-only access to the S3 data.\n\u2022WRITE - Grants write-only access to the S3 data.\n\u2022READWRITE  - Grants both read and write access to the S3 data.\nType: String\nAmazon S3 Control API Version 2006-03-01 1477Amazon Simple Storage Service API Reference\nValid Values: READ | WRITE | READWRITE\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1478Amazon Simple Storage Service API Reference\nListStorageLensCon\ufb01gurationEntry\nService: Amazon S3 Control\nPart of ListStorageLensConfigurationResult . Each entry includes the description of the \nS3 Storage Lens con\ufb01guration, its home Region, whether it is enabled, its Amazon Resource Name \n(ARN), and con\ufb01g ID.\nContents\nHomeRegion\nA container for the S3 Storage Lens home Region. Your metrics data is stored and retained in \nyour designated S3 Storage Lens home Region.\nType: String\nLength Constraints: Minimum length of 5. Maximum length of 30.\nPattern: [a-z0-9\\-]+\nRequired: Yes\nId\nA container for the S3 Storage Lens con\ufb01guration ID.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 64.\nPattern: [a-zA-Z0-9\\-\\_\\.]+\nRequired: Yes\nStorageLensArn\nThe ARN of the S3 Storage Lens con\ufb01guration.", "This property is read-only.\nType: String\nLength Constraints: Minimum length of 1.", "Maximum length of 1024.\nPattern: arn:[a-z\\-]+:s3:[a-z0-9\\-]+:\\d{12}:storage\\-lens\\/.*\nRequired: Yes\nAmazon S3 Control API Version 2006-03-01 1479Amazon Simple Storage Service API Reference\nIsEnabled\nA container for whether the S3 Storage Lens con\ufb01guration is enabled. This property is required.\nType: Boolean\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1480Amazon Simple Storage Service API Reference\nListStorageLensGroupEntry\nService: Amazon S3 Control\nEach entry contains a Storage Lens group that exists in the speci\ufb01ed home Region.\nContents\nHomeRegion\nContains the AWS Region where the Storage Lens group was created.\nType: String\nLength Constraints: Minimum length of 5.", "Maximum length of 30.\nPattern: [a-z0-9\\-]+\nRequired: Yes\nName\nContains the name of the Storage Lens group that exists in the speci\ufb01ed home Region.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 64.\nPattern: [a-zA-Z0-9\\-\\_]+\nRequired: Yes\nStorageLensGroupArn\nContains the Amazon Resource Name (ARN) of the Storage Lens group.", "This property is read-\nonly.\nType: String\nLength Constraints: Minimum length of 4.", "Maximum length of 1024.\nPattern: arn:[a-z\\-]+:s3:[a-z0-9\\-]+:\\d{12}:storage\\-lens\\-group\\/.*\nRequired: Yes\nAmazon S3 Control API Version 2006-03-01 1481Amazon Simple Storage Service API Reference\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1482Amazon Simple Storage Service API Reference\nMatchObjectAge\nService: Amazon S3 Control\nA \ufb01lter condition that speci\ufb01es the object age range of included objects in days.", "Only integers are \nsupported.\nContents\nDaysGreaterThan\nSpeci\ufb01es the maximum object age in days. Must be a positive whole number, greater than the \nminimum object age and less than or equal to 2,147,483,647.\nType: Integer\nRequired: No\nDaysLessThan\nSpeci\ufb01es the minimum object age in days.", "The value must be a positive whole number, greater \nthan 0 and less than or equal to 2,147,483,647.\nType: Integer\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1483Amazon Simple Storage Service API Reference\nMatchObjectSize\nService: Amazon S3 Control\nA \ufb01lter condition that speci\ufb01es the object size range of included objects in bytes.", "Only integers are \nsupported.\nContents\nBytesGreaterThan\nSpeci\ufb01es the minimum object size in Bytes. The value must be a positive number, greater than 0 \nand less than 5 TB.\nType: Long\nRequired: No\nBytesLessThan\nSpeci\ufb01es the maximum object size in Bytes.", "The value must be a positive number, greater than \nthe minimum object size and less than 5 TB.\nType: Long\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1484Amazon Simple Storage Service API Reference\nMetrics\nService: Amazon S3 Control\nA container that speci\ufb01es replication metrics-related settings.\nContents\nStatus\nSpeci\ufb01es whether replication metrics are enabled.\nType: String\nValid Values: Enabled | Disabled\nRequired: Yes\nEventThreshold\nA container that speci\ufb01es the time threshold for emitting the\ns3:Replication:OperationMissedThreshold  event.\nNote\nThis is not supported by Amazon S3 on Outposts buckets.\nType: ReplicationTimeValue data type\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1485Amazon Simple Storage Service API Reference\nMultiRegionAccessPointPolicyDocument\nService: Amazon S3 Control\nThe Multi-Region Access Point access control policy.\nWhen you update the policy, the update is \ufb01rst listed as the proposed policy.", "After the update is \n\ufb01nished and all Regions have been updated, the proposed policy is listed as the established policy.", "\nIf both policies have the same version number, the proposed policy is the established policy.\nContents\nEstablished\nThe last established policy for the Multi-Region Access Point.\nType: EstablishedMultiRegionAccessPointPolicy data type\nRequired: No\nProposed\nThe proposed policy for the Multi-Region Access Point.\nType: ProposedMultiRegionAccessPointPolicy data type\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1486Amazon Simple Storage Service API Reference\nMultiRegionAccessPointRegionalResponse\nService: Amazon S3 Control\nStatus information for a single Multi-Region Access Point Region.\nContents\nName\nThe name of the Region in the Multi-Region Access Point.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 64.\nRequired: No\nRequestStatus\nThe current status of the Multi-Region Access Point in this Region.\nType: String\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1487Amazon Simple Storage Service API Reference\nMultiRegionAccessPointReport\nService: Amazon S3 Control\nA collection of statuses for a Multi-Region Access Point in the various Regions it supports.\nContents\nAlias\nThe alias for the Multi-Region Access Point. For more information about the distinction between \nthe name and the alias of an Multi-Region Access Point, see Rules for naming Amazon S3 Multi-\nRegion Access Points.\nType: String\nLength Constraints: Maximum length of 63.\nPattern: ^[a-z][a-z0-9]*[.]mrap$\nRequired: No\nCreatedAt\nWhen the Multi-Region Access Point create request was received.\nType: Timestamp\nRequired: No\nName\nThe name of the Multi-Region Access Point.\nType: String\nLength Constraints: Maximum length of 50.\nPattern: ^[a-z0-9][-a-z0-9]{1,48}[a-z0-9]$\nRequired: No\nPublicAccessBlock\nThe PublicAccessBlock  con\ufb01guration that you want to apply to this Amazon S3 account.", "\nYou can enable the con\ufb01guration options in any combination.", "For more information about when \nAmazon S3 Control API Version 2006-03-01 1488Amazon Simple Storage Service API Reference\nAmazon S3 considers a bucket or object public, see The Meaning of \"Public\" in the Amazon S3 \nUser Guide .\nThis data type is not supported for Amazon S3 on Outposts.\nType: PublicAccessBlockCon\ufb01guration data type\nRequired: No\nRegions\nA collection of the Regions and buckets associated with the Multi-Region Access Point.\nType: Array of RegionReport data types\nRequired: No\nStatus\nThe current status of the Multi-Region Access Point.\nCREATING  and DELETING  are temporary states that exist while the request is propagating and \nbeing completed.", "If a Multi-Region Access Point has a status of PARTIALLY_CREATED , you \ncan retry creation or send a request to delete the Multi-Region Access Point. If a Multi-Region \nAccess Point has a status of PARTIALLY_DELETED , you can retry a delete request to \ufb01nish the \ndeletion of the Multi-Region Access Point.\nType: String\nValid Values: READY | INCONSISTENT_ACROSS_REGIONS | CREATING | \nPARTIALLY_CREATED | PARTIALLY_DELETED | DELETING\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1489Amazon Simple Storage Service API Reference\nAmazon S3 Control API Version 2006-03-01 1490Amazon Simple Storage Service API Reference\nMultiRegionAccessPointRoute\nService: Amazon S3 Control\nA structure for a Multi-Region Access Point that indicates where Amazon S3 tra\ufb03c can be routed.", "\nRoutes can be either active or passive.", "Active routes can process Amazon S3 requests through the \nMulti-Region Access Point, but passive routes are not eligible to process Amazon S3 requests.\nEach route contains the Amazon S3 bucket name and the AWS Region that the bucket is located \nin.", "The route also includes the TrafficDialPercentage  value, which shows whether the bucket \nand Region are active (indicated by a value of 100) or passive (indicated by a value of 0).\nContents\nTra\ufb03cDialPercentage\nThe tra\ufb03c state for the speci\ufb01ed bucket or AWS Region.\nA value of 0 indicates a passive state, which means that no new tra\ufb03c will be routed to the \nRegion.\nA value of 100 indicates an active state, which means that tra\ufb03c will be routed to the speci\ufb01ed \nRegion.\nWhen the routing con\ufb01guration for a Region is changed from active to passive, any in-progress \noperations (uploads, copies, deletes, and so on) to the formerly active Region will continue to \nrun to until a \ufb01nal success or failure status is reached.\nIf all Regions in the routing con\ufb01guration are designated as passive, you'll receive an\nInvalidRequest  error.\nType: Integer\nValid Range: Minimum value of 0.", "Maximum value of 100.\nRequired: Yes\nBucket\nThe name of the Amazon S3 bucket for which you'll submit a routing con\ufb01guration change.", "\nEither the Bucket  or the Region value must be provided.", "If both are provided, the bucket must \nbe in the speci\ufb01ed Region.\nType: String\nAmazon S3 Control API Version 2006-03-01 1491Amazon Simple Storage Service API Reference\nLength Constraints: Minimum length of 3.", "Maximum length of 255.\nRequired: No\nRegion\nThe AWS Region to which you'll be submitting a routing con\ufb01guration change.", "Either the\nBucket  or the Region value must be provided. If both are provided, the bucket must be in the \nspeci\ufb01ed Region.\nType: String\nLength Constraints: Minimum length of 1.", "Maximum length of 64.\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1492Amazon Simple Storage Service API Reference\nMultiRegionAccessPointsAsyncResponse\nService: Amazon S3 Control\nThe Multi-Region Access Point details that are returned when querying about an asynchronous \nrequest.\nContents\nRegions\nA collection of status information for the di\ufb00erent Regions that a Multi-Region Access Point \nsupports.\nType: Array of MultiRegionAccessPointRegionalResponse data types\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1493Amazon Simple Storage Service API Reference\nNoncurrentVersionExpiration\nService: Amazon S3 Control\nThe container of the noncurrent version expiration.\nContents\nNewerNoncurrentVersions\nSpeci\ufb01es how many noncurrent versions S3 on Outposts will retain.", "If there are this many \nmore recent noncurrent versions, S3 on Outposts will take the associated action. For more \ninformation about noncurrent versions, see Lifecycle con\ufb01guration elements in the Amazon S3 \nUser Guide .\nType: Integer\nRequired: No\nNoncurrentDays\nSpeci\ufb01es the number of days an object is noncurrent before Amazon S3 can perform the \nassociated action. For information about the noncurrent days calculations, see How Amazon S3 \nCalculates When an Object Became Noncurrent in the Amazon S3 User Guide .\nType: Integer\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1494Amazon Simple Storage Service API Reference\nNoncurrentVersionTransition\nService: Amazon S3 Control\nThe container for the noncurrent version transition.\nContents\nNoncurrentDays\nSpeci\ufb01es the number of days an object is noncurrent before Amazon S3 can perform the \nassociated action. For information about the noncurrent days calculations, see  How Amazon S3 \nCalculates How Long an Object Has Been Noncurrent in the Amazon S3 User Guide .\nType: Integer\nRequired: No\nStorageClass\nThe class of storage used to store the object.\nType: String\nValid Values: GLACIER | STANDARD_IA | ONEZONE_IA | INTELLIGENT_TIERING | \nDEEP_ARCHIVE\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1495Amazon Simple Storage Service API Reference\nObjectLambdaAccessPoint\nService: Amazon S3 Control\nAn access point with an attached AWS Lambda function used to access transformed data from an \nAmazon S3 bucket.\nContents\nName\nThe name of the Object Lambda Access Point.\nType: String\nLength Constraints: Minimum length of 3.", "Maximum length of 45.\nPattern: ^[a-z0-9]([a-z0-9\\-]*[a-z0-9])?$\nRequired: Yes\nAlias\nThe alias of the Object Lambda Access Point.\nType: ObjectLambdaAccessPointAlias data type\nRequired: No\nObjectLambdaAccessPointArn\nSpeci\ufb01es the ARN for the Object Lambda Access Point.\nType: String\nLength Constraints: Minimum length of 1.", "Maximum length of 2048.\nPattern: arn:[^:]+:s3-object-lambda:[^:]*:\\d{12}:accesspoint/.*\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\nAmazon S3 Control API Version 2006-03-01 1496Amazon Simple Storage Service API Reference\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1497Amazon Simple Storage Service API Reference\nObjectLambdaAccessPointAlias\nService: Amazon S3 Control\nThe alias of an Object Lambda Access Point. For more information, see How to use a bucket-style \nalias for your S3 bucket Object Lambda Access Point.\nContents\nStatus\nThe status of the Object Lambda Access Point alias.", "If the status is PROVISIONING , the Object \nLambda Access Point is provisioning the alias and the alias is not ready for use yet. If the status \nis READY, the Object Lambda Access Point alias is successfully provisioned and ready for use.\nType: String\nLength Constraints: Minimum length of 2. Maximum length of 16.\nValid Values: PROVISIONING | READY\nRequired: No\nValue\nThe alias value of the Object Lambda Access Point.\nType: String\nLength Constraints: Minimum length of 3.", "Maximum length of 63.\nPattern: ^[0-9a-z\\\\-]{3,63}\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1498Amazon Simple Storage Service API Reference\nAmazon S3 Control API Version 2006-03-01 1499Amazon Simple Storage Service API Reference\nObjectLambdaCon\ufb01guration\nService: Amazon S3 Control\nA con\ufb01guration used when creating an Object Lambda Access Point.\nContents\nSupportingAccessPoint\nStandard access point associated with the Object Lambda Access Point.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 2048.\nPattern: arn:[^:]+:s3:[^:]*:\\d{12}:accesspoint/.*\nRequired: Yes\nTransformationCon\ufb01gurations\nA container for transformation con\ufb01gurations for an Object Lambda Access Point.\nType: Array of ObjectLambdaTransformationCon\ufb01guration data types\nRequired: Yes\nAllowedFeatures\nA container for allowed features. Valid inputs are GetObject-Range , GetObject-\nPartNumber , HeadObject-Range , and HeadObject-PartNumber .\nType: Array of strings\nValid Values: GetObject-Range | GetObject-PartNumber | HeadObject-Range | \nHeadObject-PartNumber\nRequired: No\nCloudWatchMetricsEnabled\nA container for whether the CloudWatch metrics con\ufb01guration is enabled.\nType: Boolean\nAmazon S3 Control API Version 2006-03-01 1500Amazon Simple Storage Service API Reference\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1501Amazon Simple Storage Service API Reference\nObjectLambdaContentTransformation\nService: Amazon S3 Control\nA container for AwsLambdaTransformation.\nContents\nImportant\nThis data type is a UNION, so only one of the following members can be speci\ufb01ed when \nused or returned.\nAwsLambda\nA container for an AWS Lambda function.\nType: AwsLambdaTransformation data type\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1502Amazon Simple Storage Service API Reference\nObjectLambdaTransformationCon\ufb01guration\nService: Amazon S3 Control\nA con\ufb01guration used when creating an Object Lambda Access Point transformation.\nContents\nActions\nA container for the action of an Object Lambda Access Point con\ufb01guration.", "Valid inputs are\nGetObject , ListObjects , HeadObject , and ListObjectsV2 .\nType: Array of strings\nValid Values: GetObject | HeadObject | ListObjects | ListObjectsV2\nRequired: Yes\nContentTransformation\nA container for the content transformation of an Object Lambda Access Point con\ufb01guration.\nType: ObjectLambdaContentTransformation data type\nNote: This object is a Union.", "Only one member of this object can be speci\ufb01ed or returned.\nRequired: Yes\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1503Amazon Simple Storage Service API Reference\nPolicyStatus\nService: Amazon S3 Control\nIndicates whether this access point policy is public. For more information about how Amazon S3 \nevaluates policies to determine whether they are public, see The Meaning of \"Public\" in the Amazon \nS3 User Guide .\nContents\nIsPublic\nType: Boolean\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1504Amazon Simple Storage Service API Reference\nPre\ufb01xLevel\nService: Amazon S3 Control\nA container for the pre\ufb01x-level con\ufb01guration.\nContents\nStorageMetrics\nA container for the pre\ufb01x-level storage metrics for S3 Storage Lens.\nType: Pre\ufb01xLevelStorageMetrics data type\nRequired: Yes\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1505Amazon Simple Storage Service API Reference\nPre\ufb01xLevelStorageMetrics\nService: Amazon S3 Control\nA container for the pre\ufb01x-level storage metrics for S3 Storage Lens.\nContents\nIsEnabled\nA container for whether pre\ufb01x-level storage metrics are enabled.\nType: Boolean\nRequired: No\nSelectionCriteria\nType: SelectionCriteria data type\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1506Amazon Simple Storage Service API Reference\nProposedMultiRegionAccessPointPolicy\nService: Amazon S3 Control\nThe proposed access control policy for the Multi-Region Access Point.\nWhen you update the policy, the update is \ufb01rst listed as the proposed policy.", "After the update is \n\ufb01nished and all Regions have been updated, the proposed policy is listed as the established policy.", "\nIf both policies have the same version number, the proposed policy is the established policy.\nContents\nPolicy\nThe details of the proposed policy.\nType: String\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1507Amazon Simple Storage Service API Reference\nPublicAccessBlockCon\ufb01guration\nService: Amazon S3 Control\nThe PublicAccessBlock  con\ufb01guration that you want to apply to this Amazon S3 account.", "\nYou can enable the con\ufb01guration options in any combination.", "For more information about when \nAmazon S3 considers a bucket or object public, see The Meaning of \"Public\" in the Amazon S3 User \nGuide .\nThis data type is not supported for Amazon S3 on Outposts.\nContents\nBlockPublicAcls\nSpeci\ufb01es whether Amazon S3 should block public access control lists (ACLs) for buckets in this \naccount. Setting this element to TRUE causes the following behavior:\n\u2022PutBucketAcl  and PutObjectAcl  calls fail if the speci\ufb01ed ACL is public.\n\u2022PUT Object calls fail if the request includes a public ACL.\n\u2022PUT Bucket calls fail if the request includes a public ACL.\nEnabling this setting doesn't a\ufb00ect existing policies or ACLs.\nThis property is not supported for Amazon S3 on Outposts.\nType: Boolean\nRequired: No\nBlockPublicPolicy\nSpeci\ufb01es whether Amazon S3 should block public bucket policies for buckets in this account. \nSetting this element to TRUE causes Amazon S3 to reject calls to PUT Bucket policy if the \nspeci\ufb01ed bucket policy allows public access.\nEnabling this setting doesn't a\ufb00ect existing bucket policies.\nThis property is not supported for Amazon S3 on Outposts.\nType: Boolean\nRequired: No\nAmazon S3 Control API Version 2006-03-01 1508Amazon Simple Storage Service API Reference\nIgnorePublicAcls\nSpeci\ufb01es whether Amazon S3 should ignore public ACLs for buckets in this account. Setting this \nelement to TRUE causes Amazon S3 to ignore all public ACLs on buckets in this account and any \nobjects that they contain.\nEnabling this setting doesn't a\ufb00ect the persistence of any existing ACLs and doesn't prevent \nnew public ACLs from being set.\nThis property is not supported for Amazon S3 on Outposts.\nType: Boolean\nRequired: No\nRestrictPublicBuckets\nSpeci\ufb01es whether Amazon S3 should restrict public bucket policies for buckets in this account. \nSetting this element to TRUE restricts access to buckets with public policies to only AWS service \nprincipals and authorized users within this account.\nEnabling this setting doesn't a\ufb00ect previously stored bucket policies, except that public and \ncross-account access within any public bucket policy, including non-public delegation to speci\ufb01c \naccounts, is blocked.\nThis property is not supported for Amazon S3 on Outposts.\nType: Boolean\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1509Amazon Simple Storage Service API Reference\nPutMultiRegionAccessPointPolicyInput\nService: Amazon S3 Control\nA container for the information associated with a PutMultiRegionAccessPoint request.\nContents\nName\nThe name of the Multi-Region Access Point associated with the request.\nType: String\nLength Constraints: Maximum length of 50.\nPattern: ^[a-z0-9][-a-z0-9]{1,48}[a-z0-9]$\nRequired: Yes\nPolicy\nThe policy details for the PutMultiRegionAccessPoint  request.\nType: String\nRequired: Yes\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1510Amazon Simple Storage Service API Reference\nRegion\nService: Amazon S3 Control\nA Region that supports a Multi-Region Access Point as well as the associated bucket for the Region.\nContents\nBucket\nThe name of the associated bucket for the Region.\nType: String\nLength Constraints: Minimum length of 3. Maximum length of 255.\nRequired: Yes\nBucketAccountId\nThe AWS account ID that owns the Amazon S3 bucket that's associated with this Multi-Region \nAccess Point.\nType: String\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1511Amazon Simple Storage Service API Reference\nRegionalBucket\nService: Amazon S3 Control\nThe container for the regional bucket.\nContents\nBucket\nType: String\nLength Constraints: Minimum length of 3. Maximum length of 255.\nRequired: Yes\nCreationDate\nThe creation date of the regional bucket\nType: Timestamp\nRequired: Yes\nPublicAccessBlockEnabled\nType: Boolean\nRequired: Yes\nBucketArn\nThe Amazon Resource Name (ARN) for the regional bucket.\nType: String\nLength Constraints: Minimum length of 4.", "Maximum length of 128.\nRequired: No\nOutpostId\nThe AWS Outposts ID of the regional bucket.\nType: String\nAmazon S3 Control API Version 2006-03-01 1512Amazon Simple Storage Service API Reference\nLength Constraints: Minimum length of 1. Maximum length of 64.\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1513Amazon Simple Storage Service API Reference\nRegionReport\nService: Amazon S3 Control\nA combination of a bucket and Region that's part of a Multi-Region Access Point.\nContents\nBucket\nThe name of the bucket.\nType: String\nLength Constraints: Minimum length of 3. Maximum length of 255.\nRequired: No\nBucketAccountId\nThe AWS account ID that owns the Amazon S3 bucket that's associated with this Multi-Region \nAccess Point.\nType: String\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: No\nRegion\nThe name of the Region.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 64.\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\nAmazon S3 Control API Version 2006-03-01 1514Amazon Simple Storage Service API Reference\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1515Amazon Simple Storage Service API Reference\nReplicaModi\ufb01cations\nService: Amazon S3 Control\nA \ufb01lter that you can use to specify whether replica modi\ufb01cation sync is enabled. S3 on Outposts \nreplica modi\ufb01cation sync can help you keep object metadata synchronized between replicas and \nsource objects. By default, S3 on Outposts replicates metadata from the source objects to the \nreplicas only. When replica modi\ufb01cation sync is enabled, S3 on Outposts replicates metadata \nchanges made to the replica copies back to the source object, making the replication bidirectional.\nTo replicate object metadata modi\ufb01cations on replicas, you can specify this element and set the\nStatus  of this element to Enabled .\nNote\nYou must enable replica modi\ufb01cation sync on the source and destination buckets to \nreplicate replica metadata changes between the source and the replicas.\nContents\nStatus\nSpeci\ufb01es whether S3 on Outposts replicates modi\ufb01cations to object metadata on replicas.\nType: String\nValid Values: Enabled | Disabled\nRequired: Yes\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1516Amazon Simple Storage Service API Reference\nReplicationCon\ufb01guration\nService: Amazon S3 Control\nA container for one or more replication rules.", "A replication con\ufb01guration must have at least one \nrule and you can add up to 100 rules.", "The maximum size of a replication con\ufb01guration is 128 KB.\nContents\nRole\nThe Amazon Resource Name (ARN) of the AWS Identity and Access Management (IAM) role \nthat S3 on Outposts assumes when replicating objects. For information about S3 replication on \nOutposts con\ufb01guration, see Setting up replication in the Amazon S3 User Guide .\nType: String\nRequired: Yes\nRules\nA container for one or more replication rules. A replication con\ufb01guration must have at least one \nrule and can contain an array of 100 rules at the most.\nType: Array of ReplicationRule data types\nRequired: Yes\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1517Amazon Simple Storage Service API Reference\nReplicationRule\nService: Amazon S3 Control\nSpeci\ufb01es which S3 on Outposts objects to replicate and where to store the replicas.\nContents\nBucket\nThe Amazon Resource Name (ARN) of the access point for the source Outposts bucket that you \nwant S3 on Outposts to replicate the objects from.\nType: String\nRequired: Yes\nDestination\nA container for information about the replication destination and its con\ufb01gurations.\nType: Destination  data type\nRequired: Yes\nStatus\nSpeci\ufb01es whether the rule is enabled.\nType: String\nValid Values: Enabled | Disabled\nRequired: Yes\nDeleteMarkerReplication\nSpeci\ufb01es whether S3 on Outposts replicates delete markers.", "If you specify a Filter  element in \nyour replication con\ufb01guration, you must also include a DeleteMarkerReplication  element.", "\nIf your Filter  includes a Tag element, the DeleteMarkerReplication  element's Status\nchild element must be set to Disabled , because S3 on Outposts doesn't support replicating \ndelete markers for tag-based rules.\nFor more information about delete marker replication, see How delete operations a\ufb00ect \nreplication in the Amazon S3 User Guide .\nType: DeleteMarkerReplication data type\nAmazon S3 Control API Version 2006-03-01 1518Amazon Simple Storage Service API Reference\nRequired: No\nExistingObjectReplication\nAn optional con\ufb01guration to replicate existing source bucket objects.\nNote\nThis is not supported by Amazon S3 on Outposts buckets.\nType: ExistingObjectReplication data type\nRequired: No\nFilter\nA \ufb01lter that identi\ufb01es the subset of objects to which the replication rule applies.", "A Filter\nelement must specify exactly one Prefix , Tag, or And child element.\nType: ReplicationRuleFilter data type\nRequired: No\nID\nA unique identi\ufb01er for the rule.", "The maximum value is 255 characters.\nType: String\nRequired: No\nPre\ufb01x\nThis member has been deprecated.\nAn object key name pre\ufb01x that identi\ufb01es the object or objects to which the rule applies. The \nmaximum pre\ufb01x length is 1,024 characters.", "To include all objects in an Outposts bucket, specify \nan empty string.\nImportant\nWhen you're using XML requests, you must replace special characters (such as carriage \nreturns) in object keys with their equivalent XML entity codes.", "For more information, see\nXML-related object key constraints in the Amazon S3 User Guide .\nAmazon S3 Control API Version 2006-03-01 1519Amazon Simple Storage Service API Reference\nType: String\nRequired: No\nPriority\nThe priority indicates which rule has precedence whenever two or more replication rules \ncon\ufb02ict.", "S3 on Outposts attempts to replicate objects according to all replication rules.", "\nHowever, if there are two or more rules with the same destination Outposts bucket, then \nobjects will be replicated according to the rule with the highest priority.", "The higher the number, \nthe higher the priority.\nFor more information, see Creating replication rules on Outposts in the Amazon S3 User Guide .\nType: Integer\nRequired: No\nSourceSelectionCriteria\nA container that describes additional \ufb01lters for identifying the source Outposts objects that you \nwant to replicate. You can choose to enable or disable the replication of these objects.\nType: SourceSelectionCriteria data type\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1520Amazon Simple Storage Service API Reference\nReplicationRuleAndOperator\nService: Amazon S3 Control\nA container for specifying rule \ufb01lters.", "The \ufb01lters determine the subset of objects to which the rule \napplies.", "This element is required only if you specify more than one \ufb01lter.\nFor example:\n\u2022If you specify both a Prefix  and a Tag \ufb01lter, wrap these \ufb01lters in an And element.\n\u2022If you specify a \ufb01lter based on multiple tags, wrap the Tag elements in an And element.\nContents\nPre\ufb01x\nAn object key name pre\ufb01x that identi\ufb01es the subset of objects that the rule applies to.\nType: String\nRequired: No\nTags\nAn array of tags that contain key and value pairs.\nType: Array of S3Tag data types\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1521Amazon Simple Storage Service API Reference\nReplicationRuleFilter\nService: Amazon S3 Control\nA \ufb01lter that identi\ufb01es the subset of objects to which the replication rule applies.", "A Filter  element \nmust specify exactly one Prefix , Tag, or And child element.\nContents\nAnd\nA container for specifying rule \ufb01lters. The \ufb01lters determine the subset of objects that the rule \napplies to. This element is required only if you specify more than one \ufb01lter. For example:\n\u2022If you specify both a Prefix  and a Tag \ufb01lter, wrap these \ufb01lters in an And element.\n\u2022If you specify a \ufb01lter based on multiple tags, wrap the Tag elements in an And element.\nType: ReplicationRuleAndOperator data type\nRequired: No\nPre\ufb01x\nAn object key name pre\ufb01x that identi\ufb01es the subset of objects that the rule applies to.\nImportant\nWhen you're using XML requests, you must replace special characters (such as carriage \nreturns) in object keys with their equivalent XML entity codes.", "For more information, see\nXML-related object key constraints in the Amazon S3 User Guide .\nType: String\nRequired: No\nTag\nA container for a key-value name pair.\nType: S3Tag data type\nRequired: No\nAmazon S3 Control API Version 2006-03-01 1522Amazon Simple Storage Service API Reference\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1523Amazon Simple Storage Service API Reference\nReplicationTime\nService: Amazon S3 Control\nA container that speci\ufb01es S3 Replication Time Control (S3 RTC) related information, including \nwhether S3 RTC is enabled and the time when all objects and operations on objects must be \nreplicated.\nNote\nThis is not supported by Amazon S3 on Outposts buckets.\nContents\nStatus\nSpeci\ufb01es whether S3 Replication Time Control (S3 RTC) is enabled.\nType: String\nValid Values: Enabled | Disabled\nRequired: Yes\nTime\nA container that speci\ufb01es the time by which replication should be complete for all objects and \noperations on objects.\nType: ReplicationTimeValue data type\nRequired: Yes\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1524Amazon Simple Storage Service API Reference\nAmazon S3 Control API Version 2006-03-01 1525Amazon Simple Storage Service API Reference\nReplicationTimeValue\nService: Amazon S3 Control\nA container that speci\ufb01es the time value for S3 Replication Time Control (S3 RTC). This value is also \nused for the replication metrics EventThreshold  element.\nNote\nThis is not supported by Amazon S3 on Outposts buckets.\nContents\nMinutes\nContains an integer that speci\ufb01es the time period in minutes.\nValid value: 15\nType: Integer\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1526Amazon Simple Storage Service API Reference\nS3AccessControlList\nService: Amazon S3 Control\nContents\nOwner\nType: S3ObjectOwner data type\nRequired: Yes\nGrants\nType: Array of S3Grant  data types\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1527Amazon Simple Storage Service API Reference\nS3AccessControlPolicy\nService: Amazon S3 Control\nContents\nAccessControlList\nType: S3AccessControlList data type\nRequired: No\nCannedAccessControlList\nType: String\nValid Values: private | public-read | public-read-write | aws-exec-read | \nauthenticated-read | bucket-owner-read | bucket-owner-full-control\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1528Amazon Simple Storage Service API Reference\nS3BucketDestination\nService: Amazon S3 Control\nA container for the bucket where the Amazon S3 Storage Lens metrics export \ufb01les are located.\nContents\nAccountId\nThe account ID of the owner of the S3 Storage Lens metrics export bucket.\nType: String\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nArn\nThe Amazon Resource Name (ARN) of the bucket. This property is read-only and follows the \nfollowing format:  arn:aws:s3: us-east-1 :example-account-id :bucket/ your-\ndestination-bucket-name\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 128.\nPattern: arn:[^:]+:s3:.*\nRequired: Yes\nFormat\nType: String\nValid Values: CSV | Parquet\nRequired: Yes\nOutputSchemaVersion\nThe schema version of the export \ufb01le.\nAmazon S3 Control API Version 2006-03-01 1529Amazon Simple Storage Service API Reference\nType: String\nValid Values: V_1\nRequired: Yes\nEncryption\nThe container for the type encryption of the metrics exports in this bucket.\nType: StorageLensDataExportEncryption data type\nRequired: No\nPre\ufb01x\nThe pre\ufb01x of the destination bucket where the metrics export will be delivered.\nType: String\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1530Amazon Simple Storage Service API Reference\nS3CopyObjectOperation\nService: Amazon S3 Control\nContains the con\ufb01guration parameters for a PUT Copy object operation. S3 Batch Operations \npasses every object to the underlying CopyObject  API operation. For more information about the \nparameters for this operation, see CopyObject.\nContents\nAccessControlGrants\nNote\nThis functionality is not supported by directory buckets.\nType: Array of S3Grant  data types\nRequired: No\nBucketKeyEnabled\nSpeci\ufb01es whether Amazon S3 should use an S3 Bucket Key for object encryption with server-\nside encryption using AWS KMS (SSE-KMS). Setting this header to true causes Amazon S3 to \nuse an S3 Bucket Key for object encryption with SSE-KMS.\nSpecifying this header with an Copy  action doesn\u2019t a\ufb00ect bucket-level  settings for S3 Bucket \nKey.\nNote\nDirectory buckets - S3 Bucket Keys aren't supported, when you copy SSE-KMS \nencrypted objects from general purpose buckets to directory buckets, from directory \nbuckets to general purpose buckets, or between directory buckets, through the Copy \noperation in Batch Operations . In this case, Amazon S3 makes a call to AWS KMS every \ntime a copy request is made for a KMS-encrypted object.\nType: Boolean\nAmazon S3 Control API Version 2006-03-01 1531Amazon Simple Storage Service API Reference\nRequired: No\nCannedAccessControlList\nNote\nThis functionality is not supported by directory buckets.\nType: String\nValid Values: private | public-read | public-read-write | aws-exec-read | \nauthenticated-read | bucket-owner-read | bucket-owner-full-control\nRequired: No\nChecksumAlgorithm\nIndicates the algorithm that you want Amazon S3 to use to create the checksum. For more \ninformation, see  Checking object integrity in the Amazon S3 User Guide .\nType: String\nValid Values: CRC32 | CRC32C | SHA1 | SHA256\nRequired: No\nMetadataDirective\nType: String\nValid Values: COPY | REPLACE\nRequired: No\nModi\ufb01edSinceConstraint\nType: Timestamp\nRequired: No\nAmazon S3 Control API Version 2006-03-01 1532Amazon Simple Storage Service API Reference\nNewObjectMetadata\nIf you don't provide this parameter, Amazon S3 copies all the metadata from the original \nobjects.", "If you specify an empty set, the new objects will have no tags.", "Otherwise, Amazon S3 \nassigns the supplied tags to the new objects.\nType: S3ObjectMetadata data type\nRequired: No\nNewObjectTagging\nSpeci\ufb01es a list of tags to add to the destination objects after they are copied.", "If\nNewObjectTagging  is not speci\ufb01ed, the tags of the source objects are copied to destination \nobjects by default.\nNote\nDirectory buckets - Tags aren't supported by directory buckets. If your source objects \nhave tags and your destination bucket is a directory bucket, specify an empty tag set in \nthe NewObjectTagging  \ufb01eld to prevent copying the source object tags to the directory \nbucket.\nType: Array of S3Tag data types\nRequired: No\nObjectLockLegalHoldStatus\nThe legal hold status to be applied to all objects in the Batch Operations job.\nNote\nThis functionality is not supported by directory buckets.\nType: String\nValid Values: OFF | ON\nRequired: No\nAmazon S3 Control API Version 2006-03-01 1533Amazon Simple Storage Service API Reference\nObjectLockMode\nThe retention mode to be applied to all objects in the Batch Operations job.\nNote\nThis functionality is not supported by directory buckets.\nType: String\nValid Values: COMPLIANCE | GOVERNANCE\nRequired: No\nObjectLockRetainUntilDate\nThe date when the applied object retention con\ufb01guration expires on all objects in the Batch \nOperations job.\nNote\nThis functionality is not supported by directory buckets.\nType: Timestamp\nRequired: No\nRedirectLocation\nIf the destination bucket is con\ufb01gured as a website, speci\ufb01es an optional metadata property \nfor website redirects, x-amz-website-redirect-location . Allows webpage redirects if the \nobject copy is accessed through a website endpoint.\nNote\nThis functionality is not supported by directory buckets.\nType: String\nAmazon S3 Control API Version 2006-03-01 1534Amazon Simple Storage Service API Reference\nLength Constraints: Minimum length of 1.", "Maximum length of 2048.\nRequired: No\nRequesterPays\nNote\nThis functionality is not supported by directory buckets.\nType: Boolean\nRequired: No\nSSEAwsKmsKeyId\nSpeci\ufb01es the AWS KMS key ID (Key ID, Key ARN, or Key Alias) to use for object encryption. If the \nKMS key doesn't exist in the same account that's issuing the command, you must use the full \nKey ARN not the Key ID.\nNote\nDirectory buckets - If you specify SSEAlgorithm  with KMS, you must specify the \nSSEAwsKmsKeyId  parameter with the ID (Key ID or Key ARN) of the AWS KMS \nsymmetric encryption customer managed key to use.", "Otherwise, you get an HTTP 400 \nBad Request  error.", "The key alias format of the KMS key isn't supported.", "To encrypt \nnew object copies in a directory bucket with SSE-KMS, you must specify SSE-KMS as \nthe directory bucket's default encryption con\ufb01guration with a KMS key (speci\ufb01cally, a\ncustomer managed key).", "The AWS managed key (aws/s3) isn't supported.", "Your SSE-\nKMS con\ufb01guration can only support 1 customer managed key per directory bucket for \nthe lifetime of the bucket. After you specify a customer managed key for SSE-KMS as \nthe bucket default encryption, you can't override the customer managed key for the \nbucket's SSE-KMS con\ufb01guration. Then, when you specify server-side encryption settings \nfor new object copies with SSE-KMS, you must make sure the encryption key is the same \ncustomer managed key that you speci\ufb01ed for the directory bucket's default encryption \ncon\ufb01guration.\nType: String\nAmazon S3 Control API Version 2006-03-01 1535Amazon Simple Storage Service API Reference\nLength Constraints: Minimum length of 1.", "Maximum length of 2000.\nRequired: No\nStorageClass\nSpecify the storage class for the destination objects in a Copy  operation.\nNote\nDirectory buckets  - This functionality is not supported by directory buckets.\nType: String\nValid Values: STANDARD | STANDARD_IA | ONEZONE_IA | GLACIER | \nINTELLIGENT_TIERING | DEEP_ARCHIVE | GLACIER_IR\nRequired: No\nTargetKeyPre\ufb01x\nSpeci\ufb01es the folder pre\ufb01x that you want the objects to be copied into. For example, to copy \nobjects into a folder named Folder1 in the destination bucket, set the TargetKeyPrefix\nproperty to Folder1 .\nType: String\nLength Constraints: Minimum length of 1.", "Maximum length of 1024.\nRequired: No\nTargetResource\nSpeci\ufb01es the destination bucket Amazon Resource Name (ARN) for the batch copy operation.\n\u2022General purpose buckets - For example, to copy objects to a general purpose \nbucket named destinationBucket , set the TargetResource  property to\narn:aws:s3:::destinationBucket .\n\u2022Directory buckets - For example, to copy objects to a directory bucket named\ndestinationBucket  in the Availability Zone; identi\ufb01ed by the AZ ID usw2-az1 , set \nthe TargetResource  property to arn:aws:s3express: region:account_id :/\nbucket/destination_bucket_base_name --usw2-az1 --x-s3 .\nAmazon S3 Control API Version 2006-03-01 1536Amazon Simple Storage Service API Reference\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 128.\nPattern: arn:[^:]+:(s3|s3express):.*\nRequired: No\nUnModi\ufb01edSinceConstraint\nType: Timestamp\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1537Amazon Simple Storage Service API Reference\nS3DeleteObjectTaggingOperation\nService: Amazon S3 Control\nContains no con\ufb01guration parameters because the DELETE Object tagging \n(DeleteObjectTagging ) API operation accepts only the bucket name and key name as \nparameters, which are de\ufb01ned in the job's manifest.\nContents\nThe members of this exception structure are context-dependent.\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1538Amazon Simple Storage Service API Reference\nS3GeneratedManifestDescriptor\nService: Amazon S3 Control\nDescribes the speci\ufb01ed job's generated manifest. Batch Operations jobs created with a \nManifestGenerator populate details of this descriptor after execution of the ManifestGenerator.\nContents\nFormat\nThe format of the generated manifest.\nType: String\nValid Values: S3InventoryReport_CSV_20211130\nRequired: No\nLocation\nContains the information required to locate a manifest object.", "Manifests can't be imported from \ndirectory buckets.", "For more information, see Directory buckets.\nType: JobManifestLocation  data type\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1539Amazon Simple Storage Service API Reference\nS3Grant\nService: Amazon S3 Control\nContents\nGrantee\nType: S3Grantee  data type\nRequired: No\nPermission\nType: String\nValid Values: FULL_CONTROL | READ | WRITE | READ_ACP | WRITE_ACP\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1540Amazon Simple Storage Service API Reference\nS3Grantee\nService: Amazon S3 Control\nContents\nDisplayName\nType: String\nLength Constraints: Minimum length of 1.", "Maximum length of 1024.\nRequired: No\nIdenti\ufb01er\nType: String\nLength Constraints: Minimum length of 1.", "Maximum length of 1024.\nRequired: No\nTypeIdenti\ufb01er\nType: String\nValid Values: id | emailAddress | uri\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1541Amazon Simple Storage Service API Reference\nS3InitiateRestoreObjectOperation\nService: Amazon S3 Control\nContains the con\ufb01guration parameters for a POST Object restore job. S3 Batch Operations passes \nevery object to the underlying RestoreObject  API operation.", "For more information about the \nparameters for this operation, see RestoreObject.\nContents\nExpirationInDays\nThis argument speci\ufb01es how long the S3 Glacier or S3 Glacier Deep Archive object remains \navailable in Amazon S3. S3 Initiate Restore Object jobs that target S3 Glacier and S3 Glacier \nDeep Archive objects require ExpirationInDays  set to 1 or greater.\nConversely, do not set ExpirationInDays  when creating S3 Initiate Restore Object jobs \nthat target S3 Intelligent-Tiering Archive Access and Deep Archive Access tier objects. Objects \nin S3 Intelligent-Tiering archive access tiers are not subject to restore expiry, so specifying\nExpirationInDays  results in restore request failure.\nS3 Batch Operations jobs can operate either on S3 Glacier and S3 Glacier Deep Archive storage \nclass objects or on S3 Intelligent-Tiering Archive Access and Deep Archive Access storage tier \nobjects, but not both types in the same job. If you need to restore objects of both types you\nmust  create separate Batch Operations jobs.\nType: Integer\nValid Range: Minimum value of 1.\nRequired: No\nGlacierJobTier\nS3 Batch Operations supports STANDARD  and BULK retrieval tiers, but not the EXPEDITED\nretrieval tier.\nType: String\nValid Values: BULK | STANDARD\nRequired: No\nAmazon S3 Control API Version 2006-03-01 1542Amazon Simple Storage Service API Reference\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1543Amazon Simple Storage Service API Reference\nS3JobManifestGenerator\nService: Amazon S3 Control\nThe container for the service that will create the S3 manifest.\nContents\nEnableManifestOutput\nDetermines whether or not to write the job's generated manifest to a bucket.\nType: Boolean\nRequired: Yes\nSourceBucket\nThe ARN of the source bucket used by the ManifestGenerator.\nNote\nDirectory buckets - Directory buckets aren't supported as the source buckets used by\nS3JobManifestGenerator  to generate the job manifest.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 128.\nPattern: arn:[^:]+:s3:.*\nRequired: Yes\nExpectedBucketOwner\nThe AWS account ID that owns the bucket the generated manifest is written to. If provided the \ngenerated manifest bucket's owner AWS account ID must match this value, else the job fails.\nType: String\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nAmazon S3 Control API Version 2006-03-01 1544Amazon Simple Storage Service API Reference\nRequired: No\nFilter\nSpeci\ufb01es rules the S3JobManifestGenerator should use to decide whether an object in the \nsource bucket should or should not be included in the generated job manifest.\nType: JobManifestGeneratorFilter  data type\nRequired: No\nManifestOutputLocation\nSpeci\ufb01es the location the generated manifest will be written to.", "Manifests can't be written to \ndirectory buckets.", "For more information, see Directory buckets.\nType: S3ManifestOutputLocation  data type\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1545Amazon Simple Storage Service API Reference\nS3ManifestOutputLocation\nService: Amazon S3 Control\nLocation details for where the generated manifest should be written.\nContents\nBucket\nThe bucket ARN the generated manifest should be written to.\nNote\nDirectory buckets - Directory buckets aren't supported as the buckets to store the \ngenerated manifest.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 128.\nPattern: arn:[^:]+:s3:.*\nRequired: Yes\nManifestFormat\nThe format of the generated manifest.\nType: String\nValid Values: S3InventoryReport_CSV_20211130\nRequired: Yes\nExpectedManifestBucketOwner\nThe Account ID that owns the bucket the generated manifest is written to.\nType: String\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nAmazon S3 Control API Version 2006-03-01 1546Amazon Simple Storage Service API Reference\nRequired: No\nManifestEncryption\nSpeci\ufb01es what encryption should be used when the generated manifest objects are written.\nType: GeneratedManifestEncryption data type\nRequired: No\nManifestPre\ufb01x\nPre\ufb01x identifying one or more objects to which the manifest applies.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 512.\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1547Amazon Simple Storage Service API Reference\nS3ObjectLockLegalHold\nService: Amazon S3 Control\nWhether S3 Object Lock legal hold will be applied to objects in an S3 Batch Operations job.\nContents\nStatus\nThe Object Lock legal hold status to be applied to all objects in the Batch Operations job.\nType: String\nValid Values: OFF | ON\nRequired: Yes\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1548Amazon Simple Storage Service API Reference\nS3ObjectMetadata\nService: Amazon S3 Control\nContents\nCacheControl\nType: String\nLength Constraints: Minimum length of 1.", "Maximum length of 1024.\nRequired: No\nContentDisposition\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 1024.\nRequired: No\nContentEncoding\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 1024.\nRequired: No\nContentLanguage\nType: String\nLength Constraints: Minimum length of 1.", "Maximum length of 1024.\nRequired: No\nContentLength\nThis member has been deprecated.\nType: Long\nAmazon S3 Control API Version 2006-03-01 1549Amazon Simple Storage Service API Reference\nValid Range: Minimum value of 0.\nRequired: No\nContentMD5\nThis member has been deprecated.\nType: String\nLength Constraints: Minimum length of 1.", "Maximum length of 1024.\nRequired: No\nContentType\nType: String\nLength Constraints: Minimum length of 1.", "Maximum length of 1024.\nRequired: No\nHttpExpiresDate\nType: Timestamp\nRequired: No\nRequesterCharged\nThis member has been deprecated.\nType: Boolean\nRequired: No\nSSEAlgorithm\nThe server-side encryption algorithm used when storing objects in Amazon S3.\nDirectory buckets  - For directory buckets, there are only two supported options for server-\nside encryption: server-side encryption with Amazon S3 managed keys (SSE-S3) (AES256 ) \nand server-side encryption with AWS KMS keys (SSE-KMS) (KMS). For more information, \nAmazon S3 Control API Version 2006-03-01 1550Amazon Simple Storage Service API Reference\nsee Protecting data with server-side encryption in the Amazon S3 User Guide .", "For the Copy \noperation in Batch Operations , see S3CopyObjectOperation.\nType: String\nValid Values: AES256 | KMS\nRequired: No\nUserMetadata\nType: String to string map\nMap Entries: Maximum number of 8192 items.\nKey Length Constraints: Minimum length of 1.", "Maximum length of 1024.\nValue Length Constraints: Maximum length of 1024.\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1551Amazon Simple Storage Service API Reference\nS3ObjectOwner\nService: Amazon S3 Control\nContents\nDisplayName\nType: String\nLength Constraints: Minimum length of 1.", "Maximum length of 1024.\nRequired: No\nID\nType: String\nLength Constraints: Minimum length of 1.", "Maximum length of 1024.\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1552Amazon Simple Storage Service API Reference\nS3ReplicateObjectOperation\nService: Amazon S3 Control\nDirects the speci\ufb01ed job to invoke ReplicateObject  on every object in the job's manifest.\nContents\nThe members of this exception structure are context-dependent.\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1553Amazon Simple Storage Service API Reference\nS3Retention\nService: Amazon S3 Control\nContains the S3 Object Lock retention mode to be applied to all objects in the S3 Batch Operations \njob.", "If you don't provide Mode  and RetainUntilDate  data types in your operation, you will \nremove the retention from your objects.", "For more information, see Using S3 Object Lock retention \nwith S3 Batch Operations  in the Amazon S3 User Guide .\nContents\nMode\nThe Object Lock retention mode to be applied to all objects in the Batch Operations job.\nType: String\nValid Values: COMPLIANCE | GOVERNANCE\nRequired: No\nRetainUntilDate\nThe date when the applied Object Lock retention will expire on all objects set by the Batch \nOperations job.\nType: Timestamp\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1554Amazon Simple Storage Service API Reference\nS3SetObjectAclOperation\nService: Amazon S3 Control\nContains the con\ufb01guration parameters for a PUT Object ACL operation. S3 Batch Operations passes \nevery object to the underlying PutObjectAcl  API operation. For more information about the \nparameters for this operation, see PutObjectAcl.\nContents\nAccessControlPolicy\nType: S3AccessControlPolicy data type\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1555Amazon Simple Storage Service API Reference\nS3SetObjectLegalHoldOperation\nService: Amazon S3 Control\nContains the con\ufb01guration for an S3 Object Lock legal hold operation that an S3 Batch Operations \njob passes to every object to the underlying PutObjectLegalHold  API operation. For more \ninformation, see Using S3 Object Lock legal hold with S3 Batch Operations in the Amazon S3 User \nGuide .\nNote\nThis functionality is not supported by directory buckets.\nContents\nLegalHold\nContains the Object Lock legal hold status to be applied to all objects in the Batch Operations \njob.\nType: S3ObjectLockLegalHold data type\nRequired: Yes\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1556Amazon Simple Storage Service API Reference\nS3SetObjectRetentionOperation\nService: Amazon S3 Control\nContains the con\ufb01guration parameters for the Object Lock retention action for an S3 Batch \nOperations job.", "Batch Operations passes every object to the underlying PutObjectRetention\nAPI operation.", "For more information, see Using S3 Object Lock retention with S3 Batch Operations\nin the Amazon S3 User Guide .\nNote\nThis functionality is not supported by directory buckets.\nContents\nRetention\nContains the Object Lock retention mode to be applied to all objects in the Batch Operations \njob. For more information, see Using S3 Object Lock retention with S3 Batch Operations in the\nAmazon S3 User Guide .\nType: S3Retention data type\nRequired: Yes\nBypassGovernanceRetention\nIndicates if the action should be applied to objects in the Batch Operations job even if they have \nObject Lock  GOVERNANCE  type in place.\nType: Boolean\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\nAmazon S3 Control API Version 2006-03-01 1557Amazon Simple Storage Service API Reference\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1558Amazon Simple Storage Service API Reference\nS3SetObjectTaggingOperation\nService: Amazon S3 Control\nContains the con\ufb01guration parameters for a PUT Object Tagging operation. S3 Batch Operations \npasses every object to the underlying PutObjectTagging  API operation. For more information \nabout the parameters for this operation, see PutObjectTagging.\nContents\nTagSet\nType: Array of S3Tag data types\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1559Amazon Simple Storage Service API Reference\nS3Tag\nService: Amazon S3 Control\nA container for a key-value name pair.\nContents\nKey\nKey of the tag\nType: String\nLength Constraints: Minimum length of 1.", "Maximum length of 128.\nPattern: ^([\\p{L}\\p{Z}\\p{N}_.:/=+\\-@]*)$\nRequired: Yes\nValue\nValue of the tag\nType: String\nLength Constraints: Minimum length of 0.", "Maximum length of 256.\nPattern: ^([\\p{L}\\p{Z}\\p{N}_.:/=+\\-@]*)$\nRequired: Yes\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1560Amazon Simple Storage Service API Reference\nSelectionCriteria\nService: Amazon S3 Control\nContents\nDelimiter\nA container for the delimiter of the selection criteria being used.\nType: String\nLength Constraints: Maximum length of 1.\nRequired: No\nMaxDepth\nThe max depth of the selection criteria\nType: Integer\nValid Range: Minimum value of 1.", "Maximum value of 10.\nRequired: No\nMinStorageBytesPercentage\nThe minimum number of storage bytes percentage whose metrics will be selected.\nNote\nYou must choose a value greater than or equal to 1.0.\nType: Double\nValid Range: Minimum value of 0.1.", "Maximum value of 100.\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\nAmazon S3 Control API Version 2006-03-01 1561Amazon Simple Storage Service API Reference\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1562Amazon Simple Storage Service API Reference\nSourceSelectionCriteria\nService: Amazon S3 Control\nA container that describes additional \ufb01lters for identifying the source objects that you want to \nreplicate.", "You can choose to enable or disable the replication of these objects.\nContents\nReplicaModi\ufb01cations\nA \ufb01lter that you can use to specify whether replica modi\ufb01cation sync is enabled.", "S3 on Outposts \nreplica modi\ufb01cation sync can help you keep object metadata synchronized between replicas \nand source objects. By default, S3 on Outposts replicates metadata from the source objects \nto the replicas only. When replica modi\ufb01cation sync is enabled, S3 on Outposts replicates \nmetadata changes made to the replica copies back to the source object, making the replication \nbidirectional.\nTo replicate object metadata modi\ufb01cations on replicas, you can specify this element and set the\nStatus  of this element to Enabled .\nNote\nYou must enable replica modi\ufb01cation sync on the source and destination buckets to \nreplicate replica metadata changes between the source and the replicas.\nType: ReplicaModi\ufb01cations data type\nRequired: No\nSseKmsEncryptedObjects\nA \ufb01lter that you can use to select Amazon S3 objects that are encrypted with server-\nside encryption by using AWS Key Management Service (AWS KMS) keys. If you include\nSourceSelectionCriteria  in the replication con\ufb01guration, this element is required.\nNote\nThis is not supported by Amazon S3 on Outposts buckets.\nAmazon S3 Control API Version 2006-03-01 1563Amazon Simple Storage Service API Reference\nType: SseKmsEncryptedObjects data type\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1564Amazon Simple Storage Service API Reference\nSSEKMS\nService: Amazon S3 Control\nContents\nKeyId\nA container for the ARN of the SSE-KMS encryption. This property is read-only and \nfollows the following format:  arn:aws:kms: us-east-1 :example-account-\nid:key/example-9a73-4afc-8d29-8f5900cef44e\nType: String\nRequired: Yes\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1565Amazon Simple Storage Service API Reference\nSseKmsEncryptedObjects\nService: Amazon S3 Control\nA container for \ufb01lter information that you can use to select S3 objects that are encrypted with AWS \nKey Management Service (AWS KMS).\nNote\nThis is not supported by Amazon S3 on Outposts buckets.\nContents\nStatus\nSpeci\ufb01es whether Amazon S3 replicates objects that are created with server-side encryption by \nusing an AWS KMS key stored in AWS Key Management Service.\nType: String\nValid Values: Enabled | Disabled\nRequired: Yes\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1566Amazon Simple Storage Service API Reference\nSSEKMSEncryption\nService: Amazon S3 Control\nCon\ufb01guration for the use of SSE-KMS to encrypt generated manifest objects.\nContents\nKeyId\nSpeci\ufb01es the ID of the AWS Key Management Service (AWS KMS) symmetric encryption \ncustomer managed key to use for encrypting generated manifest objects.\nType: String\nLength Constraints: Minimum length of 1.", "Maximum length of 2000.\nRequired: Yes\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1567Amazon Simple Storage Service API Reference\nSSES3\nService: Amazon S3 Control\nContents\nThe members of this exception structure are context-dependent.\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1568Amazon Simple Storage Service API Reference\nSSES3Encryption\nService: Amazon S3 Control\nCon\ufb01guration for the use of SSE-S3 to encrypt generated manifest objects.\nContents\nThe members of this exception structure are context-dependent.\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1569Amazon Simple Storage Service API Reference\nStorageLensAwsOrg\nService: Amazon S3 Control\nThe AWS organization for your S3 Storage Lens.\nContents\nArn\nA container for the Amazon Resource Name (ARN) of the AWS organization.", "This property \nis read-only and follows the following format:  arn:aws:organizations: us-\neast-1:example-account-id :organization/ o-ex2l495dck\nType: String\nLength Constraints: Minimum length of 1.", "Maximum length of 1024.\nPattern: arn:[a-z\\-]+:organizations::\\d{12}:organization\\/o-[a-z0-9]{10,32}\nRequired: Yes\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1570Amazon Simple Storage Service API Reference\nStorageLensCon\ufb01guration\nService: Amazon S3 Control\nA container for the Amazon S3 Storage Lens con\ufb01guration.\nContents\nAccountLevel\nA container for all the account-level con\ufb01gurations of your S3 Storage Lens con\ufb01guration.\nType: AccountLevel data type\nRequired: Yes\nId\nA container for the Amazon S3 Storage Lens con\ufb01guration ID.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 64.\nPattern: [a-zA-Z0-9\\-\\_\\.]+\nRequired: Yes\nIsEnabled\nA container for whether the S3 Storage Lens con\ufb01guration is enabled.\nType: Boolean\nRequired: Yes\nAwsOrg\nA container for the AWS organization for this S3 Storage Lens con\ufb01guration.\nType: StorageLensAwsOrg data type\nRequired: No\nDataExport\nA container to specify the properties of your S3 Storage Lens metrics export including, the \ndestination, schema and format.\nAmazon S3 Control API Version 2006-03-01 1571Amazon Simple Storage Service API Reference\nType: StorageLensDataExport data type\nRequired: No\nExclude\nA container for what is excluded in this con\ufb01guration.", "This container can only be valid if there is \nno Include container submitted, and it's not empty.\nType: Exclude data type\nRequired: No\nInclude\nA container for what is included in this con\ufb01guration.", "This container can only be valid if there is \nno Exclude container submitted, and it's not empty.\nType: Include  data type\nRequired: No\nStorageLensArn\nThe Amazon Resource Name (ARN) of the S3 Storage Lens con\ufb01guration. This property is read-\nonly and follows the following format:  arn:aws:s3: us-east-1 :example-account-\nid:storage-lens/ your-dashboard-name\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 1024.\nPattern: arn:[a-z\\-]+:s3:[a-z0-9\\-]+:\\d{12}:storage\\-lens\\/.*\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\nAmazon S3 Control API Version 2006-03-01 1572Amazon Simple Storage Service API Reference\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1573Amazon Simple Storage Service API Reference\nStorageLensDataExport\nService: Amazon S3 Control\nA container to specify the properties of your S3 Storage Lens metrics export, including the \ndestination, schema, and format.\nContents\nCloudWatchMetrics\nA container for enabling Amazon CloudWatch publishing for S3 Storage Lens metrics.\nType: CloudWatchMetrics data type\nRequired: No\nS3BucketDestination\nA container for the bucket where the S3 Storage Lens metrics export will be located.\nNote\nThis bucket must be located in the same Region as the storage lens con\ufb01guration.\nType: S3BucketDestination data type\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1574Amazon Simple Storage Service API Reference\nStorageLensDataExportEncryption\nService: Amazon S3 Control\nA container for the encryption of the S3 Storage Lens metrics exports.\nContents\nSSEKMS\nType: SSEKMS data type\nRequired: No\nSSES3\nType: SSES3 data type\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1575Amazon Simple Storage Service API Reference\nStorageLensGroup\nService: Amazon S3 Control\nA custom grouping of objects that include \ufb01lters for pre\ufb01xes, su\ufb03xes, object tags, object size, or \nobject age. You can create an S3 Storage Lens group that includes a single \ufb01lter or multiple \ufb01lter \nconditions.", "To specify multiple \ufb01lter conditions, you use AND or OR logical operators.\nContents\nFilter\nSets the criteria for the Storage Lens group data that is displayed. For multiple \ufb01lter conditions, \nthe AND or OR logical operator is used.\nType: StorageLensGroupFilter data type\nRequired: Yes\nName\nContains the name of the Storage Lens group.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 64.\nPattern: [a-zA-Z0-9\\-\\_]+\nRequired: Yes\nStorageLensGroupArn\nContains the Amazon Resource Name (ARN) of the Storage Lens group.", "This property is read-\nonly.\nType: String\nLength Constraints: Minimum length of 4.", "Maximum length of 1024.\nPattern: arn:[a-z\\-]+:s3:[a-z0-9\\-]+:\\d{12}:storage\\-lens\\-group\\/.*\nRequired: No\nAmazon S3 Control API Version 2006-03-01 1576Amazon Simple Storage Service API Reference\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1577Amazon Simple Storage Service API Reference\nStorageLensGroupAndOperator\nService: Amazon S3 Control\nA logical operator that allows multiple \ufb01lter conditions to be joined for more complex comparisons \nof Storage Lens group data.\nContents\nMatchAnyPre\ufb01x\nContains a list of pre\ufb01xes.", "At least one pre\ufb01x must be speci\ufb01ed. Up to 10 pre\ufb01xes are allowed.\nType: Array of strings\nRequired: No\nMatchAnySu\ufb03x\nContains a list of su\ufb03xes. At least one su\ufb03x must be speci\ufb01ed. Up to 10 su\ufb03xes are allowed.\nType: Array of strings\nRequired: No\nMatchAnyTag\nContains the list of object tags. At least one object tag must be speci\ufb01ed.", "Up to 10 object tags \nare allowed.\nType: Array of S3Tag data types\nRequired: No\nMatchObjectAge\nContains DaysGreaterThan  and DaysLessThan  to de\ufb01ne the object age range (minimum and \nmaximum number of days).\nType: MatchObjectAge data type\nRequired: No\nMatchObjectSize\nContains BytesGreaterThan  and BytesLessThan  to de\ufb01ne the object size range (minimum \nand maximum number of Bytes).\nAmazon S3 Control API Version 2006-03-01 1578Amazon Simple Storage Service API Reference\nType: MatchObjectSize data type\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1579Amazon Simple Storage Service API Reference\nStorageLensGroupFilter\nService: Amazon S3 Control\nThe \ufb01lter element sets the criteria for the Storage Lens group data that is displayed.", "For multiple \n\ufb01lter conditions, the AND or OR logical operator is used.\nContents\nAnd\nA logical operator that allows multiple \ufb01lter conditions to be joined for more complex \ncomparisons of Storage Lens group data. Objects must match all of the listed \ufb01lter conditions \nthat are joined by the And logical operator.", "Only one of each \ufb01lter condition is allowed.\nType: StorageLensGroupAndOperator data type\nRequired: No\nMatchAnyPre\ufb01x\nContains a list of pre\ufb01xes. At least one pre\ufb01x must be speci\ufb01ed. Up to 10 pre\ufb01xes are allowed.\nType: Array of strings\nRequired: No\nMatchAnySu\ufb03x\nContains a list of su\ufb03xes. At least one su\ufb03x must be speci\ufb01ed.", "Up to 10 su\ufb03xes are allowed.\nType: Array of strings\nRequired: No\nMatchAnyTag\nContains the list of S3 object tags.", "At least one object tag must be speci\ufb01ed.", "Up to 10 object \ntags are allowed.\nType: Array of S3Tag data types\nRequired: No\nMatchObjectAge\nContains DaysGreaterThan  and DaysLessThan  to de\ufb01ne the object age range (minimum and \nmaximum number of days).\nAmazon S3 Control API Version 2006-03-01 1580Amazon Simple Storage Service API Reference\nType: MatchObjectAge data type\nRequired: No\nMatchObjectSize\nContains BytesGreaterThan  and BytesLessThan  to de\ufb01ne the object size range (minimum \nand maximum number of Bytes).\nType: MatchObjectSize data type\nRequired: No\nOr\nA single logical operator that allows multiple \ufb01lter conditions to be joined.", "Objects can match \nany of the listed \ufb01lter conditions, which are joined by the Or logical operator.", "Only one of each \n\ufb01lter condition is allowed.\nType: StorageLensGroupOrOperator data type\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1581Amazon Simple Storage Service API Reference\nStorageLensGroupLevel\nService: Amazon S3 Control\nSpeci\ufb01es the Storage Lens groups to include in the Storage Lens group aggregation.\nContents\nSelectionCriteria\nIndicates which Storage Lens group ARNs to include or exclude in the Storage Lens group \naggregation. If this value is left null, then all Storage Lens groups are selected.\nType: StorageLensGroupLevelSelectionCriteria data type\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1582Amazon Simple Storage Service API Reference\nStorageLensGroupLevelSelectionCriteria\nService: Amazon S3 Control\nIndicates which Storage Lens group ARNs to include or exclude in the Storage Lens group \naggregation. You can only attach Storage Lens groups to your Storage Lens dashboard if they're \nincluded in your Storage Lens group aggregation. If this value is left null, then all Storage Lens \ngroups are selected.\nContents\nExclude\nIndicates which Storage Lens group ARNs to exclude from the Storage Lens group aggregation.\nType: Array of strings\nLength Constraints: Minimum length of 4. Maximum length of 1024.\nPattern: arn:[a-z\\-]+:s3:[a-z0-9\\-]+:\\d{12}:storage\\-lens\\-group\\/.*\nRequired: No\nInclude\nIndicates which Storage Lens group ARNs to include in the Storage Lens group aggregation.\nType: Array of strings\nLength Constraints: Minimum length of 4. Maximum length of 1024.\nPattern: arn:[a-z\\-]+:s3:[a-z0-9\\-]+:\\d{12}:storage\\-lens\\-group\\/.*\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1583Amazon Simple Storage Service API Reference\nAmazon S3 Control API Version 2006-03-01 1584Amazon Simple Storage Service API Reference\nStorageLensGroupOrOperator\nService: Amazon S3 Control\nA container element for specifying Or rule conditions.", "The rule conditions determine the subset of \nobjects to which the Or rule applies. Objects can match any of the listed \ufb01lter conditions, which are \njoined by the Or logical operator.", "Only one of each \ufb01lter condition is allowed.\nContents\nMatchAnyPre\ufb01x\nFilters objects that match any of the speci\ufb01ed pre\ufb01xes.\nType: Array of strings\nRequired: No\nMatchAnySu\ufb03x\nFilters objects that match any of the speci\ufb01ed su\ufb03xes.\nType: Array of strings\nRequired: No\nMatchAnyTag\nFilters objects that match any of the speci\ufb01ed S3 object tags.\nType: Array of S3Tag data types\nRequired: No\nMatchObjectAge\nFilters objects that match the speci\ufb01ed object age range.\nType: MatchObjectAge data type\nRequired: No\nMatchObjectSize\nFilters objects that match the speci\ufb01ed object size range.\nType: MatchObjectSize data type\nAmazon S3 Control API Version 2006-03-01 1585Amazon Simple Storage Service API Reference\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1586Amazon Simple Storage Service API Reference\nStorageLensTag\nService: Amazon S3 Control\nContents\nKey\nType: String\nLength Constraints: Minimum length of 1.", "Maximum length of 128.\nPattern: ^([\\p{L}\\p{Z}\\p{N}_.:/=+\\-@]*)$\nRequired: Yes\nValue\nType: String\nLength Constraints: Minimum length of 0.", "Maximum length of 256.\nPattern: ^([\\p{L}\\p{Z}\\p{N}_.:/=+\\-@]*)$\nRequired: Yes\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1587Amazon Simple Storage Service API Reference\nTag\nService: Amazon S3 Control\nAn AWS resource tag that's associated with your S3 resource. You can add tags to new objects \nwhen you upload them, or you can add object tags to existing objects.\nNote\nThis operation is only supported for S3 Storage Lens groups and for S3 Access Grants. The \ntagged resource can be an S3 Storage Lens group or S3 Access Grants instance, registered \nlocation, or grant.\nContents\nKey\nThe key of the key-value pair of a tag added to your AWS resource.", "A tag key can be up to 128 \nUnicode characters in length and is case-sensitive.", "System created tags that begin with aws:\naren\u2019t supported.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 128.\nPattern: ^([\\p{L}\\p{Z}\\p{N}_.:/=+\\-@]*)$\nRequired: Yes\nValue\nThe value of the key-value pair of a tag added to your AWS resource. A tag value can be up to \n256 Unicode characters in length and is case-sensitive.\nType: String\nLength Constraints: Minimum length of 0.", "Maximum length of 256.\nPattern: ^([\\p{L}\\p{Z}\\p{N}_.:/=+\\-@]*)$\nRequired: Yes\nAmazon S3 Control API Version 2006-03-01 1588Amazon Simple Storage Service API Reference\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1589Amazon Simple Storage Service API Reference\nTagging\nService: Amazon S3 Control\nContents\nTagSet\nA collection for a set of tags.\nType: Array of S3Tag data types\nRequired: Yes\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1590Amazon Simple Storage Service API Reference\nTransition\nService: Amazon S3 Control\nSpeci\ufb01es when an object transitions to a speci\ufb01ed storage class. For more information about \nAmazon S3 Lifecycle con\ufb01guration rules, see  Transitioning objects using Amazon S3 Lifecycle in \nthe Amazon S3 User Guide .\nContents\nDate\nIndicates when objects are transitioned to the speci\ufb01ed storage class.", "The date value must be in \nISO 8601 format.", "The time is always midnight UTC.\nType: Timestamp\nRequired: No\nDays\nIndicates the number of days after creation when objects are transitioned to the speci\ufb01ed \nstorage class.", "The value must be a positive integer.\nType: Integer\nRequired: No\nStorageClass\nThe storage class to which you want the object to transition.\nType: String\nValid Values: GLACIER | STANDARD_IA | ONEZONE_IA | INTELLIGENT_TIERING | \nDEEP_ARCHIVE\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\nAmazon S3 Control API Version 2006-03-01 1591Amazon Simple Storage Service API Reference\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1592Amazon Simple Storage Service API Reference\nVersioningCon\ufb01guration\nService: Amazon S3 Control\nDescribes the versioning state of an Amazon S3 on Outposts bucket. For more information, see\nPutBucketVersioning.\nContents\nMFADelete\nSpeci\ufb01es whether MFA delete is enabled or disabled in the bucket versioning con\ufb01guration for \nthe S3 on Outposts bucket.\nType: String\nValid Values: Enabled | Disabled\nRequired: No\nStatus\nSets the versioning state of the S3 on Outposts bucket.\nType: String\nValid Values: Enabled | Suspended\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1593Amazon Simple Storage Service API Reference\nVpcCon\ufb01guration\nService: Amazon S3 Control\nThe virtual private cloud (VPC) con\ufb01guration for an access point.\nContents\nVpcId\nIf this \ufb01eld is speci\ufb01ed, this access point will only allow connections from the speci\ufb01ed VPC ID.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 1024.\nRequired: Yes\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 on Outposts\nThe following data types are supported by Amazon S3 on Outposts:\n\u2022Endpoint\n\u2022FailedReason\n\u2022NetworkInterface\n\u2022Outpost\nAmazon S3 on Outposts API Version 2006-03-01 1594Amazon Simple Storage Service API Reference\nEndpoint\nService: Amazon S3 on Outposts\nAmazon S3 on Outposts Access Points simplify managing data access at scale for shared datasets \nin S3 on Outposts. S3 on Outposts uses endpoints to connect to AWS Outposts buckets so that you \ncan perform actions within your virtual private cloud (VPC). For more information, see  Accessing \nS3 on Outposts using VPC-only access points in the Amazon Simple Storage Service User Guide.\nContents\nAccessType\nThe type of connectivity used to access the Amazon S3 on Outposts endpoint.\nType: String\nValid Values: Private | CustomerOwnedIp\nRequired: No\nCidrBlock\nThe VPC CIDR committed by this endpoint.\nType: String\nRequired: No\nCreationTime\nThe time the endpoint was created.\nType: Timestamp\nRequired: No\nCustomerOwnedIpv4Pool\nThe ID of the customer-owned IPv4 address pool used for the endpoint.\nType: String\nPattern: ^ipv4pool-coip-([0-9a-f]{17})$\nRequired: No\nAmazon S3 on Outposts API Version 2006-03-01 1595Amazon Simple Storage Service API Reference\nEndpointArn\nThe Amazon Resource Name (ARN) of the endpoint.\nType: String\nPattern: ^arn:(aws|aws-cn|aws-us-gov|aws-iso|aws-iso-b):s3-outposts:[a-\nz\\-0-9]*:[0-9]{12}:outpost/(op-[a-f0-9]{17}|ec2)/endpoint/[a-zA-Z0-9]\n{19}$\nRequired: No\nFailedReason\nThe failure reason, if any, for a create or delete endpoint operation.\nType: FailedReason object\nRequired: No\nNetworkInterfaces\nThe network interface of the endpoint.\nType: Array of NetworkInterface objects\nRequired: No\nOutpostsId\nThe ID of the AWS Outposts.\nType: String\nPattern: ^(op-[a-f0-9]{17}|\\d{12}|ec2)$\nRequired: No\nSecurityGroupId\nThe ID of the security group used for the endpoint.\nType: String\nPattern: ^sg-([0-9a-f]{8}|[0-9a-f]{17})$\nAmazon S3 on Outposts API Version 2006-03-01 1596Amazon Simple Storage Service API Reference\nRequired: No\nStatus\nThe status of the endpoint.\nType: String\nValid Values: Pending | Available | Deleting | Create_Failed | Delete_Failed\nRequired: No\nSubnetId\nThe ID of the subnet used for the endpoint.\nType: String\nPattern: ^subnet-([0-9a-f]{8}|[0-9a-f]{17})$\nRequired: No\nVpcId\nThe ID of the VPC used for the endpoint.\nType: String\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 on Outposts API Version 2006-03-01 1597Amazon Simple Storage Service API Reference\nFailedReason\nService: Amazon S3 on Outposts\nThe failure reason, if any, for a create or delete endpoint operation.\nContents\nErrorCode\nThe failure code, if any, for a create or delete endpoint operation.\nType: String\nRequired: No\nMessage\nAdditional error details describing the endpoint failure and recommended action.\nType: String\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 on Outposts API Version 2006-03-01 1598Amazon Simple Storage Service API Reference\nNetworkInterface\nService: Amazon S3 on Outposts\nThe container for the network interface.\nContents\nNetworkInterfaceId\nThe ID for the network interface.\nType: String\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 on Outposts API Version 2006-03-01 1599Amazon Simple Storage Service API Reference\nOutpost\nService: Amazon S3 on Outposts\nContains the details for the Outpost object.\nContents\nCapacityInBytes\nThe Amazon S3 capacity of the outpost in bytes.\nType: Long\nRequired: No\nOutpostArn\nSpeci\ufb01es the unique Amazon Resource Name (ARN) for the outpost.\nType: String\nPattern: ^arn:(aws|aws-cn|aws-us-gov|aws-iso|aws-iso-b):outposts:[a-z\n\\-0-9]*:[0-9]{12}:outpost/(op-[a-f0-9]{17}|ec2)$\nRequired: No\nOutpostId\nSpeci\ufb01es the unique identi\ufb01er for the outpost.\nType: String\nPattern: ^(op-[a-f0-9]{17}|\\d{12}|ec2)$\nRequired: No\nOwnerId\nReturns the AWS account ID of the outpost owner. Useful for comparing owned versus shared \noutposts.\nType: String\nPattern: ^\\d{12}$\nAmazon S3 on Outposts API Version 2006-03-01 1600Amazon Simple Storage Service API Reference\nRequired: No\nS3OutpostArn\nSpeci\ufb01es the unique S3 on Outposts ARN for use with AWS Resource Access Manager (AWS \nRAM).\nType: String\nPattern: ^arn:(aws|aws-cn|aws-us-gov|aws-iso|aws-iso-b):s3-outposts:[a-z\n\\-0-9]*:[0-9]{12}:outpost/(op-[a-f0-9]{17}|\\d{12})/s3$\nRequired: No\nSee Also\nFor more information about using this API in one of the language-speci\ufb01c AWS SDKs, see the \nfollowing:\n\u2022AWS SDK for C++\n\u2022AWS SDK for Java V2\n\u2022AWS SDK for Ruby V3\nAmazon S3 on Outposts API Version 2006-03-01 1601Amazon Simple Storage Service API Reference\nDeveloping with Amazon S3\nThis section covers developer-related topics for using Amazon S3. For more information, review the \ntopics below.\nTopics\n\u2022Making requests\n\u2022Developing with Amazon S3 using the AWS CLI\n\u2022Developing with Amazon S3 using the AWS SDKs\n\u2022Getting Amazon S3 request IDs for AWS Support\nMaking requests\nAmazon S3 is a REST service. You can send requests to Amazon S3 using the REST API or the AWS \nSDK (see Sample Code and Libraries ) wrapper libraries that wrap the underlying Amazon S3 REST \nAPI, simplifying your programming tasks.\nEvery interaction with Amazon S3 is either authenticated or anonymous.", "Authentication is a \nprocess of verifying the identity of the requester trying to access an Amazon Web Services (AWS) \nproduct. Authenticated requests must include a signature value that authenticates the request \nsender. The signature value is, in part, generated from the requester's AWS access keys (access \nkey ID and secret access key).", "For more information about getting access keys, see How Do I Get \nSecurity Credentials?", "in the AWS General Reference.\nIf you are using the AWS SDK, the libraries compute the signature from the keys you provide. \nHowever, if you make direct REST API calls in your application, you must write the code to compute \nthe signature and add it to the request.\nTopics\n\u2022About access keys\n\u2022Request endpoints\n\u2022Making requests to Amazon S3 over IPv6\n\u2022Making requests using the AWS SDKs\n\u2022Making requests using the REST API\nMaking requests API Version 2006-03-01 1602Amazon Simple Storage Service API Reference\nAbout access keys\nThe following sections review the types of access keys that you can use to make authenticated \nrequests.\nAWS account access keys\nThe account access keys provide full access to the AWS resources owned by the account.", "The \nfollowing are examples of access keys:\n\u2022Access key ID (a 20-character, alphanumeric string). For example: AKIAIOSFODNN7EXAMPLE\n\u2022Secret access key (a 40-character string).", "For example: wJalrXUtnFEMI/K7MDENG/\nbPxR\ufb01CYEXAMPLEKEY\nThe access key ID uniquely identi\ufb01es an AWS account.", "You can use these access keys to send \nauthenticated requests to Amazon S3.\nIAM user access keys\nYou can create one AWS account for your company; however, there may be several employees in \nthe organization who need access to your organization's AWS resources.", "Sharing your AWS account \naccess keys reduces security, and creating individual AWS accounts for each employee might not \nbe practical.", "Also, you cannot easily share resources such as buckets and objects because they are \nowned by di\ufb00erent accounts. To share resources, you must grant permissions, which is additional \nwork.\nIn such scenarios, you can use AWS Identity and Access Management (IAM) to create users under \nyour AWS account with their own access keys and attach IAM user policies that grant appropriate \nresource access permissions to these users. To better manage these users, IAM enables you to \ncreate groups of users and grant group-level permissions that apply to all users in that group.\nThese users are referred to as IAM users that you create and manage within AWS. The parent \naccount controls a user's ability to access AWS. Any resources an IAM user creates are under the \ncontrol of and paid for by the parent AWS account.", "These IAM users can send authenticated \nrequests to Amazon S3 using their own security credentials.", "For more information about creating \nand managing users under your AWS account, go to the AWS Identity and Access Management \nproduct details page.\nAbout access keys API Version 2006-03-01 1603Amazon Simple Storage Service API Reference\nTemporary security credentials\nIn addition to creating IAM users with their own access keys, IAM also enables you to grant \ntemporary security credentials (temporary access keys and a security token) to any IAM user to \nenable them to access your AWS services and resources. You can also manage users in your system \noutside AWS.", "These are referred to as federated users.", "Additionally, users can be applications that \nyou create to access your AWS resources.\nIAM provides the AWS Security Token Service API for you to request temporary security credentials.", "\nYou can use either the AWS STS API or the AWS SDK to request these credentials.", "The API returns \ntemporary security credentials (access key ID and secret access key), and a security token. These \ncredentials are valid only for the duration you specify when you request them. You use the access \nkey ID and secret key the same way you use them when sending requests using your AWS account \nor IAM user access keys.", "In addition, you must include the token in each request you send to \nAmazon S3.\nAn IAM user can request these temporary security credentials for their own use or hand them \nout to federated users or applications.", "When requesting temporary security credentials for \nfederated users, you must provide a user name and an IAM policy de\ufb01ning the permissions you \nwant to associate with these temporary security credentials.", "The federated user cannot get more \npermissions than the parent IAM user who requested the temporary credentials.\nYou can use these temporary security credentials in making requests to Amazon S3.", "The API \nlibraries compute the necessary signature value using those credentials to authenticate your \nrequest.", "If you send requests using expired credentials, Amazon S3 denies the request.\nFor information on signing requests using temporary security credentials in your REST API \nrequests, see Signing and authenticating REST requests (AWS signature version 2). For information \nabout sending requests using AWS SDKs, see Making requests using the AWS SDKs.\nFor more information about IAM support for temporary security credentials, see Temporary \nSecurity Credentials in the IAM User Guide .\nFor added security, you can require multifactor authentication (MFA) when accessing your Amazon \nS3 resources by con\ufb01guring a bucket policy.", "For information, see Example bucket policies: \nRequiring MFA .", "After you require MFA to access your Amazon S3 resources, the only way you can \naccess these resources is by providing temporary credentials that are created with an MFA key.", "\nFor more information, see the AWS Multi-Factor Authentication detail page and Con\ufb01guring MFA-\nProtected API Access in the IAM User Guide .\nAbout access keys API Version 2006-03-01 1604Amazon Simple Storage Service API Reference\nRequest endpoints\nYou send REST requests to the service's prede\ufb01ned endpoint.", "For a list of all AWS services and their \ncorresponding endpoints, go to Regions and Endpoints in the AWS General Reference.\nMaking requests to Amazon S3 over IPv6\nAmazon Simple Storage Service (Amazon S3) supports the ability to access S3 buckets using \nthe Internet Protocol version 6 (IPv6), in addition to the IPv4 protocol. Amazon S3 dual-stack \nendpoints support requests to S3 buckets over IPv6 and IPv4. There are no additional charges for \naccessing Amazon S3 over IPv6. For more information about pricing, see Amazon S3 Pricing.\nTopics\n\u2022Getting started making requests over IPv6\n\u2022Using IPv6 addresses in IAM policies\n\u2022Testing IP address compatibility\n\u2022Using Amazon S3 dual-stack endpoints\nGetting started making requests over IPv6\nTo make a request to an S3 bucket over IPv6, you need to use a dual-stack endpoint. The next \nsection describes how to make requests over IPv6 by using dual-stack endpoints.\nThe following are some things you should know before trying to access a bucket over IPv6:\n\u2022The client and the network accessing the bucket must be enabled to use IPv6.\n\u2022Both virtual hosted-style and path style requests are supported for IPv6 access.", "For more \ninformation, see Amazon S3 dual-stack endpoints.\n\u2022If you use source IP address \ufb01ltering in your AWS Identity and Access Management (IAM) user \nor bucket policies, you need to update the policies to include IPv6 address ranges.", "For more \ninformation, see Using IPv6 addresses in IAM policies.\n\u2022When using IPv6, server access log \ufb01les output IP addresses in an IPv6 format.", "You need to \nupdate existing tools, scripts, and software that you use to parse Amazon S3 log \ufb01les so that \nthey can parse the IPv6 formatted Remote IP  addresses. For more information, see Logging \nrequests with server access logging .\nRequest endpoints API Version 2006-03-01 1605Amazon Simple Storage Service API Reference\nNote\nIf you experience issues related to the presence of IPv6 addresses in log \ufb01les, contact\nAWS Support.\nMaking requests over IPv6 by using dual-stack endpoints\nYou make requests with Amazon S3 API calls over IPv6 by using dual-stack endpoints. The Amazon \nS3 API operations work the same way whether you're accessing Amazon S3 over IPv6 or over IPv4.", "\nPerformance should be the same too.\nWhen using the REST API, you access a dual-stack endpoint directly. For more information, see\nDual-stack endpoints .\nWhen using the AWS Command Line Interface (AWS CLI) and AWS SDKs, you can use a parameter \nor \ufb02ag to change to a dual-stack endpoint. You can also specify the dual-stack endpoint directly as \nan override of the Amazon S3 endpoint in the con\ufb01g \ufb01le.\nYou can use a dual-stack endpoint to access a bucket over IPv6 from any of the following:\n\u2022The AWS CLI, see Using dual-stack endpoints from the AWS CLI.\n\u2022The AWS SDKs, see Using dual-stack endpoints from the AWS SDKs.\n\u2022The REST API, see Making requests to dual-stack endpoints by using the REST API.\nFeatures not available over IPv6\nThe following feature is currently not supported when accessing an S3 bucket over IPv6: Static \nwebsite hosting from an S3 bucket.\nUsing IPv6 addresses in IAM policies\nBefore trying to access a bucket using IPv6, you must ensure that any IAM user or S3 bucket \npolices that are used for IP address \ufb01ltering are updated to include IPv6 address ranges. IP address \n\ufb01ltering policies that are not updated to handle IPv6 addresses may result in clients incorrectly \nlosing or gaining access to the bucket when they start using IPv6.", "For more information about \nmanaging access permissions with IAM, see Identity and Access Management for Amazon S3 .\nMaking requests over IPv6 API Version 2006-03-01 1606Amazon Simple Storage Service API Reference\nIAM policies that \ufb01lter IP addresses use IP Address Condition Operators.", "The following \nbucket policy identi\ufb01es the 54.240.143.* range of allowed IPv4 addresses by using IP address \ncondition operators. Any IP addresses outside of this range will be denied access to the bucket \n(examplebucket ). Since all IPv6 addresses are outside of the allowed range, this policy prevents \nIPv6 addresses from being able to access examplebucket .\n{ \n  \"Version\": \"2012-10-17\", \n  \"Statement\": [ \n    { \n      \"Sid\": \"IPAllow\", \n      \"Effect\": \"Allow\", \n      \"Principal\": \"*\", \n      \"Action\": \"s3:*\", \n      \"Resource\": \"arn:aws:s3::: examplebucket /*\", \n      \"Condition\": { \n         \"IpAddress\": {\"aws:SourceIp\": \"54.240.143.0/24\"} \n      }  \n    }  \n  ]\n}\nYou can modify the bucket policy's Condition  element to allow both IPv4 (54.240.143.0/24 ) \nand IPv6 ( 2001:DB8:1234:5678::/64 ) address ranges as shown in the following example. You \ncan use the same type of Condition  block shown in the example to update both your IAM user \nand bucket policies.\n       \"Condition\": { \n         \"IpAddress\": { \n            \"aws:SourceIp\": [ \n              \"54.240.143.0/24\", \n               \"2001:DB8:1234:5678::/64\" \n             ] \n          } \n        }\nBefore using IPv6 you must update all relevant IAM user and bucket policies that use IP address \n\ufb01ltering. We do not recommend using IP address \ufb01lterig in bucket policies.\nMaking requests over IPv6 API Version 2006-03-01 1607Amazon Simple Storage Service API Reference\nYou can review your IAM user policies using the IAM console at https://console.aws.amazon.com/ \niam/ .", "For more information about IAM, see the IAM User Guide .", "For information about editing S3 \nbucket policies, see Adding a bucket policy.\nTesting IP address compatibility\nIf you are using use Linux/Unix or Mac OS X, you can test whether you can access a dual-stack \nendpoint over IPv6 by using the curl command as shown in the following example:\nExample\ncurl -v  http://s3.dualstack.us-west-2.amazonaws.com/\nYou get back information similar to the following example. If you are connected over IPv6 the \nconnected IP address will be an IPv6 address.\n* About to connect() to s3-us-west-2.amazonaws.com port 80 (#0)\n*   Trying IPv6 address ... connected\n* Connected to s3.dualstack.us-west-2.amazonaws.com ( IPv6 address ) port 80 (#0)\n> GET / HTTP/1.1\n> User-Agent: curl/7.18.1 (x86_64-unknown-linux-gnu) libcurl/7.18.1 OpenSSL/1.0.1t \n zlib/1.2.3\n> Host: s3.dualstack.us-west-2.amazonaws.com\nIf you are using Microsoft Windows 7 or Windows 10, you can test whether you can access a dual-\nstack endpoint over IPv6 or IPv4 by using the ping command as shown in the following example.\nping ipv6.s3.dualstack.us-west-2.amazonaws.com \nUsing Amazon S3 dual-stack endpoints\nAmazon S3 dual-stack endpoints support requests to S3 buckets over IPv6 and IPv4. This section \ndescribes how to use dual-stack endpoints.\nTopics\n\u2022Amazon S3 dual-stack endpoints\n\u2022Using dual-stack endpoints from the AWS CLI\nMaking requests over IPv6 API Version 2006-03-01 1608Amazon Simple Storage Service API Reference\n\u2022Using dual-stack endpoints from the AWS SDKs\n\u2022Using dual-stack endpoints from the REST API\nAmazon S3 dual-stack endpoints\nWhen you make a request to a dual-stack endpoint, the bucket URL resolves to an IPv6 or an IPv4 \naddress. For more information about accessing a bucket over IPv6, see Making requests to Amazon \nS3 over IPv6.\nWhen using the REST API, you directly access an Amazon S3 endpoint by using the endpoint name \n(URI). You can access an S3 bucket through a dual-stack endpoint by using a virtual hosted-style or \na path-style endpoint name. Amazon S3 supports only regional dual-stack endpoint names, which \nmeans that you must specify the region as part of the name.\nUse the following naming conventions for the dual-stack virtual hosted-style and path-style \nendpoint names:\n\u2022Virtual hosted-style dual-stack endpoint:\nbucketname .s3.dualstack. aws-region .amazonaws.com\n\u00a0\n\u2022Path-style dual-stack endpoint:\ns3.dualstack. aws-region .amazonaws.com/bucketname\nFor more information, about endpoint name style, see Accessing and listing an Amazon S3 bucket . \nFor a list of Amazon S3 endpoints, see Regions and Endpoints in the AWS General Reference.\nImportant\nYou can use transfer acceleration with dual-stack endpoints. For more information, see\nGetting started with Amazon S3 Transfer Acceleration .\nMaking requests over IPv6 API Version 2006-03-01 1609Amazon Simple Storage Service API Reference\nNote\nThe two types of VPC endpoints to access Amazon S3 (Interface VPC endpoints and\nGateway VPC endpoints ) don't have dual-stack support. For more information about VPC \nendpoints for Amazon S3, see AWS PrivateLink for Amazon S3 .\nWhen using the AWS Command Line Interface (AWS CLI) and AWS SDKs, you can use a parameter \nor \ufb02ag to change to a dual-stack endpoint. You can also specify the dual-stack endpoint directly as \nan override of the Amazon S3 endpoint in the con\ufb01g \ufb01le.", "The following sections describe how to \nuse dual-stack endpoints from the AWS CLI and the AWS SDKs.\nUsing dual-stack endpoints from the AWS CLI\nThis section provides examples of AWS CLI commands used to make requests to a dual-stack \nendpoint. For instructions on setting up the AWS CLI, see Developing with Amazon S3 using the \nAWS CLI.\nYou set the con\ufb01guration value use_dualstack_endpoint  to true in a pro\ufb01le in your AWS \nCon\ufb01g \ufb01le to direct all Amazon S3 requests made by the s3 and s3api AWS CLI commands to \nthe dual-stack endpoint for the speci\ufb01ed region. You specify the region in the con\ufb01g \ufb01le or in a \ncommand using the --region  option.\nWhen using dual-stack endpoints with the AWS CLI, both path  and virtual addressing styles \nare supported.", "The addressing style, set in the con\ufb01g \ufb01le, controls if the bucket name is in the \nhostname or part of the URL.", "By default, the CLI will attempt to use virtual style where possible, \nbut will fall back to path style if necessary.", "For more information, see AWS CLI Amazon S3 \nCon\ufb01guration .\nYou can also make con\ufb01guration changes by using a command, as shown in the following example, \nwhich sets use_dualstack_endpoint  to true  and addressing_style  to virtual  in the \ndefault pro\ufb01le.\n$ aws configure set default.s3.use_dualstack_endpoint true\n$ aws configure set default.s3.addressing_style virtual\nIf you want to use a dual-stack endpoint for speci\ufb01ed AWS CLI commands only (not all commands), \nyou can use either of the following methods:\nMaking requests over IPv6 API Version 2006-03-01 1610Amazon Simple Storage Service API Reference\n\u2022You can use the dual-stack endpoint per command by setting the --endpoint-url\nparameter to https://s3.dualstack. aws-region .amazonaws.com  or http://\ns3.dualstack. aws-region .amazonaws.com  for any s3 or s3api command.\n$ aws s3api list-objects --bucket bucketname  --endpoint-url https://s3.dualstack. aws-\nregion.amazonaws.com\n\u2022You can set up separate pro\ufb01les in your AWS Con\ufb01g \ufb01le.", "For example, create one \npro\ufb01le that sets use_dualstack_endpoint  to true and a pro\ufb01le that does not set\nuse_dualstack_endpoint . When you run a command, specify which pro\ufb01le you want to use, \ndepending upon whether or not you want to use the dual-stack endpoint.\nNote\nWhen using the AWS CLI you currently cannot use transfer acceleration with dual-stack \nendpoints. However, support for the AWS CLI is coming soon.", "For more information, see\nEnabling and using S3 Transfer Acceleration .\nUsing dual-stack endpoints from the AWS SDKs\nThis section provides examples of how to access a dual-stack endpoint by using the AWS SDKs.\nAWS SDK for Java dual-stack endpoint example\nThe following example shows how to enable dual-stack endpoints when creating an Amazon S3 \nclient using the AWS SDK for Java.\nFor instructions on creating and testing a working Java sample, see Getting Started in the AWS SDK \nfor Java Developer Guide.\nimport com.amazonaws.AmazonServiceException;\nimport com.amazonaws.SdkClientException;\nimport com.amazonaws.auth.profile.ProfileCredentialsProvider;\nimport com.amazonaws.regions.Regions;\nimport com.amazonaws.services.s3.AmazonS3;\nimport com.amazonaws.services.s3.AmazonS3ClientBuilder;\npublic class DualStackEndpoints { \nMaking requests over IPv6 API Version 2006-03-01 1611Amazon Simple Storage Service API Reference\n    public static void main(String[] args) { \n        Regions clientRegion = Regions.DEFAULT_REGION; \n        String bucketName = \"*** Bucket name ***\"; \n        try { \n            // Create an Amazon S3 client with dual-stack endpoints enabled. \n            AmazonS3 s3Client = AmazonS3ClientBuilder.standard() \n                    .withCredentials(new ProfileCredentialsProvider()) \n                    .withRegion(clientRegion) \n                    .withDualstackEnabled(true) \n                    .build(); \n            s3Client.listObjects(bucketName); \n        } catch (AmazonServiceException e) { \n            // The call was transmitted successfully, but Amazon S3 couldn't process \n            // it, so it returned an error response. \n            e.printStackTrace(); \n        } catch (SdkClientException e) { \n            // Amazon S3 couldn't be contacted for a response, or the client \n            // couldn't parse the response from Amazon S3. \n            e.printStackTrace(); \n        } \n    }\n}\nIf you are using the AWS SDK for Java on Windows, you might have to set the following Java virtual \nmachine (JVM) property:\njava.net.preferIPv6Addresses=true\nAWS .NET SDK dual-stack endpoint example\nWhen using the AWS SDK for .NET you use the AmazonS3Config  class to enable the use of a dual-\nstack endpoint as shown in the following example.\nusing Amazon;\nusing Amazon.S3;\nusing Amazon.S3.Model;\nusing System;\nusing System.Threading.Tasks;\nMaking requests over IPv6 API Version 2006-03-01 1612Amazon Simple Storage Service API Reference\nnamespace Amazon.DocSamples.S3\n{ \n    class DualStackEndpointTest \n    { \n        private const string bucketName = \"*** bucket name ***\"; \n        // Specify your bucket region (an example region is shown). \n        private static readonly RegionEndpoint bucketRegion = RegionEndpoint.USWest2; \n        private static IAmazonS3 client; \n        public static void Main() \n        { \n            var config = new AmazonS3Config \n            { \n                UseDualstackEndpoint = true, \n                RegionEndpoint = bucketRegion \n            }; \n            client = new AmazonS3Client(config); \n            Console.WriteLine(\"Listing objects stored in a bucket\"); \n            ListingObjectsAsync().Wait(); \n        } \n        private static async Task ListingObjectsAsync() \n        { \n            try \n            { \n                var request = new ListObjectsV2Request \n                { \n                    BucketName = bucketName, \n                    MaxKeys = 10 \n                }; \n                ListObjectsV2Response response; \n                do \n                { \n                    response = await client.ListObjectsV2Async(request); \n                    // Process the response. \n                    foreach (S3Object entry in response.S3Objects) \n                    { \n                        Console.WriteLine(\"key = {0} size = {1}\", \n                            entry.Key, entry.Size); \n                    } \n                    Console.WriteLine(\"Next Continuation Token: {0}\", \n response.NextContinuationToken); \n                    request.ContinuationToken = response.NextContinuationToken; \nMaking requests over IPv6 API Version 2006-03-01 1613Amazon Simple Storage Service API Reference\n                } while (response.IsTruncated == true); \n            } \n            catch (AmazonS3Exception amazonS3Exception) \n            { \n                Console.WriteLine(\"An AmazonS3Exception was thrown. Exception: \" + \n amazonS3Exception.ToString()); \n            } \n            catch (Exception e) \n            { \n                Console.WriteLine(\"Exception: \" + e.ToString()); \n            } \n        } \n    }\n}\nFor information about setting up and running the code examples, see Getting Started with the \nAWS SDK for .NET in the AWS SDK for .NET Developer Guide.\nUsing dual-stack endpoints from the REST API\nFor information about making requests to dual-stack endpoints by using the REST API, see Making \nrequests to dual-stack endpoints by using the REST API.\nMaking requests over IPv6 API Version 2006-03-01 1614Amazon Simple Storage Service API Reference\nMaking requests using the AWS SDKs\nTopics\n\u2022Making requests using AWS account or IAM user credentials\n\u2022Making requests using IAM user temporary credentials\n\u2022Making requests using federated user temporary credentials\nYou can send authenticated requests to Amazon S3 using either the AWS SDK or by making the \nREST API calls directly in your application. The AWS SDK API uses the credentials that you provide \nto compute the signature for authentication.", "If you use the REST API directly in your applications, \nyou must write the necessary code to compute the signature for authenticating your request.", "For a \nlist of available AWS SDKs go to, Sample Code and Libraries .\nMaking requests using AWS account or IAM user credentials\nYou can use your AWS account or IAM user security credentials to send authenticated requests to \nAmazon S3.", "This section provides examples of how you can send authenticated requests using the \nAWS SDK for Java, AWS SDK for .NET, and AWS SDK for PHP. For a list of available AWS SDKs, go to\nSample Code and Libraries .\nEach of these AWS SDKs uses an SDK-speci\ufb01c credentials provider chain to \ufb01nd and use credentials \nand perform actions on behalf of the credentials owner. What all these credentials provider chains \nhave in common is that they all look for your local AWS credentials \ufb01le.\nFor more information, see the topics below:\nTopics\n\u2022To create a local AWS credentials \ufb01le\n\u2022Sending authenticated requests using the AWS SDKs\nTo create a local AWS credentials \ufb01le\nThe easiest way to con\ufb01gure credentials for your AWS SDKs is to use an AWS credentials \ufb01le. If you \nuse the AWS Command Line Interface (AWS CLI), you may already have a local AWS credentials \ufb01le \ncon\ufb01gured. Otherwise, use the following procedure to set up a credentials \ufb01le:\n1.", "Sign in to the AWS Management Console and open the IAM console at https:// \nconsole.aws.amazon.com/iam/.\nMaking requests using the AWS SDKs API Version 2006-03-01 1615Amazon Simple Storage Service API Reference\n2.", "Create a new user with permissions limited to the services and actions that you want your code \nto have access to.", "For more information about creating a new user, see Creating IAM users \n(Console), and follow the instructions through step 8.\n3.", "Choose Download .csv to save a local copy of your AWS credentials.\n4. On your computer, navigate to your home directory, and create an .aws directory. On Unix-\nbased systems, such as Linux or OS X, this is in the following location:\n~/.aws\nOn Windows, this is in the following location:\n%HOMEPATH%\\.aws\n5.", "In the .aws directory, create a new \ufb01le named credentials .\n6. Open the credentials .csv \ufb01le that you downloaded from the IAM console, and copy its \ncontents into the credentials  \ufb01le using the following format:\n[default]\naws_access_key_id = your_access_key_id\naws_secret_access_key = your_secret_access_key\n7. Save the credentials  \ufb01le, and delete the .csv \ufb01le that you downloaded in step 3.\nYour shared credentials \ufb01le is now con\ufb01gured on your local computer, and it's ready to be used with \nthe AWS SDKs.\nSending authenticated requests using the AWS SDKs\nUse the AWS SDKs to send authenticated requests.", "For more information about sending \nauthenticated requests, see AWS security credentials or IAM Identity Center Authentication.\nJava\nTo send authenticated requests to Amazon S3 using your AWS account or IAM user credentials, \ndo the following:\n\u2022Use the AmazonS3ClientBuilder  class to create an AmazonS3Client  instance.\nMaking requests using the AWS SDKs API Version 2006-03-01 1616Amazon Simple Storage Service API Reference\n\u2022Run one of the AmazonS3Client  methods to send requests to Amazon S3.", "The client \ngenerates the necessary signature from the credentials that you provide and includes it in the \nrequest.\nThe following example performs the preceding tasks.", "For information on creating and testing a \nworking sample, see Getting Started in the AWS SDK for Java Developer Guide.\nExample\nimport com.amazonaws.AmazonServiceException;\nimport com.amazonaws.SdkClientException;\nimport com.amazonaws.auth.profile.ProfileCredentialsProvider;\nimport com.amazonaws.regions.Regions;\nimport com.amazonaws.services.s3.AmazonS3;\nimport com.amazonaws.services.s3.AmazonS3ClientBuilder;\nimport com.amazonaws.services.s3.model.ListObjectsRequest;\nimport com.amazonaws.services.s3.model.ObjectListing;\nimport com.amazonaws.services.s3.model.S3ObjectSummary;\nimport java.io.IOException;\nimport java.util.List;\npublic class MakingRequests { \n    public static void main(String[] args) throws IOException { \n        Regions clientRegion = Regions.DEFAULT_REGION; \n        String bucketName = \"*** Bucket name ***\"; \n        try { \n            AmazonS3 s3Client = AmazonS3ClientBuilder.standard() \n                    .withCredentials(new ProfileCredentialsProvider()) \n                    .withRegion(clientRegion) \n                    .build(); \n            // Get a list of objects in the bucket, two at a time, and \n            // print the name and size of each object. \n            ListObjectsRequest listRequest = new \n ListObjectsRequest().withBucketName(bucketName).withMaxKeys(2); \n            ObjectListing objects = s3Client.listObjects(listRequest); \n            while (true) { \n                List<S3ObjectSummary> summaries = objects.getObjectSummaries(); \nMaking requests using the AWS SDKs API Version 2006-03-01 1617Amazon Simple Storage Service API Reference\n                for (S3ObjectSummary summary : summaries) { \n                    System.out.printf(\"Object \\\"%s\\\" retrieved with size %d\\n\", \n summary.getKey(), summary.getSize()); \n                } \n                if (objects.isTruncated()) { \n                    objects = s3Client.listNextBatchOfObjects(objects); \n                } else { \n                    break; \n                } \n            } \n        } catch (AmazonServiceException e) { \n            // The call was transmitted successfully, but Amazon S3 couldn't process \n            // it, so it returned an error response. \n            e.printStackTrace(); \n        } catch (SdkClientException e) { \n            // Amazon S3 couldn't be contacted for a response, or the client \n            // couldn't parse the response from Amazon S3. \n            e.printStackTrace(); \n        } \n    }\n}\n.NET\nTo send authenticated requests using your AWS account or IAM user credentials:\n\u2022Create an instance of the AmazonS3Client  class.\n\u2022Run one of the AmazonS3Client  methods to send requests to Amazon S3. The client \ngenerates the necessary signature from the credentials that you provide and includes it in the \nrequest it sends to Amazon S3.\nFor more information, see Making requests using AWS account or IAM user credentials >.\nNote\n\u2022You can create the AmazonS3Client  client without providing your security \ncredentials.", "Requests sent using this client are anonymous requests, without a \nsignature.", "Amazon S3 returns an error if you send anonymous requests for a resource \nthat is not publicly available.\nMaking requests using the AWS SDKs API Version 2006-03-01 1618Amazon Simple Storage Service API Reference\n\u2022You can create an AWS account and create the required users.", "You can also manage \ncredentials for those users. You need these credentials to perform the task in the \nfollowing example. For more information, see Con\ufb01gure AWS credentials in the AWS \nSDK for .NET Developer Guide .\nYou can then also con\ufb01gure your application to actively retrieve pro\ufb01les and \ncredentials, and then explicitly use those credentials when creating an AWS service \nclient. For more information, see Accessing credentials and pro\ufb01les in an application\nin the AWS SDK for .NET Developer Guide.\nThe following C# example shows how to perform the preceding tasks.", "For information about \nsetting up and running the code examples, see Getting Started with the AWS SDK for .NET in \nthe AWS SDK for .NET Developer Guide.\nExample\nusing Amazon;\nusing Amazon.S3;\nusing Amazon.S3.Model;\nusing System;\nusing System.Threading.Tasks;\nnamespace Amazon.DocSamples.S3\n{ \n    class MakeS3RequestTest \n    { \n        private const string bucketName = \"*** bucket name ***\";  \n        // Specify your bucket region (an example region is shown). \n        private static readonly RegionEndpoint bucketRegion = \n RegionEndpoint.USWest2; \n        private static IAmazonS3 client; \n        public static void Main() \n        { \n            using (client = new AmazonS3Client(bucketRegion)) \n            { \n                Console.WriteLine(\"Listing objects stored in a bucket\"); \n                ListingObjectsAsync().Wait(); \n            } \n        } \nMaking requests using the AWS SDKs API Version 2006-03-01 1619Amazon Simple Storage Service API Reference\n        static async Task ListingObjectsAsync() \n        { \n            try \n            { \n                ListObjectsRequest request = new ListObjectsRequest \n                { \n                    BucketName = bucketName, \n                    MaxKeys = 2 \n                }; \n                do \n                { \n                    ListObjectsResponse response = await \n client.ListObjectsAsync(request); \n                    // Process the response.", "\n                    foreach (S3Object entry in response.S3Objects) \n                    { \n                        Console.WriteLine(\"key = {0} size = {1}\", \n                            entry.Key, entry.Size); \n                    } \n                    // If the response is truncated, set the marker to get the next  \n                    // set of keys.", "\n                    if (response.IsTruncated) \n                    { \n                        request.Marker = response.NextMarker; \n                    } \n                    else \n                    { \n                        request = null; \n                    } \n                } while (request != null); \n            } \n            catch (AmazonS3Exception e) \n            { \n                Console.WriteLine(\"Error encountered on server.", "Message:'{0}' when \n writing an object\", e.Message); \n            } \n            catch (Exception e) \n            { \n                Console.WriteLine(\"Unknown encountered on server.", "Message:'{0}' when \n writing an object\", e.Message); \n            } \n        } \nMaking requests using the AWS SDKs API Version 2006-03-01 1620Amazon Simple Storage Service API Reference\n    }\n}\nPHP\nThe following PHP example shows how the client makes a request using your security \ncredentials to list all of the buckets for your account.\nExample\n \nrequire 'vendor/autoload.php';\nuse Aws\\S3\\Exception\\S3Exception;\nuse Aws\\S3\\S3Client;\n$bucket = '*** Your Bucket Name ***';\n$s3 = new S3Client([ \n    'region' => 'us-east-1', \n    'version' => 'latest',\n]);\n// Retrieve the list of buckets.\n$result = $s3->listBuckets();\ntry { \n    // Retrieve a paginator for listing objects. \n    $objects = $s3->getPaginator('ListObjects', [ \n        'Bucket' => $bucket \n    ]); \n    echo \"Keys retrieved!\" .", "PHP_EOL; \n    // Print the list of objects to the page.", "\n    foreach ($objects as $object) { \n        echo $object['Key'] .", "PHP_EOL; \n    }\n} catch (S3Exception $e) { \n    echo $e->getMessage() . PHP_EOL;\n}\nMaking requests using the AWS SDKs API Version 2006-03-01 1621Amazon Simple Storage Service API Reference\nNote\nYou can create the S3Client  client without providing your security credentials.", "\nRequests sent using this client are anonymous requests, without a signature.", "Amazon \nS3 returns an error if you send anonymous requests for a resource that is not publicly \navailable. For more information, see Creating Anonymous Clients in the AWS SDK for \nPHP Documentation .\nRuby\nBefore you can use version 3 of the AWS SDK for Ruby to make calls to Amazon S3, you must \nset the AWS access credentials that the SDK uses to verify your access to your buckets and \nobjects. If you have shared credentials set up in the AWS credentials pro\ufb01le on your local \nsystem, version 3 of the SDK for Ruby can use those credentials without your having to declare \nthem in your code. For more information about setting up shared credentials, see Making \nrequests using AWS account or IAM user credentials .\nThe following Ruby code snippet uses the credentials in a shared AWS credentials \ufb01le on a local \ncomputer to authenticate a request to get all of the object key names in a speci\ufb01c bucket.", "It \ndoes the following:\n1.Creates an instance of the Aws::S3::Client  class.\n2.Makes a request to Amazon S3 by enumerating objects in a bucket using the\nlist_objects_v2  method of Aws::S3::Client . The client generates the necessary \nsignature value from the credentials in the AWS credentials \ufb01le on your computer, and \nincludes it in the request it sends to Amazon S3.\n3.Prints the array of object key names to the terminal.\nExample\n# Prerequisites:\n#  - An existing Amazon S3 bucket.\nrequire 'aws-sdk-s3'\n# @param s3_client [Aws::S3::Client] An initialized Amazon S3 client.\nMaking requests using the AWS SDKs API Version 2006-03-01 1622Amazon Simple Storage Service API Reference\n# @param bucket_name [String] The bucket's name.\n# @return [Boolean] true if all operations succeed; otherwise, false.\n# @example\n#   s3_client = Aws::S3::Client.new(region: 'us-west-2')\n#   exit 1 unless list_bucket_objects?(s3_client, 'amzn-s3-demo-bucket')\ndef list_bucket_objects?(s3_client, bucket_name) \n  puts \"Accessing the bucket named '#{bucket_name}'...\" \n  objects = s3_client.list_objects_v2( \n    bucket: bucket_name, \n    max_keys: 50 \n  ) \n  if objects.count.positive? \n    puts 'The object keys in this bucket are (first 50 objects):' \n    objects.contents.each do |object| \n      puts object.key \n    end \n  else \n    puts 'No objects found in this bucket.' \n  end \n  true\nrescue StandardError => e \n  puts \"Error while accessing the bucket named '#{bucket_name}': #{e.message}\" \n  false\nend\n# Example usage:\ndef run_me \n  region = 'us-west-2' \n  bucket_name = 'BUCKET_NAME' \n  s3_client = Aws::S3::Client.new(region: region) \n  exit 1 unless list_bucket_objects?(s3_client, bucket_name)\nend\nrun_me if $PROGRAM_NAME == __FILE__\nIf you don't have a local AWS credentials \ufb01le, you can still create the Aws::S3::Client\nresource and run code against Amazon S3 buckets and objects.", "Requests that are sent using \nversion 3 of the SDK for Ruby are anonymous, with no signature by default.", "Amazon S3 returns \nan error if you send anonymous requests for a resource that's not publicly available.\nMaking requests using the AWS SDKs API Version 2006-03-01 1623Amazon Simple Storage Service API Reference\nYou can use and expand the previous code snippet for SDK for Ruby applications, as in the \nfollowing more robust example.\n# Prerequisites:\n#  - An existing Amazon S3 bucket.\nrequire 'aws-sdk-s3'\n# @param s3_client [Aws::S3::Client] An initialized Amazon S3 client.\n# @param bucket_name [String] The bucket's name.\n# @return [Boolean] true if all operations succeed; otherwise, false.\n# @example\n#   s3_client = Aws::S3::Client.new(region: 'us-west-2')\n#   exit 1 unless list_bucket_objects?(s3_client, 'amzn-s3-demo-bucket')\ndef list_bucket_objects?(s3_client, bucket_name) \n  puts \"Accessing the bucket named '#{bucket_name}'...\" \n  objects = s3_client.list_objects_v2( \n    bucket: bucket_name, \n    max_keys: 50 \n  ) \n  if objects.count.positive? \n    puts 'The object keys in this bucket are (first 50 objects):' \n    objects.contents.each do |object| \n      puts object.key \n    end \n  else \n    puts 'No objects found in this bucket.' \n  end \n  true\nrescue StandardError => e \n  puts \"Error while accessing the bucket named '#{bucket_name}': #{e.message}\" \n  false\nend\n# Example usage:\ndef run_me \n  region = 'us-west-2' \n  bucket_name = 'BUCKET_NAME' \n  s3_client = Aws::S3::Client.new(region: region) \nMaking requests using the AWS SDKs API Version 2006-03-01 1624Amazon Simple Storage Service API Reference\n  exit 1 unless list_bucket_objects?(s3_client, bucket_name)\nend\nrun_me if $PROGRAM_NAME == __FILE__\nGo\nExample\nThe following example uses AWS credentials automatically loaded by the SDK for Go from the \nshared credentials \ufb01le.\npackage main\nimport ( \n \"context\" \n \"fmt\" \n \"github.com/aws/aws-sdk-go-v2/config\" \n \"github.com/aws/aws-sdk-go-v2/service/s3\"\n)\n// main uses the AWS SDK for Go V2 to create an Amazon Simple Storage Service\n// (Amazon S3) client and list up to 10 buckets in your account.\n// This example uses the default settings specified in your shared credentials\n// and config files.\nfunc main() { \n ctx := context.Background() \n sdkConfig, err := config.LoadDefaultConfig(ctx) \n if err != nil { \n  fmt.Println(\"Couldn't load default configuration. Have you set up your AWS \n account?\") \n  fmt.Println(err) \n  return \n } \n s3Client := s3.NewFromConfig(sdkConfig) \n count := 10 \n fmt.Printf(\"Let's list up to %v buckets for your account.\\n\", count) \n result, err := s3Client.ListBuckets(ctx, &s3.ListBucketsInput{}) \n if err != nil { \n  fmt.Printf(\"Couldn't list buckets for your account. Here's why: %v\\n\", err) \n  return \nMaking requests using the AWS SDKs API Version 2006-03-01 1625Amazon Simple Storage Service API Reference\n } \n if len(result.Buckets) == 0 { \n  fmt.Println(\"You don't have any buckets!\") \n } else { \n  if count > len(result.Buckets) { \n   count = len(result.Buckets) \n  } \n  for _, bucket := range result.Buckets[:count] { \n   fmt.Printf(\"\\t%v\\n\", *bucket.Name) \n  } \n }\n}\nMaking requests using the AWS SDKs API Version 2006-03-01 1626Amazon Simple Storage Service API Reference\nMaking requests using IAM user temporary credentials\nAn AWS account or an IAM user can request temporary security credentials and use them to send \nauthenticated requests to Amazon S3. This section provides examples of how to use the AWS SDK \nfor Java, .NET, and PHP to obtain temporary security credentials and use them to authenticate your \nrequests to Amazon S3.\nJava\nAn IAM user or an AWS account can request temporary security credentials (see Making \nrequests) using the AWS SDK for Java and use them to access Amazon S3.", "These credentials \nexpire after the speci\ufb01ed session duration.\nBy default, the session duration is one hour. If you use IAM user credentials, you can specify the \nduration when requesting the temporary security credentials from 15 minutes to the maximum \nsession duration for the role. For more information about temporary security credentials, see\nTemporary Security Credentials in the IAM User Guide .", "For more information about making \nrequests, see Making requests.\nTo get temporary security credentials and access Amazon S3\n1.", "Create an instance of the AWSSecurityTokenService  class.\n2.", "Retrieve the temporary security credentials for the desired role by calling the\nassumeRole()  method of the Security Token Service (STS) client.\n3.", "Package the temporary security credentials into a BasicSessionCredentials  object.", "\nYou use this object to provide the temporary security credentials to your Amazon S3 client.\n4. Create an instance of the AmazonS3Client  class using the temporary security credentials. \nYou send requests to Amazon S3 using this client. If you send requests using expired \ncredentials, Amazon S3 will return an error.\nNote\nThe following example lists a set of object keys in the speci\ufb01ed bucket. The example obtains \ntemporary security credentials for a session and uses them to send an authenticated request to \nAmazon S3.\nMaking requests using the AWS SDKs API Version 2006-03-01 1627Amazon Simple Storage Service API Reference\nIf you want to test the sample by using IAM user credentials, you must create an IAM user under \nyour AWS account. For more information about how to create an IAM user, see Creating Your \nFirst IAM user and Administrators Group in the IAM User Guide .\nFor instructions on creating and testing a working sample, see Getting Started in the AWS SDK \nfor Java Developer Guide.\nimport com.amazonaws.AmazonServiceException;\nimport com.amazonaws.SdkClientException;\nimport com.amazonaws.auth.AWSStaticCredentialsProvider;\nimport com.amazonaws.auth.BasicSessionCredentials;\nimport com.amazonaws.auth.profile.ProfileCredentialsProvider;\nimport com.amazonaws.services.s3.AmazonS3;\nimport com.amazonaws.services.s3.AmazonS3ClientBuilder;\nimport com.amazonaws.services.s3.model.ObjectListing;\nimport com.amazonaws.services.securitytoken.AWSSecurityTokenService;\nimport com.amazonaws.services.securitytoken.AWSSecurityTokenServiceClientBuilder;\nimport com.amazonaws.services.securitytoken.model.AssumeRoleRequest;\nimport com.amazonaws.services.securitytoken.model.AssumeRoleResult;\nimport com.amazonaws.services.securitytoken.model.Credentials;\npublic class MakingRequestsWithIAMTempCredentials { \n    public static void main(String[] args) { \n        String clientRegion = \"*** Client region ***\"; \n        String roleARN = \"*** ARN for role to be assumed ***\"; \n        String roleSessionName = \"*** Role session name ***\"; \n        String bucketName = \"*** Bucket name ***\"; \n        try { \n            // Creating the STS client is part of your trusted code.", "It has \n            // the security credentials you use to obtain temporary security \n credentials.", "\n            AWSSecurityTokenService stsClient = \n AWSSecurityTokenServiceClientBuilder.standard() \n                    .withCredentials(new ProfileCredentialsProvider()) \n                    .withRegion(clientRegion) \n                    .build(); \n            // Obtain credentials for the IAM role.", "Note that you cannot assume the \n role of \n            // an AWS root account; \nMaking requests using the AWS SDKs API Version 2006-03-01 1628Amazon Simple Storage Service API Reference\n            // Amazon S3 will deny access.", "You must use credentials for an IAM user \n or an \n            // IAM role.", "\n            AssumeRoleRequest roleRequest = new AssumeRoleRequest() \n                    .withRoleArn(roleARN) \n                    .withRoleSessionName(roleSessionName); \n            AssumeRoleResult roleResponse = stsClient.assumeRole(roleRequest); \n            Credentials sessionCredentials = roleResponse.getCredentials(); \n            // Create a BasicSessionCredentials object that contains the credentials \n you \n            // just retrieved.", "\n            BasicSessionCredentials awsCredentials = new BasicSessionCredentials( \n                    sessionCredentials.getAccessKeyId(), \n                    sessionCredentials.getSecretAccessKey(), \n                    sessionCredentials.getSessionToken()); \n            // Provide temporary security credentials so that the Amazon S3 client \n            // can send authenticated requests to Amazon S3.", "You create the client \n            // using the sessionCredentials object.", "\n            AmazonS3 s3Client = AmazonS3ClientBuilder.standard() \n                    .withCredentials(new \n AWSStaticCredentialsProvider(awsCredentials)) \n                    .withRegion(clientRegion) \n                    .build(); \n            // Verify that assuming the role worked and the permissions are set \n correctly \n            // by getting a set of object keys from the bucket. \n            ObjectListing objects = s3Client.listObjects(bucketName); \n            System.out.println(\"No. of Objects: \" + \n objects.getObjectSummaries().size()); \n        } catch (AmazonServiceException e) { \n            // The call was transmitted successfully, but Amazon S3 couldn't process \n            // it, so it returned an error response. \n            e.printStackTrace(); \n        } catch (SdkClientException e) { \n            // Amazon S3 couldn't be contacted for a response, or the client \n            // couldn't parse the response from Amazon S3. \n            e.printStackTrace(); \n        } \n    }\n}\nMaking requests using the AWS SDKs API Version 2006-03-01 1629Amazon Simple Storage Service API Reference\n.NET\nAn IAM user or an AWS account can request temporary security credentials using the AWS SDK \nfor .NET and use them to access Amazon S3.", "These credentials expire after the session duration.\nBy default, the session duration is one hour. If you use IAM user credentials, you can specify the \nduration when requesting the temporary security credentials from 15 minutes to the maximum \nsession duration for the role. For more information about temporary security credentials, see\nTemporary Security Credentials in the IAM User Guide .", "For more information about making \nrequests, see Making requests.\nTo get temporary security credentials and access Amazon S3\n1.", "Create an instance of the AWS Security Token Service client,\nAmazonSecurityTokenServiceClient .\n2.", "Start a session by calling the GetSessionToken  method of the STS client you \ncreated in the preceding step.", "You provide session information to this method using a\nGetSessionTokenRequest  object.\nThe method returns your temporary security credentials.\n3. Package the temporary security credentials in an instance of the\nSessionAWSCredentials  object.", "You use this object to provide the temporary security \ncredentials to your Amazon S3 client.\n4. Create an instance of the AmazonS3Client  class by passing in the temporary security \ncredentials. You send requests to Amazon S3 using this client. If you send requests using \nexpired credentials, Amazon S3 returns an error.\nNote\nThe following C# example lists object keys in the speci\ufb01ed bucket. For illustration, the example \nobtains temporary security credentials for a default one-hour session and uses them to send \nauthenticated request to Amazon S3.\nMaking requests using the AWS SDKs API Version 2006-03-01 1630Amazon Simple Storage Service API Reference\nIf you want to test the sample by using IAM user credentials, you must create an IAM user under \nyour AWS account.", "For more information about how to create an IAM user, see Creating Your \nFirst IAM user and Administrators Group in the IAM User Guide .", "For more information about \nmaking requests, see Making requests.\nFor information about setting up and running the code examples, see Getting Started with the \nAWS SDK for .NET in the AWS SDK for .NET Developer Guide.\nusing Amazon;\nusing Amazon.Runtime;\nusing Amazon.S3;\nusing Amazon.S3.Model;\nusing Amazon.SecurityToken;\nusing Amazon.SecurityToken.Model;\nusing System;\nusing System.Collections.Generic;\nusing System.Threading.Tasks;\nnamespace Amazon.DocSamples.S3\n{ \n    class TempCredExplicitSessionStartTest \n    { \n        private const string bucketName = \"*** bucket name ***\"; \n        // Specify your bucket region (an example region is shown). \n        private static readonly RegionEndpoint bucketRegion = \n RegionEndpoint.USWest2; \n        private static IAmazonS3 s3Client; \n        public static void Main() \n        { \n            ListObjectsAsync().Wait(); \n        } \n        private static async Task ListObjectsAsync() \n        { \n            try \n            { \n                // Credentials use the default AWS SDK for .NET credential search \n chain.", "\n                // On local development machines, this is your default profile.", "\n                Console.WriteLine(\"Listing objects stored in a bucket\"); \n                SessionAWSCredentials tempCredentials = await \n GetTemporaryCredentialsAsync(); \nMaking requests using the AWS SDKs API Version 2006-03-01 1631Amazon Simple Storage Service API Reference\n                // Create a client by providing temporary security credentials.", "\n                using (s3Client = new AmazonS3Client(tempCredentials, bucketRegion)) \n                { \n                    var listObjectRequest = new ListObjectsRequest \n                    { \n                        BucketName = bucketName \n                    }; \n                    // Send request to Amazon S3. \n                    ListObjectsResponse response = await \n s3Client.ListObjectsAsync(listObjectRequest); \n                    List<S3Object> objects = response.S3Objects; \n                    Console.WriteLine(\"Object count = {0}\", objects.Count); \n                } \n            } \n            catch (AmazonS3Exception s3Exception) \n            { \n                Console.WriteLine(s3Exception.Message, s3Exception.InnerException); \n            } \n            catch (AmazonSecurityTokenServiceException stsException) \n            { \n                Console.WriteLine(stsException.Message, \n stsException.InnerException); \n            } \n        } \n        private static async Task<SessionAWSCredentials> \n GetTemporaryCredentialsAsync() \n        { \n            using (var stsClient = new AmazonSecurityTokenServiceClient()) \n            { \n                var getSessionTokenRequest = new GetSessionTokenRequest \n                { \n                    DurationSeconds = 7200 // seconds \n                }; \n                GetSessionTokenResponse sessionTokenResponse = \n                              await \n stsClient.GetSessionTokenAsync(getSessionTokenRequest); \n                Credentials credentials = sessionTokenResponse.Credentials; \n                var sessionCredentials = \n                    new SessionAWSCredentials(credentials.AccessKeyId, \n                                              credentials.SecretAccessKey, \nMaking requests using the AWS SDKs API Version 2006-03-01 1632Amazon Simple Storage Service API Reference\n                                              credentials.SessionToken); \n                return sessionCredentials; \n            } \n        } \n    }\n}\nPHP\nFor more information about the AWS SDK for Ruby API, go to AWS SDK for Ruby - Version 2.\nAn IAM user or an AWS account can request temporary security credentials using version 3 \nof the AWS SDK for PHP. It can then use the temporary credentials to access Amazon S3.", "The \ncredentials expire when the session duration expires.\nBy default, the session duration is one hour. If you use IAM user credentials, you can specify the \nduration when requesting the temporary security credentials from 15 minutes to the maximum \nsession duration for the role. For more information about temporary security credentials, see\nTemporary Security Credentials in the IAM User Guide .", "For more information about making \nrequests, see Making requests.\nNote\nExample\nThe following PHP example lists object keys in the speci\ufb01ed bucket using temporary security \ncredentials.", "The example obtains temporary security credentials for a default one-hour session, \nand uses them to send authenticated request to Amazon S3.", "For more information about the \nAWS SDK for Ruby API, go to AWS SDK for Ruby - Version 2.\nIf you want to test the example by using IAM user credentials, you must create an IAM user \nunder your AWS account.", "For information about how to create an IAM user, see Creating Your \nFirst IAM user and Administrators Group in the IAM User Guide .", "For examples of setting the \nsession duration when using IAM user credentials to request a session, see Making requests \nusing IAM user temporary credentials .\n require 'vendor/autoload.php';\nuse Aws\\S3\\Exception\\S3Exception;\nMaking requests using the AWS SDKs API Version 2006-03-01 1633Amazon Simple Storage Service API Reference\nuse Aws\\S3\\S3Client;\nuse Aws\\Sts\\StsClient;\n$bucket = '*** Your Bucket Name ***';\n$sts = new StsClient([ \n    'version' => 'latest', \n    'region' => 'us-east-1'\n]);\n$sessionToken = $sts->getSessionToken();\n$s3 = new S3Client([ \n    'region' => 'us-east-1', \n    'version' => 'latest', \n    'credentials' => [ \n        'key'    => $sessionToken['Credentials']['AccessKeyId'], \n        'secret' => $sessionToken['Credentials']['SecretAccessKey'], \n        'token'  => $sessionToken['Credentials']['SessionToken'] \n    ]\n]);\n$result = $s3->listBuckets();\ntry { \n    // Retrieve a paginator for listing objects. \n    $objects = $s3->getPaginator('ListObjects', [ \n        'Bucket' => $bucket \n    ]); \n    echo \"Keys retrieved!\" .", "PHP_EOL; \n    // List objects \n    foreach ($objects as $object) { \n        echo $object['Key'] .", "PHP_EOL; \n    }\n} catch (S3Exception $e) { \n    echo $e->getMessage() .", "PHP_EOL;\n}\nMaking requests using the AWS SDKs API Version 2006-03-01 1634Amazon Simple Storage Service API Reference\nRuby\nAn IAM user or an AWS account can request temporary security credentials using AWS SDK for \nRuby and use them to access Amazon S3.", "These credentials expire after the session duration.\nBy default, the session duration is one hour. If you use IAM user credentials, you can specify the \nduration when requesting the temporary security credentials from 15 minutes to the maximum \nsession duration for the role. For more information about temporary security credentials, see\nTemporary Security Credentials in the IAM User Guide .", "For more information about making \nrequests, see Making requests.\nNote\nThe following Ruby example creates a temporary user to list the items in a speci\ufb01ed bucket \nfor one hour.", "To use this example, you must have AWS credentials that have the necessary \npermissions to create new AWS Security Token Service (AWS STS) clients, and list Amazon S3 \nbuckets.\n# Prerequisites:\n# - A user in AWS Identity and Access Management (IAM).", "This user must\n#   be able to assume the following IAM role.", "You must run this code example\n#   within the context of this user.\n# - An existing role in IAM that allows all of the Amazon S3 actions for all of the\n#   resources in this code example. This role must also trust the preceding IAM \n user.\n# - An existing S3 bucket.\nrequire 'aws-sdk-core'\nrequire 'aws-sdk-s3'\nrequire 'aws-sdk-iam'\n# Checks whether a user exists in IAM.\n#\n# @param iam [Aws::IAM::Client] An initialized IAM client.\n# @param user_name [String] The user's name.\n# @return [Boolean] true if the user exists; otherwise, false.\n# @example\n#   iam_client = Aws::IAM::Client.new(region: 'us-west-2')\n#   exit 1 unless user_exists?(iam_client, 'my-user')\nMaking requests using the AWS SDKs API Version 2006-03-01 1635Amazon Simple Storage Service API Reference\ndef user_exists?(iam_client, user_name) \n  response = iam_client.get_user(user_name: user_name) \n  return true if response.user.user_name\nrescue Aws::IAM::Errors::NoSuchEntity \n  # User doesn't exist.\nrescue StandardError => e \n  puts 'Error while determining whether the user ' \\ \n    \"'#{user_name}' exists: #{e.message}\"\nend\n# Creates a user in IAM.\n#\n# @param iam_client [Aws::IAM::Client] An initialized IAM client.\n# @param user_name [String] The user's name.\n# @return [AWS:IAM::Types::User] The new user.\n# @example\n#   iam_client = Aws::IAM::Client.new(region: 'us-west-2')\n#   user = create_user(iam_client, 'my-user')\n#   exit 1 unless user.user_name\ndef create_user(iam_client, user_name) \n  response = iam_client.create_user(user_name: user_name) \n  response.user\nrescue StandardError => e \n  puts \"Error while creating the user '#{user_name}': #{e.message}\"\nend\n# Gets a user in IAM.\n#\n# @param iam_client [Aws::IAM::Client] An initialized IAM client.\n# @param user_name [String] The user's name.\n# @return [AWS:IAM::Types::User] The existing user.\n# @example\n#   iam_client = Aws::IAM::Client.new(region: 'us-west-2')\n#   user = get_user(iam_client, 'my-user')\n#   exit 1 unless user.user_name\ndef get_user(iam_client, user_name) \n  response = iam_client.get_user(user_name: user_name) \n  response.user\nrescue StandardError => e \n  puts \"Error while getting the user '#{user_name}': #{e.message}\"\nend\n# Checks whether a role exists in IAM.\n#\nMaking requests using the AWS SDKs API Version 2006-03-01 1636Amazon Simple Storage Service API Reference\n# @param iam_client [Aws::IAM::Client] An initialized IAM client.\n# @param role_name [String] The role's name.\n# @return [Boolean] true if the role exists; otherwise, false.\n# @example\n#   iam_client = Aws::IAM::Client.new(region: 'us-west-2')\n#   exit 1 unless role_exists?(iam_client, 'my-role')\ndef role_exists?(iam_client, role_name) \n  response = iam_client.get_role(role_name: role_name) \n  return true if response.role.role_name\nrescue StandardError => e \n  puts 'Error while determining whether the role ' \\ \n    \"'#{role_name}' exists: #{e.message}\"\nend\n# Gets credentials for a role in IAM.\n#\n# @param sts_client [Aws::STS::Client] An initialized AWS STS client.\n# @param role_arn [String] The role's Amazon Resource Name (ARN).\n# @param role_session_name [String] A name for this role's session.\n# @param duration_seconds [Integer] The number of seconds this session is valid.\n# @return [AWS::AssumeRoleCredentials] The credentials.\n# @example\n#   sts_client = Aws::STS::Client.new(region: 'us-west-2')\n#   credentials = get_credentials(\n#     sts_client,\n#     'arn:aws:iam::123456789012:role/AmazonS3ReadOnly',\n#     'ReadAmazonS3Bucket',\n#     3600\n#   )\n#   exit 1 if credentials.nil?\ndef get_credentials(sts_client, role_arn, role_session_name, duration_seconds) \n  Aws::AssumeRoleCredentials.new( \n    client: sts_client, \n    role_arn: role_arn, \n    role_session_name: role_session_name, \n    duration_seconds: duration_seconds \n  )\nrescue StandardError => e \n  puts \"Error while getting credentials: #{e.message}\"\nend\n# Checks whether a bucket exists in Amazon S3.\n#\n# @param s3_client [Aws::S3::Client] An initialized Amazon S3 client.\nMaking requests using the AWS SDKs API Version 2006-03-01 1637Amazon Simple Storage Service API Reference\n# @param bucket_name [String] The name of the bucket.\n# @return [Boolean] true if the bucket exists; otherwise, false.\n# @example\n#   s3_client = Aws::S3::Client.new(region: 'us-west-2')\n#   exit 1 unless bucket_exists?(s3_client, 'amzn-s3-demo-bucket')\ndef bucket_exists?(s3_client, bucket_name) \n  response = s3_client.list_buckets \n  response.buckets.each do |bucket| \n    return true if bucket.name == bucket_name \n  end\nrescue StandardError => e \n  puts \"Error while checking whether the bucket '#{bucket_name}' \" \\ \n    \"exists: #{e.message}\"\nend\n# Lists the keys and ETags for the objects in an Amazon S3 bucket.\n#\n# @param s3_client [Aws::S3::Client] An initialized Amazon S3 client.\n# @param bucket_name [String] The bucket's name.\n# @return [Boolean] true if the objects were listed; otherwise, false.\n# @example\n#   s3_client = Aws::S3::Client.new(region: 'us-west-2')\n#   exit 1 unless list_objects_in_bucket?(s3_client, 'amzn-s3-demo-bucket')\ndef list_objects_in_bucket?(s3_client, bucket_name) \n  puts \"Accessing the contents of the bucket named '#{bucket_name}'...\" \n  response = s3_client.list_objects_v2( \n    bucket: bucket_name, \n    max_keys: 50 \n  ) \n  if response.count.positive? \n    puts \"Contents of the bucket named '#{bucket_name}' (first 50 objects):\" \n    puts 'Name => ETag' \n    response.contents.each do |obj| \n      puts \"#{obj.key} => #{obj.etag}\" \n    end \n  else \n    puts \"No objects in the bucket named '#{bucket_name}'.\" \n  end \n  true\nrescue StandardError => e \n  puts \"Error while accessing the bucket named '#{bucket_name}': #{e.message}\"\nend\nMaking requests using the AWS SDKs API Version 2006-03-01 1638Amazon Simple Storage Service API Reference\nMaking requests using the AWS SDKs API Version 2006-03-01 1639Amazon Simple Storage Service API Reference\nMaking requests using federated user temporary credentials\nYou can request temporary security credentials and provide them to your federated users or \napplications who need to access your AWS resources.", "This section provides examples of how \nyou can use the AWS SDK to obtain temporary security credentials for your federated users or \napplications and send authenticated requests to Amazon S3 using those credentials. For a list of \navailable AWS SDKs, see Sample Code and Libraries .\nNote\nBoth the AWS account and an IAM user can request temporary security credentials \nfor federated users. However, for added security, only an IAM user with the necessary \npermissions should request these temporary credentials to ensure that the federated user \ngets at most the permissions of the requesting IAM user. In some applications, you might \n\ufb01nd it suitable to create an IAM user with speci\ufb01c permissions for the sole purpose of \ngranting temporary security credentials to your federated users and applications.\nJava\nYou can provide temporary security credentials for your federated users and applications so \nthat they can send authenticated requests to access your AWS resources. When requesting these \ntemporary credentials, you must provide a user name and an IAM policy that describes the \nresource permissions that you want to grant.", "By default, the session duration is one hour. You \ncan explicitly set a di\ufb00erent duration value when requesting the temporary security credentials \nfor federated users and applications.\nNote\nFor added security when requesting temporary security credentials for federated \nusers and applications, we recommend that you use a dedicated IAM user with only \nthe necessary access permissions. The temporary user you create can never get more \npermissions than the IAM user who requested the temporary security credentials.", "For \nmore information, see AWS Identity and Access Management FAQs .\nTo provide security credentials and send authenticated request to access resources, do the \nfollowing:\nMaking requests using the AWS SDKs API Version 2006-03-01 1640Amazon Simple Storage Service API Reference\n\u2022Create an instance of the AWSSecurityTokenServiceClient  class.\n\u2022Start a session by calling the getFederationToken()  method of the Security Token Service \n(STS) client.", "Provide session information, including the user name and an IAM policy, that you \nwant to attach to the temporary credentials. You can provide an optional session duration. \nThis method returns your temporary security credentials.\n\u2022Package the temporary security credentials in an instance of the\nBasicSessionCredentials  object.", "You use this object to provide the temporary security \ncredentials to your Amazon S3 client.\n\u2022Create an instance of the AmazonS3Client  class using the temporary security credentials. \nYou send requests to Amazon S3 using this client. If you send requests using expired \ncredentials, Amazon S3 returns an error.\nExample\nThe example lists keys in the speci\ufb01ed S3 bucket. In the example, you obtain temporary security \ncredentials for a two-hour session for your federated user and use the credentials to send \nauthenticated requests to Amazon S3.", "To run the example, you need to create an IAM user with \nan attached policy that allows the user to request temporary security credentials and list your \nAWS resources.", "The following policy accomplishes this:\n{ \n  \"Statement\":[{ \n      \"Action\":[\"s3:ListBucket\", \n        \"sts:GetFederationToken*\" \n      ], \n      \"Effect\":\"Allow\", \n      \"Resource\":\"*\" \n    } \n  ]\n}\nFor more information about how to create an IAM user, see Creating Your First IAM user and \nAdministrators Group in the IAM User Guide .\nAfter creating an IAM user and attaching the preceding policy, you can run the following \nexample. For instructions on creating and testing a working sample, see Getting Started in the \nAWS SDK for Java Developer Guide.\nMaking requests using the AWS SDKs API Version 2006-03-01 1641Amazon Simple Storage Service API Reference\nimport com.amazonaws.AmazonServiceException;\nimport com.amazonaws.SdkClientException;\nimport com.amazonaws.auth.AWSStaticCredentialsProvider;\nimport com.amazonaws.auth.BasicSessionCredentials;\nimport com.amazonaws.auth.policy.Policy;\nimport com.amazonaws.auth.policy.Resource;\nimport com.amazonaws.auth.policy.Statement;\nimport com.amazonaws.auth.policy.Statement.Effect;\nimport com.amazonaws.auth.policy.actions.S3Actions;\nimport com.amazonaws.auth.profile.ProfileCredentialsProvider;\nimport com.amazonaws.regions.Regions;\nimport com.amazonaws.services.s3.AmazonS3;\nimport com.amazonaws.services.s3.AmazonS3ClientBuilder;\nimport com.amazonaws.services.s3.model.ObjectListing;\nimport com.amazonaws.services.securitytoken.AWSSecurityTokenService;\nimport com.amazonaws.services.securitytoken.AWSSecurityTokenServiceClientBuilder;\nimport com.amazonaws.services.securitytoken.model.Credentials;\nimport com.amazonaws.services.securitytoken.model.GetFederationTokenRequest;\nimport com.amazonaws.services.securitytoken.model.GetFederationTokenResult;\nimport java.io.IOException;\npublic class MakingRequestsWithFederatedTempCredentials { \n    public static void main(String[] args) throws IOException { \n        Regions clientRegion = Regions.DEFAULT_REGION; \n        String bucketName = \"*** Specify bucket name ***\"; \n        String federatedUser = \"*** Federated user name ***\"; \n        String resourceARN = \"arn:aws:s3:::\" + bucketName; \n        try { \n            AWSSecurityTokenService stsClient = AWSSecurityTokenServiceClientBuilder \n                    .standard() \n                    .withCredentials(new ProfileCredentialsProvider()) \n                    .withRegion(clientRegion) \n                    .build(); \n            GetFederationTokenRequest getFederationTokenRequest = new \n GetFederationTokenRequest(); \n            getFederationTokenRequest.setDurationSeconds(7200); \n            getFederationTokenRequest.setName(federatedUser); \nMaking requests using the AWS SDKs API Version 2006-03-01 1642Amazon Simple Storage Service API Reference\n            // Define the policy and add it to the request.", "\n            Policy policy = new Policy(); \n            policy.withStatements(new Statement(Effect.Allow) \n                    .withActions(S3Actions.ListObjects) \n                    .withResources(new Resource(resourceARN))); \n            getFederationTokenRequest.setPolicy(policy.toJson()); \n            // Get the temporary security credentials. \n            GetFederationTokenResult federationTokenResult = \n stsClient.getFederationToken(getFederationTokenRequest); \n            Credentials sessionCredentials = federationTokenResult.getCredentials(); \n            // Package the session credentials as a BasicSessionCredentials \n            // object for an Amazon S3 client object to use. \n            BasicSessionCredentials basicSessionCredentials = new \n BasicSessionCredentials( \n                    sessionCredentials.getAccessKeyId(), \n                    sessionCredentials.getSecretAccessKey(), \n                    sessionCredentials.getSessionToken()); \n            AmazonS3 s3Client = AmazonS3ClientBuilder.standard() \n                    .withCredentials(new \n AWSStaticCredentialsProvider(basicSessionCredentials)) \n                    .withRegion(clientRegion) \n                    .build(); \n            // To verify that the client works, send a listObjects request using \n            // the temporary security credentials. \n            ObjectListing objects = s3Client.listObjects(bucketName); \n            System.out.println(\"No. of Objects = \" + \n objects.getObjectSummaries().size()); \n        } catch (AmazonServiceException e) { \n            // The call was transmitted successfully, but Amazon S3 couldn't process \n            // it, so it returned an error response. \n            e.printStackTrace(); \n        } catch (SdkClientException e) { \n            // Amazon S3 couldn't be contacted for a response, or the client \n            // couldn't parse the response from Amazon S3.", "\n            e.printStackTrace(); \n        } \n    }\n}\nMaking requests using the AWS SDKs API Version 2006-03-01 1643Amazon Simple Storage Service API Reference\n.NET\nYou can provide temporary security credentials for your federated users and applications so \nthat they can send authenticated requests to access your AWS resources.", "When requesting \nthese temporary credentials, you must provide a user name and an IAM policy that describes \nthe resource permissions that you want to grant.", "By default, the duration of a session is one \nhour.", "You can explicitly set a di\ufb00erent duration value when requesting the temporary security \ncredentials for federated users and applications. For information about sending authenticated \nrequests, see Making requests.\nNote\nWhen requesting temporary security credentials for federated users and applications, \nfor added security, we suggest that you use a dedicated IAM user with only the \nnecessary access permissions. The temporary user you create can never get more \npermissions than the IAM user who requested the temporary security credentials.", "For \nmore information, see AWS Identity and Access Management FAQs .\nYou do the following:\n\u2022Create an instance of the AWS Security Token Service client,\nAmazonSecurityTokenServiceClient  class.\n\u2022Start a session by calling the GetFederationToken  method of the STS client.", "You need \nto provide session information, including the user name and an IAM policy that you want \nto attach to the temporary credentials. Optionally, you can provide a session duration. This \nmethod returns your temporary security credentials.\n\u2022Package the temporary security credentials in an instance of the SessionAWSCredentials\nobject.", "You use this object to provide the temporary security credentials to your Amazon S3 \nclient.\n\u2022Create an instance of the AmazonS3Client  class by passing the temporary security \ncredentials. You use this client to send requests to Amazon S3. If you send requests using \nexpired credentials, Amazon S3 returns an error.\nMaking requests using the AWS SDKs API Version 2006-03-01 1644Amazon Simple Storage Service API Reference\nExample\nThe following C# example lists the keys in the speci\ufb01ed bucket. In the example, you obtain \ntemporary security credentials for a two-hour session for your federated user (User1), and use \nthe credentials to send authenticated requests to Amazon S3.\n\u2022For this exercise, you create an IAM user with minimal permissions.", "Using the credentials \nof this IAM user, you request temporary credentials for others.", "This example lists only the \nobjects in a speci\ufb01c bucket.", "Create an IAM user with the following policy attached:\n{ \n  \"Statement\":[{ \n      \"Action\":[\"s3:ListBucket\", \n        \"sts:GetFederationToken*\" \n      ], \n      \"Effect\":\"Allow\", \n      \"Resource\":\"*\" \n    } \n  ]\n}\nThe policy allows the IAM user to request temporary security credentials and access \npermission only to list your AWS resources.", "For more information about how to create an IAM \nuser, see Creating Your IAM user User and Administrators Group in the IAM User Guide .\n\u2022Use the IAM user security credentials to test the following example.", "The example sends \nauthenticated request to Amazon S3 using temporary security credentials.", "The example \nspeci\ufb01es the following policy when requesting temporary security credentials for the \nfederated user (User1), which restricts access to listing objects in a speci\ufb01c bucket \n(YourBucketName ). You must update the policy and provide your own existing bucket name.\n{ \n  \"Statement\":[ \n    { \n      \"Sid\":\"1\", \n      \"Action\":[\"s3:ListBucket\"], \n      \"Effect\":\"Allow\",  \n      \"Resource\":\"arn:aws:s3:::YourBucketName\" \n    } \n  ]\n}\nMaking requests using the AWS SDKs API Version 2006-03-01 1645Amazon Simple Storage Service API Reference\n\u2022Example\nUpdate the following sample and provide the bucket name that you speci\ufb01ed in the \npreceding federated user access policy. For information about setting up and running the \ncode examples, see Getting Started with the AWS SDK for .NET in the AWS SDK for .NET \nDeveloper Guide .\nusing Amazon;\nusing Amazon.Runtime;\nusing Amazon.S3;\nusing Amazon.S3.Model;\nusing Amazon.SecurityToken;\nusing Amazon.SecurityToken.Model;\nusing System;\nusing System.Collections.Generic;\nusing System.Threading.Tasks;\nnamespace Amazon.DocSamples.S3\n{ \n    class TempFederatedCredentialsTest \n    { \n        private const string bucketName = \"*** bucket name ***\"; \n        // Specify your bucket region (an example region is shown). \n        private static readonly RegionEndpoint bucketRegion = \n RegionEndpoint.USWest2; \n        private static IAmazonS3 client; \n        public static void Main() \n        { \n            ListObjectsAsync().Wait(); \n        } \n        private static async Task ListObjectsAsync() \n        { \n            try \n            { \n                Console.WriteLine(\"Listing objects stored in a bucket\"); \n                // Credentials use the default AWS SDK for .NET credential search \n chain.", "\n                // On local development machines, this is your default profile.", "\n                SessionAWSCredentials tempCredentials = \n                    await GetTemporaryFederatedCredentialsAsync(); \nMaking requests using the AWS SDKs API Version 2006-03-01 1646Amazon Simple Storage Service API Reference\n                // Create a client by providing temporary security credentials.", "\n                using (client = new AmazonS3Client(bucketRegion)) \n                { \n                    ListObjectsRequest listObjectRequest = new \n ListObjectsRequest(); \n                    listObjectRequest.BucketName = bucketName; \n                    ListObjectsResponse response = await \n client.ListObjectsAsync(listObjectRequest); \n                    List<S3Object> objects = response.S3Objects; \n                    Console.WriteLine(\"Object count = {0}\", objects.Count); \n                    Console.WriteLine(\"Press any key to continue...\"); \n                    Console.ReadKey(); \n                } \n            } \n            catch (AmazonS3Exception e) \n            { \n                Console.WriteLine(\"Error encountered ***.", "Message:'{0}' when \n writing an object\", e.Message); \n            } \n            catch (Exception e) \n            { \n                Console.WriteLine(\"Unknown encountered on server.", "Message:'{0}' \n when writing an object\", e.Message); \n            } \n        } \n        private static async Task<SessionAWSCredentials> \n GetTemporaryFederatedCredentialsAsync() \n        { \n            AmazonSecurityTokenServiceConfig config = new \n AmazonSecurityTokenServiceConfig(); \n            AmazonSecurityTokenServiceClient stsClient = \n                new AmazonSecurityTokenServiceClient( \n                                             config); \n            GetFederationTokenRequest federationTokenRequest = \n                                     new GetFederationTokenRequest(); \n            federationTokenRequest.DurationSeconds = 7200; \n            federationTokenRequest.Name = \"User1\"; \n            federationTokenRequest.Policy = @\"{ \n               \"\"Statement\"\": \n               [ \nMaking requests using the AWS SDKs API Version 2006-03-01 1647Amazon Simple Storage Service API Reference\n                 { \n                   \"\"Sid\"\":\"\"Stmt1311212314284\"\", \n                   \"\"Action\"\":[\"\"s3:ListBucket\"\"], \n                   \"\"Effect\"\":\"\"Allow\"\", \n                   \"\"Resource\"\":\"\"arn:aws:s3:::\" + bucketName + @\"\"\" \n                  } \n               ] \n             } \n            \"; \n            GetFederationTokenResponse federationTokenResponse = \n                        await \n stsClient.GetFederationTokenAsync(federationTokenRequest); \n            Credentials credentials = federationTokenResponse.Credentials; \n            SessionAWSCredentials sessionCredentials = \n                new SessionAWSCredentials(credentials.AccessKeyId, \n                                          credentials.SecretAccessKey, \n                                          credentials.SessionToken); \n            return sessionCredentials; \n        } \n    }\n}\nPHP\nThis topic explains how to use classes from version 3 of the AWS SDK for PHP to request \ntemporary security credentials for federated users and applications and use them to access \nresources stored in Amazon S3.", "For more information about the AWS SDK for Ruby API, go to\nAWS SDK for Ruby - Version 2.\nYou can provide temporary security credentials to your federated users and applications so \nthey can send authenticated requests to access your AWS resources.", "When requesting these \ntemporary credentials, you must provide a user name and an IAM policy that describes the \nresource permissions that you want to grant. These credentials expire when the session duration \nexpires. By default, the session duration is one hour.", "You can explicitly set a di\ufb00erent value \nfor the duration when requesting the temporary security credentials for federated users and \napplications.", "For more information about temporary security credentials, see Temporary \nSecurity Credentials in the IAM User Guide . For information about providing temporary security \ncredentials to your federated users and applications, see Making requests.\nMaking requests using the AWS SDKs API Version 2006-03-01 1648Amazon Simple Storage Service API Reference\nFor added security when requesting temporary security credentials for federated users and \napplications, we recommend using a dedicated IAM user with only the necessary access \npermissions. The temporary user you create can never get more permissions than the IAM user \nwho requested the temporary security credentials.", "For information about identity federation, \nsee AWS Identity and Access Management FAQs.\nFor more information about the AWS SDK for Ruby API, go to AWS SDK for Ruby - Version 2.\nExample\nThe following PHP example lists keys in the speci\ufb01ed bucket.", "In the example, you obtain \ntemporary security credentials for an hour session for your federated user (User1).", "Then you use \nthe temporary security credentials to send authenticated requests to Amazon S3.\nFor added security when requesting temporary credentials for others, you use the security \ncredentials of an IAM user who has permissions to request temporary security credentials.", "\nTo ensure that the IAM user grants only the minimum application-speci\ufb01c permissions to the \nfederated user, you can also limit the access permissions of this IAM user.", "This example lists only \nobjects in a speci\ufb01c bucket.", "Create an IAM user with the following policy attached:\n{ \n  \"Statement\":[{ \n      \"Action\":[\"s3:ListBucket\", \n        \"sts:GetFederationToken*\" \n      ], \n      \"Effect\":\"Allow\", \n      \"Resource\":\"*\" \n    } \n  ]\n}\nThe policy allows the IAM user to request temporary security credentials and access permission \nonly to list your AWS resources.", "For more information about how to create an IAM user, see\nCreating Your First IAM user and Administrators Group in the IAM User Guide .\nYou can now use the IAM user security credentials to test the following example.", "The example \nsends an authenticated request to Amazon S3 using temporary security credentials.", "When \nrequesting temporary security credentials for the federated user (User1), the example speci\ufb01es \nthe following policy, which restricts access to list objects in a speci\ufb01c bucket.", "Update the policy \nwith your bucket name.\nMaking requests using the AWS SDKs API Version 2006-03-01 1649Amazon Simple Storage Service API Reference\n{ \n  \"Statement\":[ \n    { \n      \"Sid\":\"1\", \n      \"Action\":[\"s3:ListBucket\"], \n      \"Effect\":\"Allow\",  \n      \"Resource\":\"arn:aws:s3::: YourBucketName \" \n    } \n  ]\n}\nIn the following example, when specifying the policy resource, replace YourBucketName  with \nthe name of your bucket.:\n require 'vendor/autoload.php';\nuse Aws\\S3\\Exception\\S3Exception;\nuse Aws\\S3\\S3Client;\nuse Aws\\Sts\\StsClient;\n$bucket = '*** Your Bucket Name ***';\n// In real applications, the following code is part of your trusted code.", "It has\n// the security credentials that you use to obtain temporary security credentials.\n$sts = new StsClient([ \n    'version' => 'latest', \n    'region' => 'us-east-1'\n]);\n// Fetch the federated credentials.\n$sessionToken = $sts->getFederationToken([ \n    'Name'              => 'User1', \n    'DurationSeconds'    => '3600', \n    'Policy'            => json_encode([ \n        'Statement' => [ \n            'Sid'              => 'randomstatementid' .", "time(), \n            'Action'           => ['s3:ListBucket'], \n            'Effect'           => 'Allow', \n            'Resource'         => 'arn:aws:s3:::' .", "$bucket \n        ] \n    ])\n]);\nMaking requests using the AWS SDKs API Version 2006-03-01 1650Amazon Simple Storage Service API Reference\n// The following will be part of your less trusted code.", "You provide temporary\n// security credentials so the code can send authenticated requests to Amazon S3.\n$s3 = new S3Client([ \n    'region' => 'us-east-1', \n    'version' => 'latest', \n    'credentials' => [ \n        'key' => $sessionToken['Credentials']['AccessKeyId'], \n        'secret' => $sessionToken['Credentials']['SecretAccessKey'], \n        'token' => $sessionToken['Credentials']['SessionToken'] \n    ]\n]);\ntry { \n    $result = $s3->listObjects([ \n        'Bucket' => $bucket \n    ]);\n} catch (S3Exception $e) { \n    echo $e->getMessage() .", "PHP_EOL;\n}\nRuby\nYou can provide temporary security credentials for your federated users and applications so \nthat they can send authenticated requests to access your AWS resources.", "When requesting \ntemporary credentials from the IAM service, you must provide a user name and an IAM policy \nthat describes the resource permissions that you want to grant.", "By default, the session duration \nis one hour.", "However, if you are requesting temporary credentials using IAM user credentials, \nyou can explicitly set a di\ufb00erent duration value when requesting the temporary security \ncredentials for federated users and applications. For information about temporary security \ncredentials for your federated users and applications, see Making requests.\nNote\nFor added security when you request temporary security credentials for federated users \nand applications, you might want to use a dedicated IAM user with only the necessary \naccess permissions. The temporary user you create can never get more permissions than \nthe IAM user who requested the temporary security credentials.", "For more information, \nsee AWS Identity and Access Management FAQs .\nMaking requests using the AWS SDKs API Version 2006-03-01 1651Amazon Simple Storage Service API Reference\nExample\nThe following Ruby code example allows a federated user with a limited set of permissions to \nlists keys in the speci\ufb01ed bucket.\n# Prerequisites:\n#  - An existing Amazon S3 bucket.\nrequire 'aws-sdk-s3'\nrequire 'aws-sdk-iam'\nrequire 'json'\n# Checks to see whether a user exists in IAM; otherwise,\n# creates the user.\n#\n# @param iam [Aws::IAM::Client] An initialized IAM client.\n# @param user_name [String] The user's name.\n# @return [Aws::IAM::Types::User] The existing or new user.\n# @example\n#   iam = Aws::IAM::Client.new(region: 'us-west-2')\n#   user = get_user(iam, 'my-user')\n#   exit 1 unless user.user_name\n#   puts \"User's name: #{user.user_name}\"\ndef get_user(iam, user_name) \n  puts \"Checking for a user with the name '#{user_name}'...\" \n  response = iam.get_user(user_name: user_name) \n  puts \"A user with the name '#{user_name}' already exists.\" \n  response.user\n# If the user doesn't exist, create them.\nrescue Aws::IAM::Errors::NoSuchEntity \n  puts \"A user with the name '#{user_name}' doesn't exist. Creating this user...\" \n  response = iam.create_user(user_name: user_name) \n  iam.wait_until(:user_exists, user_name: user_name) \n  puts \"Created user with the name '#{user_name}'.\" \n  response.user\nrescue StandardError => e \n  puts \"Error while accessing or creating the user named '#{user_name}': \n #{e.message}\"\nend\n# Gets temporary AWS credentials for an IAM user with the specified permissions.\n#\n# @param sts [Aws::STS::Client] An initialized AWS STS client.\n# @param duration_seconds [Integer] The number of seconds for valid credentials.\nMaking requests using the AWS SDKs API Version 2006-03-01 1652Amazon Simple Storage Service API Reference\n# @param user_name [String] The user's name.\n# @param policy [Hash] The access policy.\n# @return [Aws::STS::Types::Credentials] AWS credentials for API authentication.\n# @example\n#   sts = Aws::STS::Client.new(region: 'us-west-2')\n#   credentials = get_temporary_credentials(sts, duration_seconds, user_name,\n#     {\n#       'Version' => '2012-10-17',\n#       'Statement' => [\n#         'Sid' => 'Stmt1',\n#         'Effect' => 'Allow',\n#         'Action' => 's3:ListBucket',\n#         'Resource' => 'arn:aws:s3:::amzn-s3-demo-bucket'\n#       ]\n#     }\n#   )\n#   exit 1 unless credentials.access_key_id\n#   puts \"Access key ID: #{credentials.access_key_id}\"\ndef get_temporary_credentials(sts, duration_seconds, user_name, policy) \n  response = sts.get_federation_token( \n    duration_seconds: duration_seconds, \n    name: user_name, \n    policy: policy.to_json \n  ) \n  response.credentials\nrescue StandardError => e \n  puts \"Error while getting federation token: #{e.message}\"\nend\n# Lists the keys and ETags for the objects in an Amazon S3 bucket.\n#\n# @param s3_client [Aws::S3::Client] An initialized Amazon S3 client.\n# @param bucket_name [String] The bucket's name.\n# @return [Boolean] true if the objects were listed; otherwise, false.\n# @example\n#   s3_client = Aws::S3::Client.new(region: 'us-west-2')\n#   exit 1 unless list_objects_in_bucket?(s3_client, 'amzn-s3-demo-bucket')\ndef list_objects_in_bucket?(s3_client, bucket_name) \n  puts \"Accessing the contents of the bucket named '#{bucket_name}'...\" \n  response = s3_client.list_objects_v2( \n    bucket: bucket_name, \n    max_keys: 50 \n  ) \nMaking requests using the AWS SDKs API Version 2006-03-01 1653Amazon Simple Storage Service API Reference\n  if response.count.positive? \n    puts \"Contents of the bucket named '#{bucket_name}' (first 50 objects):\" \n    puts 'Name => ETag' \n    response.contents.each do |obj| \n      puts \"#{obj.key} => #{obj.etag}\" \n    end \n  else \n    puts \"No objects in the bucket named '#{bucket_name}'.\" \n  end \n  true\nrescue StandardError => e \n  puts \"Error while accessing the bucket named '#{bucket_name}': #{e.message}\"\nend\n# Example usage:\ndef run_me\n<<<<<<< HEAD \n  region = \"us-west-2\" \n  user_name = \"my-user\" \n  bucket_name = \"amzn-s3-demo-bucket\"\n======= \n  region = 'us-west-2' \n  user_name = 'my-user' \n  bucket_name = 'doc-example-bucket'\n>>>>>>> 999c6133e (fixes) \n  iam = Aws::IAM::Client.new(region: region) \n  user = get_user(iam, user_name) \n  exit 1 unless user.user_name \n  puts \"User's name: #{user.user_name}\" \n  sts = Aws::STS::Client.new(region: region) \n  credentials = get_temporary_credentials(sts, 3600, user_name, \n                                          { \n                                            'Version' => '2012-10-17', \n                                            'Statement' => [ \n                                              'Sid' => 'Stmt1', \n                                              'Effect' => 'Allow', \n                                              'Action' => 's3:ListBucket', \n                                              'Resource' => \n \"arn:aws:s3:::#{bucket_name}\" \n                                            ] \n                                          }) \nMaking requests using the AWS SDKs API Version 2006-03-01 1654Amazon Simple Storage Service API Reference\n  exit 1 unless credentials.access_key_id \n  puts \"Access key ID: #{credentials.access_key_id}\" \n  s3_client = Aws::S3::Client.new(region: region, credentials: credentials) \n  exit 1 unless list_objects_in_bucket?(s3_client, bucket_name)\nend\nrun_me if $PROGRAM_NAME == __FILE__\nMaking requests using the REST API\nThis section contains information on how to make requests to Amazon S3 endpoints by using \nthe REST API. For a list of Amazon S3 endpoints, see Regions and Endpoints in the AWS General \nReference.\nConstructing S3 hostnames for REST API requests\nAmazon S3 endpoints follow the structure shown below:\ns3.Region.amazonaws.com\nAmazon S3 access points endpoints and dual-stack endpoints also follow the standard structure:\n\u2022Amazon S3 access points \u2010s3-accesspoint.", "Region.amazonaws.com\n\u2022Dual-stack  \u2010 s3.dualstack. Region.amazonaws.com\nFor a complete list of Amazon S3 Regions and endpoints, see Amazon S3 endpoints and quotas in \nthe Amazon Web Services General Reference.\nVirtual hosted\u2010style and path\u2010style requests\nWhen making requests by using the REST API, you can use virtual hosted\u2013style or path-style URIs \nfor the Amazon S3 endpoints.", "For more information, see Path-style requests .\nMaking requests using the REST API API Version 2006-03-01 1655Amazon Simple Storage Service API Reference\nExample Virtual hosted\u2013Style request\nFollowing is an example of a virtual hosted\u2013style request to delete the puppy.jpg  \ufb01le from the \nbucket named examplebucket  in the US West (Oregon) Region. For more information about \nvirtual hosted-style requests, see Path-style requests .\nDELETE /puppy.jpg HTTP/1.1\nHost: examplebucket.s3.us-west-2.amazonaws.com\nDate: Mon, 11 Apr 2016 12:00:00 GMT\nx-amz-date: Mon, 11 Apr 2016 12:00:00 GMT\nAuthorization: authorization string\nExample Path-style request\nFollowing is an example of a path-style version of the same request.\nDELETE /examplebucket/puppy.jpg HTTP/1.1\nHost: s3.us-west-2.amazonaws.com\nDate: Mon, 11 Apr 2016 12:00:00 GMT\nx-amz-date: Mon, 11 Apr 2016 12:00:00 GMT\nAuthorization: authorization string\n  \nYou will receive an HTTP response code 307 Temporary Redirect error and a message indicating \nwhat the correct URI is for your resource if you try to access a bucket outside the US East (N.", "\nVirginia) region with path-style syntax that uses either of the following:\nFor more information about path-style requests, see Path-style requests .\nImportant\nUpdate (September 23, 2020) \u2013 To make sure that customers have the time that they need \nto transition to virtual-hosted\u2013style URLs, we have decided to delay the deprecation of \npath-style URLs.", "For more information, see Amazon S3 Path Deprecation Plan \u2013 The Rest of \nthe Story in the AWS News Blog.\nMaking requests to dual-stack endpoints by using the REST API\nWhen using the REST API, you can directly access a dual-stack endpoint by using a virtual hosted\u2013\nstyle or a path style endpoint name (URI). All Amazon S3 dual-stack endpoint names include the \nMaking requests using the REST API API Version 2006-03-01 1656Amazon Simple Storage Service API Reference\nregion in the name.", "Unlike the standard IPv4-only endpoints, both virtual hosted\u2013style and a path-\nstyle endpoints use region-speci\ufb01c endpoint names.\nExample Virtual hosted\u2013Style dual-stack endpoint request\nYou can use a virtual hosted\u2013style endpoint in your REST request as shown in the following \nexample that retrieves the puppy.jpg  object from the bucket named examplebucket  in the US \nWest (Oregon) Region.\nGET /puppy.jpg HTTP/1.1\nHost: examplebucket.s3.dualstack.us-west-2.amazonaws.com\nDate: Mon, 11 Apr 2016 12:00:00 GMT\nx-amz-date: Mon, 11 Apr 2016 12:00:00 GMT\nAuthorization: authorization string\nExample Path-style dual-stack endpoint request\nOr you can use a path-style endpoint in your request as shown in the following example.\nGET /examplebucket/puppy.jpg HTTP/1.1\nHost: s3.dualstack.us-west-2.amazonaws.com\nDate: Mon, 11 Apr 2016 12:00:00 GMT\nx-amz-date: Mon, 11 Apr 2016 12:00:00 GMT\nAuthorization: authorization string\nFor more information about dual-stack endpoints, see Using Amazon S3 dual-stack endpoints.\nFor more information about making requests using the REST API, see the topics beldow.\nTopics\n\u2022Request redirection and the REST API\n\u2022Request routing\nRequest redirection and the REST API\nTopics\n\u2022Redirects and HTTP user-agents\n\u2022Redirects and 100-Continue\n\u2022Redirect example\nMaking requests using the REST API API Version 2006-03-01 1657Amazon Simple Storage Service API Reference\nThis section describes how to handle HTTP redirects by using the Amazon S3 REST API.", "For general \ninformation about Amazon S3 redirects, see Making requests in the Amazon Simple Storage \nService API Reference.\nRedirects and HTTP user-agents\nPrograms that use the Amazon S3 REST API should handle redirects either at the application \nlayer or the HTTP layer.", "Many HTTP client libraries and user agents can be con\ufb01gured to correctly \nhandle redirects automatically; however, many others have incorrect or incomplete redirect \nimplementations.\nBefore you rely on a library to ful\ufb01ll the redirect requirement, test the following cases:\n\u2022Verify all HTTP request headers are correctly included in the redirected request (the second \nrequest after receiving a redirect) including HTTP standards such as Authorization and Date.\n\u2022Verify non-GET redirects, such as PUT and DELETE, work correctly.\n\u2022Verify large PUT requests follow redirects correctly.\n\u2022Verify PUT requests follow redirects correctly if the 100-continue response takes a long time to \narrive.\nHTTP user-agents that strictly conform to RFC 2616 might require explicit con\ufb01rmation before \nfollowing a redirect when the HTTP request method is not GET or HEAD.", "It is generally safe to \nfollow redirects generated by Amazon S3 automatically, as the system will issue redirects only to \nhosts within the amazonaws.com domain and the e\ufb00ect of the redirected request will be the same \nas that of the original request.\nRedirects and 100-Continue\nTo simplify redirect handling, improve e\ufb03ciencies, and avoid the costs associated with sending a \nredirected request body twice, con\ufb01gure your application to use 100-continues for PUT operations.", "\nWhen your application uses 100-continue, it does not send the request body until it receives an \nacknowledgement.", "If the message is rejected based on the headers, the body of the message is not \nsent.", "For more information about 100-continue, go to RFC 2616 Section 8.2.3\nNote\nAccording to RFC 2616, when using Expect: Continue  with an unknown HTTP server, \nyou should not wait an inde\ufb01nite period before sending the request body.", "This is because \nMaking requests using the REST API API Version 2006-03-01 1658Amazon Simple Storage Service API Reference\nsome HTTP servers do not recognize 100-continue.", "However, Amazon S3 does recognize \nif your request contains an Expect: Continue  and will respond with a provisional \n100-continue status or a \ufb01nal status code.", "Additionally, no redirect error will occur after \nreceiving the provisional 100 continue go-ahead.", "This will help you avoid receiving a \nredirect response while you are still writing the request body.\nRedirect example\nThis section provides an example of client-server interaction using HTTP redirects and 100-\ncontinue.\nFollowing is a sample PUT to the quotes.s3.amazonaws.com  bucket.\nPUT /nelson.txt HTTP/1.1\nHost: quotes.s3.amazonaws.com\nDate: Mon, 15 Oct 2007 22:18:46 +0000\nContent-Length: 6\nExpect: 100-continue\nAmazon S3 returns the following:\nHTTP/1.1 307 Temporary Redirect\nLocation: http://quotes.s3-4c25d83b.amazonaws.com/nelson.txt?rk=8d47490b\nContent-Type: application/xml\nTransfer-Encoding: chunked\nDate: Mon, 15 Oct 2007 22:18:46 GMT\nServer: AmazonS3\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<Error> \n  <Code>TemporaryRedirect</Code> \n  <Message>Please re-send this request to the \n  specified temporary endpoint.", "Continue to use the \n  original request endpoint for future requests.", "\n  </Message> \n  <Endpoint>quotes.s3-4c25d83b.amazonaws.com</Endpoint> \n  <Bucket>quotes</Bucket>\nMaking requests using the REST API API Version 2006-03-01 1659Amazon Simple Storage Service API Reference\n</Error>\nThe client follows the redirect response and issues a new request to the\nquotes.s3-4c25d83b.amazonaws.com  temporary endpoint.\nPUT /nelson.txt?rk=8d47490b HTTP/1.1\nHost: quotes.s3-4c25d83b.amazonaws.com\nDate: Mon, 15 Oct 2007 22:18:46 +0000\nContent-Length: 6\nExpect: 100-continue\nAmazon S3 returns a 100-continue indicating the client should proceed with sending the request \nbody.\nHTTP/1.1 100 Continue\nThe client sends the request body.\nha ha\\n\nAmazon S3 returns the \ufb01nal response.\nHTTP/1.1 200 OK\nDate: Mon, 15 Oct 2007 22:18:48 GMT\nETag: \"a2c8d6b872054293afd41061e93bc289\"\nContent-Length: 0\nServer: AmazonS3\nRequest routing\nPrograms that make requests against buckets created using the CreateBucket API that include a\nCreateBucketCon\ufb01guration must support redirects. Additionally, some clients that do not respect \nDNS TTLs might encounter issues.\nThis section describes routing and DNS issues to consider when designing your service or \napplication for use with Amazon S3.\nMaking requests using the REST API API Version 2006-03-01 1660Amazon Simple Storage Service API Reference\nRequest redirection and the REST API\nAmazon S3 uses the Domain Name System (DNS) to route requests to facilities that can process \nthem.", "This system works e\ufb00ectively, but temporary routing errors can occur.", "If a request arrives \nat the wrong Amazon S3 location, Amazon S3 responds with a temporary redirect that tells the \nrequester to resend the request to a new endpoint. If a request is incorrectly formed, Amazon S3 \nuses permanent redirects to provide direction on how to perform the request correctly.\nImportant\nTo use this feature, you must have an application that can handle Amazon S3 redirect \nresponses.", "The only exception is for applications that work exclusively with buckets that \nwere created without <CreateBucketConfiguration> .", "For more information about \nlocation constraints, see Accessing and listing an Amazon S3 bucket .\nFor all Regions that launched after March 20, 2019, if a request arrives at the wrong \nAmazon S3 location, Amazon S3 returns an HTTP 400 Bad Request error.\nFor more information about enabling or disabling an AWS Region, see AWS Regions and \nEndpoints  in the AWS General Reference.\nTopics\n\u2022DNS routing\n\u2022Temporary request redirection\n\u2022Permanent request redirection\n\u2022Request redirection examples\nDNS routing\nDNS routing routes requests to appropriate Amazon S3 facilities.", "The following \ufb01gure and \nprocedure show an example of DNS routing.\nMaking requests using the REST API API Version 2006-03-01 1661Amazon Simple Storage Service API Reference\nDNS routing request steps\n1.", "The client makes a DNS request to get an object stored on Amazon S3.\nMaking requests using the REST API API Version 2006-03-01 1662Amazon Simple Storage Service API Reference\n2.", "The client receives one or more IP addresses for facilities that can process the request. In this \nexample, the IP address is for Facility B.\n3.", "The client makes a request to Amazon S3 Facility B.\n4.", "Facility B returns a copy of the object to the client.\nTemporary request redirection\nA temporary redirect is a type of error response that signals to the requester that they should \nresend the request to a di\ufb00erent endpoint.", "Due to the distributed nature of Amazon S3, requests \ncan be temporarily routed to the wrong facility.", "This is most likely to occur immediately after \nbuckets are created or deleted.\nFor example, if you create a new bucket and immediately make a request to the bucket, you might \nreceive a temporary redirect, depending on the location constraint of the bucket. If you created the \nbucket in the US East (N. Virginia) AWS Region, you will not see the redirect because this is also the \ndefault Amazon S3 endpoint.\nHowever, if the bucket is created in any other Region, any requests for the bucket go to the default \nendpoint while the bucket's DNS entry is propagated.", "The default endpoint redirects the request to \nthe correct endpoint with an HTTP 302 response. Temporary redirects contain a URI to the correct \nfacility, which you can use to immediately resend the request.\nImportant\nDon't reuse an endpoint provided by a previous redirect response.", "It might appear to \nwork (even for long periods of time), but it might provide unpredictable results and will \neventually fail without notice.\nThe following \ufb01gure and procedure shows an example of a temporary redirect.\nMaking requests using the REST API API Version 2006-03-01 1663Amazon Simple Storage Service API Reference\nTemporary request redirection steps\n1.", "The client makes a DNS request to get an object stored on Amazon S3.\n2.", "The client receives one or more IP addresses for facilities that can process the request.\nMaking requests using the REST API API Version 2006-03-01 1664Amazon Simple Storage Service API Reference\n3.", "The client makes a request to Amazon S3 Facility B.\n4.", "Facility B returns a redirect indicating the object is available from Location C.\n5. The client resends the request to Facility C.\n6. Facility C returns a copy of the object.\nPermanent request redirection\nA permanent redirect indicates that your request addressed a resource inappropriately.", "For \nexample, permanent redirects occur if you use a path-style request to access a bucket that was \ncreated using <CreateBucketConfiguration> .", "For more information, see Accessing and listing \nan Amazon S3 bucket .\nTo help you \ufb01nd these errors during development, this type of redirect does not contain a Location \nHTTP header that allows you to automatically follow the request to the correct location. Consult \nthe resulting XML error document for help using the correct Amazon S3 endpoint.\nRequest redirection examples\nThe following are examples of temporary request redirection responses.\nREST API temporary redirect response\nHTTP/1.1 307 Temporary Redirect\nLocation: http://awsexamplebucket1.s3-gztb4pa9sq.amazonaws.com/photos/puppy.jpg?\nrk=e2c69a31\nContent-Type: application/xml\nTransfer-Encoding: chunked\nDate: Fri, 12 Oct 2007 01:12:56 GMT\nServer: AmazonS3\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<Error> \n  <Code>TemporaryRedirect</Code> \n  <Message>Please re-send this request to the specified temporary endpoint. \n  Continue to use the original request endpoint for future requests.</Message> \n  <Endpoint>awsexamplebucket1.s3-gztb4pa9sq.amazonaws.com</Endpoint>\n</Error>\nMaking requests using the REST API API Version 2006-03-01 1665Amazon Simple Storage Service API Reference\nSOAP API temporary redirect response\nNote\nSOAP support over HTTP is deprecated, but it is still available over HTTPS.", "New Amazon S3 \nfeatures will not be supported for SOAP.", "We recommend that you use either the REST API \nor the AWS SDKs.\n<soapenv:Body> \n  <soapenv:Fault> \n    <Faultcode>soapenv:Client.TemporaryRedirect</Faultcode> \n    <Faultstring>Please re-send this request to the specified temporary endpoint. \n    Continue to use the original request endpoint for future requests.</Faultstring> \n    <Detail> \n      <Bucket>images</Bucket> \n      <Endpoint>s3-gztb4pa9sq.amazonaws.com</Endpoint> \n    </Detail> \n  </soapenv:Fault>\n</soapenv:Body>\nDNS considerations\nOne of the design requirements of Amazon S3 is extremely high availability. One of the ways we \nmeet this requirement is by updating the IP addresses associated with the Amazon S3 endpoint in \nDNS as needed.", "These changes are automatically re\ufb02ected in short-lived clients, but not in some \nlong-lived clients.", "Long-lived clients will need to take special action to re-resolve the Amazon S3 \nendpoint periodically to bene\ufb01t from these changes.", "For more information about virtual machines \n(VMs), refer to the following:\n\u2022For Java, Sun's JVM caches DNS lookups forever by default; go to the \"InetAddress Caching\" \nsection of the InetAddress documentation for information on how to change this behavior.\n\u2022For PHP, the persistent PHP VM that runs in the most popular deployment con\ufb01gurations caches \nDNS lookups until the VM is restarted.", "Go to the getHostByName PHP docs.\nMaking requests using the REST API API Version 2006-03-01 1666Amazon Simple Storage Service API Reference\nDeveloping with Amazon S3 using the AWS CLI\nThe Amazon S3 AWS CLI commands are organized into di\ufb00erent sets in AWS CLI Command \nReference and each has it\u2019s own available commands.", "If you don't \ufb01nd the command that you're \nlooking for in one set, check one of the other sets.", "The di\ufb00erent sets are as follows:\n\u2022s3 \u2013 Describes high-level commands for working with objects and buckets.", "These include \ncopy, list and move actions.", "For a complete list of commands in this set, see s3 in the AWS CLI \nCommand Reference.\n\u2022s3api \u2013 Describes low-level commands that manage S3 resources such as buckets, objects, \nsessions and multipart uploads. These commands correspond to the Amazon S3 API operations. \nFor a complete list of CLI commands in this set, see s3api  in the AWS CLI Command Reference.\n\u2022s3control  \u2013 Describes low-level commands that manage all other S3 resources such as Access \nGrants, Storage Lens groups, and Amazon S3 on Outposts buckets. These commands correspond \nto the Amazon S3 Control API operations. For a complete list of CLI commands in this set, see\ns3control in the AWS CLI Command Reference.\nNote\nServices in AWS, such as Amazon S3, require that you provide credentials when you \naccess them.", "The service can then determine whether you have permissions to access the \nresources that it owns.", "The console requires your password.", "You can create access keys for \nyour AWS account to access the AWS CLI or API. However, we don't recommend that you \naccess AWS using the credentials for your AWS account. Instead, we recommend that you \nuse AWS Identity and Access Management (IAM). Create an IAM user, add the user to an IAM \ngroup with administrative permissions, and then grant administrative permissions to the \nIAM user that you created. You can then access AWS using a special URL and the credentials \nof that IAM user. For instructions, go to Creating Your First IAM user and Administrators \nGroup in the IAM User Guide .\nLearn more about the AWS CLI\nTo learn more about the AWS, see the following resources:\n\u2022AWS Command Line Interface\nUsing the AWS CLI API Version 2006-03-01 1667Amazon Simple Storage Service API Reference\n\u2022AWS Command Line Interface User Guide for Version 2\nDeveloping with Amazon S3 using the AWS SDKs\nAWS software development kits (SDKs) are available for many popular programming languages.", "\nEach SDK provides an API, code examples, and documentation that make it easier for developers to \nbuild applications in their preferred language.\nNote\nYou can use AWS Amplify for end-to-end fullstack development of web and mobile apps.", "\nAmplify Storage seamlessly integrates \ufb01le storage and management capabilities into \nfrontend web and mobile apps, built on top of Amazon S3. For more information, see\nStorage  in the Amplify user guide.\nSDK documentation Code examples\nAWS SDK for C++ AWS SDK for C++ code examples\nAWS CLI AWS CLI code examples\nAWS SDK for Go AWS SDK for Go code examples\nAWS SDK for Java AWS SDK for Java code examples\nAWS SDK for JavaScript AWS SDK for JavaScript code examples\nAWS SDK for Kotlin AWS SDK for Kotlin code examples\nAWS SDK for .NET AWS SDK for .NET code examples\nAWS SDK for PHP AWS SDK for PHP code examples\nAWS Tools for PowerShell Tools for PowerShell code examples\nAWS SDK for Python (Boto3) AWS SDK for Python (Boto3) code examples\nAWS SDK for Ruby AWS SDK for Ruby code examples\nDeveloping with AWS SDKs API Version 2006-03-01 1668Amazon Simple Storage Service API Reference\nSDK documentation Code examples\nAWS SDK for Rust AWS SDK for Rust code examples\nAWS SDK for SAP ABAP AWS SDK for SAP ABAP code examples\nAWS SDK for Swift AWS SDK for Swift code examples\nFor speci\ufb01c examples, see Code examples for Amazon S3 using AWS SDKs.\nSDK Programming interfaces\nEach AWS SDK provides one or more programmatic interfaces for working with Amazon S3. \nEach SDK provides a low-level interface for Amazon S3, with methods that closely resemble API \noperations. Some SDKs provide high-level interfaces for Amazon S3, that are abstractions intended \nto simplify common use cases.\nFor example, when you perform a multipart upload by using the low-level API operations, you \nuse an operation to initiate the upload, another operation to upload parts, and a \ufb01nal operation \nto complete the upload.", "A high-level multipart upload API operation lets you to do all of the \noperations required for upload in a single API call.", "For examples, see Uploading an object using \nmultipart upload in the Amazon S3 User Guide .\nLow-level API operations allow greater control over the upload. We recommend that you use \nthe low-level API operations if you need to pause and resume uploads, vary part sizes during the \nupload, or begin uploads when you don't know the size of the data in advance.\nSpecifying the Signature Version in Request Authentication\nAmazon S3 supports only AWS Signature Version 4 in most AWS Regions. In some of the older \nAWS Regions, Amazon S3 supports both Signature Version 4 and Signature Version 2.", "However, \nSignature Version 2 is being turned o\ufb00 (deprecated).", "For more information about the end of \nsupport for Signature Version 2, see AWS Signature Version 2 Turned O\ufb00 (Deprecated) for Amazon \nS3.\nFor a list of all the Amazon S3 Regions and the signature versions they support, see Regions and \nEndpoints  in the AWS General Reference.\nSDK Programming interfaces API Version 2006-03-01 1669Amazon Simple Storage Service API Reference\nFor all AWS Regions, AWS SDKs use Signature Version 4 by default to authenticate requests. When \nusing AWS SDKs that were released before May 2016, you might be required to request Signature \nVersion 4, as shown in the following table.\nSDK Requesting Signature Version 4 for Request Authentication\nAWS CLI For the default pro\ufb01le, run the following command:\n$ aws configure set default.s3.signature_version \n s3v4\nFor a custom pro\ufb01le, run the following command:\n$ aws configure set profile.your_profile_name.s \n3.signature_version s3v4\nJava SDK Add the following in your code:\nSystem.setProperty(SDKGlobalConfiguration.ENA \nBLE_S3_SIGV4_SYSTEM_PROPERTY, \"true\");\nOr, on the command line, specify the following:\n-Dcom.amazonaws.services.s3.enableV4\nJavaScript SDK Set the signatureVersion  parameter to v4 when construct \ning the client:\nvar s3 = new AWS.S3({signatureVersion: 'v4'});\nPHP SDK Set the signature  parameter to v4 when constructing the \nAmazon S3 service client for PHP SDK v2:\n<?php  \n$client = S3Client::factory([ \n    'region' => 'YOUR-REGION', \n    'version' => 'latest', \n    'signature' => 'v4'\nSpecifying the Signature Version in Request Authentication API Version 2006-03-01 1670Amazon Simple Storage Service API Reference\nSDK Requesting Signature Version 4 for Request Authentication\n]);\nWhen using the PHP SDK v3, set the signature_version\nparameter to v4 during construction of the Amazon S3 service \nclient:\n<?php  \n$s3 = new Aws\\S3\\S3Client([ \n    'version' => '2006-03-01', \n    'region' => 'YOUR-REGION', \n    'signature_version' => 'v4'\n]);\nPython-Boto SDK Specify the following in the boto default con\ufb01g \ufb01le:\n[s3] use-sigv4 = True\nRuby SDK Ruby SDK - Version 1: Set the :s3_signature_version\nparameter to :v4 when constructing the client:\ns3 = AWS::S3::Client.new(:s3_signature_version \n => :v4)\nRuby SDK - Version 3: Set the signature_version\nparameter to v4 when constructing the client:\ns3 = Aws::S3::Client.new(signature_version: 'v4')\nSpecifying the Signature Version in Request Authentication API Version 2006-03-01 1671Amazon Simple Storage Service API Reference\nSDK Requesting Signature Version 4 for Request Authentication\n.NET SDK Add the following to the code before creating the Amazon S3 \nclient:\nAWSConfigsS3.UseSignatureVersion4 = true;\nOr, add the following to the con\ufb01g \ufb01le:\n<appSettings> \n   <add key=\"AWS.S3.UseSignatureVersion4\" value=\"tr \nue\" />\n</appSettings>\n\u00a0\nAWS Signature Version 2 Turned O\ufb00 (Deprecated) for Amazon S3\nSignature Version 2 is being turned o\ufb00 (deprecated) in Amazon S3. Amazon S3 will then only \naccept API requests that are signed using Signature Version 4.\nThis section provides answers to common questions regarding the end of support for Signature \nVersion 2.\nWhat is Signature Version 2/4, and What Does It Mean to Sign Requests?\nThe Signature Version 2 or Signature Version 4 signing process is used to authenticate your \nAmazon S3 API requests. Signing requests enables Amazon S3 to identify who is sending the \nrequest and protects your requests from bad actors.\nFor more information about signing AWS requests, see Signing AWS API Requests in the AWS \nGeneral Reference.\nWhat Update Are You Making?\nWe currently support Amazon S3 API requests that are signed using Signature Version 2 and \nSignature Version 4 processes. After that, Amazon S3 will only accept requests that are signed \nusing Signature Version 4.\nSpecifying the Signature Version in Request Authentication API Version 2006-03-01 1672Amazon Simple Storage Service API Reference\nFor more information about signing AWS requests, see Changes in Signature Version 4 in the AWS \nGeneral Reference.\nWhy Are You Making the Update?\nSignature Version 4 provides improved security by using a signing key instead of your secret access \nkey.", "Signature Version 4 is currently supported in all AWS Regions, whereas Signature Version 2 \nis only supported in Regions that were launched before January 2014. This update allows us to \nprovide a more consistent experience across all Regions.\nHow Do I Ensure That I'm Using Signature Version 4, and What Updates Do I Need?\nThe signature version that is used to sign your requests is usually set by the tool or the SDK on the \nclient side. By default, the latest versions of our AWS SDKs use Signature Version 4.", "For third-party \nsoftware, contact the appropriate support team for your software to con\ufb01rm what version you \nneed.", "If you are sending direct REST calls to Amazon S3, you must modify your application to use \nthe Signature Version 4 signing process.\nFor information about which version of the AWS SDKs to use when moving to Signature Version 4, \nsee Moving from Signature Version 2 to Signature Version 4.\nFor information about using Signature Version 4 with the Amazon S3 REST API, see Authenticating \nRequests (AWS Signature Version 4) in the Amazon Simple Storage Service API Reference.\nWhat Happens if I Don't Make Updates?\nRequests signed with Signature Version 2 that are made after that will fail to authenticate with \nAmazon S3.", "Requesters will see errors stating that the request must be signed with Signature \nVersion 4.\nShould I Make Changes Even if I\u2019m Using a Presigned URL That Requires Me to Sign for More \nthan 7 Days?\nIf you are using a presigned URL that requires you to sign for more than 7 days, no action is \ncurrently needed.", "You can continue to use AWS Signature Version 2 to sign and authenticate the \npresigned URL. We will follow up and provide more details on how to migrate to Signature Version \n4 for a presigned URL scenario.\nMore Info\n\u2022For more information about using Signature Version 4, see Signing AWS API Requests.\nSpecifying the Signature Version in Request Authentication API Version 2006-03-01 1673Amazon Simple Storage Service API Reference\n\u2022View the list of changes between Signature Version 2 and Signature Version 4 in Changes in \nSignature Version 4.\n\u2022View the post AWS Signature Version 4 to replace AWS Signature Version 2 for signing Amazon \nS3 API requests in the AWS forums.\n\u2022If you have any questions or concerns, contact AWS Support.\n\u00a0\nMoving from Signature Version 2 to Signature Version 4\nIf you currently use Signature Version 2 for Amazon S3 API request authentication, you should \nmove to using Signature Version 4. Support is ending for Signature Version 2, as described in AWS \nSignature Version 2 Turned O\ufb00 (Deprecated) for Amazon S3.\nFor information about using Signature Version 4 with the Amazon S3 REST API, see Authenticating \nRequests (AWS Signature Version 4) in the Amazon Simple Storage Service API Reference.\nThe following table lists the SDKs with the necessary minimum version to use Signature Version \n4 (SigV4). If you are using presigned URLs with the AWS Java, JavaScript (Node.js), or Python \n(Boto/CLI) SDKs, you must set the correct AWS Region and set Signature Version 4 in the client \ncon\ufb01guration. For information about setting SigV4 in the client con\ufb01guration, see Specifying the \nSignature Version in Request Authentication.\nIf you use \nthis SDK/\nProductUpgrade \nto this SDK \nversionCode change \nneeded to \nthe client to \nuse Sigv4?Link to SDK documentation\nAWS SDK for \nJava v1Upgrade \nto Java \n1.11.201+ or \nv2.Yes Specifying the Signature Version in Request \nAuthentication\nAWS SDK for \nJava v2No SDK \nupgrade is \nneeded.No AWS SDK for Java\nSpecifying the Signature Version in Request Authentication API Version 2006-03-01 1674Amazon Simple Storage Service API Reference\nIf you use \nthis SDK/\nProductUpgrade \nto this SDK \nversionCode change \nneeded to \nthe client to \nuse Sigv4?Link to SDK documentation\nAWS SDK \nfor .NET v1Upgrade to \n3.1.10 or \nlater.YesAWS SDK for .NET\nAWS SDK \nfor .NET v2Upgrade to \n3.1.10 or \nlater.NoAWS SDK for .NET v2\nAWS SDK \nfor .NET v3Upgrade to \n3.3.0.0 or \nlater.YesAWS SDK for .NET v3\nAWS SDK for \nJavaScript v1Upgrade to \n2.68.0 or \nlater.YesAWS SDK for JavaScript\nAWS SDK for \nJavaScript v2Upgrade to \n2.68.0 or \nlater.YesAWS SDK for JavaScript\nAWS SDK for \nJavaScript v3No action \nis currently \nneeded. \nUpgrade to \nmajor version \nV3 in Q3 \n2019.NoAWS SDK for JavaScript\nSpecifying the Signature Version in Request Authentication API Version 2006-03-01 1675Amazon Simple Storage Service API Reference\nIf you use \nthis SDK/\nProductUpgrade \nto this SDK \nversionCode change \nneeded to \nthe client to \nuse Sigv4?Link to SDK documentation\nAWS SDK for \nPHP v1Recommend \nto upgrade \nto the most \nrecent \nversion of \nPHP or, at \nleast to \nv2.7.4 with \nthe signature \nparameter \nset to v4 \nin the S3 \nclient's \ncon\ufb01gura \ntion.YesAWS SDK for PHP\nAWS SDK for \nPHP v2Recommend \nto upgrade \nto the most \nrecent \nversion of \nPHP or, at \nleast to \nv2.7.4 with \nthe signature \nparameter \nset to v4 \nin the S3 \nclient's \ncon\ufb01gura \ntion.NoAWS SDK for PHP\nSpecifying the Signature Version in Request Authentication API Version 2006-03-01 1676Amazon Simple Storage Service API Reference\nIf you use \nthis SDK/\nProductUpgrade \nto this SDK \nversionCode change \nneeded to \nthe client to \nuse Sigv4?Link to SDK documentation\nAWS SDK for \nPHP v3No SDK \nupgrade is \nneeded.NoAWS SDK for PHP\nBoto2 Upgrade \nto Boto2 \nv2.49.0.Yes Boto 2 Upgrade\nBoto3 Upgrade \nto 1.5.71 \n(Botocore), \n1.4.6 (Boto3).YesBoto 3 - AWS SDK for Python\nAWS CLI Upgrade to \n1.11.108.YesAWS Command Line Interface\nAWS CLI v2 \n(preview)No SDK \nupgrade is \nneeded.NoAWS Command Line Interface version 2\nAWS SDK for \nRuby v1Upgrade to \nRuby V3.YesRuby V3 for AWS\nAWS SDK for \nRuby v2Upgrade to \nRuby V3.YesRuby V3 for AWS\nAWS SDK for \nRuby v3No SDK \nupgrade is \nneeded.NoRuby V3 for AWS\nGo No SDK \nupgrade is \nneeded.NoAWS SDK for Go\nSpecifying the Signature Version in Request Authentication API Version 2006-03-01 1677Amazon Simple Storage Service API Reference\nIf you use \nthis SDK/\nProductUpgrade \nto this SDK \nversionCode change \nneeded to \nthe client to \nuse Sigv4?Link to SDK documentation\nC++ No SDK \nupgrade is \nneeded.NoAWS SDK for C++\nAWS Tools for Windows PowerShell or AWS Tools for PowerShell Core\nIf you are using module versions earlier  than 3.3.0.0, you must upgrade to 3.3.0.0.\nTo get the version information, use the Get-Module  cmdlet:\n          Get-Module \u2013Name AWSPowershell \n          Get-Module \u2013Name AWSPowershell.NetCore   \n         \nTo update the 3.3.0.0 version, use the Update-Module  cmdlet:\n          Update-Module \u2013Name AWSPowershell \n          Update-Module \u2013Name AWSPowershell.NetCore   \n         \nYou can use presigned URLs that are valid for more than 7 days that you will send Signature \nVersion 2 tra\ufb03c on.\nGetting Amazon S3 request IDs for AWS Support\nWhenever you contact AWS Support because you've encountered errors or unexpected behavior in \nAmazon S3, you must provide the request IDs associated with the failed action.", "AWS Support uses \nthese request IDs to help resolve the problems that you're experiencing.\nRequest IDs come in pairs, are returned in every response that Amazon S3 processes (even the \nerroneous ones), and can be accessed through verbose logs. There are a number of common \nGet Amazon S3 request IDs for AWS Support API Version 2006-03-01 1678Amazon Simple Storage Service API Reference\nmethods for getting your request IDs, including S3 access logs and AWS CloudTrail events or data \nevents.\nAfter you've recovered these logs, copy and retain those two values, because you'll need them \nwhen you contact AWS Support.", "For information about contacting AWS Support, see Contact AWS\nor the AWS Support Documentation.\nUsing HTTP to obtain request IDs\nYou can obtain your request IDs, x-amz-request-id  and x-amz-id-2  by logging the bits of an \nHTTP request before it reaches the target application.", "There are a variety of third-party tools that \ncan be used to recover verbose logs for HTTP requests.", "Choose one that you trust, and then run the \ntool to listen on the port that your Amazon S3 tra\ufb03c travels on, as you send out another Amazon \nS3 HTTP request.\nFor HTTP requests, the pair of request IDs will look like the following:\nx-amz-request-id: 79104EXAMPLEB723  \nx-amz-id-2: IOWQ4fDEXAMPLEQM+ey7N9WgVhSnQ6JEXAMPLEZb7hSQDASK+Jd1vEXAMPLEa3Km\nNote\nHTTPS requests are encrypted and hidden in most packet captures.\nUsing a web browser to obtain request IDs\nMost web browsers have developer tools that you can use to view request headers.\nFor web browser-based requests that return an error, the pair of requests IDs will look like the \nfollowing examples.\n<Error><Code>AccessDenied</Code><Message>Access Denied</Message>\n<RequestId>79104EXAMPLEB723</RequestId><HostId>IOWQ4fDEXAMPLEQM\n+ey7N9WgVhSnQ6JEXAMPLEZb7hSQDASK+Jd1vEXAMPLEa3Km</HostId></Error>\nTo obtain the request ID pair from successful requests, use your browser's developer tools to look \nat the HTTP response headers. For information about developer tools for speci\ufb01c browsers, see\nAmazon S3 Troubleshooting - How to recover your S3 request IDs in AWS re:Post.\nUsing HTTP to obtain request IDs API Version 2006-03-01 1679Amazon Simple Storage Service API Reference\nUsing the AWS SDKs to obtain request IDs\nThe following sections include information for con\ufb01guring logging by using an AWS SDK. Although \nyou can enable verbose logging on every request and response, we don't recommend enabling \nlogging in production systems, because large requests or responses can signi\ufb01cantly slow down an \napplication.\nFor AWS SDK requests, the pair of request IDs will look like the following examples.\nStatus Code: 403, AWS Service: Amazon S3, AWS Request ID: 79104EXAMPLEB723   \nAWS Error Code: AccessDenied  AWS Error Message: Access Denied   \nS3 Extended Request ID: IOWQ4fDEXAMPLEQM+ey7N9WgVhSnQ6JEXAMPLEZb7hSQDASK\n+Jd1vEXAMPLEa3Km\nUsing the SDK for Go to obtain request IDs\nYou can con\ufb01gure logging by using SDK for Go.", "For more information, see Response metadata in \nthe SDK for Go V2 Developer Guide .\nUsing the SDK for PHP to obtain request IDs\nYou can con\ufb01gure logging by using PHP.", "For more information, see How can I see what data is sent \nover the wire?", "in the AWS SDK for PHP Developer Guide.\nUsing the SDK for Java to obtain request IDs\nYou can enable logging for speci\ufb01c requests or responses to catch and return only the relevant \nheaders.", "To do this, import the com.amazonaws.services.s3.S3ResponseMetadata  class.", "\nAfterward, you can store the request in a variable before performing the actual request.", "To get the \nlogged request or response, call getCachedResponseMetadata(AmazonWebServiceRequest \nrequest).getRequestID() .\nExample\nPutObjectRequest req = new PutObjectRequest(bucketName, key, createSampleFile());\ns3.putObject(req);\nS3ResponseMetadata md = s3.getCachedResponseMetadata(req);\nSystem.out.println(\"Host ID: \" + md.getHostId() + \" RequestID: \" + md.getRequestId());\nAlternatively, you can use verbose logging of every Java request and response.", "For more \ninformation, see Verbose Wire Logging in the AWS SDK for Java Developer Guide.\nUsing the AWS SDKs to obtain request IDs API Version 2006-03-01 1680Amazon Simple Storage Service API Reference\nUsing the AWS SDK for .NET to obtain request IDs\nYou can con\ufb01gure logging with the AWS SDK for .NET by using the built-in System.Diagnostics\nlogging tool. For more information, see the  Logging with the AWS SDK for .NET AWS Developer \nBlog  post.\nNote\nBy default, the returned log contains only error information.", "To get the request IDs, the \ncon\ufb01g \ufb01le must have AWSLogMetrics  (and optionally, AWSResponseLogging ) added.\nUsing the SDK for Python (Boto3) to obtain request IDs\nWith the AWS SDK for Python (Boto3), you can log speci\ufb01c responses.", "You can use this feature to \ncapture only the relevant headers.", "The following code shows how to log parts of the response to a \n\ufb01le:\nimport logging\nimport boto3\nlogging.basicConfig(filename='logfile.txt', level=logging.INFO)\nlogger = logging.getLogger(__name__)\ns3 = boto3.resource('s3')\nresponse = s3.Bucket(bucket_name).Object(object_key).put()\nlogger.info(\"HTTPStatusCode: %s\", response['ResponseMetadata']['HTTPStatusCode'])\nlogger.info(\"RequestId: %s\", response['ResponseMetadata']['RequestId'])\nlogger.info(\"HostId: %s\", response['ResponseMetadata']['HostId'])\nlogger.info(\"Date: %s\", response['ResponseMetadata']['HTTPHeaders']['date'])\nYou can also catch exceptions and log relevant information when an exception is raised. For more \ninformation, see Discerning useful information from error responses in the AWS SDK for Python \n(Boto) API Reference.\nAdditionally, you can con\ufb01gure Boto3 to output verbose debugging logs by using the following \ncode:\nimport boto3\nboto3.set_stream_logger('', logging.DEBUG)\nFor more information, see set_stream_logger in the AWS SDK for Python (Boto) API Reference.\nUsing the AWS SDKs to obtain request IDs API Version 2006-03-01 1681Amazon Simple Storage Service API Reference\nUsing the SDK for Ruby to obtain request IDs\nYou can get your request IDs using the SDK for Ruby Versions 1, 2, or 3.\n\u2022Using the SDK for Ruby - Version 1\u2013 You can enable HTTP wire logging globally with the \nfollowing line of code.\ns3 = AWS::S3.new(:logger => Logger.new($stdout), :http_wire_trace => true)\n\u2022Using the SDK for Ruby - Version 2 or Version 3\u2013 You can enable HTTP wire logging globally \nwith the following line of code.\ns3 = Aws::S3::Client.new(:logger => Logger.new($stdout), :http_wire_trace => true)\nFor tips on getting wire information from an AWS client, see Debugging tip: Getting wire trace \ninformation from a client.\nUsing the AWS CLI to obtain request IDs\nTo get your request IDs when using the AWS Command Line Interface (AWS CLI), add --debug  to \nyour command.\nUsing Windows PowerShell to obtain request IDs\nFor information on recovering logs with Windows PowerShell, see the Response Logging in AWS \nTools for Windows PowerShell .NET Development blog post.\nUsing AWS CloudTrail data events to obtain request IDs\nAn Amazon S3 bucket that is con\ufb01gured with CloudTrail data events to log S3 object-level API \noperations provides detailed information about actions that are taken by a user, role, or an AWS \nservice in Amazon S3. You can identify S3 request IDs by querying CloudTrail events with Athena.\nUsing S3 server access logging to obtain request IDs\nAn Amazon S3 bucket con\ufb01gured for S3 server access logging provides detailed records for each \nrequest that is made to the bucket. You can identify S3 request IDs by querying the server access \nlogs using Athena .\nUsing the AWS CLI to obtain request IDs API Version 2006-03-01 1682Amazon Simple Storage Service API Reference\nCode examples for Amazon S3 using AWS SDKs\nThe following code examples show how to use Amazon S3 with an AWS software development kit \n(SDK).\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nCode examples\n\u2022Code examples for Amazon S3 using AWS SDKs\n\u2022Basic examples for Amazon S3 using AWS SDKs\n\u2022Hello Amazon S3\n\u2022Learn the basics of Amazon S3 with an AWS SDK\n\u2022Actions for Amazon S3 using AWS SDKs\n\u2022Use AbortMultipartUpload with an AWS SDK or CLI\n\u2022Use AbortMultipartUploads with an AWS SDK\n\u2022Use CompleteMultipartUpload with an AWS SDK or CLI\n\u2022Use CopyObject with an AWS SDK or CLI\n\u2022Use CreateBucket with an AWS SDK or CLI\n\u2022Use CreateMultiRegionAccessPoint with an AWS SDK\n\u2022Use CreateMultipartUpload with an AWS SDK or CLI\n\u2022Use DeleteBucket with an AWS SDK or CLI\n\u2022Use DeleteBucketAnalyticsCon\ufb01guration with a CLI\n\u2022Use DeleteBucketCors with an AWS SDK or CLI\n\u2022Use DeleteBucketEncryption with a CLI\n\u2022Use DeleteBucketInventoryCon\ufb01guration with a CLI\n\u2022Use DeleteBucketLifecycle with an AWS SDK or CLI\n\u2022Use DeleteBucketMetricsCon\ufb01guration with a CLI\n\u2022Use DeleteBucketPolicy with an AWS SDK or CLI\n\u2022Use DeleteBucketReplication with a CLI\n\u2022Use DeleteBucketTagging with a CLI API Version 2006-03-01 1683Amazon Simple Storage Service API Reference\n\u2022Use DeleteBucketWebsite with an AWS SDK or CLI\n\u2022Use DeleteObject with an AWS SDK or CLI\n\u2022Use DeleteObjectTagging with a CLI\n\u2022Use DeleteObjects with an AWS SDK or CLI\n\u2022Use DeletePublicAccessBlock with a CLI\n\u2022Use GetBucketAccelerateCon\ufb01guration with a CLI\n\u2022Use GetBucketAcl with an AWS SDK or CLI\n\u2022Use GetBucketAnalyticsCon\ufb01guration with a CLI\n\u2022Use GetBucketCors with an AWS SDK or CLI\n\u2022Use GetBucketEncryption with an AWS SDK or CLI\n\u2022Use GetBucketInventoryCon\ufb01guration with a CLI\n\u2022Use GetBucketLifecycleCon\ufb01guration with an AWS SDK or CLI\n\u2022Use GetBucketLocation with an AWS SDK or CLI\n\u2022Use GetBucketLogging with a CLI\n\u2022Use GetBucketMetricsCon\ufb01guration with a CLI\n\u2022Use GetBucketNoti\ufb01cation with a CLI\n\u2022Use GetBucketPolicy with an AWS SDK or CLI\n\u2022Use GetBucketPolicyStatus with a CLI\n\u2022Use GetBucketReplication with a CLI\n\u2022Use GetBucketRequestPayment with a CLI\n\u2022Use GetBucketTagging with a CLI\n\u2022Use GetBucketVersioning with a CLI\n\u2022Use GetBucketWebsite with an AWS SDK or CLI\n\u2022Use GetObject with an AWS SDK or CLI\n\u2022Use GetObjectAcl with an AWS SDK or CLI\n\u2022Use GetObjectAttributes with an AWS SDK or CLI\n\u2022Use GetObjectLegalHold with an AWS SDK or CLI\n\u2022Use GetObjectLockCon\ufb01guration with an AWS SDK or CLI\n\u2022Use GetObjectRetention with an AWS SDK or CLI\n\u2022Use GetObjectTagging with a CLIAPI Version 2006-03-01 1684Amazon Simple Storage Service API Reference\n\u2022Use GetPublicAccessBlock with a CLI\n\u2022Use HeadBucket with an AWS SDK or CLI\n\u2022Use HeadObject with an AWS SDK or CLI\n\u2022Use ListBucketAnalyticsCon\ufb01gurations with a CLI\n\u2022Use ListBucketInventoryCon\ufb01gurations with a CLI\n\u2022Use ListBuckets with an AWS SDK or CLI\n\u2022Use ListMultipartUploads with an AWS SDK or CLI\n\u2022Use ListObjectVersions with an AWS SDK or CLI\n\u2022Use ListObjects with a CLI\n\u2022Use ListObjectsV2 with an AWS SDK or CLI\n\u2022Use PutBucketAccelerateCon\ufb01guration with an AWS SDK or CLI\n\u2022Use PutBucketAcl with an AWS SDK or CLI\n\u2022Use PutBucketCors with an AWS SDK or CLI\n\u2022Use PutBucketEncryption with an AWS SDK or CLI\n\u2022Use PutBucketLifecycleCon\ufb01guration with an AWS SDK or CLI\n\u2022Use PutBucketLogging with an AWS SDK or CLI\n\u2022Use PutBucketNoti\ufb01cation with a CLI\n\u2022Use PutBucketNoti\ufb01cationCon\ufb01guration with an AWS SDK or CLI\n\u2022Use PutBucketPolicy with an AWS SDK or CLI\n\u2022Use PutBucketReplication with a CLI\n\u2022Use PutBucketRequestPayment with a CLI\n\u2022Use PutBucketTagging with a CLI\n\u2022Use PutBucketVersioning with a CLI\n\u2022Use PutBucketWebsite with an AWS SDK or CLI\n\u2022Use PutObject with an AWS SDK or CLI\n\u2022Use PutObjectAcl with an AWS SDK or CLI\n\u2022Use PutObjectLegalHold with an AWS SDK or CLI\n\u2022Use PutObjectLockCon\ufb01guration with an AWS SDK or CLI\n\u2022Use PutObjectRetention with an AWS SDK or CLI\n\u2022Use RestoreObject with an AWS SDK or CLIAPI Version 2006-03-01 1685Amazon Simple Storage Service API Reference\n\u2022Use SelectObjectContent with an AWS SDK or CLI\n\u2022Use UploadPart with an AWS SDK or CLI\n\u2022Scenarios for Amazon S3 using AWS SDKs\n\u2022Convert text to speech and back to text using an AWS SDK\n\u2022Create a presigned URL for Amazon S3 using an AWS SDK\n\u2022Create a photo asset management application that lets users manage photos using labels\n\u2022A web page that lists Amazon S3 objects using an AWS SDK\n\u2022Create an Amazon Textract explorer application\n\u2022Delete all objects in a given Amazon S3 bucket using an AWS SDK.\n\u2022Delete incomplete multipart uploads to Amazon S3 using an AWS SDK\n\u2022Detect PPE in images with Amazon Rekognition using an AWS SDK\n\u2022Detect entities in text extracted from an image using an AWS SDK\n\u2022Detect faces in an image using an AWS SDK\n\u2022Detect objects in images with Amazon Rekognition using an AWS SDK\n\u2022Detect people and objects in a video with Amazon Rekognition using an AWS SDK\n\u2022Download all objects in an Amazon Simple Storage Service (Amazon S3) bucket to a local \ndirectory\n\u2022Get an Amazon S3 object from a Multi-Region Access Point by using an AWS SDK\n\u2022Get an object from an Amazon S3 bucket using an AWS SDK, specifying an If-Modi\ufb01ed-\nSince header\n\u2022Get started with encryption for Amazon S3 objects using an AWS SDK\n\u2022Get started with tags for Amazon S3 objects using an AWS SDK\n\u2022Work with Amazon S3 object lock features using an AWS SDK\n\u2022Manage access control lists (ACLs) for Amazon S3 buckets using an AWS SDK\n\u2022Manage versioned Amazon S3 objects in batches with a Lambda function using an AWS \nSDK\n\u2022Parse Amazon S3 URIs using an AWS SDK\n\u2022Perform a multipart copy of an Amazon S3 object using an AWS SDK\n\u2022Perform a multipart upload of an Amazon S3 object using an AWS SDK\n\u2022Receive and process Amazon S3 event noti\ufb01cations by using an AWS SDK.\n\u2022Save EXIF and other image information using an AWS SDKAPI Version 2006-03-01 1686Amazon Simple Storage Service API Reference\n\u2022Send S3 event noti\ufb01cations to Amazon EventBridge using an AWS SDK\n\u2022Track an Amazon S3 object upload or download using an AWS SDK\n\u2022Transform data for your application with S3 Object Lambda\n\u2022Example approaches for unit and integration testing with an AWS SDK\n\u2022Recursively upload a local directory to an Amazon Simple Storage Service (Amazon S3) \nbucket\n\u2022Upload or download large \ufb01les to and from Amazon S3 using an AWS SDK\n\u2022Upload a stream of unknown size to an Amazon S3 object using an AWS SDK\n\u2022Use checksums to work with an Amazon S3 object using an AWS SDK\n\u2022Work with Amazon S3 object integrity features using an AWS SDK\n\u2022Work with Amazon S3 versioned objects using an AWS SDK\n\u2022Serverless examples for Amazon S3 using AWS SDKs\n\u2022Invoke a Lambda function from an Amazon S3 trigger\n\u2022Code examples for Amazon S3 Control using AWS SDKs\n\u2022Basic examples for Amazon S3 Control using AWS SDKs\n\u2022Hello Amazon S3 Control\n\u2022Learn the basics of Amazon S3 Control with an AWS SDK\n\u2022Actions for Amazon S3 Control using AWS SDKs\n\u2022Use CreateJob with an AWS SDK or CLI\n\u2022Use DeleteJobTagging with an AWS SDK\n\u2022Use DescribeJob with an AWS SDK or CLI\n\u2022Use GetJobTagging with an AWS SDK\n\u2022Use PutJobTagging with an AWS SDK\n\u2022Use UpdateJobPriority with an AWS SDK or CLI\n\u2022Use UpdateJobStatus with an AWS SDK or CLI\nCode examples for Amazon S3 using AWS SDKs\nThe following code examples show how to use Amazon S3 with an AWS software development kit \n(SDK).\nBasics  are code examples that show you how to perform the essential operations within a service.\nAmazon S3 API Version 2006-03-01 1687Amazon Simple Storage Service API Reference\nActions  are code excerpts from larger programs and must be run in context. While actions show you \nhow to call individual service functions, you can see actions in context in their related scenarios.\nScenarios  are code examples that show you how to accomplish speci\ufb01c tasks by calling multiple \nfunctions within a service or combined with other AWS services.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nGet started\nHello Amazon S3\nThe following code examples show how to get started using Amazon S3.\nC++\nSDK for C++\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nCode for the CMakeLists.txt CMake \ufb01le.\n# Set the minimum required version of CMake for this project.\ncmake_minimum_required(VERSION 3.13)\n# Set the AWS service components used by this project.\nset(SERVICE_COMPONENTS s3)\n# Set this project's name.\nproject(\"hello_s3\")\n# Set the C++ standard to use to build this target.\n# At least C++ 11 is required for the AWS SDK for C++.\nset(CMAKE_CXX_STANDARD 11)\n# Use the MSVC variable to determine if this is a Windows build.\nAmazon S3 API Version 2006-03-01 1688Amazon Simple Storage Service API Reference\nset(WINDOWS_BUILD ${MSVC})\nif (WINDOWS_BUILD) # Set the location where CMake can find the installed \n libraries for the AWS SDK. \n    string(REPLACE \";\" \"/aws-cpp-sdk-all;\" SYSTEM_MODULE_PATH \n \"${CMAKE_SYSTEM_PREFIX_PATH}/aws-cpp-sdk-all\") \n    list(APPEND CMAKE_PREFIX_PATH ${SYSTEM_MODULE_PATH})\nendif ()\n# Find the AWS SDK for C++ package.\nfind_package(AWSSDK REQUIRED COMPONENTS ${SERVICE_COMPONENTS})\nif (WINDOWS_BUILD AND AWSSDK_INSTALL_AS_SHARED_LIBS) \n    # Copy relevant AWS SDK for C++ libraries into the current binary directory \n for running and debugging.", "\n    # set(BIN_SUB_DIR \"/Debug\") # if you are building from the command line you \n may need to uncomment this \n    # and set the proper subdirectory to the executables' location.", "\n    AWSSDK_CPY_DYN_LIBS(SERVICE_COMPONENTS \"\" \n ${CMAKE_CURRENT_BINARY_DIR}${BIN_SUB_DIR})\nendif ()\nadd_executable(${PROJECT_NAME} \n        hello_s3.cpp)\ntarget_link_libraries(${PROJECT_NAME} \n        ${AWSSDK_LINK_LIBRARIES})\nCode for the hello_s3.cpp source \ufb01le.\n#include <aws/core/Aws.h>\n#include <aws/s3/S3Client.h>\n#include <iostream>\n#include <aws/core/auth/AWSCredentialsProviderChain.h>\nusing namespace Aws;\nusing namespace Aws::Auth;\n/* \n *  A \"Hello S3\" starter application which initializes an Amazon Simple Storage \n Service (Amazon S3) client \nAmazon S3 API Version 2006-03-01 1689Amazon Simple Storage Service API Reference\n *  and lists the Amazon S3 buckets in the selected region. \n * \n *  main function \n * \n *  Usage: 'hello_s3' \n * \n */\nint main(int argc, char **argv) { \n    Aws::SDKOptions options; \n    // Optionally change the log level for debugging.\n//   options.loggingOptions.logLevel = Utils::Logging::LogLevel::Debug; \n    Aws::InitAPI(options); // Should only be called once.", "\n    int result = 0; \n    { \n        Aws::Client::ClientConfiguration clientConfig; \n        // Optional: Set to the AWS Region (overrides config file).", "\n        // clientConfig.region = \"us-east-1\"; \n                \n        // You don't normally have to test that you are authenticated.", "But the \n S3 service permits anonymous requests, thus the s3Client will return \"success\" \n and 0 buckets even if you are unauthenticated, which can be confusing to a new \n user. \n        auto provider = \n Aws::MakeShared<DefaultAWSCredentialsProviderChain>(\"alloc-tag\"); \n        auto creds = provider->GetAWSCredentials(); \n        if (creds.IsEmpty()) { \n            std::cerr << \"Failed authentication\" << std::endl; \n        } \n        Aws::S3::S3Client s3Client(clientConfig); \n        auto outcome = s3Client.ListBuckets(); \n        if (!outcome.IsSuccess()) { \n            std::cerr << \"Failed with error: \" << outcome.GetError() << \n std::endl; \n            result = 1; \n        } else { \n            std::cout << \"Found \" << outcome.GetResult().GetBuckets().size() \n                      << \" buckets\\n\"; \n            for (auto &bucket: outcome.GetResult().GetBuckets()) { \n                std::cout << bucket.GetName() << std::endl; \n            } \n        } \nAmazon S3 API Version 2006-03-01 1690Amazon Simple Storage Service API Reference\n    } \n    Aws::ShutdownAPI(options); // Should only be called once. \n    return result;\n}\n\u2022For API details, see ListBuckets in AWS SDK for C++ API Reference.\nGo\nSDK for Go V2\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\npackage main\nimport ( \n \"context\" \n \"fmt\" \n \"github.com/aws/aws-sdk-go-v2/config\" \n \"github.com/aws/aws-sdk-go-v2/service/s3\"\n)\n// main uses the AWS SDK for Go V2 to create an Amazon Simple Storage Service\n// (Amazon S3) client and list up to 10 buckets in your account.\n// This example uses the default settings specified in your shared credentials\n// and config files.\nfunc main() { \n ctx := context.Background() \n sdkConfig, err := config.LoadDefaultConfig(ctx) \n if err != nil { \n  fmt.Println(\"Couldn't load default configuration. Have you set up your AWS \n account?\") \n  fmt.Println(err) \n  return \nAmazon S3 API Version 2006-03-01 1691Amazon Simple Storage Service API Reference\n } \n s3Client := s3.NewFromConfig(sdkConfig) \n count := 10 \n fmt.Printf(\"Let's list up to %v buckets for your account.\\n\", count) \n result, err := s3Client.ListBuckets(ctx, &s3.ListBucketsInput{}) \n if err != nil { \n  fmt.Printf(\"Couldn't list buckets for your account.", "Here's why: %v\\n\", err) \n  return \n } \n if len(result.Buckets) == 0 { \n  fmt.Println(\"You don't have any buckets!\") \n } else { \n  if count > len(result.Buckets) { \n   count = len(result.Buckets) \n  } \n  for _, bucket := range result.Buckets[:count] { \n   fmt.Printf(\"\\t%v\\n\", *bucket.Name) \n  } \n }\n}\n\u2022For API details, see ListBuckets in AWS SDK for Go API Reference.\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nimport software.amazon.awssdk.regions.Region;\nimport software.amazon.awssdk.services.s3.S3Client;\nimport software.amazon.awssdk.services.s3.model.Bucket;\nimport software.amazon.awssdk.services.s3.model.ListBucketsResponse;\nimport software.amazon.awssdk.services.s3.model.S3Exception;\nimport java.util.List;\nAmazon S3 API Version 2006-03-01 1692Amazon Simple Storage Service API Reference\n/** \n * Before running this Java V2 code example, set up your development \n * environment, including your credentials. \n * <p> \n * For more information, see the following documentation topic: \n * <p> \n * https://docs.aws.amazon.com/sdk-for-java/latest/developer-guide/get-\nstarted.html \n */\npublic class HelloS3 { \n    public static void main(String[] args) { \n        Region region = Region.US_EAST_1; \n        S3Client s3 = S3Client.builder() \n            .region(region) \n            .build(); \n        listBuckets(s3); \n    } \n    /** \n     * Lists all the S3 buckets associated with the provided AWS S3 client. \n     * \n     * @param s3 the S3Client instance used to interact with the AWS S3 service \n     */ \n    public static void listBuckets(S3Client s3) { \n        try { \n            ListBucketsResponse response = s3.listBuckets(); \n            List<Bucket> bucketList = response.buckets(); \n            bucketList.forEach(bucket -> { \n                System.out.println(\"Bucket Name: \" + bucket.name()); \n            }); \n        } catch (S3Exception e) { \n            System.err.println(e.awsErrorDetails().errorMessage()); \n            System.exit(1); \n        } \n    }\n}\n\u2022For API details, see ListBuckets in AWS SDK for Java 2.x API Reference.\nAmazon S3 API Version 2006-03-01 1693Amazon Simple Storage Service API Reference\nJavaScript\nSDK for JavaScript (v3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nimport { \n  paginateListBuckets, \n  S3Client, \n  S3ServiceException,\n} from \"@aws-sdk/client-s3\";\n/** \n * List the S3 buckets in your configured AWS account.", "\n */\nexport const helloS3 = async () => { \n  // When no region or credentials are provided, the SDK will use the \n  // region and credentials from the local AWS config.", "\n  const client = new S3Client({}); \n  try { \n    /** \n     * @type { import(\"@aws-sdk/client-s3\").Bucket[] } \n     */ \n    const buckets = []; \n    for await (const page of paginateListBuckets({ client }, {})) { \n      buckets.push(...page.Buckets); \n    } \n    console.log(\"Buckets: \"); \n    console.log(buckets.map((bucket) => bucket.Name).join(\"\\n\")); \n    return buckets; \n  } catch (caught) { \n    // ListBuckets does not throw any modeled errors.", "Any error caught \n    // here will be something generic like `AccessDenied`.", "\n    if (caught instanceof S3ServiceException) { \n      console.error(`${caught.name}: ${caught.message}`); \n    } else { \nAmazon S3 API Version 2006-03-01 1694Amazon Simple Storage Service API Reference\n      // Something besides S3 failed.", "\n      throw caught; \n    } \n  }\n};\n\u2022For API details, see ListBuckets in AWS SDK for JavaScript API Reference.\nPHP\nSDK for PHP\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nuse Aws\\S3\\S3Client;\n$client = new S3Client(['region' => 'us-west-2']);\n$results = $client->listBuckets();\nvar_dump($results);\n\u2022For API details, see ListBuckets in AWS SDK for PHP API Reference.\nPython\nSDK for Python (Boto3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nimport boto3\nAmazon S3 API Version 2006-03-01 1695Amazon Simple Storage Service API Reference\ndef hello_s3(): \n    \"\"\" \n    Use the AWS SDK for Python (Boto3) to create an Amazon Simple Storage Service \n    (Amazon S3) resource and list the buckets in your account.", "\n    This example uses the default settings specified in your shared credentials \n    and config files.", "\n    \"\"\" \n    s3_resource = boto3.resource(\"s3\") \n    print(\"Hello, Amazon S3! Let's list your buckets:\") \n    for bucket in s3_resource.buckets.all(): \n        print(f\"\\t{bucket.name}\")\nif __name__ == \"__main__\": \n    hello_s3()\n\u2022For API details, see ListBuckets in AWS SDK for Python (Boto3) API Reference.\nRuby\nSDK for Ruby\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n# frozen_string_literal: true\n# S3Manager is a class responsible for managing S3 operations\n# such as listing all S3 buckets in the current AWS account.\nclass S3Manager \n  def initialize(client) \n    @client = client \n    @logger = Logger.new($stdout) \n  end \nAmazon S3 API Version 2006-03-01 1696Amazon Simple Storage Service API Reference\n  # Lists and prints all S3 buckets in the current AWS account.", "\n  def list_buckets \n    @logger.info('Here are the buckets in your account:') \n    response = @client.list_buckets \n    if response.buckets.empty? \n      @logger.info(\"You don't have any S3 buckets yet.\") \n    else \n      response.buckets.each do |bucket| \n        @logger.info(\"- #{bucket.name}\") \n      end \n    end \n  rescue Aws::Errors::ServiceError => e \n    @logger.error(\"Encountered an error while listing buckets: #{e.message}\") \n  end\nend\nif $PROGRAM_NAME == __FILE__ \n  s3_client = Aws::S3::Client.new \n  manager = S3Manager.new(s3_client) \n  manager.list_buckets\nend\n\u2022For API details, see ListBuckets in AWS SDK for Ruby API Reference.\nRust\nSDK for Rust\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n/// S3 Hello World Example using the AWS SDK for Rust.\n///\n/// This example lists the objects in a bucket, uploads an object to that bucket,\nAmazon S3 API Version 2006-03-01 1697Amazon Simple Storage Service API Reference\n/// and then retrieves the object and prints some S3 information about the \n object.\n/// This shows a number of S3 features, including how to use built-in paginators\n/// for large data sets.\n///\n/// # Arguments\n///\n/// * `client` - an S3 client configured appropriately for the environment.\n/// * `bucket` - the bucket name that the object will be uploaded to. Must be \n present in the region the `client` is configured to use.\n/// * `filename` - a reference to a path that will be read and uploaded to S3.\n/// * `key` - the string key that the object will be uploaded as inside the \n bucket.\nasync fn list_bucket_and_upload_object( \n    client: &aws_sdk_s3::Client, \n    bucket: &str, \n    filepath: &Path, \n    key: &str,\n) -> Result<(), S3ExampleError> { \n    // List the buckets in this account \n    let mut objects = client \n        .list_objects_v2() \n        .bucket(bucket) \n        .into_paginator() \n        .send(); \n    println!(\"key\\tetag\\tlast_modified\\tstorage_class\"); \n    while let Some(Ok(object)) = objects.next().await { \n        for item in object.contents() { \n            println!( \n                \"{}\\t{}\\t{}\\t{}\", \n                item.key().unwrap_or_default(), \n                item.e_tag().unwrap_or_default(), \n                item.last_modified() \n                    .map(|lm| format!(\"{lm}\")) \n                    .unwrap_or_default(), \n                item.storage_class() \n                    .map(|sc| format!(\"{sc}\")) \n                    .unwrap_or_default() \n            ); \n        } \n    } \nAmazon S3 API Version 2006-03-01 1698Amazon Simple Storage Service API Reference\n    // Prepare a ByteStream around the file, and upload the object using that \n ByteStream. \n    let body = aws_sdk_s3::primitives::ByteStream::from_path(filepath) \n        .await \n        .map_err(|err| { \n            S3ExampleError::new(format!( \n                \"Failed to create bytestream for {filepath:?} ({err:?})\" \n            )) \n        })?; \n    let resp = client \n        .put_object() \n        .bucket(bucket) \n        .key(key) \n        .body(body) \n        .send() \n        .await?; \n    println!( \n        \"Upload success. Version: {:?}\", \n        resp.version_id() \n            .expect(\"S3 Object upload missing version ID\") \n    ); \n    // Retrieve the just-uploaded object. \n    let resp = client.get_object().bucket(bucket).key(key).send().await?; \n    println!(\"etag: {}\", resp.e_tag().unwrap_or(\"(missing)\")); \n    println!(\"version: {}\", resp.version_id().unwrap_or(\"(missing)\")); \n    Ok(())\n}\nS3ExampleError utilities\n/// S3ExampleError provides a From<T: ProvideErrorMetadata> impl to extract\n/// client-specific error details. This serves as a consistent backup to handling\n/// specific service errors, depending on what is needed by the scenario.\n/// It is used throughout the code examples for the AWS SDK for Rust.\n#[derive(Debug)]\npub struct S3ExampleError(String);\nimpl S3ExampleError { \n    pub fn new(value: impl Into<String>) -> Self { \n        S3ExampleError(value.into()) \nAmazon S3 API Version 2006-03-01 1699Amazon Simple Storage Service API Reference\n    } \n    pub fn add_message(self, message: impl Into<String>) -> Self { \n        S3ExampleError(format!(\"{}: {}\", message.into(), self.0)) \n    }\n}\nimpl<T: aws_sdk_s3::error::ProvideErrorMetadata> From<T> for S3ExampleError { \n    fn from(value: T) -> Self { \n        S3ExampleError(format!( \n            \"{}: {}\", \n            value \n                .code() \n                .map(String::from) \n                .unwrap_or(\"unknown code\".into()), \n            value \n                .message() \n                .map(String::from) \n                .unwrap_or(\"missing reason\".into()), \n        )) \n    }\n}\nimpl std::error::Error for S3ExampleError {}\nimpl std::fmt::Display for S3ExampleError { \n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result { \n        write!(f, \"{}\", self.0) \n    }\n}\n\u2022For API details, see ListBuckets in AWS SDK for Rust API reference.\nCode examples\n\u2022Basic examples for Amazon S3 using AWS SDKs\n\u2022Hello Amazon S3\n\u2022Learn the basics of Amazon S3 with an AWS SDK\n\u2022Actions for Amazon S3 using AWS SDKs\n\u2022Use AbortMultipartUpload with an AWS SDK or CLI\nAmazon S3 API Version 2006-03-01 1700Amazon Simple Storage Service API Reference\n\u2022Use AbortMultipartUploads with an AWS SDK\n\u2022Use CompleteMultipartUpload with an AWS SDK or CLI\n\u2022Use CopyObject with an AWS SDK or CLI\n\u2022Use CreateBucket with an AWS SDK or CLI\n\u2022Use CreateMultiRegionAccessPoint with an AWS SDK\n\u2022Use CreateMultipartUpload with an AWS SDK or CLI\n\u2022Use DeleteBucket with an AWS SDK or CLI\n\u2022Use DeleteBucketAnalyticsCon\ufb01guration with a CLI\n\u2022Use DeleteBucketCors with an AWS SDK or CLI\n\u2022Use DeleteBucketEncryption with a CLI\n\u2022Use DeleteBucketInventoryCon\ufb01guration with a CLI\n\u2022Use DeleteBucketLifecycle with an AWS SDK or CLI\n\u2022Use DeleteBucketMetricsCon\ufb01guration with a CLI\n\u2022Use DeleteBucketPolicy with an AWS SDK or CLI\n\u2022Use DeleteBucketReplication with a CLI\n\u2022Use DeleteBucketTagging with a CLI\n\u2022Use DeleteBucketWebsite with an AWS SDK or CLI\n\u2022Use DeleteObject with an AWS SDK or CLI\n\u2022Use DeleteObjectTagging with a CLI\n\u2022Use DeleteObjects with an AWS SDK or CLI\n\u2022Use DeletePublicAccessBlock with a CLI\n\u2022Use GetBucketAccelerateCon\ufb01guration with a CLI\n\u2022Use GetBucketAcl with an AWS SDK or CLI\n\u2022Use GetBucketAnalyticsCon\ufb01guration with a CLI\n\u2022Use GetBucketCors with an AWS SDK or CLI\n\u2022Use GetBucketEncryption with an AWS SDK or CLI\n\u2022Use GetBucketInventoryCon\ufb01guration with a CLI\n\u2022Use GetBucketLifecycleCon\ufb01guration with an AWS SDK or CLI\n\u2022Use GetBucketLocation with an AWS SDK or CLI\n\u2022Use GetBucketLogging with a CLIAmazon S3 API Version 2006-03-01 1701Amazon Simple Storage Service API Reference\n\u2022Use GetBucketMetricsCon\ufb01guration with a CLI\n\u2022Use GetBucketNoti\ufb01cation with a CLI\n\u2022Use GetBucketPolicy with an AWS SDK or CLI\n\u2022Use GetBucketPolicyStatus with a CLI\n\u2022Use GetBucketReplication with a CLI\n\u2022Use GetBucketRequestPayment with a CLI\n\u2022Use GetBucketTagging with a CLI\n\u2022Use GetBucketVersioning with a CLI\n\u2022Use GetBucketWebsite with an AWS SDK or CLI\n\u2022Use GetObject with an AWS SDK or CLI\n\u2022Use GetObjectAcl with an AWS SDK or CLI\n\u2022Use GetObjectAttributes with an AWS SDK or CLI\n\u2022Use GetObjectLegalHold with an AWS SDK or CLI\n\u2022Use GetObjectLockCon\ufb01guration with an AWS SDK or CLI\n\u2022Use GetObjectRetention with an AWS SDK or CLI\n\u2022Use GetObjectTagging with a CLI\n\u2022Use GetPublicAccessBlock with a CLI\n\u2022Use HeadBucket with an AWS SDK or CLI\n\u2022Use HeadObject with an AWS SDK or CLI\n\u2022Use ListBucketAnalyticsCon\ufb01gurations with a CLI\n\u2022Use ListBucketInventoryCon\ufb01gurations with a CLI\n\u2022Use ListBuckets with an AWS SDK or CLI\n\u2022Use ListMultipartUploads with an AWS SDK or CLI\n\u2022Use ListObjectVersions with an AWS SDK or CLI\n\u2022Use ListObjects with a CLI\n\u2022Use ListObjectsV2 with an AWS SDK or CLI\n\u2022Use PutBucketAccelerateCon\ufb01guration with an AWS SDK or CLI\n\u2022Use PutBucketAcl with an AWS SDK or CLI\n\u2022Use PutBucketCors with an AWS SDK or CLI\n\u2022Use PutBucketEncryption with an AWS SDK or CLIAmazon S3 API Version 2006-03-01 1702Amazon Simple Storage Service API Reference\n\u2022Use PutBucketLifecycleCon\ufb01guration with an AWS SDK or CLI\n\u2022Use PutBucketLogging with an AWS SDK or CLI\n\u2022Use PutBucketNoti\ufb01cation with a CLI\n\u2022Use PutBucketNoti\ufb01cationCon\ufb01guration with an AWS SDK or CLI\n\u2022Use PutBucketPolicy with an AWS SDK or CLI\n\u2022Use PutBucketReplication with a CLI\n\u2022Use PutBucketRequestPayment with a CLI\n\u2022Use PutBucketTagging with a CLI\n\u2022Use PutBucketVersioning with a CLI\n\u2022Use PutBucketWebsite with an AWS SDK or CLI\n\u2022Use PutObject with an AWS SDK or CLI\n\u2022Use PutObjectAcl with an AWS SDK or CLI\n\u2022Use PutObjectLegalHold with an AWS SDK or CLI\n\u2022Use PutObjectLockCon\ufb01guration with an AWS SDK or CLI\n\u2022Use PutObjectRetention with an AWS SDK or CLI\n\u2022Use RestoreObject with an AWS SDK or CLI\n\u2022Use SelectObjectContent with an AWS SDK or CLI\n\u2022Use UploadPart with an AWS SDK or CLI\n\u2022Scenarios for Amazon S3 using AWS SDKs\n\u2022Convert text to speech and back to text using an AWS SDK\n\u2022Create a presigned URL for Amazon S3 using an AWS SDK\n\u2022Create a photo asset management application that lets users manage photos using labels\n\u2022A web page that lists Amazon S3 objects using an AWS SDK\n\u2022Create an Amazon Textract explorer application\n\u2022Delete all objects in a given Amazon S3 bucket using an AWS SDK.\n\u2022Delete incomplete multipart uploads to Amazon S3 using an AWS SDK\n\u2022Detect PPE in images with Amazon Rekognition using an AWS SDK\n\u2022Detect entities in text extracted from an image using an AWS SDK\n\u2022Detect faces in an image using an AWS SDK\n\u2022Detect objects in images with Amazon Rekognition using an AWS SDKAmazon S3 API Version 2006-03-01 1703Amazon Simple Storage Service API Reference\n\u2022Detect people and objects in a video with Amazon Rekognition using an AWS SDK\n\u2022Download all objects in an Amazon Simple Storage Service (Amazon S3) bucket to a local \ndirectory\n\u2022Get an Amazon S3 object from a Multi-Region Access Point by using an AWS SDK\n\u2022Get an object from an Amazon S3 bucket using an AWS SDK, specifying an If-Modi\ufb01ed-Since \nheader\n\u2022Get started with encryption for Amazon S3 objects using an AWS SDK\n\u2022Get started with tags for Amazon S3 objects using an AWS SDK\n\u2022Work with Amazon S3 object lock features using an AWS SDK\n\u2022Manage access control lists (ACLs) for Amazon S3 buckets using an AWS SDK\n\u2022Manage versioned Amazon S3 objects in batches with a Lambda function using an AWS SDK\n\u2022Parse Amazon S3 URIs using an AWS SDK\n\u2022Perform a multipart copy of an Amazon S3 object using an AWS SDK\n\u2022Perform a multipart upload of an Amazon S3 object using an AWS SDK\n\u2022Receive and process Amazon S3 event noti\ufb01cations by using an AWS SDK.\n\u2022Save EXIF and other image information using an AWS SDK\n\u2022Send S3 event noti\ufb01cations to Amazon EventBridge using an AWS SDK\n\u2022Track an Amazon S3 object upload or download using an AWS SDK\n\u2022Transform data for your application with S3 Object Lambda\n\u2022Example approaches for unit and integration testing with an AWS SDK\n\u2022Recursively upload a local directory to an Amazon Simple Storage Service (Amazon S3) bucket\n\u2022Upload or download large \ufb01les to and from Amazon S3 using an AWS SDK\n\u2022Upload a stream of unknown size to an Amazon S3 object using an AWS SDK\n\u2022Use checksums to work with an Amazon S3 object using an AWS SDK\n\u2022Work with Amazon S3 object integrity features using an AWS SDK\n\u2022Work with Amazon S3 versioned objects using an AWS SDK\n\u2022Serverless examples for Amazon S3 using AWS SDKs\n\u2022Invoke a Lambda function from an Amazon S3 trigger\nAmazon S3 API Version 2006-03-01 1704Amazon Simple Storage Service API Reference\nBasic examples for Amazon S3 using AWS SDKs\nThe following code examples show how to use the basics of Amazon Simple Storage Service with \nAWS SDKs.\nExamples\n\u2022Hello Amazon S3\n\u2022Learn the basics of Amazon S3 with an AWS SDK\n\u2022Actions for Amazon S3 using AWS SDKs\n\u2022Use AbortMultipartUpload with an AWS SDK or CLI\n\u2022Use AbortMultipartUploads with an AWS SDK\n\u2022Use CompleteMultipartUpload with an AWS SDK or CLI\n\u2022Use CopyObject with an AWS SDK or CLI\n\u2022Use CreateBucket with an AWS SDK or CLI\n\u2022Use CreateMultiRegionAccessPoint with an AWS SDK\n\u2022Use CreateMultipartUpload with an AWS SDK or CLI\n\u2022Use DeleteBucket with an AWS SDK or CLI\n\u2022Use DeleteBucketAnalyticsCon\ufb01guration with a CLI\n\u2022Use DeleteBucketCors with an AWS SDK or CLI\n\u2022Use DeleteBucketEncryption with a CLI\n\u2022Use DeleteBucketInventoryCon\ufb01guration with a CLI\n\u2022Use DeleteBucketLifecycle with an AWS SDK or CLI\n\u2022Use DeleteBucketMetricsCon\ufb01guration with a CLI\n\u2022Use DeleteBucketPolicy with an AWS SDK or CLI\n\u2022Use DeleteBucketReplication with a CLI\n\u2022Use DeleteBucketTagging with a CLI\n\u2022Use DeleteBucketWebsite with an AWS SDK or CLI\n\u2022Use DeleteObject with an AWS SDK or CLI\n\u2022Use DeleteObjectTagging with a CLI\n\u2022Use DeleteObjects with an AWS SDK or CLI\n\u2022Use DeletePublicAccessBlock with a CLI\n\u2022Use GetBucketAccelerateCon\ufb01guration with a CLI\nBasics API Version 2006-03-01 1705Amazon Simple Storage Service API Reference\n\u2022Use GetBucketAcl with an AWS SDK or CLI\n\u2022Use GetBucketAnalyticsCon\ufb01guration with a CLI\n\u2022Use GetBucketCors with an AWS SDK or CLI\n\u2022Use GetBucketEncryption with an AWS SDK or CLI\n\u2022Use GetBucketInventoryCon\ufb01guration with a CLI\n\u2022Use GetBucketLifecycleCon\ufb01guration with an AWS SDK or CLI\n\u2022Use GetBucketLocation with an AWS SDK or CLI\n\u2022Use GetBucketLogging with a CLI\n\u2022Use GetBucketMetricsCon\ufb01guration with a CLI\n\u2022Use GetBucketNoti\ufb01cation with a CLI\n\u2022Use GetBucketPolicy with an AWS SDK or CLI\n\u2022Use GetBucketPolicyStatus with a CLI\n\u2022Use GetBucketReplication with a CLI\n\u2022Use GetBucketRequestPayment with a CLI\n\u2022Use GetBucketTagging with a CLI\n\u2022Use GetBucketVersioning with a CLI\n\u2022Use GetBucketWebsite with an AWS SDK or CLI\n\u2022Use GetObject with an AWS SDK or CLI\n\u2022Use GetObjectAcl with an AWS SDK or CLI\n\u2022Use GetObjectAttributes with an AWS SDK or CLI\n\u2022Use GetObjectLegalHold with an AWS SDK or CLI\n\u2022Use GetObjectLockCon\ufb01guration with an AWS SDK or CLI\n\u2022Use GetObjectRetention with an AWS SDK or CLI\n\u2022Use GetObjectTagging with a CLI\n\u2022Use GetPublicAccessBlock with a CLI\n\u2022Use HeadBucket with an AWS SDK or CLI\n\u2022Use HeadObject with an AWS SDK or CLI\n\u2022Use ListBucketAnalyticsCon\ufb01gurations with a CLI\n\u2022Use ListBucketInventoryCon\ufb01gurations with a CLI\n\u2022Use ListBuckets with an AWS SDK or CLIBasics API Version 2006-03-01 1706Amazon Simple Storage Service API Reference\n\u2022Use ListMultipartUploads with an AWS SDK or CLI\n\u2022Use ListObjectVersions with an AWS SDK or CLI\n\u2022Use ListObjects with a CLI\n\u2022Use ListObjectsV2 with an AWS SDK or CLI\n\u2022Use PutBucketAccelerateCon\ufb01guration with an AWS SDK or CLI\n\u2022Use PutBucketAcl with an AWS SDK or CLI\n\u2022Use PutBucketCors with an AWS SDK or CLI\n\u2022Use PutBucketEncryption with an AWS SDK or CLI\n\u2022Use PutBucketLifecycleCon\ufb01guration with an AWS SDK or CLI\n\u2022Use PutBucketLogging with an AWS SDK or CLI\n\u2022Use PutBucketNoti\ufb01cation with a CLI\n\u2022Use PutBucketNoti\ufb01cationCon\ufb01guration with an AWS SDK or CLI\n\u2022Use PutBucketPolicy with an AWS SDK or CLI\n\u2022Use PutBucketReplication with a CLI\n\u2022Use PutBucketRequestPayment with a CLI\n\u2022Use PutBucketTagging with a CLI\n\u2022Use PutBucketVersioning with a CLI\n\u2022Use PutBucketWebsite with an AWS SDK or CLI\n\u2022Use PutObject with an AWS SDK or CLI\n\u2022Use PutObjectAcl with an AWS SDK or CLI\n\u2022Use PutObjectLegalHold with an AWS SDK or CLI\n\u2022Use PutObjectLockCon\ufb01guration with an AWS SDK or CLI\n\u2022Use PutObjectRetention with an AWS SDK or CLI\n\u2022Use RestoreObject with an AWS SDK or CLI\n\u2022Use SelectObjectContent with an AWS SDK or CLI\n\u2022Use UploadPart with an AWS SDK or CLI\nHello Amazon S3\nThe following code examples show how to get started using Amazon S3.Basics API Version 2006-03-01 1707Amazon Simple Storage Service API Reference\nC++\nSDK for C++\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nCode for the CMakeLists.txt CMake \ufb01le.\n# Set the minimum required version of CMake for this project.\ncmake_minimum_required(VERSION 3.13)\n# Set the AWS service components used by this project.\nset(SERVICE_COMPONENTS s3)\n# Set this project's name.\nproject(\"hello_s3\")\n# Set the C++ standard to use to build this target.\n# At least C++ 11 is required for the AWS SDK for C++.\nset(CMAKE_CXX_STANDARD 11)\n# Use the MSVC variable to determine if this is a Windows build.\nset(WINDOWS_BUILD ${MSVC})\nif (WINDOWS_BUILD) # Set the location where CMake can find the installed \n libraries for the AWS SDK. \n    string(REPLACE \";\" \"/aws-cpp-sdk-all;\" SYSTEM_MODULE_PATH \n \"${CMAKE_SYSTEM_PREFIX_PATH}/aws-cpp-sdk-all\") \n    list(APPEND CMAKE_PREFIX_PATH ${SYSTEM_MODULE_PATH})\nendif ()\n# Find the AWS SDK for C++ package.\nfind_package(AWSSDK REQUIRED COMPONENTS ${SERVICE_COMPONENTS})\nif (WINDOWS_BUILD AND AWSSDK_INSTALL_AS_SHARED_LIBS) \n    # Copy relevant AWS SDK for C++ libraries into the current binary directory \n for running and debugging.", "\nBasics API Version 2006-03-01 1708Amazon Simple Storage Service API Reference\n    # set(BIN_SUB_DIR \"/Debug\") # if you are building from the command line you \n may need to uncomment this \n    # and set the proper subdirectory to the executables' location.", "\n    AWSSDK_CPY_DYN_LIBS(SERVICE_COMPONENTS \"\" \n ${CMAKE_CURRENT_BINARY_DIR}${BIN_SUB_DIR})\nendif ()\nadd_executable(${PROJECT_NAME} \n        hello_s3.cpp)\ntarget_link_libraries(${PROJECT_NAME} \n        ${AWSSDK_LINK_LIBRARIES})\nCode for the hello_s3.cpp source \ufb01le.\n#include <aws/core/Aws.h>\n#include <aws/s3/S3Client.h>\n#include <iostream>\n#include <aws/core/auth/AWSCredentialsProviderChain.h>\nusing namespace Aws;\nusing namespace Aws::Auth;\n/* \n *  A \"Hello S3\" starter application which initializes an Amazon Simple Storage \n Service (Amazon S3) client \n *  and lists the Amazon S3 buckets in the selected region. \n * \n *  main function \n * \n *  Usage: 'hello_s3' \n * \n */\nint main(int argc, char **argv) { \n    Aws::SDKOptions options; \n    // Optionally change the log level for debugging.\n//   options.loggingOptions.logLevel = Utils::Logging::LogLevel::Debug; \n    Aws::InitAPI(options); // Should only be called once.", "\n    int result = 0; \n    { \n        Aws::Client::ClientConfiguration clientConfig; \nBasics API Version 2006-03-01 1709Amazon Simple Storage Service API Reference\n        // Optional: Set to the AWS Region (overrides config file).", "\n        // clientConfig.region = \"us-east-1\"; \n                \n        // You don't normally have to test that you are authenticated.", "But the \n S3 service permits anonymous requests, thus the s3Client will return \"success\" \n and 0 buckets even if you are unauthenticated, which can be confusing to a new \n user. \n        auto provider = \n Aws::MakeShared<DefaultAWSCredentialsProviderChain>(\"alloc-tag\"); \n        auto creds = provider->GetAWSCredentials(); \n        if (creds.IsEmpty()) { \n            std::cerr << \"Failed authentication\" << std::endl; \n        } \n        Aws::S3::S3Client s3Client(clientConfig); \n        auto outcome = s3Client.ListBuckets(); \n        if (!outcome.IsSuccess()) { \n            std::cerr << \"Failed with error: \" << outcome.GetError() << \n std::endl; \n            result = 1; \n        } else { \n            std::cout << \"Found \" << outcome.GetResult().GetBuckets().size() \n                      << \" buckets\\n\"; \n            for (auto &bucket: outcome.GetResult().GetBuckets()) { \n                std::cout << bucket.GetName() << std::endl; \n            } \n        } \n    } \n    Aws::ShutdownAPI(options); // Should only be called once.", "\n    return result;\n}\n\u2022For API details, see ListBuckets in AWS SDK for C++ API Reference.\nBasics API Version 2006-03-01 1710Amazon Simple Storage Service API Reference\nGo\nSDK for Go V2\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\npackage main\nimport ( \n \"context\" \n \"fmt\" \n \"github.com/aws/aws-sdk-go-v2/config\" \n \"github.com/aws/aws-sdk-go-v2/service/s3\"\n)\n// main uses the AWS SDK for Go V2 to create an Amazon Simple Storage Service\n// (Amazon S3) client and list up to 10 buckets in your account.\n// This example uses the default settings specified in your shared credentials\n// and config files.\nfunc main() { \n ctx := context.Background() \n sdkConfig, err := config.LoadDefaultConfig(ctx) \n if err != nil { \n  fmt.Println(\"Couldn't load default configuration. Have you set up your AWS \n account?\") \n  fmt.Println(err) \n  return \n } \n s3Client := s3.NewFromConfig(sdkConfig) \n count := 10 \n fmt.Printf(\"Let's list up to %v buckets for your account.\\n\", count) \n result, err := s3Client.ListBuckets(ctx, &s3.ListBucketsInput{}) \n if err != nil { \n  fmt.Printf(\"Couldn't list buckets for your account.", "Here's why: %v\\n\", err) \n  return \n } \nBasics API Version 2006-03-01 1711Amazon Simple Storage Service API Reference\n if len(result.Buckets) == 0 { \n  fmt.Println(\"You don't have any buckets!\") \n } else { \n  if count > len(result.Buckets) { \n   count = len(result.Buckets) \n  } \n  for _, bucket := range result.Buckets[:count] { \n   fmt.Printf(\"\\t%v\\n\", *bucket.Name) \n  } \n }\n}\n\u2022For API details, see ListBuckets in AWS SDK for Go API Reference.\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nimport software.amazon.awssdk.regions.Region;\nimport software.amazon.awssdk.services.s3.S3Client;\nimport software.amazon.awssdk.services.s3.model.Bucket;\nimport software.amazon.awssdk.services.s3.model.ListBucketsResponse;\nimport software.amazon.awssdk.services.s3.model.S3Exception;\nimport java.util.List;\n/** \n * Before running this Java V2 code example, set up your development \n * environment, including your credentials. \n * <p> \n * For more information, see the following documentation topic: \n * <p> \n * https://docs.aws.amazon.com/sdk-for-java/latest/developer-guide/get-\nstarted.html \nBasics API Version 2006-03-01 1712Amazon Simple Storage Service API Reference\n */\npublic class HelloS3 { \n    public static void main(String[] args) { \n        Region region = Region.US_EAST_1; \n        S3Client s3 = S3Client.builder() \n            .region(region) \n            .build(); \n        listBuckets(s3); \n    } \n    /** \n     * Lists all the S3 buckets associated with the provided AWS S3 client. \n     * \n     * @param s3 the S3Client instance used to interact with the AWS S3 service \n     */ \n    public static void listBuckets(S3Client s3) { \n        try { \n            ListBucketsResponse response = s3.listBuckets(); \n            List<Bucket> bucketList = response.buckets(); \n            bucketList.forEach(bucket -> { \n                System.out.println(\"Bucket Name: \" + bucket.name()); \n            }); \n        } catch (S3Exception e) { \n            System.err.println(e.awsErrorDetails().errorMessage()); \n            System.exit(1); \n        } \n    }\n}\n\u2022For API details, see ListBuckets in AWS SDK for Java 2.x API Reference.\nJavaScript\nSDK for JavaScript (v3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nBasics API Version 2006-03-01 1713Amazon Simple Storage Service API Reference\nimport { \n  paginateListBuckets, \n  S3Client, \n  S3ServiceException,\n} from \"@aws-sdk/client-s3\";\n/** \n * List the S3 buckets in your configured AWS account.", "\n */\nexport const helloS3 = async () => { \n  // When no region or credentials are provided, the SDK will use the \n  // region and credentials from the local AWS config.", "\n  const client = new S3Client({}); \n  try { \n    /** \n     * @type { import(\"@aws-sdk/client-s3\").Bucket[] } \n     */ \n    const buckets = []; \n    for await (const page of paginateListBuckets({ client }, {})) { \n      buckets.push(...page.Buckets); \n    } \n    console.log(\"Buckets: \"); \n    console.log(buckets.map((bucket) => bucket.Name).join(\"\\n\")); \n    return buckets; \n  } catch (caught) { \n    // ListBuckets does not throw any modeled errors.", "Any error caught \n    // here will be something generic like `AccessDenied`.", "\n    if (caught instanceof S3ServiceException) { \n      console.error(`${caught.name}: ${caught.message}`); \n    } else { \n      // Something besides S3 failed.", "\n      throw caught; \n    } \n  }\n};\n\u2022For API details, see ListBuckets in AWS SDK for JavaScript API Reference.\nBasics API Version 2006-03-01 1714Amazon Simple Storage Service API Reference\nPHP\nSDK for PHP\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nuse Aws\\S3\\S3Client;\n$client = new S3Client(['region' => 'us-west-2']);\n$results = $client->listBuckets();\nvar_dump($results);\n\u2022For API details, see ListBuckets in AWS SDK for PHP API Reference.\nPython\nSDK for Python (Boto3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nimport boto3\ndef hello_s3(): \n    \"\"\" \n    Use the AWS SDK for Python (Boto3) to create an Amazon Simple Storage Service \n    (Amazon S3) resource and list the buckets in your account.", "\n    This example uses the default settings specified in your shared credentials \n    and config files.", "\n    \"\"\" \n    s3_resource = boto3.resource(\"s3\") \nBasics API Version 2006-03-01 1715Amazon Simple Storage Service API Reference\n    print(\"Hello, Amazon S3! Let's list your buckets:\") \n    for bucket in s3_resource.buckets.all(): \n        print(f\"\\t{bucket.name}\")\nif __name__ == \"__main__\": \n    hello_s3()\n\u2022For API details, see ListBuckets in AWS SDK for Python (Boto3) API Reference.\nRuby\nSDK for Ruby\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n# frozen_string_literal: true\n# S3Manager is a class responsible for managing S3 operations\n# such as listing all S3 buckets in the current AWS account.\nclass S3Manager \n  def initialize(client) \n    @client = client \n    @logger = Logger.new($stdout) \n  end \n  # Lists and prints all S3 buckets in the current AWS account.", "\n  def list_buckets \n    @logger.info('Here are the buckets in your account:') \n    response = @client.list_buckets \n    if response.buckets.empty?", "\n      @logger.info(\"You don't have any S3 buckets yet.\") \n    else \n      response.buckets.each do |bucket| \nBasics API Version 2006-03-01 1716Amazon Simple Storage Service API Reference\n        @logger.info(\"- #{bucket.name}\") \n      end \n    end \n  rescue Aws::Errors::ServiceError => e \n    @logger.error(\"Encountered an error while listing buckets: #{e.message}\") \n  end\nend\nif $PROGRAM_NAME == __FILE__ \n  s3_client = Aws::S3::Client.new \n  manager = S3Manager.new(s3_client) \n  manager.list_buckets\nend\n\u2022For API details, see ListBuckets in AWS SDK for Ruby API Reference.\nRust\nSDK for Rust\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n/// S3 Hello World Example using the AWS SDK for Rust.\n///\n/// This example lists the objects in a bucket, uploads an object to that bucket,\n/// and then retrieves the object and prints some S3 information about the \n object.\n/// This shows a number of S3 features, including how to use built-in paginators\n/// for large data sets.\n///\n/// # Arguments\n///\n/// * `client` - an S3 client configured appropriately for the environment.\n/// * `bucket` - the bucket name that the object will be uploaded to. Must be \n present in the region the `client` is configured to use.\n/// * `filename` - a reference to a path that will be read and uploaded to S3.\nBasics API Version 2006-03-01 1717Amazon Simple Storage Service API Reference\n/// * `key` - the string key that the object will be uploaded as inside the \n bucket.\nasync fn list_bucket_and_upload_object( \n    client: &aws_sdk_s3::Client, \n    bucket: &str, \n    filepath: &Path, \n    key: &str,\n) -> Result<(), S3ExampleError> { \n    // List the buckets in this account \n    let mut objects = client \n        .list_objects_v2() \n        .bucket(bucket) \n        .into_paginator() \n        .send(); \n    println!(\"key\\tetag\\tlast_modified\\tstorage_class\"); \n    while let Some(Ok(object)) = objects.next().await { \n        for item in object.contents() { \n            println!( \n                \"{}\\t{}\\t{}\\t{}\", \n                item.key().unwrap_or_default(), \n                item.e_tag().unwrap_or_default(), \n                item.last_modified() \n                    .map(|lm| format!(\"{lm}\")) \n                    .unwrap_or_default(), \n                item.storage_class() \n                    .map(|sc| format!(\"{sc}\")) \n                    .unwrap_or_default() \n            ); \n        } \n    } \n    // Prepare a ByteStream around the file, and upload the object using that \n ByteStream. \n    let body = aws_sdk_s3::primitives::ByteStream::from_path(filepath) \n        .await \n        .map_err(|err| { \n            S3ExampleError::new(format!( \n                \"Failed to create bytestream for {filepath:?} ({err:?})\" \n            )) \n        })?; \n    let resp = client \n        .put_object() \n        .bucket(bucket) \nBasics API Version 2006-03-01 1718Amazon Simple Storage Service API Reference\n        .key(key) \n        .body(body) \n        .send() \n        .await?; \n    println!( \n        \"Upload success. Version: {:?}\", \n        resp.version_id() \n            .expect(\"S3 Object upload missing version ID\") \n    ); \n    // Retrieve the just-uploaded object. \n    let resp = client.get_object().bucket(bucket).key(key).send().await?; \n    println!(\"etag: {}\", resp.e_tag().unwrap_or(\"(missing)\")); \n    println!(\"version: {}\", resp.version_id().unwrap_or(\"(missing)\")); \n    Ok(())\n}\nS3ExampleError utilities\n/// S3ExampleError provides a From<T: ProvideErrorMetadata> impl to extract\n/// client-specific error details. This serves as a consistent backup to handling\n/// specific service errors, depending on what is needed by the scenario.\n/// It is used throughout the code examples for the AWS SDK for Rust.\n#[derive(Debug)]\npub struct S3ExampleError(String);\nimpl S3ExampleError { \n    pub fn new(value: impl Into<String>) -> Self { \n        S3ExampleError(value.into()) \n    } \n    pub fn add_message(self, message: impl Into<String>) -> Self { \n        S3ExampleError(format!(\"{}: {}\", message.into(), self.0)) \n    }\n}\nimpl<T: aws_sdk_s3::error::ProvideErrorMetadata> From<T> for S3ExampleError { \n    fn from(value: T) -> Self { \n        S3ExampleError(format!( \n            \"{}: {}\", \n            value \nBasics API Version 2006-03-01 1719Amazon Simple Storage Service API Reference\n                .code() \n                .map(String::from) \n                .unwrap_or(\"unknown code\".into()), \n            value \n                .message() \n                .map(String::from) \n                .unwrap_or(\"missing reason\".into()), \n        )) \n    }\n}\nimpl std::error::Error for S3ExampleError {}\nimpl std::fmt::Display for S3ExampleError { \n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result { \n        write!(f, \"{}\", self.0) \n    }\n}\n\u2022For API details, see ListBuckets in AWS SDK for Rust API reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nLearn the basics of Amazon S3 with an AWS SDK\nThe following code examples show how to:\n\u2022Create a bucket and upload a \ufb01le to it.\n\u2022Download an object from a bucket.\n\u2022Copy an object to a subfolder in a bucket.\n\u2022List the objects in a bucket.\n\u2022Delete the bucket objects and the bucket.\nBasics API Version 2006-03-01 1720Amazon Simple Storage Service API Reference\n.NET\nAWS SDK for .NET\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n    public class S3_Basics \n    { \n        public static async Task Main() \n        { \n            // Create an Amazon S3 client object.", "The constructor uses the \n            // default user installed on the system.", "To work with Amazon S3 \n            // features in a different AWS Region, pass the AWS Region as a \n            // parameter to the client constructor. \n            IAmazonS3 client = new AmazonS3Client(); \n            string bucketName = string.Empty; \n            string filePath = string.Empty; \n            string keyName = string.Empty; \n            var sepBar = new string('-', Console.WindowWidth); \n            Console.WriteLine(sepBar); \n            Console.WriteLine(\"Amazon Simple Storage Service (Amazon S3) basic\"); \n            Console.WriteLine(\"procedures.", "This application will:\"); \n            Console.WriteLine(\"\\n\\t1. Create a bucket\"); \n            Console.WriteLine(\"\\n\\t2. Upload an object to the new bucket\"); \n            Console.WriteLine(\"\\n\\t3. Copy the uploaded object to a folder in the \n bucket\"); \n            Console.WriteLine(\"\\n\\t4. List the items in the new bucket\"); \n            Console.WriteLine(\"\\n\\t5. Delete all the items in the bucket\"); \n            Console.WriteLine(\"\\n\\t6. Delete the bucket\"); \n            Console.WriteLine(sepBar); \n            // Create a bucket. \n            Console.WriteLine($\"\\n{sepBar}\"); \n            Console.WriteLine(\"\\nCreate a new Amazon S3 bucket.\\n\"); \n            Console.WriteLine(sepBar); \nBasics API Version 2006-03-01 1721Amazon Simple Storage Service API Reference\n            Console.Write(\"Please enter a name for the new bucket: \"); \n            bucketName = Console.ReadLine(); \n            var success = await S3Bucket.CreateBucketAsync(client, bucketName); \n            if (success) \n            { \n                Console.WriteLine($\"Successfully created bucket: {bucketName}.\n\\n\"); \n            } \n            else \n            { \n                Console.WriteLine($\"Could not create bucket: {bucketName}.\\n\"); \n            } \n            Console.WriteLine(sepBar); \n            Console.WriteLine(\"Upload a file to the new bucket.\"); \n            Console.WriteLine(sepBar); \n            // Get the local path and filename for the file to upload.", "\n            while (string.IsNullOrEmpty(filePath)) \n            { \n                Console.Write(\"Please enter the path and filename of the file to \n upload: \"); \n                filePath = Console.ReadLine(); \n                // Confirm that the file exists on the local computer. \n                if (!File.Exists(filePath)) \n                { \n                    Console.WriteLine($\"Couldn't find {filePath}. Try again.\\n\"); \n                    filePath = string.Empty; \n                } \n            } \n            // Get the file name from the full path.", "\n            keyName = Path.GetFileName(filePath); \n            success = await S3Bucket.UploadFileAsync(client, bucketName, keyName, \n filePath); \n            if (success) \n            { \n                Console.WriteLine($\"Successfully uploaded {keyName} from \n {filePath} to {bucketName}.\\n\"); \n            } \nBasics API Version 2006-03-01 1722Amazon Simple Storage Service API Reference\n            else \n            { \n                Console.WriteLine($\"Could not upload {keyName}.\\n\"); \n            } \n            // Set the file path to an empty string to avoid overwriting the \n            // file we just uploaded to the bucket.", "\n            filePath = string.Empty; \n            // Now get a new location where we can save the file. \n            while (string.IsNullOrEmpty(filePath)) \n            { \n                // First get the path to which the file will be downloaded. \n                Console.Write(\"Please enter the path where the file will be \n downloaded: \"); \n                filePath = Console.ReadLine(); \n                // Confirm that the file exists on the local computer. \n                if (File.Exists($\"{filePath}\\\\{keyName}\")) \n                { \n                    Console.WriteLine($\"Sorry, the file already exists in that \n location.\\n\"); \n                    filePath = string.Empty; \n                } \n            } \n            // Download an object from a bucket. \n            success = await S3Bucket.DownloadObjectFromBucketAsync(client, \n bucketName, keyName, filePath); \n            if (success) \n            { \n                Console.WriteLine($\"Successfully downloaded {keyName}.\\n\"); \n            } \n            else \n            { \n                Console.WriteLine($\"Sorry, could not download {keyName}.\\n\"); \n            } \n            // Copy the object to a different folder in the bucket.", "\n            string folderName = string.Empty; \n            while (string.IsNullOrEmpty(folderName)) \n            { \nBasics API Version 2006-03-01 1723Amazon Simple Storage Service API Reference\n                Console.Write(\"Please enter the name of the folder to copy your \n object to: \"); \n                folderName = Console.ReadLine(); \n            } \n            while (string.IsNullOrEmpty(keyName)) \n            { \n                // Get the name to give to the object once uploaded.", "\n                Console.Write(\"Enter the name of the object to copy: \"); \n                keyName = Console.ReadLine(); \n            } \n            await S3Bucket.CopyObjectInBucketAsync(client, bucketName, keyName, \n folderName); \n            // List the objects in the bucket. \n            await S3Bucket.ListBucketContentsAsync(client, bucketName); \n            // Delete the contents of the bucket. \n            await S3Bucket.DeleteBucketContentsAsync(client, bucketName); \n            // Deleting the bucket too quickly after deleting its contents will \n            // cause an error that the bucket isn't empty.", "So...", "\n            Console.WriteLine(\"Press <Enter> when you are ready to delete the \n bucket.\"); \n            _ = Console.ReadLine(); \n            // Delete the bucket.", "\n            await S3Bucket.DeleteBucketAsync(client, bucketName); \n        } \n    }\n\u2022For API details, see the following topics in AWS SDK for .NET API Reference.\n\u2022CopyObject\n\u2022CreateBucket\n\u2022DeleteBucket\n\u2022DeleteObjects\n\u2022GetObject\n\u2022ListObjectsV2\nBasics API Version 2006-03-01 1724Amazon Simple Storage Service API Reference\n\u2022PutObject\nBash\nAWS CLI with Bash script\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n###############################################################################\n# function s3_getting_started\n#\n# This function creates, copies, and deletes S3 buckets and objects.\n#\n# Returns:\n#       0 - If successful.\n#       1 - If an error occurred.\n###############################################################################\nfunction s3_getting_started() { \n  { \n    if [ \"$BUCKET_OPERATIONS_SOURCED\" != \"True\" ]; then \n      cd bucket-lifecycle-operations || exit \n      source ./bucket_operations.sh \n      cd .. \n    fi \n  } \n  echo_repeat \"*\" 88 \n  echo \"Welcome to the Amazon S3 getting started demo.\" \n  echo_repeat \"*\" 88 \n    echo \"A unique bucket will be created by appending a Universally Unique \n Identifier to a bucket name prefix.\" \n    echo -n \"Enter a prefix for the S3 bucket that will be used in this demo: \" \n    get_input \n    bucket_name_prefix=$get_input_result \n  local bucket_name \n  bucket_name=$(generate_random_name \"$bucket_name_prefix\") \nBasics API Version 2006-03-01 1725Amazon Simple Storage Service API Reference\n  local region_code \n  region_code=$(aws configure get region) \n  if create_bucket -b \"$bucket_name\" -r \"$region_code\"; then \n    echo \"Created demo bucket named $bucket_name\" \n  else \n    errecho \"The bucket failed to create. This demo will exit.\" \n    return 1 \n  fi \n  local file_name \n  while [ -z \"$file_name\" ]; do \n    echo -n \"Enter a file you want to upload to your bucket: \" \n    get_input \n    file_name=$get_input_result \n    if [ ! -f \"$file_name\" ]; then \n      echo \"Could not find file $file_name. Are you sure it exists?\" \n      file_name=\"\" \n    fi \n  done \n  local key \n  key=\"$(basename \"$file_name\")\" \n  local result=0 \n  if copy_file_to_bucket \"$bucket_name\" \"$file_name\" \"$key\"; then \n    echo \"Uploaded file $file_name into bucket $bucket_name with key $key.\" \n  else \n    result=1 \n  fi \n  local destination_file \n  destination_file=\"$file_name.download\" \n  if yes_no_input \"Would you like to download $key to the file $destination_file? \n (y/n) \"; then \n    if download_object_from_bucket \"$bucket_name\" \"$destination_file\" \"$key\"; \n then \n      echo \"Downloaded $key in the bucket $bucket_name to the file \n $destination_file.\" \n    else \n      result=1 \n    fi \nBasics API Version 2006-03-01 1726Amazon Simple Storage Service API Reference\n  fi \n  if yes_no_input \"Would you like to copy $key a new object key in your bucket? \n (y/n) \"; then \n    local to_key \n    to_key=\"demo/$key\" \n    if copy_item_in_bucket \"$bucket_name\" \"$key\" \"$to_key\"; then \n      echo \"Copied $key in the bucket $bucket_name to the  $to_key.\" \n    else \n      result=1 \n    fi \n  fi \n  local bucket_items \n  bucket_items=$(list_items_in_bucket \"$bucket_name\") \n  # shellcheck disable=SC2181 \n  if [[ $? -ne 0 ]]; then \n    result=1 \n  fi \n  echo \"Your bucket contains the following items.\" \n  echo -e \"Name\\t\\tSize\" \n  echo \"$bucket_items\" \n  if yes_no_input \"Delete the bucket, $bucket_name, as well as the objects in it? \n (y/n) \"; then \n    bucket_items=$(echo \"$bucket_items\" | cut -f 1) \n    if delete_items_in_bucket \"$bucket_name\" \"$bucket_items\"; then \n      echo \"The following items were deleted from the bucket $bucket_name\" \n      echo \"$bucket_items\" \n    else \n      result=1 \n    fi \n    if delete_bucket \"$bucket_name\"; then \n      echo \"Deleted the bucket $bucket_name\" \n    else \n      result=1 \n    fi \n  fi \n  return $result\nBasics API Version 2006-03-01 1727Amazon Simple Storage Service API Reference\n}\nThe Amazon S3 functions used in this scenario.\n###############################################################################\n# function create-bucket\n#\n# This function creates the specified bucket in the specified AWS Region, unless\n# it already exists.\n#\n# Parameters:\n#       -b bucket_name  -- The name of the bucket to create.\n#       -r region_code  -- The code for an AWS Region in which to\n#                          create the bucket.\n#\n# Returns:\n#       The URL of the bucket that was created.\n#     And:\n#       0 - If successful.\n#       1 - If it fails.\n###############################################################################\nfunction create_bucket() { \n  local bucket_name region_code response \n  local option OPTARG # Required to use getopts command in a function. \n  # bashsupport disable=BP5008 \n  function usage() { \n    echo \"function create_bucket\" \n    echo \"Creates an Amazon S3 bucket. You must supply a bucket name:\" \n    echo \"  -b bucket_name    The name of the bucket. It must be globally \n unique.\" \n    echo \"  [-r region_code]    The code for an AWS Region in which the bucket is \n created.\" \n    echo \"\" \n  } \n  # Retrieve the calling parameters. \n  while getopts \"b:r:h\" option; do \n    case \"${option}\" in \n      b) bucket_name=\"${OPTARG}\" ;; \n      r) region_code=\"${OPTARG}\" ;; \n      h) \nBasics API Version 2006-03-01 1728Amazon Simple Storage Service API Reference\n        usage \n        return 0 \n        ;; \n      \\?) \n        echo \"Invalid parameter\" \n        usage \n        return 1 \n        ;; \n    esac \n  done \n  if [[ -z \"$bucket_name\" ]]; then \n    errecho \"ERROR: You must provide a bucket name with the -b parameter.\" \n    usage \n    return 1 \n  fi \n  local bucket_config_arg \n  # A location constraint for \"us-east-1\" returns an error. \n  if [[ -n \"$region_code\" ]] && [[ \"$region_code\" != \"us-east-1\" ]]; then \n    bucket_config_arg=\"--create-bucket-configuration LocationConstraint=\n$region_code\" \n  fi \n  iecho \"Parameters:\\n\" \n  iecho \"    Bucket name:   $bucket_name\" \n  iecho \"    Region code:   $region_code\" \n  iecho \"\" \n  # If the bucket already exists, we don't want to try to create it.", "\n  if (bucket_exists \"$bucket_name\"); then \n    errecho \"ERROR: A bucket with that name already exists. Try again.\" \n    return 1 \n  fi \n  # shellcheck disable=SC2086 \n  response=$(aws s3api create-bucket \\ \n    --bucket \"$bucket_name\" \\ \n    $bucket_config_arg) \n  # shellcheck disable=SC2181 \n  if [[ ${?} -ne 0 ]]; then \n    errecho \"ERROR: AWS reports create-bucket operation failed.\\n$response\" \n    return 1 \nBasics API Version 2006-03-01 1729Amazon Simple Storage Service API Reference\n  fi\n}\n###############################################################################\n# function copy_file_to_bucket\n#\n# This function creates a file in the specified bucket.\n#\n# Parameters:\n#       $1 - The name of the bucket to copy the file to.\n#       $2 - The path and file name of the local file to copy to the bucket.\n#       $3 - The key (name) to call the copy of the file in the bucket.\n#\n# Returns:\n#       0 - If successful.\n#       1 - If it fails.\n###############################################################################\nfunction copy_file_to_bucket() { \n  local response bucket_name source_file destination_file_name \n  bucket_name=$1 \n  source_file=$2 \n  destination_file_name=$3 \n  response=$(aws s3api put-object \\ \n    --bucket \"$bucket_name\" \\ \n    --body \"$source_file\" \\ \n    --key \"$destination_file_name\") \n  # shellcheck disable=SC2181 \n  if [[ ${?} -ne 0 ]]; then \n    errecho \"ERROR: AWS reports put-object operation failed.\\n$response\" \n    return 1 \n  fi\n}\n###############################################################################\n# function download_object_from_bucket\n#\n# This function downloads an object in a bucket to a file.\n#\n# Parameters:\n#       $1 - The name of the bucket to download the object from.\n#       $2 - The path and file name to store the downloaded bucket.\n#       $3 - The key (name) of the object in the bucket.\nBasics API Version 2006-03-01 1730Amazon Simple Storage Service API Reference\n#\n# Returns:\n#       0 - If successful.\n#       1 - If it fails.\n###############################################################################\nfunction download_object_from_bucket() { \n  local bucket_name=$1 \n  local destination_file_name=$2 \n  local object_name=$3 \n  local response \n  response=$(aws s3api get-object \\ \n    --bucket \"$bucket_name\" \\ \n    --key \"$object_name\" \\ \n    \"$destination_file_name\") \n  # shellcheck disable=SC2181 \n  if [[ ${?} -ne 0 ]]; then \n    errecho \"ERROR: AWS reports put-object operation failed.\\n$response\" \n    return 1 \n  fi\n}\n###############################################################################\n# function copy_item_in_bucket\n#\n# This function creates a copy of the specified file in the same bucket.\n#\n# Parameters:\n#       $1 - The name of the bucket to copy the file from and to.\n#       $2 - The key of the source file to copy.\n#       $3 - The key of the destination file.\n#\n# Returns:\n#       0 - If successful.\n#       1 - If it fails.\n###############################################################################\nfunction copy_item_in_bucket() { \n  local bucket_name=$1 \n  local source_key=$2 \n  local destination_key=$3 \n  local response \n  response=$(aws s3api copy-object \\ \nBasics API Version 2006-03-01 1731Amazon Simple Storage Service API Reference\n    --bucket \"$bucket_name\" \\ \n    --copy-source \"$bucket_name/$source_key\" \\ \n    --key \"$destination_key\") \n  # shellcheck disable=SC2181 \n  if [[ $? -ne 0 ]]; then \n    errecho \"ERROR:  AWS reports s3api copy-object operation failed.\\n$response\" \n    return 1 \n  fi\n}\n###############################################################################\n# function list_items_in_bucket\n#\n# This function displays a list of the files in the bucket with each file's\n# size. The function uses the --query parameter to retrieve only the key and\n# size fields from the Contents collection.\n#\n# Parameters:\n#       $1 - The name of the bucket.\n#\n# Returns:\n#       The list of files in text format.\n#     And:\n#       0 - If successful.\n#       1 - If it fails.\n###############################################################################\nfunction list_items_in_bucket() { \n  local bucket_name=$1 \n  local response \n  response=$(aws s3api list-objects \\ \n    --bucket \"$bucket_name\" \\ \n    --output text \\ \n    --query 'Contents[].{Key: Key, Size: Size}') \n  # shellcheck disable=SC2181 \n  if [[ ${?} -eq 0 ]]; then \n    echo \"$response\" \n  else \n    errecho \"ERROR: AWS reports s3api list-objects operation failed.\\n$response\" \n    return 1 \n  fi\n}\nBasics API Version 2006-03-01 1732Amazon Simple Storage Service API Reference\n###############################################################################\n# function delete_items_in_bucket\n#\n# This function deletes the specified list of keys from the specified bucket.\n#\n# Parameters:\n#       $1 - The name of the bucket.\n#       $2 - A list of keys in the bucket to delete.\n# Returns:\n#       0 - If successful.\n#       1 - If it fails.\n###############################################################################\nfunction delete_items_in_bucket() { \n  local bucket_name=$1 \n  local keys=$2 \n  local response \n  # Create the JSON for the items to delete. \n  local delete_items \n  delete_items=\"{\\\"Objects\\\":[\" \n  for key in $keys; do \n    delete_items=\"$delete_items{\\\"Key\\\": \\\"$key\\\"},\" \n  done \n  delete_items=${delete_items%?} # Remove the final comma.", "\n  delete_items=\"$delete_items]}\" \n  response=$(aws s3api delete-objects \\ \n    --bucket \"$bucket_name\" \\ \n    --delete \"$delete_items\") \n  # shellcheck disable=SC2181 \n  if [[ $? -ne 0 ]]; then \n    errecho \"ERROR:  AWS reports s3api delete-object operation failed.\\n\n$response\" \n    return 1 \n  fi\n}\n###############################################################################\n# function delete_bucket\n#\n# This function deletes the specified bucket.\nBasics API Version 2006-03-01 1733Amazon Simple Storage Service API Reference\n#\n# Parameters:\n#       $1 - The name of the bucket.\n# Returns:\n#       0 - If successful.\n#       1 - If it fails.\n###############################################################################\nfunction delete_bucket() { \n  local bucket_name=$1 \n  local response \n  response=$(aws s3api delete-bucket \\ \n    --bucket \"$bucket_name\") \n  # shellcheck disable=SC2181 \n  if [[ $? -ne 0 ]]; then \n    errecho \"ERROR: AWS reports s3api delete-bucket failed.\\n$response\" \n    return 1 \n  fi\n}\n\u2022For API details, see the following topics in AWS CLI Command Reference.\n\u2022CopyObject\n\u2022CreateBucket\n\u2022DeleteBucket\n\u2022DeleteObjects\n\u2022GetObject\n\u2022ListObjectsV2\n\u2022PutObject\nBasics API Version 2006-03-01 1734Amazon Simple Storage Service API Reference\nC++\nSDK for C++\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n#include <iostream>\n#include <aws/core/Aws.h>\n#include <aws/s3/S3Client.h>\n#include <aws/s3/model/CopyObjectRequest.h>\n#include <aws/s3/model/CreateBucketRequest.h>\n#include <aws/s3/model/DeleteBucketRequest.h>\n#include <aws/s3/model/DeleteObjectRequest.h>\n#include <aws/s3/model/GetObjectRequest.h>\n#include <aws/s3/model/ListObjectsV2Request.h>\n#include <aws/s3/model/PutObjectRequest.h>\n#include <aws/s3/model/BucketLocationConstraint.h>\n#include <aws/s3/model/CreateBucketConfiguration.h>\n#include <aws/core/utils/UUID.h>\n#include <aws/core/utils/StringUtils.h>\n#include <aws/core/utils/memory/stl/AWSAllocator.h>\n#include <fstream>\n#include \"s3_examples.h\"\nnamespace AwsDoc { \n    namespace S3 { \n        //! Delete an S3 bucket.", "\n        /*!", "\n          \\param bucketName: The S3 bucket's name. \n          \\param client: An S3 client.", "\n          \\return bool: Function succeeded.", "\n        */ \n        static bool \n        deleteBucket(const Aws::String &bucketName, Aws::S3::S3Client &client); \n        //! Delete an object in an S3 bucket.", "\n        /*!", "\nBasics API Version 2006-03-01 1735Amazon Simple Storage Service API Reference\n          \\param bucketName: The S3 bucket's name. \n          \\param key: The key for the object in the S3 bucket. \n          \\param client: An S3 client.", "\n          \\return bool: Function succeeded.", "\n         */ \n        static bool \n        deleteObjectFromBucket(const Aws::String &bucketName, const Aws::String \n &key, \n                               Aws::S3::S3Client &client); \n    }\n}\n//! Scenario to create, copy, and delete S3 buckets and objects.\n/*!", "\n  \\param bucketNamePrefix: A prefix for a bucket name.", "\n  \\param uploadFilePath: Path to file to upload to an Amazon S3 bucket. \n  \\param saveFilePath: Path for saving a downloaded S3 object.", "\n  \\param clientConfig: Aws client configuration.", "\n  \\return bool: Function succeeded.", "\n */\nbool AwsDoc::S3::S3_GettingStartedScenario(const Aws::String &bucketNamePrefix, \n        const Aws::String &uploadFilePath, \n                                           const Aws::String &saveFilePath, \n                                           const Aws::Client::ClientConfiguration \n &clientConfig) { \n    Aws::S3::S3Client client(clientConfig); \n    // Create a unique bucket name which is only temporary and will be deleted.", "\n    // Format: <bucketNamePrefix> + \"-\" + lowercase UUID. \n    Aws::String uuid = Aws::Utils::UUID::RandomUUID(); \n    Aws::String bucketName = bucketNamePrefix + \n                             Aws::Utils::StringUtils::ToLower(uuid.c_str()); \n    // 1. Create a bucket. \n    { \n        Aws::S3::Model::CreateBucketRequest request; \n        request.SetBucket(bucketName); \n        if (clientConfig.region != Aws::Region::US_EAST_1) { \n            Aws::S3::Model::CreateBucketConfiguration createBucketConfiguration; \n            createBucketConfiguration.WithLocationConstraint( \nBasics API Version 2006-03-01 1736Amazon Simple Storage Service API Reference\n                   \n Aws::S3::Model::BucketLocationConstraintMapper::GetBucketLocationConstraintForName( \n                            clientConfig.region)); \n            request.WithCreateBucketConfiguration(createBucketConfiguration); \n        } \n        Aws::S3::Model::CreateBucketOutcome outcome = \n client.CreateBucket(request); \n        if (!outcome.IsSuccess()) { \n            const Aws::S3::S3Error &err = outcome.GetError(); \n            std::cerr << \"Error: createBucket: \" << \n                      err.GetExceptionName() << \": \" << err.GetMessage() << \n std::endl; \n            return false; \n        } else { \n            std::cout << \"Created the bucket, '\" << bucketName << \n                      \"', in the region, '\" << clientConfig.region << \"'.\" << \n std::endl; \n        } \n    } \n    // 2.", "Upload a local file to the bucket. \n    Aws::String key = \"key-for-test\"; \n    { \n        Aws::S3::Model::PutObjectRequest request; \n        request.SetBucket(bucketName); \n        request.SetKey(key); \n        std::shared_ptr<Aws::FStream> input_data = \n                Aws::MakeShared<Aws::FStream>(\"SampleAllocationTag\", \n                                              uploadFilePath, \n                                              std::ios_base::in | \n                                              std::ios_base::binary); \n        if (!input_data->is_open()) { \n            std::cerr << \"Error: unable to open file, '\" << uploadFilePath << \n \"'.\" \n                      << std::endl; \n            AwsDoc::S3::deleteBucket(bucketName, client); \n            return false; \n        } \n        request.SetBody(input_data); \nBasics API Version 2006-03-01 1737Amazon Simple Storage Service API Reference\n        Aws::S3::Model::PutObjectOutcome outcome = \n                client.PutObject(request); \n        if (!outcome.IsSuccess()) { \n            std::cerr << \"Error: putObject: \" << \n                      outcome.GetError().GetMessage() << std::endl; \n            AwsDoc::S3::deleteObjectFromBucket(bucketName, key, client); \n            AwsDoc::S3::deleteBucket(bucketName, client); \n            return false; \n        } else { \n            std::cout << \"Added the object with the key, '\" << key \n                      << \"', to the bucket, '\" \n                      << bucketName << \"'.\" << std::endl; \n        } \n    } \n    // 3.", "Download the object to a local file.", "\n    { \n        Aws::S3::Model::GetObjectRequest request; \n        request.SetBucket(bucketName); \n        request.SetKey(key); \n        Aws::S3::Model::GetObjectOutcome outcome = \n                client.GetObject(request); \n        if (!outcome.IsSuccess()) { \n            const Aws::S3::S3Error &err = outcome.GetError(); \n            std::cerr << \"Error: getObject: \" << \n                      err.GetExceptionName() << \": \" << err.GetMessage() << \n std::endl; \n        } else { \n            std::cout << \"Downloaded the object with the key, '\" << key \n                      << \"', in the bucket, '\" \n                      << bucketName << \"'.\" << std::endl; \n            Aws::IOStream &ioStream = outcome.GetResultWithOwnership().", "\n                    GetBody(); \n            Aws::OFStream outStream(saveFilePath, \n                                    std::ios_base::out | std::ios_base::binary); \n            if (!outStream.is_open()) { \n                std::cout << \"Error: unable to open file, '\" << saveFilePath << \n \"'.\" \n                          << std::endl; \nBasics API Version 2006-03-01 1738Amazon Simple Storage Service API Reference\n            } else { \n                outStream << ioStream.rdbuf(); \n                std::cout << \"Wrote the downloaded object to the file '\" \n                          << saveFilePath << \"'.\" << std::endl; \n            } \n        } \n    } \n    // 4.", "Copy the object to a different \"folder\" in the bucket. \n    Aws::String copiedToKey = \"test-folder/\" + key; \n    { \n        Aws::S3::Model::CopyObjectRequest request; \n        request.WithBucket(bucketName) \n                .WithKey(copiedToKey) \n                .WithCopySource(bucketName + \"/\" + key); \n        Aws::S3::Model::CopyObjectOutcome outcome = \n                client.CopyObject(request); \n        if (!outcome.IsSuccess()) { \n            std::cerr << \"Error: copyObject: \" << \n                      outcome.GetError().GetMessage() << std::endl; \n        } else { \n            std::cout << \"Copied the object with the key, '\" << key \n                      << \"', to the key, '\" << copiedToKey \n                      << \", in the bucket, '\" << bucketName << \"'.\" << std::endl; \n        } \n    } \n    // 5.", "List objects in the bucket. \n    { \n        Aws::S3::Model::ListObjectsV2Request request; \n        request.WithBucket(bucketName); \n        Aws::String continuationToken; \n        Aws::Vector<Aws::S3::Model::Object> allObjects; \n        do { \n            if (!continuationToken.empty()) { \n                request.SetContinuationToken(continuationToken); \n            } \n            Aws::S3::Model::ListObjectsV2Outcome outcome = client.ListObjectsV2( \n                    request); \n            if (!outcome.IsSuccess()) { \nBasics API Version 2006-03-01 1739Amazon Simple Storage Service API Reference\n                std::cerr << \"Error: ListObjects: \" << \n                          outcome.GetError().GetMessage() << std::endl; \n                break; \n            } else { \n                Aws::Vector<Aws::S3::Model::Object> objects = \n                        outcome.GetResult().GetContents(); \n                allObjects.insert(allObjects.end(), objects.begin(), \n objects.end()); \n                continuationToken = outcome.GetResult().GetContinuationToken(); \n            } \n        } while (!continuationToken.empty()); \n        std::cout << allObjects.size() << \" objects in the bucket, '\" << \n bucketName \n                  << \"':\" << std::endl; \n        for (Aws::S3::Model::Object &object: allObjects) { \n            std::cout << \"     '\" << object.GetKey() << \"'\" << std::endl; \n        } \n    } \n    // 6. Delete all objects in the bucket. \n    // All objects in the bucket must be deleted before deleting the bucket.", "\n    AwsDoc::S3::deleteObjectFromBucket(bucketName, copiedToKey, client); \n    AwsDoc::S3::deleteObjectFromBucket(bucketName, key, client); \n    // 7.", "Delete the bucket. \n    return AwsDoc::S3::deleteBucket(bucketName, client);\n}\nbool AwsDoc::S3::deleteObjectFromBucket(const Aws::String &bucketName, \n                                        const Aws::String &key, \n                                        Aws::S3::S3Client &client) { \n    Aws::S3::Model::DeleteObjectRequest request; \n    request.SetBucket(bucketName); \n    request.SetKey(key); \n    Aws::S3::Model::DeleteObjectOutcome outcome = \n            client.DeleteObject(request); \n    if (!outcome.IsSuccess()) { \n        std::cerr << \"Error: deleteObject: \" << \n                  outcome.GetError().GetMessage() << std::endl; \n    } else { \nBasics API Version 2006-03-01 1740Amazon Simple Storage Service API Reference\n        std::cout << \"Deleted the object with the key, '\" << key \n                  << \"', from the bucket, '\" \n                  << bucketName << \"'.\" << std::endl; \n    } \n    return outcome.IsSuccess();\n}\nbool\nAwsDoc::S3::deleteBucket(const Aws::String &bucketName, Aws::S3::S3Client \n &client) { \n    Aws::S3::Model::DeleteBucketRequest request; \n    request.SetBucket(bucketName); \n    Aws::S3::Model::DeleteBucketOutcome outcome = \n            client.DeleteBucket(request); \n    if (!outcome.IsSuccess()) { \n        const Aws::S3::S3Error &err = outcome.GetError(); \n        std::cerr << \"Error: deleteBucket: \" << \n                  err.GetExceptionName() << \": \" << err.GetMessage() << \n std::endl; \n    } else { \n        std::cout << \"Deleted the bucket, '\" << bucketName << \"'.\" << std::endl; \n    } \n    return outcome.IsSuccess();\n}\n\u2022For API details, see the following topics in AWS SDK for C++ API Reference.\n\u2022CopyObject\n\u2022CreateBucket\n\u2022DeleteBucket\n\u2022DeleteObjects\n\u2022GetObject\n\u2022ListObjectsV2\n\u2022PutObject\nBasics API Version 2006-03-01 1741Amazon Simple Storage Service API Reference\nGo\nSDK for Go V2\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nDe\ufb01ne a struct that wraps bucket and object actions used by the scenario.\n// BucketBasics encapsulates the Amazon Simple Storage Service (Amazon S3) \n actions\n// used in the examples.\n// It contains S3Client, an Amazon S3 service client that is used to perform \n bucket\n// and object actions.\ntype BucketBasics struct { \n S3Client *s3.Client\n}\n// ListBuckets lists the buckets in the current account.\nfunc (basics BucketBasics) ListBuckets(ctx context.Context) ([]types.Bucket, \n error) { \n result, err := basics.S3Client.ListBuckets(ctx, &s3.ListBucketsInput{}) \n var buckets []types.Bucket \n if err != nil { \n  log.Printf(\"Couldn't list buckets for your account. Here's why: %v\\n\", err) \n } else { \n  buckets = result.Buckets \n } \n return buckets, err\n}\n// BucketExists checks whether a bucket exists in the current account.\nfunc (basics BucketBasics) BucketExists(ctx context.Context, bucketName string) \n (bool, error) { \nBasics API Version 2006-03-01 1742Amazon Simple Storage Service API Reference\n _, err := basics.S3Client.HeadBucket(ctx, &s3.HeadBucketInput{ \n  Bucket: aws.String(bucketName), \n }) \n exists := true \n if err != nil { \n  var apiError smithy.APIError \n  if errors.As(err, &apiError) { \n   switch apiError.(type) { \n   case *types.NotFound: \n    log.Printf(\"Bucket %v is available.\\n\", bucketName) \n    exists = false \n    err = nil \n   default: \n    log.Printf(\"Either you don't have access to bucket %v or another error \n occurred. \"+ \n     \"Here's what happened: %v\\n\", bucketName, err) \n   } \n  } \n } else { \n  log.Printf(\"Bucket %v exists and you already own it.\", bucketName) \n } \n return exists, err\n}\n// CreateBucket creates a bucket with the specified name in the specified Region.\nfunc (basics BucketBasics) CreateBucket(ctx context.Context, name string, region \n string) error { \n _, err := basics.S3Client.CreateBucket(ctx, &s3.CreateBucketInput{ \n  Bucket: aws.String(name), \n  CreateBucketConfiguration: &types.CreateBucketConfiguration{ \n   LocationConstraint: types.BucketLocationConstraint(region), \n  }, \n }) \n if err != nil { \n  log.Printf(\"Couldn't create bucket %v in Region %v. Here's why: %v\\n\", \n   name, region, err) \n } \n return err\n}\nBasics API Version 2006-03-01 1743Amazon Simple Storage Service API Reference\n// UploadFile reads from a file and puts the data into an object in a bucket.\nfunc (basics BucketBasics) UploadFile(ctx context.Context, bucketName string, \n objectKey string, fileName string) error { \n file, err := os.Open(fileName) \n if err != nil { \n  log.Printf(\"Couldn't open file %v to upload. Here's why: %v\\n\", fileName, err) \n } else { \n  defer file.Close() \n  _, err = basics.S3Client.PutObject(ctx, &s3.PutObjectInput{ \n   Bucket: aws.String(bucketName), \n   Key:    aws.String(objectKey), \n   Body:   file, \n  }) \n  if err != nil { \n   log.Printf(\"Couldn't upload file %v to %v:%v. Here's why: %v\\n\", \n    fileName, bucketName, objectKey, err) \n  } \n } \n return err\n}\n// UploadLargeObject uses an upload manager to upload data to an object in a \n bucket.\n// The upload manager breaks large data into parts and uploads the parts \n concurrently.\nfunc (basics BucketBasics) UploadLargeObject(ctx context.Context, bucketName \n string, objectKey string, largeObject []byte) error { \n largeBuffer := bytes.NewReader(largeObject) \n var partMiBs int64 = 10 \n uploader := manager.NewUploader(basics.S3Client, func(u *manager.Uploader) { \n  u.PartSize = partMiBs * 1024 * 1024 \n }) \n _, err := uploader.Upload(ctx, &s3.PutObjectInput{ \n  Bucket: aws.String(bucketName), \n  Key:    aws.String(objectKey), \n  Body:   largeBuffer, \n }) \n if err != nil { \n  log.Printf(\"Couldn't upload large object to %v:%v. Here's why: %v\\n\", \n   bucketName, objectKey, err) \n } \nBasics API Version 2006-03-01 1744Amazon Simple Storage Service API Reference\n return err\n}\n// DownloadFile gets an object from a bucket and stores it in a local file.\nfunc (basics BucketBasics) DownloadFile(ctx context.Context, bucketName string, \n objectKey string, fileName string) error { \n result, err := basics.S3Client.GetObject(ctx, &s3.GetObjectInput{ \n  Bucket: aws.String(bucketName), \n  Key:    aws.String(objectKey), \n }) \n if err != nil { \n  log.Printf(\"Couldn't get object %v:%v. Here's why: %v\\n\", bucketName, \n objectKey, err) \n  return err \n } \n defer result.Body.Close() \n file, err := os.Create(fileName) \n if err != nil { \n  log.Printf(\"Couldn't create file %v. Here's why: %v\\n\", fileName, err) \n  return err \n } \n defer file.Close() \n body, err := io.ReadAll(result.Body) \n if err != nil { \n  log.Printf(\"Couldn't read object body from %v.", "Here's why: %v\\n\", objectKey, \n err) \n } \n _, err = file.Write(body) \n return err\n}\n// DownloadLargeObject uses a download manager to download an object from a \n bucket.\n// The download manager gets the data in parts and writes them to a buffer until \n all of\n// the data has been downloaded.\nfunc (basics BucketBasics) DownloadLargeObject(ctx context.Context, bucketName \n string, objectKey string) ([]byte, error) { \n var partMiBs int64 = 10 \nBasics API Version 2006-03-01 1745Amazon Simple Storage Service API Reference\n downloader := manager.NewDownloader(basics.S3Client, func(d *manager.Downloader) \n { \n  d.PartSize = partMiBs * 1024 * 1024 \n }) \n buffer := manager.NewWriteAtBuffer([]byte{}) \n _, err := downloader.Download(ctx, buffer, &s3.GetObjectInput{ \n  Bucket: aws.String(bucketName), \n  Key:    aws.String(objectKey), \n }) \n if err != nil { \n  log.Printf(\"Couldn't download large object from %v:%v. Here's why: %v\\n\", \n   bucketName, objectKey, err) \n } \n return buffer.Bytes(), err\n}\n// CopyToFolder copies an object in a bucket to a subfolder in the same bucket.\nfunc (basics BucketBasics) CopyToFolder(ctx context.Context, bucketName string, \n objectKey string, folderName string) error { \n _, err := basics.S3Client.CopyObject(ctx, &s3.CopyObjectInput{ \n  Bucket:     aws.String(bucketName), \n  CopySource: aws.String(fmt.Sprintf(\"%v/%v\", bucketName, objectKey)), \n  Key:        aws.String(fmt.Sprintf(\"%v/%v\", folderName, objectKey)), \n }) \n if err != nil { \n  log.Printf(\"Couldn't copy object from %v:%v to %v:%v/%v. Here's why: %v\\n\", \n   bucketName, objectKey, bucketName, folderName, objectKey, err) \n } \n return err\n}\n// CopyToBucket copies an object in a bucket to another bucket.\nfunc (basics BucketBasics) CopyToBucket(ctx context.Context, sourceBucket string, \n destinationBucket string, objectKey string) error { \n _, err := basics.S3Client.CopyObject(ctx, &s3.CopyObjectInput{ \n  Bucket:     aws.String(destinationBucket), \n  CopySource: aws.String(fmt.Sprintf(\"%v/%v\", sourceBucket, objectKey)), \n  Key:        aws.String(objectKey), \n }) \n if err != nil { \nBasics API Version 2006-03-01 1746Amazon Simple Storage Service API Reference\n  log.Printf(\"Couldn't copy object from %v:%v to %v:%v. Here's why: %v\\n\", \n   sourceBucket, objectKey, destinationBucket, objectKey, err) \n } \n return err\n}\n// ListObjects lists the objects in a bucket.\nfunc (basics BucketBasics) ListObjects(ctx context.Context, bucketName string) \n ([]types.Object, error) { \n result, err := basics.S3Client.ListObjectsV2(ctx, &s3.ListObjectsV2Input{ \n  Bucket: aws.String(bucketName), \n }) \n var contents []types.Object \n if err != nil { \n  log.Printf(\"Couldn't list objects in bucket %v.", "Here's why: %v\\n\", bucketName, \n err) \n } else { \n  contents = result.Contents \n } \n return contents, err\n}\n// DeleteObjects deletes a list of objects from a bucket.\nfunc (basics BucketBasics) DeleteObjects(ctx context.Context, bucketName string, \n objectKeys []string) error { \n var objectIds []types.ObjectIdentifier \n for _, key := range objectKeys { \n  objectIds = append(objectIds, types.ObjectIdentifier{Key: aws.String(key)}) \n } \n output, err := basics.S3Client.DeleteObjects(ctx, &s3.DeleteObjectsInput{ \n  Bucket: aws.String(bucketName), \n  Delete: &types.Delete{Objects: objectIds}, \n }) \n if err != nil { \n  log.Printf(\"Couldn't delete objects from bucket %v. Here's why: %v\\n\", \n bucketName, err) \n } else { \n  log.Printf(\"Deleted %v objects.\\n\", len(output.Deleted)) \n } \n return err\nBasics API Version 2006-03-01 1747Amazon Simple Storage Service API Reference\n}\n// DeleteBucket deletes a bucket. The bucket must be empty or an error is \n returned.\nfunc (basics BucketBasics) DeleteBucket(ctx context.Context, bucketName string) \n error { \n _, err := basics.S3Client.DeleteBucket(ctx, &s3.DeleteBucketInput{ \n  Bucket: aws.String(bucketName)}) \n if err != nil { \n  log.Printf(\"Couldn't delete bucket %v. Here's why: %v\\n\", bucketName, err) \n } \n return err\n}\nRun an interactive scenario that shows you how work with S3 buckets and objects.\n// RunGetStartedScenario is an interactive example that shows you how to use \n Amazon\n// Simple Storage Service (Amazon S3) to create an S3 bucket and use it to store \n objects.\n//\n// 1.", "Create a bucket.\n// 2. Upload a local file to the bucket.\n// 3. Upload a large object to the bucket by using an upload manager.\n// 4.", "Download an object to a local file.\n// 5. Download a large object by using a download manager.\n// 6.", "Copy an object to a different folder in the bucket.\n// 7. List objects in the bucket.\n// 8. Delete all objects in the bucket.\n// 9. Delete the bucket.\n//\n// This example creates an Amazon S3 service client from the specified sdkConfig \n so that\n// you can replace it with a mocked or stubbed config for unit testing.\n//\n// It uses a questioner from the `demotools` package to get input during the \n example.\n// This package can be found in the ..\\..\\demotools folder of this repo.\nBasics API Version 2006-03-01 1748Amazon Simple Storage Service API Reference\nfunc RunGetStartedScenario(ctx context.Context, sdkConfig aws.Config, questioner \n demotools.IQuestioner) { \n defer func() { \n  if r := recover(); r != nil { \n   fmt.Println(\"Something went wrong with the demo.\\n\", r) \n  } \n }() \n log.Println(strings.Repeat(\"-\", 88)) \n log.Println(\"Welcome to the Amazon S3 getting started demo.\") \n log.Println(strings.Repeat(\"-\", 88)) \n s3Client := s3.NewFromConfig(sdkConfig) \n bucketBasics := actions.BucketBasics{S3Client: s3Client} \n count := 10 \n log.Printf(\"Let's list up to %v buckets for your account:\", count) \n buckets, err := bucketBasics.ListBuckets(ctx) \n if err != nil { \n  panic(err) \n } \n if len(buckets) == 0 { \n  log.Println(\"You don't have any buckets!\") \n } else { \n  if count > len(buckets) { \n   count = len(buckets) \n  } \n  for _, bucket := range buckets[:count] { \n   log.Printf(\"\\t%v\\n\", *bucket.Name) \n  } \n } \n bucketName := questioner.Ask(\"Let's create a bucket. Enter a name for your \n bucket:\", \n  demotools.NotEmpty{}) \n bucketExists, err := bucketBasics.BucketExists(ctx, bucketName) \n if err != nil { \n  panic(err) \n } \n if !bucketExists { \n  err = bucketBasics.CreateBucket(ctx, bucketName, sdkConfig.Region) \n  if err != nil { \n   panic(err) \n  } else { \nBasics API Version 2006-03-01 1749Amazon Simple Storage Service API Reference\n   log.Println(\"Bucket created.\") \n  } \n } \n log.Println(strings.Repeat(\"-\", 88)) \n fmt.Println(\"Let's upload a file to your bucket.\") \n smallFile := questioner.Ask(\"Enter the path to a file you want to upload:\", \n  demotools.NotEmpty{}) \n const smallKey = \"doc-example-key\" \n err = bucketBasics.UploadFile(ctx, bucketName, smallKey, smallFile) \n if err != nil { \n  panic(err) \n } \n log.Printf(\"Uploaded %v as %v.\\n\", smallFile, smallKey) \n log.Println(strings.Repeat(\"-\", 88)) \n mibs := 30 \n log.Printf(\"Let's create a slice of %v MiB of random bytes and upload it to your \n bucket. \", mibs) \n questioner.Ask(\"Press Enter when you're ready.\") \n largeBytes := make([]byte, 1024*1024*mibs) \n _, _ = rand.Read(largeBytes) \n largeKey := \"doc-example-large\" \n log.Println(\"Uploading...\") \n err = bucketBasics.UploadLargeObject(ctx, bucketName, largeKey, largeBytes) \n if err != nil { \n  panic(err) \n } \n log.Printf(\"Uploaded %v MiB object as %v\", mibs, largeKey) \n log.Println(strings.Repeat(\"-\", 88)) \n log.Printf(\"Let's download %v to a file.\", smallKey) \n downloadFileName := questioner.Ask(\"Enter a name for the downloaded file:\", \n demotools.NotEmpty{}) \n err = bucketBasics.DownloadFile(ctx, bucketName, smallKey, downloadFileName) \n if err != nil { \n  panic(err) \n } \n log.Printf(\"File %v downloaded.\", downloadFileName) \n log.Println(strings.Repeat(\"-\", 88)) \n log.Printf(\"Let's download the %v MiB object.\", mibs) \n questioner.Ask(\"Press Enter when you're ready.\") \n log.Println(\"Downloading...\") \nBasics API Version 2006-03-01 1750Amazon Simple Storage Service API Reference\n largeDownload, err := bucketBasics.DownloadLargeObject(ctx, bucketName, \n largeKey) \n if err != nil { \n  panic(err) \n } \n log.Printf(\"Downloaded %v bytes.\", len(largeDownload)) \n log.Println(strings.Repeat(\"-\", 88)) \n log.Printf(\"Let's copy %v to a folder in the same bucket.\", smallKey) \n folderName := questioner.Ask(\"Enter a folder name: \", demotools.NotEmpty{}) \n err = bucketBasics.CopyToFolder(ctx, bucketName, smallKey, folderName) \n if err != nil { \n  panic(err) \n } \n log.Printf(\"Copied %v to %v/%v.\\n\", smallKey, folderName, smallKey) \n log.Println(strings.Repeat(\"-\", 88)) \n log.Println(\"Let's list the objects in your bucket.\") \n questioner.Ask(\"Press Enter when you're ready.\") \n objects, err := bucketBasics.ListObjects(ctx, bucketName) \n if err != nil { \n  panic(err) \n } \n log.Printf(\"Found %v objects.\\n\", len(objects)) \n var objKeys []string \n for _, object := range objects { \n  objKeys = append(objKeys, *object.Key) \n  log.Printf(\"\\t%v\\n\", *object.Key) \n } \n log.Println(strings.Repeat(\"-\", 88)) \n if questioner.AskBool(\"Do you want to delete your bucket and all of its \"+ \n  \"contents? (y/n)\", \"y\") { \n  log.Println(\"Deleting objects.\") \n  err = bucketBasics.DeleteObjects(ctx, bucketName, objKeys) \n  if err != nil { \n   panic(err) \n  } \n  log.Println(\"Deleting bucket.\") \n  err = bucketBasics.DeleteBucket(ctx, bucketName) \n  if err != nil { \n   panic(err) \n  } \n  log.Printf(\"Deleting downloaded file %v.\\n\", downloadFileName) \nBasics API Version 2006-03-01 1751Amazon Simple Storage Service API Reference\n  err = os.Remove(downloadFileName) \n  if err != nil { \n   panic(err) \n  } \n } else { \n  log.Println(\"Okay. Don't forget to delete objects from your bucket to avoid \n charges.\") \n } \n log.Println(strings.Repeat(\"-\", 88)) \n log.Println(\"Thanks for watching!\") \n log.Println(strings.Repeat(\"-\", 88))\n}\n\u2022For API details, see the following topics in AWS SDK for Go API Reference.\n\u2022CopyObject\n\u2022CreateBucket\n\u2022DeleteBucket\n\u2022DeleteObjects\n\u2022GetObject\n\u2022ListObjectsV2\n\u2022PutObject\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nA scenario example.\nimport java.io.IOException;\nBasics API Version 2006-03-01 1752Amazon Simple Storage Service API Reference\nimport java.util.Scanner;\nimport java.util.UUID;\nimport java.util.concurrent.CompletableFuture;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\nimport software.amazon.awssdk.services.s3.model.PutObjectResponse;\nimport software.amazon.awssdk.services.s3.model.S3Exception;\n/** \n * Before running this Java V2 code example, set up your development \n * environment, including your credentials. \n * \n * For more information, see the following documentation topic: \n * \n * https://docs.aws.amazon.com/sdk-for-java/latest/developer-guide/get-\nstarted.html \n * \n * This Java code example performs the following tasks: \n * \n * 1.", "Creates an Amazon S3 bucket.", "\n * 2.", "Uploads an object to the bucket.", "\n * 3.", "Downloads the object to another local file.", "\n * 4.", "Uploads an object using multipart upload.", "\n * 5.", "List all objects located in the Amazon S3 bucket.", "\n * 6.", "Copies the object to another Amazon S3 bucket.", "\n * 7.", "Deletes the object from the Amazon S3 bucket.", "\n * 8.", "Deletes the Amazon S3 bucket. \n */\npublic class S3Scenario { \n    public static Scanner scanner = new Scanner(System.in); \n    static S3Actions s3Actions = new S3Actions(); \n    public static final String DASHES = new String(new char[80]).replace(\"\\0\", \n \"-\"); \n    private static final Logger logger = \n LoggerFactory.getLogger(S3Scenario.class); \n    public static void main(String[] args) throws IOException { \n        final String usage = \"\"\" \n            Usage: \n               <bucketName> <key> <objectPath> <savePath> <toBucket> \n            Where: \n                bucketName - The name of the  S3 bucket. \nBasics API Version 2006-03-01 1753Amazon Simple Storage Service API Reference\n                key - The unique identifier for the object stored in the S3 \n bucket.", "\n                objectPath - The full file path of the object within the S3 \n bucket (e.g., \"documents/reports/annual_report.pdf\").", "\n                savePath - The local file path where the object will be \n downloaded and saved (e.g., \"C:/Users/username/Downloads/annual_report.pdf\").", "\n                toBucket - The name of the S3 bucket to which the object will be \n copied. \n            \"\"\"; \n        if (args.length != 5) { \n            logger.info(usage); \n            return; \n        } \n        String bucketName = args[0]; \n        String key = args[1]; \n        String objectPath = args[2]; \n        String savePath = args[3]; \n        String toBucket = args[4]; \n        logger.info(DASHES); \n        logger.info(\"Welcome to the Amazon Simple Storage Service (S3) example \n scenario.\"); \n        logger.info(\"\"\" \n            Amazon S3 is a highly scalable and durable object storage  \n            service provided by Amazon Web Services (AWS).", "It is designed to \n store and retrieve  \n            any amount of data, from anywhere on the web, at any time.", "\n                         \n            The `S3AsyncClient` interface in the AWS SDK for Java 2.x provides a \n set of methods to  \n            programmatically interact with the Amazon S3 (Simple Storage Service) \n service. This allows  \n            developers to automate the management and manipulation of S3 buckets \n and objects as  \n            part of their application deployment pipelines. With S3, teams can \n focus on building  \n            and deploying their applications without having to worry about the \n underlying storage  \n            infrastructure required to host and manage large amounts of data.", "\n                         \n            This scenario walks you through how to perform key operations for \n this service.", "\nBasics API Version 2006-03-01 1754Amazon Simple Storage Service API Reference\n            Let's get started...", "\n            \"\"\"); \n        waitForInputToContinue(scanner); \n        logger.info(DASHES); \n        try { \n            // Run the methods that belong to this scenario.", "\n            runScenario(bucketName, key, objectPath, savePath, toBucket); \n        } catch (Throwable rt) { \n            Throwable cause = rt.getCause(); \n            if (cause instanceof S3Exception kmsEx) { \n                logger.info(\"KMS error occurred: Error message: {}, Error code \n {}\", kmsEx.getMessage(), kmsEx.awsErrorDetails().errorCode()); \n            } else { \n                logger.info(\"An unexpected error occurred: \" + rt.getMessage()); \n            } \n        } \n    } \n    private static void runScenario(String bucketName, String key, String \n objectPath, String savePath, String toBucket) throws Throwable { \n        logger.info(DASHES); \n        logger.info(\"1. Create an Amazon S3 bucket.\"); \n        try { \n            CompletableFuture<Void> future = \n s3Actions.createBucketAsync(bucketName); \n            future.join(); \n            waitForInputToContinue(scanner); \n        } catch (RuntimeException rt) { \n            Throwable cause = rt.getCause(); \n            if (cause instanceof S3Exception s3Ex) { \n                logger.info(\"S3 error occurred: Error message: {}, Error code \n {}\", s3Ex.getMessage(), s3Ex.awsErrorDetails().errorCode()); \n            } else { \n                logger.info(\"An unexpected error occurred: \" + rt.getMessage()); \n            } \n            throw cause; \n        } \n        logger.info(DASHES); \n        logger.info(DASHES); \nBasics API Version 2006-03-01 1755Amazon Simple Storage Service API Reference\n        logger.info(\"2. Upload a local file to the Amazon S3 bucket.\"); \n        waitForInputToContinue(scanner); \n        try { \n            CompletableFuture<PutObjectResponse> future = \n s3Actions.uploadLocalFileAsync(bucketName, key, objectPath); \n            future.join(); \n            logger.info(\"File uploaded successfully to {}/{}\", bucketName, key); \n        } catch (RuntimeException rt) { \n            Throwable cause = rt.getCause(); \n            if (cause instanceof S3Exception s3Ex) { \n                logger.info(\"S3 error occurred: Error message: {}, Error code \n {}\", s3Ex.getMessage(), s3Ex.awsErrorDetails().errorCode()); \n            } else { \n                logger.info(\"An unexpected error occurred: \" + rt.getMessage()); \n            } \n            throw cause; \n        } \n        waitForInputToContinue(scanner); \n        logger.info(DASHES); \n        logger.info(DASHES); \n        logger.info(\"3. Download the object to another local file.\"); \n        waitForInputToContinue(scanner); \n        try { \n            CompletableFuture<Void> future = \n s3Actions.getObjectBytesAsync(bucketName, key, savePath); \n            future.join(); \n            logger.info(\"Successfully obtained bytes from S3 object and wrote to \n file {}\", savePath); \n        } catch (RuntimeException rt) { \n            Throwable cause = rt.getCause(); \n            if (cause instanceof S3Exception s3Ex) { \n                logger.info(\"S3 error occurred: Error message: {}, Error code \n {}\", s3Ex.getMessage(), s3Ex.awsErrorDetails().errorCode()); \n            } else { \n                logger.info(\"An unexpected error occurred: \" + rt.getMessage()); \n            } \n            throw cause; \n        } \n        waitForInputToContinue(scanner); \n        logger.info(DASHES); \nBasics API Version 2006-03-01 1756Amazon Simple Storage Service API Reference\n        logger.info(DASHES); \n        logger.info(\"4. Perform a multipart upload.\"); \n        waitForInputToContinue(scanner); \n        String multipartKey = \"multiPartKey\"; \n        try { \n            // Call the multipartUpload method \n            CompletableFuture<Void> future = \n s3Actions.multipartUpload(bucketName, multipartKey); \n            future.join(); \n            logger.info(\"Multipart upload completed successfully for bucket '{}' \n and key '{}'\", bucketName, multipartKey); \n        } catch (RuntimeException rt) { \n            Throwable cause = rt.getCause(); \n            if (cause instanceof S3Exception s3Ex) { \n                logger.info(\"S3 error occurred: Error message: {}, Error code \n {}\", s3Ex.getMessage(), s3Ex.awsErrorDetails().errorCode()); \n            } else { \n                logger.info(\"An unexpected error occurred: \" + rt.getMessage()); \n            } \n            throw cause; \n        } \n        waitForInputToContinue(scanner); \n        logger.info(DASHES); \n        logger.info(DASHES); \n        logger.info(\"5. List all objects located in the Amazon S3 bucket.\"); \n        waitForInputToContinue(scanner); \n        try { \n            CompletableFuture<Void> future = \n s3Actions.listAllObjectsAsync(bucketName); \n            future.join(); \n            logger.info(\"Object listing completed successfully.\"); \n        } catch (RuntimeException rt) { \n            Throwable cause = rt.getCause(); \n            if (cause instanceof S3Exception s3Ex) { \n                logger.info(\"S3 error occurred: Error message: {}, Error code \n {}\", s3Ex.getMessage(), s3Ex.awsErrorDetails().errorCode()); \n            } else { \n                logger.info(\"An unexpected error occurred: \" + rt.getMessage()); \n            } \n            throw cause; \nBasics API Version 2006-03-01 1757Amazon Simple Storage Service API Reference\n        } \n        waitForInputToContinue(scanner); \n        logger.info(DASHES); \n        logger.info(DASHES); \n        logger.info(\"6. Copy the object to another Amazon S3 bucket.\"); \n        waitForInputToContinue(scanner); \n        try { \n            CompletableFuture<String> future = \n s3Actions.copyBucketObjectAsync(bucketName, key, toBucket); \n            String result = future.join(); \n            logger.info(\"Copy operation result: {}\", result); \n        } catch (RuntimeException rt) { \n            Throwable cause = rt.getCause(); \n            if (cause instanceof S3Exception s3Ex) { \n                logger.info(\"S3 error occurred: Error message: {}, Error code \n {}\", s3Ex.getMessage(), s3Ex.awsErrorDetails().errorCode()); \n            } else { \n                logger.info(\"An unexpected error occurred: \" + rt.getMessage()); \n            } \n            throw cause; \n        } \n        waitForInputToContinue(scanner); \n        logger.info(DASHES); \n        logger.info(DASHES); \n        logger.info(\"7. Copy the object to another Amazon S3 bucket using multi \n copy.\"); \n        waitForInputToContinue(scanner); \n        try { \n            CompletableFuture<String> future = \n s3Actions.performMultiCopy(toBucket, bucketName, key); \n            String result = future.join(); \n            logger.info(\"Copy operation result: {}\", result); \n        } catch (RuntimeException rt) { \n            Throwable cause = rt.getCause(); \n            if (cause instanceof S3Exception s3Ex) { \n                logger.info(\"KMS error occurred: Error message: {}, Error code \n {}\", s3Ex.getMessage(), s3Ex.awsErrorDetails().errorCode()); \n            } else { \n                logger.info(\"An unexpected error occurred: \" + rt.getMessage()); \nBasics API Version 2006-03-01 1758Amazon Simple Storage Service API Reference\n            } \n        } \n        waitForInputToContinue(scanner); \n        logger.info(DASHES); \n        logger.info(DASHES); \n        logger.info(\"8. Delete objects from the Amazon S3 bucket.\"); \n        waitForInputToContinue(scanner); \n        try { \n            CompletableFuture<Void> future = \n s3Actions.deleteObjectFromBucketAsync(bucketName, key); \n            future.join(); \n        } catch (RuntimeException rt) { \n            Throwable cause = rt.getCause(); \n            if (cause instanceof S3Exception s3Ex) { \n                logger.info(\"S3 error occurred: Error message: {}, Error code \n {}\", s3Ex.getMessage(), s3Ex.awsErrorDetails().errorCode()); \n            } else { \n                logger.info(\"An unexpected error occurred: \" + rt.getMessage()); \n            } \n            throw cause; \n        } \n        try { \n            CompletableFuture<Void> future = \n s3Actions.deleteObjectFromBucketAsync(bucketName, \"multiPartKey\"); \n            future.join(); \n        } catch (RuntimeException rt) { \n            Throwable cause = rt.getCause(); \n            if (cause instanceof S3Exception s3Ex) { \n                logger.info(\"S3 error occurred: Error message: {}, Error code \n {}\", s3Ex.getMessage(), s3Ex.awsErrorDetails().errorCode()); \n            } else { \n                logger.info(\"An unexpected error occurred: \" + rt.getMessage()); \n            } \n            throw cause; \n        } \n        waitForInputToContinue(scanner); \n        logger.info(DASHES); \n        logger.info(DASHES); \n        logger.info(\"9. Delete the Amazon S3 bucket.\"); \nBasics API Version 2006-03-01 1759Amazon Simple Storage Service API Reference\n        waitForInputToContinue(scanner); \n        try { \n            CompletableFuture<Void> future = \n s3Actions.deleteBucketAsync(bucketName); \n            future.join(); \n        } catch (RuntimeException rt) { \n            Throwable cause = rt.getCause(); \n            if (cause instanceof S3Exception s3Ex) { \n                logger.info(\"S3 error occurred: Error message: {}, Error code \n {}\", s3Ex.getMessage(), s3Ex.awsErrorDetails().errorCode()); \n            } else { \n                logger.info(\"An unexpected error occurred: \" + rt.getMessage()); \n            } \n            throw cause; \n        } \n        waitForInputToContinue(scanner); \n        logger.info(DASHES); \n        logger.info(DASHES); \n        logger.info(\"You successfully completed the Amazon S3 scenario.\"); \n        logger.info(DASHES); \n    } \n    private static void waitForInputToContinue(Scanner scanner) { \n        while (true) { \n            logger.info(\"\"); \n            logger.info(\"Enter 'c' followed by <ENTER> to continue:\"); \n            String input = scanner.nextLine(); \n            if (input.trim().equalsIgnoreCase(\"c\")) { \n                logger.info(\"Continuing with the program...\"); \n                logger.info(\"\"); \n                break; \n            } else { \n                // Handle invalid input.", "\n                logger.info(\"Invalid input.", "Please try again.\"); \n            } \n        } \n    }\n}\nBasics API Version 2006-03-01 1760Amazon Simple Storage Service API Reference\nA wrapper class that contains the operations.\npublic class S3Actions { \n    private static final Logger logger = \n LoggerFactory.getLogger(S3Actions.class); \n    private static S3AsyncClient s3AsyncClient; \n    public static S3AsyncClient getAsyncClient() { \n        if (s3AsyncClient == null) { \n            /* \n            The `NettyNioAsyncHttpClient` class is part of the AWS SDK for Java, \n version 2, \n            and it is designed to provide a high-performance, asynchronous HTTP \n client for interacting with AWS services.", "\n             It uses the Netty framework to handle the underlying network \n communication and the Java NIO API to \n             provide a non-blocking, event-driven approach to HTTP requests and \n responses.", "\n             */ \n            SdkAsyncHttpClient httpClient = NettyNioAsyncHttpClient.builder() \n                .maxConcurrency(50)  // Adjust as needed.", "\n                .connectionTimeout(Duration.ofSeconds(60))  // Set the connection \n timeout. \n                .readTimeout(Duration.ofSeconds(60))  // Set the read timeout. \n                .writeTimeout(Duration.ofSeconds(60))  // Set the write timeout. \n                .build(); \n            ClientOverrideConfiguration overrideConfig = \n ClientOverrideConfiguration.builder() \n                .apiCallTimeout(Duration.ofMinutes(2))  // Set the overall API \n call timeout. \n                .apiCallAttemptTimeout(Duration.ofSeconds(90))  // Set the \n individual call attempt timeout.", "\n                .retryStrategy(RetryMode.STANDARD) \n                .build(); \n            s3AsyncClient = S3AsyncClient.builder() \n                .region(Region.US_EAST_1) \n                .httpClient(httpClient) \n                .overrideConfiguration(overrideConfig) \n                .build(); \n        } \nBasics API Version 2006-03-01 1761Amazon Simple Storage Service API Reference\n        return s3AsyncClient; \n    } \n    /** \n     * Creates an S3 bucket asynchronously. \n     * \n     * @param bucketName the name of the S3 bucket to create \n     * @return a {@link CompletableFuture} that completes when the bucket is \n created and ready \n     * @throws RuntimeException if there is a failure while creating the bucket \n     */ \n    public CompletableFuture<Void> createBucketAsync(String bucketName) { \n        CreateBucketRequest bucketRequest = CreateBucketRequest.builder() \n            .bucket(bucketName) \n            .build(); \n        CompletableFuture<CreateBucketResponse> response = \n getAsyncClient().createBucket(bucketRequest); \n        return response.thenCompose(resp -> { \n            S3AsyncWaiter s3Waiter = getAsyncClient().waiter(); \n            HeadBucketRequest bucketRequestWait = HeadBucketRequest.builder() \n                .bucket(bucketName) \n                .build(); \n            CompletableFuture<WaiterResponse<HeadBucketResponse>> \n waiterResponseFuture = \n                s3Waiter.waitUntilBucketExists(bucketRequestWait); \n            return waiterResponseFuture.thenAccept(waiterResponse -> { \n                waiterResponse.matched().response().ifPresent(headBucketResponse \n -> { \n                    logger.info(bucketName + \" is ready\"); \n                }); \n            }); \n        }).whenComplete((resp, ex) -> { \n            if (ex != null) { \n                throw new RuntimeException(\"Failed to create bucket\", ex); \n            } \n        }); \n    } \n    /** \n     * Uploads a local file to an AWS S3 bucket asynchronously. \nBasics API Version 2006-03-01 1762Amazon Simple Storage Service API Reference\n     * \n     * @param bucketName the name of the S3 bucket to upload the file to \n     * @param key        the key (object name) to use for the uploaded file \n     * @param objectPath the local file path of the file to be uploaded \n     * @return a {@link CompletableFuture} that completes with the {@link \n PutObjectResponse} when the upload is successful, or throws a {@link \n RuntimeException} if the upload fails \n     */ \n    public CompletableFuture<PutObjectResponse> uploadLocalFileAsync(String \n bucketName, String key, String objectPath) { \n        PutObjectRequest objectRequest = PutObjectRequest.builder() \n            .bucket(bucketName) \n            .key(key) \n            .build(); \n        CompletableFuture<PutObjectResponse> response = \n getAsyncClient().putObject(objectRequest, \n AsyncRequestBody.fromFile(Paths.get(objectPath))); \n        return response.whenComplete((resp, ex) -> { \n            if (ex != null) { \n                throw new RuntimeException(\"Failed to upload file\", ex); \n            } \n        }); \n    } \n    /** \n     * Asynchronously retrieves the bytes of an object from an Amazon S3 bucket \n and writes them to a local file. \n     * \n     * @param bucketName the name of the S3 bucket containing the object \n     * @param keyName    the key (or name) of the S3 object to retrieve \n     * @param path       the local file path where the object's bytes will be \n written \n     * @return a {@link CompletableFuture} that completes when the object bytes \n have been written to the local file \n     */ \n    public CompletableFuture<Void> getObjectBytesAsync(String bucketName, String \n keyName, String path) { \n        GetObjectRequest objectRequest = GetObjectRequest.builder() \n            .key(keyName) \n            .bucket(bucketName) \n            .build(); \nBasics API Version 2006-03-01 1763Amazon Simple Storage Service API Reference\n        CompletableFuture<ResponseBytes<GetObjectResponse>> response = \n getAsyncClient().getObject(objectRequest, AsyncResponseTransformer.toBytes()); \n        return response.thenAccept(objectBytes -> { \n            try { \n                byte[] data = objectBytes.asByteArray(); \n                Path filePath = Paths.get(path); \n                Files.write(filePath, data); \n                logger.info(\"Successfully obtained bytes from an S3 object\"); \n            } catch (IOException ex) { \n                throw new RuntimeException(\"Failed to write data to file\", ex); \n            } \n        }).whenComplete((resp, ex) -> { \n            if (ex != null) { \n                throw new RuntimeException(\"Failed to get object bytes from S3\", \n ex); \n            } \n        }); \n    } \n    /** \n     * Asynchronously lists all objects in the specified S3 bucket. \n     * \n     * @param bucketName the name of the S3 bucket to list objects for \n     * @return a {@link CompletableFuture} that completes when all objects have \n been listed \n     */ \n    public CompletableFuture<Void> listAllObjectsAsync(String bucketName) { \n        ListObjectsV2Request initialRequest = ListObjectsV2Request.builder() \n            .bucket(bucketName) \n            .maxKeys(1) \n            .build(); \n        ListObjectsV2Publisher paginator = \n getAsyncClient().listObjectsV2Paginator(initialRequest); \n        return paginator.subscribe(response -> { \n            response.contents().forEach(s3Object -> { \n                logger.info(\"Object key: \" + s3Object.key()); \n            }); \n        }).thenRun(() -> { \n            logger.info(\"Successfully listed all objects in the bucket: \" + \n bucketName); \n        }).exceptionally(ex -> { \n            throw new RuntimeException(\"Failed to list objects\", ex); \nBasics API Version 2006-03-01 1764Amazon Simple Storage Service API Reference\n        }); \n    } \n    /** \n     * Asynchronously copies an object from one S3 bucket to another. \n     * \n     * @param fromBucket the name of the source S3 bucket \n     * @param objectKey  the key (name) of the object to be copied \n     * @param toBucket   the name of the destination S3 bucket \n     * @return a {@link CompletableFuture} that completes with the copy result as \n a {@link String} \n     * @throws RuntimeException if the URL could not be encoded or an S3 \n exception occurred during the copy \n     */ \n    public CompletableFuture<String> copyBucketObjectAsync(String fromBucket, \n String objectKey, String toBucket) { \n        CopyObjectRequest copyReq = CopyObjectRequest.builder() \n            .sourceBucket(fromBucket) \n            .sourceKey(objectKey) \n            .destinationBucket(toBucket) \n            .destinationKey(objectKey) \n            .build(); \n        CompletableFuture<CopyObjectResponse> response = \n getAsyncClient().copyObject(copyReq); \n        response.whenComplete((copyRes, ex) -> { \n            if (copyRes != null) { \n                logger.info(\"The \" + objectKey + \" was copied to \" + toBucket); \n            } else { \n                throw new RuntimeException(\"An S3 exception occurred during \n copy\", ex); \n            } \n        }); \n        return response.thenApply(CopyObjectResponse::copyObjectResult) \n            .thenApply(Object::toString); \n    } \n    /** \n     * Performs a multipart upload to an Amazon S3 bucket. \n     * \n     * @param bucketName the name of the S3 bucket to upload the file to \n     * @param key        the key (name) of the file to be uploaded \nBasics API Version 2006-03-01 1765Amazon Simple Storage Service API Reference\n     * @return a {@link CompletableFuture} that completes when the multipart \n upload is successful \n     */ \n    public CompletableFuture<Void> multipartUpload(String bucketName, String key) \n { \n        int mB = 1024 * 1024; \n        CreateMultipartUploadRequest createMultipartUploadRequest = \n CreateMultipartUploadRequest.builder() \n            .bucket(bucketName) \n            .key(key) \n            .build(); \n        return \n getAsyncClient().createMultipartUpload(createMultipartUploadRequest) \n            .thenCompose(createResponse -> { \n                String uploadId = createResponse.uploadId(); \n                System.out.println(\"Upload ID: \" + uploadId); \n                // Upload part 1. \n                UploadPartRequest uploadPartRequest1 = \n UploadPartRequest.builder() \n                    .bucket(bucketName) \n                    .key(key) \n                    .uploadId(uploadId) \n                    .partNumber(1) \n                    .contentLength((long) (5 * mB)) // Specify the content length \n                    .build(); \n                CompletableFuture<CompletedPart> part1Future = \n getAsyncClient().uploadPart(uploadPartRequest1, \n                        AsyncRequestBody.fromByteBuffer(getRandomByteBuffer(5 * \n mB))) \n                    .thenApply(uploadPartResponse -> CompletedPart.builder() \n                        .partNumber(1) \n                        .eTag(uploadPartResponse.eTag()) \n                        .build()); \n                // Upload part 2. \n                UploadPartRequest uploadPartRequest2 = \n UploadPartRequest.builder() \n                    .bucket(bucketName) \n                    .key(key) \n                    .uploadId(uploadId) \nBasics API Version 2006-03-01 1766Amazon Simple Storage Service API Reference\n                    .partNumber(2) \n                    .contentLength((long) (3 * mB)) \n                    .build(); \n                CompletableFuture<CompletedPart> part2Future = \n getAsyncClient().uploadPart(uploadPartRequest2, \n                        AsyncRequestBody.fromByteBuffer(getRandomByteBuffer(3 * \n mB))) \n                    .thenApply(uploadPartResponse -> CompletedPart.builder() \n                        .partNumber(2) \n                        .eTag(uploadPartResponse.eTag()) \n                        .build()); \n                // Combine the results of both parts. \n                return CompletableFuture.allOf(part1Future, part2Future) \n                    .thenCompose(v -> { \n                        CompletedPart part1 = part1Future.join(); \n                        CompletedPart part2 = part2Future.join(); \n                        CompletedMultipartUpload completedMultipartUpload = \n CompletedMultipartUpload.builder() \n                            .parts(part1, part2) \n                            .build(); \n                        CompleteMultipartUploadRequest \n completeMultipartUploadRequest = CompleteMultipartUploadRequest.builder() \n                            .bucket(bucketName) \n                            .key(key) \n                            .uploadId(uploadId) \n                            .multipartUpload(completedMultipartUpload) \n                            .build(); \n                        // Complete the multipart upload \n                        return \n getAsyncClient().completeMultipartUpload(completeMultipartUploadRequest); \n                    }); \n            }) \n            .thenAccept(response -> System.out.println(\"Multipart upload \n completed successfully\")) \n            .exceptionally(ex -> { \n                System.err.println(\"Failed to complete multipart upload: \" + \n ex.getMessage()); \n                throw new RuntimeException(ex); \n            }); \nBasics API Version 2006-03-01 1767Amazon Simple Storage Service API Reference\n    } \n    /** \n     * Deletes an object from an S3 bucket asynchronously. \n     * \n     * @param bucketName the name of the S3 bucket \n     * @param key        the key (file name) of the object to be deleted \n     * @return a {@link CompletableFuture} that completes when the object has \n been deleted \n     */ \n    public CompletableFuture<Void> deleteObjectFromBucketAsync(String bucketName, \n String key) { \n        DeleteObjectRequest deleteObjectRequest = DeleteObjectRequest.builder() \n            .bucket(bucketName) \n            .key(key) \n            .build(); \n        CompletableFuture<DeleteObjectResponse> response = \n getAsyncClient().deleteObject(deleteObjectRequest); \n        response.whenComplete((deleteRes, ex) -> { \n            if (deleteRes != null) { \n                logger.info(key + \" was deleted\"); \n            } else { \n                throw new RuntimeException(\"An S3 exception occurred during \n delete\", ex); \n            } \n        }); \n        return response.thenApply(r -> null); \n    } \n    /** \n     * Deletes an S3 bucket asynchronously. \n     * \n     * @param bucket the name of the bucket to be deleted \n     * @return a {@link CompletableFuture} that completes when the bucket \n deletion is successful, or throws a {@link RuntimeException} \n     * if an error occurs during the deletion process \n     */ \n    public CompletableFuture<Void> deleteBucketAsync(String bucket) { \n        DeleteBucketRequest deleteBucketRequest = DeleteBucketRequest.builder() \n            .bucket(bucket) \nBasics API Version 2006-03-01 1768Amazon Simple Storage Service API Reference\n            .build(); \n        CompletableFuture<DeleteBucketResponse> response = \n getAsyncClient().deleteBucket(deleteBucketRequest); \n        response.whenComplete((deleteRes, ex) -> { \n            if (deleteRes != null) { \n                logger.info(bucket + \" was deleted.\"); \n            } else { \n                throw new RuntimeException(\"An S3 exception occurred during \n bucket deletion\", ex); \n            } \n        }); \n        return response.thenApply(r -> null); \n    } \n    public CompletableFuture<String> performMultiCopy(String toBucket, String \n bucketName, String key) { \n        CreateMultipartUploadRequest createMultipartUploadRequest = \n CreateMultipartUploadRequest.builder() \n            .bucket(toBucket) \n            .key(key) \n            .build(); \n        getAsyncClient().createMultipartUpload(createMultipartUploadRequest) \n            .thenApply(createMultipartUploadResponse -> { \n                String uploadId = createMultipartUploadResponse.uploadId(); \n                System.out.println(\"Upload ID: \" + uploadId); \n                UploadPartCopyRequest uploadPartCopyRequest = \n UploadPartCopyRequest.builder() \n                    .sourceBucket(bucketName) \n                    .destinationBucket(toBucket) \n                    .sourceKey(key) \n                    .destinationKey(key) \n                    .uploadId(uploadId)  // Use the valid uploadId.", "\n                    .partNumber(1)  // Ensure the part number is correct.", "\n                    .copySourceRange(\"bytes=0-1023\")  // Adjust range as needed \n                    .build(); \n                return getAsyncClient().uploadPartCopy(uploadPartCopyRequest); \n            }) \n            .thenCompose(uploadPartCopyFuture -> uploadPartCopyFuture) \n            .whenComplete((uploadPartCopyResponse, exception) -> { \n                if (exception != null) { \nBasics API Version 2006-03-01 1769Amazon Simple Storage Service API Reference\n                    // Handle any exceptions.", "\n                    logger.error(\"Error during upload part copy: \" + \n exception.getMessage()); \n                } else { \n                    // Successfully completed the upload part copy. \n                    System.out.println(\"Upload Part Copy completed successfully.", "\n ETag: \" + uploadPartCopyResponse.copyPartResult().eTag()); \n                } \n            }); \n        return null; \n    } \n    private static ByteBuffer getRandomByteBuffer(int size) { \n        ByteBuffer buffer = ByteBuffer.allocate(size); \n        for (int i = 0; i < size; i++) { \n            buffer.put((byte) (Math.random() * 256)); \n        } \n        buffer.flip(); \n        return buffer; \n    }\n}\n\u2022For API details, see the following topics in AWS SDK for Java 2.x API Reference.\n\u2022CopyObject\n\u2022CreateBucket\n\u2022DeleteBucket\n\u2022DeleteObjects\n\u2022GetObject\n\u2022ListObjectsV2\n\u2022PutObject\nBasics API Version 2006-03-01 1770Amazon Simple Storage Service API Reference\nJavaScript\nSDK for JavaScript (v3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nFirst, import all the necessary modules.\n// Used to check if currently running file is this file.\nimport { fileURLToPath } from \"node:url\";\nimport { readdirSync, readFileSync, writeFileSync } from \"node:fs\";\n// Local helper utils.\nimport { dirnameFromMetaUrl } from \"@aws-doc-sdk-examples/lib/utils/util-fs.js\";\nimport { Prompter } from \"@aws-doc-sdk-examples/lib/prompter.js\";\nimport { wrapText } from \"@aws-doc-sdk-examples/lib/utils/util-string.js\";\nimport { \n  S3Client, \n  CreateBucketCommand, \n  PutObjectCommand, \n  ListObjectsCommand, \n  CopyObjectCommand, \n  GetObjectCommand, \n  DeleteObjectsCommand, \n  DeleteBucketCommand,\n} from \"@aws-sdk/client-s3\";\nThe preceding imports reference some helper utilities.", "These utilities are local to the \nGitHub repository linked at the start of this section.", "For your reference, see the following \nimplementations of those utilities.\nexport const dirnameFromMetaUrl = (metaUrl) => \n  fileURLToPath(new URL(\".\", metaUrl));\nimport { select, input, confirm, checkbox } from \"@inquirer/prompts\";\nBasics API Version 2006-03-01 1771Amazon Simple Storage Service API Reference\nexport class Prompter { \n  /** \n   * @param {{ message: string, choices: { name: string, value: string }[]}} \n options \n   */ \n  select(options) { \n    return select(options); \n  } \n  /** \n   * @param {{ message: string }} options \n   */ \n  input(options) { \n    return input(options); \n  } \n  /** \n   * @param {string} prompt \n   */ \n  checkContinue = async (prompt = \"\") => { \n    const prefix = prompt && `${prompt} `; \n    const ok = await this.confirm({ \n      message: `${prefix}Continue?`, \n    }); \n    if (!ok) throw new Error(\"Exiting...\"); \n  }; \n  /** \n   * @param {{ message: string }} options \n   */ \n  confirm(options) { \n    return confirm(options); \n  } \n  /** \n   * @param {{ message: string, choices: { name: string, value: string }[]}} \n options \n   */ \n  checkbox(options) { \n    return checkbox(options); \n  }\n}\nexport const wrapText = (text, char = \"=\") => { \nBasics API Version 2006-03-01 1772Amazon Simple Storage Service API Reference\n  const rule = char.repeat(80); \n  return `${rule}\\n    ${text}\\n${rule}\\n`;\n};\nObjects in S3 are stored in 'buckets'.", "Let's de\ufb01ne a function for creating a new bucket.\nexport const createBucket = async () => { \n  const bucketName = await prompter.input({ \n    message: \"Enter a bucket name. Bucket names must be globally unique:\", \n  }); \n  const command = new CreateBucketCommand({ Bucket: bucketName }); \n  await s3Client.send(command); \n  console.log(\"Bucket created successfully.\\n\"); \n  return bucketName;\n};\nBuckets contain 'objects'. This function uploads the contents of a directory to your bucket as \nobjects.\nexport const uploadFilesToBucket = async ({ bucketName, folderPath }) => { \n  console.log(`Uploading files from ${folderPath}\\n`); \n  const keys = readdirSync(folderPath); \n  const files = keys.map((key) => { \n    const filePath = `${folderPath}/${key}`; \n    const fileContent = readFileSync(filePath); \n    return { \n      Key: key, \n      Body: fileContent, \n    }; \n  }); \n  for (const file of files) { \n    await s3Client.send( \n      new PutObjectCommand({ \n        Bucket: bucketName, \n        Body: file.Body, \n        Key: file.Key, \n      }), \n    ); \n    console.log(`${file.Key} uploaded successfully.`); \n  }\nBasics API Version 2006-03-01 1773Amazon Simple Storage Service API Reference\n};\nAfter uploading objects, check to con\ufb01rm that they were uploaded correctly.", "You can use \nListObjects for that.", "You'll be using the 'Key' property, but there are other useful properties \nin the response also.\nexport const listFilesInBucket = async ({ bucketName }) => { \n  const command = new ListObjectsCommand({ Bucket: bucketName }); \n  const { Contents } = await s3Client.send(command); \n  const contentsList = Contents.map((c) => ` \u2022 ${c.Key}`).join(\"\\n\"); \n  console.log(\"\\nHere's a list of files in the bucket:\"); \n  console.log(`${contentsList}\\n`);\n};\nSometimes you might want to copy an object from one bucket to another. Use the \nCopyObject command for that.\nexport const copyFileFromBucket = async ({ destinationBucket }) => { \n  const proceed = await prompter.confirm({ \n    message: \"Would you like to copy an object from another bucket?\", \n  }); \n  if (!proceed) { \n    return; \n  } \n  const copy = async () => { \n    try { \n      const sourceBucket = await prompter.input({ \n        message: \"Enter source bucket name:\", \n      }); \n      const sourceKey = await prompter.input({ \n        message: \"Enter source key:\", \n      }); \n      const destinationKey = await prompter.input({ \n        message: \"Enter destination key:\", \n      }); \n      const command = new CopyObjectCommand({ \n        Bucket: destinationBucket, \n        CopySource: `${sourceBucket}/${sourceKey}`, \nBasics API Version 2006-03-01 1774Amazon Simple Storage Service API Reference\n        Key: destinationKey, \n      }); \n      await s3Client.send(command); \n      await copyFileFromBucket({ destinationBucket }); \n    } catch (err) { \n      console.error(\"Copy error.\"); \n      console.error(err); \n      const retryAnswer = await prompter.confirm({ message: \"Try again?\" }); \n      if (retryAnswer) { \n        await copy(); \n      } \n    } \n  }; \n  await copy();\n};\nThere's no SDK method for getting multiple objects from a bucket. Instead, you'll create a \nlist of objects to download and iterate over them.\nexport const downloadFilesFromBucket = async ({ bucketName }) => { \n  const { Contents } = await s3Client.send( \n    new ListObjectsCommand({ Bucket: bucketName }), \n  ); \n  const path = await prompter.input({ \n    message: \"Enter destination path for files:\", \n  }); \n  for (const content of Contents) { \n    const obj = await s3Client.send( \n      new GetObjectCommand({ Bucket: bucketName, Key: content.Key }), \n    ); \n    writeFileSync( \n      `${path}/${content.Key}`, \n      await obj.Body.transformToByteArray(), \n    ); \n  } \n  console.log(\"Files downloaded successfully.\\n\");\n};\nIt's time to clean up your resources.", "A bucket must be empty before it can be deleted. These \ntwo functions empty and delete the bucket.\nBasics API Version 2006-03-01 1775Amazon Simple Storage Service API Reference\nexport const emptyBucket = async ({ bucketName }) => { \n  const listObjectsCommand = new ListObjectsCommand({ Bucket: bucketName }); \n  const { Contents } = await s3Client.send(listObjectsCommand); \n  const keys = Contents.map((c) => c.Key); \n  const deleteObjectsCommand = new DeleteObjectsCommand({ \n    Bucket: bucketName, \n    Delete: { Objects: keys.map((key) => ({ Key: key })) }, \n  }); \n  await s3Client.send(deleteObjectsCommand); \n  console.log(`${bucketName} emptied successfully.\\n`);\n};\nexport const deleteBucket = async ({ bucketName }) => { \n  const command = new DeleteBucketCommand({ Bucket: bucketName }); \n  await s3Client.send(command); \n  console.log(`${bucketName} deleted successfully.\\n`);\n};\nThe 'main' function pulls everything together. If you run this \ufb01le directly the main function \nwill be called.\nconst main = async () => { \n  const OBJECT_DIRECTORY = `${dirnameFromMetaUrl( \n    import.meta.url, \n  )}../../../../resources/sample_files/.sample_media`; \n  try { \n    console.log(wrapText(\"Welcome to the Amazon S3 getting started example.\")); \n    console.log(\"Let's create a bucket.\"); \n    const bucketName = await createBucket(); \n    await prompter.confirm({ message: continueMessage }); \n    console.log(wrapText(\"File upload.\")); \n    console.log( \n      \"I have some default files ready to go. You can edit the source code to \n provide your own.\", \n    ); \n    await uploadFilesToBucket({ \n      bucketName, \n      folderPath: OBJECT_DIRECTORY, \n    }); \nBasics API Version 2006-03-01 1776Amazon Simple Storage Service API Reference\n    await listFilesInBucket({ bucketName }); \n    await prompter.confirm({ message: continueMessage }); \n    console.log(wrapText(\"Copy files.\")); \n    await copyFileFromBucket({ destinationBucket: bucketName }); \n    await listFilesInBucket({ bucketName }); \n    await prompter.confirm({ message: continueMessage }); \n    console.log(wrapText(\"Download files.\")); \n    await downloadFilesFromBucket({ bucketName }); \n    console.log(wrapText(\"Clean up.\")); \n    await emptyBucket({ bucketName }); \n    await deleteBucket({ bucketName }); \n  } catch (err) { \n    console.error(err); \n  }\n};\n\u2022For API details, see the following topics in AWS SDK for JavaScript API Reference.\n\u2022CopyObject\n\u2022CreateBucket\n\u2022DeleteBucket\n\u2022DeleteObjects\n\u2022GetObject\n\u2022ListObjectsV2\n\u2022PutObject\nKotlin\nSDK for Kotlin\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nBasics API Version 2006-03-01 1777Amazon Simple Storage Service API Reference\nsuspend fun main(args: Array<String>) { \n    val usage = \"\"\" \n    Usage: \n        <bucketName> <key> <objectPath> <savePath> <toBucket> \n    Where: \n        bucketName - The Amazon S3 bucket to create.", "\n        key - The key to use.", "\n        objectPath - The path where the file is located (for example, C:/AWS/\nbook2.pdf). \n        savePath - The path where the file is saved after it's downloaded (for \n example, C:/AWS/book2.pdf).", "\n        toBucket - An Amazon S3 bucket to where an object is copied to (for \n example, C:/AWS/book2.pdf). \n        \"\"\" \n    if (args.size != 4) { \n        println(usage) \n        exitProcess(1) \n    } \n    val bucketName = args[0] \n    val key = args[1] \n    val objectPath = args[2] \n    val savePath = args[3] \n    val toBucket = args[4] \n    // Create an Amazon S3 bucket. \n    createBucket(bucketName) \n    // Update a local file to the Amazon S3 bucket.", "\n    putObject(bucketName, key, objectPath) \n    // Download the object to another local file.", "\n    getObjectFromMrap(bucketName, key, savePath) \n    // List all objects located in the Amazon S3 bucket. \n    listBucketObs(bucketName) \n    // Copy the object to another Amazon S3 bucket \n    copyBucketOb(bucketName, key, toBucket) \n    // Delete the object from the Amazon S3 bucket. \nBasics API Version 2006-03-01 1778Amazon Simple Storage Service API Reference\n    deleteBucketObs(bucketName, key) \n    // Delete the Amazon S3 bucket. \n    deleteBucket(bucketName) \n    println(\"All Amazon S3 operations were successfully performed\")\n}\nsuspend fun createBucket(bucketName: String) { \n    val request = \n        CreateBucketRequest { \n            bucket = bucketName \n        } \n    S3Client { region = \"us-east-1\" }.use { s3 -> \n        s3.createBucket(request) \n        println(\"$bucketName is ready\") \n    }\n}\nsuspend fun putObject( \n    bucketName: String, \n    objectKey: String, \n    objectPath: String,\n) { \n    val metadataVal = mutableMapOf<String, String>() \n    metadataVal[\"myVal\"] = \"test\" \n    val request = \n        PutObjectRequest { \n            bucket = bucketName \n            key = objectKey \n            metadata = metadataVal \n            this.body = Paths.get(objectPath).asByteStream() \n        } \n    S3Client { region = \"us-east-1\" }.use { s3 -> \n        val response = s3.putObject(request) \n        println(\"Tag information is ${response.eTag}\") \n    }\n}\nsuspend fun getObjectFromMrap( \n    bucketName: String, \n    keyName: String, \nBasics API Version 2006-03-01 1779Amazon Simple Storage Service API Reference\n    path: String,\n) { \n    val request = \n        GetObjectRequest { \n            key = keyName \n            bucket = bucketName \n        } \n    S3Client { region = \"us-east-1\" }.use { s3 -> \n        s3.getObject(request) { resp -> \n            val myFile = File(path) \n            resp.body?.writeToFile(myFile) \n            println(\"Successfully read $keyName from $bucketName\") \n        } \n    }\n}\nsuspend fun listBucketObs(bucketName: String) { \n    val request = \n        ListObjectsRequest { \n            bucket = bucketName \n        } \n    S3Client { region = \"us-east-1\" }.use { s3 -> \n        val response = s3.listObjects(request) \n        response.contents?.forEach { myObject -> \n            println(\"The name of the key is ${myObject.key}\") \n            println(\"The owner is ${myObject.owner}\") \n        } \n    }\n}\nsuspend fun copyBucketOb( \n    fromBucket: String, \n    objectKey: String, \n    toBucket: String,\n) { \n    var encodedUrl = \"\" \n    try { \n        encodedUrl = URLEncoder.encode(\"$fromBucket/$objectKey\", \n StandardCharsets.UTF_8.toString()) \n    } catch (e: UnsupportedEncodingException) { \n        println(\"URL could not be encoded: \" + e.message) \nBasics API Version 2006-03-01 1780Amazon Simple Storage Service API Reference\n    } \n    val request = \n        CopyObjectRequest { \n            copySource = encodedUrl \n            bucket = toBucket \n            key = objectKey \n        } \n    S3Client { region = \"us-east-1\" }.use { s3 -> \n        s3.copyObject(request) \n    }\n}\nsuspend fun deleteBucketObs( \n    bucketName: String, \n    objectName: String,\n) { \n    val objectId = \n        ObjectIdentifier { \n            key = objectName \n        } \n    val delOb = \n        Delete { \n            objects = listOf(objectId) \n        } \n    val request = \n        DeleteObjectsRequest { \n            bucket = bucketName \n            delete = delOb \n        } \n    S3Client { region = \"us-east-1\" }.use { s3 -> \n        s3.deleteObjects(request) \n        println(\"$objectName was deleted from $bucketName\") \n    }\n}\nsuspend fun deleteBucket(bucketName: String?) { \n    val request = \n        DeleteBucketRequest { \n            bucket = bucketName \n        } \nBasics API Version 2006-03-01 1781Amazon Simple Storage Service API Reference\n    S3Client { region = \"us-east-1\" }.use { s3 -> \n        s3.deleteBucket(request) \n        println(\"The $bucketName was successfully deleted!\") \n    }\n}\n\u2022For API details, see the following topics in AWS SDK for Kotlin API reference.\n\u2022CopyObject\n\u2022CreateBucket\n\u2022DeleteBucket\n\u2022DeleteObjects\n\u2022GetObject\n\u2022ListObjectsV2\n\u2022PutObject\nPHP\nSDK for PHP\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n        echo(\"\\n\"); \n        echo(\"--------------------------------------\\n\"); \n        print(\"Welcome to the Amazon S3 getting started demo using PHP!\\n\"); \n        echo(\"--------------------------------------\\n\"); \n        $region = 'us-west-2'; \n        $this->s3client = new S3Client([ \n                'region' => $region, \n        ]); \n        /* Inline declaration example \n        $s3client = new Aws\\S3\\S3Client(['region' => 'us-west-2']); \nBasics API Version 2006-03-01 1782Amazon Simple Storage Service API Reference\n        */ \n        $this->bucketName = \"amzn-s3-demo-bucket-\" . uniqid(); \n        try { \n            $this->s3client->createBucket([ \n                'Bucket' => $this->bucketName, \n                'CreateBucketConfiguration' => ['LocationConstraint' => $region], \n            ]); \n            echo \"Created bucket named: $this->bucketName \\n\"; \n        } catch (Exception $exception) { \n            echo \"Failed to create bucket $this->bucketName with error: \" .", "\n $exception->getMessage(); \n            exit(\"Please fix error with bucket creation before continuing.\"); \n        } \n        $fileName = __DIR__ .", "\"/local-file-\" .", "uniqid(); \n        try { \n            $this->s3client->putObject([ \n                'Bucket' => $this->bucketName, \n                'Key' => $fileName, \n                'SourceFile' => __DIR__ .", "'/testfile.txt' \n            ]); \n            echo \"Uploaded $fileName to $this->bucketName.\\n\"; \n        } catch (Exception $exception) { \n            echo \"Failed to upload $fileName with error: \" . $exception-\n>getMessage(); \n            exit(\"Please fix error with file upload before continuing.\"); \n        } \n        try { \n            $file = $this->s3client->getObject([ \n                'Bucket' => $this->bucketName, \n                'Key' => $fileName, \n            ]); \n            $body = $file->get('Body'); \n            $body->rewind(); \n            echo \"Downloaded the file and it begins with: {$body->read(26)}.\\n\"; \n        } catch (Exception $exception) { \n            echo \"Failed to download $fileName from $this->bucketName with error: \n \" . $exception->getMessage(); \n            exit(\"Please fix error with file downloading before continuing.\"); \n        } \nBasics API Version 2006-03-01 1783Amazon Simple Storage Service API Reference\n        try { \n            $folder = \"copied-folder\"; \n            $this->s3client->copyObject([ \n                'Bucket' => $this->bucketName, \n                'CopySource' => \"$this->bucketName/$fileName\", \n                'Key' => \"$folder/$fileName-copy\", \n            ]); \n            echo \"Copied $fileName to $folder/$fileName-copy.\\n\"; \n        } catch (Exception $exception) { \n            echo \"Failed to copy $fileName with error: \" . $exception-\n>getMessage(); \n            exit(\"Please fix error with object copying before continuing.\"); \n        } \n        try { \n            $contents = $this->s3client->listObjectsV2([ \n                'Bucket' => $this->bucketName, \n            ]); \n            echo \"The contents of your bucket are: \\n\"; \n            foreach ($contents['Contents'] as $content) { \n                echo $content['Key'] .", "\"\\n\"; \n            } \n        } catch (Exception $exception) { \n            echo \"Failed to list objects in $this->bucketName with error: \" .", "\n $exception->getMessage(); \n            exit(\"Please fix error with listing objects before continuing.\"); \n        } \n        try { \n            $objects = []; \n            foreach ($contents['Contents'] as $content) { \n                $objects[] = [ \n                    'Key' => $content['Key'], \n                ]; \n            } \n            $this->s3client->deleteObjects([ \n                'Bucket' => $this->bucketName, \n                'Delete' => [ \n                    'Objects' => $objects, \n                ], \n            ]); \n            $check = $this->s3client->listObjectsV2([ \n                'Bucket' => $this->bucketName, \n            ]); \nBasics API Version 2006-03-01 1784Amazon Simple Storage Service API Reference\n            if (count($check) <= 0) { \n                throw new Exception(\"Bucket wasn't empty.\"); \n            } \n            echo \"Deleted all objects and folders from $this->bucketName.\\n\"; \n        } catch (Exception $exception) { \n            echo \"Failed to delete $fileName from $this->bucketName with error: \n \" . $exception->getMessage(); \n            exit(\"Please fix error with object deletion before continuing.\"); \n        } \n        try { \n            $this->s3client->deleteBucket([ \n                'Bucket' => $this->bucketName, \n            ]); \n            echo \"Deleted bucket $this->bucketName.\\n\"; \n        } catch (Exception $exception) { \n            echo \"Failed to delete $this->bucketName with error: \" . $exception-\n>getMessage(); \n            exit(\"Please fix error with bucket deletion before continuing.\"); \n        } \n        echo \"Successfully ran the Amazon S3 with PHP demo.\\n\";\n\u2022For API details, see the following topics in AWS SDK for PHP API Reference.\n\u2022CopyObject\n\u2022CreateBucket\n\u2022DeleteBucket\n\u2022DeleteObjects\n\u2022GetObject\n\u2022ListObjectsV2\n\u2022PutObject\nBasics API Version 2006-03-01 1785Amazon Simple Storage Service API Reference\nPython\nSDK for Python (Boto3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nimport io\nimport os\nimport uuid\nimport boto3\nfrom boto3.s3.transfer import S3UploadFailedError\nfrom botocore.exceptions import ClientError\ndef do_scenario(s3_resource): \n    print(\"-\" * 88) \n    print(\"Welcome to the Amazon S3 getting started demo!\") \n    print(\"-\" * 88) \n    bucket_name = f\"amzn-s3-demo-bucket-{uuid.uuid4()}\" \n    bucket = s3_resource.Bucket(bucket_name) \n    try: \n        bucket.create( \n            CreateBucketConfiguration={ \n                \"LocationConstraint\": s3_resource.meta.client.meta.region_name \n            } \n        ) \n        print(f\"Created demo bucket named {bucket.name}.\") \n    except ClientError as err: \n        print(f\"Tried and failed to create demo bucket {bucket_name}.\") \n        print(f\"\\t{err.response['Error']['Code']}:{err.response['Error']\n['Message']}\") \n        print(f\"\\nCan't continue the demo without a bucket!\") \n        return \n    file_name = None \n    while file_name is None: \nBasics API Version 2006-03-01 1786Amazon Simple Storage Service API Reference\n        file_name = input(\"\\nEnter a file you want to upload to your bucket: \") \n        if not os.path.exists(file_name): \n            print(f\"Couldn't find file {file_name}. Are you sure it exists?\") \n            file_name = None \n    obj = bucket.Object(os.path.basename(file_name)) \n    try: \n        obj.upload_file(file_name) \n        print( \n            f\"Uploaded file {file_name} into bucket {bucket.name} with key \n {obj.key}.\" \n        ) \n    except S3UploadFailedError as err: \n        print(f\"Couldn't upload file {file_name} to {bucket.name}.\") \n        print(f\"\\t{err}\") \n    answer = input(f\"\\nDo you want to download {obj.key} into memory (y/n)?", "\") \n    if answer.lower() == \"y\": \n        data = io.BytesIO() \n        try: \n            obj.download_fileobj(data) \n            data.seek(0) \n            print(f\"Got your object. Here are the first 20 bytes:\\n\") \n            print(f\"\\t{data.read(20)}\") \n        except ClientError as err: \n            print(f\"Couldn't download {obj.key}.\") \n            print( \n                f\"\\t{err.response['Error']['Code']}:{err.response['Error']\n['Message']}\" \n            ) \n    answer = input( \n        f\"\\nDo you want to copy {obj.key} to a subfolder in your bucket (y/n)? \" \n    ) \n    if answer.lower() == \"y\": \n        dest_obj = bucket.Object(f\"demo-folder/{obj.key}\") \n        try: \n            dest_obj.copy({\"Bucket\": bucket.name, \"Key\": obj.key}) \n            print(f\"Copied {obj.key} to {dest_obj.key}.\") \n        except ClientError as err: \n            print(f\"Couldn't copy {obj.key} to {dest_obj.key}.\") \n            print( \n                f\"\\t{err.response['Error']['Code']}:{err.response['Error']\n['Message']}\" \nBasics API Version 2006-03-01 1787Amazon Simple Storage Service API Reference\n            ) \n    print(\"\\nYour bucket contains the following objects:\") \n    try: \n        for o in bucket.objects.all(): \n            print(f\"\\t{o.key}\") \n    except ClientError as err: \n        print(f\"Couldn't list the objects in bucket {bucket.name}.\") \n        print(f\"\\t{err.response['Error']['Code']}:{err.response['Error']\n['Message']}\") \n    answer = input( \n        \"\\nDo you want to delete all of the objects as well as the bucket (y/n)? \n \" \n    ) \n    if answer.lower() == \"y\": \n        try: \n            bucket.objects.delete() \n            bucket.delete() \n            print(f\"Emptied and deleted bucket {bucket.name}.\\n\") \n        except ClientError as err: \n            print(f\"Couldn't empty and delete bucket {bucket.name}.\") \n            print( \n                f\"\\t{err.response['Error']['Code']}:{err.response['Error']\n['Message']}\" \n            ) \n    print(\"Thanks for watching!\") \n    print(\"-\" * 88)\nif __name__ == \"__main__\": \n    do_scenario(boto3.resource(\"s3\"))\n\u2022For API details, see the following topics in AWS SDK for Python (Boto3) API Reference.\n\u2022CopyObject\n\u2022CreateBucket\n\u2022DeleteBucket\n\u2022DeleteObjects\n\u2022GetObject\nBasics API Version 2006-03-01 1788Amazon Simple Storage Service API Reference\n\u2022ListObjectsV2\n\u2022PutObject\nRuby\nSDK for Ruby\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nrequire 'aws-sdk-s3'\n# Wraps the getting started scenario actions.\nclass ScenarioGettingStarted \n  attr_reader :s3_resource \n  # @param s3_resource [Aws::S3::Resource] An Amazon S3 resource. \n  def initialize(s3_resource) \n    @s3_resource = s3_resource \n  end \n  # Creates a bucket with a random name in the currently configured account and \n  # AWS Region. \n  # \n  # @return [Aws::S3::Bucket] The newly created bucket. \n  def create_bucket \n    bucket = @s3_resource.create_bucket( \n      bucket: \"amzn-s3-demo-bucket-#{Random.uuid}\", \n      create_bucket_configuration: { \n        location_constraint: 'us-east-1' # NOTE: only certain regions permitted \n      } \n    ) \n    puts(\"Created demo bucket named #{bucket.name}.\") \n  rescue Aws::Errors::ServiceError => e \n    puts('Tried and failed to create demo bucket.') \n    puts(\"\\t#{e.code}: #{e.message}\") \n    puts(\"\\nCan't continue the demo without a bucket!\") \n    raise \nBasics API Version 2006-03-01 1789Amazon Simple Storage Service API Reference\n  else \n    bucket \n  end \n  # Requests a file name from the user.", "\n  # \n  # @return The name of the file.", "\n  def create_file \n    File.open('demo.txt', w) { |f| f.write('This is a demo file.') } \n  end \n  # Uploads a file to an Amazon S3 bucket. \n  # \n  # @param bucket [Aws::S3::Bucket] The bucket object representing the upload \n destination \n  # @return [Aws::S3::Object] The Amazon S3 object that contains the uploaded \n file. \n  def upload_file(bucket) \n    File.open('demo.txt', 'w+') { |f| f.write('This is a demo file.') } \n    s3_object = bucket.object(File.basename('demo.txt')) \n    s3_object.upload_file('demo.txt') \n    puts(\"Uploaded file demo.txt into bucket #{bucket.name} with key \n #{s3_object.key}.\") \n  rescue Aws::Errors::ServiceError => e \n    puts(\"Couldn't upload file demo.txt to #{bucket.name}.\") \n    puts(\"\\t#{e.code}: #{e.message}\") \n    raise \n  else \n    s3_object \n  end \n  # Downloads an Amazon S3 object to a file. \n  # \n  # @param s3_object [Aws::S3::Object] The object to download. \n  def download_file(s3_object) \n    puts(\"\\nDo you want to download #{s3_object.key} to a local file (y/n)? \") \n    answer = gets.chomp.downcase \n    if answer == 'y' \n      puts('Enter a name for the downloaded file: ') \n      file_name = gets.chomp \n      s3_object.download_file(file_name) \n      puts(\"Object #{s3_object.key} successfully downloaded to #{file_name}.\") \n    end \n  rescue Aws::Errors::ServiceError => e \nBasics API Version 2006-03-01 1790Amazon Simple Storage Service API Reference\n    puts(\"Couldn't download #{s3_object.key}.\") \n    puts(\"\\t#{e.code}: #{e.message}\") \n    raise \n  end \n  # Copies an Amazon S3 object to a subfolder within the same bucket. \n  # \n  # @param source_object [Aws::S3::Object] The source object to copy. \n  # @return [Aws::S3::Object, nil] The destination object.", "\n  def copy_object(source_object) \n    dest_object = nil \n    puts(\"\\nDo you want to copy #{source_object.key} to a subfolder in your \n bucket (y/n)? \") \n    answer = gets.chomp.downcase \n    if answer == 'y' \n      dest_object = source_object.bucket.object(\"demo-folder/\n#{source_object.key}\") \n      dest_object.copy_from(source_object) \n      puts(\"Copied #{source_object.key} to #{dest_object.key}.\") \n    end \n  rescue Aws::Errors::ServiceError => e \n    puts(\"Couldn't copy #{source_object.key}.\") \n    puts(\"\\t#{e.code}: #{e.message}\") \n    raise \n  else \n    dest_object \n  end \n  # Lists the objects in an Amazon S3 bucket. \n  # \n  # @param bucket [Aws::S3::Bucket] The bucket to query. \n  def list_objects(bucket) \n    puts(\"\\nYour bucket contains the following objects:\") \n    bucket.objects.each do |obj| \n      puts(\"\\t#{obj.key}\") \n    end \n  rescue Aws::Errors::ServiceError => e \n    puts(\"Couldn't list the objects in bucket #{bucket.name}.\") \n    puts(\"\\t#{e.code}: #{e.message}\") \n    raise \n  end \n  # Deletes the objects in an Amazon S3 bucket and deletes the bucket. \n  # \nBasics API Version 2006-03-01 1791Amazon Simple Storage Service API Reference\n  # @param bucket [Aws::S3::Bucket] The bucket to empty and delete.", "\n  def delete_bucket(bucket) \n    puts(\"\\nDo you want to delete all of the objects as well as the bucket (y/n)? \n \") \n    answer = gets.chomp.downcase \n    if answer == 'y' \n      bucket.objects.batch_delete! \n      bucket.delete \n      puts(\"Emptied and deleted bucket #{bucket.name}.\\n\") \n    end \n  rescue Aws::Errors::ServiceError => e \n    puts(\"Couldn't empty and delete bucket #{bucket.name}.\") \n    puts(\"\\t#{e.code}: #{e.message}\") \n    raise \n  end\nend\n# Runs the Amazon S3 getting started scenario.\ndef run_scenario(scenario) \n  puts('-' * 88) \n  puts('Welcome to the Amazon S3 getting started demo!') \n  puts('-' * 88) \n  bucket = scenario.create_bucket \n  s3_object = scenario.upload_file(bucket) \n  scenario.download_file(s3_object) \n  scenario.copy_object(s3_object) \n  scenario.list_objects(bucket) \n  scenario.delete_bucket(bucket) \n  puts('Thanks for watching!') \n  puts('-' * 88)\nrescue Aws::Errors::ServiceError \n  puts('Something went wrong with the demo!')\nend\nrun_scenario(ScenarioGettingStarted.new(Aws::S3::Resource.new)) if $PROGRAM_NAME \n == __FILE__\n\u2022For API details, see the following topics in AWS SDK for Ruby API Reference.\n\u2022CopyObject\n\u2022CreateBucket\nBasics API Version 2006-03-01 1792Amazon Simple Storage Service API Reference\n\u2022DeleteBucket\n\u2022DeleteObjects\n\u2022GetObject\n\u2022ListObjectsV2\n\u2022PutObject\nRust\nSDK for Rust\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nCode for the binary crate which runs the scenario.\n#![allow(clippy::result_large_err)]\n//!", "Purpose\n//!", "Shows how to use the AWS SDK for Rust to get started using\n//!", "Amazon Simple Storage Service (Amazon S3).", "Create a bucket, move objects \n into and out of it,\n//!", "and delete all resources at the end of the demo.\n//!\n//!", "This example follows the steps in \"Getting started with Amazon S3\" in the \n Amazon S3\n//!", "user guide.\n//!", "- https://docs.aws.amazon.com/AmazonS3/latest/userguide/\nGetStartedWithS3.html\nuse aws_config::meta::region::RegionProviderChain;\nuse aws_sdk_s3::{config::Region, Client};\nuse s3_code_examples::error::S3ExampleError;\nuse uuid::Uuid;\n#[tokio::main]\nasync fn main() -> Result<(), S3ExampleError> { \nBasics API Version 2006-03-01 1793Amazon Simple Storage Service API Reference\n    let region_provider = RegionProviderChain::first_try(Region::new(\"us-\nwest-2\")); \n    let region = region_provider.region().await.unwrap(); \n    let shared_config = \n aws_config::from_env().region(region_provider).load().await; \n    let client = Client::new(&shared_config); \n    let bucket_name = format!(\"amzn-s3-demo-bucket-{}\", Uuid::new_v4()); \n    let file_name = \"s3/testfile.txt\".to_string(); \n    let key = \"test file key name\".to_string(); \n    let target_key = \"target_key\".to_string(); \n    if let Err(e) = run_s3_operations(region, client, bucket_name, file_name, \n key, target_key).await \n    { \n        eprintln!(\"{:?}\", e); \n    }; \n    Ok(())\n}\nasync fn run_s3_operations( \n    region: Region, \n    client: Client, \n    bucket_name: String, \n    file_name: String, \n    key: String, \n    target_key: String,\n) -> Result<(), S3ExampleError> { \n    s3_code_examples::create_bucket(&client, &bucket_name, &region).await?; \n    let run_example: Result<(), S3ExampleError> = (async { \n        s3_code_examples::upload_object(&client, &bucket_name, &file_name, \n &key).await?; \n        let _object = s3_code_examples::download_object(&client, &bucket_name, \n &key).await; \n        s3_code_examples::copy_object(&client, &bucket_name, &bucket_name, &key, \n &target_key) \n            .await?; \n        s3_code_examples::list_objects(&client, &bucket_name).await?; \n        s3_code_examples::clear_bucket(&client, &bucket_name).await?; \n        Ok(()) \n    }) \n    .await; \n    if let Err(err) = run_example { \n        eprintln!(\"Failed to complete getting-started example: {err:?}\"); \nBasics API Version 2006-03-01 1794Amazon Simple Storage Service API Reference\n    } \n    s3_code_examples::delete_bucket(&client, &bucket_name).await?; \n    Ok(())\n}\nCommon actions used by the scenario.\npub async fn create_bucket( \n    client: &aws_sdk_s3::Client, \n    bucket_name: &str, \n    region: &aws_config::Region,\n) -> Result<Option<aws_sdk_s3::operation::create_bucket::CreateBucketOutput>, \n S3ExampleError> { \n    let constraint = \n aws_sdk_s3::types::BucketLocationConstraint::from(region.to_string().as_str()); \n    let cfg = aws_sdk_s3::types::CreateBucketConfiguration::builder() \n        .location_constraint(constraint) \n        .build(); \n    let create = client \n        .create_bucket() \n        .create_bucket_configuration(cfg) \n        .bucket(bucket_name) \n        .send() \n        .await; \n    // BucketAlreadyExists and BucketAlreadyOwnedByYou are not problems for this \n task. \n    create.map(Some).or_else(|err| { \n        if err \n            .as_service_error() \n            .map(|se| se.is_bucket_already_exists() || \n se.is_bucket_already_owned_by_you()) \n            == Some(true) \n        { \n            Ok(None) \n        } else { \n            Err(S3ExampleError::from(err)) \n        } \n    })\n}\nBasics API Version 2006-03-01 1795Amazon Simple Storage Service API Reference\npub async fn upload_object( \n    client: &aws_sdk_s3::Client, \n    bucket_name: &str, \n    file_name: &str, \n    key: &str,\n) -> Result<aws_sdk_s3::operation::put_object::PutObjectOutput, S3ExampleError> { \n    let body = \n aws_sdk_s3::primitives::ByteStream::from_path(std::path::Path::new(file_name)).await; \n    client \n        .put_object() \n        .bucket(bucket_name) \n        .key(key) \n        .body(body.unwrap()) \n        .send() \n        .await \n        .map_err(S3ExampleError::from)\n}\npub async fn download_object( \n    client: &aws_sdk_s3::Client, \n    bucket_name: &str, \n    key: &str,\n) -> Result<aws_sdk_s3::operation::get_object::GetObjectOutput, S3ExampleError> { \n    client \n        .get_object() \n        .bucket(bucket_name) \n        .key(key) \n        .send() \n        .await \n        .map_err(S3ExampleError::from)\n}\n/// Copy an object from one bucket to another.\npub async fn copy_object( \n    client: &aws_sdk_s3::Client, \n    source_bucket: &str, \n    destination_bucket: &str, \n    source_object: &str, \n    destination_object: &str,\n) -> Result<(), S3ExampleError> { \n    let source_key = format!(\"{source_bucket}/{source_object}\"); \n    let response = client \n        .copy_object() \n        .copy_source(&source_key) \nBasics API Version 2006-03-01 1796Amazon Simple Storage Service API Reference\n        .bucket(destination_bucket) \n        .key(destination_object) \n        .send() \n        .await?; \n    println!( \n        \"Copied from {source_key} to {destination_bucket}/{destination_object} \n with etag {}\", \n        response \n            .copy_object_result \n            .unwrap_or_else(|| \n aws_sdk_s3::types::CopyObjectResult::builder().build()) \n            .e_tag() \n            .unwrap_or(\"missing\") \n    ); \n    Ok(())\n}\npub async fn list_objects(client: &aws_sdk_s3::Client, bucket: &str) -> \n Result<(), S3ExampleError> { \n    let mut response = client \n        .list_objects_v2() \n        .bucket(bucket.to_owned()) \n        .max_keys(10) // In this example, go 10 at a time. \n        .into_paginator() \n        .send(); \n    while let Some(result) = response.next().await { \n        match result { \n            Ok(output) => { \n                for object in output.contents() { \n                    println!(\" - {}\", object.key().unwrap_or(\"Unknown\")); \n                } \n            } \n            Err(err) => { \n                eprintln!(\"{err:?}\") \n            } \n        } \n    } \n    Ok(())\n}\n/// Given a bucket, remove all objects in the bucket, and then ensure no objects\nBasics API Version 2006-03-01 1797Amazon Simple Storage Service API Reference\n/// remain in the bucket.\npub async fn clear_bucket( \n    client: &aws_sdk_s3::Client, \n    bucket_name: &str,\n) -> Result<Vec<String>, S3ExampleError> { \n    let objects = client.list_objects_v2().bucket(bucket_name).send().await?; \n    // delete_objects no longer needs to be mutable. \n    let objects_to_delete: Vec<String> = objects \n        .contents() \n        .iter() \n        .filter_map(|obj| obj.key()) \n        .map(String::from) \n        .collect(); \n    if objects_to_delete.is_empty() { \n        return Ok(vec![]); \n    } \n    let return_keys = objects_to_delete.clone(); \n    delete_objects(client, bucket_name, objects_to_delete).await?; \n    let objects = client.list_objects_v2().bucket(bucket_name).send().await?; \n    eprintln!(\"{objects:?}\"); \n    match objects.key_count { \n        Some(0) => Ok(return_keys), \n        _ => Err(S3ExampleError::new( \n            \"There were still objects left in the bucket.\", \n        )), \n    }\n}\npub async fn delete_bucket( \n    client: &aws_sdk_s3::Client, \n    bucket_name: &str,\n) -> Result<(), S3ExampleError> { \n    let resp = client.delete_bucket().bucket(bucket_name).send().await; \n    match resp { \n        Ok(_) => Ok(()), \n        Err(err) => { \n            if err \nBasics API Version 2006-03-01 1798Amazon Simple Storage Service API Reference\n                .as_service_error() \n                .and_then(aws_sdk_s3::error::ProvideErrorMetadata::code) \n                == Some(\"NoSuchBucket\") \n            { \n                Ok(()) \n            } else { \n                Err(S3ExampleError::from(err)) \n            } \n        } \n    }\n}\n\u2022For API details, see the following topics in AWS SDK for Rust API reference.\n\u2022CopyObject\n\u2022CreateBucket\n\u2022DeleteBucket\n\u2022DeleteObjects\n\u2022GetObject\n\u2022ListObjectsV2\n\u2022PutObject\nSAP ABAP\nSDK for SAP ABAP\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n    DATA(lo_session) = /aws1/cl_rt_session_aws=>create( cv_pfl ).", "\n    DATA(lo_s3) = /aws1/cl_s3_factory=>create( lo_session ). \n    \" Create an Amazon Simple Storage Service (Amazon S3) bucket.", "\" \n    TRY.", "\n        lo_s3->createbucket( \nBasics API Version 2006-03-01 1799Amazon Simple Storage Service API Reference\n            iv_bucket = iv_bucket_name \n        ). \n        MESSAGE 'S3 bucket created.' TYPE 'I'. \n      CATCH /aws1/cx_s3_bucketalrdyexists.", "\n        MESSAGE 'Bucket name already exists.' TYPE 'E'.", "\n      CATCH /aws1/cx_s3_bktalrdyownedbyyou.", "\n        MESSAGE 'Bucket already exists and is owned by you.' TYPE 'E'.", "\n    ENDTRY.", "\n    \"Upload an object to an S3 bucket.\" \n    TRY.", "\n        \"Get contents of file from application server.\" \n        DATA lv_file_content TYPE xstring.", "\n        OPEN DATASET iv_key FOR INPUT IN BINARY MODE. \n        READ DATASET iv_key INTO lv_file_content. \n        CLOSE DATASET iv_key.", "\n        lo_s3->putobject( \n            iv_bucket = iv_bucket_name \n            iv_key = iv_key \n            iv_body = lv_file_content \n        ). \n        MESSAGE 'Object uploaded to S3 bucket.' TYPE 'I'.", "\n      CATCH /aws1/cx_s3_nosuchbucket.", "\n        MESSAGE 'Bucket does not exist.' TYPE 'E'.", "\n    ENDTRY.", "\n    \" Get an object from a bucket.", "\" \n    TRY.", "\n        DATA(lo_result) = lo_s3->getobject( \n                   iv_bucket = iv_bucket_name \n                   iv_key = iv_key \n                ).", "\n        DATA(lv_object_data) = lo_result->get_body( ).", "\n        MESSAGE 'Object retrieved from S3 bucket.' TYPE 'I'.", "\n      CATCH /aws1/cx_s3_nosuchbucket.", "\n        MESSAGE 'Bucket does not exist.' TYPE 'E'.", "\n      CATCH /aws1/cx_s3_nosuchkey.", "\n        MESSAGE 'Object key does not exist.' TYPE 'E'.", "\n    ENDTRY.", "\n    \" Copy an object to a subfolder in a bucket.", "\" \n    TRY.", "\nBasics API Version 2006-03-01 1800Amazon Simple Storage Service API Reference\n        lo_s3->copyobject( \n          iv_bucket = iv_bucket_name \n          iv_key = |{ iv_copy_to_folder }/{ iv_key }| \n          iv_copysource = |{ iv_bucket_name }/{ iv_key }| \n        ).", "\n        MESSAGE 'Object copied to a subfolder.' TYPE 'I'.", "\n      CATCH /aws1/cx_s3_nosuchbucket.", "\n        MESSAGE 'Bucket does not exist.' TYPE 'E'.", "\n      CATCH /aws1/cx_s3_nosuchkey.", "\n        MESSAGE 'Object key does not exist.' TYPE 'E'.", "\n    ENDTRY.", "\n    \" List objects in the bucket.", "\" \n    TRY.", "\n        DATA(lo_list) = lo_s3->listobjects( \n           iv_bucket = iv_bucket_name \n         ). \n        MESSAGE 'Retrieved list of objects in S3 bucket.' TYPE 'I'.", "\n      CATCH /aws1/cx_s3_nosuchbucket.", "\n        MESSAGE 'Bucket does not exist.' TYPE 'E'.", "\n    ENDTRY.", "\n    DATA text TYPE string VALUE 'Object List - '.", "\n    DATA lv_object_key TYPE /aws1/s3_objectkey.", "\n    LOOP AT lo_list->get_contents( ) INTO DATA(lo_object).", "\n      lv_object_key = lo_object->get_key( ). \n      CONCATENATE lv_object_key ', ' INTO text.", "\n    ENDLOOP.", "\n    MESSAGE text TYPE'I'.", "\n    \" Delete the objects in a bucket.", "\" \n    TRY.", "\n        lo_s3->deleteobject( \n            iv_bucket = iv_bucket_name \n            iv_key = iv_key \n        ). \n        lo_s3->deleteobject( \n            iv_bucket = iv_bucket_name \n            iv_key = |{ iv_copy_to_folder }/{ iv_key }| \n        ). \n        MESSAGE 'Objects deleted from S3 bucket.' TYPE 'I'.", "\n      CATCH /aws1/cx_s3_nosuchbucket.", "\n        MESSAGE 'Bucket does not exist.' TYPE 'E'.", "\n    ENDTRY.", "\nBasics API Version 2006-03-01 1801Amazon Simple Storage Service API Reference\n    \" Delete the bucket.", "\" \n    TRY.", "\n        lo_s3->deletebucket( \n            iv_bucket = iv_bucket_name \n        ). \n        MESSAGE 'Deleted S3 bucket.' TYPE 'I'.", "\n      CATCH /aws1/cx_s3_nosuchbucket.", "\n        MESSAGE 'Bucket does not exist.' TYPE 'E'.", "\n    ENDTRY.\n\u2022For API details, see the following topics in AWS SDK for SAP ABAP API reference.\n\u2022CopyObject\n\u2022CreateBucket\n\u2022DeleteBucket\n\u2022DeleteObjects\n\u2022GetObject\n\u2022ListObjectsV2\n\u2022PutObject\nSwift\nSDK for Swift\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nimport AWSS3\nimport Foundation\nimport AWSS3\nimport Smithy\nimport ClientRuntime\nBasics API Version 2006-03-01 1802Amazon Simple Storage Service API Reference\n/// A class containing all the code that interacts with the AWS SDK for Swift.\npublic class ServiceHandler { \n    let configuration: S3Client.S3ClientConfiguration \n    let client: S3Client \n    enum HandlerError: Error { \n        case getObjectBody(String) \n        case readGetObjectBody(String) \n        case missingContents(String) \n    } \n    /// Initialize and return a new ``ServiceHandler`` object, which is used to \n drive the AWS calls \n    /// used for the example. \n    /// \n    /// - Returns: A new ``ServiceHandler`` object, ready to be called to \n    ///            execute AWS operations.", "\n    public init() async throws { \n        do { \n            configuration = try await S3Client.S3ClientConfiguration()  \n         //   configuration.region = \"us-east-2\" // Uncomment this to set the \n region programmatically. \n            client = S3Client(config: configuration) \n        } \n        catch { \n            print(\"ERROR: \", dump(error, name: \"Initializing S3 client\")) \n            throw error \n        } \n    } \n    /// Create a new user given the specified name.", "\n    /// \n    /// - Parameters: \n    ///   - name: Name of the bucket to create.", "\n    /// Throws an exception if an error occurs.", "\n    public func createBucket(name: String) async throws { \n        var input = CreateBucketInput( \n            bucket: name \n        ) \n         \n        // For regions other than \"us-east-1\", you must set the \n locationConstraint in the createBucketConfiguration.", "\n        // For more information, see LocationConstraint in the S3 API guide.", "\nBasics API Version 2006-03-01 1803Amazon Simple Storage Service API Reference\n        // https://docs.aws.amazon.com/AmazonS3/latest/API/\nAPI_CreateBucket.html#API_CreateBucket_RequestBody \n        if let region = configuration.region { \n            if region != \"us-east-1\" { \n                input.createBucketConfiguration = \n S3ClientTypes.CreateBucketConfiguration(locationConstraint: \n S3ClientTypes.BucketLocationConstraint(rawValue: region)) \n            } \n        } \n        do { \n            _ = try await client.createBucket(input: input) \n        } \n        catch let error as BucketAlreadyOwnedByYou { \n            print(\"The bucket '\\(name)' already exists and is owned by you. You \n may wish to ignore this exception.\") \n            throw error \n        } \n        catch { \n            print(\"ERROR: \", dump(error, name: \"Creating a bucket\")) \n            throw error \n        } \n    } \n    /// Delete a bucket. \n    /// - Parameter name: Name of the bucket to delete. \n    public func deleteBucket(name: String) async throws { \n        let input = DeleteBucketInput( \n            bucket: name \n        ) \n        do { \n            _ = try await client.deleteBucket(input: input) \n        } \n        catch { \n            print(\"ERROR: \", dump(error, name: \"Deleting a bucket\")) \n            throw error \n        } \n    } \n    /// Upload a file from local storage to the bucket. \n    /// - Parameters: \n    ///   - bucket: Name of the bucket to upload the file to.", "\n    ///   - key: Name of the file to create. \n    ///   - file: Path name of the file to upload. \nBasics API Version 2006-03-01 1804Amazon Simple Storage Service API Reference\n    public func uploadFile(bucket: String, key: String, file: String) async \n throws { \n        let fileUrl = URL(fileURLWithPath: file) \n        do { \n            let fileData = try Data(contentsOf: fileUrl) \n            let dataStream = ByteStream.data(fileData) \n            let input = PutObjectInput( \n                body: dataStream, \n                bucket: bucket, \n                key: key \n            ) \n            _ = try await client.putObject(input: input) \n        } \n        catch { \n            print(\"ERROR: \", dump(error, name: \"Putting an object.\")) \n            throw error \n        } \n    } \n    /// Create a file in the specified bucket with the given name.", "The new \n    /// file's contents are uploaded from a `Data` object.", "\n    /// \n    /// - Parameters: \n    ///   - bucket: Name of the bucket to create a file in.", "\n    ///   - key: Name of the file to create. \n    ///   - data: A `Data` object to write into the new file.", "\n    public func createFile(bucket: String, key: String, withData data: Data) \n async throws { \n        let dataStream = ByteStream.data(data) \n        let input = PutObjectInput( \n            body: dataStream, \n            bucket: bucket, \n            key: key \n        ) \n        do { \n            _ = try await client.putObject(input: input) \n        } \n        catch { \n            print(\"ERROR: \", dump(error, name: \"Putting an object.\")) \n            throw error \nBasics API Version 2006-03-01 1805Amazon Simple Storage Service API Reference\n        } \n    } \n    /// Download the named file to the given directory on the local device. \n    /// \n    /// - Parameters: \n    ///   - bucket: Name of the bucket that contains the file to be copied. \n    ///   - key: The name of the file to copy from the bucket.", "\n    ///   - to: The path of the directory on the local device where you want to \n    ///     download the file.", "\n    public func downloadFile(bucket: String, key: String, to: String) async \n throws { \n        let fileUrl = URL(fileURLWithPath: to).appendingPathComponent(key) \n        let input = GetObjectInput( \n            bucket: bucket, \n            key: key \n        ) \n        do { \n            let output = try await client.getObject(input: input) \n            guard let body = output.body else { \n                throw HandlerError.getObjectBody(\"GetObjectInput missing body.\") \n            } \n            guard let data = try await body.readData() else { \n                throw HandlerError.readGetObjectBody(\"GetObjectInput unable to \n read data.\") \n            } \n            try data.write(to: fileUrl) \n        } \n        catch { \n            print(\"ERROR: \", dump(error, name: \"Downloading a file.\")) \n            throw error \n        } \n    } \n    /// Read the specified file from the given S3 bucket into a Swift \n    /// `Data` object. \n    /// \n    /// - Parameters: \n    ///   - bucket: Name of the bucket containing the file to read. \n    ///   - key: Name of the file within the bucket to read.", "\nBasics API Version 2006-03-01 1806Amazon Simple Storage Service API Reference\n    /// \n    /// - Returns: A `Data` object containing the complete file data.", "\n    public func readFile(bucket: String, key: String) async throws -> Data { \n        let input = GetObjectInput( \n            bucket: bucket, \n            key: key \n        ) \n        do { \n            let output = try await client.getObject(input: input) \n             \n            guard let body = output.body else { \n                throw HandlerError.getObjectBody(\"GetObjectInput missing body.\") \n            } \n            guard let data = try await body.readData() else { \n                throw HandlerError.readGetObjectBody(\"GetObjectInput unable to \n read data.\") \n            } \n            return data \n        } \n        catch { \n            print(\"ERROR: \", dump(error, name: \"Reading a file.\")) \n            throw error \n        } \n   } \n    /// Copy a file from one bucket to another. \n    /// \n    /// - Parameters: \n    ///   - sourceBucket: Name of the bucket containing the source file.", "\n    ///   - name: Name of the source file.", "\n    ///   - destBucket: Name of the bucket to copy the file into. \n    public func copyFile(from sourceBucket: String, name: String, to destBucket: \n String) async throws { \n        let srcUrl = (\"\\(sourceBucket)/\n\\(name)\").addingPercentEncoding(withAllowedCharacters: .urlPathAllowed) \n        let input = CopyObjectInput( \n            bucket: destBucket, \n            copySource: srcUrl, \n            key: name \n        ) \nBasics API Version 2006-03-01 1807Amazon Simple Storage Service API Reference\n        do { \n            _ = try await client.copyObject(input: input) \n        } \n        catch { \n            print(\"ERROR: \", dump(error, name: \"Copying an object.\")) \n            throw error \n        } \n    } \n    /// Deletes the specified file from Amazon S3. \n    /// \n    /// - Parameters: \n    ///   - bucket: Name of the bucket containing the file to delete. \n    ///   - key: Name of the file to delete. \n    /// \n    public func deleteFile(bucket: String, key: String) async throws { \n        let input = DeleteObjectInput( \n            bucket: bucket, \n            key: key \n        ) \n        do { \n            _ = try await client.deleteObject(input: input) \n        } \n        catch { \n            print(\"ERROR: \", dump(error, name: \"Deleting a file.\")) \n            throw error \n        } \n    } \n    /// Returns an array of strings, each naming one file in the \n    /// specified bucket. \n    /// \n    /// - Parameter bucket: Name of the bucket to get a file listing for. \n    /// - Returns: An array of `String` objects, each giving the name of \n    ///            one file contained in the bucket. \n    public func listBucketFiles(bucket: String) async throws -> [String] { \n        do { \n            let input = ListObjectsV2Input( \n                bucket: bucket \n            ) \n             \n            // Use \"Paginated\" to get all the objects.", "\nBasics API Version 2006-03-01 1808Amazon Simple Storage Service API Reference\n            // This lets the SDK handle the 'continuationToken' in \n \"ListObjectsV2Output\".", "\n            let output = client.listObjectsV2Paginated(input: input) \n            var names: [String] = [] \n             \n            for try await page in output { \n                guard let objList = page.contents else { \n                    print(\"ERROR: listObjectsV2Paginated returned nil contents.\") \n                    continue \n                } \n                 \n                for obj in objList { \n                    if let objName = obj.key { \n                        names.append(objName) \n                    } \n                } \n            } \n             \n             \n            return names \n        } \n        catch { \n            print(\"ERROR: \", dump(error, name: \"Listing objects.\")) \n            throw error \n        } \n    }\n}\nimport AWSS3\nimport Foundation\nimport ServiceHandler\nimport ArgumentParser\n/// The command-line arguments and options available for this\n/// example command.\nstruct ExampleCommand: ParsableCommand { \n    @Argument(help: \"Name of the S3 bucket to create\") \n    var bucketName: String \n    @Argument(help: \"Pathname of the file to upload to the S3 bucket\") \n    var uploadSource: String \nBasics API Version 2006-03-01 1809Amazon Simple Storage Service API Reference\n    @Argument(help: \"The name (key) to give the file in the S3 bucket\") \n    var objName: String \n    @Argument(help: \"S3 bucket to copy the object to\") \n    var destBucket: String \n    @Argument(help: \"Directory where you want to download the file from the S3 \n bucket\") \n    var downloadDir: String \n    static var configuration = CommandConfiguration( \n        commandName: \"s3-basics\", \n        abstract: \"Demonstrates a series of basic AWS S3 functions.\", \n        discussion: \"\"\" \n        Performs the following Amazon S3 commands: \n        * `CreateBucket` \n        * `PutObject` \n        * `GetObject` \n        * `CopyObject` \n        * `ListObjects` \n        * `DeleteObjects` \n        * `DeleteBucket` \n        \"\"\" \n    ) \n    /// Called by ``main()`` to do the actual running of the AWS \n    /// example.", "\n    func runAsync() async throws { \n        let serviceHandler = try await ServiceHandler() \n        // 1.", "Create the bucket. \n        print(\"Creating the bucket \\(bucketName)...\") \n        try await serviceHandler.createBucket(name: bucketName) \n        // 2. Upload a file to the bucket. \n        print(\"Uploading the file \\(uploadSource)...\") \n        try await serviceHandler.uploadFile(bucket: bucketName, key: objName, \n file: uploadSource) \n        // 3.", "Download the file.", "\n        print(\"Downloading the file \\(objName) to \\(downloadDir)...\") \nBasics API Version 2006-03-01 1810Amazon Simple Storage Service API Reference\n        try await serviceHandler.downloadFile(bucket: bucketName, key: objName, \n to: downloadDir) \n        // 4.", "Copy the file to another bucket. \n        print(\"Copying the file to the bucket \\(destBucket)...\") \n        try await serviceHandler.copyFile(from: bucketName, name: objName, to: \n destBucket) \n        // 5. List the contents of the bucket. \n        print(\"Getting a list of the files in the bucket \\(bucketName)\") \n        let fileList = try await serviceHandler.listBucketFiles(bucket: \n bucketName) \n        let numFiles = fileList.count \n        if numFiles != 0 { \n            print(\"\\(numFiles) file\\((numFiles > 1) ? \"s\" : \"\") in bucket \n \\(bucketName):\") \n            for name in fileList { \n                print(\"  \\(name)\") \n            } \n        } else { \n            print(\"No files found in bucket \\(bucketName)\") \n        } \n        // 6. Delete the objects from the bucket. \n        print(\"Deleting the file \\(objName) from the bucket \\(bucketName)...\") \n        try await serviceHandler.deleteFile(bucket: bucketName, key: objName) \n        print(\"Deleting the file \\(objName) from the bucket \\(destBucket)...\") \n        try await serviceHandler.deleteFile(bucket: destBucket, key: objName) \n        // 7. Delete the bucket. \n        print(\"Deleting the bucket \\(bucketName)...\") \n        try await serviceHandler.deleteBucket(name: bucketName) \n        print(\"Done.\") \n    }\n}\n//\n// Main program entry point.\n//\n@main\nstruct Main { \nBasics API Version 2006-03-01 1811Amazon Simple Storage Service API Reference\n    static func main() async { \n        let args = Array(CommandLine.arguments.dropFirst()) \n        do { \n            let command = try ExampleCommand.parse(args) \n            try await command.runAsync() \n        } catch { \n            ExampleCommand.exit(withError: error) \n        } \n    }     \n}\n\u2022For API details, see the following topics in AWS SDK for Swift API reference.\n\u2022CopyObject\n\u2022CreateBucket\n\u2022DeleteBucket\n\u2022DeleteObjects\n\u2022GetObject\n\u2022ListObjectsV2\n\u2022PutObject\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs.", "This topic also includes information about getting started and details \nabout previous SDK versions.\nActions for Amazon S3 using AWS SDKs\nThe following code examples demonstrate how to perform individual Amazon S3 actions with AWS \nSDKs. Each example includes a link to GitHub, where you can \ufb01nd instructions for setting up and \nrunning the code.\nThese excerpts call the Amazon S3 API and are code excerpts from larger programs that must be \nrun in context. You can see actions in context in Scenarios for Amazon S3 using AWS SDKs .\nThe following examples include only the most commonly used actions.", "For a complete list, see the\nAmazon Simple Storage Service API Reference.\nExamples\nBasics API Version 2006-03-01 1812Amazon Simple Storage Service API Reference\n\u2022Use AbortMultipartUpload with an AWS SDK or CLI\n\u2022Use AbortMultipartUploads with an AWS SDK\n\u2022Use CompleteMultipartUpload with an AWS SDK or CLI\n\u2022Use CopyObject with an AWS SDK or CLI\n\u2022Use CreateBucket with an AWS SDK or CLI\n\u2022Use CreateMultiRegionAccessPoint with an AWS SDK\n\u2022Use CreateMultipartUpload with an AWS SDK or CLI\n\u2022Use DeleteBucket with an AWS SDK or CLI\n\u2022Use DeleteBucketAnalyticsCon\ufb01guration with a CLI\n\u2022Use DeleteBucketCors with an AWS SDK or CLI\n\u2022Use DeleteBucketEncryption with a CLI\n\u2022Use DeleteBucketInventoryCon\ufb01guration with a CLI\n\u2022Use DeleteBucketLifecycle with an AWS SDK or CLI\n\u2022Use DeleteBucketMetricsCon\ufb01guration with a CLI\n\u2022Use DeleteBucketPolicy with an AWS SDK or CLI\n\u2022Use DeleteBucketReplication with a CLI\n\u2022Use DeleteBucketTagging with a CLI\n\u2022Use DeleteBucketWebsite with an AWS SDK or CLI\n\u2022Use DeleteObject with an AWS SDK or CLI\n\u2022Use DeleteObjectTagging with a CLI\n\u2022Use DeleteObjects with an AWS SDK or CLI\n\u2022Use DeletePublicAccessBlock with a CLI\n\u2022Use GetBucketAccelerateCon\ufb01guration with a CLI\n\u2022Use GetBucketAcl with an AWS SDK or CLI\n\u2022Use GetBucketAnalyticsCon\ufb01guration with a CLI\n\u2022Use GetBucketCors with an AWS SDK or CLI\n\u2022Use GetBucketEncryption with an AWS SDK or CLI\n\u2022Use GetBucketInventoryCon\ufb01guration with a CLI\nBasics API Version 2006-03-01 1813Amazon Simple Storage Service API Reference\n\u2022Use GetBucketLifecycleCon\ufb01guration with an AWS SDK or CLI\n\u2022Use GetBucketLocation with an AWS SDK or CLI\n\u2022Use GetBucketLogging with a CLI\n\u2022Use GetBucketMetricsCon\ufb01guration with a CLI\n\u2022Use GetBucketNoti\ufb01cation with a CLI\n\u2022Use GetBucketPolicy with an AWS SDK or CLI\n\u2022Use GetBucketPolicyStatus with a CLI\n\u2022Use GetBucketReplication with a CLI\n\u2022Use GetBucketRequestPayment with a CLI\n\u2022Use GetBucketTagging with a CLI\n\u2022Use GetBucketVersioning with a CLI\n\u2022Use GetBucketWebsite with an AWS SDK or CLI\n\u2022Use GetObject with an AWS SDK or CLI\n\u2022Use GetObjectAcl with an AWS SDK or CLI\n\u2022Use GetObjectAttributes with an AWS SDK or CLI\n\u2022Use GetObjectLegalHold with an AWS SDK or CLI\n\u2022Use GetObjectLockCon\ufb01guration with an AWS SDK or CLI\n\u2022Use GetObjectRetention with an AWS SDK or CLI\n\u2022Use GetObjectTagging with a CLI\n\u2022Use GetPublicAccessBlock with a CLI\n\u2022Use HeadBucket with an AWS SDK or CLI\n\u2022Use HeadObject with an AWS SDK or CLI\n\u2022Use ListBucketAnalyticsCon\ufb01gurations with a CLI\n\u2022Use ListBucketInventoryCon\ufb01gurations with a CLI\n\u2022Use ListBuckets with an AWS SDK or CLI\n\u2022Use ListMultipartUploads with an AWS SDK or CLI\n\u2022Use ListObjectVersions with an AWS SDK or CLI\n\u2022Use ListObjects with a CLI\n\u2022Use ListObjectsV2 with an AWS SDK or CLI\nBasics API Version 2006-03-01 1814Amazon Simple Storage Service API Reference\n\u2022Use PutBucketAccelerateCon\ufb01guration with an AWS SDK or CLI\n\u2022Use PutBucketAcl with an AWS SDK or CLI\n\u2022Use PutBucketCors with an AWS SDK or CLI\n\u2022Use PutBucketEncryption with an AWS SDK or CLI\n\u2022Use PutBucketLifecycleCon\ufb01guration with an AWS SDK or CLI\n\u2022Use PutBucketLogging with an AWS SDK or CLI\n\u2022Use PutBucketNoti\ufb01cation with a CLI\n\u2022Use PutBucketNoti\ufb01cationCon\ufb01guration with an AWS SDK or CLI\n\u2022Use PutBucketPolicy with an AWS SDK or CLI\n\u2022Use PutBucketReplication with a CLI\n\u2022Use PutBucketRequestPayment with a CLI\n\u2022Use PutBucketTagging with a CLI\n\u2022Use PutBucketVersioning with a CLI\n\u2022Use PutBucketWebsite with an AWS SDK or CLI\n\u2022Use PutObject with an AWS SDK or CLI\n\u2022Use PutObjectAcl with an AWS SDK or CLI\n\u2022Use PutObjectLegalHold with an AWS SDK or CLI\n\u2022Use PutObjectLockCon\ufb01guration with an AWS SDK or CLI\n\u2022Use PutObjectRetention with an AWS SDK or CLI\n\u2022Use RestoreObject with an AWS SDK or CLI\n\u2022Use SelectObjectContent with an AWS SDK or CLI\n\u2022Use UploadPart with an AWS SDK or CLI\nUse AbortMultipartUpload  with an AWS SDK or CLI\nThe following code examples show how to use AbortMultipartUpload .\nAction examples are code excerpts from larger programs and must be run in context.", "You can see \nthis action in context in the following code examples:\n\u2022Delete incomplete multipart uploads\nBasics API Version 2006-03-01 1815Amazon Simple Storage Service API Reference\n\u2022Work with Amazon S3 object integrity\nC++\nSDK for C++\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n//!", "Abort a multipart upload to an S3 bucket.\n/*! \n    \\param bucket: The name of the S3 bucket where the object will be uploaded. \n    \\param key: The unique identifier (key) for the object within the S3 bucket.", "\n    \\param uploadID: An upload ID string.", "\n    \\param client: The S3 client instance used to perform the upload operation. \n    \\return bool: Function succeeded.\n*/\nbool AwsDoc::S3::abortMultipartUpload(const Aws::String &bucket, \n                                      const Aws::String &key, \n                                      const Aws::String &uploadID, \n                                      const Aws::S3::S3Client &client) { \n    Aws::S3::Model::AbortMultipartUploadRequest request; \n    request.SetBucket(bucket); \n    request.SetKey(key); \n    request.SetUploadId(uploadID); \n    Aws::S3::Model::AbortMultipartUploadOutcome outcome = \n            client.AbortMultipartUpload(request); \n    if (outcome.IsSuccess()) { \n        std::cout << \"Multipart upload aborted.\" << std::endl; \n    } else { \n        std::cerr << \"Error aborting multipart upload: \" << \n outcome.GetError().GetMessage() << std::endl; \n    } \n    return outcome.IsSuccess();\n}\nBasics API Version 2006-03-01 1816Amazon Simple Storage Service API Reference\n\u2022For API details, see AbortMultipartUpload in AWS SDK for C++ API Reference.\nCLI\nAWS CLI\nTo abort the speci\ufb01ed multipart upload\nThe following abort-multipart-upload  command aborts a multipart upload for the key\nmultipart/01  in the bucket my-bucket .\naws s3api abort-multipart-upload \\ \n    --bucket my-bucket  \\ \n    --key multipart/01  \\ \n    --upload-\nid dfRtDYU0WWCCcH43C3WFbkRONycyCpTJJvxu2i5GYkZljF.Yxwh6XG7WfS2vC4to6HiV6Yjlx.cph0gtNBtJ8P3URCSbB7rjxI5iEwVDmgaXZOGgkk5nVTW16HOQ5l0R\nThe upload ID required by this command is output by create-multipart-upload  and can \nalso be retrieved with list-multipart-uploads .\n\u2022For API details, see AbortMultipartUpload in AWS CLI Command Reference.\nPowerShell\nTools for PowerShell\nExample 1: This command aborts multipart uploads created earlier than 5 days ago.\nRemove-S3MultipartUpload -BucketName amzn-s3-demo-bucket -DaysBefore 5\nExample 2: This command aborts multipart uploads created earlier than January 2nd, \n2014.\nRemove-S3MultipartUpload -BucketName amzn-s3-demo-bucket -InitiatedDate \n \"Thursday, January 02, 2014\"\nExample 3: This command aborts multipart uploads created earlier than January 2nd, \n2014, 10:45:37.\nBasics API Version 2006-03-01 1817Amazon Simple Storage Service API Reference\nRemove-S3MultipartUpload -BucketName amzn-s3-demo-bucket -InitiatedDate \n \"2014/01/02 10:45:37\"\n\u2022For API details, see AbortMultipartUpload in AWS Tools for PowerShell Cmdlet Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nUse AbortMultipartUploads  with an AWS SDK\nThe following code example shows how to use AbortMultipartUploads .\n.NET\nAWS SDK for .NET\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n    using System; \n    using System.Threading.Tasks; \n    using Amazon.S3; \n    using Amazon.S3.Transfer; \n    /// <summary> \n    /// This example shows how to use the Amazon Simple Storage Service \n    /// (Amazon S3) to stop a multi-part upload process using the Amazon S3 \n    /// TransferUtility. \n    /// </summary> \n    public class AbortMPU \n    { \n        public static async Task Main() \n        { \n            string bucketName = \"amzn-s3-demo-bucket\"; \n            // If the AWS Region defined for your default user is different \nBasics API Version 2006-03-01 1818Amazon Simple Storage Service API Reference\n            // from the Region where your Amazon S3 bucket is located, \n            // pass the Region name to the S3 client object's constructor.", "\n            // For example: RegionEndpoint.USWest2.", "\n            IAmazonS3 client = new AmazonS3Client(); \n            await AbortMPUAsync(client, bucketName); \n        } \n        /// <summary> \n        /// Cancels the multi-part copy process. \n        /// </summary> \n        /// <param name=\"client\">The initialized client object used to create \n        /// the TransferUtility object.</param> \n        /// <param name=\"bucketName\">The name of the S3 bucket where the \n        /// multi-part copy operation is in progress.</param> \n        public static async Task AbortMPUAsync(IAmazonS3 client, string \n bucketName) \n        { \n            try \n            { \n                var transferUtility = new TransferUtility(client); \n                // Cancel all in-progress uploads initiated before the specified \n date. \n                await transferUtility.AbortMultipartUploadsAsync( \n                    bucketName, DateTime.Now.AddDays(-7)); \n            } \n            catch (AmazonS3Exception e) \n            { \n                Console.WriteLine($\"Error: {e.Message}\"); \n            } \n        } \n    }\n\u2022For API details, see AbortMultipartUploads in AWS SDK for .NET API Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nBasics API Version 2006-03-01 1819Amazon Simple Storage Service API Reference\nUse CompleteMultipartUpload  with an AWS SDK or CLI\nThe following code examples show how to use CompleteMultipartUpload .\nAction examples are code excerpts from larger programs and must be run in context.", "You can see \nthis action in context in the following code examples:\n\u2022Perform a multipart copy\n\u2022Perform a multipart upload\n\u2022Use checksums\n\u2022Work with Amazon S3 object integrity\nC++\nSDK for C++\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n//!", "Complete a multipart upload to an S3 bucket.\n/*! \n    \\param bucket: The name of the S3 bucket where the object will be uploaded. \n    \\param key: The unique identifier (key) for the object within the S3 bucket.", "\n    \\param uploadID: An upload ID string.", "\n    \\param parts: A vector of CompleteParts.", "\n    \\param client: The S3 client instance used to perform the upload operation. \n    \\return CompleteMultipartUploadOutcome: The request outcome.\n*/\nAws::S3::Model::CompleteMultipartUploadOutcome \n AwsDoc::S3::completeMultipartUpload(const Aws::String &bucket, \n                                                                                  \n  const Aws::String &key, \n                                                                                  \n  const Aws::String &uploadID, \n                                                                                  \n  const Aws::Vector<Aws::S3::Model::CompletedPart> &parts, \nBasics API Version 2006-03-01 1820Amazon Simple Storage Service API Reference\n                                                                                 \n  const Aws::S3::S3Client &client) { \n    Aws::S3::Model::CompletedMultipartUpload completedMultipartUpload; \n    completedMultipartUpload.SetParts(parts); \n    Aws::S3::Model::CompleteMultipartUploadRequest request; \n    request.SetBucket(bucket); \n    request.SetKey(key); \n    request.SetUploadId(uploadID); \n    request.SetMultipartUpload(completedMultipartUpload); \n    Aws::S3::Model::CompleteMultipartUploadOutcome outcome = \n            client.CompleteMultipartUpload(request); \n    if (!outcome.IsSuccess()) { \n        std::cerr << \"Error completing multipart upload: \" << \n outcome.GetError().GetMessage() << std::endl; \n    } \n    return outcome;\n}\n\u2022For API details, see CompleteMultipartUpload in AWS SDK for C++ API Reference.\nCLI\nAWS CLI\nThe following command completes a multipart upload for the key multipart/01  in the \nbucket my-bucket :\naws s3api complete-multipart-upload --multipart-upload file://\nmpustruct  --bucket my-bucket  --key ' multipart/01 ' --upload-\nid dfRtDYU0WWCCcH43C3WFbkRONycyCpTJJvxu2i5GYkZljF.Yxwh6XG7WfS2vC4to6HiV6Yjlx.cph0gtNBtJ8P3URCSbB7rjxI5iEwVDmgaXZOGgkk5nVTW16HOQ5l0R\nThe upload ID required by this command is output by create-multipart-upload  and can \nalso be retrieved with list-multipart-uploads .\nThe multipart upload option in the above command takes a JSON structure that describes \nthe parts of the multipart upload that should be reassembled into the complete \ufb01le. In \nthis example, the file:// pre\ufb01x is used to load the JSON structure from a \ufb01le in the local \nfolder named mpustruct .\nBasics API Version 2006-03-01 1821Amazon Simple Storage Service API Reference\nmpustruct:\n{ \n  \"Parts\": [ \n    { \n      \"ETag\": \"e868e0f4719e394144ef36531ee6824c\", \n      \"PartNumber\": 1 \n    }, \n    { \n      \"ETag\": \"6bb2b12753d66fe86da4998aa33fffb0\", \n      \"PartNumber\": 2 \n    }, \n    { \n      \"ETag\": \"d0a0112e841abec9c9ec83406f0159c8\", \n      \"PartNumber\": 3 \n    } \n  ]\n}\nThe ETag value for each part is upload is output each time you upload a part using the\nupload-part  command and can also be retrieved by calling list-parts  or calculated by \ntaking the MD5 checksum of each part.\nOutput:\n{ \n    \"ETag\": \"\\\"3944a9f7a4faab7f78788ff6210f63f0-3\\\"\", \n    \"Bucket\": \"my-bucket\", \n    \"Location\": \"https://my-bucket.s3.amazonaws.com/multipart%2F01\", \n    \"Key\": \"multipart/01\"\n}\n\u2022For API details, see CompleteMultipartUpload in AWS CLI Command Reference.\nBasics API Version 2006-03-01 1822Amazon Simple Storage Service API Reference\nRust\nSDK for Rust\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n    // upload_parts: Vec<aws_sdk_s3::types::CompletedPart> \n    let completed_multipart_upload: CompletedMultipartUpload = \n CompletedMultipartUpload::builder() \n        .set_parts(Some(upload_parts)) \n        .build(); \n    let _complete_multipart_upload_res = client \n        .complete_multipart_upload() \n        .bucket(&bucket_name) \n        .key(&key) \n        .multipart_upload(completed_multipart_upload) \n        .upload_id(upload_id) \n        .send() \n        .await?;\n    // Create a multipart upload.", "Use UploadPart and CompleteMultipartUpload to \n    // upload the file.", "\n    let multipart_upload_res: CreateMultipartUploadOutput = client \n        .create_multipart_upload() \n        .bucket(&bucket_name) \n        .key(&key) \n        .send() \n        .await?; \n    let upload_id = multipart_upload_res.upload_id().ok_or(S3ExampleError::new( \n        \"Missing upload_id after CreateMultipartUpload\", \n    ))?;\n    let mut upload_parts: Vec<aws_sdk_s3::types::CompletedPart> = Vec::new(); \nBasics API Version 2006-03-01 1823Amazon Simple Storage Service API Reference\n    for chunk_index in 0..chunk_count { \n        let this_chunk = if chunk_count - 1 == chunk_index { \n            size_of_last_chunk \n        } else { \n            CHUNK_SIZE \n        }; \n        let stream = ByteStream::read_from() \n            .path(path) \n            .offset(chunk_index * CHUNK_SIZE) \n            .length(Length::Exact(this_chunk)) \n            .build() \n            .await \n            .unwrap(); \n        // Chunk index needs to start at 0, but part numbers start at 1. \n        let part_number = (chunk_index as i32) + 1; \n        let upload_part_res = client \n            .upload_part() \n            .key(&key) \n            .bucket(&bucket_name) \n            .upload_id(upload_id) \n            .body(stream) \n            .part_number(part_number) \n            .send() \n            .await?; \n        upload_parts.push( \n            CompletedPart::builder() \n                .e_tag(upload_part_res.e_tag.unwrap_or_default()) \n                .part_number(part_number) \n                .build(), \n        ); \n    }\n\u2022For API details, see CompleteMultipartUpload in AWS SDK for Rust API reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs.", "This topic also includes information about getting started and details \nabout previous SDK versions.\nBasics API Version 2006-03-01 1824Amazon Simple Storage Service API Reference\nUse CopyObject  with an AWS SDK or CLI\nThe following code examples show how to use CopyObject .\nAction examples are code excerpts from larger programs and must be run in context.", "You can see \nthis action in context in the following code examples:\n\u2022Learn the basics\n\u2022Get started with encryption\n.NET\nAWS SDK for .NET\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n    using System; \n    using System.Threading.Tasks; \n    using Amazon.S3; \n    using Amazon.S3.Model; \n    public class CopyObject \n    { \n        public static async Task Main() \n        { \n            // Specify the AWS Region where your buckets are located if it is \n            // different from the AWS Region of the default user. \n            IAmazonS3 s3Client = new AmazonS3Client(); \n            // Remember to change these values to refer to your Amazon S3 \n objects. \n            string sourceBucketName = \"amzn-s3-demo-bucket1\"; \n            string destinationBucketName = \"amzn-s3-demo-bucket2\"; \n            string sourceObjectKey = \"testfile.txt\"; \n            string destinationObjectKey = \"testfilecopy.txt\"; \nBasics API Version 2006-03-01 1825Amazon Simple Storage Service API Reference\n            Console.WriteLine($\"Copying {sourceObjectKey} from {sourceBucketName} \n to \"); \n            Console.WriteLine($\"{destinationBucketName} as \n {destinationObjectKey}\"); \n            var response = await CopyingObjectAsync( \n                s3Client, \n                sourceObjectKey, \n                destinationObjectKey, \n                sourceBucketName, \n                destinationBucketName); \n            if (response.HttpStatusCode == System.Net.HttpStatusCode.OK) \n            { \n                Console.WriteLine(\"\\nCopy complete.\"); \n            } \n        } \n        /// <summary> \n        /// This method calls the AWS SDK for .NET to copy an \n        /// object from one Amazon S3 bucket to another. \n        /// </summary> \n        /// <param name=\"client\">The Amazon S3 client object.</param> \n        /// <param name=\"sourceKey\">The name of the object to be copied.</param> \n        /// <param name=\"destinationKey\">The name under which to save the copy.</\nparam> \n        /// <param name=\"sourceBucketName\">The name of the Amazon S3 bucket \n        /// where the file is located now.</param> \n        /// <param name=\"destinationBucketName\">The name of the Amazon S3 \n        /// bucket where the copy should be saved.</param> \n        /// <returns>Returns a CopyObjectResponse object with the results from \n        /// the async call.</returns> \n        public static async Task<CopyObjectResponse> CopyingObjectAsync( \n            IAmazonS3 client, \n            string sourceKey, \n            string destinationKey, \n            string sourceBucketName, \n            string destinationBucketName) \n        { \n            var response = new CopyObjectResponse(); \n            try \n            { \n                var request = new CopyObjectRequest \n                { \nBasics API Version 2006-03-01 1826Amazon Simple Storage Service API Reference\n                    SourceBucket = sourceBucketName, \n                    SourceKey = sourceKey, \n                    DestinationBucket = destinationBucketName, \n                    DestinationKey = destinationKey, \n                }; \n                response = await client.CopyObjectAsync(request); \n            } \n            catch (AmazonS3Exception ex) \n            { \n                Console.WriteLine($\"Error copying object: '{ex.Message}'\"); \n            } \n            return response; \n        } \n    }\n\u2022For API details, see CopyObject in AWS SDK for .NET API Reference.\nBash\nAWS CLI with Bash script\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n###############################################################################\n# function errecho\n#\n# This function outputs everything sent to it to STDERR (standard error output).\n###############################################################################\nfunction errecho() { \n  printf \"%s\\n\" \"$*\" 1>&2\n}\n###############################################################################\n# function copy_item_in_bucket\n#\nBasics API Version 2006-03-01 1827Amazon Simple Storage Service API Reference\n# This function creates a copy of the specified file in the same bucket.\n#\n# Parameters:\n#       $1 - The name of the bucket to copy the file from and to.\n#       $2 - The key of the source file to copy.\n#       $3 - The key of the destination file.\n#\n# Returns:\n#       0 - If successful.\n#       1 - If it fails.\n###############################################################################\nfunction copy_item_in_bucket() { \n  local bucket_name=$1 \n  local source_key=$2 \n  local destination_key=$3 \n  local response \n  response=$(aws s3api copy-object \\ \n    --bucket \"$bucket_name\" \\ \n    --copy-source \"$bucket_name/$source_key\" \\ \n    --key \"$destination_key\") \n  # shellcheck disable=SC2181 \n  if [[ $?", "-ne 0 ]]; then \n    errecho \"ERROR:  AWS reports s3api copy-object operation failed.\\n$response\" \n    return 1 \n  fi\n}\n\u2022For API details, see CopyObject in AWS CLI Command Reference.\nC++\nSDK for C++\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nBasics API Version 2006-03-01 1828Amazon Simple Storage Service API Reference\nbool AwsDoc::S3::copyObject(const Aws::String &objectKey, const Aws::String \n &fromBucket, const Aws::String &toBucket, \n                            const Aws::S3::S3ClientConfiguration &clientConfig) { \n    Aws::S3::S3Client client(clientConfig); \n    Aws::S3::Model::CopyObjectRequest request; \n    request.WithCopySource(fromBucket + \"/\" + objectKey) \n            .WithKey(objectKey) \n            .WithBucket(toBucket); \n    Aws::S3::Model::CopyObjectOutcome outcome = client.CopyObject(request); \n    if (!outcome.IsSuccess()) { \n        const Aws::S3::S3Error &err = outcome.GetError(); \n        std::cerr << \"Error: copyObject: \" << \n                  err.GetExceptionName() << \": \" << err.GetMessage() << \n std::endl; \n    } else { \n        std::cout << \"Successfully copied \" << objectKey << \" from \" << \n fromBucket << \n                  \" to \" << toBucket << \".\" << std::endl; \n    } \n    return outcome.IsSuccess();\n}\n\u2022For API details, see CopyObject in AWS SDK for C++ API Reference.\nCLI\nAWS CLI\nThe following command copies an object from bucket-1  to bucket-2 :\naws s3api copy-object --copy-source bucket-1/test.txt  --key test.txt  --\nbucket bucket-2\nOutput:\n{ \n    \"CopyObjectResult\": { \nBasics API Version 2006-03-01 1829Amazon Simple Storage Service API Reference\n        \"LastModified\": \"2015-11-10T01:07:25.000Z\", \n        \"ETag\": \"\\\"589c8b79c230a6ecd5a7e1d040a9a030\\\"\" \n    }, \n    \"VersionId\": \"YdnYvTCVDqRRFA.NFJjy36p0hxifMlkA\"\n}\n\u2022For API details, see CopyObject in AWS CLI Command Reference.\nGo\nSDK for Go V2\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n// BucketBasics encapsulates the Amazon Simple Storage Service (Amazon S3) \n actions\n// used in the examples.\n// It contains S3Client, an Amazon S3 service client that is used to perform \n bucket\n// and object actions.\ntype BucketBasics struct { \n S3Client *s3.Client\n}\n// CopyToBucket copies an object in a bucket to another bucket.\nfunc (basics BucketBasics) CopyToBucket(ctx context.Context, sourceBucket string, \n destinationBucket string, objectKey string) error { \n _, err := basics.S3Client.CopyObject(ctx, &s3.CopyObjectInput{ \n  Bucket:     aws.String(destinationBucket), \n  CopySource: aws.String(fmt.Sprintf(\"%v/%v\", sourceBucket, objectKey)), \n  Key:        aws.String(objectKey), \n }) \n if err != nil { \n  log.Printf(\"Couldn't copy object from %v:%v to %v:%v. Here's why: %v\\n\", \n   sourceBucket, objectKey, destinationBucket, objectKey, err) \nBasics API Version 2006-03-01 1830Amazon Simple Storage Service API Reference\n } \n return err\n}\n\u2022For API details, see CopyObject in AWS SDK for Go API Reference.\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nCopy an object using an S3Client .\n    /** \n     * Asynchronously copies an object from one S3 bucket to another. \n     * \n     * @param fromBucket the name of the source S3 bucket \n     * @param objectKey  the key (name) of the object to be copied \n     * @param toBucket   the name of the destination S3 bucket \n     * @return a {@link CompletableFuture} that completes with the copy result as \n a {@link String} \n     * @throws RuntimeException if the URL could not be encoded or an S3 \n exception occurred during the copy \n     */ \n    public CompletableFuture<String> copyBucketObjectAsync(String fromBucket, \n String objectKey, String toBucket) { \n        CopyObjectRequest copyReq = CopyObjectRequest.builder() \n            .sourceBucket(fromBucket) \n            .sourceKey(objectKey) \n            .destinationBucket(toBucket) \n            .destinationKey(objectKey) \n            .build(); \nBasics API Version 2006-03-01 1831Amazon Simple Storage Service API Reference\n        CompletableFuture<CopyObjectResponse> response = \n getAsyncClient().copyObject(copyReq); \n        response.whenComplete((copyRes, ex) -> { \n            if (copyRes != null) { \n                logger.info(\"The \" + objectKey + \" was copied to \" + toBucket); \n            } else { \n                throw new RuntimeException(\"An S3 exception occurred during \n copy\", ex); \n            } \n        }); \n        return response.thenApply(CopyObjectResponse::copyObjectResult) \n            .thenApply(Object::toString); \n    }\nUse an S3TransferManager to copy an object from one bucket to another. View the complete \n\ufb01le and test.\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\nimport software.amazon.awssdk.core.sync.RequestBody;\nimport software.amazon.awssdk.services.s3.model.CopyObjectRequest;\nimport software.amazon.awssdk.transfer.s3.S3TransferManager;\nimport software.amazon.awssdk.transfer.s3.model.CompletedCopy;\nimport software.amazon.awssdk.transfer.s3.model.Copy;\nimport software.amazon.awssdk.transfer.s3.model.CopyRequest;\nimport java.util.UUID; \n    public String copyObject(S3TransferManager transferManager, String \n bucketName, \n            String key, String destinationBucket, String destinationKey) { \n        CopyObjectRequest copyObjectRequest = CopyObjectRequest.builder() \n                .sourceBucket(bucketName) \n                .sourceKey(key) \n                .destinationBucket(destinationBucket) \n                .destinationKey(destinationKey) \n                .build(); \n        CopyRequest copyRequest = CopyRequest.builder() \n                .copyObjectRequest(copyObjectRequest) \n                .build(); \nBasics API Version 2006-03-01 1832Amazon Simple Storage Service API Reference\n        Copy copy = transferManager.copy(copyRequest); \n        CompletedCopy completedCopy = copy.completionFuture().join(); \n        return completedCopy.response().copyObjectResult().eTag(); \n    }\n\u2022For API details, see CopyObject in AWS SDK for Java 2.x API Reference.\nJavaScript\nSDK for JavaScript (v3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nCopy the object.\nimport { \n  S3Client, \n  CopyObjectCommand, \n  ObjectNotInActiveTierError, \n  waitUntilObjectExists,\n} from \"@aws-sdk/client-s3\";\n/** \n * Copy an S3 object from one bucket to another. \n * \n * @param {{ \n *   sourceBucket: string, \n *   sourceKey: string, \n *   destinationBucket: string, \n *   destinationKey: string }} config \n */\nexport const main = async ({ \n  sourceBucket, \n  sourceKey, \n  destinationBucket, \nBasics API Version 2006-03-01 1833Amazon Simple Storage Service API Reference\n  destinationKey,\n}) => { \n  const client = new S3Client({}); \n  try { \n    await client.send( \n      new CopyObjectCommand({ \n        CopySource: `${sourceBucket}/${sourceKey}`, \n        Bucket: destinationBucket, \n        Key: destinationKey, \n      }), \n    ); \n    await waitUntilObjectExists( \n      { client }, \n      { Bucket: destinationBucket, Key: destinationKey }, \n    ); \n    console.log( \n      `Successfully copied ${sourceBucket}/${sourceKey} to ${destinationBucket}/\n${destinationKey}`, \n    ); \n  } catch (caught) { \n    if (caught instanceof ObjectNotInActiveTierError) { \n      console.error( \n        `Could not copy ${sourceKey} from ${sourceBucket}.", "Object is not in the \n active tier.`, \n      ); \n    } else { \n      throw caught; \n    } \n  }\n};\n\u2022For API details, see CopyObject in AWS SDK for JavaScript API Reference.\nBasics API Version 2006-03-01 1834Amazon Simple Storage Service API Reference\nKotlin\nSDK for Kotlin\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nsuspend fun copyBucketObject( \n    fromBucket: String, \n    objectKey: String, \n    toBucket: String,\n) { \n    var encodedUrl = \"\" \n    try { \n        encodedUrl = URLEncoder.encode(\"$fromBucket/$objectKey\", \n StandardCharsets.UTF_8.toString()) \n    } catch (e: UnsupportedEncodingException) { \n        println(\"URL could not be encoded: \" + e.message) \n    } \n    val request = \n        CopyObjectRequest { \n            copySource = encodedUrl \n            bucket = toBucket \n            key = objectKey \n        } \n    S3Client { region = \"us-east-1\" }.use { s3 -> \n        s3.copyObject(request) \n    }\n}\n\u2022For API details, see CopyObject in AWS SDK for Kotlin API reference.\nBasics API Version 2006-03-01 1835Amazon Simple Storage Service API Reference\nPHP\nSDK for PHP\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nSimple copy of an object.\n        $s3client = new Aws\\S3\\S3Client(['region' => 'us-west-2']); \n        try { \n            $folder = \"copied-folder\"; \n            $this->s3client->copyObject([ \n                'Bucket' => $this->bucketName, \n                'CopySource' => \"$this->bucketName/$fileName\", \n                'Key' => \"$folder/$fileName-copy\", \n            ]); \n            echo \"Copied $fileName to $folder/$fileName-copy.\\n\"; \n        } catch (Exception $exception) { \n            echo \"Failed to copy $fileName with error: \" . $exception-\n>getMessage(); \n            exit(\"Please fix error with object copying before continuing.\"); \n        }\n\u2022For API details, see CopyObject in AWS SDK for PHP API Reference.\nPowerShell\nTools for PowerShell\nExample 1: This command copies the object \"sample.txt\" from bucket \"test-\ufb01les\" to the \nsame bucket but with a new key of \"sample-copy.txt\".\nCopy-S3Object -BucketName amzn-s3-demo-bucket -Key sample.txt -DestinationKey \n sample-copy.txt\nBasics API Version 2006-03-01 1836Amazon Simple Storage Service API Reference\nExample 2: This command copies the object \"sample.txt\" from bucket \"test-\ufb01les\" to the \nbucket \"backup-\ufb01les\" with a key of \"sample-copy.txt\".\nCopy-S3Object -BucketName amzn-s3-demo-source-bucket -Key sample.txt -\nDestinationKey sample-copy.txt -DestinationBucket amzn-s3-demo-destination-bucket\nExample 3: This command downloads the object \"sample.txt\" from bucket \"test-\ufb01les\" to \na local \ufb01le with name \"local-sample.txt\".\nCopy-S3Object -BucketName amzn-s3-demo-bucket -Key sample.txt -LocalFile local-\nsample.txt\nExample 4: Downloads the single object to the speci\ufb01ed \ufb01le. The downloaded \ufb01le will be \nfound at c:\\downloads\\data\\archive.zip\nCopy-S3Object -BucketName amzn-s3-demo-bucket -Key data/archive.zip -LocalFolder \n c:\\downloads\nExample 5: Downloads all objects that match the speci\ufb01ed key pre\ufb01x to the local folder. \nThe relative key hierarchy will be preserved as subfolders in the overall download \nlocation.\nCopy-S3Object -BucketName amzn-s3-demo-bucket -KeyPrefix data -LocalFolder c:\n\\downloads\n\u2022For API details, see CopyObject in AWS Tools for PowerShell Cmdlet Reference.\nPython\nSDK for Python (Boto3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nclass ObjectWrapper: \n    \"\"\"Encapsulates S3 object actions.\"\"\" \nBasics API Version 2006-03-01 1837Amazon Simple Storage Service API Reference\n    def __init__(self, s3_object): \n        \"\"\" \n        :param s3_object: A Boto3 Object resource.", "This is a high-level resource \n in Boto3 \n                          that wraps object actions in a class-like structure.", "\n        \"\"\" \n        self.object = s3_object \n        self.key = self.object.key \n    def copy(self, dest_object): \n        \"\"\" \n        Copies the object to another bucket.", "\n        :param dest_object: The destination object initialized with a bucket and \n key.", "\n                            This is a Boto3 Object resource.", "\n        \"\"\" \n        try: \n            dest_object.copy_from( \n                CopySource={\"Bucket\": self.object.bucket_name, \"Key\": \n self.object.key} \n            ) \n            dest_object.wait_until_exists() \n            logger.info( \n                \"Copied object from %s:%s to %s:%s.\", \n                self.object.bucket_name, \n                self.object.key, \n                dest_object.bucket_name, \n                dest_object.key, \n            ) \n        except ClientError: \n            logger.exception( \n                \"Couldn't copy object from %s/%s to %s/%s.\", \n                self.object.bucket_name, \n                self.object.key, \n                dest_object.bucket_name, \n                dest_object.key, \n            ) \n            raise\nBasics API Version 2006-03-01 1838Amazon Simple Storage Service API Reference\n\u2022For API details, see CopyObject in AWS SDK for Python (Boto3) API Reference.\nRuby\nSDK for Ruby\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nCopy an object.\nrequire 'aws-sdk-s3'\n# Wraps Amazon S3 object actions.\nclass ObjectCopyWrapper \n  attr_reader :source_object \n  # @param source_object [Aws::S3::Object] An existing Amazon S3 object.", "This is \n used as the source object for \n  #                                        copy actions.", "\n  def initialize(source_object) \n    @source_object = source_object \n  end \n  # Copy the source object to the specified target bucket and rename it with the \n target key.", "\n  # \n  # @param target_bucket [Aws::S3::Bucket] An existing Amazon S3 bucket where the \n object is copied.", "\n  # @param target_object_key [String] The key to give the copy of the object.", "\n  # @return [Aws::S3::Object, nil] The copied object when successful; otherwise, \n nil.", "\n  def copy_object(target_bucket, target_object_key) \n    @source_object.copy_to(bucket: target_bucket.name, key: target_object_key) \n    target_bucket.object(target_object_key) \n  rescue Aws::Errors::ServiceError => e \n    puts \"Couldn't copy #{@source_object.key} to #{target_object_key}. Here's \n why: #{e.message}\" \n  end\nBasics API Version 2006-03-01 1839Amazon Simple Storage Service API Reference\nend\n# Example usage:\ndef run_demo\n<<<<<<< HEAD \n  source_bucket_name = \"amzn-s3-demo-bucket1\" \n  source_key = \"my-source-file.txt\" \n  target_bucket_name = \"amzn-s3-demo-bucket2\" \n  target_key = \"my-target-file.txt\"\n======= \n  source_bucket_name = 'doc-example-bucket1' \n  source_key = 'my-source-file.txt' \n  target_bucket_name = 'doc-example-bucket2' \n  target_key = 'my-target-file.txt'\n>>>>>>> 999c6133e (fixes) \n  source_bucket = Aws::S3::Bucket.new(source_bucket_name) \n  wrapper = ObjectCopyWrapper.new(source_bucket.object(source_key)) \n  target_bucket = Aws::S3::Bucket.new(target_bucket_name) \n  target_object = wrapper.copy_object(target_bucket, target_key) \n  return unless target_object \n  puts \"Copied #{source_key} from #{source_bucket_name} to \n #{target_object.bucket_name}:#{target_object.key}.\"\nend\nrun_demo if $PROGRAM_NAME == __FILE__\nCopy an object and add server-side encryption to the destination object.\nrequire 'aws-sdk-s3'\n# Wraps Amazon S3 object actions.\nclass ObjectCopyEncryptWrapper \n  attr_reader :source_object \n  # @param source_object [Aws::S3::Object] An existing Amazon S3 object.", "This is \n used as the source object for \n  #                                        copy actions.", "\n  def initialize(source_object) \n    @source_object = source_object \n  end \nBasics API Version 2006-03-01 1840Amazon Simple Storage Service API Reference\n  # Copy the source object to the specified target bucket, rename it with the \n target key, and encrypt it.", "\n  # \n  # @param target_bucket [Aws::S3::Bucket] An existing Amazon S3 bucket where the \n object is copied.", "\n  # @param target_object_key [String] The key to give the copy of the object.", "\n  # @return [Aws::S3::Object, nil] The copied object when successful; otherwise, \n nil.", "\n  def copy_object(target_bucket, target_object_key, encryption) \n    @source_object.copy_to(bucket: target_bucket.name, key: target_object_key, \n server_side_encryption: encryption) \n    target_bucket.object(target_object_key) \n  rescue Aws::Errors::ServiceError => e \n    puts \"Couldn't copy #{@source_object.key} to #{target_object_key}. Here's \n why: #{e.message}\" \n  end\nend\n# Example usage:\ndef run_demo\n<<<<<<< HEAD \n  source_bucket_name = \"amzn-s3-demo-bucket1\" \n  source_key = \"my-source-file.txt\" \n  target_bucket_name = \"amzn-s3-demo-bucket2\" \n  target_key = \"my-target-file.txt\" \n  target_encryption = \"AES256\"\n======= \n  source_bucket_name = 'doc-example-bucket1' \n  source_key = 'my-source-file.txt' \n  target_bucket_name = 'doc-example-bucket2' \n  target_key = 'my-target-file.txt' \n  target_encryption = 'AES256'\n>>>>>>> 999c6133e (fixes) \n  source_bucket = Aws::S3::Bucket.new(source_bucket_name) \n  wrapper = ObjectCopyEncryptWrapper.new(source_bucket.object(source_key)) \n  target_bucket = Aws::S3::Bucket.new(target_bucket_name) \n  target_object = wrapper.copy_object(target_bucket, target_key, \n target_encryption) \n  return unless target_object \n  puts \"Copied #{source_key} from #{source_bucket_name} to \n #{target_object.bucket_name}:#{target_object.key} and \"\\ \nBasics API Version 2006-03-01 1841Amazon Simple Storage Service API Reference\n       \"encrypted the target with #{target_object.server_side_encryption} \n encryption.\"\nend\nrun_demo if $PROGRAM_NAME == __FILE__\n\u2022For API details, see CopyObject in AWS SDK for Ruby API Reference.\nRust\nSDK for Rust\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n/// Copy an object from one bucket to another.\npub async fn copy_object( \n    client: &aws_sdk_s3::Client, \n    source_bucket: &str, \n    destination_bucket: &str, \n    source_object: &str, \n    destination_object: &str,\n) -> Result<(), S3ExampleError> { \n    let source_key = format!(\"{source_bucket}/{source_object}\"); \n    let response = client \n        .copy_object() \n        .copy_source(&source_key) \n        .bucket(destination_bucket) \n        .key(destination_object) \n        .send() \n        .await?; \n    println!( \n        \"Copied from {source_key} to {destination_bucket}/{destination_object} \n with etag {}\", \n        response \n            .copy_object_result \nBasics API Version 2006-03-01 1842Amazon Simple Storage Service API Reference\n            .unwrap_or_else(|| \n aws_sdk_s3::types::CopyObjectResult::builder().build()) \n            .e_tag() \n            .unwrap_or(\"missing\") \n    ); \n    Ok(())\n}\n\u2022For API details, see CopyObject in AWS SDK for Rust API reference.\nSAP ABAP\nSDK for SAP ABAP\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n    TRY.", "\n        lo_s3->copyobject( \n          iv_bucket = iv_dest_bucket \n          iv_key = iv_dest_object \n          iv_copysource = |{ iv_src_bucket }/{ iv_src_object }| \n        ).", "\n        MESSAGE 'Object copied to another bucket.' TYPE 'I'.", "\n      CATCH /aws1/cx_s3_nosuchbucket.", "\n        MESSAGE 'Bucket does not exist.' TYPE 'E'.", "\n      CATCH /aws1/cx_s3_nosuchkey.", "\n        MESSAGE 'Object key does not exist.' TYPE 'E'.", "\n    ENDTRY.\n\u2022For API details, see CopyObject in AWS SDK for SAP ABAP API reference.\nBasics API Version 2006-03-01 1843Amazon Simple Storage Service API Reference\nSwift\nSDK for Swift\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nimport AWSS3 \n    public func copyFile(from sourceBucket: String, name: String, to destBucket: \n String) async throws { \n        let srcUrl = (\"\\(sourceBucket)/\n\\(name)\").addingPercentEncoding(withAllowedCharacters: .urlPathAllowed) \n        let input = CopyObjectInput( \n            bucket: destBucket, \n            copySource: srcUrl, \n            key: name \n        ) \n        do { \n            _ = try await client.copyObject(input: input) \n        } \n        catch { \n            print(\"ERROR: \", dump(error, name: \"Copying an object.\")) \n            throw error \n        } \n    }\n\u2022For API details, see CopyObject in AWS SDK for Swift API reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nUse CreateBucket  with an AWS SDK or CLI\nThe following code examples show how to use CreateBucket .\nBasics API Version 2006-03-01 1844Amazon Simple Storage Service API Reference\nAction examples are code excerpts from larger programs and must be run in context.", "You can see \nthis action in context in the following code examples:\n\u2022Learn the basics\n\u2022Work with versioned objects\n.NET\nAWS SDK for .NET\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n        /// <summary> \n        /// Shows how to create a new Amazon S3 bucket. \n        /// </summary> \n        /// <param name=\"client\">An initialized Amazon S3 client object.</param> \n        /// <param name=\"bucketName\">The name of the bucket to create.</param> \n        /// <returns>A boolean value representing the success or failure of \n        /// the bucket creation process.</returns> \n        public static async Task<bool> CreateBucketAsync(IAmazonS3 client, string \n bucketName) \n        { \n            try \n            { \n                var request = new PutBucketRequest \n                { \n                    BucketName = bucketName, \n                    UseClientRegion = true, \n                }; \n                var response = await client.PutBucketAsync(request); \n                return response.HttpStatusCode == System.Net.HttpStatusCode.OK; \n            } \n            catch (AmazonS3Exception ex) \n            { \n                Console.WriteLine($\"Error creating bucket: '{ex.Message}'\"); \nBasics API Version 2006-03-01 1845Amazon Simple Storage Service API Reference\n                return false; \n            } \n        }\nCreate a bucket with object lock enabled.\n    /// <summary> \n    /// Create a new Amazon S3 bucket with object lock actions. \n    /// </summary> \n    /// <param name=\"bucketName\">The name of the bucket to create.</param> \n    /// <param name=\"enableObjectLock\">True to enable object lock on the \n bucket.</param> \n    /// <returns>True if successful.</returns> \n    public async Task<bool> CreateBucketWithObjectLock(string bucketName, bool \n enableObjectLock) \n    { \n        Console.WriteLine($\"\\tCreating bucket {bucketName} with object lock \n {enableObjectLock}.\"); \n        try \n        { \n            var request = new PutBucketRequest \n            { \n                BucketName = bucketName, \n                UseClientRegion = true, \n                ObjectLockEnabledForBucket = enableObjectLock, \n            }; \n            var response = await _amazonS3.PutBucketAsync(request); \n            return response.HttpStatusCode == System.Net.HttpStatusCode.OK; \n        } \n        catch (AmazonS3Exception ex) \n        { \n            Console.WriteLine($\"Error creating bucket: '{ex.Message}'\"); \n            return false; \n        } \n    }\n\u2022For API details, see CreateBucket in AWS SDK for .NET API Reference.\nBasics API Version 2006-03-01 1846Amazon Simple Storage Service API Reference\nBash\nAWS CLI with Bash script\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n###############################################################################\n# function iecho\n#\n# This function enables the script to display the specified text only if\n# the global variable $VERBOSE is set to true.\n###############################################################################\nfunction iecho() { \n  if [[ $VERBOSE == true ]]; then \n    echo \"$@\" \n  fi\n}\n###############################################################################\n# function errecho\n#\n# This function outputs everything sent to it to STDERR (standard error output).\n###############################################################################\nfunction errecho() { \n  printf \"%s\\n\" \"$*\" 1>&2\n}\n###############################################################################\n# function create-bucket\n#\n# This function creates the specified bucket in the specified AWS Region, unless\n# it already exists.\n#\n# Parameters:\n#       -b bucket_name  -- The name of the bucket to create.\n#       -r region_code  -- The code for an AWS Region in which to\n#                          create the bucket.\n#\nBasics API Version 2006-03-01 1847Amazon Simple Storage Service API Reference\n# Returns:\n#       The URL of the bucket that was created.\n#     And:\n#       0 - If successful.\n#       1 - If it fails.\n###############################################################################\nfunction create_bucket() { \n  local bucket_name region_code response \n  local option OPTARG # Required to use getopts command in a function.", "\n  # bashsupport disable=BP5008 \n  function usage() { \n    echo \"function create_bucket\" \n    echo \"Creates an Amazon S3 bucket. You must supply a bucket name:\" \n    echo \"  -b bucket_name    The name of the bucket. It must be globally \n unique.\" \n    echo \"  [-r region_code]    The code for an AWS Region in which the bucket is \n created.\" \n    echo \"\" \n  } \n  # Retrieve the calling parameters. \n  while getopts \"b:r:h\" option; do \n    case \"${option}\" in \n      b) bucket_name=\"${OPTARG}\" ;; \n      r) region_code=\"${OPTARG}\" ;; \n      h) \n        usage \n        return 0 \n        ;; \n      \\?) \n        echo \"Invalid parameter\" \n        usage \n        return 1 \n        ;; \n    esac \n  done \n  if [[ -z \"$bucket_name\" ]]; then \n    errecho \"ERROR: You must provide a bucket name with the -b parameter.\" \n    usage \n    return 1 \n  fi \nBasics API Version 2006-03-01 1848Amazon Simple Storage Service API Reference\n  local bucket_config_arg \n  # A location constraint for \"us-east-1\" returns an error. \n  if [[ -n \"$region_code\" ]] && [[ \"$region_code\" != \"us-east-1\" ]]; then \n    bucket_config_arg=\"--create-bucket-configuration LocationConstraint=\n$region_code\" \n  fi \n  iecho \"Parameters:\\n\" \n  iecho \"    Bucket name:   $bucket_name\" \n  iecho \"    Region code:   $region_code\" \n  iecho \"\" \n  # If the bucket already exists, we don't want to try to create it.", "\n  if (bucket_exists \"$bucket_name\"); then \n    errecho \"ERROR: A bucket with that name already exists.", "Try again.\" \n    return 1 \n  fi \n  # shellcheck disable=SC2086 \n  response=$(aws s3api create-bucket \\ \n    --bucket \"$bucket_name\" \\ \n    $bucket_config_arg) \n  # shellcheck disable=SC2181 \n  if [[ ${?} -ne 0 ]]; then \n    errecho \"ERROR: AWS reports create-bucket operation failed.\\n$response\" \n    return 1 \n  fi\n}\n\u2022For API details, see CreateBucket in AWS CLI Command Reference.\nC++\nSDK for C++\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nBasics API Version 2006-03-01 1849Amazon Simple Storage Service API Reference\nbool AwsDoc::S3::createBucket(const Aws::String &bucketName, \n                              const Aws::S3::S3ClientConfiguration &clientConfig) \n { \n    Aws::S3::S3Client client(clientConfig); \n    Aws::S3::Model::CreateBucketRequest request; \n    request.SetBucket(bucketName); \n    if (clientConfig.region != \"us-east-1\") { \n        Aws::S3::Model::CreateBucketConfiguration createBucketConfig; \n        createBucketConfig.SetLocationConstraint( \n                \n Aws::S3::Model::BucketLocationConstraintMapper::GetBucketLocationConstraintForName( \n                        clientConfig.region)); \n        request.SetCreateBucketConfiguration(createBucketConfig); \n    } \n    Aws::S3::Model::CreateBucketOutcome outcome = client.CreateBucket(request); \n    if (!outcome.IsSuccess()) { \n        auto err = outcome.GetError(); \n        std::cerr << \"Error: createBucket: \" << \n                  err.GetExceptionName() << \": \" << err.GetMessage() << \n std::endl; \n    } else { \n        std::cout << \"Created bucket \" << bucketName << \n                  \" in the specified AWS Region.\" << std::endl; \n    } \n    return outcome.IsSuccess();\n}\n\u2022For API details, see CreateBucket in AWS SDK for C++ API Reference.\nCLI\nAWS CLI\nExample 1: To create a bucket\nThe following create-bucket  example creates a bucket named my-bucket :\naws s3api create-bucket \\ \nBasics API Version 2006-03-01 1850Amazon Simple Storage Service API Reference\n    --bucket my-bucket  \\ \n    --region us-east-1\nOutput:\n{ \n    \"Location\": \"/my-bucket\"\n}\nFor more information, see Creating a bucket in the Amazon S3 User Guide .\nExample 2: To create a bucket with owner enforced\nThe following create-bucket  example creates a bucket named my-bucket  that uses the \nbucket owner enforced setting for S3 Object Ownership.\naws s3api create-bucket \\ \n    --bucket my-bucket  \\ \n    --region us-east-1  \\ \n    --object-ownership BucketOwnerEnforced\nOutput:\n{ \n    \"Location\": \"/my-bucket\"\n}\nFor more information, see Controlling ownership of objects and disabling ACLs in the\nAmazon S3 User Guide .\nExample 3: To create a bucket outside of the ``us-east-1`` region\nThe following create-bucket  example creates a bucket named my-bucket  in \nthe eu-west-1  region. Regions outside of us-east-1  require the appropriate\nLocationConstraint  to be speci\ufb01ed in order to create the bucket in the desired region.\naws s3api create-bucket \\ \n    --bucket my-bucket  \\ \n    --region eu-west-1  \\ \n    --create-bucket-configuration LocationConstraint=eu-west-1\nBasics API Version 2006-03-01 1851Amazon Simple Storage Service API Reference\nOutput:\n{ \n    \"Location\": \"http://my-bucket.s3.amazonaws.com/\"\n}\nFor more information, see Creating a bucket in the Amazon S3 User Guide .\n\u2022For API details, see CreateBucket in AWS CLI Command Reference.\nGo\nSDK for Go V2\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nCreate a bucket with default con\ufb01guration.\n// BucketBasics encapsulates the Amazon Simple Storage Service (Amazon S3) \n actions\n// used in the examples.\n// It contains S3Client, an Amazon S3 service client that is used to perform \n bucket\n// and object actions.\ntype BucketBasics struct { \n S3Client *s3.Client\n}\n// CreateBucket creates a bucket with the specified name in the specified Region.\nfunc (basics BucketBasics) CreateBucket(ctx context.Context, name string, region \n string) error { \n _, err := basics.S3Client.CreateBucket(ctx, &s3.CreateBucketInput{ \n  Bucket: aws.String(name), \n  CreateBucketConfiguration: &types.CreateBucketConfiguration{ \n   LocationConstraint: types.BucketLocationConstraint(region), \nBasics API Version 2006-03-01 1852Amazon Simple Storage Service API Reference\n  }, \n }) \n if err != nil { \n  log.Printf(\"Couldn't create bucket %v in Region %v. Here's why: %v\\n\", \n   name, region, err) \n } \n return err\n}\nCreate a bucket with object locking and wait for it to exist.\n// S3Actions wraps S3 service actions.\ntype S3Actions struct { \n S3Client  *s3.Client \n S3Manager *manager.Uploader\n}\n// CreateBucketWithLock creates a new S3 bucket with optional object locking \n enabled\n// and waits for the bucket to exist before returning.\nfunc (actor S3Actions) CreateBucketWithLock(ctx context.Context, bucket string, \n region string, enableObjectLock bool) (string, error) { \n input := &s3.CreateBucketInput{ \n  Bucket: aws.String(bucket), \n  CreateBucketConfiguration: &types.CreateBucketConfiguration{ \n   LocationConstraint: types.BucketLocationConstraint(region), \n  }, \n } \n if enableObjectLock { \n  input.ObjectLockEnabledForBucket = aws.Bool(true) \n } \n _, err := actor.S3Client.CreateBucket(ctx, input) \n if err != nil { \n  var owned *types.BucketAlreadyOwnedByYou \n  var exists *types.BucketAlreadyExists \n  if errors.As(err, &owned) { \nBasics API Version 2006-03-01 1853Amazon Simple Storage Service API Reference\n   log.Printf(\"You already own bucket %s.\\n\", bucket) \n   err = owned \n  } else if errors.As(err, &exists) { \n   log.Printf(\"Bucket %s already exists.\\n\", bucket) \n   err = exists \n  } \n } else { \n  err = s3.NewBucketExistsWaiter(actor.S3Client).Wait( \n   ctx, &s3.HeadBucketInput{Bucket: aws.String(bucket)}, time.Minute) \n  if err != nil { \n   log.Printf(\"Failed attempt to wait for bucket %s to exist.\\n\", bucket) \n  } \n } \n return bucket, err\n}\n\u2022For API details, see CreateBucket in AWS SDK for Go API Reference.\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nCreate a bucket.\n    /** \n     * Creates an S3 bucket asynchronously. \n     * \n     * @param bucketName the name of the S3 bucket to create \n     * @return a {@link CompletableFuture} that completes when the bucket is \n created and ready \n     * @throws RuntimeException if there is a failure while creating the bucket \n     */ \nBasics API Version 2006-03-01 1854Amazon Simple Storage Service API Reference\n    public CompletableFuture<Void> createBucketAsync(String bucketName) { \n        CreateBucketRequest bucketRequest = CreateBucketRequest.builder() \n            .bucket(bucketName) \n            .build(); \n        CompletableFuture<CreateBucketResponse> response = \n getAsyncClient().createBucket(bucketRequest); \n        return response.thenCompose(resp -> { \n            S3AsyncWaiter s3Waiter = getAsyncClient().waiter(); \n            HeadBucketRequest bucketRequestWait = HeadBucketRequest.builder() \n                .bucket(bucketName) \n                .build(); \n            CompletableFuture<WaiterResponse<HeadBucketResponse>> \n waiterResponseFuture = \n                s3Waiter.waitUntilBucketExists(bucketRequestWait); \n            return waiterResponseFuture.thenAccept(waiterResponse -> { \n                waiterResponse.matched().response().ifPresent(headBucketResponse \n -> { \n                    logger.info(bucketName + \" is ready\"); \n                }); \n            }); \n        }).whenComplete((resp, ex) -> { \n            if (ex != null) { \n                throw new RuntimeException(\"Failed to create bucket\", ex); \n            } \n        }); \n    }\nCreate a bucket with object lock enabled.\n    // Create a new Amazon S3 bucket with object lock options. \n    public void createBucketWithLockOptions(boolean enableObjectLock, String \n bucketName) { \n        S3Waiter s3Waiter = getClient().waiter(); \n        CreateBucketRequest bucketRequest = CreateBucketRequest.builder() \n            .bucket(bucketName) \n            .objectLockEnabledForBucket(enableObjectLock) \n            .build(); \n        getClient().createBucket(bucketRequest); \n        HeadBucketRequest bucketRequestWait = HeadBucketRequest.builder() \nBasics API Version 2006-03-01 1855Amazon Simple Storage Service API Reference\n            .bucket(bucketName) \n            .build(); \n        // Wait until the bucket is created and print out the response. \n        s3Waiter.waitUntilBucketExists(bucketRequestWait); \n        System.out.println(bucketName + \" is ready\"); \n    }\n\u2022For API details, see CreateBucket in AWS SDK for Java 2.x API Reference.\nJavaScript\nSDK for JavaScript (v3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nCreate the bucket.\nimport { \n  BucketAlreadyExists, \n  BucketAlreadyOwnedByYou, \n  CreateBucketCommand, \n  S3Client, \n  waitUntilBucketExists,\n} from \"@aws-sdk/client-s3\";\n/** \n * Create an Amazon S3 bucket. \n * @param {{ bucketName: string }} config \n */\nexport const main = async ({ bucketName }) => { \n  const client = new S3Client({}); \n  try { \n    const { Location } = await client.send( \n      new CreateBucketCommand({ \nBasics API Version 2006-03-01 1856Amazon Simple Storage Service API Reference\n        // The name of the bucket.", "Bucket names are unique and have several other \n constraints. \n        // See https://docs.aws.amazon.com/AmazonS3/latest/userguide/\nbucketnamingrules.html \n        Bucket: bucketName, \n      }), \n    ); \n    await waitUntilBucketExists({ client }, { Bucket: bucketName }); \n    console.log(`Bucket created with location ${Location}`); \n  } catch (caught) { \n    if (caught instanceof BucketAlreadyExists) { \n      console.error( \n        `The bucket \"${bucketName}\" already exists in another AWS account. Bucket \n names must be globally unique.`, \n      ); \n    } \n    // WARNING: If you try to create a bucket in the North Virginia region, \n    // and you already own a bucket in that region with the same name, this \n    // error will not be thrown. Instead, the call will return successfully \n    // and the ACL on that bucket will be reset. \n    else if (caught instanceof BucketAlreadyOwnedByYou) { \n      console.error( \n        `The bucket \"${bucketName}\" already exists in this AWS account.`, \n      ); \n    } else { \n      throw caught; \n    } \n  }\n};\n\u2022For more information, see AWS SDK for JavaScript Developer Guide.\n\u2022For API details, see CreateBucket in AWS SDK for JavaScript API Reference.\nBasics API Version 2006-03-01 1857Amazon Simple Storage Service API Reference\nKotlin\nSDK for Kotlin\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nsuspend fun createNewBucket(bucketName: String) { \n    val request = \n        CreateBucketRequest { \n            bucket = bucketName \n        } \n    S3Client { region = \"us-east-1\" }.use { s3 -> \n        s3.createBucket(request) \n        println(\"$bucketName is ready\") \n    }\n}\n\u2022For API details, see CreateBucket in AWS SDK for Kotlin API reference.\nPHP\nSDK for PHP\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nCreate a bucket.\n        $s3client = new Aws\\S3\\S3Client(['region' => 'us-west-2']); \n        try { \nBasics API Version 2006-03-01 1858Amazon Simple Storage Service API Reference\n            $this->s3client->createBucket([ \n                'Bucket' => $this->bucketName, \n                'CreateBucketConfiguration' => ['LocationConstraint' => $region], \n            ]); \n            echo \"Created bucket named: $this->bucketName \\n\"; \n        } catch (Exception $exception) { \n            echo \"Failed to create bucket $this->bucketName with error: \" . \n $exception->getMessage(); \n            exit(\"Please fix error with bucket creation before continuing.\"); \n        }\n\u2022For API details, see CreateBucket in AWS SDK for PHP API Reference.\nPython\nSDK for Python (Boto3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nCreate a bucket with default settings.\nclass BucketWrapper: \n    \"\"\"Encapsulates S3 bucket actions.\"\"\" \n    def __init__(self, bucket): \n        \"\"\" \n        :param bucket: A Boto3 Bucket resource. This is a high-level resource in \n Boto3 \n                       that wraps bucket actions in a class-like structure.", "\n        \"\"\" \n        self.bucket = bucket \n        self.name = bucket.name \n    def create(self, region_override=None): \n        \"\"\" \nBasics API Version 2006-03-01 1859Amazon Simple Storage Service API Reference\n        Create an Amazon S3 bucket in the default Region for the account or in \n the \n        specified Region.", "\n        :param region_override: The Region in which to create the bucket.", "If this \n is \n                                not specified, the Region configured in your \n shared \n                                credentials is used.", "\n        \"\"\" \n        if region_override is not None: \n            region = region_override \n        else: \n            region = self.bucket.meta.client.meta.region_name \n        try: \n            self.bucket.create(CreateBucketConfiguration={\"LocationConstraint\": \n region}) \n            self.bucket.wait_until_exists() \n            logger.info(\"Created bucket '%s' in region=%s\", self.bucket.name, \n region) \n        except ClientError as error: \n            logger.exception( \n                \"Couldn't create bucket named '%s' in region=%s.\", \n                self.bucket.name, \n                region, \n            ) \n            raise error\nCreate a versioned bucket with a lifecycle con\ufb01guration.\ndef create_versioned_bucket(bucket_name, prefix): \n    \"\"\" \n    Creates an Amazon S3 bucket, enables it for versioning, and configures a \n lifecycle \n    that expires noncurrent object versions after 7 days. \n    Adding a lifecycle configuration to a versioned bucket is a best practice. \n    It helps prevent objects in the bucket from accumulating a large number of \n    noncurrent versions, which can slow down request performance.", "\nBasics API Version 2006-03-01 1860Amazon Simple Storage Service API Reference\n    Usage is shown in the usage_demo_single_object function at the end of this \n module.", "\n    :param bucket_name: The name of the bucket to create.", "\n    :param prefix: Identifies which objects are automatically expired under the \n                   configured lifecycle rules.", "\n    :return: The newly created bucket. \n    \"\"\" \n    try: \n        bucket = s3.create_bucket( \n            Bucket=bucket_name, \n            CreateBucketConfiguration={ \n                \"LocationConstraint\": s3.meta.client.meta.region_name \n            }, \n        ) \n        logger.info(\"Created bucket %s.\", bucket.name) \n    except ClientError as error: \n        if error.response[\"Error\"][\"Code\"] == \"BucketAlreadyOwnedByYou\": \n            logger.warning(\"Bucket %s already exists! Using it.\", bucket_name) \n            bucket = s3.Bucket(bucket_name) \n        else: \n            logger.exception(\"Couldn't create bucket %s.\", bucket_name) \n            raise \n    try: \n        bucket.Versioning().enable() \n        logger.info(\"Enabled versioning on bucket %s.\", bucket.name) \n    except ClientError: \n        logger.exception(\"Couldn't enable versioning on bucket %s.\", bucket.name) \n        raise \n    try: \n        expiration = 7 \n        bucket.LifecycleConfiguration().put( \n            LifecycleConfiguration={ \n                \"Rules\": [ \n                    { \n                        \"Status\": \"Enabled\", \n                        \"Prefix\": prefix, \n                        \"NoncurrentVersionExpiration\": {\"NoncurrentDays\": \n expiration}, \n                    } \n                ] \n            } \nBasics API Version 2006-03-01 1861Amazon Simple Storage Service API Reference\n        ) \n        logger.info( \n            \"Configured lifecycle to expire noncurrent versions after %s days \" \n            \"on bucket %s.\", \n            expiration, \n            bucket.name, \n        ) \n    except ClientError as error: \n        logger.warning( \n            \"Couldn't configure lifecycle on bucket %s because %s. \" \n            \"Continuing anyway.\", \n            bucket.name, \n            error, \n        ) \n    return bucket\n\u2022For API details, see CreateBucket in AWS SDK for Python (Boto3) API Reference.\nRuby\nSDK for Ruby\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nrequire 'aws-sdk-s3'\n# Wraps Amazon S3 bucket actions.\nclass BucketCreateWrapper \n  attr_reader :bucket \n  # @param bucket [Aws::S3::Bucket] An Amazon S3 bucket initialized with a name.", "\n This is a client-side object until \n  #                                 create is called.", "\n  def initialize(bucket) \nBasics API Version 2006-03-01 1862Amazon Simple Storage Service API Reference\n    @bucket = bucket \n  end \n  # Creates an Amazon S3 bucket in the specified AWS Region.", "\n  # \n  # @param region [String] The Region where the bucket is created. \n  # @return [Boolean] True when the bucket is created; otherwise, false. \n  def create?(region) \n    @bucket.create(create_bucket_configuration: { location_constraint: region }) \n    true \n  rescue Aws::Errors::ServiceError => e \n    puts \"Couldn't create bucket. Here's why: #{e.message}\" \n    false \n  end \n  # Gets the Region where the bucket is located. \n  # \n  # @return [String] The location of the bucket. \n  def location \n    if @bucket.nil?", "\n      'None.", "You must create a bucket before you can get its location!' \n    else \n      @bucket.client.get_bucket_location(bucket: \n @bucket.name).location_constraint \n    end \n  rescue Aws::Errors::ServiceError => e \n    \"Couldn't get the location of #{@bucket.name}. Here's why: #{e.message}\" \n  end\nend\n# Example usage:\ndef run_demo\n<<<<<<< HEAD \n  region = \"us-west-2\" \n  wrapper = BucketCreateWrapper.new(Aws::S3::Bucket.new(\"amzn-s3-demo-bucket-\n#{Random.uuid}\"))\n======= \n  region = 'us-west-2' \n  wrapper = BucketCreateWrapper.new(Aws::S3::Bucket.new(\"doc-example-bucket-\n#{Random.uuid}\"))\n>>>>>>> 999c6133e (fixes) \n  return unless wrapper.create?(region) \n  puts \"Created bucket #{wrapper.bucket.name}.\" \nBasics API Version 2006-03-01 1863Amazon Simple Storage Service API Reference\n  puts \"Your bucket's region is: #{wrapper.location}\"\nend\nrun_demo if $PROGRAM_NAME == __FILE__\n\u2022For API details, see CreateBucket in AWS SDK for Ruby API Reference.\nRust\nSDK for Rust\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\npub async fn create_bucket( \n    client: &aws_sdk_s3::Client, \n    bucket_name: &str, \n    region: &aws_config::Region,\n) -> Result<Option<aws_sdk_s3::operation::create_bucket::CreateBucketOutput>, \n S3ExampleError> { \n    let constraint = \n aws_sdk_s3::types::BucketLocationConstraint::from(region.to_string().as_str()); \n    let cfg = aws_sdk_s3::types::CreateBucketConfiguration::builder() \n        .location_constraint(constraint) \n        .build(); \n    let create = client \n        .create_bucket() \n        .create_bucket_configuration(cfg) \n        .bucket(bucket_name) \n        .send() \n        .await; \n    // BucketAlreadyExists and BucketAlreadyOwnedByYou are not problems for this \n task. \n    create.map(Some).or_else(|err| { \n        if err \n            .as_service_error() \nBasics API Version 2006-03-01 1864Amazon Simple Storage Service API Reference\n            .map(|se| se.is_bucket_already_exists() || \n se.is_bucket_already_owned_by_you()) \n            == Some(true) \n        { \n            Ok(None) \n        } else { \n            Err(S3ExampleError::from(err)) \n        } \n    })\n}\n\u2022For API details, see CreateBucket in AWS SDK for Rust API reference.\nSAP ABAP\nSDK for SAP ABAP\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n    TRY.", "\n        lo_s3->createbucket( \n            iv_bucket = iv_bucket_name \n        ). \n        MESSAGE 'S3 bucket created.' TYPE 'I'. \n      CATCH /aws1/cx_s3_bucketalrdyexists.", "\n        MESSAGE 'Bucket name already exists.' TYPE 'E'.", "\n      CATCH /aws1/cx_s3_bktalrdyownedbyyou.", "\n        MESSAGE 'Bucket already exists and is owned by you.' TYPE 'E'.", "\n    ENDTRY.\n\u2022For API details, see CreateBucket in AWS SDK for SAP ABAP API reference.\nBasics API Version 2006-03-01 1865Amazon Simple Storage Service API Reference\nSwift\nSDK for Swift\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nimport AWSS3 \n    public func createBucket(name: String) async throws { \n        var input = CreateBucketInput( \n            bucket: name \n        ) \n         \n        // For regions other than \"us-east-1\", you must set the \n locationConstraint in the createBucketConfiguration.", "\n        // For more information, see LocationConstraint in the S3 API guide.", "\n        // https://docs.aws.amazon.com/AmazonS3/latest/API/\nAPI_CreateBucket.html#API_CreateBucket_RequestBody \n        if let region = configuration.region { \n            if region != \"us-east-1\" { \n                input.createBucketConfiguration = \n S3ClientTypes.CreateBucketConfiguration(locationConstraint: \n S3ClientTypes.BucketLocationConstraint(rawValue: region)) \n            } \n        } \n        do { \n            _ = try await client.createBucket(input: input) \n        } \n        catch let error as BucketAlreadyOwnedByYou { \n            print(\"The bucket '\\(name)' already exists and is owned by you. You \n may wish to ignore this exception.\") \n            throw error \n        } \n        catch { \n            print(\"ERROR: \", dump(error, name: \"Creating a bucket\")) \n            throw error \n        } \nBasics API Version 2006-03-01 1866Amazon Simple Storage Service API Reference\n    }\n\u2022For API details, see CreateBucket in AWS SDK for Swift API reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs.", "This topic also includes information about getting started and details \nabout previous SDK versions.\nUse CreateMultiRegionAccessPoint  with an AWS SDK\nThe following code example shows how to use CreateMultiRegionAccessPoint .\nKotlin\nSDK for Kotlin\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nCon\ufb01gure the S3 control client to send request to the us-west-2 Region.\n        suspend fun createS3ControlClient(): S3ControlClient { \n            // Configure your S3ControlClient to send requests to US West \n (Oregon). \n            val s3Control = S3ControlClient.fromEnvironment { \n                region = \"us-west-2\" \n            } \n            return s3Control \n        }\nCreate the Multi-Region Access Point.\n    suspend fun createMrap( \n        s3Control: S3ControlClient, \n        accountIdParam: String, \nBasics API Version 2006-03-01 1867Amazon Simple Storage Service API Reference\n        bucketName1: String, \n        bucketName2: String, \n        mrapName: String, \n    ): String { \n        println(\"Creating MRAP ...\") \n        val createMrapResponse: CreateMultiRegionAccessPointResponse = \n            s3Control.createMultiRegionAccessPoint { \n                accountId = accountIdParam \n                clientToken = UUID.randomUUID().toString() \n                details { \n                    name = mrapName \n                    regions = listOf( \n                        Region { \n                            bucket = bucketName1 \n                        }, \n                        Region { \n                            bucket = bucketName2 \n                        }, \n                    ) \n                } \n            } \n        val requestToken: String?", "= createMrapResponse.requestTokenArn \n        // Use the request token to check for the status of the \n CreateMultiRegionAccessPoint operation.", "\n        if (requestToken != null) { \n            waitForSucceededStatus(s3Control, requestToken, accountIdParam) \n            println(\"MRAP created\") \n        } \n        val getMrapResponse = \n            s3Control.getMultiRegionAccessPoint( \n                input = GetMultiRegionAccessPointRequest { \n                    accountId = accountIdParam \n                    name = mrapName \n                }, \n            ) \n        val mrapAlias = getMrapResponse.accessPoint?.alias \n        return \"arn:aws:s3::$accountIdParam:accesspoint/$mrapAlias\" \n    }\nWait for the Multi-Region Access Point to become available.\nBasics API Version 2006-03-01 1868Amazon Simple Storage Service API Reference\n        suspend fun waitForSucceededStatus( \n            s3Control: S3ControlClient, \n            requestToken: String, \n            accountIdParam: String, \n            timeBetweenChecks: Duration = 1.minutes, \n        ) { \n            var describeResponse: DescribeMultiRegionAccessPointOperationResponse \n            describeResponse = s3Control.describeMultiRegionAccessPointOperation( \n                input = DescribeMultiRegionAccessPointOperationRequest { \n                    accountId = accountIdParam \n                    requestTokenArn = requestToken \n                }, \n            ) \n            var status: String? = describeResponse.asyncOperation?.requestStatus \n            while (status != \"SUCCEEDED\") { \n                delay(timeBetweenChecks) \n                describeResponse = \n s3Control.describeMultiRegionAccessPointOperation( \n                    input = DescribeMultiRegionAccessPointOperationRequest { \n                        accountId = accountIdParam \n                        requestTokenArn = requestToken \n                    }, \n                ) \n                status = describeResponse.asyncOperation?.requestStatus \n                println(status) \n            } \n        }\n\u2022For more information, see AWS SDK for Kotlin developer guide.\n\u2022For API details, see CreateMultiRegionAccessPoint in AWS SDK for Kotlin API reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs.", "This topic also includes information about getting started and details \nabout previous SDK versions.\nUse CreateMultipartUpload  with an AWS SDK or CLI\nThe following code examples show how to use CreateMultipartUpload .\nBasics API Version 2006-03-01 1869Amazon Simple Storage Service API Reference\nAction examples are code excerpts from larger programs and must be run in context.", "You can see \nthis action in context in the following code examples:\n\u2022Perform a multipart copy\n\u2022Perform a multipart upload\n\u2022Use checksums\n\u2022Work with Amazon S3 object integrity\nC++\nSDK for C++\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n//!", "Create a multipart upload.\n/*!", "\n    \\param bucket: The name of the S3 bucket where the object will be uploaded. \n    \\param key: The unique identifier (key) for the object within the S3 bucket. \n    \\param client: The S3 client instance used to perform the upload operation. \n    \\return Aws::String: Upload ID or empty string if failed.\n*/\nAws::String\nAwsDoc::S3::createMultipartUpload(const Aws::String &bucket, const Aws::String \n &key, \n                                  Aws::S3::Model::ChecksumAlgorithm \n checksumAlgorithm, \n                                  const Aws::S3::S3Client &client) { \n    Aws::S3::Model::CreateMultipartUploadRequest request; \n    request.SetBucket(bucket); \n    request.SetKey(key); \n    if (checksumAlgorithm != Aws::S3::Model::ChecksumAlgorithm::NOT_SET) { \n        request.SetChecksumAlgorithm(checksumAlgorithm); \n    } \n    Aws::S3::Model::CreateMultipartUploadOutcome outcome = \nBasics API Version 2006-03-01 1870Amazon Simple Storage Service API Reference\n            client.CreateMultipartUpload(request); \n    Aws::String uploadID; \n    if (outcome.IsSuccess()) { \n        uploadID = outcome.GetResult().GetUploadId(); \n    } else { \n        std::cerr << \"Error creating multipart upload: \" << \n outcome.GetError().GetMessage() << std::endl; \n    } \n    return uploadID;\n}\n\u2022For API details, see CreateMultipartUpload in AWS SDK for C++ API Reference.\nCLI\nAWS CLI\nThe following command creates a multipart upload in the bucket my-bucket  with the key\nmultipart/01 :\naws s3api create-multipart-upload --bucket my-bucket  --key ' multipart/01 '\nOutput:\n{ \n    \"Bucket\": \"my-bucket\", \n    \"UploadId\": \n \"dfRtDYU0WWCCcH43C3WFbkRONycyCpTJJvxu2i5GYkZljF.Yxwh6XG7WfS2vC4to6HiV6Yjlx.cph0gtNBtJ8P3URCSbB7rjxI5iEwVDmgaXZOGgkk5nVTW16HOQ5l0R\", \n    \"Key\": \"multipart/01\"\n}\nThe completed \ufb01le will be named 01 in a folder called multipart  in the bucket my-\nbucket. Save the upload ID, key and bucket name for use with the upload-part\ncommand.\n\u2022For API details, see CreateMultipartUpload in AWS CLI Command Reference.\nBasics API Version 2006-03-01 1871Amazon Simple Storage Service API Reference\nRust\nSDK for Rust\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n    // Create a multipart upload.", "Use UploadPart and CompleteMultipartUpload to \n    // upload the file.", "\n    let multipart_upload_res: CreateMultipartUploadOutput = client \n        .create_multipart_upload() \n        .bucket(&bucket_name) \n        .key(&key) \n        .send() \n        .await?; \n    let upload_id = multipart_upload_res.upload_id().ok_or(S3ExampleError::new( \n        \"Missing upload_id after CreateMultipartUpload\", \n    ))?;\n    let mut upload_parts: Vec<aws_sdk_s3::types::CompletedPart> = Vec::new(); \n    for chunk_index in 0..chunk_count { \n        let this_chunk = if chunk_count - 1 == chunk_index { \n            size_of_last_chunk \n        } else { \n            CHUNK_SIZE \n        }; \n        let stream = ByteStream::read_from() \n            .path(path) \n            .offset(chunk_index * CHUNK_SIZE) \n            .length(Length::Exact(this_chunk)) \n            .build() \n            .await \n            .unwrap(); \n        // Chunk index needs to start at 0, but part numbers start at 1. \n        let part_number = (chunk_index as i32) + 1; \nBasics API Version 2006-03-01 1872Amazon Simple Storage Service API Reference\n        let upload_part_res = client \n            .upload_part() \n            .key(&key) \n            .bucket(&bucket_name) \n            .upload_id(upload_id) \n            .body(stream) \n            .part_number(part_number) \n            .send() \n            .await?; \n        upload_parts.push( \n            CompletedPart::builder() \n                .e_tag(upload_part_res.e_tag.unwrap_or_default()) \n                .part_number(part_number) \n                .build(), \n        ); \n    }\n    // upload_parts: Vec<aws_sdk_s3::types::CompletedPart> \n    let completed_multipart_upload: CompletedMultipartUpload = \n CompletedMultipartUpload::builder() \n        .set_parts(Some(upload_parts)) \n        .build(); \n    let _complete_multipart_upload_res = client \n        .complete_multipart_upload() \n        .bucket(&bucket_name) \n        .key(&key) \n        .multipart_upload(completed_multipart_upload) \n        .upload_id(upload_id) \n        .send() \n        .await?;\n\u2022For API details, see CreateMultipartUpload in AWS SDK for Rust API reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs.", "This topic also includes information about getting started and details \nabout previous SDK versions.\nBasics API Version 2006-03-01 1873Amazon Simple Storage Service API Reference\nUse DeleteBucket  with an AWS SDK or CLI\nThe following code examples show how to use DeleteBucket .\nAction examples are code excerpts from larger programs and must be run in context.", "You can see \nthis action in context in the following code example:\n\u2022Learn the basics\n.NET\nAWS SDK for .NET\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n        /// <summary> \n        /// Shows how to delete an Amazon S3 bucket. \n        /// </summary> \n        /// <param name=\"client\">An initialized Amazon S3 client object.</param> \n        /// <param name=\"bucketName\">The name of the Amazon S3 bucket to \n delete.</param> \n        /// <returns>A boolean value that represents the success or failure of \n        /// the delete operation.</returns> \n        public static async Task<bool> DeleteBucketAsync(IAmazonS3 client, string \n bucketName) \n        { \n            var request = new DeleteBucketRequest \n            { \n                BucketName = bucketName, \n            }; \n            var response = await client.DeleteBucketAsync(request); \n            return response.HttpStatusCode == System.Net.HttpStatusCode.OK; \n        }\nBasics API Version 2006-03-01 1874Amazon Simple Storage Service API Reference\n\u2022For API details, see DeleteBucket in AWS SDK for .NET API Reference.\nBash\nAWS CLI with Bash script\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n###############################################################################\n# function errecho\n#\n# This function outputs everything sent to it to STDERR (standard error output).\n###############################################################################\nfunction errecho() { \n  printf \"%s\\n\" \"$*\" 1>&2\n}\n###############################################################################\n# function delete_bucket\n#\n# This function deletes the specified bucket.\n#\n# Parameters:\n#       $1 - The name of the bucket.\n# Returns:\n#       0 - If successful.\n#       1 - If it fails.\n###############################################################################\nfunction delete_bucket() { \n  local bucket_name=$1 \n  local response \n  response=$(aws s3api delete-bucket \\ \n    --bucket \"$bucket_name\") \n  # shellcheck disable=SC2181 \n  if [[ $?", "-ne 0 ]]; then \nBasics API Version 2006-03-01 1875Amazon Simple Storage Service API Reference\n    errecho \"ERROR: AWS reports s3api delete-bucket failed.\\n$response\" \n    return 1 \n  fi\n}\n\u2022For API details, see DeleteBucket in AWS CLI Command Reference.\nC++\nSDK for C++\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nbool AwsDoc::S3::deleteBucket(const Aws::String &bucketName, \n                              const Aws::S3::S3ClientConfiguration &clientConfig) \n { \n    Aws::S3::S3Client client(clientConfig); \n    Aws::S3::Model::DeleteBucketRequest request; \n    request.SetBucket(bucketName); \n    Aws::S3::Model::DeleteBucketOutcome outcome = \n            client.DeleteBucket(request); \n    if (!outcome.IsSuccess()) { \n        const Aws::S3::S3Error &err = outcome.GetError(); \n        std::cerr << \"Error: deleteBucket: \" << \n                  err.GetExceptionName() << \": \" << err.GetMessage() << \n std::endl; \n    } else { \n        std::cout << \"The bucket was deleted\" << std::endl; \n    } \n    return outcome.IsSuccess();\n}\nBasics API Version 2006-03-01 1876Amazon Simple Storage Service API Reference\n\u2022For API details, see DeleteBucket in AWS SDK for C++ API Reference.\nCLI\nAWS CLI\nThe following command deletes a bucket named my-bucket :\naws s3api delete-bucket --bucket my-bucket  --region us-east-1\n\u2022For API details, see DeleteBucket in AWS CLI Command Reference.\nGo\nSDK for Go V2\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n// BucketBasics encapsulates the Amazon Simple Storage Service (Amazon S3) \n actions\n// used in the examples.\n// It contains S3Client, an Amazon S3 service client that is used to perform \n bucket\n// and object actions.\ntype BucketBasics struct { \n S3Client *s3.Client\n}\n// DeleteBucket deletes a bucket. The bucket must be empty or an error is \n returned.\nfunc (basics BucketBasics) DeleteBucket(ctx context.Context, bucketName string) \n error { \nBasics API Version 2006-03-01 1877Amazon Simple Storage Service API Reference\n _, err := basics.S3Client.DeleteBucket(ctx, &s3.DeleteBucketInput{ \n  Bucket: aws.String(bucketName)}) \n if err != nil { \n  log.Printf(\"Couldn't delete bucket %v. Here's why: %v\\n\", bucketName, err) \n } \n return err\n}\n\u2022For API details, see DeleteBucket in AWS SDK for Go API Reference.\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n    /** \n     * Deletes an S3 bucket asynchronously.", "\n     * \n     * @param bucket the name of the bucket to be deleted \n     * @return a {@link CompletableFuture} that completes when the bucket \n deletion is successful, or throws a {@link RuntimeException} \n     * if an error occurs during the deletion process \n     */ \n    public CompletableFuture<Void> deleteBucketAsync(String bucket) { \n        DeleteBucketRequest deleteBucketRequest = DeleteBucketRequest.builder() \n            .bucket(bucket) \n            .build(); \n        CompletableFuture<DeleteBucketResponse> response = \n getAsyncClient().deleteBucket(deleteBucketRequest); \n        response.whenComplete((deleteRes, ex) -> { \n            if (deleteRes != null) { \n                logger.info(bucket + \" was deleted.\"); \n            } else { \nBasics API Version 2006-03-01 1878Amazon Simple Storage Service API Reference\n                throw new RuntimeException(\"An S3 exception occurred during \n bucket deletion\", ex); \n            } \n        }); \n        return response.thenApply(r -> null); \n    }\n\u2022For API details, see DeleteBucket in AWS SDK for Java 2.x API Reference.\nJavaScript\nSDK for JavaScript (v3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nDelete the bucket.\nimport { \n  DeleteBucketCommand, \n  S3Client, \n  S3ServiceException,\n} from \"@aws-sdk/client-s3\";\n/** \n * Delete an Amazon S3 bucket. \n * @param {{ bucketName: string }} \n */\nexport const main = async ({ bucketName }) => { \n  const client = new S3Client({}); \n  const command = new DeleteBucketCommand({ \n    Bucket: bucketName, \n  }); \n  try { \n    await client.send(command); \n    console.log(\"Bucket was deleted.\"); \n  } catch (caught) { \nBasics API Version 2006-03-01 1879Amazon Simple Storage Service API Reference\n    if ( \n      caught instanceof S3ServiceException && \n      caught.name === \"NoSuchBucket\" \n    ) { \n      console.error( \n        `Error from S3 while deleting bucket. The bucket doesn't exist.`, \n      ); \n    } else if (caught instanceof S3ServiceException) { \n      console.error( \n        `Error from S3 while deleting the bucket.", "${caught.name}: \n ${caught.message}`, \n      ); \n    } else { \n      throw caught; \n    } \n  }\n};\n\u2022For more information, see AWS SDK for JavaScript Developer Guide.\n\u2022For API details, see DeleteBucket in AWS SDK for JavaScript API Reference.\nPHP\nSDK for PHP\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nDelete an empty bucket.\n        $s3client = new Aws\\S3\\S3Client(['region' => 'us-west-2']); \n        try { \n            $this->s3client->deleteBucket([ \n                'Bucket' => $this->bucketName, \n            ]); \n            echo \"Deleted bucket $this->bucketName.\\n\"; \nBasics API Version 2006-03-01 1880Amazon Simple Storage Service API Reference\n        } catch (Exception $exception) { \n            echo \"Failed to delete $this->bucketName with error: \" . $exception-\n>getMessage(); \n            exit(\"Please fix error with bucket deletion before continuing.\"); \n        }\n\u2022For API details, see DeleteBucket in AWS SDK for PHP API Reference.\nPowerShell\nTools for PowerShell\nExample 1: This command removes all objects and object versions from the bucket 'test-\n\ufb01les' and then deletes the bucket.", "The command will prompt for con\ufb01rmation before \nproceeding. Add the -Force switch to suppress con\ufb01rmation.", "Note that buckets that are \nnot empty cannot be deleted.\nRemove-S3Bucket -BucketName amzn-s3-demo-bucket -DeleteBucketContent\n\u2022For API details, see DeleteBucket in AWS Tools for PowerShell Cmdlet Reference.\nPython\nSDK for Python (Boto3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nclass BucketWrapper: \n    \"\"\"Encapsulates S3 bucket actions.\"\"\" \n    def __init__(self, bucket): \n        \"\"\" \n        :param bucket: A Boto3 Bucket resource. This is a high-level resource in \n Boto3 \n                       that wraps bucket actions in a class-like structure.", "\nBasics API Version 2006-03-01 1881Amazon Simple Storage Service API Reference\n        \"\"\" \n        self.bucket = bucket \n        self.name = bucket.name \n    def delete(self): \n        \"\"\" \n        Delete the bucket. The bucket must be empty or an error is raised. \n        \"\"\" \n        try: \n            self.bucket.delete() \n            self.bucket.wait_until_not_exists() \n            logger.info(\"Bucket %s successfully deleted.\", self.bucket.name) \n        except ClientError: \n            logger.exception(\"Couldn't delete bucket %s.\", self.bucket.name) \n            raise\n\u2022For API details, see DeleteBucket in AWS SDK for Python (Boto3) API Reference.\nRuby\nSDK for Ruby\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n  # Deletes the objects in an Amazon S3 bucket and deletes the bucket. \n  # \n  # @param bucket [Aws::S3::Bucket] The bucket to empty and delete. \n  def delete_bucket(bucket) \n    puts(\"\\nDo you want to delete all of the objects as well as the bucket (y/n)? \n \") \n    answer = gets.chomp.downcase \n    if answer == 'y' \n      bucket.objects.batch_delete! \n      bucket.delete \n      puts(\"Emptied and deleted bucket #{bucket.name}.\\n\") \nBasics API Version 2006-03-01 1882Amazon Simple Storage Service API Reference\n    end \n  rescue Aws::Errors::ServiceError => e \n    puts(\"Couldn't empty and delete bucket #{bucket.name}.\") \n    puts(\"\\t#{e.code}: #{e.message}\") \n    raise \n  end\n\u2022For API details, see DeleteBucket in AWS SDK for Ruby API Reference.\nRust\nSDK for Rust\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\npub async fn delete_bucket( \n    client: &aws_sdk_s3::Client, \n    bucket_name: &str,\n) -> Result<(), S3ExampleError> { \n    let resp = client.delete_bucket().bucket(bucket_name).send().await; \n    match resp { \n        Ok(_) => Ok(()), \n        Err(err) => { \n            if err \n                .as_service_error() \n                .and_then(aws_sdk_s3::error::ProvideErrorMetadata::code) \n                == Some(\"NoSuchBucket\") \n            { \n                Ok(()) \n            } else { \n                Err(S3ExampleError::from(err)) \n            } \n        } \n    }\n}\nBasics API Version 2006-03-01 1883Amazon Simple Storage Service API Reference\n\u2022For API details, see DeleteBucket in AWS SDK for Rust API reference.\nSAP ABAP\nSDK for SAP ABAP\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n    TRY.", "\n        lo_s3->deletebucket( \n            iv_bucket = iv_bucket_name \n        ). \n        MESSAGE 'Deleted S3 bucket.' TYPE 'I'.", "\n      CATCH /aws1/cx_s3_nosuchbucket.", "\n        MESSAGE 'Bucket does not exist.' TYPE 'E'.", "\n    ENDTRY.\n\u2022For API details, see DeleteBucket in AWS SDK for SAP ABAP API reference.\nSwift\nSDK for Swift\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nimport AWSS3 \n    public func deleteBucket(name: String) async throws { \n        let input = DeleteBucketInput( \nBasics API Version 2006-03-01 1884Amazon Simple Storage Service API Reference\n            bucket: name \n        ) \n        do { \n            _ = try await client.deleteBucket(input: input) \n        } \n        catch { \n            print(\"ERROR: \", dump(error, name: \"Deleting a bucket\")) \n            throw error \n        } \n    }\n\u2022For API details, see DeleteBucket in AWS SDK for Swift API reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nUse DeleteBucketAnalyticsConfiguration  with a CLI\nThe following code examples show how to use DeleteBucketAnalyticsConfiguration .\nCLI\nAWS CLI\nTo delete an analytics con\ufb01guration for a bucket\nThe following delete-bucket-analytics-configuration  example removes the \nanalytics con\ufb01guration for the speci\ufb01ed bucket and ID.\naws s3api delete-bucket-analytics-configuration \\ \n    --bucket my-bucket  \\ \n    --id 1\nThis command produces no output.\n\u2022For API details, see DeleteBucketAnalyticsCon\ufb01guration in AWS CLI Command Reference.\nBasics API Version 2006-03-01 1885Amazon Simple Storage Service API Reference\nPowerShell\nTools for PowerShell\nExample 1: The command removes the analytics \ufb01lter with name 'test\ufb01lter' in the given \nS3 bucket.\nRemove-S3BucketAnalyticsConfiguration -BucketName 'amzn-s3-demo-bucket' -\nAnalyticsId 'testfilter'\n\u2022For API details, see DeleteBucketAnalyticsCon\ufb01guration in AWS Tools for PowerShell \nCmdlet Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nUse DeleteBucketCors  with an AWS SDK or CLI\nThe following code examples show how to use DeleteBucketCors .\n.NET\nAWS SDK for .NET\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n        /// <summary> \n        /// Deletes a CORS configuration from an Amazon S3 bucket. \n        /// </summary> \n        /// <param name=\"client\">The initialized Amazon S3 client object used \n        /// to delete the CORS configuration from the bucket.</param> \n        private static async Task DeleteCORSConfigurationAsync(AmazonS3Client \n client) \n        { \nBasics API Version 2006-03-01 1886Amazon Simple Storage Service API Reference\n            DeleteCORSConfigurationRequest request = new \n DeleteCORSConfigurationRequest() \n            { \n                BucketName = BucketName, \n            }; \n            await client.DeleteCORSConfigurationAsync(request); \n        }\n\u2022For API details, see DeleteBucketCors in AWS SDK for .NET API Reference.\nCLI\nAWS CLI\nThe following command deletes a Cross-Origin Resource Sharing con\ufb01guration from a \nbucket named my-bucket :\naws s3api delete-bucket-cors --bucket my-bucket\n\u2022For API details, see DeleteBucketCors in AWS CLI Command Reference.\nPython\nSDK for Python (Boto3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nclass BucketWrapper: \n    \"\"\"Encapsulates S3 bucket actions.\"\"\" \n    def __init__(self, bucket): \n        \"\"\" \n        :param bucket: A Boto3 Bucket resource. This is a high-level resource in \n Boto3 \nBasics API Version 2006-03-01 1887Amazon Simple Storage Service API Reference\n                       that wraps bucket actions in a class-like structure.", "\n        \"\"\" \n        self.bucket = bucket \n        self.name = bucket.name \n    def delete_cors(self): \n        \"\"\" \n        Delete the CORS rules from the bucket. \n        :param bucket_name: The name of the bucket to update. \n        \"\"\" \n        try: \n            self.bucket.Cors().delete() \n            logger.info(\"Deleted CORS from bucket '%s'.\", self.bucket.name) \n        except ClientError: \n            logger.exception(\"Couldn't delete CORS from bucket '%s'.\", \n self.bucket.name) \n            raise\n\u2022For API details, see DeleteBucketCors in AWS SDK for Python (Boto3) API Reference.\nRuby\nSDK for Ruby\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nrequire 'aws-sdk-s3'\n# Wraps Amazon S3 bucket CORS configuration.\nclass BucketCorsWrapper \n  attr_reader :bucket_cors \n  # @param bucket_cors [Aws::S3::BucketCors] A bucket CORS object configured with \n an existing bucket.", "\nBasics API Version 2006-03-01 1888Amazon Simple Storage Service API Reference\n  def initialize(bucket_cors) \n    @bucket_cors = bucket_cors \n  end \n  # Deletes the CORS configuration of a bucket.", "\n  # \n  # @return [Boolean] True if the CORS rules were deleted; otherwise, false.", "\n  def delete_cors \n    @bucket_cors.delete \n    true \n  rescue Aws::Errors::ServiceError => e \n    puts \"Couldn't delete CORS rules for #{@bucket_cors.bucket.name}.", "Here's why: \n #{e.message}\" \n    false \n  end\nend\n\u2022For API details, see DeleteBucketCors in AWS SDK for Ruby API Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nUse DeleteBucketEncryption  with a CLI\nThe following code examples show how to use DeleteBucketEncryption .\nCLI\nAWS CLI\nTo delete the server-side encryption con\ufb01guration of a bucket\nThe following delete-bucket-encryption  example deletes the server-side encryption \ncon\ufb01guration of the speci\ufb01ed bucket.\naws s3api delete-bucket-encryption \\ \n    --bucket my-bucket\nThis command produces no output.\nBasics API Version 2006-03-01 1889Amazon Simple Storage Service API Reference\n\u2022For API details, see DeleteBucketEncryption in AWS CLI Command Reference.\nPowerShell\nTools for PowerShell\nExample 1: This disables the encryption enabled for the S3 bucket provided.\nRemove-S3BucketEncryption -BucketName 'amzn-s3-demo-bucket'\nOutput:\nConfirm\nAre you sure you want to perform this action?\nPerforming the operation \"Remove-S3BucketEncryption (DeleteBucketEncryption)\" on \n target \"s3casetestbucket\".\n[Y] Yes  [A] Yes to All  [N] No  [L] No to All  [S] Suspend  [?] Help (default is \n \"Y\"): Y\n\u2022For API details, see DeleteBucketEncryption in AWS Tools for PowerShell Cmdlet Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nUse DeleteBucketInventoryConfiguration  with a CLI\nThe following code examples show how to use DeleteBucketInventoryConfiguration .\nCLI\nAWS CLI\nTo delete the inventory con\ufb01guration of a bucket\nThe following delete-bucket-inventory-configuration  example deletes the \ninventory con\ufb01guration with ID 1 for the speci\ufb01ed bucket.\naws s3api delete-bucket-inventory-configuration \\ \nBasics API Version 2006-03-01 1890Amazon Simple Storage Service API Reference\n    --bucket my-bucket  \\ \n    --id 1\nThis command produces no output.\n\u2022For API details, see DeleteBucketInventoryCon\ufb01guration in AWS CLI Command Reference.\nPowerShell\nTools for PowerShell\nExample 1: This command removes the invventory named 'testInventoryName' \ncorresponding to the given S3 bucket.\nRemove-S3BucketInventoryConfiguration -BucketName 'amzn-s3-demo-bucket' -\nInventoryId 'testInventoryName'\nOutput:\nConfirm\nAre you sure you want to perform this action?\nPerforming the operation \"Remove-S3BucketInventoryConfiguration \n (DeleteBucketInventoryConfiguration)\" on target \"s3testbucket\".\n[Y] Yes  [A] Yes to All  [N] No  [L] No to All  [S] Suspend  [?] Help (default is \n \"Y\"): Y\n\u2022For API details, see DeleteBucketInventoryCon\ufb01guration in AWS Tools for PowerShell \nCmdlet Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nUse DeleteBucketLifecycle  with an AWS SDK or CLI\nThe following code examples show how to use DeleteBucketLifecycle .\nBasics API Version 2006-03-01 1891Amazon Simple Storage Service API Reference\n.NET\nAWS SDK for .NET\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n        /// <summary> \n        /// This method removes the Lifecycle configuration from the named \n        /// S3 bucket. \n        /// </summary> \n        /// <param name=\"client\">The S3 client object used to call \n        /// the RemoveLifecycleConfigAsync method.</param> \n        /// <param name=\"bucketName\">A string representing the name of the \n        /// S3 bucket from which the configuration will be removed.</param> \n        public static async Task RemoveLifecycleConfigAsync(IAmazonS3 client, \n string bucketName) \n        { \n            var request = new DeleteLifecycleConfigurationRequest() \n            { \n                BucketName = bucketName, \n            }; \n            await client.DeleteLifecycleConfigurationAsync(request); \n        }\n\u2022For API details, see DeleteBucketLifecycle in AWS SDK for .NET API Reference.\nCLI\nAWS CLI\nThe following command deletes a lifecycle con\ufb01guration from a bucket named my-bucket :\naws s3api delete-bucket-lifecycle --bucket my-bucket\nBasics API Version 2006-03-01 1892Amazon Simple Storage Service API Reference\n\u2022For API details, see DeleteBucketLifecycle in AWS CLI Command Reference.\nPython\nSDK for Python (Boto3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nclass BucketWrapper: \n    \"\"\"Encapsulates S3 bucket actions.\"\"\" \n    def __init__(self, bucket): \n        \"\"\" \n        :param bucket: A Boto3 Bucket resource. This is a high-level resource in \n Boto3 \n                       that wraps bucket actions in a class-like structure. \n        \"\"\" \n        self.bucket = bucket \n        self.name = bucket.name \n    def delete_lifecycle_configuration(self): \n        \"\"\" \n        Remove the lifecycle configuration from the specified bucket. \n        \"\"\" \n        try: \n            self.bucket.LifecycleConfiguration().delete() \n            logger.info( \n                \"Deleted lifecycle configuration for bucket '%s'.\", \n self.bucket.name \n            ) \n        except ClientError: \n            logger.exception( \n                \"Couldn't delete lifecycle configuration for bucket '%s'.\", \n                self.bucket.name, \n            ) \n            raise\nBasics API Version 2006-03-01 1893Amazon Simple Storage Service API Reference\n\u2022For API details, see DeleteBucketLifecycle in AWS SDK for Python (Boto3) API Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nUse DeleteBucketMetricsConfiguration  with a CLI\nThe following code examples show how to use DeleteBucketMetricsConfiguration .\nCLI\nAWS CLI\nTo delete a metrics con\ufb01guration for a bucket\nThe following delete-bucket-metrics-configuration  example removes the metrics \ncon\ufb01guration for the speci\ufb01ed bucket and ID.\naws s3api delete-bucket-metrics-configuration \\ \n    --bucket my-bucket  \\ \n    --id 123\nThis command produces no output.\n\u2022For API details, see DeleteBucketMetricsCon\ufb01guration in AWS CLI Command Reference.\nPowerShell\nTools for PowerShell\nExample 1: The command removes the metrics \ufb01lter with name 'testmetrics' in the given \nS3 bucket.\nRemove-S3BucketMetricsConfiguration -BucketName 'amzn-s3-demo-bucket' -MetricsId \n 'testmetrics'\n\u2022For API details, see DeleteBucketMetricsCon\ufb01guration in AWS Tools for PowerShell Cmdlet \nReference.\nBasics API Version 2006-03-01 1894Amazon Simple Storage Service API Reference\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nUse DeleteBucketPolicy  with an AWS SDK or CLI\nThe following code examples show how to use DeleteBucketPolicy .\nC++\nSDK for C++\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nbool AwsDoc::S3::deleteBucketPolicy(const Aws::String &bucketName, \n                                    const Aws::S3::S3ClientConfiguration \n &clientConfig) { \n    Aws::S3::S3Client client(clientConfig); \n    Aws::S3::Model::DeleteBucketPolicyRequest request; \n    request.SetBucket(bucketName); \n    Aws::S3::Model::DeleteBucketPolicyOutcome outcome = \n client.DeleteBucketPolicy(request); \n    if (!outcome.IsSuccess()) { \n        const Aws::S3::S3Error &err = outcome.GetError(); \n        std::cerr << \"Error: deleteBucketPolicy: \" << \n                  err.GetExceptionName() << \": \" << err.GetMessage() << \n std::endl; \n    } else { \n        std::cout << \"Policy was deleted from the bucket.\" << std::endl; \n    } \n    return outcome.IsSuccess();\n}\nBasics API Version 2006-03-01 1895Amazon Simple Storage Service API Reference\n\u2022For API details, see DeleteBucketPolicy in AWS SDK for C++ API Reference.\nCLI\nAWS CLI\nThe following command deletes a bucket policy from a bucket named my-bucket :\naws s3api delete-bucket-policy --bucket my-bucket\n\u2022For API details, see DeleteBucketPolicy in AWS CLI Command Reference.\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nimport software.amazon.awssdk.services.s3.model.S3Exception;\nimport software.amazon.awssdk.regions.Region;\nimport software.amazon.awssdk.services.s3.S3Client;\nimport software.amazon.awssdk.services.s3.model.DeleteBucketPolicyRequest;\n/** \n * Before running this Java V2 code example, set up your development \n * environment, including your credentials. \n * \n * For more information, see the following documentation topic: \n * \n * https://docs.aws.amazon.com/sdk-for-java/latest/developer-guide/get-\nstarted.html \n */\npublic class DeleteBucketPolicy { \n    public static void main(String[] args) { \n        final String usage = \"\"\" \nBasics API Version 2006-03-01 1896Amazon Simple Storage Service API Reference\n                Usage: \n                    <bucketName> \n                Where: \n                    bucketName - The Amazon S3 bucket to delete the policy from \n (for example, bucket1).\"\"\"; \n        if (args.length != 1) { \n            System.out.println(usage); \n            System.exit(1); \n        } \n        String bucketName = args[0]; \n        System.out.format(\"Deleting policy from bucket: \\\"%s\\\"\\n\\n\", bucketName); \n        Region region = Region.US_EAST_1; \n        S3Client s3 = S3Client.builder() \n                .region(region) \n                .build(); \n        deleteS3BucketPolicy(s3, bucketName); \n        s3.close(); \n    } \n    /** \n     * Deletes the S3 bucket policy for the specified bucket. \n     * \n     * @param s3 the {@link S3Client} instance to use for the operation \n     * @param bucketName the name of the S3 bucket for which the policy should be \n deleted \n     * \n     * @throws S3Exception if there is an error deleting the bucket policy \n     */ \n    public static void deleteS3BucketPolicy(S3Client s3, String bucketName) { \n        DeleteBucketPolicyRequest delReq = DeleteBucketPolicyRequest.builder() \n                .bucket(bucketName) \n                .build(); \n        try { \n            s3.deleteBucketPolicy(delReq); \n            System.out.println(\"Done!\"); \n        } catch (S3Exception e) { \n            System.err.println(e.awsErrorDetails().errorMessage()); \nBasics API Version 2006-03-01 1897Amazon Simple Storage Service API Reference\n            System.exit(1); \n        } \n    }\n}\n\u2022For API details, see DeleteBucketPolicy in AWS SDK for Java 2.x API Reference.\nJavaScript\nSDK for JavaScript (v3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nDelete the bucket policy.\nimport { \n  DeleteBucketPolicyCommand, \n  S3Client, \n  S3ServiceException,\n} from \"@aws-sdk/client-s3\";\n/** \n * Remove the policy from an Amazon S3 bucket. \n * @param {{ bucketName: string }} \n */\nexport const main = async ({ bucketName }) => { \n  const client = new S3Client({}); \n  try { \n    await client.send( \n      new DeleteBucketPolicyCommand({ \n        Bucket: bucketName, \n      }), \n    ); \n    console.log(`Bucket policy deleted from \"${bucketName}\".`); \n  } catch (caught) { \n    if ( \nBasics API Version 2006-03-01 1898Amazon Simple Storage Service API Reference\n      caught instanceof S3ServiceException && \n      caught.name === \"NoSuchBucket\" \n    ) { \n      console.error( \n        `Error from S3 while deleting policy from ${bucketName}. The bucket \n doesn't exist.`, \n      ); \n    } else if (caught instanceof S3ServiceException) { \n      console.error( \n        `Error from S3 while deleting policy from ${bucketName}.", "${caught.name}: \n ${caught.message}`, \n      ); \n    } else { \n      throw caught; \n    } \n  }\n};\n\u2022For more information, see AWS SDK for JavaScript Developer Guide.\n\u2022For API details, see DeleteBucketPolicy in AWS SDK for JavaScript API Reference.\nKotlin\nSDK for Kotlin\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nsuspend fun deleteS3BucketPolicy(bucketName: String?) { \n    val request = \n        DeleteBucketPolicyRequest { \n            bucket = bucketName \n        } \n    S3Client { region = \"us-east-1\" }.use { s3 -> \n        s3.deleteBucketPolicy(request) \n        println(\"Done!\") \nBasics API Version 2006-03-01 1899Amazon Simple Storage Service API Reference\n    }\n}\n\u2022For API details, see DeleteBucketPolicy in AWS SDK for Kotlin API reference.\nPowerShell\nTools for PowerShell\nExample 1: The command removes the bucket policy associated with the given S3 bucket.\nRemove-S3BucketPolicy -BucketName 'amzn-s3-demo-bucket'\n\u2022For API details, see DeleteBucketPolicy in AWS Tools for PowerShell Cmdlet Reference.\nPython\nSDK for Python (Boto3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nclass BucketWrapper: \n    \"\"\"Encapsulates S3 bucket actions.\"\"\" \n    def __init__(self, bucket): \n        \"\"\" \n        :param bucket: A Boto3 Bucket resource. This is a high-level resource in \n Boto3 \n                       that wraps bucket actions in a class-like structure.", "\n        \"\"\" \n        self.bucket = bucket \n        self.name = bucket.name \n    def delete_policy(self): \nBasics API Version 2006-03-01 1900Amazon Simple Storage Service API Reference\n        \"\"\" \n        Delete the security policy from the bucket. \n        \"\"\" \n        try: \n            self.bucket.Policy().delete() \n            logger.info(\"Deleted policy for bucket '%s'.\", self.bucket.name) \n        except ClientError: \n            logger.exception( \n                \"Couldn't delete policy for bucket '%s'.\", self.bucket.name \n            ) \n            raise\n\u2022For API details, see DeleteBucketPolicy in AWS SDK for Python (Boto3) API Reference.\nRuby\nSDK for Ruby\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n# Wraps an Amazon S3 bucket policy.\nclass BucketPolicyWrapper \n  attr_reader :bucket_policy \n  # @param bucket_policy [Aws::S3::BucketPolicy] A bucket policy object \n configured with an existing bucket. \n  def initialize(bucket_policy) \n    @bucket_policy = bucket_policy \n  end \n  def delete_policy \n    @bucket_policy.delete \n    true \n  rescue Aws::Errors::ServiceError => e \n    puts \"Couldn't delete the policy from #{@bucket_policy.bucket.name}.", "Here's \n why: #{e.message}\" \nBasics API Version 2006-03-01 1901Amazon Simple Storage Service API Reference\n    false \n  end\nend\n\u2022For API details, see DeleteBucketPolicy in AWS SDK for Ruby API Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nUse DeleteBucketReplication  with a CLI\nThe following code examples show how to use DeleteBucketReplication .\nCLI\nAWS CLI\nThe following command deletes a replication con\ufb01guration from a bucket named my-\nbucket :\naws s3api delete-bucket-replication --bucket my-bucket\n\u2022For API details, see DeleteBucketReplication in AWS CLI Command Reference.\nPowerShell\nTools for PowerShell\nExample 1: Deletes the replication con\ufb01guration associated with the bucket \nnamed 'mybucket'.", "Note that this operation requires permission for the \ns3:DeleteReplicationCon\ufb01guration action. You will be prompted for con\ufb01rmation before \nthe operation proceeds - to suppress con\ufb01rmation, use the -Force switch.\nRemove-S3BucketReplication -BucketName amzn-s3-demo-bucket\n\u2022For API details, see DeleteBucketReplication in AWS Tools for PowerShell Cmdlet Reference.\nBasics API Version 2006-03-01 1902Amazon Simple Storage Service API Reference\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nUse DeleteBucketTagging  with a CLI\nThe following code examples show how to use DeleteBucketTagging .\nCLI\nAWS CLI\nThe following command deletes a tagging con\ufb01guration from a bucket named my-bucket :\naws s3api delete-bucket-tagging --bucket my-bucket\n\u2022For API details, see DeleteBucketTagging in AWS CLI Command Reference.\nPowerShell\nTools for PowerShell\nExample 1: This command removes all the tags associated with the given S3 bucket.\nRemove-S3BucketTagging -BucketName 'amzn-s3-demo-bucket'\nOutput:\nConfirm\nAre you sure you want to perform this action?\nPerforming the operation \"Remove-S3BucketTagging (DeleteBucketTagging)\" on target \n \"s3testbucket\".\n[Y] Yes  [A] Yes to All  [N] No  [L] No to All  [S] Suspend  [?] Help (default is \n \"Y\"): Y\n\u2022For API details, see DeleteBucketTagging in AWS Tools for PowerShell Cmdlet Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nBasics API Version 2006-03-01 1903Amazon Simple Storage Service API Reference\nUse DeleteBucketWebsite  with an AWS SDK or CLI\nThe following code examples show how to use DeleteBucketWebsite .\nC++\nSDK for C++\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nbool AwsDoc::S3::deleteBucketWebsite(const Aws::String &bucketName, \n                                     const Aws::S3::S3ClientConfiguration \n &clientConfig) { \n    Aws::S3::S3Client client(clientConfig); \n    Aws::S3::Model::DeleteBucketWebsiteRequest request; \n    request.SetBucket(bucketName); \n    Aws::S3::Model::DeleteBucketWebsiteOutcome outcome = \n            client.DeleteBucketWebsite(request); \n    if (!outcome.IsSuccess()) { \n        auto err = outcome.GetError(); \n        std::cerr << \"Error: deleteBucketWebsite: \" << \n                  err.GetExceptionName() << \": \" << err.GetMessage() << \n std::endl; \n    } else { \n        std::cout << \"Website configuration was removed.\" << std::endl; \n    } \n    return outcome.IsSuccess();\n}\n\u2022For API details, see DeleteBucketWebsite in AWS SDK for C++ API Reference.\nBasics API Version 2006-03-01 1904Amazon Simple Storage Service API Reference\nCLI\nAWS CLI\nThe following command deletes a website con\ufb01guration from a bucket named my-bucket :\naws s3api delete-bucket-website --bucket my-bucket\n\u2022For API details, see DeleteBucketWebsite in AWS CLI Command Reference.\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nimport software.amazon.awssdk.regions.Region;\nimport software.amazon.awssdk.services.s3.S3Client;\nimport software.amazon.awssdk.services.s3.model.DeleteBucketWebsiteRequest;\nimport software.amazon.awssdk.services.s3.model.S3Exception;\n/** \n * Before running this Java V2 code example, set up your development \n * environment, including your credentials. \n * <p> \n * For more information, see the following documentation topic: \n * <p> \n * https://docs.aws.amazon.com/sdk-for-java/latest/developer-guide/get-\nstarted.html \n */\npublic class DeleteWebsiteConfiguration { \n    public static void main(String[] args) { \n        final String usage = \"\"\" \n            Usage:     <bucketName> \nBasics API Version 2006-03-01 1905Amazon Simple Storage Service API Reference\n            Where: \n                bucketName - The Amazon S3 bucket to delete the website \n configuration from. \n            \"\"\"; \n        if (args.length != 1) { \n            System.out.println(usage); \n            System.exit(1); \n        } \n        String bucketName = args[0]; \n        System.out.format(\"Deleting website configuration for Amazon S3 bucket: \n %s\\n\", bucketName); \n        Region region = Region.US_EAST_1; \n        S3Client s3 = S3Client.builder() \n            .region(region) \n            .build(); \n        deleteBucketWebsiteConfig(s3, bucketName); \n        System.out.println(\"Done!\"); \n        s3.close(); \n    } \n    /** \n     * Deletes the website configuration for an Amazon S3 bucket. \n     * \n     * @param s3 The {@link S3Client} instance used to interact with Amazon S3. \n     * @param bucketName The name of the S3 bucket for which the website \n configuration should be deleted. \n     * @throws S3Exception If an error occurs while deleting the website \n configuration. \n     */ \n    public static void deleteBucketWebsiteConfig(S3Client s3, String bucketName) \n { \n        DeleteBucketWebsiteRequest delReq = DeleteBucketWebsiteRequest.builder() \n            .bucket(bucketName) \n            .build(); \n        try { \n            s3.deleteBucketWebsite(delReq); \n        } catch (S3Exception e) { \n            System.err.println(e.awsErrorDetails().errorMessage()); \nBasics API Version 2006-03-01 1906Amazon Simple Storage Service API Reference\n            System.out.println(\"Failed to delete website configuration!\"); \n            System.exit(1); \n        } \n    }\n}\n\u2022For API details, see DeleteBucketWebsite in AWS SDK for Java 2.x API Reference.\nJavaScript\nSDK for JavaScript (v3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nDelete the website con\ufb01guration from the bucket.\nimport { \n  DeleteBucketWebsiteCommand, \n  S3Client, \n  S3ServiceException,\n} from \"@aws-sdk/client-s3\";\n/** \n * Remove the website configuration for a bucket. \n * @param {{ bucketName: string }} \n */\nexport const main = async ({ bucketName }) => { \n  const client = new S3Client({}); \n  try { \n    await client.send( \n      new DeleteBucketWebsiteCommand({ \n        Bucket: bucketName, \n      }), \n    ); \n    // The response code will be successful for both removed configurations and \n    // configurations that did not exist in the first place. \nBasics API Version 2006-03-01 1907Amazon Simple Storage Service API Reference\n    console.log( \n      `The bucket \"${bucketName}\" is not longer configured as a website, or it \n never was.`, \n    ); \n  } catch (caught) { \n    if ( \n      caught instanceof S3ServiceException && \n      caught.name === \"NoSuchBucket\" \n    ) { \n      console.error( \n        `Error from S3 while removing website configuration from ${bucketName}. \n The bucket doesn't exist.`, \n      ); \n    } else if (caught instanceof S3ServiceException) { \n      console.error( \n        `Error from S3 while removing website configuration from ${bucketName}. \n ${caught.name}: ${caught.message}`, \n      ); \n    } else { \n      throw caught; \n    } \n  }\n};\n\u2022For more information, see AWS SDK for JavaScript Developer Guide.\n\u2022For API details, see DeleteBucketWebsite in AWS SDK for JavaScript API Reference.\nPowerShell\nTools for PowerShell\nExample 1: This command disables the static website hosting property of the given S3 \nbucket.\nRemove-S3BucketWebsite -BucketName 'amzn-s3-demo-bucket'\nOutput:\nConfirm\nAre you sure you want to perform this action?\nBasics API Version 2006-03-01 1908Amazon Simple Storage Service API Reference\nPerforming the operation \"Remove-S3BucketWebsite (DeleteBucketWebsite)\" on target \n \"s3testbucket\".\n[Y] Yes  [A] Yes to All  [N] No  [L] No to All  [S] Suspend  [?] Help (default is \n \"Y\"): Y\n\u2022For API details, see DeleteBucketWebsite in AWS Tools for PowerShell Cmdlet Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nUse DeleteObject  with an AWS SDK or CLI\nThe following code examples show how to use DeleteObject .\nAction examples are code excerpts from larger programs and must be run in context. You can see \nthis action in context in the following code examples:\n\u2022Work with Amazon S3 object integrity\n\u2022Work with versioned objects\n.NET\nAWS SDK for .NET\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nDelete an object in a non-versioned S3 bucket.\n    using System; \n    using System.Threading.Tasks; \n    using Amazon.S3; \n    using Amazon.S3.Model; \n    /// <summary> \n    /// This example shows how to delete an object from a non-versioned Amazon \nBasics API Version 2006-03-01 1909Amazon Simple Storage Service API Reference\n    /// Simple Storage Service (Amazon S3) bucket.", "\n    /// </summary> \n    public class DeleteObject \n    { \n        /// <summary> \n        /// The Main method initializes the necessary variables and then calls \n        /// the DeleteObjectNonVersionedBucketAsync method to delete the object \n        /// named by the keyName parameter.", "\n        /// </summary> \n        public static async Task Main() \n        { \n            const string bucketName = \"amzn-s3-demo-bucket\"; \n            const string keyName = \"testfile.txt\"; \n            // If the Amazon S3 bucket is located in an AWS Region other than the \n            // Region of the default account, define the AWS Region for the \n            // Amazon S3 bucket in your call to the AmazonS3Client constructor.", "\n            // For example RegionEndpoint.USWest2.", "\n            IAmazonS3 client = new AmazonS3Client(); \n            await DeleteObjectNonVersionedBucketAsync(client, bucketName, \n keyName); \n        } \n        /// <summary> \n        /// The DeleteObjectNonVersionedBucketAsync takes care of deleting the \n        /// desired object from the named bucket. \n        /// </summary> \n        /// <param name=\"client\">An initialized Amazon S3 client used to delete \n        /// an object from an Amazon S3 bucket.</param> \n        /// <param name=\"bucketName\">The name of the bucket from which the \n        /// object will be deleted.</param> \n        /// <param name=\"keyName\">The name of the object to delete.</param> \n        public static async Task DeleteObjectNonVersionedBucketAsync(IAmazonS3 \n client, string bucketName, string keyName) \n        { \n            try \n            { \n                var deleteObjectRequest = new DeleteObjectRequest \n                { \n                    BucketName = bucketName, \n                    Key = keyName, \n                }; \n                Console.WriteLine($\"Deleting object: {keyName}\"); \nBasics API Version 2006-03-01 1910Amazon Simple Storage Service API Reference\n                await client.DeleteObjectAsync(deleteObjectRequest); \n                Console.WriteLine($\"Object: {keyName} deleted from \n {bucketName}.\"); \n            } \n            catch (AmazonS3Exception ex) \n            { \n                Console.WriteLine($\"Error encountered on server. \n Message:'{ex.Message}' when deleting an object.\"); \n            } \n        } \n    }\nDelete an object in a versioned S3 bucket.\n    using System; \n    using System.Threading.Tasks; \n    using Amazon.S3; \n    using Amazon.S3.Model; \n    /// <summary> \n    /// This example creates an object in an Amazon Simple Storage Service \n    /// (Amazon S3) bucket and then deletes the object version that was \n    /// created. \n    /// </summary> \n    public class DeleteObjectVersion \n    { \n        public static async Task Main() \n        { \n            string bucketName = \"amzn-s3-demo-bucket\"; \n            string keyName = \"verstioned-object.txt\"; \n            // If the AWS Region of the default user is different from the AWS \n            // Region of the Amazon S3 bucket, pass the AWS Region of the \n            // bucket region to the Amazon S3 client object's constructor. \n            // Define it like this: \n            //      RegionEndpoint bucketRegion = RegionEndpoint.USWest2; \n            IAmazonS3 client = new AmazonS3Client(); \n            await CreateAndDeleteObjectVersionAsync(client, bucketName, keyName); \n        } \nBasics API Version 2006-03-01 1911Amazon Simple Storage Service API Reference\n        /// <summary> \n        /// This method creates and then deletes a versioned object. \n        /// </summary> \n        /// <param name=\"client\">The initialized Amazon S3 client object used to \n        /// create and delete the object.</param> \n        /// <param name=\"bucketName\">The name of the Amazon S3 bucket where the \n        /// object will be created and deleted.</param> \n        /// <param name=\"keyName\">The key name of the object to create.</param> \n        public static async Task CreateAndDeleteObjectVersionAsync(IAmazonS3 \n client, string bucketName, string keyName) \n        { \n            try \n            { \n                // Add a sample object.", "\n                string versionID = await PutAnObject(client, bucketName, \n keyName); \n                // Delete the object by specifying an object key and a version \n ID. \n                DeleteObjectRequest request = new DeleteObjectRequest() \n                { \n                    BucketName = bucketName, \n                    Key = keyName, \n                    VersionId = versionID, \n                }; \n                Console.WriteLine(\"Deleting an object\"); \n                await client.DeleteObjectAsync(request); \n            } \n            catch (AmazonS3Exception ex) \n            { \n                Console.WriteLine($\"Error: {ex.Message}\"); \n            } \n        } \n        /// <summary> \n        /// This method is used to create the temporary Amazon S3 object. \n        /// </summary> \n        /// <param name=\"client\">The initialized Amazon S3 object which will be \n used \n        /// to create the temporary Amazon S3 object.</param> \n        /// <param name=\"bucketName\">The name of the Amazon S3 bucket where the \n object \n        /// will be created.</param> \nBasics API Version 2006-03-01 1912Amazon Simple Storage Service API Reference\n        /// <param name=\"objectKey\">The name of the Amazon S3 object co create.</\nparam> \n        /// <returns>The Version ID of the created object.</returns> \n        public static async Task<string> PutAnObject(IAmazonS3 client, string \n bucketName, string objectKey) \n        { \n            PutObjectRequest request = new PutObjectRequest() \n            { \n                BucketName = bucketName, \n                Key = objectKey, \n                ContentBody = \"This is the content body!\", \n            }; \n            PutObjectResponse response = await client.PutObjectAsync(request); \n            return response.VersionId; \n        } \n    }\n\u2022For API details, see DeleteObject in AWS SDK for .NET API Reference.\nBash\nAWS CLI with Bash script\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n###############################################################################\n# function errecho\n#\n# This function outputs everything sent to it to STDERR (standard error output).\n###############################################################################\nfunction errecho() { \n  printf \"%s\\n\" \"$*\" 1>&2\n}\n###############################################################################\nBasics API Version 2006-03-01 1913Amazon Simple Storage Service API Reference\n# function delete_item_in_bucket\n#\n# This function deletes the specified file from the specified bucket.\n#\n# Parameters:\n#       $1 - The name of the bucket.\n#       $2 - The key (file name) in the bucket to delete.\n# Returns:\n#       0 - If successful.\n#       1 - If it fails.\n###############################################################################\nfunction delete_item_in_bucket() { \n  local bucket_name=$1 \n  local key=$2 \n  local response \n  response=$(aws s3api delete-object \\ \n    --bucket \"$bucket_name\" \\ \n    --key \"$key\") \n  # shellcheck disable=SC2181 \n  if [[ $?", "-ne 0 ]]; then \n    errecho \"ERROR:  AWS reports s3api delete-object operation failed.\\n\n$response\" \n    return 1 \n  fi\n}\n\u2022For API details, see DeleteObject in AWS CLI Command Reference.\nC++\nSDK for C++\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nBasics API Version 2006-03-01 1914Amazon Simple Storage Service API Reference\nbool AwsDoc::S3::deleteObject(const Aws::String &objectKey, \n                              const Aws::String &fromBucket, \n                              const Aws::S3::S3ClientConfiguration &clientConfig) \n { \n    Aws::S3::S3Client client(clientConfig); \n    Aws::S3::Model::DeleteObjectRequest request; \n    request.WithKey(objectKey) \n            .WithBucket(fromBucket); \n    Aws::S3::Model::DeleteObjectOutcome outcome = \n            client.DeleteObject(request); \n    if (!outcome.IsSuccess()) { \n        auto err = outcome.GetError(); \n        std::cerr << \"Error: deleteObject: \" << \n                  err.GetExceptionName() << \": \" << err.GetMessage() << \n std::endl; \n    } else { \n        std::cout << \"Successfully deleted the object.\" << std::endl; \n    } \n    return outcome.IsSuccess();\n}\n\u2022For API details, see DeleteObject in AWS SDK for C++ API Reference.\nCLI\nAWS CLI\nThe following command deletes an object named test.txt  from a bucket named my-\nbucket :\naws s3api delete-object --bucket my-bucket  --key test.txt\nIf bucket versioning is enabled, the output will contain the version ID of the delete marker:\n{ \n  \"VersionId\": \"9_gKg5vG56F.TTEUdwkxGpJ3tNDlWlGq\", \n  \"DeleteMarker\": true\nBasics API Version 2006-03-01 1915Amazon Simple Storage Service API Reference\n}\nFor more information about deleting objects, see Deleting Objects in the Amazon S3 \nDeveloper Guide .\n\u2022For API details, see DeleteObject in AWS CLI Command Reference.\nGo\nSDK for Go V2\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n// S3Actions wraps S3 service actions.\ntype S3Actions struct { \n S3Client  *s3.Client \n S3Manager *manager.Uploader\n}\n// DeleteObject deletes an object from a bucket.\nfunc (actor S3Actions) DeleteObject(ctx context.Context, bucket string, key \n string, versionId string, bypassGovernance bool) (bool, error) { \n deleted := false \n input := &s3.DeleteObjectInput{ \n  Bucket: aws.String(bucket), \n  Key:    aws.String(key), \n } \n if versionId != \"\" { \n  input.VersionId = aws.String(versionId) \n } \n if bypassGovernance { \n  input.BypassGovernanceRetention = aws.Bool(true) \n } \n _, err := actor.S3Client.DeleteObject(ctx, input) \n if err != nil { \nBasics API Version 2006-03-01 1916Amazon Simple Storage Service API Reference\n  var noKey *types.NoSuchKey \n  var apiErr *smithy.GenericAPIError \n  if errors.As(err, &noKey) { \n   log.Printf(\"Object %s does not exist in %s.\\n\", key, bucket) \n   err = noKey \n  } else if errors.As(err, &apiErr) { \n   switch apiErr.ErrorCode() { \n   case \"AccessDenied\": \n    log.Printf(\"Access denied: cannot delete object %s from %s.\\n\", key, bucket) \n    err = nil \n   case \"InvalidArgument\": \n    if bypassGovernance { \n     log.Printf(\"You cannot specify bypass governance on a bucket without lock \n enabled.\") \n     err = nil \n    } \n   } \n  } \n } else { \n  deleted = true \n } \n return deleted, err\n}\n\u2022For API details, see DeleteObject in AWS SDK for Go API Reference.\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n    /** \n     * Deletes an object from an S3 bucket asynchronously. \n     * \nBasics API Version 2006-03-01 1917Amazon Simple Storage Service API Reference\n     * @param bucketName the name of the S3 bucket \n     * @param key        the key (file name) of the object to be deleted \n     * @return a {@link CompletableFuture} that completes when the object has \n been deleted \n     */ \n    public CompletableFuture<Void> deleteObjectFromBucketAsync(String bucketName, \n String key) { \n        DeleteObjectRequest deleteObjectRequest = DeleteObjectRequest.builder() \n            .bucket(bucketName) \n            .key(key) \n            .build(); \n        CompletableFuture<DeleteObjectResponse> response = \n getAsyncClient().deleteObject(deleteObjectRequest); \n        response.whenComplete((deleteRes, ex) -> { \n            if (deleteRes != null) { \n                logger.info(key + \" was deleted\"); \n            } else { \n                throw new RuntimeException(\"An S3 exception occurred during \n delete\", ex); \n            } \n        }); \n        return response.thenApply(r -> null); \n    }\n\u2022For API details, see DeleteObject in AWS SDK for Java 2.x API Reference.\nJavaScript\nSDK for JavaScript (v3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nDelete an object.\nimport { \nBasics API Version 2006-03-01 1918Amazon Simple Storage Service API Reference\n  DeleteObjectCommand, \n  S3Client, \n  S3ServiceException, \n  waitUntilObjectNotExists,\n} from \"@aws-sdk/client-s3\";\n/** \n * Delete one object from an Amazon S3 bucket. \n * @param {{ bucketName: string, key: string }} \n */\nexport const main = async ({ bucketName, key }) => { \n  const client = new S3Client({}); \n  try { \n    await client.send( \n      new DeleteObjectCommand({ \n        Bucket: bucketName, \n        Key: key, \n      }), \n    ); \n    await waitUntilObjectNotExists( \n      { client }, \n      { Bucket: bucketName, Key: key }, \n    ); \n    // A successful delete, or a delete for a non-existent object, both return \n    // a 204 response code. \n    console.log( \n      `The object \"${key}\" from bucket \"${bucketName}\" was deleted, or it didn't \n exist.`, \n    ); \n  } catch (caught) { \n    if ( \n      caught instanceof S3ServiceException && \n      caught.name === \"NoSuchBucket\" \n    ) { \n      console.error( \n        `Error from S3 while deleting object from ${bucketName}. The bucket \n doesn't exist.`, \n      ); \n    } else if (caught instanceof S3ServiceException) { \n      console.error( \n        `Error from S3 while deleting object from ${bucketName}.", "${caught.name}: \n ${caught.message}`, \n      ); \nBasics API Version 2006-03-01 1919Amazon Simple Storage Service API Reference\n    } else { \n      throw caught; \n    } \n  }\n};\n\u2022For API details, see DeleteObject in AWS SDK for JavaScript API Reference.\nPython\nSDK for Python (Boto3)\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nDelete an object.\nclass ObjectWrapper: \n    \"\"\"Encapsulates S3 object actions.\"\"\" \n    def __init__(self, s3_object): \n        \"\"\" \n        :param s3_object: A Boto3 Object resource. This is a high-level resource \n in Boto3 \n                          that wraps object actions in a class-like structure.", "\n        \"\"\" \n        self.object = s3_object \n        self.key = self.object.key \n    def delete(self): \n        \"\"\" \n        Deletes the object.", "\n        \"\"\" \n        try: \n            self.object.delete() \n            self.object.wait_until_not_exists() \n            logger.info( \nBasics API Version 2006-03-01 1920Amazon Simple Storage Service API Reference\n                \"Deleted object '%s' from bucket '%s'.\", \n                self.object.key, \n                self.object.bucket_name, \n            ) \n        except ClientError: \n            logger.exception( \n                \"Couldn't delete object '%s' from bucket '%s'.\", \n                self.object.key, \n                self.object.bucket_name, \n            ) \n            raise\nRoll an object back to a previous version by deleting later versions of the object.\ndef rollback_object(bucket, object_key, version_id): \n    \"\"\" \n    Rolls back an object to an earlier version by deleting all versions that \n    occurred after the specified rollback version.", "\n    Usage is shown in the usage_demo_single_object function at the end of this \n module.", "\n    :param bucket: The bucket that holds the object to roll back. \n    :param object_key: The object to roll back. \n    :param version_id: The version ID to roll back to.", "\n    \"\"\" \n    # Versions must be sorted by last_modified date because delete markers are \n    # at the end of the list even when they are interspersed in time. \n    versions = sorted( \n        bucket.object_versions.filter(Prefix=object_key), \n        key=attrgetter(\"last_modified\"), \n        reverse=True, \n    ) \n    logger.debug( \n        \"Got versions:\\n%s\", \n        \"\\n\".join( \n            [ \n                f\"\\t{version.version_id}, last modified {version.last_modified}\" \n                for version in versions \n            ] \nBasics API Version 2006-03-01 1921Amazon Simple Storage Service API Reference\n        ), \n    ) \n    if version_id in [ver.version_id for ver in versions]: \n        print(f\"Rolling back to version {version_id}\") \n        for version in versions: \n            if version.version_id != version_id: \n                version.delete() \n                print(f\"Deleted version {version.version_id}\") \n            else: \n                break \n        print(f\"Active version is now {bucket.Object(object_key).version_id}\") \n    else: \n        raise KeyError( \n            f\"{version_id} was not found in the list of versions for \" \n f\"{object_key}.\" \n        )\nRevive a deleted object by removing the object's active delete marker.\ndef revive_object(bucket, object_key): \n    \"\"\" \n    Revives a versioned object that was deleted by removing the object's active \n    delete marker.", "\n    A versioned object presents as deleted when its latest version is a delete \n marker. \n    By removing the delete marker, we make the previous version the latest \n version \n    and the object then presents as *not* deleted.", "\n    Usage is shown in the usage_demo_single_object function at the end of this \n module.", "\n    :param bucket: The bucket that contains the object.", "\n    :param object_key: The object to revive. \n    \"\"\" \n    # Get the latest version for the object.", "\n    response = s3.meta.client.list_object_versions( \n        Bucket=bucket.name, Prefix=object_key, MaxKeys=1 \nBasics API Version 2006-03-01 1922Amazon Simple Storage Service API Reference\n    ) \n    if \"DeleteMarkers\" in response: \n        latest_version = response[\"DeleteMarkers\"][0] \n        if latest_version[\"IsLatest\"]: \n            logger.info( \n                \"Object %s was indeed deleted on %s. Let's revive it.\", \n                object_key, \n                latest_version[\"LastModified\"], \n            ) \n            obj = bucket.Object(object_key) \n            obj.Version(latest_version[\"VersionId\"]).delete() \n            logger.info( \n                \"Revived %s, active version is now %s  with body '%s'\", \n                object_key, \n                obj.version_id, \n                obj.get()[\"Body\"].read(), \n            ) \n        else: \n            logger.warning( \n                \"Delete marker is not the latest version for %s!\", object_key \n            ) \n    elif \"Versions\" in response: \n        logger.warning(\"Got an active version for %s, nothing to do.\", \n object_key) \n    else: \n        logger.error(\"Couldn't get any version info for %s.\", object_key)\nCreate a Lambda handler that removes a delete marker from an S3 object. This handler can \nbe used to e\ufb03ciently clean up extraneous delete markers in a versioned bucket.\nimport logging\nfrom urllib import parse\nimport boto3\nfrom botocore.exceptions import ClientError\nlogger = logging.getLogger(__name__)\nlogger.setLevel(\"INFO\")\ns3 = boto3.client(\"s3\")\nBasics API Version 2006-03-01 1923Amazon Simple Storage Service API Reference\ndef lambda_handler(event, context): \n    \"\"\" \n    Removes a delete marker from the specified versioned object. \n    :param event: The S3 batch event that contains the ID of the delete marker \n                  to remove.", "\n    :param context: Context about the event.", "\n    :return: A result structure that Amazon S3 uses to interpret the result of \n the \n             operation. When the result code is TemporaryFailure, S3 retries the \n             operation. \n    \"\"\" \n    # Parse job parameters from Amazon S3 batch operations \n    invocation_id = event[\"invocationId\"] \n    invocation_schema_version = event[\"invocationSchemaVersion\"] \n    results = [] \n    result_code = None \n    result_string = None \n    task = event[\"tasks\"][0] \n    task_id = task[\"taskId\"] \n    try: \n        obj_key = parse.unquote(task[\"s3Key\"], encoding=\"utf-8\") \n        obj_version_id = task[\"s3VersionId\"] \n        bucket_name = task[\"s3BucketArn\"].split(\":\")[-1] \n        logger.info( \n            \"Got task: remove delete marker %s from object %s.\", obj_version_id, \n obj_key \n        ) \n        try: \n            # If this call does not raise an error, the object version is not a \n delete \n            # marker and should not be deleted. \n            response = s3.head_object( \n                Bucket=bucket_name, Key=obj_key, VersionId=obj_version_id \n            ) \n            result_code = \"PermanentFailure\" \n            result_string = ( \nBasics API Version 2006-03-01 1924Amazon Simple Storage Service API Reference\n                f\"Object {obj_key}, ID {obj_version_id} is not \" f\"a delete \n marker.\" \n            ) \n            logger.debug(response) \n            logger.warning(result_string) \n        except ClientError as error: \n            delete_marker = error.response[\"ResponseMetadata\"]\n[\"HTTPHeaders\"].get( \n                \"x-amz-delete-marker\", \"false\" \n            ) \n            if delete_marker == \"true\": \n                logger.info( \n                    \"Object %s, version %s is a delete marker.\", obj_key, \n obj_version_id \n                ) \n                try: \n                    s3.delete_object( \n                        Bucket=bucket_name, Key=obj_key, VersionId=obj_version_id \n                    ) \n                    result_code = \"Succeeded\" \n                    result_string = ( \n                        f\"Successfully removed delete marker \" \n                        f\"{obj_version_id} from object {obj_key}.\" \n                    ) \n                    logger.info(result_string) \n                except ClientError as error: \n                    # Mark request timeout as a temporary failure so it will be \n retried. \n                    if error.response[\"Error\"][\"Code\"] == \"RequestTimeout\": \n                        result_code = \"TemporaryFailure\" \n                        result_string = ( \n                            f\"Attempt to remove delete marker from  \" \n                            f\"object {obj_key} timed out.\" \n                        ) \n                        logger.info(result_string) \n                    else: \n                        raise \n            else: \n                raise ValueError( \n                    f\"The x-amz-delete-marker header is either not \" \n                    f\"present or is not 'true'.\" \n                ) \n    except Exception as error: \nBasics API Version 2006-03-01 1925Amazon Simple Storage Service API Reference\n        # Mark all other exceptions as permanent failures.", "\n        result_code = \"PermanentFailure\" \n        result_string = str(error) \n        logger.exception(error) \n    finally: \n        results.append( \n            { \n                \"taskId\": task_id, \n                \"resultCode\": result_code, \n                \"resultString\": result_string, \n            } \n        ) \n    return { \n        \"invocationSchemaVersion\": invocation_schema_version, \n        \"treatMissingKeysAs\": \"PermanentFailure\", \n        \"invocationId\": invocation_id, \n        \"results\": results, \n    }\n\u2022For API details, see DeleteObject in AWS SDK for Python (Boto3) API Reference.\nRust\nSDK for Rust\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n/// Delete an object from a bucket.\npub async fn remove_object( \n    client: &aws_sdk_s3::Client, \n    bucket: &str, \n    key: &str,\n) -> Result<(), S3ExampleError> { \n    client \n        .delete_object() \nBasics API Version 2006-03-01 1926Amazon Simple Storage Service API Reference\n        .bucket(bucket) \n        .key(key) \n        .send() \n        .await?; \n    // There are no modeled errors to handle when deleting an object.", "\n    Ok(())\n}\n\u2022For API details, see DeleteObject in AWS SDK for Rust API reference.\nSAP ABAP\nSDK for SAP ABAP\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n    TRY.", "\n        lo_s3->deleteobject( \n            iv_bucket = iv_bucket_name \n            iv_key = iv_object_key \n        ). \n        MESSAGE 'Object deleted from S3 bucket.' TYPE 'I'.", "\n      CATCH /aws1/cx_s3_nosuchbucket.", "\n        MESSAGE 'Bucket does not exist.' TYPE 'E'.", "\n    ENDTRY.\n\u2022For API details, see DeleteObject in AWS SDK for SAP ABAP API reference.\nBasics API Version 2006-03-01 1927Amazon Simple Storage Service API Reference\nSwift\nSDK for Swift\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nimport AWSS3 \n    public func deleteFile(bucket: String, key: String) async throws { \n        let input = DeleteObjectInput( \n            bucket: bucket, \n            key: key \n        ) \n        do { \n            _ = try await client.deleteObject(input: input) \n        } \n        catch { \n            print(\"ERROR: \", dump(error, name: \"Deleting a file.\")) \n            throw error \n        } \n    }\n\u2022For API details, see DeleteObject in AWS SDK for Swift API reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nUse DeleteObjectTagging  with a CLI\nThe following code examples show how to use DeleteObjectTagging .\nBasics API Version 2006-03-01 1928Amazon Simple Storage Service API Reference\nCLI\nAWS CLI\nTo delete the tag sets of an object\nThe following delete-object-tagging  example deletes the tag with the speci\ufb01ed key \nfrom the object doc1.rtf .\naws s3api delete-object-tagging \\ \n    --bucket my-bucket  \\ \n    --key doc1.rtf\nThis command produces no output.\n\u2022For API details, see DeleteObjectTagging in AWS CLI Command Reference.\nPowerShell\nTools for PowerShell\nExample 1: This command removes all the tags associated with the object with key \n'test\ufb01le.txt' in the given S3 Bucket.\nRemove-S3ObjectTagSet -Key 'testfile.txt' -BucketName 'amzn-s3-demo-bucket' -\nSelect '^Key'\nOutput:\nConfirm\nAre you sure you want to perform this action?\nPerforming the operation \"Remove-S3ObjectTagSet (DeleteObjectTagging)\" on target \n \"testfile.txt\".\n[Y] Yes  [A] Yes to All  [N] No  [L] No to All  [S] Suspend  [?] Help (default is \n \"Y\"): Y\ntestfile.txt\n\u2022For API details, see DeleteObjectTagging in AWS Tools for PowerShell Cmdlet Reference.\nBasics API Version 2006-03-01 1929Amazon Simple Storage Service API Reference\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nUse DeleteObjects  with an AWS SDK or CLI\nThe following code examples show how to use DeleteObjects .\nAction examples are code excerpts from larger programs and must be run in context. You can see \nthis action in context in the following code examples:\n\u2022Learn the basics\n\u2022Delete all objects in a bucket\n.NET\nAWS SDK for .NET\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nDelete all objects in an S3 bucket.\n        /// <summary> \n        /// Delete all of the objects stored in an existing Amazon S3 bucket. \n        /// </summary> \n        /// <param name=\"client\">An initialized Amazon S3 client object.</param> \n        /// <param name=\"bucketName\">The name of the bucket from which the \n        /// contents will be deleted.</param> \n        /// <returns>A boolean value that represents the success or failure of \n        /// deleting all of the objects in the bucket.</returns> \n        public static async Task<bool> DeleteBucketContentsAsync(IAmazonS3 \n client, string bucketName) \n        { \n            // Iterate over the contents of the bucket and delete all objects.", "\n            var request = new ListObjectsV2Request \n            { \nBasics API Version 2006-03-01 1930Amazon Simple Storage Service API Reference\n                BucketName = bucketName, \n            }; \n            try \n            { \n                ListObjectsV2Response response; \n                do \n                { \n                    response = await client.ListObjectsV2Async(request); \n                    response.S3Objects \n                        .ForEach(async obj => await \n client.DeleteObjectAsync(bucketName, obj.Key)); \n                    // If the response is truncated, set the request \n ContinuationToken \n                    // from the NextContinuationToken property of the response. \n                    request.ContinuationToken = response.NextContinuationToken; \n                } \n                while (response.IsTruncated); \n                return true; \n            } \n            catch (AmazonS3Exception ex) \n            { \n                Console.WriteLine($\"Error deleting objects: {ex.Message}\"); \n                return false; \n            } \n        }\nDelete multiple objects in a non-versioned S3 bucket.\n    using System; \n    using System.Collections.Generic; \n    using System.Threading.Tasks; \n    using Amazon.S3; \n    using Amazon.S3.Model; \n    /// <summary> \n    /// This example shows how to delete multiple objects from an Amazon Simple \n    /// Storage Service (Amazon S3) bucket. \nBasics API Version 2006-03-01 1931Amazon Simple Storage Service API Reference\n    /// </summary> \n    public class DeleteMultipleObjects \n    { \n        /// <summary> \n        /// The Main method initializes the Amazon S3 client and the name of \n        /// the bucket and then passes those values to MultiObjectDeleteAsync. \n        /// </summary> \n        public static async Task Main() \n        { \n            const string bucketName = \"amzn-s3-demo-bucket\"; \n            // If the Amazon S3 bucket from which you wish to delete objects is \n not \n            // located in the same AWS Region as the default user, define the \n            // AWS Region for the Amazon S3 bucket as a parameter to the client \n            // constructor. \n            IAmazonS3 s3Client = new AmazonS3Client(); \n            await MultiObjectDeleteAsync(s3Client, bucketName); \n        } \n        /// <summary> \n        /// This method uses the passed Amazon S3 client to first create and then \n        /// delete three files from the named bucket. \n        /// </summary> \n        /// <param name=\"client\">The initialized Amazon S3 client object used to \n call \n        /// Amazon S3 methods.</param> \n        /// <param name=\"bucketName\">The name of the Amazon S3 bucket where \n objects \n        /// will be created and then deleted.</param> \n        public static async Task MultiObjectDeleteAsync(IAmazonS3 client, string \n bucketName) \n        { \n            // Create three sample objects which we will then delete. \n            var keysAndVersions = await PutObjectsAsync(client, 3, bucketName); \n            // Now perform the multi-object delete, passing the key names and \n            // version IDs. Since we are working with a non-versioned bucket, \n            // the object keys collection includes null version IDs. \n            DeleteObjectsRequest multiObjectDeleteRequest = new \n DeleteObjectsRequest \n            { \n                BucketName = bucketName, \nBasics API Version 2006-03-01 1932Amazon Simple Storage Service API Reference\n                Objects = keysAndVersions, \n            }; \n            // You can add a specific object key to the delete request using the \n            // AddKey method of the multiObjectDeleteRequest. \n            try \n            { \n                DeleteObjectsResponse response = await \n client.DeleteObjectsAsync(multiObjectDeleteRequest); \n                Console.WriteLine(\"Successfully deleted all the {0} items\", \n response.DeletedObjects.Count); \n            } \n            catch (DeleteObjectsException e) \n            { \n                PrintDeletionErrorStatus(e); \n            } \n        } \n        /// <summary> \n        /// Prints the list of errors raised by the call to DeleteObjectsAsync. \n        /// </summary> \n        /// <param name=\"ex\">A collection of exceptions returned by the call to \n        /// DeleteObjectsAsync.</param> \n        public static void PrintDeletionErrorStatus(DeleteObjectsException ex) \n        { \n            DeleteObjectsResponse errorResponse = ex.Response; \n            Console.WriteLine(\"x {0}\", errorResponse.DeletedObjects.Count); \n            Console.WriteLine($\"Successfully deleted \n {errorResponse.DeletedObjects.Count}.\"); \n            Console.WriteLine($\"No. of objects failed to delete = \n {errorResponse.DeleteErrors.Count}\"); \n            Console.WriteLine(\"Printing error data...\"); \n            foreach (DeleteError deleteError in errorResponse.DeleteErrors) \n            { \n                Console.WriteLine($\"Object Key: \n {deleteError.Key}\\t{deleteError.Code}\\t{deleteError.Message}\"); \n            } \n        } \n        /// <summary> \n        /// This method creates simple text file objects that can be used in \n        /// the delete method.", "\nBasics API Version 2006-03-01 1933Amazon Simple Storage Service API Reference\n        /// </summary> \n        /// <param name=\"client\">The Amazon S3 client used to call \n PutObjectAsync.</param> \n        /// <param name=\"number\">The number of objects to create.</param> \n        /// <param name=\"bucketName\">The name of the bucket where the objects \n        /// will be created.</param> \n        /// <returns>A list of keys (object keys) and versions that the calling \n        /// method will use to delete the newly created files.</returns> \n        public static async Task<List<KeyVersion>> PutObjectsAsync(IAmazonS3 \n client, int number, string bucketName) \n        { \n            List<KeyVersion> keys = new List<KeyVersion>(); \n            for (int i = 0; i < number; i++) \n            { \n                string key = \"ExampleObject-\" + new System.Random().Next(); \n                PutObjectRequest request = new PutObjectRequest \n                { \n                    BucketName = bucketName, \n                    Key = key, \n                    ContentBody = \"This is the content body!\", \n                }; \n                PutObjectResponse response = await \n client.PutObjectAsync(request); \n                // For non-versioned bucket operations, we only need the \n                // object key. \n                KeyVersion keyVersion = new KeyVersion \n                { \n                    Key = key, \n                }; \n                keys.Add(keyVersion); \n            } \n            return keys; \n        } \n    }\nDelete multiple objects in a versioned S3 bucket.\n    using System; \nBasics API Version 2006-03-01 1934Amazon Simple Storage Service API Reference\n    using System.Collections.Generic; \n    using System.Threading.Tasks; \n    using Amazon.S3; \n    using Amazon.S3.Model; \n    /// <summary> \n    /// This example shows how to delete objects in a version-enabled Amazon \n    /// Simple StorageService (Amazon S3) bucket. \n    /// </summary> \n    public class DeleteMultipleObjects \n    { \n        public static async Task Main() \n        { \n            string bucketName = \"amzn-s3-demo-bucket\"; \n            // If the AWS Region for your Amazon S3 bucket is different from \n            // the AWS Region of the default user, define the AWS Region for \n            // the Amazon S3 bucket and pass it to the client constructor \n            // like this: \n            // RegionEndpoint bucketRegion = RegionEndpoint.USWest2; \n            IAmazonS3 s3Client; \n            s3Client = new AmazonS3Client(); \n            await DeleteMultipleObjectsFromVersionedBucketAsync(s3Client, \n bucketName); \n        } \n        /// <summary> \n        /// This method removes multiple versions and objects from a \n        /// version-enabled Amazon S3 bucket. \n        /// </summary> \n        /// <param name=\"client\">The initialized Amazon S3 client object used to \n call \n        /// DeleteObjectVersionsAsync, DeleteObjectsAsync, and \n        /// RemoveDeleteMarkersAsync.</param> \n        /// <param name=\"bucketName\">The name of the bucket from which to delete \n        /// objects.</param> \n        public static async Task \n DeleteMultipleObjectsFromVersionedBucketAsync(IAmazonS3 client, string \n bucketName) \n        { \n            // Delete objects (specifying object version in the request). \n            await DeleteObjectVersionsAsync(client, bucketName); \nBasics API Version 2006-03-01 1935Amazon Simple Storage Service API Reference\n            // Delete objects (without specifying object version in the request). \n            var deletedObjects = await DeleteObjectsAsync(client, bucketName); \n            // Additional exercise - remove the delete markers Amazon S3 returned \n from \n            // the preceding response.", "This results in the objects reappearing \n            // in the bucket (you can verify the appearance/disappearance of \n            // objects in the console).", "\n            await RemoveDeleteMarkersAsync(client, bucketName, deletedObjects); \n        } \n        /// <summary> \n        /// Creates and then deletes non-versioned Amazon S3 objects and then \n deletes \n        /// them again. The method returns a list of the Amazon S3 objects \n deleted. \n        /// </summary> \n        /// <param name=\"client\">The initialized Amazon S3 client object used to \n call \n        /// PubObjectsAsync and NonVersionedDeleteAsync.</param> \n        /// <param name=\"bucketName\">The name of the bucket where the objects \n        /// will be created and then deleted.</param> \n        /// <returns>A list of DeletedObjects.</returns> \n        public static async Task<List<DeletedObject>> \n DeleteObjectsAsync(IAmazonS3 client, string bucketName) \n        { \n            // Upload the sample objects. \n            var keysAndVersions2 = await PutObjectsAsync(client, bucketName, 3); \n            // Delete objects using only keys.", "Amazon S3 creates a delete marker \n and \n            // returns its version ID in the response.", "\n            List<DeletedObject> deletedObjects = await \n NonVersionedDeleteAsync(client, bucketName, keysAndVersions2); \n            return deletedObjects; \n        } \n        /// <summary> \n        /// This method creates several temporary objects and then deletes them.", "\n        /// </summary> \n        /// <param name=\"client\">The S3 client.</param> \n        /// <param name=\"bucketName\">Name of the bucket.</param> \n        /// <returns>Async task.</returns> \nBasics API Version 2006-03-01 1936Amazon Simple Storage Service API Reference\n        public static async Task DeleteObjectVersionsAsync(IAmazonS3 client, \n string bucketName) \n        { \n            // Upload the sample objects. \n            var keysAndVersions1 = await PutObjectsAsync(client, bucketName, 3); \n            // Delete the specific object versions. \n            await VersionedDeleteAsync(client, bucketName, keysAndVersions1); \n        } \n        /// <summary> \n        /// Displays the list of information about deleted files to the console.", "\n        /// </summary> \n        /// <param name=\"e\">Error information from the delete process.</param> \n        private static void DisplayDeletionErrors(DeleteObjectsException e) \n        { \n            var errorResponse = e.Response; \n            Console.WriteLine($\"No. of objects successfully deleted = \n {errorResponse.DeletedObjects.Count}\"); \n            Console.WriteLine($\"No. of objects failed to delete = \n {errorResponse.DeleteErrors.Count}\"); \n            Console.WriteLine(\"Printing error data...\"); \n            foreach (var deleteError in errorResponse.DeleteErrors) \n            { \n                Console.WriteLine($\"Object Key: \n {deleteError.Key}\\t{deleteError.Code}\\t{deleteError.Message}\"); \n            } \n        } \n        /// <summary> \n        /// Delete multiple objects from a version-enabled bucket. \n        /// </summary> \n        /// <param name=\"client\">The initialized Amazon S3 client object used to \n call \n        /// DeleteObjectVersionsAsync, DeleteObjectsAsync, and \n        /// RemoveDeleteMarkersAsync.</param> \n        /// <param name=\"bucketName\">The name of the bucket from which to delete \n        /// objects.</param> \n        /// <param name=\"keys\">A list of key names for the objects to delete.</\nparam> \n        private static async Task VersionedDeleteAsync(IAmazonS3 client, string \n bucketName, List<KeyVersion> keys) \n        { \n            var multiObjectDeleteRequest = new DeleteObjectsRequest \nBasics API Version 2006-03-01 1937Amazon Simple Storage Service API Reference\n            { \n                BucketName = bucketName, \n                Objects = keys, // This includes the object keys and specific \n version IDs. \n            }; \n            try \n            { \n                Console.WriteLine(\"Executing VersionedDelete...\"); \n                DeleteObjectsResponse response = await \n client.DeleteObjectsAsync(multiObjectDeleteRequest); \n                Console.WriteLine($\"Successfully deleted all the \n {response.DeletedObjects.Count} items\"); \n            } \n            catch (DeleteObjectsException ex) \n            { \n                DisplayDeletionErrors(ex); \n            } \n        } \n        /// <summary> \n        /// Deletes multiple objects from a non-versioned Amazon S3 bucket. \n        /// </summary> \n        /// <param name=\"client\">The initialized Amazon S3 client object used to \n call \n        /// DeleteObjectVersionsAsync, DeleteObjectsAsync, and \n        /// RemoveDeleteMarkersAsync.</param> \n        /// <param name=\"bucketName\">The name of the bucket from which to delete \n        /// objects.</param> \n        /// <param name=\"keys\">A list of key names for the objects to delete.</\nparam> \n        /// <returns>A list of the deleted objects.</returns> \n        private static async Task<List<DeletedObject>> \n NonVersionedDeleteAsync(IAmazonS3 client, string bucketName, List<KeyVersion> \n keys) \n        { \n            // Create a request that includes only the object key names. \n            DeleteObjectsRequest multiObjectDeleteRequest = new \n DeleteObjectsRequest(); \n            multiObjectDeleteRequest.BucketName = bucketName; \n            foreach (var key in keys) \n            { \n                multiObjectDeleteRequest.AddKey(key.Key); \nBasics API Version 2006-03-01 1938Amazon Simple Storage Service API Reference\n            } \n            // Execute DeleteObjectsAsync. \n            // The DeleteObjectsAsync method adds a delete marker for each \n            // object deleted.", "You can verify that the objects were removed \n            // using the Amazon S3 console.", "\n            DeleteObjectsResponse response; \n            try \n            { \n                Console.WriteLine(\"Executing NonVersionedDelete...\"); \n                response = await \n client.DeleteObjectsAsync(multiObjectDeleteRequest); \n                Console.WriteLine(\"Successfully deleted all the {0} items\", \n response.DeletedObjects.Count); \n            } \n            catch (DeleteObjectsException ex) \n            { \n                DisplayDeletionErrors(ex); \n                throw; // Some deletions failed.", "Investigate before continuing.", "\n            } \n            // This response contains the DeletedObjects list which we use to \n delete the delete markers. \n            return response.DeletedObjects; \n        } \n        /// <summary> \n        /// Deletes the markers left after deleting the temporary objects.", "\n        /// </summary> \n        /// <param name=\"client\">The initialized Amazon S3 client object used to \n call \n        /// DeleteObjectVersionsAsync, DeleteObjectsAsync, and \n        /// RemoveDeleteMarkersAsync.</param> \n        /// <param name=\"bucketName\">The name of the bucket from which to delete \n        /// objects.</param> \n        /// <param name=\"deletedObjects\">A list of the objects that were \n deleted.</param> \n        private static async Task RemoveDeleteMarkersAsync(IAmazonS3 client, \n string bucketName, List<DeletedObject> deletedObjects) \n        { \n            var keyVersionList = new List<KeyVersion>(); \n            foreach (var deletedObject in deletedObjects) \n            { \nBasics API Version 2006-03-01 1939Amazon Simple Storage Service API Reference\n                KeyVersion keyVersion = new KeyVersion \n                { \n                    Key = deletedObject.Key, \n                    VersionId = deletedObject.DeleteMarkerVersionId, \n                }; \n                keyVersionList.Add(keyVersion); \n            } \n            // Create another request to delete the delete markers. \n            var multiObjectDeleteRequest = new DeleteObjectsRequest \n            { \n                BucketName = bucketName, \n                Objects = keyVersionList, \n            }; \n            // Now, delete the delete marker to bring your objects back to the \n bucket. \n            try \n            { \n                Console.WriteLine(\"Removing the delete markers .....\"); \n                var deleteObjectResponse = await \n client.DeleteObjectsAsync(multiObjectDeleteRequest); \n                Console.WriteLine($\"Successfully deleted the \n {deleteObjectResponse.DeletedObjects.Count} delete markers\"); \n            } \n            catch (DeleteObjectsException ex) \n            { \n                DisplayDeletionErrors(ex); \n            } \n        } \n        /// <summary> \n        /// Create temporary Amazon S3 objects to show how object deletion wors \n in an \n        /// Amazon S3 bucket with versioning enabled. \n        /// </summary> \n        /// <param name=\"client\">The initialized Amazon S3 client object used to \n call \n        /// PutObjectAsync to create temporary objects for the example.</param> \n        /// <param name=\"bucketName\">A string representing the name of the S3 \n        /// bucket where we will create the temporary objects.</param> \n        /// <param name=\"number\">The number of temporary objects to create.</\nparam> \n        /// <returns>A list of the KeyVersion objects.</returns> \nBasics API Version 2006-03-01 1940Amazon Simple Storage Service API Reference\n        private static async Task<List<KeyVersion>> PutObjectsAsync(IAmazonS3 \n client, string bucketName, int number) \n        { \n            var keys = new List<KeyVersion>(); \n            for (var i = 0; i < number; i++) \n            { \n                string key = \"ObjectToDelete-\" + new System.Random().Next(); \n                PutObjectRequest request = new PutObjectRequest \n                { \n                    BucketName = bucketName, \n                    Key = key, \n                    ContentBody = \"This is the content body!\", \n                }; \n                var response = await client.PutObjectAsync(request); \n                KeyVersion keyVersion = new KeyVersion \n                { \n                    Key = key, \n                    VersionId = response.VersionId, \n                }; \n                keys.Add(keyVersion); \n            } \n            return keys; \n        } \n    }\n\u2022For API details, see DeleteObjects in AWS SDK for .NET API Reference.\nBash\nAWS CLI with Bash script\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nBasics API Version 2006-03-01 1941Amazon Simple Storage Service API Reference\n###############################################################################\n# function errecho\n#\n# This function outputs everything sent to it to STDERR (standard error output).\n###############################################################################\nfunction errecho() { \n  printf \"%s\\n\" \"$*\" 1>&2\n}\n###############################################################################\n# function delete_items_in_bucket\n#\n# This function deletes the specified list of keys from the specified bucket.\n#\n# Parameters:\n#       $1 - The name of the bucket.\n#       $2 - A list of keys in the bucket to delete.\n# Returns:\n#       0 - If successful.\n#       1 - If it fails.\n###############################################################################\nfunction delete_items_in_bucket() { \n  local bucket_name=$1 \n  local keys=$2 \n  local response \n  # Create the JSON for the items to delete.", "\n  local delete_items \n  delete_items=\"{\\\"Objects\\\":[\" \n  for key in $keys; do \n    delete_items=\"$delete_items{\\\"Key\\\": \\\"$key\\\"},\" \n  done \n  delete_items=${delete_items%?} # Remove the final comma.", "\n  delete_items=\"$delete_items]}\" \n  response=$(aws s3api delete-objects \\ \n    --bucket \"$bucket_name\" \\ \n    --delete \"$delete_items\") \n  # shellcheck disable=SC2181 \n  if [[ $? -ne 0 ]]; then \nBasics API Version 2006-03-01 1942Amazon Simple Storage Service API Reference\n    errecho \"ERROR:  AWS reports s3api delete-object operation failed.\\n\n$response\" \n    return 1 \n  fi\n}\n\u2022For API details, see DeleteObjects in AWS CLI Command Reference.\nC++\nSDK for C++\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nbool AwsDoc::S3::deleteObjects(const std::vector<Aws::String> &objectKeys, \n                               const Aws::String &fromBucket, \n                               const Aws::S3::S3ClientConfiguration \n &clientConfig) { \n    Aws::S3::S3Client client(clientConfig); \n    Aws::S3::Model::DeleteObjectsRequest request; \n    Aws::S3::Model::Delete deleteObject; \n    for (const Aws::String &objectKey: objectKeys) { \n        \n deleteObject.AddObjects(Aws::S3::Model::ObjectIdentifier().WithKey(objectKey)); \n    } \n    request.SetDelete(deleteObject); \n    request.SetBucket(fromBucket); \n    Aws::S3::Model::DeleteObjectsOutcome outcome = \n            client.DeleteObjects(request); \n    if (!outcome.IsSuccess()) { \n        auto err = outcome.GetError(); \n        std::cerr << \"Error deleting objects. \" << \nBasics API Version 2006-03-01 1943Amazon Simple Storage Service API Reference\n                  err.GetExceptionName() << \": \" << err.GetMessage() << \n std::endl; \n    } else { \n        std::cout << \"Successfully deleted the objects.\"; \n        for (size_t i = 0; i < objectKeys.size(); ++i) { \n            std::cout << objectKeys[i]; \n            if (i < objectKeys.size() - 1) { \n                std::cout << \", \"; \n            } \n        } \n        std::cout << \" from bucket \" << fromBucket << \".\" << std::endl; \n    } \n    return outcome.IsSuccess();\n}\n\u2022For API details, see DeleteObjects in AWS SDK for C++ API Reference.\nCLI\nAWS CLI\nThe following command deletes an object from a bucket named my-bucket :\naws s3api delete-objects --bucket my-bucket  --delete file://delete.json\ndelete.json  is a JSON document in the current directory that speci\ufb01es the object to \ndelete:\n{ \n  \"Objects\": [ \n    { \n      \"Key\": \"test1.txt\" \n    } \n  ], \n  \"Quiet\": false\n}\nOutput:\nBasics API Version 2006-03-01 1944Amazon Simple Storage Service API Reference\n{ \n    \"Deleted\": [ \n        { \n            \"DeleteMarkerVersionId\": \"mYAT5Mc6F7aeUL8SS7FAAqUPO1koHwzU\", \n            \"Key\": \"test1.txt\", \n            \"DeleteMarker\": true \n        } \n    ]\n}\n\u2022For API details, see DeleteObjects in AWS CLI Command Reference.\nGo\nSDK for Go V2\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n// S3Actions wraps S3 service actions.\ntype S3Actions struct { \n S3Client  *s3.Client \n S3Manager *manager.Uploader\n}\n// DeleteObjects deletes a list of objects from a bucket.\nfunc (actor S3Actions) DeleteObjects(ctx context.Context, bucket string, objects \n []types.ObjectIdentifier, bypassGovernance bool) error { \n if len(objects) == 0 { \n  return nil \n } \n input := s3.DeleteObjectsInput{ \n  Bucket: aws.String(bucket), \n  Delete: &types.Delete{ \nBasics API Version 2006-03-01 1945Amazon Simple Storage Service API Reference\n   Objects: objects, \n   Quiet:   aws.Bool(true), \n  }, \n } \n if bypassGovernance { \n  input.BypassGovernanceRetention = aws.Bool(true) \n } \n delOut, err := actor.S3Client.DeleteObjects(ctx, &input) \n if err != nil || len(delOut.Errors) > 0 { \n  log.Printf(\"Error deleting objects from bucket %s.\\n\", bucket) \n  if err != nil { \n   var noBucket *types.NoSuchBucket \n   if errors.As(err, &noBucket) { \n    log.Printf(\"Bucket %s does not exist.\\n\", bucket) \n    err = noBucket \n   } \n  } else if len(delOut.Errors) > 0 { \n   for _, outErr := range delOut.Errors { \n    log.Printf(\"%s: %s\\n\", *outErr.Key, *outErr.Message) \n   } \n   err = fmt.Errorf(\"%s\", *delOut.Errors[0].Message) \n  } \n } \n return err\n}\n\u2022For API details, see DeleteObjects in AWS SDK for Go API Reference.\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nimport software.amazon.awssdk.core.sync.RequestBody;\nBasics API Version 2006-03-01 1946Amazon Simple Storage Service API Reference\nimport software.amazon.awssdk.regions.Region;\nimport software.amazon.awssdk.services.s3.S3Client;\nimport software.amazon.awssdk.services.s3.model.PutObjectRequest;\nimport software.amazon.awssdk.services.s3.model.ObjectIdentifier;\nimport software.amazon.awssdk.services.s3.model.Delete;\nimport software.amazon.awssdk.services.s3.model.DeleteObjectsRequest;\nimport software.amazon.awssdk.services.s3.model.S3Exception;\nimport java.util.ArrayList;\n/** \n * Before running this Java V2 code example, set up your development \n * environment, including your credentials. \n * <p> \n * For more information, see the following documentation topic: \n * <p> \n * https://docs.aws.amazon.com/sdk-for-java/latest/developer-guide/get-\nstarted.html \n */\npublic class DeleteMultiObjects { \n    public static void main(String[] args) { \n        final String usage = \"\"\" \n            Usage:    <bucketName> \n            Where: \n               bucketName - the Amazon S3 bucket name. \n            \"\"\"; \n        if (args.length != 1) { \n            System.out.println(usage); \n            System.exit(1); \n        } \n        String bucketName = args[0]; \n        Region region = Region.US_EAST_1; \n        S3Client s3 = S3Client.builder() \n            .region(region) \n            .build(); \n        deleteBucketObjects(s3, bucketName); \n        s3.close(); \n    } \nBasics API Version 2006-03-01 1947Amazon Simple Storage Service API Reference\n    /** \n     * Deletes multiple objects from an Amazon S3 bucket. \n     * \n     * @param s3 An Amazon S3 client object. \n     * @param bucketName The name of the Amazon S3 bucket to delete objects from. \n     */ \n    public static void deleteBucketObjects(S3Client s3, String bucketName) { \n        // Upload three sample objects to the specfied Amazon S3 bucket. \n        ArrayList<ObjectIdentifier> keys = new ArrayList<>(); \n        PutObjectRequest putOb; \n        ObjectIdentifier objectId; \n        for (int i = 0; i < 3; i++) { \n            String keyName = \"delete object example \" + i; \n            objectId = ObjectIdentifier.builder() \n                .key(keyName) \n                .build(); \n            putOb = PutObjectRequest.builder() \n                .bucket(bucketName) \n                .key(keyName) \n                .build(); \n            s3.putObject(putOb, RequestBody.fromString(keyName)); \n            keys.add(objectId); \n        } \n        System.out.println(keys.size() + \" objects successfully created.\"); \n        // Delete multiple objects in one request. \n        Delete del = Delete.builder() \n            .objects(keys) \n            .build(); \n        try { \n            DeleteObjectsRequest multiObjectDeleteRequest = \n DeleteObjectsRequest.builder() \n                .bucket(bucketName) \n                .delete(del) \n                .build(); \n            s3.deleteObjects(multiObjectDeleteRequest); \n            System.out.println(\"Multiple objects are deleted!\"); \nBasics API Version 2006-03-01 1948Amazon Simple Storage Service API Reference\n        } catch (S3Exception e) { \n            System.err.println(e.awsErrorDetails().errorMessage()); \n            System.exit(1); \n        } \n    }\n}\n\u2022For API details, see DeleteObjects in AWS SDK for Java 2.x API Reference.\nJavaScript\nSDK for JavaScript (v3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nDelete multiple objects.\nimport { \n  DeleteObjectsCommand, \n  S3Client, \n  S3ServiceException, \n  waitUntilObjectNotExists,\n} from \"@aws-sdk/client-s3\";\n/** \n * Delete multiple objects from an S3 bucket. \n * @param {{ bucketName: string, keys: string[] }} \n */\nexport const main = async ({ bucketName, keys }) => { \n  const client = new S3Client({}); \n  try { \n    const { Deleted } = await client.send( \n      new DeleteObjectsCommand({ \n        Bucket: bucketName, \n        Delete: { \nBasics API Version 2006-03-01 1949Amazon Simple Storage Service API Reference\n          Objects: keys.map((k) => ({ Key: k })), \n        }, \n      }), \n    ); \n    for (const key in keys) { \n      await waitUntilObjectNotExists( \n        { client }, \n        { Bucket: bucketName, Key: key }, \n      ); \n    } \n    console.log( \n      `Successfully deleted ${Deleted.length} objects from S3 bucket. Deleted \n objects:`, \n    ); \n    console.log(Deleted.map((d) => ` \u2022 ${d.Key}`).join(\"\\n\")); \n  } catch (caught) { \n    if ( \n      caught instanceof S3ServiceException && \n      caught.name === \"NoSuchBucket\" \n    ) { \n      console.error( \n        `Error from S3 while deleting objects from ${bucketName}. The bucket \n doesn't exist.`, \n      ); \n    } else if (caught instanceof S3ServiceException) { \n      console.error( \n        `Error from S3 while deleting objects from ${bucketName}.", "\n ${caught.name}: ${caught.message}`, \n      ); \n    } else { \n      throw caught; \n    } \n  }\n};\n\u2022For API details, see DeleteObjects in AWS SDK for JavaScript API Reference.\nBasics API Version 2006-03-01 1950Amazon Simple Storage Service API Reference\nKotlin\nSDK for Kotlin\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nsuspend fun deleteBucketObjects( \n    bucketName: String, \n    objectName: String,\n) { \n    val objectId = \n        ObjectIdentifier { \n            key = objectName \n        } \n    val delOb = \n        Delete { \n            objects = listOf(objectId) \n        } \n    val request = \n        DeleteObjectsRequest { \n            bucket = bucketName \n            delete = delOb \n        } \n    S3Client { region = \"us-east-1\" }.use { s3 -> \n        s3.deleteObjects(request) \n        println(\"$objectName was deleted from $bucketName\") \n    }\n}\n\u2022For API details, see DeleteObjects in AWS SDK for Kotlin API reference.\nBasics API Version 2006-03-01 1951Amazon Simple Storage Service API Reference\nPHP\nSDK for PHP\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nDelete a set of objects from a list of keys.\n        $s3client = new Aws\\S3\\S3Client(['region' => 'us-west-2']); \n        try { \n            $objects = []; \n            foreach ($contents['Contents'] as $content) { \n                $objects[] = [ \n                    'Key' => $content['Key'], \n                ]; \n            } \n            $this->s3client->deleteObjects([ \n                'Bucket' => $this->bucketName, \n                'Delete' => [ \n                    'Objects' => $objects, \n                ], \n            ]); \n            $check = $this->s3client->listObjectsV2([ \n                'Bucket' => $this->bucketName, \n            ]); \n            if (count($check) <= 0) { \n                throw new Exception(\"Bucket wasn't empty.\"); \n            } \n            echo \"Deleted all objects and folders from $this->bucketName.\\n\"; \n        } catch (Exception $exception) { \n            echo \"Failed to delete $fileName from $this->bucketName with error: \n \" . $exception->getMessage(); \n            exit(\"Please fix error with object deletion before continuing.\"); \n        }\n\u2022For API details, see DeleteObjects in AWS SDK for PHP API Reference.\nBasics API Version 2006-03-01 1952Amazon Simple Storage Service API Reference\nPowerShell\nTools for PowerShell\nExample 1: This command removes the object \"sample.txt\" from bucket \"test-\ufb01les\". You \nare prompted for con\ufb01rmation before the command executes; to suppress the prompt \nuse the -Force switch.\nRemove-S3Object -BucketName amzn-s3-demo-bucket -Key sample.txt\nExample 2: This command removes the speci\ufb01ed version of object \"sample.txt\" from \nbucket \"test-\ufb01les\", assuming the bucket has been con\ufb01gured to enable object versions.\nRemove-S3Object -BucketName amzn-s3-demo-bucket -Key sample.txt -VersionId \n HLbxnx6V9omT6AQYVpks8mmFKQcejpqt\nExample 3: This command removes objects \"sample1.txt\", \"sample2.txt\" and \n\"sample3.txt\" from bucket \"test-\ufb01les\" as a single batch operation.", "The service response \nwill list all keys processed, regardless of the success or error status of the deletion.", "To \nobtain only errors for keys that were not able to be processed by the service add the -\nReportErrorsOnly parameter (this parameter can also be speci\ufb01ed with the alias -Quiet.\nRemove-S3Object -BucketName amzn-s3-demo-bucket -KeyCollection @( \"sample1.txt\", \n \"sample2.txt\", \"sample3.txt\" )\nExample 4: This example uses an inline expression with the -KeyCollection parameter \nto obtain the keys of the objects to delete. Get-S3Object returns a collection of \nAmazon.S3.Model.S3Object instances, each of which has a Key member of type string \nidentifying the object.\nRemove-S3Object -bucketname \"amzn-s3-demo-bucket\" -KeyCollection (Get-S3Object \n \"test-files\" -KeyPrefix \"prefix/subprefix\" | select -ExpandProperty Key)\nExample 5: This example obtains all objects that have a key pre\ufb01x \"pre\ufb01x/subpre\ufb01x\" in \nthe bucket and deletes them.", "Note that the incoming objects are processed one at a time.", "\nFor large collections consider passing the collection to the cmdlet's -InputObject (alias \n-S3ObjectCollection) parameter to enable the deletion to occur as a batch with a single \ncall to the service.\nBasics API Version 2006-03-01 1953Amazon Simple Storage Service API Reference\nGet-S3Object -BucketName \"amzn-s3-demo-bucket\" -KeyPrefix \"prefix/subprefix\" | \n Remove-S3Object -Force\nExample 6: This example pipes a collection of Amazon.S3.Model.S3ObjectVersion \ninstances that represent delete markers to the cmdlet for deletion.", "Note that the \nincoming objects are processed one at a time.", "For large collections consider passing the \ncollection to the cmdlet's -InputObject (alias -S3ObjectCollection) parameter to enable \nthe deletion to occur as a batch with a single call to the service.\n(Get-S3Version -BucketName \"amzn-s3-demo-bucket\").Versions | Where \n {$_.IsDeleteMarker -eq \"True\"} | Remove-S3Object -Force\nExample 7: This script shows how to perform a batch delete of a set of objects (in \nthis case delete markers) by constructing an array of objects to be used with the -\nKeyAndVersionCollection parameter.\n$keyVersions = @()\n$markers = (Get-S3Version -BucketName $BucketName).Versions | Where \n {$_.IsDeleteMarker -eq \"True\"}\nforeach ($marker in $markers) { $keyVersions += @{ Key = $marker.Key; VersionId = \n $marker.VersionId } }\nRemove-S3Object -BucketName $BucketName -KeyAndVersionCollection $keyVersions -\nForce\n\u2022For API details, see DeleteObjects in AWS Tools for PowerShell Cmdlet Reference.\nPython\nSDK for Python (Boto3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nDelete a set of objects by using a list of object keys.\nclass ObjectWrapper: \nBasics API Version 2006-03-01 1954Amazon Simple Storage Service API Reference\n    \"\"\"Encapsulates S3 object actions.\"\"\" \n    def __init__(self, s3_object): \n        \"\"\" \n        :param s3_object: A Boto3 Object resource.", "This is a high-level resource \n in Boto3 \n                          that wraps object actions in a class-like structure.", "\n        \"\"\" \n        self.object = s3_object \n        self.key = self.object.key \n    @staticmethod \n    def delete_objects(bucket, object_keys): \n        \"\"\" \n        Removes a list of objects from a bucket.", "\n        This operation is done as a batch in a single request.", "\n        :param bucket: The bucket that contains the objects. This is a Boto3 \n Bucket \n                       resource.", "\n        :param object_keys: The list of keys that identify the objects to remove. \n        :return: The response that contains data about which objects were deleted \n                 and any that could not be deleted. \n        \"\"\" \n        try: \n            response = bucket.delete_objects( \n                Delete={\"Objects\": [{\"Key\": key} for key in object_keys]} \n            ) \n            if \"Deleted\" in response: \n                logger.info( \n                    \"Deleted objects '%s' from bucket '%s'.\", \n                    [del_obj[\"Key\"] for del_obj in response[\"Deleted\"]], \n                    bucket.name, \n                ) \n            if \"Errors\" in response: \n                logger.warning( \n                    \"Could not delete objects '%s' from bucket '%s'.\", \n                    [ \n                        f\"{del_obj['Key']}: {del_obj['Code']}\" \n                        for del_obj in response[\"Errors\"] \n                    ], \n                    bucket.name, \n                ) \nBasics API Version 2006-03-01 1955Amazon Simple Storage Service API Reference\n        except ClientError: \n            logger.exception(\"Couldn't delete any objects from bucket %s.\", \n bucket.name) \n            raise \n        else: \n            return response\nDelete all objects in a bucket.\nclass ObjectWrapper: \n    \"\"\"Encapsulates S3 object actions.\"\"\" \n    def __init__(self, s3_object): \n        \"\"\" \n        :param s3_object: A Boto3 Object resource.", "This is a high-level resource \n in Boto3 \n                          that wraps object actions in a class-like structure.", "\n        \"\"\" \n        self.object = s3_object \n        self.key = self.object.key \n    @staticmethod \n    def empty_bucket(bucket): \n        \"\"\" \n        Remove all objects from a bucket.", "\n        :param bucket: The bucket to empty.", "This is a Boto3 Bucket resource.", "\n        \"\"\" \n        try: \n            bucket.objects.delete() \n            logger.info(\"Emptied bucket '%s'.\", bucket.name) \n        except ClientError: \n            logger.exception(\"Couldn't empty bucket '%s'.\", bucket.name) \n            raise\nPermanently delete a versioned object by deleting all of its versions.\ndef permanently_delete_object(bucket, object_key): \nBasics API Version 2006-03-01 1956Amazon Simple Storage Service API Reference\n    \"\"\" \n    Permanently deletes a versioned object by deleting all of its versions.", "\n    Usage is shown in the usage_demo_single_object function at the end of this \n module.", "\n    :param bucket: The bucket that contains the object.", "\n    :param object_key: The object to delete. \n    \"\"\" \n    try: \n        bucket.object_versions.filter(Prefix=object_key).delete() \n        logger.info(\"Permanently deleted all versions of object %s.\", object_key) \n    except ClientError: \n        logger.exception(\"Couldn't delete all versions of %s.\", object_key) \n        raise\n\u2022For API details, see DeleteObjects in AWS SDK for Python (Boto3) API Reference.\nRuby\nSDK for Ruby\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n  # Deletes the objects in an Amazon S3 bucket and deletes the bucket. \n  # \n  # @param bucket [Aws::S3::Bucket] The bucket to empty and delete. \n  def delete_bucket(bucket) \n    puts(\"\\nDo you want to delete all of the objects as well as the bucket (y/n)? \n \") \n    answer = gets.chomp.downcase \n    if answer == 'y' \n      bucket.objects.batch_delete! \n      bucket.delete \n      puts(\"Emptied and deleted bucket #{bucket.name}.\\n\") \nBasics API Version 2006-03-01 1957Amazon Simple Storage Service API Reference\n    end \n  rescue Aws::Errors::ServiceError => e \n    puts(\"Couldn't empty and delete bucket #{bucket.name}.\") \n    puts(\"\\t#{e.code}: #{e.message}\") \n    raise \n  end\n\u2022For API details, see DeleteObjects in AWS SDK for Ruby API Reference.\nRust\nSDK for Rust\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n/// Delete the objects in a bucket.\npub async fn delete_objects( \n    client: &aws_sdk_s3::Client, \n    bucket_name: &str, \n    objects_to_delete: Vec<String>,\n) -> Result<(), S3ExampleError> { \n    // Push into a mut vector to use `?` early return errors while building \n object keys. \n    let mut delete_object_ids: Vec<aws_sdk_s3::types::ObjectIdentifier> = vec![]; \n    for obj in objects_to_delete { \n        let obj_id = aws_sdk_s3::types::ObjectIdentifier::builder() \n            .key(obj) \n            .build() \n            .map_err(|err| { \n                S3ExampleError::new(format!(\"Failed to build key for \n delete_object: {err:?}\")) \n            })?; \n        delete_object_ids.push(obj_id); \n    } \n    client \n        .delete_objects() \nBasics API Version 2006-03-01 1958Amazon Simple Storage Service API Reference\n        .bucket(bucket_name) \n        .delete( \n            aws_sdk_s3::types::Delete::builder() \n                .set_objects(Some(delete_object_ids)) \n                .build() \n                .map_err(|err| { \n                    S3ExampleError::new(format!(\"Failed to build delete_object \n input {err:?}\")) \n                })?, \n        ) \n        .send() \n        .await?; \n    Ok(())\n}\n\u2022For API details, see DeleteObjects in AWS SDK for Rust API reference.\nSwift\nSDK for Swift\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nimport AWSS3 \n    public func deleteObjects(bucket: String, keys: [String]) async throws { \n        let input = DeleteObjectsInput( \n            bucket: bucket, \n            delete: S3ClientTypes.Delete( \n                objects: keys.map { S3ClientTypes.ObjectIdentifier(key: $0) }, \n                quiet: true \n            ) \n        ) \n        do { \n            _ = try await client.deleteObjects(input: input) \n        } catch { \nBasics API Version 2006-03-01 1959Amazon Simple Storage Service API Reference\n            print(\"ERROR: deleteObjects:\", dump(error)) \n            throw error \n        } \n    }\n\u2022For API details, see DeleteObjects in AWS SDK for Swift API reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nUse DeletePublicAccessBlock  with a CLI\nThe following code examples show how to use DeletePublicAccessBlock .\nCLI\nAWS CLI\nTo delete the block public access con\ufb01guration for a bucket\nThe following delete-public-access-block  example removes the block public access \ncon\ufb01guration on the speci\ufb01ed bucket.\naws s3api delete-public-access-block \\ \n    --bucket my-bucket\nThis command produces no output.\n\u2022For API details, see DeletePublicAccessBlock in AWS CLI Command Reference.\nPowerShell\nTools for PowerShell\nExample 1: This command turns o\ufb00 the block public access setting for the given bucket.\nRemove-S3PublicAccessBlock -BucketName 'amzn-s3-demo-bucket' -Force -Select \n '^BucketName'\nOutput:\nBasics API Version 2006-03-01 1960Amazon Simple Storage Service API Reference\ns3testbucket\n\u2022For API details, see DeletePublicAccessBlock in AWS Tools for PowerShell Cmdlet Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nUse GetBucketAccelerateConfiguration  with a CLI\nThe following code examples show how to use GetBucketAccelerateConfiguration .\nCLI\nAWS CLI\nTo retrieve the accelerate con\ufb01guration of a bucket\nThe following get-bucket-accelerate-configuration  example retrieves the \naccelerate con\ufb01guration for the speci\ufb01ed bucket.\naws s3api get-bucket-accelerate-configuration \\ \n    --bucket my-bucket\nOutput:\n{ \n    \"Status\": \"Enabled\"\n}\n\u2022For API details, see GetBucketAccelerateCon\ufb01guration in AWS CLI Command Reference.\nPowerShell\nTools for PowerShell\nExample 1: This command returns the value Enabled, if the transfer acceleration settings \nis enabled for the bucket speci\ufb01ed.\nGet-S3BucketAccelerateConfiguration -BucketName 'amzn-s3-demo-bucket'\nBasics API Version 2006-03-01 1961Amazon Simple Storage Service API Reference\nOutput:\nValue                                   \n-----                                     \nEnabled\n\u2022For API details, see GetBucketAccelerateCon\ufb01guration in AWS Tools for PowerShell Cmdlet \nReference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nUse GetBucketAcl  with an AWS SDK or CLI\nThe following code examples show how to use GetBucketAcl .\nAction examples are code excerpts from larger programs and must be run in context.", "You can see \nthis action in context in the following code example:\n\u2022Manage access control lists (ACLs)\n.NET\nAWS SDK for .NET\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n        /// <summary> \n        /// Get the access control list (ACL) for the new bucket. \n        /// </summary> \n        /// <param name=\"client\">The initialized client object used to get the \n        /// access control list (ACL) of the bucket.</param> \n        /// <param name=\"newBucketName\">The name of the newly created bucket.</\nparam> \nBasics API Version 2006-03-01 1962Amazon Simple Storage Service API Reference\n        /// <returns>An S3AccessControlList.</returns> \n        public static async Task<S3AccessControlList> \n GetACLForBucketAsync(IAmazonS3 client, string newBucketName) \n        { \n            // Retrieve bucket ACL to show that the ACL was properly applied to \n            // the new bucket. \n            GetACLResponse getACLResponse = await client.GetACLAsync(new \n GetACLRequest \n            { \n                BucketName = newBucketName, \n            }); \n            return getACLResponse.AccessControlList; \n        }\n\u2022For API details, see GetBucketAcl in AWS SDK for .NET API Reference.\nC++\nSDK for C++\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nbool AwsDoc::S3::getBucketAcl(const Aws::String &bucketName, \n                              const Aws::S3::S3ClientConfiguration &clientConfig) \n { \n    Aws::S3::S3Client s3Client(clientConfig); \n    Aws::S3::Model::GetBucketAclRequest request; \n    request.SetBucket(bucketName); \n    Aws::S3::Model::GetBucketAclOutcome outcome = \n            s3Client.GetBucketAcl(request); \n    if (!outcome.IsSuccess()) { \n        const Aws::S3::S3Error &err = outcome.GetError(); \nBasics API Version 2006-03-01 1963Amazon Simple Storage Service API Reference\n        std::cerr << \"Error: getBucketAcl: \" \n                  << err.GetExceptionName() << \": \" << err.GetMessage() << \n std::endl; \n    } else { \n        Aws::Vector<Aws::S3::Model::Grant> grants = \n                outcome.GetResult().GetGrants(); \n        for (auto it = grants.begin(); it != grants.end(); it++) { \n            Aws::S3::Model::Grant grant = *it; \n            Aws::S3::Model::Grantee grantee = grant.GetGrantee(); \n            std::cout << \"For bucket \" << bucketName << \": \" \n                      << std::endl << std::endl; \n            if (grantee.TypeHasBeenSet()) { \n                std::cout << \"Type:          \" \n                          << getGranteeTypeString(grantee.GetType()) << \n std::endl; \n            } \n            if (grantee.DisplayNameHasBeenSet()) { \n                std::cout << \"Display name:  \" \n                          << grantee.GetDisplayName() << std::endl; \n            } \n            if (grantee.EmailAddressHasBeenSet()) { \n                std::cout << \"Email address: \" \n                          << grantee.GetEmailAddress() << std::endl; \n            } \n            if (grantee.IDHasBeenSet()) { \n                std::cout << \"ID:            \" \n                          << grantee.GetID() << std::endl; \n            } \n            if (grantee.URIHasBeenSet()) { \n                std::cout << \"URI:           \" \n                          << grantee.GetURI() << std::endl; \n            } \n            std::cout << \"Permission:    \" << \n                      getPermissionString(grant.GetPermission()) << \n                      std::endl << std::endl; \n        } \nBasics API Version 2006-03-01 1964Amazon Simple Storage Service API Reference\n    } \n    return outcome.IsSuccess();\n}\n//!", "Routine which converts a built-in type enumeration to a human-readable \n string.\n/*! \n \\param type: Type enumeration.", "\n \\return String: Human-readable string.\n*/\nAws::String getGranteeTypeString(const Aws::S3::Model::Type &type) { \n    switch (type) { \n        case Aws::S3::Model::Type::AmazonCustomerByEmail: \n            return \"Email address of an AWS account\"; \n        case Aws::S3::Model::Type::CanonicalUser: \n            return \"Canonical user ID of an AWS account\"; \n        case Aws::S3::Model::Type::Group: \n            return \"Predefined Amazon S3 group\"; \n        case Aws::S3::Model::Type::NOT_SET: \n            return \"Not set\"; \n        default: \n            return \"Type unknown\"; \n    }\n}\n//!", "Routine which converts a built-in type enumeration to a human-readable \n string.\n/*!", "\n \\param permission: Permission enumeration.", "\n \\return String: Human-readable string.\n*/\nAws::String getPermissionString(const Aws::S3::Model::Permission &permission) { \n    switch (permission) { \n        case Aws::S3::Model::Permission::FULL_CONTROL: \n            return \"Can list objects in this bucket, create/overwrite/delete \" \n                   \"objects in this bucket, and read/write this \" \n                   \"bucket's permissions\"; \n        case Aws::S3::Model::Permission::NOT_SET: \n            return \"Permission not set\"; \n        case Aws::S3::Model::Permission::READ: \n            return \"Can list objects in this bucket\"; \nBasics API Version 2006-03-01 1965Amazon Simple Storage Service API Reference\n        case Aws::S3::Model::Permission::READ_ACP: \n            return \"Can read this bucket's permissions\"; \n        case Aws::S3::Model::Permission::WRITE: \n            return \"Can create, overwrite, and delete objects in this bucket\"; \n        case Aws::S3::Model::Permission::WRITE_ACP: \n            return \"Can write this bucket's permissions\"; \n        default: \n            return \"Permission unknown\"; \n    } \n    return \"Permission unknown\";\n}\n\u2022For API details, see GetBucketAcl in AWS SDK for C++ API Reference.\nCLI\nAWS CLI\nThe following command retrieves the access control list for a bucket named my-bucket :\naws s3api get-bucket-acl --bucket my-bucket\nOutput:\n{ \n    \"Owner\": { \n        \"DisplayName\": \"my-username\", \n        \"ID\": \"7009a8971cd538e11f6b6606438875e7c86c5b672f46db45460ddcd087d36c32\" \n    }, \n    \"Grants\": [ \n        { \n            \"Grantee\": { \n                \"DisplayName\": \"my-username\", \n                \"ID\": \n \"7009a8971cd538e11f6b6606438875e7c86c5b672f46db45460ddcd087d36c32\" \n            }, \n            \"Permission\": \"FULL_CONTROL\" \n        } \n    ]\nBasics API Version 2006-03-01 1966Amazon Simple Storage Service API Reference\n}\n\u2022For API details, see GetBucketAcl in AWS CLI Command Reference.\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nimport software.amazon.awssdk.services.s3.model.S3Exception;\nimport software.amazon.awssdk.regions.Region;\nimport software.amazon.awssdk.services.s3.S3Client;\nimport software.amazon.awssdk.services.s3.model.GetObjectAclRequest;\nimport software.amazon.awssdk.services.s3.model.GetObjectAclResponse;\nimport software.amazon.awssdk.services.s3.model.Grant;\nimport java.util.List;\n/** \n * Before running this Java V2 code example, set up your development \n * environment, including your credentials. \n * <p> \n * For more information, see the following documentation topic: \n * <p> \n * https://docs.aws.amazon.com/sdk-for-java/latest/developer-guide/get-\nstarted.html \n */\npublic class GetAcl { \n    public static void main(String[] args) { \n        final String usage = \"\"\" \n            Usage: \n              <bucketName> <objectKey> \n            Where: \nBasics API Version 2006-03-01 1967Amazon Simple Storage Service API Reference\n              bucketName - The Amazon S3 bucket to get the access control list \n (ACL) for. \n              objectKey - The object to get the ACL for.\\s \n            \"\"\"; \n        if (args.length != 2) { \n            System.out.println(usage); \n            System.exit(1); \n        } \n        String bucketName = args[0]; \n        String objectKey = args[1]; \n        System.out.println(\"Retrieving ACL for object: \" + objectKey); \n        System.out.println(\"in bucket: \" + bucketName); \n        Region region = Region.US_EAST_1; \n        S3Client s3 = S3Client.builder() \n            .region(region) \n            .build(); \n        getBucketACL(s3, objectKey, bucketName); \n        s3.close(); \n        System.out.println(\"Done!\"); \n    } \n    /** \n     * Retrieves the Access Control List (ACL) for an object in an Amazon S3 \n bucket. \n     * \n     * @param s3 The S3Client object used to interact with the Amazon S3 service.", "\n     * @param objectKey The key of the object for which the ACL is to be \n retrieved.", "\n     * @param bucketName The name of the bucket containing the object.", "\n     * @return The ID of the grantee who has permission on the object, or an \n empty string if an error occurs.", "\n     */ \n    public static String getBucketACL(S3Client s3, String objectKey, String \n bucketName) { \n        try { \n            GetObjectAclRequest aclReq = GetObjectAclRequest.builder() \n                .bucket(bucketName) \n                .key(objectKey) \n                .build(); \n            GetObjectAclResponse aclRes = s3.getObjectAcl(aclReq); \nBasics API Version 2006-03-01 1968Amazon Simple Storage Service API Reference\n            List<Grant> grants = aclRes.grants(); \n            String grantee = \"\"; \n            for (Grant grant : grants) { \n                System.out.format(\"  %s: %s\\n\", grant.grantee().id(), \n grant.permission()); \n                grantee = grant.grantee().id(); \n            } \n            return grantee; \n        } catch (S3Exception e) { \n            System.err.println(e.awsErrorDetails().errorMessage()); \n            System.exit(1); \n        } \n        return \"\"; \n    }\n}\n\u2022For API details, see GetBucketAcl in AWS SDK for Java 2.x API Reference.\nJavaScript\nSDK for JavaScript (v3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nGet the ACL permissions.\nimport { \n  GetBucketAclCommand, \n  S3Client, \n  S3ServiceException,\n} from \"@aws-sdk/client-s3\";\n/** \n * Retrieves the Access Control List (ACL) for an S3 bucket. \n * @param {{ bucketName: string }} \nBasics API Version 2006-03-01 1969Amazon Simple Storage Service API Reference\n */\nexport const main = async ({ bucketName }) => { \n  const client = new S3Client({}); \n  try { \n    const response = await client.send( \n      new GetBucketAclCommand({ \n        Bucket: bucketName, \n      }), \n    ); \n    console.log(`ACL for bucket \"${bucketName}\":`); \n    console.log(JSON.stringify(response, null, 2)); \n  } catch (caught) { \n    if ( \n      caught instanceof S3ServiceException && \n      caught.name === \"NoSuchBucket\" \n    ) { \n      console.error( \n        `Error from S3 while getting ACL for ${bucketName}. The bucket doesn't \n exist.`, \n      ); \n    } else if (caught instanceof S3ServiceException) { \n      console.error( \n        `Error from S3 while getting ACL for ${bucketName}.", "${caught.name}: \n ${caught.message}`, \n      ); \n    } else { \n      throw caught; \n    } \n  }\n};\n\u2022For more information, see AWS SDK for JavaScript Developer Guide.\n\u2022For API details, see GetBucketAcl in AWS SDK for JavaScript API Reference.\nBasics API Version 2006-03-01 1970Amazon Simple Storage Service API Reference\nPython\nSDK for Python (Boto3)\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nclass BucketWrapper: \n    \"\"\"Encapsulates S3 bucket actions.\"\"\" \n    def __init__(self, bucket): \n        \"\"\" \n        :param bucket: A Boto3 Bucket resource. This is a high-level resource in \n Boto3 \n                       that wraps bucket actions in a class-like structure.", "\n        \"\"\" \n        self.bucket = bucket \n        self.name = bucket.name \n    def get_acl(self): \n        \"\"\" \n        Get the ACL of the bucket. \n        :return: The ACL of the bucket. \n        \"\"\" \n        try: \n            acl = self.bucket.Acl() \n            logger.info( \n                \"Got ACL for bucket %s. Owner is %s.\", self.bucket.name, \n acl.owner \n            ) \n        except ClientError: \n            logger.exception(\"Couldn't get ACL for bucket %s.\", self.bucket.name) \n            raise \n        else: \n            return acl\nBasics API Version 2006-03-01 1971Amazon Simple Storage Service API Reference\n\u2022For API details, see GetBucketAcl in AWS SDK for Python (Boto3) API Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nUse GetBucketAnalyticsConfiguration  with a CLI\nThe following code examples show how to use GetBucketAnalyticsConfiguration .\nCLI\nAWS CLI\nTo retrieve the analytics con\ufb01guration for a bucket with a speci\ufb01c ID\nThe following get-bucket-analytics-configuration  example displays the analytics \ncon\ufb01guration for the speci\ufb01ed bucket and ID.\naws s3api get-bucket-analytics-configuration \\ \n    --bucket my-bucket  \\ \n    --id 1\nOutput:\n{ \n    \"AnalyticsConfiguration\": { \n        \"StorageClassAnalysis\": {}, \n        \"Id\": \"1\" \n    }\n}\n\u2022For API details, see GetBucketAnalyticsCon\ufb01guration in AWS CLI Command Reference.\nPowerShell\nTools for PowerShell\nExample 1: This command returns the details of the analytics \ufb01lter with the name \n'test\ufb01lter' in the given S3 bucket.\nBasics API Version 2006-03-01 1972Amazon Simple Storage Service API Reference\nGet-S3BucketAnalyticsConfiguration -BucketName 'amzn-s3-demo-bucket' -AnalyticsId \n 'testfilter'\n\u2022For API details, see GetBucketAnalyticsCon\ufb01guration in AWS Tools for PowerShell Cmdlet \nReference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs.", "This topic also includes information about getting started and details \nabout previous SDK versions.\nUse GetBucketCors  with an AWS SDK or CLI\nThe following code examples show how to use GetBucketCors .\n.NET\nAWS SDK for .NET\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n        /// <summary> \n        /// Retrieve the CORS configuration applied to the Amazon S3 bucket. \n        /// </summary> \n        /// <param name=\"client\">The initialized Amazon S3 client object used \n        /// to retrieve the CORS configuration.</param> \n        /// <returns>The created CORS configuration object.</returns> \n        private static async Task<CORSConfiguration> \n RetrieveCORSConfigurationAsync(AmazonS3Client client) \n        { \n            GetCORSConfigurationRequest request = new \n GetCORSConfigurationRequest() \n            { \n                BucketName = BucketName, \n            }; \n            var response = await client.GetCORSConfigurationAsync(request); \nBasics API Version 2006-03-01 1973Amazon Simple Storage Service API Reference\n            var configuration = response.Configuration; \n            PrintCORSRules(configuration); \n            return configuration; \n        }\n\u2022For API details, see GetBucketCors in AWS SDK for .NET API Reference.\nCLI\nAWS CLI\nThe following command retrieves the Cross-Origin Resource Sharing con\ufb01guration for a \nbucket named my-bucket :\naws s3api get-bucket-cors --bucket my-bucket\nOutput:\n{ \n    \"CORSRules\": [ \n        { \n            \"AllowedHeaders\": [ \n                \"*\" \n            ], \n            \"ExposeHeaders\": [ \n                \"x-amz-server-side-encryption\" \n            ], \n            \"AllowedMethods\": [ \n                \"PUT\", \n                \"POST\", \n                \"DELETE\" \n            ], \n            \"MaxAgeSeconds\": 3000, \n            \"AllowedOrigins\": [ \n                \"http://www.example.com\" \n            ] \n        }, \n        { \n            \"AllowedHeaders\": [ \n                \"Authorization\" \nBasics API Version 2006-03-01 1974Amazon Simple Storage Service API Reference\n            ], \n            \"MaxAgeSeconds\": 3000, \n            \"AllowedMethods\": [ \n                \"GET\" \n            ], \n            \"AllowedOrigins\": [ \n                \"*\" \n            ] \n        } \n    ]\n}\n\u2022For API details, see GetBucketCors in AWS CLI Command Reference.\nJavaScript\nSDK for JavaScript (v3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nGet the CORS policy for the bucket.\nimport { \n  GetBucketCorsCommand, \n  S3Client, \n  S3ServiceException,\n} from \"@aws-sdk/client-s3\";\n/** \n * Log the Cross-Origin Resource Sharing (CORS) configuration information \n * set for the bucket. \n * @param {{ bucketName: string }} \n */\nexport const main = async ({ bucketName }) => { \n  const client = new S3Client({}); \n  const command = new GetBucketCorsCommand({ \n    Bucket: bucketName, \n  }); \nBasics API Version 2006-03-01 1975Amazon Simple Storage Service API Reference\n  try { \n    const { CORSRules } = await client.send(command); \n    console.log(JSON.stringify(CORSRules)); \n    CORSRules.forEach((cr, i) => { \n      console.log( \n        `\\nCORSRule ${i + 1}`, \n        `\\n${\"-\".repeat(10)}`, \n        `\\nAllowedHeaders: ${cr.AllowedHeaders}`, \n        `\\nAllowedMethods: ${cr.AllowedMethods}`, \n        `\\nAllowedOrigins: ${cr.AllowedOrigins}`, \n        `\\nExposeHeaders: ${cr.ExposeHeaders}`, \n        `\\nMaxAgeSeconds: ${cr.MaxAgeSeconds}`, \n      ); \n    }); \n  } catch (caught) { \n    if ( \n      caught instanceof S3ServiceException && \n      caught.name === \"NoSuchBucket\" \n    ) { \n      console.error( \n        `Error from S3 while getting bucket CORS rules for ${bucketName}. The \n bucket doesn't exist.`, \n      ); \n    } else if (caught instanceof S3ServiceException) { \n      console.error( \n        `Error from S3 while getting bucket CORS rules for ${bucketName}.", "\n ${caught.name}: ${caught.message}`, \n      ); \n    } else { \n      throw caught; \n    } \n  }\n};\n\u2022For more information, see AWS SDK for JavaScript Developer Guide.\n\u2022For API details, see GetBucketCors in AWS SDK for JavaScript API Reference.\nBasics API Version 2006-03-01 1976Amazon Simple Storage Service API Reference\nPython\nSDK for Python (Boto3)\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nclass BucketWrapper: \n    \"\"\"Encapsulates S3 bucket actions.\"\"\" \n    def __init__(self, bucket): \n        \"\"\" \n        :param bucket: A Boto3 Bucket resource. This is a high-level resource in \n Boto3 \n                       that wraps bucket actions in a class-like structure.", "\n        \"\"\" \n        self.bucket = bucket \n        self.name = bucket.name \n    def get_cors(self): \n        \"\"\" \n        Get the CORS rules for the bucket. \n        :return The CORS rules for the specified bucket. \n        \"\"\" \n        try: \n            cors = self.bucket.Cors() \n            logger.info( \n                \"Got CORS rules %s for bucket '%s'.\", cors.cors_rules, \n self.bucket.name \n            ) \n        except ClientError: \n            logger.exception((\"Couldn't get CORS for bucket %s.\", \n self.bucket.name)) \n            raise \n        else: \n            return cors\nBasics API Version 2006-03-01 1977Amazon Simple Storage Service API Reference\n\u2022For API details, see GetBucketCors in AWS SDK for Python (Boto3) API Reference.\nRuby\nSDK for Ruby\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nrequire 'aws-sdk-s3'\n# Wraps Amazon S3 bucket CORS configuration.\nclass BucketCorsWrapper \n  attr_reader :bucket_cors \n  # @param bucket_cors [Aws::S3::BucketCors] A bucket CORS object configured with \n an existing bucket.", "\n  def initialize(bucket_cors) \n    @bucket_cors = bucket_cors \n  end \n  # Gets the CORS configuration of a bucket.", "\n  # \n  # @return [Aws::S3::Type::GetBucketCorsOutput, nil] The current CORS \n configuration for the bucket. \n  def cors \n    @bucket_cors.data \n  rescue Aws::Errors::ServiceError => e \n    puts \"Couldn't get CORS configuration for #{@bucket_cors.bucket.name}.", "Here's \n why: #{e.message}\" \n    nil \n  end\nend\nBasics API Version 2006-03-01 1978Amazon Simple Storage Service API Reference\n\u2022For API details, see GetBucketCors in AWS SDK for Ruby API Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs.", "This topic also includes information about getting started and details \nabout previous SDK versions.\nUse GetBucketEncryption  with an AWS SDK or CLI\nThe following code examples show how to use GetBucketEncryption .\n.NET\nAWS SDK for .NET\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n    /// <summary> \n    /// Get and print the encryption settings of a bucket. \n    /// </summary> \n    /// <param name=\"bucketName\">Name of the bucket.</param> \n    /// <returns>Async task.</returns> \n    public static async Task GetEncryptionSettings(string bucketName) \n    { \n        // Check and print the bucket encryption settings. \n        Console.WriteLine($\"Getting encryption settings for bucket \n {bucketName}.\"); \n        try \n        { \n            var settings = \n                await _s3Client.GetBucketEncryptionAsync( \n                    new GetBucketEncryptionRequest() { BucketName = \n bucketName }); \n            foreach (var encryptionSettings in \n settings?.ServerSideEncryptionConfiguration?.ServerSideEncryptionRules!) \n            { \nBasics API Version 2006-03-01 1979Amazon Simple Storage Service API Reference\n                Console.WriteLine( \n                    $\"\\tAlgorithm: \n {encryptionSettings.ServerSideEncryptionByDefault.ServerSideEncryptionAlgorithm}\"); \n                Console.WriteLine( \n                    $\"\\tKey: \n {encryptionSettings.ServerSideEncryptionByDefault.ServerSideEncryptionKeyManagementServiceKeyId}\"); \n            } \n        } \n        catch (AmazonS3Exception ex) \n        { \n            Console.WriteLine(ex.ErrorCode == \"InvalidBucketName\" \n                ? $\"Bucket {bucketName} was not found.\" \n                : $\"Unable to get bucket encryption for bucket {bucketName}, \n {ex.Message}\"); \n        } \n    }\n\u2022For API details, see GetBucketEncryption in AWS SDK for .NET API Reference.\nCLI\nAWS CLI\nTo retrieve the server-side encryption con\ufb01guration for a bucket\nThe following get-bucket-encryption  example retrieves the server-side encryption \ncon\ufb01guration for the bucket my-bucket .\naws s3api get-bucket-encryption \\ \n    --bucket my-bucket\nOutput:\n{ \n    \"ServerSideEncryptionConfiguration\": { \n        \"Rules\": [ \n            { \n                \"ApplyServerSideEncryptionByDefault\": { \n                    \"SSEAlgorithm\": \"AES256\" \n                } \n            } \nBasics API Version 2006-03-01 1980Amazon Simple Storage Service API Reference\n        ] \n    }\n}\n\u2022For API details, see GetBucketEncryption in AWS CLI Command Reference.\nPowerShell\nTools for PowerShell\nExample 1: This command returns all the server side encryption rules associated with the \ngiven bucket.\nGet-S3BucketEncryption -BucketName 'amzn-s3-demo-bucket'\n\u2022For API details, see GetBucketEncryption in AWS Tools for PowerShell Cmdlet Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nUse GetBucketInventoryConfiguration  with a CLI\nThe following code examples show how to use GetBucketInventoryConfiguration .\nCLI\nAWS CLI\nTo retrieve the inventory con\ufb01guration for a bucket\nThe following get-bucket-inventory-configuration  example retrieves the inventory \ncon\ufb01guration for the speci\ufb01ed bucket with ID 1.\naws s3api get-bucket-inventory-configuration \\ \n    --bucket my-bucket  \\ \n    --id 1\nOutput:\nBasics API Version 2006-03-01 1981Amazon Simple Storage Service API Reference\n{ \n    \"InventoryConfiguration\": { \n        \"IsEnabled\": true, \n        \"Destination\": { \n            \"S3BucketDestination\": { \n                \"Format\": \"ORC\", \n                \"Bucket\": \"arn:aws:s3:::my-bucket\", \n                \"AccountId\": \"123456789012\" \n            } \n        }, \n        \"IncludedObjectVersions\": \"Current\", \n        \"Id\": \"1\", \n        \"Schedule\": { \n            \"Frequency\": \"Weekly\" \n        } \n    }\n}\n\u2022For API details, see GetBucketInventoryCon\ufb01guration in AWS CLI Command Reference.\nPowerShell\nTools for PowerShell\nExample 1: This command returns the details of the inventory named 'testinventory' for \nthe given S3 bucket.\nGet-S3BucketInventoryConfiguration -BucketName 'amzn-s3-demo-bucket' -InventoryId \n 'testinventory'\n\u2022For API details, see GetBucketInventoryCon\ufb01guration in AWS Tools for PowerShell Cmdlet \nReference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nUse GetBucketLifecycleConfiguration  with an AWS SDK or CLI\nThe following code examples show how to use GetBucketLifecycleConfiguration .\nBasics API Version 2006-03-01 1982Amazon Simple Storage Service API Reference\n.NET\nAWS SDK for .NET\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n        /// <summary> \n        /// Returns a configuration object for the supplied bucket name. \n        /// </summary> \n        /// <param name=\"client\">The S3 client object used to call \n        /// the GetLifecycleConfigurationAsync method.</param> \n        /// <param name=\"bucketName\">The name of the S3 bucket for which a \n        /// configuration will be created.</param> \n        /// <returns>Returns a new LifecycleConfiguration object.</returns> \n        public static async Task<LifecycleConfiguration> \n RetrieveLifecycleConfigAsync(IAmazonS3 client, string bucketName) \n        { \n            var request = new GetLifecycleConfigurationRequest() \n            { \n                BucketName = bucketName, \n            }; \n            var response = await client.GetLifecycleConfigurationAsync(request); \n            var configuration = response.Configuration; \n            return configuration; \n        }\n\u2022For API details, see GetBucketLifecycleCon\ufb01guration in AWS SDK for .NET API Reference.\nCLI\nAWS CLI\nThe following command retrieves the lifecycle con\ufb01guration for a bucket named my-\nbucket :\nBasics API Version 2006-03-01 1983Amazon Simple Storage Service API Reference\naws s3api get-bucket-lifecycle-configuration --bucket my-bucket\nOutput:\n{ \n    \"Rules\": [ \n        { \n            \"ID\": \"Move rotated logs to Glacier\", \n            \"Prefix\": \"rotated/\", \n            \"Status\": \"Enabled\", \n            \"Transitions\": [ \n                { \n                    \"Date\": \"2015-11-10T00:00:00.000Z\", \n                    \"StorageClass\": \"GLACIER\" \n                } \n            ] \n        }, \n        { \n            \"Status\": \"Enabled\", \n            \"Prefix\": \"\", \n            \"NoncurrentVersionTransitions\": [ \n                { \n                    \"NoncurrentDays\": 0, \n                    \"StorageClass\": \"GLACIER\" \n                } \n            ], \n            \"ID\": \"Move old versions to Glacier\" \n        } \n    ]\n}\n\u2022For API details, see GetBucketLifecycleCon\ufb01guration in AWS CLI Command Reference.\nPython\nSDK for Python (Boto3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nBasics API Version 2006-03-01 1984Amazon Simple Storage Service API Reference\nclass BucketWrapper: \n    \"\"\"Encapsulates S3 bucket actions.\"\"\" \n    def __init__(self, bucket): \n        \"\"\" \n        :param bucket: A Boto3 Bucket resource. This is a high-level resource in \n Boto3 \n                       that wraps bucket actions in a class-like structure.", "\n        \"\"\" \n        self.bucket = bucket \n        self.name = bucket.name \n    def get_lifecycle_configuration(self): \n        \"\"\" \n        Get the lifecycle configuration of the bucket. \n        :return: The lifecycle rules of the specified bucket. \n        \"\"\" \n        try: \n            config = self.bucket.LifecycleConfiguration() \n            logger.info( \n                \"Got lifecycle rules %s for bucket '%s'.\", \n                config.rules, \n                self.bucket.name, \n            ) \n        except: \n            logger.exception( \n                \"Couldn't get lifecycle rules for bucket '%s'.\", self.bucket.name \n            ) \n            raise \n        else: \n            return config.rules\n\u2022For API details, see GetBucketLifecycleCon\ufb01guration in AWS SDK for Python (Boto3) API \nReference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nBasics API Version 2006-03-01 1985Amazon Simple Storage Service API Reference\nUse GetBucketLocation  with an AWS SDK or CLI\nThe following code examples show how to use GetBucketLocation .\nCLI\nAWS CLI\nThe following command retrieves the location constraint for a bucket named my-bucket , if \na constraint exists:\naws s3api get-bucket-location --bucket my-bucket\nOutput:\n{ \n    \"LocationConstraint\": \"us-west-2\"\n}\n\u2022For API details, see GetBucketLocation in AWS CLI Command Reference.\nPowerShell\nTools for PowerShell\nExample 1: This command returns the location constraint for the bucket 's3testbucket', if \na constraint exists.\nGet-S3BucketLocation -BucketName 'amzn-s3-demo-bucket'\nOutput:\nValue\n-----\nap-south-1\n\u2022For API details, see GetBucketLocation in AWS Tools for PowerShell Cmdlet Reference.\nBasics API Version 2006-03-01 1986Amazon Simple Storage Service API Reference\nRust\nSDK for Rust\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nasync fn show_buckets( \n    strict: bool, \n    client: &Client, \n    region: BucketLocationConstraint,\n) -> Result<(), S3ExampleError> { \n    let mut buckets = client.list_buckets().into_paginator().send(); \n    let mut num_buckets = 0; \n    let mut in_region = 0; \n    while let Some(Ok(output)) = buckets.next().await { \n        for bucket in output.buckets() { \n            num_buckets += 1; \n            if strict { \n                let r = client \n                    .get_bucket_location() \n                    .bucket(bucket.name().unwrap_or_default()) \n                    .send() \n                    .await?; \n                if r.location_constraint() == Some(&region) { \n                    println!(\"{}\", bucket.name().unwrap_or_default()); \n                    in_region += 1; \n                } \n            } else { \n                println!(\"{}\", bucket.name().unwrap_or_default()); \n            } \n        } \n    } \n    println!(); \n    if strict { \nBasics API Version 2006-03-01 1987Amazon Simple Storage Service API Reference\n        println!( \n            \"Found {} buckets in the {} region out of a total of {} buckets.\", \n            in_region, region, num_buckets \n        ); \n    } else { \n        println!(\"Found {} buckets in all regions.\", num_buckets); \n    } \n    Ok(())\n}\n\u2022For API details, see GetBucketLocation in AWS SDK for Rust API reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nUse GetBucketLogging  with a CLI\nThe following code examples show how to use GetBucketLogging .\nCLI\nAWS CLI\nTo retrieve the logging status for a bucket\nThe following get-bucket-logging  example retrieves the logging status for the speci\ufb01ed \nbucket.\naws s3api get-bucket-logging \\ \n    --bucket my-bucket\nOutput:\n{ \n    \"LoggingEnabled\": { \n        \"TargetPrefix\": \"\", \n        \"TargetBucket\": \"my-bucket-logs\" \n          }\n}\nBasics API Version 2006-03-01 1988Amazon Simple Storage Service API Reference\n\u2022For API details, see GetBucketLogging in AWS CLI Command Reference.\nPowerShell\nTools for PowerShell\nExample 1: This command returns the logging status for the speci\ufb01ed bucket.\nGet-S3BucketLogging -BucketName 'amzn-s3-demo-bucket'\nOutput:\nTargetBucketName   Grants TargetPrefix\n----------------   ------ ------------\ntestbucket1        {}     testprefix\n\u2022For API details, see GetBucketLogging in AWS Tools for PowerShell Cmdlet Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nUse GetBucketMetricsConfiguration  with a CLI\nThe following code examples show how to use GetBucketMetricsConfiguration .\nCLI\nAWS CLI\nTo retrieve the metrics con\ufb01guration for a bucket with a speci\ufb01c ID\nThe following get-bucket-metrics-configuration  example displays the metrics \ncon\ufb01guration for the speci\ufb01ed bucket and ID.\naws s3api get-bucket-metrics-configuration \\ \n    --bucket my-bucket  \\ \n    --id 123\nOutput:\nBasics API Version 2006-03-01 1989Amazon Simple Storage Service API Reference\n{ \n    \"MetricsConfiguration\": { \n        \"Filter\": { \n            \"Prefix\": \"logs\" \n        }, \n        \"Id\": \"123\" \n    }\n}\n\u2022For API details, see GetBucketMetricsCon\ufb01guration in AWS CLI Command Reference.\nPowerShell\nTools for PowerShell\nExample 1: This command returns the details about the metrics \ufb01lter named 'test\ufb01lter' \nfor the given S3 bucket.\nGet-S3BucketMetricsConfiguration -BucketName 'amzn-s3-demo-bucket' -MetricsId \n 'testfilter'\n\u2022For API details, see GetBucketMetricsCon\ufb01guration in AWS Tools for PowerShell Cmdlet \nReference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nUse GetBucketNotification  with a CLI\nThe following code examples show how to use GetBucketNotification .\nCLI\nAWS CLI\nThe following command retrieves the noti\ufb01cation con\ufb01guration for a bucket named my-\nbucket :\naws s3api get-bucket-notification --bucket my-bucket\nBasics API Version 2006-03-01 1990Amazon Simple Storage Service API Reference\nOutput:\n{ \n    \"TopicConfiguration\": { \n        \"Topic\": \"arn:aws:sns:us-west-2:123456789012:my-notification-topic\", \n        \"Id\": \"YmQzMmEwM2EjZWVlI0NGItNzVtZjI1MC00ZjgyLWZDBiZWNl\", \n        \"Event\": \"s3:ObjectCreated:*\", \n        \"Events\": [ \n            \"s3:ObjectCreated:*\" \n        ] \n    }\n}\n\u2022For API details, see GetBucketNoti\ufb01cation in AWS CLI Command Reference.\nPowerShell\nTools for PowerShell\nExample 1: This example retrieves noti\ufb01cation con\ufb01guration of the given bucket\nGet-S3BucketNotification -BucketName amzn-s3-demo-bucket | select -ExpandProperty \n TopicConfigurations\nOutput:\nId   Topic\n--   -----\nmimo arn:aws:sns:eu-west-1:123456789012:topic-1\n\u2022For API details, see GetBucketNoti\ufb01cation in AWS Tools for PowerShell Cmdlet Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nUse GetBucketPolicy  with an AWS SDK or CLI\nThe following code examples show how to use GetBucketPolicy .\nBasics API Version 2006-03-01 1991Amazon Simple Storage Service API Reference\nC++\nSDK for C++\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nbool AwsDoc::S3::getBucketPolicy(const Aws::String &bucketName, \n                                 const Aws::S3::S3ClientConfiguration \n &clientConfig) { \n    Aws::S3::S3Client s3Client(clientConfig); \n    Aws::S3::Model::GetBucketPolicyRequest request; \n    request.SetBucket(bucketName); \n    Aws::S3::Model::GetBucketPolicyOutcome outcome = \n            s3Client.GetBucketPolicy(request); \n    if (!outcome.IsSuccess()) { \n        const Aws::S3::S3Error &err = outcome.GetError(); \n        std::cerr << \"Error: getBucketPolicy: \" \n                  << err.GetExceptionName() << \": \" << err.GetMessage() << \n std::endl; \n    } else { \n        Aws::StringStream policy_stream; \n        Aws::String line; \n        outcome.GetResult().GetPolicy() >> line; \n        policy_stream << line; \n        std::cout << \"Retrieve the policy for bucket '\" << bucketName << \"':\\n\\n\" \n << \n                  policy_stream.str() << std::endl; \n    } \n    return outcome.IsSuccess();\n}\nBasics API Version 2006-03-01 1992Amazon Simple Storage Service API Reference\n\u2022For API details, see GetBucketPolicy in AWS SDK for C++ API Reference.\nCLI\nAWS CLI\nThe following command retrieves the bucket policy for a bucket named my-bucket :\naws s3api get-bucket-policy --bucket my-bucket\nOutput:\n{ \n    \"Policy\": \"{\\\"Version\\\":\\\"2008-10-17\\\",\\\"Statement\\\":[{\\\"Sid\\\":\\\"\\\",\\\"Effect\n\\\":\\\"Allow\\\",\\\"Principal\\\":\\\"*\\\",\\\"Action\\\":\\\"s3:GetObject\\\",\\\"Resource\\\":\n\\\"arn:aws:s3:::my-bucket/*\\\"},{\\\"Sid\\\":\\\"\\\",\\\"Effect\\\":\\\"Deny\\\",\\\"Principal\\\":\n\\\"*\\\",\\\"Action\\\":\\\"s3:GetObject\\\",\\\"Resource\\\":\\\"arn:aws:s3:::my-bucket/secret/*\n\\\"}]}\"\n}\nGet and put a bucket policyThe following example shows how you can download an Amazon \nS3 bucket policy, make modi\ufb01cations to the \ufb01le, and then use put-bucket-policy  to \napply the modi\ufb01ed bucket policy. To download the bucket policy to a \ufb01le, you can run:\naws s3api get-bucket-policy --bucket mybucket --query Policy --output text > \n policy.json\nYou can then modify the policy.json  \ufb01le as needed. Finally you can apply this modi\ufb01ed \npolicy back to the S3 bucket by running:\npolicy.json  \ufb01le as needed. Finally you can apply this modi\ufb01ed policy back to the S3 \nbucket by running:\n\ufb01le as needed. Finally you can apply this modi\ufb01ed policy back to the S3 bucket by running:\naws s3api put-bucket-policy --bucket mybucket --policy file://policy.json\n\u2022For API details, see GetBucketPolicy in AWS CLI Command Reference.\nBasics API Version 2006-03-01 1993Amazon Simple Storage Service API Reference\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nimport software.amazon.awssdk.services.s3.model.S3Exception;\nimport software.amazon.awssdk.regions.Region;\nimport software.amazon.awssdk.services.s3.S3Client;\nimport software.amazon.awssdk.services.s3.model.GetBucketPolicyRequest;\nimport software.amazon.awssdk.services.s3.model.GetBucketPolicyResponse;\n/** \n * Before running this Java V2 code example, set up your development \n * environment, including your credentials. \n * <p> \n * For more information, see the following documentation topic: \n * <p> \n * https://docs.aws.amazon.com/sdk-for-java/latest/developer-guide/get-\nstarted.html \n */\npublic class GetBucketPolicy { \n    public static void main(String[] args) { \n        final String usage = \"\"\" \n            Usage: \n                <bucketName> \n            Where: \n                bucketName - The Amazon S3 bucket to get the policy from. \n            \"\"\"; \n        if (args.length != 1) { \n            System.out.println(usage); \n            System.exit(1); \n        } \nBasics API Version 2006-03-01 1994Amazon Simple Storage Service API Reference\n        String bucketName = args[0]; \n        System.out.format(\"Getting policy for bucket: \\\"%s\\\"\\n\\n\", bucketName); \n        Region region = Region.US_EAST_1; \n        S3Client s3 = S3Client.builder() \n            .region(region) \n            .build(); \n        String polText = getPolicy(s3, bucketName); \n        System.out.println(\"Policy Text: \" + polText); \n        s3.close(); \n    } \n    /** \n     * Retrieves the policy for the specified Amazon S3 bucket. \n     * \n     * @param s3 the {@link S3Client} instance to use for making the request \n     * @param bucketName the name of the S3 bucket for which to retrieve the \n policy \n     * @return the policy text for the specified bucket, or an empty string if an \n error occurs \n     */ \n    public static String getPolicy(S3Client s3, String bucketName) { \n        String policyText; \n        System.out.format(\"Getting policy for bucket: \\\"%s\\\"\\n\\n\", bucketName); \n        GetBucketPolicyRequest policyReq = GetBucketPolicyRequest.builder() \n            .bucket(bucketName) \n            .build(); \n        try { \n            GetBucketPolicyResponse policyRes = s3.getBucketPolicy(policyReq); \n            policyText = policyRes.policy(); \n            return policyText; \n        } catch (S3Exception e) { \n            System.err.println(e.awsErrorDetails().errorMessage()); \n            System.exit(1); \n        } \n        return \"\"; \n    }\n}\nBasics API Version 2006-03-01 1995Amazon Simple Storage Service API Reference\n\u2022For API details, see GetBucketPolicy in AWS SDK for Java 2.x API Reference.\nJavaScript\nSDK for JavaScript (v3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nGet the bucket policy.\nimport { \n  GetBucketPolicyCommand, \n  S3Client, \n  S3ServiceException,\n} from \"@aws-sdk/client-s3\";\n/** \n * Logs the policy for a specified bucket. \n * @param {{ bucketName: string }} \n */\nexport const main = async ({ bucketName }) => { \n  const client = new S3Client({}); \n  try { \n    const { Policy } = await client.send( \n      new GetBucketPolicyCommand({ \n        Bucket: bucketName, \n      }), \n    ); \n    console.log(`Policy for \"${bucketName}\":\\n${Policy}`); \n  } catch (caught) { \n    if ( \n      caught instanceof S3ServiceException && \n      caught.name === \"NoSuchBucket\" \n    ) { \n      console.error( \n        `Error from S3 while getting policy from ${bucketName}. The bucket \n doesn't exist.`, \nBasics API Version 2006-03-01 1996Amazon Simple Storage Service API Reference\n      ); \n    } else if (caught instanceof S3ServiceException) { \n      console.error( \n        `Error from S3 while getting policy from ${bucketName}.", "${caught.name}: \n ${caught.message}`, \n      ); \n    } else { \n      throw caught; \n    } \n  }\n};\n\u2022For more information, see AWS SDK for JavaScript Developer Guide.\n\u2022For API details, see GetBucketPolicy in AWS SDK for JavaScript API Reference.\nKotlin\nSDK for Kotlin\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nsuspend fun getPolicy(bucketName: String): String?", "{ \n    println(\"Getting policy for bucket $bucketName\") \n    val request = \n        GetBucketPolicyRequest { \n            bucket = bucketName \n        } \n    S3Client { region = \"us-east-1\" }.use { s3 -> \n        val policyRes = s3.getBucketPolicy(request) \n        return policyRes.policy \n    }\n}\nBasics API Version 2006-03-01 1997Amazon Simple Storage Service API Reference\n\u2022For API details, see GetBucketPolicy in AWS SDK for Kotlin API reference.\nPowerShell\nTools for PowerShell\nExample 1: This command outputs the bucket policy associated with the given S3 bucket.\nGet-S3BucketPolicy -BucketName 'amzn-s3-demo-bucket'\n\u2022For API details, see GetBucketPolicy in AWS Tools for PowerShell Cmdlet Reference.\nPython\nSDK for Python (Boto3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nclass BucketWrapper: \n    \"\"\"Encapsulates S3 bucket actions.\"\"\" \n    def __init__(self, bucket): \n        \"\"\" \n        :param bucket: A Boto3 Bucket resource. This is a high-level resource in \n Boto3 \n                       that wraps bucket actions in a class-like structure.", "\n        \"\"\" \n        self.bucket = bucket \n        self.name = bucket.name \n    def get_policy(self): \n        \"\"\" \n        Get the security policy of the bucket. \n        :return: The security policy of the specified bucket, in JSON format.", "\nBasics API Version 2006-03-01 1998Amazon Simple Storage Service API Reference\n        \"\"\" \n        try: \n            policy = self.bucket.Policy() \n            logger.info( \n                \"Got policy %s for bucket '%s'.\", policy.policy, self.bucket.name \n            ) \n        except ClientError: \n            logger.exception(\"Couldn't get policy for bucket '%s'.\", \n self.bucket.name) \n            raise \n        else: \n            return json.loads(policy.policy)\n\u2022For API details, see GetBucketPolicy in AWS SDK for Python (Boto3) API Reference.\nRuby\nSDK for Ruby\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n# Wraps an Amazon S3 bucket policy.\nclass BucketPolicyWrapper \n  attr_reader :bucket_policy \n  # @param bucket_policy [Aws::S3::BucketPolicy] A bucket policy object \n configured with an existing bucket.", "\n  def initialize(bucket_policy) \n    @bucket_policy = bucket_policy \n  end \n  # Gets the policy of a bucket.", "\n  # \n  # @return [Aws::S3::GetBucketPolicyOutput, nil] The current bucket policy.", "\n  def policy \n    policy = @bucket_policy.data.policy \nBasics API Version 2006-03-01 1999Amazon Simple Storage Service API Reference\n    policy.respond_to?(:read) ? policy.read : policy \n  rescue Aws::Errors::ServiceError => e \n    puts \"Couldn't get the policy for #{@bucket_policy.bucket.name}.", "Here's why: \n #{e.message}\" \n    nil \n  end\nend\n\u2022For API details, see GetBucketPolicy in AWS SDK for Ruby API Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nUse GetBucketPolicyStatus  with a CLI\nThe following code examples show how to use GetBucketPolicyStatus .\nCLI\nAWS CLI\nTo retrieve the policy status for a bucket indicating whether the bucket is public\nThe following get-bucket-policy-status  example retrieves the policy status for the \nbucket my-bucket .\naws s3api get-bucket-policy-status \\ \n    --bucket my-bucket\nOutput:\n{ \n    \"PolicyStatus\": { \n        \"IsPublic\": false \n    }\n}\n\u2022For API details, see GetBucketPolicyStatus in AWS CLI Command Reference.\nBasics API Version 2006-03-01 2000Amazon Simple Storage Service API Reference\nPowerShell\nTools for PowerShell\nExample 1: This command returns policy status for the given S3 bucket, indicating \nwhether the bucket is public.\nGet-S3BucketPolicyStatus -BucketName 'amzn-s3-demo-bucket'\n\u2022For API details, see GetBucketPolicyStatus in AWS Tools for PowerShell Cmdlet Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nUse GetBucketReplication  with a CLI\nThe following code examples show how to use GetBucketReplication .\nCLI\nAWS CLI\nThe following command retrieves the replication con\ufb01guration for a bucket named my-\nbucket :\naws s3api get-bucket-replication --bucket my-bucket\nOutput:\n{ \n    \"ReplicationConfiguration\": { \n        \"Rules\": [ \n            { \n                \"Status\": \"Enabled\", \n                \"Prefix\": \"\", \n                \"Destination\": { \n                    \"Bucket\": \"arn:aws:s3:::my-bucket-backup\", \n                    \"StorageClass\": \"STANDARD\" \n                }, \n                \"ID\": \"ZmUwNzE4ZmQ4tMjVhOS00MTlkLOGI4NDkzZTIWJjNTUtYTA1\" \nBasics API Version 2006-03-01 2001Amazon Simple Storage Service API Reference\n            } \n        ], \n        \"Role\": \"arn:aws:iam::123456789012:role/s3-replication-role\" \n    }\n}\n\u2022For API details, see GetBucketReplication in AWS CLI Command Reference.\nPowerShell\nTools for PowerShell\nExample 1: Returns the replication con\ufb01guration information set on the bucket named \n'mybucket'.\nGet-S3BucketReplication -BucketName amzn-s3-demo-bucket\n\u2022For API details, see GetBucketReplication in AWS Tools for PowerShell Cmdlet Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nUse GetBucketRequestPayment  with a CLI\nThe following code examples show how to use GetBucketRequestPayment .\nCLI\nAWS CLI\nTo retrieve the request payment con\ufb01guration for a bucket\nThe following get-bucket-request-payment  example retrieves the requester pays \ncon\ufb01guration for the speci\ufb01ed bucket.\naws s3api get-bucket-request-payment \\ \n    --bucket my-bucket\nOutput:\nBasics API Version 2006-03-01 2002Amazon Simple Storage Service API Reference\n{ \n    \"Payer\": \"BucketOwner\"\n}\n\u2022For API details, see GetBucketRequestPayment in AWS CLI Command Reference.\nPowerShell\nTools for PowerShell\nExample 1: Returns the request payment con\ufb01guration for the bucket named 'mybucket'. \nBy default, the bucket owner pays for downloads from the bucket.\nGet-S3BucketRequestPayment -BucketName amzn-s3-demo-bucket\n\u2022For API details, see GetBucketRequestPayment in AWS Tools for PowerShell Cmdlet \nReference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nUse GetBucketTagging  with a CLI\nThe following code examples show how to use GetBucketTagging .\nCLI\nAWS CLI\nThe following command retrieves the tagging con\ufb01guration for a bucket named my-\nbucket :\naws s3api get-bucket-tagging --bucket my-bucket\nOutput:\n{ \n    \"TagSet\": [ \nBasics API Version 2006-03-01 2003Amazon Simple Storage Service API Reference\n        { \n            \"Value\": \"marketing\", \n            \"Key\": \"organization\" \n        } \n    ]\n}\n\u2022For API details, see GetBucketTagging in AWS CLI Command Reference.\nPowerShell\nTools for PowerShell\nExample 1: This command returns all the tags associated with the given bucket.\nGet-S3BucketTagging -BucketName 'amzn-s3-demo-bucket'\n\u2022For API details, see GetBucketTagging in AWS Tools for PowerShell Cmdlet Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nUse GetBucketVersioning  with a CLI\nThe following code examples show how to use GetBucketVersioning .\nCLI\nAWS CLI\nThe following command retrieves the versioning con\ufb01guration for a bucket named my-\nbucket :\naws s3api get-bucket-versioning --bucket my-bucket\nOutput:\n{ \nBasics API Version 2006-03-01 2004Amazon Simple Storage Service API Reference\n    \"Status\": \"Enabled\"\n}\n\u2022For API details, see GetBucketVersioning in AWS CLI Command Reference.\nPowerShell\nTools for PowerShell\nExample 1: This command returns the status of versioning with respect to the given \nbucket.\nGet-S3BucketVersioning -BucketName 'amzn-s3-demo-bucket'\n\u2022For API details, see GetBucketVersioning in AWS Tools for PowerShell Cmdlet Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nUse GetBucketWebsite  with an AWS SDK or CLI\nThe following code examples show how to use GetBucketWebsite .\n.NET\nAWS SDK for .NET\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n                // Get the website configuration. \n                GetBucketWebsiteRequest getRequest = new \n GetBucketWebsiteRequest() \n                { \n                    BucketName = bucketName, \nBasics API Version 2006-03-01 2005Amazon Simple Storage Service API Reference\n                }; \n                GetBucketWebsiteResponse getResponse = await \n client.GetBucketWebsiteAsync(getRequest); \n                Console.WriteLine($\"Index document: \n {getResponse.WebsiteConfiguration.IndexDocumentSuffix}\"); \n                Console.WriteLine($\"Error document: \n {getResponse.WebsiteConfiguration.ErrorDocument}\");\n\u2022For API details, see GetBucketWebsite in AWS SDK for .NET API Reference.\nC++\nSDK for C++\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nbool AwsDoc::S3::getWebsiteConfig(const Aws::String &bucketName, \n                                  const Aws::S3::S3ClientConfiguration \n &clientConfig) { \n    Aws::S3::S3Client s3Client(clientConfig); \n    Aws::S3::Model::GetBucketWebsiteRequest request; \n    request.SetBucket(bucketName); \n    Aws::S3::Model::GetBucketWebsiteOutcome outcome = \n            s3Client.GetBucketWebsite(request); \n    if (!outcome.IsSuccess()) { \n        const Aws::S3::S3Error &err = outcome.GetError(); \n        std::cerr << \"Error: GetBucketWebsite: \" \n                  << err.GetMessage() << std::endl; \n    } else { \n        Aws::S3::Model::GetBucketWebsiteResult websiteResult = \n outcome.GetResult(); \nBasics API Version 2006-03-01 2006Amazon Simple Storage Service API Reference\n        std::cout << \"Success: GetBucketWebsite: \" \n                  << std::endl << std::endl \n                  << \"For bucket '\" << bucketName << \"':\" \n                  << std::endl \n                  << \"Index page : \" \n                  << websiteResult.GetIndexDocument().GetSuffix() \n                  << std::endl \n                  << \"Error page: \" \n                  << websiteResult.GetErrorDocument().GetKey() \n                  << std::endl; \n    } \n    return outcome.IsSuccess();\n}\n\u2022For API details, see GetBucketWebsite in AWS SDK for C++ API Reference.\nCLI\nAWS CLI\nThe following command retrieves the static website con\ufb01guration for a bucket named my-\nbucket :\naws s3api get-bucket-website --bucket my-bucket\nOutput:\n{ \n    \"IndexDocument\": { \n        \"Suffix\": \"index.html\" \n    }, \n    \"ErrorDocument\": { \n        \"Key\": \"error.html\" \n    }\n}\n\u2022For API details, see GetBucketWebsite in AWS CLI Command Reference.\nBasics API Version 2006-03-01 2007Amazon Simple Storage Service API Reference\nJavaScript\nSDK for JavaScript (v3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nGet the website con\ufb01guration.\nimport { \n  GetBucketWebsiteCommand, \n  S3Client, \n  S3ServiceException,\n} from \"@aws-sdk/client-s3\";\n/** \n * Log the website configuration for a bucket. \n * @param {{ bucketName }} \n */\nexport const main = async ({ bucketName }) => { \n  const client = new S3Client({}); \n  try { \n    const response = await client.send( \n      new GetBucketWebsiteCommand({ \n        Bucket: bucketName, \n      }), \n    ); \n    console.log( \n      `Your bucket is set up to host a website with the following configuration:\n\\n${JSON.stringify(response, null, 2)}`, \n    ); \n  } catch (caught) { \n    if ( \n      caught instanceof S3ServiceException && \n      caught.name === \"NoSuchWebsiteConfiguration\" \n    ) { \n      console.error( \n        `Error from S3 while getting website configuration for ${bucketName}. The \n bucket isn't configured as a website.`, \nBasics API Version 2006-03-01 2008Amazon Simple Storage Service API Reference\n      ); \n    } else if (caught instanceof S3ServiceException) { \n      console.error( \n        `Error from S3 while getting website configuration for ${bucketName}. \n ${caught.name}: ${caught.message}`, \n      ); \n    } else { \n      throw caught; \n    } \n  }\n};\n\u2022For API details, see GetBucketWebsite in AWS SDK for JavaScript API Reference.\nPowerShell\nTools for PowerShell\nExample 1: This command returns the details of the static website con\ufb01gurations of the \ngiven S3 bucket.\nGet-S3BucketWebsite -BucketName 'amzn-s3-demo-bucket'\n\u2022For API details, see GetBucketWebsite in AWS Tools for PowerShell Cmdlet Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs.", "This topic also includes information about getting started and details \nabout previous SDK versions.\nUse GetObject  with an AWS SDK or CLI\nThe following code examples show how to use GetObject .\nAction examples are code excerpts from larger programs and must be run in context. You can see \nthis action in context in the following code examples:\n\u2022Learn the basics\n\u2022Get an object from a bucket if it has been modi\ufb01ed\n\u2022Get an object from a Multi-Region Access Point\nBasics API Version 2006-03-01 2009Amazon Simple Storage Service API Reference\n\u2022Get started with encryption\n\u2022Track uploads and downloads\n.NET\nAWS SDK for .NET\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n        /// <summary> \n        /// Shows how to download an object from an Amazon S3 bucket to the \n        /// local computer. \n        /// </summary> \n        /// <param name=\"client\">An initialized Amazon S3 client object.</param> \n        /// <param name=\"bucketName\">The name of the bucket where the object is \n        /// currently stored.</param> \n        /// <param name=\"objectName\">The name of the object to download.</param> \n        /// <param name=\"filePath\">The path, including filename, where the \n        /// downloaded object will be stored.</param> \n        /// <returns>A boolean value indicating the success or failure of the \n        /// download process.</returns> \n        public static async Task<bool> DownloadObjectFromBucketAsync( \n            IAmazonS3 client, \n            string bucketName, \n            string objectName, \n            string filePath) \n        { \n            // Create a GetObject request \n            var request = new GetObjectRequest \n            { \n                BucketName = bucketName, \n                Key = objectName, \n            }; \n            // Issue request and remember to dispose of the response \nBasics API Version 2006-03-01 2010Amazon Simple Storage Service API Reference\n            using GetObjectResponse response = await \n client.GetObjectAsync(request); \n            try \n            { \n                // Save object to local file \n                await response.WriteResponseStreamToFileAsync($\"{filePath}\\\n\\{objectName}\", true, CancellationToken.None); \n                return response.HttpStatusCode == System.Net.HttpStatusCode.OK; \n            } \n            catch (AmazonS3Exception ex) \n            { \n                Console.WriteLine($\"Error saving {objectName}: {ex.Message}\"); \n                return false; \n            } \n        }\n\u2022For API details, see GetObject in AWS SDK for .NET API Reference.\nBash\nAWS CLI with Bash script\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n###############################################################################\n# function errecho\n#\n# This function outputs everything sent to it to STDERR (standard error output).\n###############################################################################\nfunction errecho() { \n  printf \"%s\\n\" \"$*\" 1>&2\n}\n###############################################################################\n# function download_object_from_bucket\nBasics API Version 2006-03-01 2011Amazon Simple Storage Service API Reference\n#\n# This function downloads an object in a bucket to a file.\n#\n# Parameters:\n#       $1 - The name of the bucket to download the object from.\n#       $2 - The path and file name to store the downloaded bucket.\n#       $3 - The key (name) of the object in the bucket.\n#\n# Returns:\n#       0 - If successful.\n#       1 - If it fails.\n###############################################################################\nfunction download_object_from_bucket() { \n  local bucket_name=$1 \n  local destination_file_name=$2 \n  local object_name=$3 \n  local response \n  response=$(aws s3api get-object \\ \n    --bucket \"$bucket_name\" \\ \n    --key \"$object_name\" \\ \n    \"$destination_file_name\") \n  # shellcheck disable=SC2181 \n  if [[ ${?} -ne 0 ]]; then \n    errecho \"ERROR: AWS reports put-object operation failed.\\n$response\" \n    return 1 \n  fi\n}\n\u2022For API details, see GetObject in AWS CLI Command Reference.\nC++\nSDK for C++\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nBasics API Version 2006-03-01 2012Amazon Simple Storage Service API Reference\nbool AwsDoc::S3::getObject(const Aws::String &objectKey, \n                           const Aws::String &fromBucket, \n                           const Aws::S3::S3ClientConfiguration &clientConfig) { \n    Aws::S3::S3Client client(clientConfig); \n    Aws::S3::Model::GetObjectRequest request; \n    request.SetBucket(fromBucket); \n    request.SetKey(objectKey); \n    Aws::S3::Model::GetObjectOutcome outcome = \n            client.GetObject(request); \n    if (!outcome.IsSuccess()) { \n        const Aws::S3::S3Error &err = outcome.GetError(); \n        std::cerr << \"Error: getObject: \" << \n                  err.GetExceptionName() << \": \" << err.GetMessage() << \n std::endl; \n    } else { \n        std::cout << \"Successfully retrieved '\" << objectKey << \"' from '\" \n                  << fromBucket << \"'.\" << std::endl; \n    } \n    return outcome.IsSuccess();\n}\n\u2022For API details, see GetObject in AWS SDK for C++ API Reference.\nCLI\nAWS CLI\nThe following example uses the get-object  command to download an object from \nAmazon S3:\naws s3api get-object --bucket text-content  --key dir/\nmy_images.tar.bz2  my_images.tar.bz2\nNote that the out\ufb01le parameter is speci\ufb01ed without an option name such as \"--out\ufb01le\".", "The \nname of the output \ufb01le must be the last parameter in the command.\nBasics API Version 2006-03-01 2013Amazon Simple Storage Service API Reference\nThe example below demonstrates the use of --range to download a speci\ufb01c byte range \nfrom an object.", "Note the byte ranges needs to be pre\ufb01xed with \"bytes=\":\naws s3api get-object --bucket text-content  --key dir/my_data  --\nrange bytes=8888-9999  my_data_range\nFor more information about retrieving objects, see Getting Objects in the Amazon S3 \nDeveloper Guide .\n\u2022For API details, see GetObject in AWS CLI Command Reference.\nGo\nSDK for Go V2\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n// BucketBasics encapsulates the Amazon Simple Storage Service (Amazon S3) \n actions\n// used in the examples.\n// It contains S3Client, an Amazon S3 service client that is used to perform \n bucket\n// and object actions.\ntype BucketBasics struct { \n S3Client *s3.Client\n}\n// DownloadFile gets an object from a bucket and stores it in a local file.\nfunc (basics BucketBasics) DownloadFile(ctx context.Context, bucketName string, \n objectKey string, fileName string) error { \n result, err := basics.S3Client.GetObject(ctx, &s3.GetObjectInput{ \n  Bucket: aws.String(bucketName), \n  Key:    aws.String(objectKey), \n }) \nBasics API Version 2006-03-01 2014Amazon Simple Storage Service API Reference\n if err != nil { \n  log.Printf(\"Couldn't get object %v:%v.", "Here's why: %v\\n\", bucketName, \n objectKey, err) \n  return err \n } \n defer result.Body.Close() \n file, err := os.Create(fileName) \n if err != nil { \n  log.Printf(\"Couldn't create file %v. Here's why: %v\\n\", fileName, err) \n  return err \n } \n defer file.Close() \n body, err := io.ReadAll(result.Body) \n if err != nil { \n  log.Printf(\"Couldn't read object body from %v. Here's why: %v\\n\", objectKey, \n err) \n } \n _, err = file.Write(body) \n return err\n}\n\u2022For API details, see GetObject in AWS SDK for Go API Reference.\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nRead data as a byte array using an S3Client .\n    /** \n     * Asynchronously retrieves the bytes of an object from an Amazon S3 bucket \n and writes them to a local file. \n     * \nBasics API Version 2006-03-01 2015Amazon Simple Storage Service API Reference\n     * @param bucketName the name of the S3 bucket containing the object \n     * @param keyName    the key (or name) of the S3 object to retrieve \n     * @param path       the local file path where the object's bytes will be \n written \n     * @return a {@link CompletableFuture} that completes when the object bytes \n have been written to the local file \n     */ \n    public CompletableFuture<Void> getObjectBytesAsync(String bucketName, String \n keyName, String path) { \n        GetObjectRequest objectRequest = GetObjectRequest.builder() \n            .key(keyName) \n            .bucket(bucketName) \n            .build(); \n        CompletableFuture<ResponseBytes<GetObjectResponse>> response = \n getAsyncClient().getObject(objectRequest, AsyncResponseTransformer.toBytes()); \n        return response.thenAccept(objectBytes -> { \n            try { \n                byte[] data = objectBytes.asByteArray(); \n                Path filePath = Paths.get(path); \n                Files.write(filePath, data); \n                logger.info(\"Successfully obtained bytes from an S3 object\"); \n            } catch (IOException ex) { \n                throw new RuntimeException(\"Failed to write data to file\", ex); \n            } \n        }).whenComplete((resp, ex) -> { \n            if (ex != null) { \n                throw new RuntimeException(\"Failed to get object bytes from S3\", \n ex); \n            } \n        }); \n    }\nUse an S3TransferManager to download an object in an S3 bucket to a local \ufb01le. View the\ncomplete \ufb01le and test.\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\nimport software.amazon.awssdk.core.sync.RequestBody;\nimport software.amazon.awssdk.transfer.s3.S3TransferManager;\nimport software.amazon.awssdk.transfer.s3.model.CompletedFileDownload;\nBasics API Version 2006-03-01 2016Amazon Simple Storage Service API Reference\nimport software.amazon.awssdk.transfer.s3.model.DownloadFileRequest;\nimport software.amazon.awssdk.transfer.s3.model.FileDownload;\nimport software.amazon.awssdk.transfer.s3.progress.LoggingTransferListener;\nimport java.io.IOException;\nimport java.net.URISyntaxException;\nimport java.net.URL;\nimport java.nio.file.Files;\nimport java.nio.file.Path;\nimport java.nio.file.Paths;\nimport java.util.UUID; \n    public Long downloadFile(S3TransferManager transferManager, String \n bucketName, \n                             String key, String downloadedFileWithPath) { \n        DownloadFileRequest downloadFileRequest = DownloadFileRequest.builder() \n                .getObjectRequest(b -> b.bucket(bucketName).key(key)) \n                .destination(Paths.get(downloadedFileWithPath)) \n                .build(); \n        FileDownload downloadFile = \n transferManager.downloadFile(downloadFileRequest); \n        CompletedFileDownload downloadResult = \n downloadFile.completionFuture().join(); \n        logger.info(\"Content length [{}]\", \n downloadResult.response().contentLength()); \n        return downloadResult.response().contentLength(); \n    }\nRead tags that belong to an object using an S3Client .\nimport software.amazon.awssdk.regions.Region;\nimport software.amazon.awssdk.services.s3.S3Client;\nimport software.amazon.awssdk.services.s3.model.GetObjectTaggingRequest;\nimport software.amazon.awssdk.services.s3.model.GetObjectTaggingResponse;\nimport software.amazon.awssdk.services.s3.model.S3Exception;\nimport software.amazon.awssdk.services.s3.model.Tag;\nimport java.util.List;\nBasics API Version 2006-03-01 2017Amazon Simple Storage Service API Reference\n/** \n * Before running this Java V2 code example, set up your development \n * environment, including your credentials. \n * <p> \n * For more information, see the following documentation topic: \n * <p> \n * https://docs.aws.amazon.com/sdk-for-java/latest/developer-guide/get-\nstarted.html \n */\npublic class GetObjectTags { \n    public static void main(String[] args) { \n        final String usage = \"\"\" \n            Usage: \n                <bucketName> <keyName>\\s \n            Where: \n                bucketName - The Amazon S3 bucket name.\\s \n                keyName - A key name that represents the object.\\s \n            \"\"\"; \n        if (args.length != 2) { \n            System.out.println(usage); \n            System.exit(1); \n        } \n        String bucketName = args[0]; \n        String keyName = args[1]; \n        Region region = Region.US_EAST_1; \n        S3Client s3 = S3Client.builder() \n            .region(region) \n            .build(); \n        listTags(s3, bucketName, keyName); \n        s3.close(); \n    } \n    /** \n     * Lists the tags associated with an Amazon S3 object. \n     * \n     * @param s3 the S3Client object used to interact with the Amazon S3 service \n     * @param bucketName the name of the S3 bucket that contains the object \n     * @param keyName the key (name) of the S3 object \nBasics API Version 2006-03-01 2018Amazon Simple Storage Service API Reference\n     */ \n    public static void listTags(S3Client s3, String bucketName, String keyName) { \n        try { \n            GetObjectTaggingRequest getTaggingRequest = GetObjectTaggingRequest \n                .builder() \n                .key(keyName) \n                .bucket(bucketName) \n                .build(); \n            GetObjectTaggingResponse tags = \n s3.getObjectTagging(getTaggingRequest); \n            List<Tag> tagSet = tags.tagSet(); \n            for (Tag tag : tagSet) { \n                System.out.println(tag.key()); \n                System.out.println(tag.value()); \n            } \n        } catch (S3Exception e) { \n            System.err.println(e.awsErrorDetails().errorMessage()); \n            System.exit(1); \n        } \n    }\n}\nGet a URL for an object using an S3Client .\nimport software.amazon.awssdk.regions.Region;\nimport software.amazon.awssdk.services.s3.S3Client;\nimport software.amazon.awssdk.services.s3.model.GetUrlRequest;\nimport software.amazon.awssdk.services.s3.model.S3Exception;\nimport java.net.URL;\n/** \n * Before running this Java V2 code example, set up your development \n * environment, including your credentials. \n * <p> \n * For more information, see the following documentation topic: \n * <p> \n * https://docs.aws.amazon.com/sdk-for-java/latest/developer-guide/get-\nstarted.html \nBasics API Version 2006-03-01 2019Amazon Simple Storage Service API Reference\n */\npublic class GetObjectUrl { \n    public static void main(String[] args) { \n        final String usage = \"\"\" \n            Usage: \n                <bucketName> <keyName>\\s \n            Where: \n                bucketName - The Amazon S3 bucket name. \n                keyName - A key name that represents the object.\\s \n            \"\"\"; \n        if (args.length != 2) { \n            System.out.println(usage); \n            System.exit(1); \n        } \n        String bucketName = args[0]; \n        String keyName = args[1]; \n        Region region = Region.US_EAST_1; \n        S3Client s3 = S3Client.builder() \n            .region(region) \n            .build(); \n        getURL(s3, bucketName, keyName); \n        s3.close(); \n    } \n    /** \n     * Retrieves the URL for a specific object in an Amazon S3 bucket. \n     * \n     * @param s3 the S3Client object used to interact with the Amazon S3 service \n     * @param bucketName the name of the S3 bucket where the object is stored \n     * @param keyName the name of the object for which the URL should be \n retrieved \n     * @throws S3Exception if there is an error retrieving the URL for the \n specified object \n     */ \n    public static void getURL(S3Client s3, String bucketName, String keyName) { \n        try { \n            GetUrlRequest request = GetUrlRequest.builder() \n                .bucket(bucketName) \nBasics API Version 2006-03-01 2020Amazon Simple Storage Service API Reference\n                .key(keyName) \n                .build(); \n            URL url = s3.utilities().getUrl(request); \n            System.out.println(\"The URL for  \" + keyName + \" is \" + url); \n        } catch (S3Exception e) { \n            System.err.println(e.awsErrorDetails().errorMessage()); \n            System.exit(1); \n        } \n    }\n}\nGet an object by using the S3Presigner client object using an S3Client .\nimport java.io.IOException;\nimport java.io.InputStream;\nimport java.io.OutputStream;\nimport java.net.HttpURLConnection;\nimport java.time.Duration;\nimport software.amazon.awssdk.regions.Region;\nimport software.amazon.awssdk.services.s3.model.GetObjectRequest;\nimport software.amazon.awssdk.services.s3.model.S3Exception;\nimport \n software.amazon.awssdk.services.s3.presigner.model.GetObjectPresignRequest;\nimport \n software.amazon.awssdk.services.s3.presigner.model.PresignedGetObjectRequest;\nimport software.amazon.awssdk.services.s3.presigner.S3Presigner;\nimport software.amazon.awssdk.utils.IoUtils;\n/** \n * Before running this Java V2 code example, set up your development \n * environment, including your credentials. \n * <p> \n * For more information, see the following documentation topic: \n * <p> \n * https://docs.aws.amazon.com/sdk-for-java/latest/developer-guide/get-\nstarted.html \n */\npublic class GetObjectPresignedUrl { \nBasics API Version 2006-03-01 2021Amazon Simple Storage Service API Reference\n    public static void main(String[] args) { \n        final String USAGE = \"\"\" \n            Usage: \n                <bucketName> <keyName>\\s \n            Where: \n                bucketName - The Amazon S3 bucket name.\\s \n                keyName - A key name that represents a text file.\\s \n            \"\"\"; \n        if (args.length != 2) { \n            System.out.println(USAGE); \n            System.exit(1); \n        } \n        String bucketName = args[0]; \n        String keyName = args[1]; \n        Region region = Region.US_EAST_1; \n        S3Presigner presigner = S3Presigner.builder() \n            .region(region) \n            .build(); \n        getPresignedUrl(presigner, bucketName, keyName); \n        presigner.close(); \n    } \n    /** \n     * Generates a pre-signed URL for an Amazon S3 object. \n     * \n     * @param presigner The {@link S3Presigner} instance to use for generating \n the pre-signed URL.", "\n     * @param bucketName The name of the Amazon S3 bucket where the object is \n stored. \n     * @param keyName The key name (file name) of the object in the Amazon S3 \n bucket. \n     * \n     * @throws S3Exception If there is an error interacting with the Amazon S3 \n service.", "\n     * @throws IOException If there is an error opening the HTTP connection or \n reading/writing the request/response.", "\n     */ \n    public static void getPresignedUrl(S3Presigner presigner, String bucketName, \n String keyName) { \nBasics API Version 2006-03-01 2022Amazon Simple Storage Service API Reference\n        try { \n            GetObjectRequest getObjectRequest = GetObjectRequest.builder() \n                .bucket(bucketName) \n                .key(keyName) \n                .build(); \n            GetObjectPresignRequest getObjectPresignRequest = \n GetObjectPresignRequest.builder() \n                .signatureDuration(Duration.ofMinutes(60)) \n                .getObjectRequest(getObjectRequest) \n                .build(); \n            PresignedGetObjectRequest presignedGetObjectRequest = \n presigner.presignGetObject(getObjectPresignRequest); \n            String theUrl = presignedGetObjectRequest.url().toString(); \n            System.out.println(\"Presigned URL: \" + theUrl); \n            HttpURLConnection connection = (HttpURLConnection) \n presignedGetObjectRequest.url().openConnection(); \n            presignedGetObjectRequest.httpRequest().headers().forEach((header, \n values) -> { \n                values.forEach(value -> { \n                    connection.addRequestProperty(header, value); \n                }); \n            }); \n            // Send any request payload that the service needs (not needed when \n            // isBrowserExecutable is true).", "\n            if (presignedGetObjectRequest.signedPayload().isPresent()) { \n                connection.setDoOutput(true); \n                try (InputStream signedPayload = \n presignedGetObjectRequest.signedPayload().get().asInputStream(); \n                     OutputStream httpOutputStream = \n connection.getOutputStream()) { \n                    IoUtils.copy(signedPayload, httpOutputStream); \n                } \n            } \n            // Download the result of executing the request.", "\n            try (InputStream content = connection.getInputStream()) { \n                System.out.println(\"Service returned response: \"); \n                IoUtils.copy(content, System.out); \n            } \nBasics API Version 2006-03-01 2023Amazon Simple Storage Service API Reference\n        } catch (S3Exception | IOException e) { \n            e.getStackTrace(); \n        } \n    }\n}\nGet an object by using a ResponseTransformer object and S3Client .\nimport software.amazon.awssdk.core.ResponseBytes;\nimport software.amazon.awssdk.core.sync.ResponseTransformer;\nimport software.amazon.awssdk.regions.Region;\nimport software.amazon.awssdk.services.s3.S3Client;\nimport software.amazon.awssdk.services.s3.model.GetObjectRequest;\nimport software.amazon.awssdk.services.s3.model.S3Exception;\nimport software.amazon.awssdk.services.s3.model.GetObjectResponse;\nimport java.io.File;\nimport java.io.FileOutputStream;\nimport java.io.IOException;\nimport java.io.OutputStream;\n/** \n * Before running this Java V2 code example, set up your development \n * environment, including your credentials. \n * <p> \n * For more information, see the following documentation topic: \n * <p> \n * https://docs.aws.amazon.com/sdk-for-java/latest/developer-guide/get-\nstarted.html \n */\npublic class GetObjectData { \n    public static void main(String[] args) { \n        final String usage = \"\"\" \n            Usage: \n                <bucketName> <keyName> <path> \n            Where: \n                bucketName - The Amazon S3 bucket name.\\s \n                keyName - The key name.\\s \nBasics API Version 2006-03-01 2024Amazon Simple Storage Service API Reference\n                path - The path where the file is written to.\\s \n            \"\"\"; \n        if (args.length != 3) { \n            System.out.println(usage); \n            System.exit(1); \n        } \n        String bucketName = args[0]; \n        String keyName = args[1]; \n        String path = args[2]; \n        Region region = Region.US_EAST_1; \n        S3Client s3 = S3Client.builder() \n            .region(region) \n            .build(); \n        getObjectBytes(s3, bucketName, keyName, path); \n        s3.close(); \n    } \n    /** \n     * Retrieves the bytes of an object stored in an Amazon S3 bucket and saves \n them to a local file. \n     * \n     * @param s3 The S3Client instance used to interact with the Amazon S3 \n service. \n     * @param bucketName The name of the S3 bucket where the object is stored. \n     * @param keyName The key (or name) of the S3 object.", "\n     * @param path The local file path where the object's bytes will be saved. \n     * @throws IOException If an I/O error occurs while writing the bytes to the \n local file.", "\n     * @throws S3Exception If an error occurs while retrieving the object from \n the S3 bucket. \n     */ \n    public static void getObjectBytes(S3Client s3, String bucketName, String \n keyName, String path) { \n        try { \n            GetObjectRequest objectRequest = GetObjectRequest \n                .builder() \n                .key(keyName) \n                .bucket(bucketName) \n                .build(); \nBasics API Version 2006-03-01 2025Amazon Simple Storage Service API Reference\n            ResponseBytes<GetObjectResponse> objectBytes = \n s3.getObject(objectRequest, ResponseTransformer.toBytes()); \n            byte[] data = objectBytes.asByteArray(); \n            // Write the data to a local file. \n            File myFile = new File(path); \n            OutputStream os = new FileOutputStream(myFile); \n            os.write(data); \n            System.out.println(\"Successfully obtained bytes from an S3 object\"); \n            os.close(); \n        } catch (IOException ex) { \n            ex.printStackTrace(); \n        } catch (S3Exception e) { \n            System.err.println(e.awsErrorDetails().errorMessage()); \n            System.exit(1); \n        } \n    }\n}\n\u2022For API details, see GetObject in AWS SDK for Java 2.x API Reference.\nJavaScript\nSDK for JavaScript (v3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nDownload the object.\nimport { \n  GetObjectCommand, \n  NoSuchKey, \n  S3Client, \n  S3ServiceException,\n} from \"@aws-sdk/client-s3\";\nBasics API Version 2006-03-01 2026Amazon Simple Storage Service API Reference\n/** \n * Get a single object from a specified S3 bucket. \n * @param {{ bucketName: string, key: string }} \n */\nexport const main = async ({ bucketName, key }) => { \n  const client = new S3Client({}); \n  try { \n    const response = await client.send( \n      new GetObjectCommand({ \n        Bucket: bucketName, \n        Key: key, \n      }), \n    ); \n    // The Body object also has 'transformToByteArray' and 'transformToWebStream' \n methods. \n    const str = await response.Body.transformToString(); \n    console.log(str); \n  } catch (caught) { \n    if (caught instanceof NoSuchKey) { \n      console.error( \n        `Error from S3 while getting object \"${key}\" from \"${bucketName}\". No \n such key exists.`, \n      ); \n    } else if (caught instanceof S3ServiceException) { \n      console.error( \n        `Error from S3 while getting object from ${bucketName}.", "${caught.name}: \n ${caught.message}`, \n      ); \n    } else { \n      throw caught; \n    } \n  }\n};\n\u2022For more information, see AWS SDK for JavaScript Developer Guide.\n\u2022For API details, see GetObject in AWS SDK for JavaScript API Reference.\nBasics API Version 2006-03-01 2027Amazon Simple Storage Service API Reference\nKotlin\nSDK for Kotlin\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nsuspend fun getObjectBytes( \n    bucketName: String, \n    keyName: String, \n    path: String,\n) { \n    val request = \n        GetObjectRequest { \n            key = keyName \n            bucket = bucketName \n        } \n    S3Client { region = \"us-east-1\" }.use { s3 -> \n        s3.getObject(request) { resp -> \n            val myFile = File(path) \n            resp.body?.writeToFile(myFile) \n            println(\"Successfully read $keyName from $bucketName\") \n        } \n    }\n}\n\u2022For API details, see GetObject in AWS SDK for Kotlin API reference.\nBasics API Version 2006-03-01 2028Amazon Simple Storage Service API Reference\nPHP\nSDK for PHP\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nGet an object.\n        $s3client = new Aws\\S3\\S3Client(['region' => 'us-west-2']); \n        try { \n            $file = $this->s3client->getObject([ \n                'Bucket' => $this->bucketName, \n                'Key' => $fileName, \n            ]); \n            $body = $file->get('Body'); \n            $body->rewind(); \n            echo \"Downloaded the file and it begins with: {$body->read(26)}.\\n\"; \n        } catch (Exception $exception) { \n            echo \"Failed to download $fileName from $this->bucketName with error: \n \" .", "$exception->getMessage(); \n            exit(\"Please fix error with file downloading before continuing.\"); \n        }\n\u2022For API details, see GetObject in AWS SDK for PHP API Reference.\nPowerShell\nTools for PowerShell\nExample 1: This command retrieves item \"sample.txt\" from bucket \"test-\ufb01les\" and saves \nit to a \ufb01le named \"local-sample.txt\" in the current location.", "The \ufb01le \"local-sample.txt\" \ndoes not have to exist before this command is called.\nRead-S3Object -BucketName amzn-s3-demo-bucket -Key sample.txt -File local-\nsample.txt\nBasics API Version 2006-03-01 2029Amazon Simple Storage Service API Reference\nExample 2: This command retrieves virtual directory \"DIR\" from bucket \"test-\ufb01les\" and \nsaves it to a folder named \"Local-DIR\" in the current location. The folder \"Local-DIR\" \ndoes not have to exist before this command is called.\nRead-S3Object -BucketName amzn-s3-demo-bucket -KeyPrefix DIR -Folder Local-DIR\nExample 3: Downloads all objects with keys ending in '.json' from buckets with 'con\ufb01g' \nin the bucket name to \ufb01les in the speci\ufb01ed folder. The object keys are used to set the \n\ufb01lenames.\nGet-S3Bucket | ? { $_.BucketName -like '*config*' } | Get-S3Object | ? { $_.Key -\nlike '*.json' } | Read-S3Object -Folder C:\\ConfigObjects\n\u2022For API details, see GetObject in AWS Tools for PowerShell Cmdlet Reference.\nPython\nSDK for Python (Boto3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nclass ObjectWrapper: \n    \"\"\"Encapsulates S3 object actions.\"\"\" \n    def __init__(self, s3_object): \n        \"\"\" \n        :param s3_object: A Boto3 Object resource. This is a high-level resource \n in Boto3 \n                          that wraps object actions in a class-like structure.", "\n        \"\"\" \n        self.object = s3_object \n        self.key = self.object.key \n    def get(self): \n        \"\"\" \nBasics API Version 2006-03-01 2030Amazon Simple Storage Service API Reference\n        Gets the object.", "\n        :return: The object data in bytes.", "\n        \"\"\" \n        try: \n            body = self.object.get()[\"Body\"].read() \n            logger.info( \n                \"Got object '%s' from bucket '%s'.\", \n                self.object.key, \n                self.object.bucket_name, \n            ) \n        except ClientError: \n            logger.exception( \n                \"Couldn't get object '%s' from bucket '%s'.\", \n                self.object.key, \n                self.object.bucket_name, \n            ) \n            raise \n        else: \n            return body\n\u2022For API details, see GetObject in AWS SDK for Python (Boto3) API Reference.\nRuby\nSDK for Ruby\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nGet an object.\nrequire 'aws-sdk-s3'\n# Wraps Amazon S3 object actions.\nclass ObjectGetWrapper \n  attr_reader :object \nBasics API Version 2006-03-01 2031Amazon Simple Storage Service API Reference\n  # @param object [Aws::S3::Object] An existing Amazon S3 object.", "\n  def initialize(object) \n    @object = object \n  end \n  # Gets the object directly to a file. \n  # \n  # @param target_path [String] The path to the file where the object is \n downloaded.", "\n  # @return [Aws::S3::Types::GetObjectOutput, nil] The retrieved object data if \n successful; otherwise nil.", "\n  def get_object(target_path) \n    @object.get(response_target: target_path) \n  rescue Aws::Errors::ServiceError => e \n    puts \"Couldn't get object #{@object.key}. Here's why: #{e.message}\" \n  end\nend\n# Example usage:\ndef run_demo\n<<<<<<< HEAD \n  bucket_name = \"amzn-s3-demo-bucket\" \n  object_key = \"my-object.txt\" \n  target_path = \"my-object-as-file.txt\"\n======= \n  bucket_name = 'doc-example-bucket' \n  object_key = 'my-object.txt' \n  target_path = 'my-object-as-file.txt'\n>>>>>>> 999c6133e (fixes) \n  wrapper = ObjectGetWrapper.new(Aws::S3::Object.new(bucket_name, object_key)) \n  obj_data = wrapper.get_object(target_path) \n  return unless obj_data \n  puts \"Object #{object_key} (#{obj_data.content_length} bytes} downloaded to \n #{target_path}.\"\nend\nrun_demo if $PROGRAM_NAME == __FILE__\nGet an object and report its server-side encryption state.\nBasics API Version 2006-03-01 2032Amazon Simple Storage Service API Reference\nrequire 'aws-sdk-s3'\n# Wraps Amazon S3 object actions.\nclass ObjectGetEncryptionWrapper \n  attr_reader :object \n  # @param object [Aws::S3::Object] An existing Amazon S3 object.", "\n  def initialize(object) \n    @object = object \n  end \n  # Gets the object into memory.", "\n  # \n  # @return [Aws::S3::Types::GetObjectOutput, nil] The retrieved object data if \n successful; otherwise nil.", "\n  def object \n    @object.get \n  rescue Aws::Errors::ServiceError => e \n    puts \"Couldn't get object #{@object.key}.", "Here's why: #{e.message}\" \n  end\nend\n# Example usage:\ndef run_demo\n<<<<<<< HEAD \n  bucket_name = \"amzn-s3-demo-bucket\" \n  object_key = \"my-object.txt\"\n======= \n  bucket_name = 'doc-example-bucket' \n  object_key = 'my-object.txt'\n>>>>>>> 999c6133e (fixes) \n  wrapper = ObjectGetEncryptionWrapper.new(Aws::S3::Object.new(bucket_name, \n object_key)) \n  obj_data = wrapper.get_object \n  return unless obj_data \n  encryption = obj_data.server_side_encryption.nil?", "?", "'no' : \n obj_data.server_side_encryption \n  puts \"Object #{object_key} uses #{encryption} encryption.\"\nend\nrun_demo if $PROGRAM_NAME == __FILE__\nBasics API Version 2006-03-01 2033Amazon Simple Storage Service API Reference\n\u2022For API details, see GetObject in AWS SDK for Ruby API Reference.\nRust\nSDK for Rust\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nasync fn get_object(client: Client, opt: Opt) -> Result<usize, S3ExampleError> { \n    trace!(\"bucket:      {}\", opt.bucket); \n    trace!(\"object:      {}\", opt.object); \n    trace!(\"destination: {}\", opt.destination.display()); \n    let mut file = File::create(opt.destination.clone()).map_err(|err| { \n        S3ExampleError::new(format!( \n            \"Failed to initialize file for saving S3 download: {err:?}\" \n        )) \n    })?; \n    let mut object = client \n        .get_object() \n        .bucket(opt.bucket) \n        .key(opt.object) \n        .send() \n        .await?; \n    let mut byte_count = 0_usize; \n    while let Some(bytes) = object.body.try_next().await.map_err(|err| { \n        S3ExampleError::new(format!(\"Failed to read from S3 download stream: \n {err:?}\")) \n    })? { \n        let bytes_len = bytes.len(); \n        file.write_all(&bytes).map_err(|err| { \n            S3ExampleError::new(format!( \n                \"Failed to write from S3 download stream to local file: {err:?}\" \n            )) \nBasics API Version 2006-03-01 2034Amazon Simple Storage Service API Reference\n        })?; \n        trace!(\"Intermediate write of {bytes_len}\"); \n        byte_count += bytes_len; \n    } \n    Ok(byte_count)\n}\n\u2022For API details, see GetObject in AWS SDK for Rust API reference.\nSAP ABAP\nSDK for SAP ABAP\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n    TRY.", "\n        oo_result = lo_s3->getobject(           \" oo_result is returned for \n testing purposes.", "\" \n                  iv_bucket = iv_bucket_name \n                  iv_key = iv_object_key \n               ).", "\n        DATA(lv_object_data) = oo_result->get_body( ).", "\n        MESSAGE 'Object retrieved from S3 bucket.' TYPE 'I'.", "\n      CATCH /aws1/cx_s3_nosuchbucket.", "\n        MESSAGE 'Bucket does not exist.' TYPE 'E'.", "\n      CATCH /aws1/cx_s3_nosuchkey.", "\n        MESSAGE 'Object key does not exist.' TYPE 'E'.", "\n    ENDTRY.\n\u2022For API details, see GetObject in AWS SDK for SAP ABAP API reference.\nBasics API Version 2006-03-01 2035Amazon Simple Storage Service API Reference\nSwift\nSDK for Swift\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nimport AWSS3 \n    public func downloadFile(bucket: String, key: String, to: String) async \n throws { \n        let fileUrl = URL(fileURLWithPath: to).appendingPathComponent(key) \n        let input = GetObjectInput( \n            bucket: bucket, \n            key: key \n        ) \n        do { \n            let output = try await client.getObject(input: input) \n            guard let body = output.body else { \n                throw HandlerError.getObjectBody(\"GetObjectInput missing body.\") \n            } \n            guard let data = try await body.readData() else { \n                throw HandlerError.readGetObjectBody(\"GetObjectInput unable to \n read data.\") \n            } \n            try data.write(to: fileUrl) \n        } \n        catch { \n            print(\"ERROR: \", dump(error, name: \"Downloading a file.\")) \n            throw error \n        } \n    }\nimport AWSS3 \nBasics API Version 2006-03-01 2036Amazon Simple Storage Service API Reference\n    public func readFile(bucket: String, key: String) async throws -> Data { \n        let input = GetObjectInput( \n            bucket: bucket, \n            key: key \n        ) \n        do { \n            let output = try await client.getObject(input: input) \n             \n            guard let body = output.body else { \n                throw HandlerError.getObjectBody(\"GetObjectInput missing body.\") \n            } \n            guard let data = try await body.readData() else { \n                throw HandlerError.readGetObjectBody(\"GetObjectInput unable to \n read data.\") \n            } \n            return data \n        } \n        catch { \n            print(\"ERROR: \", dump(error, name: \"Reading a file.\")) \n            throw error \n        } \n   }\n\u2022For API details, see GetObject in AWS SDK for Swift API reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nUse GetObjectAcl  with an AWS SDK or CLI\nThe following code examples show how to use GetObjectAcl .\nAction examples are code excerpts from larger programs and must be run in context.", "You can see \nthis action in context in the following code example:\n\u2022Manage access control lists (ACLs)\nBasics API Version 2006-03-01 2037Amazon Simple Storage Service API Reference\nC++\nSDK for C++\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nbool AwsDoc::S3::getObjectAcl(const Aws::String &bucketName, \n                              const Aws::String &objectKey, \n                              const Aws::S3::S3ClientConfiguration &clientConfig) \n { \n    Aws::S3::S3Client s3Client(clientConfig); \n    Aws::S3::Model::GetObjectAclRequest request; \n    request.SetBucket(bucketName); \n    request.SetKey(objectKey); \n    Aws::S3::Model::GetObjectAclOutcome outcome = \n            s3Client.GetObjectAcl(request); \n    if (!outcome.IsSuccess()) { \n        const Aws::S3::S3Error &err = outcome.GetError(); \n        std::cerr << \"Error: getObjectAcl: \" \n                  << err.GetExceptionName() << \": \" << err.GetMessage() << \n std::endl; \n    } else { \n        Aws::Vector<Aws::S3::Model::Grant> grants = \n                outcome.GetResult().GetGrants(); \n        for (auto it = grants.begin(); it != grants.end(); it++) { \n            std::cout << \"For object \" << objectKey << \": \" \n                      << std::endl << std::endl; \n            Aws::S3::Model::Grant grant = *it; \n            Aws::S3::Model::Grantee grantee = grant.GetGrantee(); \n            if (grantee.TypeHasBeenSet()) { \n                std::cout << \"Type:          \" \nBasics API Version 2006-03-01 2038Amazon Simple Storage Service API Reference\n                          << getGranteeTypeString(grantee.GetType()) << \n std::endl; \n            } \n            if (grantee.DisplayNameHasBeenSet()) { \n                std::cout << \"Display name:  \" \n                          << grantee.GetDisplayName() << std::endl; \n            } \n            if (grantee.EmailAddressHasBeenSet()) { \n                std::cout << \"Email address: \" \n                          << grantee.GetEmailAddress() << std::endl; \n            } \n            if (grantee.IDHasBeenSet()) { \n                std::cout << \"ID:            \" \n                          << grantee.GetID() << std::endl; \n            } \n            if (grantee.URIHasBeenSet()) { \n                std::cout << \"URI:           \" \n                          << grantee.GetURI() << std::endl; \n            } \n            std::cout << \"Permission:    \" << \n                      getPermissionString(grant.GetPermission()) << \n                      std::endl << std::endl; \n        } \n    } \n    return outcome.IsSuccess();\n}\n//!", "Routine which converts a built-in type enumeration to a human-readable \n string.\n/*! \n \\param type: Type enumeration.", "\n \\return String: Human-readable string\n*/\nAws::String getGranteeTypeString(const Aws::S3::Model::Type &type) { \n    switch (type) { \n        case Aws::S3::Model::Type::AmazonCustomerByEmail: \n            return \"Email address of an AWS account\"; \n        case Aws::S3::Model::Type::CanonicalUser: \nBasics API Version 2006-03-01 2039Amazon Simple Storage Service API Reference\n            return \"Canonical user ID of an AWS account\"; \n        case Aws::S3::Model::Type::Group: \n            return \"Predefined Amazon S3 group\"; \n        case Aws::S3::Model::Type::NOT_SET: \n            return \"Not set\"; \n        default: \n            return \"Type unknown\"; \n    }\n}\n//!", "Routine which converts a built-in type enumeration to a human-readable \n string.\n/*!", "\n \\param permission: Permission enumeration.", "\n \\return String: Human-readable string\n*/\nAws::String getPermissionString(const Aws::S3::Model::Permission &permission) { \n    switch (permission) { \n        case Aws::S3::Model::Permission::FULL_CONTROL: \n            return \"Can read this object's data and its metadata, \" \n                   \"and read/write this object's permissions\"; \n        case Aws::S3::Model::Permission::NOT_SET: \n            return \"Permission not set\"; \n        case Aws::S3::Model::Permission::READ: \n            return \"Can read this object's data and its metadata\"; \n        case Aws::S3::Model::Permission::READ_ACP: \n            return \"Can read this object's permissions\"; \n            // case Aws::S3::Model::Permission::WRITE // Not applicable. \n        case Aws::S3::Model::Permission::WRITE_ACP: \n            return \"Can write this object's permissions\"; \n        default: \n            return \"Permission unknown\"; \n    }\n}\n\u2022For API details, see GetObjectAcl in AWS SDK for C++ API Reference.\nBasics API Version 2006-03-01 2040Amazon Simple Storage Service API Reference\nCLI\nAWS CLI\nThe following command retrieves the access control list for an object in a bucket named my-\nbucket :\naws s3api get-object-acl --bucket my-bucket  --key index.html\nOutput:\n{ \n    \"Owner\": { \n        \"DisplayName\": \"my-username\", \n        \"ID\": \"7009a8971cd538e11f6b6606438875e7c86c5b672f46db45460ddcd087d36c32\" \n    }, \n    \"Grants\": [ \n        { \n            \"Grantee\": { \n                \"DisplayName\": \"my-username\", \n                \"ID\": \n \"7009a8971cd538e11f6b6606438875e7c86c5b672f46db45460ddcd087d36c32\" \n            }, \n            \"Permission\": \"FULL_CONTROL\" \n        }, \n        { \n            \"Grantee\": { \n                \"URI\": \"http://acs.amazonaws.com/groups/global/AllUsers\" \n            }, \n            \"Permission\": \"READ\" \n        } \n    ]\n}\n\u2022For API details, see GetObjectAcl in AWS CLI Command Reference.\nBasics API Version 2006-03-01 2041Amazon Simple Storage Service API Reference\nKotlin\nSDK for Kotlin\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nsuspend fun getBucketACL( \n    objectKey: String, \n    bucketName: String,\n) { \n    val request = \n        GetObjectAclRequest { \n            bucket = bucketName \n            key = objectKey \n        } \n    S3Client { region = \"us-east-1\" }.use { s3 -> \n        val response = s3.getObjectAcl(request) \n        response.grants?.forEach { grant -> \n            println(\"Grant permission is ${grant.permission}\") \n        } \n    }\n}\n\u2022For API details, see GetObjectAcl in AWS SDK for Kotlin API reference.\nPython\nSDK for Python (Boto3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nBasics API Version 2006-03-01 2042Amazon Simple Storage Service API Reference\nclass ObjectWrapper: \n    \"\"\"Encapsulates S3 object actions.\"\"\" \n    def __init__(self, s3_object): \n        \"\"\" \n        :param s3_object: A Boto3 Object resource.", "This is a high-level resource \n in Boto3 \n                          that wraps object actions in a class-like structure.", "\n        \"\"\" \n        self.object = s3_object \n        self.key = self.object.key \n    def get_acl(self): \n        \"\"\" \n        Gets the ACL of the object.", "\n        :return: The ACL of the object.", "\n        \"\"\" \n        try: \n            acl = self.object.Acl() \n            logger.info( \n                \"Got ACL for object %s owned by %s.\", \n                self.object.key, \n                acl.owner[\"DisplayName\"], \n            ) \n        except ClientError: \n            logger.exception(\"Couldn't get ACL for object %s.\", self.object.key) \n            raise \n        else: \n            return acl\n\u2022For API details, see GetObjectAcl in AWS SDK for Python (Boto3) API Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs.", "This topic also includes information about getting started and details \nabout previous SDK versions.\nBasics API Version 2006-03-01 2043Amazon Simple Storage Service API Reference\nUse GetObjectAttributes  with an AWS SDK or CLI\nThe following code examples show how to use GetObjectAttributes .\nAction examples are code excerpts from larger programs and must be run in context.", "You can see \nthis action in context in the following code example:\n\u2022Work with Amazon S3 object integrity\nC++\nSDK for C++\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n// !", "Routine which retrieves the hash value of an object stored in an S3 bucket.\n/*! \n   \\param bucket: The name of the S3 bucket where the object is stored. \n   \\param key: The unique identifier (key) of the object within the S3 bucket.", "\n   \\param hashMethod: The hashing algorithm used to calculate the hash value of \n the object. \n   \\param[out] hashData: The retrieved hash. \n   \\param[out] partHashes: The part hashes if available.", "\n   \\param client: The S3 client instance used to retrieve the object.", "\n   \\return bool: Function succeeded.\n*/\nbool AwsDoc::S3::retrieveObjectHash(const Aws::String &bucket, const Aws::String \n &key, \n                                    AwsDoc::S3::HASH_METHOD hashMethod, \n                                    Aws::String &hashData, \n                                    std::vector<Aws::String> *partHashes, \n                                    const Aws::S3::S3Client &client) { \n    Aws::S3::Model::GetObjectAttributesRequest request; \n    request.SetBucket(bucket); \n    request.SetKey(key); \n    if (hashMethod == MD5) { \n        Aws::Vector<Aws::S3::Model::ObjectAttributes> attributes; \nBasics API Version 2006-03-01 2044Amazon Simple Storage Service API Reference\n        attributes.push_back(Aws::S3::Model::ObjectAttributes::ETag); \n        request.SetObjectAttributes(attributes); \n        Aws::S3::Model::GetObjectAttributesOutcome outcome = \n client.GetObjectAttributes( \n                request); \n        if (outcome.IsSuccess()) { \n            const Aws::S3::Model::GetObjectAttributesResult &result = \n outcome.GetResult(); \n            hashData = result.GetETag(); \n        } else { \n            std::cerr << \"Error retrieving object etag attributes.\" << \n                      outcome.GetError().GetMessage() << std::endl; \n            return false; \n        } \n    } else { // hashMethod != MD5 \n        Aws::Vector<Aws::S3::Model::ObjectAttributes> attributes; \n        attributes.push_back(Aws::S3::Model::ObjectAttributes::Checksum); \n        request.SetObjectAttributes(attributes); \n        Aws::S3::Model::GetObjectAttributesOutcome outcome = \n client.GetObjectAttributes( \n                request); \n        if (outcome.IsSuccess()) { \n            const Aws::S3::Model::GetObjectAttributesResult &result = \n outcome.GetResult(); \n            switch (hashMethod) { \n                case AwsDoc::S3::DEFAULT: // NOLINT(*-branch-clone) \n                    break;  // Default is not supported.\n#pragma clang diagnostic push\n#pragma ide diagnostic ignored \"UnreachableCode\" \n                case AwsDoc::S3::MD5: \n                    break;  // MD5 is not supported.\n#pragma clang diagnostic pop \n                case AwsDoc::S3::SHA1: \n                    hashData = result.GetChecksum().GetChecksumSHA1(); \n                    break; \n                case AwsDoc::S3::SHA256: \n                    hashData = result.GetChecksum().GetChecksumSHA256(); \n                    break; \n                case AwsDoc::S3::CRC32: \n                    hashData = result.GetChecksum().GetChecksumCRC32(); \n                    break; \n                case AwsDoc::S3::CRC32C: \nBasics API Version 2006-03-01 2045Amazon Simple Storage Service API Reference\n                    hashData = result.GetChecksum().GetChecksumCRC32C(); \n                    break; \n                default: \n                    std::cerr << \"Unknown hash method.\" << std::endl; \n                    return false; \n            } \n        } else { \n            std::cerr << \"Error retrieving object checksum attributes.\" << \n                      outcome.GetError().GetMessage() << std::endl; \n            return false; \n        } \n        if (nullptr != partHashes) { \n            attributes.clear(); \n            attributes.push_back(Aws::S3::Model::ObjectAttributes::ObjectParts); \n            request.SetObjectAttributes(attributes); \n            outcome = client.GetObjectAttributes(request); \n            if (outcome.IsSuccess()) { \n                const Aws::S3::Model::GetObjectAttributesResult &result = \n outcome.GetResult(); \n                const Aws::Vector<Aws::S3::Model::ObjectPart> parts = \n result.GetObjectParts().GetParts(); \n                for (const Aws::S3::Model::ObjectPart &part: parts) { \n                    switch (hashMethod) { \n                        case AwsDoc::S3::DEFAULT: // Default is not supported.", "\n NOLINT(*-branch-clone) \n                            break; \n                        case AwsDoc::S3::MD5: // MD5 is not supported.", "\n                            break; \n                        case AwsDoc::S3::SHA1: \n                            partHashes->push_back(part.GetChecksumSHA1()); \n                            break; \n                        case AwsDoc::S3::SHA256: \n                            partHashes->push_back(part.GetChecksumSHA256()); \n                            break; \n                        case AwsDoc::S3::CRC32: \n                            partHashes->push_back(part.GetChecksumCRC32()); \n                            break; \n                        case AwsDoc::S3::CRC32C: \n                            partHashes->push_back(part.GetChecksumCRC32C()); \n                            break; \n                        default: \n                            std::cerr << \"Unknown hash method.\" << std::endl; \n                            return false; \nBasics API Version 2006-03-01 2046Amazon Simple Storage Service API Reference\n                    } \n                } \n            } else { \n                std::cerr << \"Error retrieving object attributes for object \n parts.\" << \n                          outcome.GetError().GetMessage() << std::endl; \n                return false; \n            } \n        } \n    } \n    return true;\n}\n\u2022For API details, see GetObjectAttributes in AWS SDK for C++ API Reference.\nCLI\nAWS CLI\nTo retrieves metadata from an object without returning the object itself\nThe following get-object-attributes  example retrieves metadata from the object\ndoc1.rtf .\naws s3api get-object-attributes \\ \n    --bucket my-bucket  \\ \n    --key doc1.rtf  \\ \n    --object-attributes \"StorageClass\"  \"ETag\" \"ObjectSize\"\nOutput:\n{ \n    \"LastModified\": \"2022-03-15T19:37:31+00:00\", \n    \"VersionId\": \"IuCPjXTDzHNfldAuitVBIKJpF2p1fg4P\", \n    \"ETag\": \"b662d79adeb7c8d787ea7eafb9ef6207\", \n    \"StorageClass\": \"STANDARD\", \n    \"ObjectSize\": 405\n}\nFor more information, see GetObjectAttributes in the Amazon S3 API Reference.\nBasics API Version 2006-03-01 2047Amazon Simple Storage Service API Reference\n\u2022For API details, see GetObjectAttributes in AWS CLI Command Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nUse GetObjectLegalHold  with an AWS SDK or CLI\nThe following code examples show how to use GetObjectLegalHold .\nAction examples are code excerpts from larger programs and must be run in context.", "You can see \nthis action in context in the following code example:\n\u2022Lock Amazon S3 objects\n.NET\nAWS SDK for .NET\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n    /// <summary> \n    /// Get the legal hold details for an S3 object.", "\n    /// </summary> \n    /// <param name=\"bucketName\">The bucket of the object.</param> \n    /// <param name=\"objectKey\">The object key.</param> \n    /// <returns>The object legal hold details.</returns> \n    public async Task<ObjectLockLegalHold> GetObjectLegalHold(string bucketName, \n        string objectKey) \n    { \n        try \n        { \n            var request = new GetObjectLegalHoldRequest() \n            { \n                BucketName = bucketName, \n                Key = objectKey \nBasics API Version 2006-03-01 2048Amazon Simple Storage Service API Reference\n            }; \n            var response = await _amazonS3.GetObjectLegalHoldAsync(request); \n            Console.WriteLine($\"\\tObject legal hold for {objectKey} in \n {bucketName}: \" + \n                              $\"\\n\\tStatus: {response.LegalHold.Status}\"); \n            return response.LegalHold; \n        } \n        catch (AmazonS3Exception ex) \n        { \n            Console.WriteLine($\"\\tUnable to fetch legal hold: '{ex.Message}'\"); \n            return new ObjectLockLegalHold(); \n        } \n    }\n\u2022For API details, see GetObjectLegalHold in AWS SDK for .NET API Reference.\nCLI\nAWS CLI\nRetrieves the Legal Hold status of an object\nThe following get-object-legal-hold  example retrieves the Legal Hold status for the \nspeci\ufb01ed object.\naws s3api get-object-legal-hold \\ \n    --bucket my-bucket-with-object-lock  \\ \n    --key doc1.rtf\nOutput:\n{ \n    \"LegalHold\": { \n        \"Status\": \"ON\" \n    }\n}\n\u2022For API details, see GetObjectLegalHold in AWS CLI Command Reference.\nBasics API Version 2006-03-01 2049Amazon Simple Storage Service API Reference\nGo\nSDK for Go V2\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n// S3Actions wraps S3 service actions.\ntype S3Actions struct { \n S3Client  *s3.Client \n S3Manager *manager.Uploader\n}\n// GetObjectLegalHold retrieves the legal hold status for an S3 object.\nfunc (actor S3Actions) GetObjectLegalHold(ctx context.Context, bucket string, key \n string, versionId string) (*types.ObjectLockLegalHoldStatus, error) { \n var status *types.ObjectLockLegalHoldStatus \n input := &s3.GetObjectLegalHoldInput{ \n  Bucket:    aws.String(bucket), \n  Key:       aws.String(key), \n  VersionId: aws.String(versionId), \n } \n output, err := actor.S3Client.GetObjectLegalHold(ctx, input) \n if err != nil { \n  var noSuchKeyErr *types.NoSuchKey \n  var apiErr *smithy.GenericAPIError \n  if errors.As(err, &noSuchKeyErr) { \n   log.Printf(\"Object %s does not exist in bucket %s.\\n\", key, bucket) \n   err = noSuchKeyErr \n  } else if errors.As(err, &apiErr) { \n   switch apiErr.ErrorCode() { \n   case \"NoSuchObjectLockConfiguration\": \n    log.Printf(\"Object %s does not have an object lock configuration.\\n\", key) \n    err = nil \n   case \"InvalidRequest\": \nBasics API Version 2006-03-01 2050Amazon Simple Storage Service API Reference\n    log.Printf(\"Bucket %s does not have an object lock configuration.\\n\", bucket) \n    err = nil \n   } \n  } \n } else { \n  status = &output.LegalHold.Status \n } \n return status, err\n}\n\u2022For API details, see GetObjectLegalHold in AWS SDK for Go API Reference.\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n    // Get the legal hold details for an S3 object.", "\n    public ObjectLockLegalHold getObjectLegalHold(String bucketName, String \n objectKey) { \n        try { \n            GetObjectLegalHoldRequest legalHoldRequest = \n GetObjectLegalHoldRequest.builder() \n                .bucket(bucketName) \n                .key(objectKey) \n                .build(); \n            GetObjectLegalHoldResponse response = \n getClient().getObjectLegalHold(legalHoldRequest); \n            System.out.println(\"Object legal hold for \" + objectKey + \" in \" + \n bucketName + \n                \":\\n\\tStatus: \" + response.legalHold().status()); \n            return response.legalHold(); \nBasics API Version 2006-03-01 2051Amazon Simple Storage Service API Reference\n        } catch (S3Exception ex) { \n            System.out.println(\"\\tUnable to fetch legal hold: '\" + \n ex.getMessage() + \"'\"); \n        } \n        return null; \n    }\n\u2022For API details, see GetObjectLegalHold in AWS SDK for Java 2.x API Reference.\nJavaScript\nSDK for JavaScript (v3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nimport { \n  GetObjectLegalHoldCommand, \n  S3Client, \n  S3ServiceException,\n} from \"@aws-sdk/client-s3\";\n/** \n * Get an object's current legal hold status. \n * @param {{ bucketName: string, key: string }} \n */\nexport const main = async ({ bucketName, key }) => { \n  const client = new S3Client({}); \n  try { \n    const response = await client.send( \n      new GetObjectLegalHoldCommand({ \n        Bucket: bucketName, \n        Key: key, \n        // Optionally, you can provide additional parameters \nBasics API Version 2006-03-01 2052Amazon Simple Storage Service API Reference\n        // ExpectedBucketOwner: \"<account ID that is expected to own the \n bucket>\", \n        // VersionId: \"<the specific version id of the object to check>\", \n      }), \n    ); \n    console.log(`Legal Hold Status: ${response.LegalHold.Status}`); \n  } catch (caught) { \n    if ( \n      caught instanceof S3ServiceException && \n      caught.name === \"NoSuchBucket\" \n    ) { \n      console.error( \n        `Error from S3 while getting legal hold status for ${key} in \n ${bucketName}. The bucket doesn't exist.`, \n      ); \n    } else if (caught instanceof S3ServiceException) { \n      console.error( \n        `Error from S3 while getting legal hold status for ${key} in \n ${bucketName} from ${bucketName}.", "${caught.name}: ${caught.message}`, \n      ); \n    } else { \n      throw caught; \n    } \n  }\n};\n// Call function if run directly\nimport { parseArgs } from \"node:util\";\nimport { \n  isMain, \n  validateArgs,\n} from \"@aws-doc-sdk-examples/lib/utils/util-node.js\";\nconst loadArgs = () => { \n  const options = { \n    bucketName: { \n      type: \"string\", \n      required: true, \n    }, \n    key: { \n      type: \"string\", \n      required: true, \n    }, \n  }; \nBasics API Version 2006-03-01 2053Amazon Simple Storage Service API Reference\n  const results = parseArgs({ options }); \n  const { errors } = validateArgs({ options }, results); \n  return { errors, results };\n};\nif (isMain(import.meta.url)) { \n  const { errors, results } = loadArgs(); \n  if (!errors) { \n    main(results.values); \n  } else { \n    console.error(errors.join(\"\\n\")); \n  }\n}\n\u2022For API details, see GetObjectLegalHold in AWS SDK for JavaScript API Reference.\nPython\nSDK for Python (Boto3)\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nPut an object legal hold.\ndef get_legal_hold(s3_client, bucket: str, key: str) -> None: \n    \"\"\" \n    Get the legal hold status of a specific file in a bucket. \n    Args: \n        s3_client: Boto3 S3 client.", "\n        bucket: The name of the bucket containing the file.", "\n        key: The key of the file to get the legal hold status of. \n    \"\"\" \n    print() \n    logger.info(\"Getting legal hold status of file [%s] in bucket [%s]\", key, \n bucket) \n    try: \nBasics API Version 2006-03-01 2054Amazon Simple Storage Service API Reference\n        response = s3_client.get_object_legal_hold(Bucket=bucket, Key=key) \n        legal_hold_status = response[\"LegalHold\"][\"Status\"] \n        logger.debug( \n            \"Legal hold status of file [%s] in bucket [%s] is [%s]\", \n            key, \n            bucket, \n            legal_hold_status, \n        ) \n    except Exception as e: \n        logger.error( \n            \"Failed to get legal hold status of file [%s] in bucket [%s]: %s\", \n            key, \n            bucket, \n            e, \n        )\n\u2022For API details, see GetObjectLegalHold in AWS SDK for Python (Boto3) API Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs.", "This topic also includes information about getting started and details \nabout previous SDK versions.\nUse GetObjectLockConfiguration  with an AWS SDK or CLI\nThe following code examples show how to use GetObjectLockConfiguration .\nAction examples are code excerpts from larger programs and must be run in context.", "You can see \nthis action in context in the following code example:\n\u2022Lock Amazon S3 objects\nBasics API Version 2006-03-01 2055Amazon Simple Storage Service API Reference\n.NET\nAWS SDK for .NET\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n    /// <summary> \n    /// Get the object lock configuration details for an S3 bucket. \n    /// </summary> \n    /// <param name=\"bucketName\">The bucket to get details.</param> \n    /// <returns>The bucket's object lock configuration details.</returns> \n    public async Task<ObjectLockConfiguration> \n GetBucketObjectLockConfiguration(string bucketName) \n    { \n        try \n        { \n            var request = new GetObjectLockConfigurationRequest() \n            { \n                BucketName = bucketName \n            }; \n            var response = await \n _amazonS3.GetObjectLockConfigurationAsync(request); \n            Console.WriteLine($\"\\tBucket object lock config for {bucketName} in \n {bucketName}: \" + \n                              $\"\\n\\tEnabled: \n {response.ObjectLockConfiguration.ObjectLockEnabled}\" + \n                              $\"\\n\\tRule: \n {response.ObjectLockConfiguration.Rule?.DefaultRetention}\"); \n            return response.ObjectLockConfiguration; \n        } \n        catch (AmazonS3Exception ex) \n        { \n            Console.WriteLine($\"\\tUnable to fetch object lock config: \n '{ex.Message}'\"); \n            return new ObjectLockConfiguration(); \n        } \nBasics API Version 2006-03-01 2056Amazon Simple Storage Service API Reference\n    }\n\u2022For API details, see GetObjectLockCon\ufb01guration in AWS SDK for .NET API Reference.\nCLI\nAWS CLI\nTo retrieve an object lock con\ufb01guration for a bucket\nThe following get-object-lock-configuration  example retrieves the object lock \ncon\ufb01guration for the speci\ufb01ed bucket.\naws s3api get-object-lock-configuration \\ \n    --bucket my-bucket-with-object-lock\nOutput:\n{ \n    \"ObjectLockConfiguration\": { \n        \"ObjectLockEnabled\": \"Enabled\", \n        \"Rule\": { \n            \"DefaultRetention\": { \n                \"Mode\": \"COMPLIANCE\", \n                \"Days\": 50 \n            } \n        } \n    }\n}\n\u2022For API details, see GetObjectLockCon\ufb01guration in AWS CLI Command Reference.\nBasics API Version 2006-03-01 2057Amazon Simple Storage Service API Reference\nGo\nSDK for Go V2\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n// S3Actions wraps S3 service actions.\ntype S3Actions struct { \n S3Client  *s3.Client \n S3Manager *manager.Uploader\n}\n// GetObjectLockConfiguration retrieves the object lock configuration for an S3 \n bucket.\nfunc (actor S3Actions) GetObjectLockConfiguration(ctx context.Context, bucket \n string) (*types.ObjectLockConfiguration, error) { \n var lockConfig *types.ObjectLockConfiguration \n input := &s3.GetObjectLockConfigurationInput{ \n  Bucket: aws.String(bucket), \n } \n output, err := actor.S3Client.GetObjectLockConfiguration(ctx, input) \n if err != nil { \n  var noBucket *types.NoSuchBucket \n  var apiErr *smithy.GenericAPIError \n  if errors.As(err, &noBucket) { \n   log.Printf(\"Bucket %s does not exist.\\n\", bucket) \n   err = noBucket \n  } else if errors.As(err, &apiErr) && apiErr.ErrorCode() == \n \"ObjectLockConfigurationNotFoundError\" { \n   log.Printf(\"Bucket %s does not have an object lock configuration.\\n\", bucket) \n   err = nil \n  } \n } else { \n  lockConfig = output.ObjectLockConfiguration \nBasics API Version 2006-03-01 2058Amazon Simple Storage Service API Reference\n } \n return lockConfig, err\n}\n\u2022For API details, see GetObjectLockCon\ufb01guration in AWS SDK for Go API Reference.\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n    // Get the object lock configuration details for an S3 bucket.", "\n    public void getBucketObjectLockConfiguration(String bucketName) { \n        GetObjectLockConfigurationRequest objectLockConfigurationRequest = \n GetObjectLockConfigurationRequest.builder() \n            .bucket(bucketName) \n            .build(); \n        GetObjectLockConfigurationResponse response = \n getClient().getObjectLockConfiguration(objectLockConfigurationRequest); \n        System.out.println(\"Bucket object lock config for \"+bucketName +\":  \"); \n        System.out.println(\"\\tEnabled: \n \"+response.objectLockConfiguration().objectLockEnabled()); \n        System.out.println(\"\\tRule: \"+ \n response.objectLockConfiguration().rule().defaultRetention()); \n    }\n\u2022For API details, see GetObjectLockCon\ufb01guration in AWS SDK for Java 2.x API Reference.\nBasics API Version 2006-03-01 2059Amazon Simple Storage Service API Reference\nJavaScript\nSDK for JavaScript (v3)\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nimport { \n  GetObjectLockConfigurationCommand, \n  S3Client, \n  S3ServiceException,\n} from \"@aws-sdk/client-s3\";\n/** \n * Gets the Object Lock configuration for a bucket. \n * @param {{ bucketName: string }} \n */\nexport const main = async ({ bucketName }) => { \n  const client = new S3Client({}); \n  try { \n    const { ObjectLockConfiguration } = await client.send( \n      new GetObjectLockConfigurationCommand({ \n        Bucket: bucketName, \n        // Optionally, you can provide additional parameters \n        // ExpectedBucketOwner: \"<account ID that is expected to own the \n bucket>\", \n      }), \n    ); \n    console.log( \n      `Object Lock Configuration:\\n${JSON.stringify(ObjectLockConfiguration)}`, \n    ); \n  } catch (caught) { \n    if ( \n      caught instanceof S3ServiceException && \n      caught.name === \"NoSuchBucket\" \n    ) { \n      console.error( \nBasics API Version 2006-03-01 2060Amazon Simple Storage Service API Reference\n        `Error from S3 while getting object lock configuration for ${bucketName}. \n The bucket doesn't exist.`, \n      ); \n    } else if (caught instanceof S3ServiceException) { \n      console.error( \n        `Error from S3 while getting object lock configuration for ${bucketName}.", "\n  ${caught.name}: ${caught.message}`, \n      ); \n    } else { \n      throw caught; \n    } \n  }\n};\n// Call function if run directly\nimport { parseArgs } from \"node:util\";\nimport { \n  isMain, \n  validateArgs,\n} from \"@aws-doc-sdk-examples/lib/utils/util-node.js\";\nconst loadArgs = () => { \n  const options = { \n    bucketName: { \n      type: \"string\", \n      required: true, \n    }, \n  }; \n  const results = parseArgs({ options }); \n  const { errors } = validateArgs({ options }, results); \n  return { errors, results };\n};\nif (isMain(import.meta.url)) { \n  const { errors, results } = loadArgs(); \n  if (!errors) { \n    main(results.values); \n  } else { \n    console.error(errors.join(\"\\n\")); \n  }\n}\n\u2022For API details, see GetObjectLockCon\ufb01guration in AWS SDK for JavaScript API Reference.\nBasics API Version 2006-03-01 2061Amazon Simple Storage Service API Reference\nPowerShell\nTools for PowerShell\nExample 1: This command returns the value 'Enabled' if Object lock con\ufb01guration is \nenabled for the given S3 bucket.\nGet-S3ObjectLockConfiguration -BucketName 'amzn-s3-demo-bucket' -Select \n ObjectLockConfiguration.ObjectLockEnabled\nOutput:\nValue\n-----\nEnabled\n\u2022For API details, see GetObjectLockCon\ufb01guration in AWS Tools for PowerShell Cmdlet \nReference.\nPython\nSDK for Python (Boto3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nGet the object lock con\ufb01guration.\ndef is_object_lock_enabled(s3_client, bucket: str) -> bool: \n    \"\"\" \n    Check if object lock is enabled for a bucket. \n    Args: \n        s3_client: Boto3 S3 client.", "\n        bucket: The name of the bucket to check.", "\nBasics API Version 2006-03-01 2062Amazon Simple Storage Service API Reference\n    Returns: \n        True if object lock is enabled, False otherwise.", "\n    \"\"\" \n    try: \n        response = s3_client.get_object_lock_configuration(Bucket=bucket) \n        return ( \n            \"ObjectLockConfiguration\" in response \n            and response[\"ObjectLockConfiguration\"][\"ObjectLockEnabled\"] == \n \"Enabled\" \n        ) \n    except s3_client.exceptions.ClientError as e: \n        if e.response[\"Error\"][\"Code\"] == \"ObjectLockConfigurationNotFoundError\": \n            return False \n        else: \n            raise\n\u2022For API details, see GetObjectLockCon\ufb01guration in AWS SDK for Python (Boto3) API \nReference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs.", "This topic also includes information about getting started and details \nabout previous SDK versions.\nUse GetObjectRetention  with an AWS SDK or CLI\nThe following code examples show how to use GetObjectRetention .\nAction examples are code excerpts from larger programs and must be run in context.", "You can see \nthis action in context in the following code example:\n\u2022Lock Amazon S3 objects\nBasics API Version 2006-03-01 2063Amazon Simple Storage Service API Reference\n.NET\nAWS SDK for .NET\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n    /// <summary> \n    /// Get the retention period for an S3 object.", "\n    /// </summary> \n    /// <param name=\"bucketName\">The bucket of the object.</param> \n    /// <param name=\"objectKey\">The object key.</param> \n    /// <returns>The object retention details.</returns> \n    public async Task<ObjectLockRetention> GetObjectRetention(string bucketName, \n        string objectKey) \n    { \n        try \n        { \n            var request = new GetObjectRetentionRequest() \n            { \n                BucketName = bucketName, \n                Key = objectKey \n            }; \n            var response = await _amazonS3.GetObjectRetentionAsync(request); \n            Console.WriteLine($\"\\tObject retention for {objectKey} in \n {bucketName}: \" + \n                              $\"\\n\\t{response.Retention.Mode} until \n {response.Retention.RetainUntilDate:d}.\"); \n            return response.Retention; \n        } \n        catch (AmazonS3Exception ex) \n        { \n            Console.WriteLine($\"\\tUnable to fetch object lock retention: \n '{ex.Message}'\"); \n            return new ObjectLockRetention(); \n        } \n    }\nBasics API Version 2006-03-01 2064Amazon Simple Storage Service API Reference\n\u2022For API details, see GetObjectRetention in AWS SDK for .NET API Reference.\nCLI\nAWS CLI\nTo retrieve the object retention con\ufb01guration for an object\nThe following get-object-retention  example retrieves the object retention \ncon\ufb01guration for the speci\ufb01ed object.\naws s3api get-object-retention \\ \n    --bucket my-bucket-with-object-lock  \\ \n    --key doc1.rtf\nOutput:\n{ \n    \"Retention\": { \n        \"Mode\": \"GOVERNANCE\", \n        \"RetainUntilDate\": \"2025-01-01T00:00:00.000Z\" \n    }\n}\n\u2022For API details, see GetObjectRetention in AWS CLI Command Reference.\nGo\nSDK for Go V2\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n// S3Actions wraps S3 service actions.\ntype S3Actions struct { \nBasics API Version 2006-03-01 2065Amazon Simple Storage Service API Reference\n S3Client  *s3.Client \n S3Manager *manager.Uploader\n}\n// GetObjectRetention retrieves the object retention configuration for an S3 \n object.\nfunc (actor S3Actions) GetObjectRetention(ctx context.Context, bucket string, key \n string) (*types.ObjectLockRetention, error) { \n var retention *types.ObjectLockRetention \n input := &s3.GetObjectRetentionInput{ \n  Bucket: aws.String(bucket), \n  Key:    aws.String(key), \n } \n output, err := actor.S3Client.GetObjectRetention(ctx, input) \n if err != nil { \n  var noKey *types.NoSuchKey \n  var apiErr *smithy.GenericAPIError \n  if errors.As(err, &noKey) { \n   log.Printf(\"Object %s does not exist in bucket %s.\\n\", key, bucket) \n   err = noKey \n  } else if errors.As(err, &apiErr) { \n   switch apiErr.ErrorCode() { \n   case \"NoSuchObjectLockConfiguration\": \n    err = nil \n   case \"InvalidRequest\": \n    log.Printf(\"Bucket %s does not have locking enabled.\", bucket) \n    err = nil \n   } \n  } \n } else { \n  retention = output.Retention \n } \n return retention, err\n}\n\u2022For API details, see GetObjectRetention in AWS SDK for Go API Reference.\nBasics API Version 2006-03-01 2066Amazon Simple Storage Service API Reference\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n    // Get the retention period for an S3 object. \n    public ObjectLockRetention getObjectRetention(String bucketName, String key){ \n        try { \n            GetObjectRetentionRequest retentionRequest = \n GetObjectRetentionRequest.builder() \n                .bucket(bucketName) \n                .key(key) \n                .build(); \n            GetObjectRetentionResponse response = \n getClient().getObjectRetention(retentionRequest); \n            System.out.println(\"tObject retention for \"+key +\" \n in \"+ bucketName +\": \" + response.retention().mode() +\" until \"+ \n response.retention().retainUntilDate() +\".\"); \n            return response.retention(); \n        } catch (S3Exception e) { \n            System.err.println(e.awsErrorDetails().errorMessage()); \n            return null; \n        } \n    }\n\u2022For API details, see GetObjectRetention in AWS SDK for Java 2.x API Reference.\nBasics API Version 2006-03-01 2067Amazon Simple Storage Service API Reference\nJavaScript\nSDK for JavaScript (v3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nimport { \n  GetObjectRetentionCommand, \n  S3Client, \n  S3ServiceException,\n} from \"@aws-sdk/client-s3\";\n/** \n * Log the \"RetainUntilDate\" for an object in an S3 bucket. \n * @param {{ bucketName: string, key: string }} \n */\nexport const main = async ({ bucketName, key }) => { \n  const client = new S3Client({}); \n  try { \n    const { Retention } = await client.send( \n      new GetObjectRetentionCommand({ \n        Bucket: bucketName, \n        Key: key, \n      }), \n    ); \n    console.log( \n      `${key} in ${bucketName} will be retained until \n ${Retention.RetainUntilDate}`, \n    ); \n  } catch (caught) { \n    if ( \n      caught instanceof S3ServiceException && \n      caught.name === \"NoSuchObjectLockConfiguration\" \n    ) { \n      console.warn( \nBasics API Version 2006-03-01 2068Amazon Simple Storage Service API Reference\n        `The object \"${key}\" in the bucket \"${bucketName}\" does not have an \n ObjectLock configuration.`, \n      ); \n    } else if (caught instanceof S3ServiceException) { \n      console.error( \n        `Error from S3 while getting object retention settings for \n \"${bucketName}\". ${caught.name}: ${caught.message}`, \n      ); \n    } else { \n      throw caught; \n    } \n  }\n};\n// Call function if run directly\nimport { parseArgs } from \"node:util\";\nimport { \n  isMain, \n  validateArgs,\n} from \"@aws-doc-sdk-examples/lib/utils/util-node.js\";\nconst loadArgs = () => { \n  const options = { \n    bucketName: { \n      type: \"string\", \n      required: true, \n    }, \n    key: { \n      type: \"string\", \n      required: true, \n    }, \n  }; \n  const results = parseArgs({ options }); \n  const { errors } = validateArgs({ options }, results); \n  return { errors, results };\n};\nif (isMain(import.meta.url)) { \n  const { errors, results } = loadArgs(); \n  if (!errors) { \n    main(results.values); \n  } else { \n    console.error(errors.join(\"\\n\")); \n  }\nBasics API Version 2006-03-01 2069Amazon Simple Storage Service API Reference\n}\n\u2022For API details, see GetObjectRetention in AWS SDK for JavaScript API Reference.\nPowerShell\nTools for PowerShell\nExample 1: The command returns the mode and date till the object would be retained.\nGet-S3ObjectRetention -BucketName 'amzn-s3-demo-bucket' -Key 'testfile.txt'\n\u2022For API details, see GetObjectRetention in AWS Tools for PowerShell Cmdlet Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs.", "This topic also includes information about getting started and details \nabout previous SDK versions.\nUse GetObjectTagging  with a CLI\nThe following code examples show how to use GetObjectTagging .\nAction examples are code excerpts from larger programs and must be run in context.", "You can see \nthis action in context in the following code example:\n\u2022Get started with tags\nCLI\nAWS CLI\nTo retrieve the tags attached to an object\nThe following get-object-tagging  example retrieves the values for the speci\ufb01ed key \nfrom the speci\ufb01ed object.\naws s3api get-object-tagging \\ \n    --bucket my-bucket  \\ \n    --key doc1.rtf\nBasics API Version 2006-03-01 2070Amazon Simple Storage Service API Reference\nOutput:\n{ \n    \"TagSet\": [ \n        { \n            \"Value\": \"confidential\", \n            \"Key\": \"designation\" \n        } \n    ]\n}\nThe following get-object-tagging  example tries to retrieve the tag sets of the object\ndoc2.rtf , which has no tags.\naws s3api get-object-tagging \\ \n    --bucket my-bucket  \\ \n    --key doc2.rtf\nOutput:\n{ \n    \"TagSet\": []\n}\nThe following get-object-tagging  example retrieves the tag sets of the object\ndoc3.rtf , which has multiple tags.\naws s3api get-object-tagging \\ \n    --bucket my-bucket  \\ \n    --key doc3.rtf\nOutput:\n{ \n    \"TagSet\": [ \n        { \n            \"Value\": \"confidential\", \n            \"Key\": \"designation\" \n        }, \n        { \n            \"Value\": \"finance\", \nBasics API Version 2006-03-01 2071Amazon Simple Storage Service API Reference\n            \"Key\": \"department\" \n        }, \n        { \n            \"Value\": \"payroll\", \n            \"Key\": \"team\" \n        } \n    ]\n}\n\u2022For API details, see GetObjectTagging in AWS CLI Command Reference.\nPowerShell\nTools for PowerShell\nExample 1: The sample returns the tags associated with the object present on the given \nS3 bucket.\nGet-S3ObjectTagSet -Key 'testfile.txt' -BucketName 'amzn-s3-demo-bucket'\nOutput:\nKey  Value\n---  -----\ntest value\n\u2022For API details, see GetObjectTagging in AWS Tools for PowerShell Cmdlet Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nUse GetPublicAccessBlock  with a CLI\nThe following code examples show how to use GetPublicAccessBlock .\nCLI\nAWS CLI\nTo set or modify the block public access con\ufb01guration for a bucket\nBasics API Version 2006-03-01 2072Amazon Simple Storage Service API Reference\nThe following get-public-access-block  example displays the block public access \ncon\ufb01guration for the speci\ufb01ed bucket.\naws s3api get-public-access-block \\ \n    --bucket my-bucket\nOutput:\n{ \n    \"PublicAccessBlockConfiguration\": { \n        \"IgnorePublicAcls\": true, \n        \"BlockPublicPolicy\": true, \n        \"BlockPublicAcls\": true, \n        \"RestrictPublicBuckets\": true \n    }\n}\n\u2022For API details, see GetPublicAccessBlock in AWS CLI Command Reference.\nPowerShell\nTools for PowerShell\nExample 1: The command returns the public access block con\ufb01guration of the given S3 \nbucket.\nGet-S3PublicAccessBlock -BucketName 'amzn-s3-demo-bucket'\n\u2022For API details, see GetPublicAccessBlock in AWS Tools for PowerShell Cmdlet Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nUse HeadBucket  with an AWS SDK or CLI\nThe following code examples show how to use HeadBucket .\nBasics API Version 2006-03-01 2073Amazon Simple Storage Service API Reference\nBash\nAWS CLI with Bash script\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n###############################################################################\n# function bucket_exists\n#\n# This function checks to see if the specified bucket already exists.\n#\n# Parameters:\n#       $1 - The name of the bucket to check.\n#\n# Returns:\n#       0 - If the bucket already exists.\n#       1 - If the bucket doesn't exist.\n###############################################################################\nfunction bucket_exists() { \n  local bucket_name \n  bucket_name=$1 \n  # Check whether the bucket already exists.", "\n  # We suppress all output - we're interested only in the return code.", "\n  if aws s3api head-bucket \\ \n    --bucket \"$bucket_name\" \\ \n    >/dev/null 2>&1; then \n    return 0 # 0 in Bash script means true.", "\n  else \n    return 1 # 1 in Bash script means false.", "\n  fi\n}\n\u2022For API details, see HeadBucket in AWS CLI Command Reference.\nBasics API Version 2006-03-01 2074Amazon Simple Storage Service API Reference\nCLI\nAWS CLI\nThe following command veri\ufb01es access to a bucket named my-bucket :\naws s3api head-bucket --bucket my-bucket\nIf the bucket exists and you have access to it, no output is returned.", "Otherwise, an error \nmessage will be shown.", "For example:\nA client error (404) occurred when calling the HeadBucket operation: Not Found\n\u2022For API details, see HeadBucket in AWS CLI Command Reference.\nGo\nSDK for Go V2\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n// BucketBasics encapsulates the Amazon Simple Storage Service (Amazon S3) \n actions\n// used in the examples.\n// It contains S3Client, an Amazon S3 service client that is used to perform \n bucket\n// and object actions.\ntype BucketBasics struct { \n S3Client *s3.Client\n}\n// BucketExists checks whether a bucket exists in the current account.\nfunc (basics BucketBasics) BucketExists(ctx context.Context, bucketName string) \n (bool, error) { \nBasics API Version 2006-03-01 2075Amazon Simple Storage Service API Reference\n _, err := basics.S3Client.HeadBucket(ctx, &s3.HeadBucketInput{ \n  Bucket: aws.String(bucketName), \n }) \n exists := true \n if err != nil { \n  var apiError smithy.APIError \n  if errors.As(err, &apiError) { \n   switch apiError.(type) { \n   case *types.NotFound: \n    log.Printf(\"Bucket %v is available.\\n\", bucketName) \n    exists = false \n    err = nil \n   default: \n    log.Printf(\"Either you don't have access to bucket %v or another error \n occurred. \"+ \n     \"Here's what happened: %v\\n\", bucketName, err) \n   } \n  } \n } else { \n  log.Printf(\"Bucket %v exists and you already own it.\", bucketName) \n } \n return exists, err\n}\n\u2022For API details, see HeadBucket in AWS SDK for Go API Reference.\nPython\nSDK for Python (Boto3)\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nclass BucketWrapper: \n    \"\"\"Encapsulates S3 bucket actions.\"\"\" \nBasics API Version 2006-03-01 2076Amazon Simple Storage Service API Reference\n    def __init__(self, bucket): \n        \"\"\" \n        :param bucket: A Boto3 Bucket resource. This is a high-level resource in \n Boto3 \n                       that wraps bucket actions in a class-like structure. \n        \"\"\" \n        self.bucket = bucket \n        self.name = bucket.name \n    def exists(self): \n        \"\"\" \n        Determine whether the bucket exists and you have access to it. \n        :return: True when the bucket exists; otherwise, False. \n        \"\"\" \n        try: \n            self.bucket.meta.client.head_bucket(Bucket=self.bucket.name) \n            logger.info(\"Bucket %s exists.\", self.bucket.name) \n            exists = True \n        except ClientError: \n            logger.warning( \n                \"Bucket %s doesn't exist or you don't have access to it.\", \n                self.bucket.name, \n            ) \n            exists = False \n        return exists\n\u2022For API details, see HeadBucket in AWS SDK for Python (Boto3) API Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nUse HeadObject  with an AWS SDK or CLI\nThe following code examples show how to use HeadObject .\nBasics API Version 2006-03-01 2077Amazon Simple Storage Service API Reference\nCLI\nAWS CLI\nThe following command retrieves metadata for an object in a bucket named my-bucket :\naws s3api head-object --bucket my-bucket  --key index.html\nOutput:\n{ \n    \"AcceptRanges\": \"bytes\", \n    \"ContentType\": \"text/html\", \n    \"LastModified\": \"Thu, 16 Apr 2015 18:19:14 GMT\", \n    \"ContentLength\": 77, \n    \"VersionId\": \"null\", \n    \"ETag\": \"\\\"30a6ec7e1a9ad79c203d05a589c8b400\\\"\", \n    \"Metadata\": {}\n}\n\u2022For API details, see HeadObject in AWS CLI Command Reference.\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nDetermine the content type of an object.\nimport software.amazon.awssdk.regions.Region;\nimport software.amazon.awssdk.services.s3.S3Client;\nimport software.amazon.awssdk.services.s3.model.HeadObjectRequest;\nimport software.amazon.awssdk.services.s3.model.HeadObjectResponse;\nimport software.amazon.awssdk.services.s3.model.S3Exception;\nBasics API Version 2006-03-01 2078Amazon Simple Storage Service API Reference\n/** \n * Before running this Java V2 code example, set up your development \n * environment, including your credentials. \n * <p> \n * For more information, see the following documentation topic: \n * <p> \n * https://docs.aws.amazon.com/sdk-for-java/latest/developer-guide/get-\nstarted.html \n */\npublic class GetObjectContentType { \n    public static void main(String[] args) { \n        final String usage = \"\"\" \n            Usage: \n                <bucketName> <keyName> \n            Where: \n                bucketName - The Amazon S3 bucket name.\\s \n                keyName - The key name.\\s \n            \"\"\"; \n        if (args.length != 2) { \n            System.out.println(usage); \n            System.exit(1); \n        } \n        String bucketName = args[0]; \n        String keyName = args[1]; \n        Region region = Region.US_EAST_1; \n        S3Client s3 = S3Client.builder() \n            .region(region) \n            .build(); \n        getContentType(s3, bucketName, keyName); \n        s3.close(); \n    } \n    /** \n     * Retrieves the content type of an object stored in an Amazon S3 bucket. \n     * \n     * @param s3 an instance of the {@link S3Client} class, which is used to \n interact with the Amazon S3 service \n     * @param bucketName the name of the S3 bucket where the object is stored \n     * @param keyName the key (file name) of the object in the S3 bucket \nBasics API Version 2006-03-01 2079Amazon Simple Storage Service API Reference\n     */ \n    public static void getContentType(S3Client s3, String bucketName, String \n keyName) { \n        try { \n            HeadObjectRequest objectRequest = HeadObjectRequest.builder() \n                .key(keyName) \n                .bucket(bucketName) \n                .build(); \n            HeadObjectResponse objectHead = s3.headObject(objectRequest); \n            String type = objectHead.contentType(); \n            System.out.println(\"The object content type is \" + type); \n        } catch (S3Exception e) { \n            System.err.println(e.awsErrorDetails().errorMessage()); \n            System.exit(1); \n        } \n    }\n}\nGet the restore status of an object.\nimport software.amazon.awssdk.regions.Region;\nimport software.amazon.awssdk.services.s3.S3Client;\nimport software.amazon.awssdk.services.s3.model.HeadObjectRequest;\nimport software.amazon.awssdk.services.s3.model.HeadObjectResponse;\nimport software.amazon.awssdk.services.s3.model.S3Exception;\npublic class GetObjectRestoreStatus { \n    public static void main(String[] args) { \n        final String usage = \"\"\" \n            Usage: \n                <bucketName> <keyName>\\s \n            Where: \n                bucketName - The Amazon S3 bucket name.\\s \n                keyName - A key name that represents the object.\\s \n            \"\"\"; \n        if (args.length != 2) { \nBasics API Version 2006-03-01 2080Amazon Simple Storage Service API Reference\n            System.out.println(usage); \n            System.exit(1); \n        } \n        String bucketName = args[0]; \n        String keyName = args[1]; \n        Region region = Region.US_EAST_1; \n        S3Client s3 = S3Client.builder() \n            .region(region) \n            .build(); \n        checkStatus(s3, bucketName, keyName); \n        s3.close(); \n    } \n    /** \n     * Checks the restoration status of an Amazon S3 object. \n     * \n     * @param s3         an instance of the {@link S3Client} class used to \n interact with the Amazon S3 service \n     * @param bucketName the name of the Amazon S3 bucket where the object is \n stored \n     * @param keyName    the name of the Amazon S3 object to be checked \n     * @throws S3Exception if an error occurs while interacting with the Amazon \n S3 service \n     */ \n    public static void checkStatus(S3Client s3, String bucketName, String \n keyName) { \n        try { \n            HeadObjectRequest headObjectRequest = HeadObjectRequest.builder() \n                .bucket(bucketName) \n                .key(keyName) \n                .build(); \n            HeadObjectResponse response = s3.headObject(headObjectRequest); \n            System.out.println(\"The Amazon S3 object restoration status is \" + \n response.restore()); \n        } catch (S3Exception e) { \n            System.err.println(e.awsErrorDetails().errorMessage()); \n            System.exit(1); \n        } \n    }\n}\nBasics API Version 2006-03-01 2081Amazon Simple Storage Service API Reference\n\u2022For API details, see HeadObject in AWS SDK for Java 2.x API Reference.\nRuby\nSDK for Ruby\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nrequire 'aws-sdk-s3'\n# Wraps Amazon S3 object actions.\nclass ObjectExistsWrapper \n  attr_reader :object \n  # @param object [Aws::S3::Object] An Amazon S3 object.", "\n  def initialize(object) \n    @object = object \n  end \n  # Checks whether the object exists. \n  # \n  # @return [Boolean] True if the object exists; otherwise false. \n  def exists? \n    @object.exists?", "\n  rescue Aws::Errors::ServiceError => e \n    puts \"Couldn't check existence of object \n #{@object.bucket.name}:#{@object.key}. Here's why: #{e.message}\" \n    false \n  end\nend\n# Example usage:\ndef run_demo\n<<<<<<< HEAD \n  bucket_name = \"amzn-s3-demo-bucket\" \n  object_key = \"my-object.txt\"\nBasics API Version 2006-03-01 2082Amazon Simple Storage Service API Reference\n======= \n  bucket_name = 'doc-example-bucket' \n  object_key = 'my-object.txt'\n>>>>>>> 999c6133e (fixes) \n  wrapper = ObjectExistsWrapper.new(Aws::S3::Object.new(bucket_name, object_key)) \n  exists = wrapper.exists?", "\n  puts \"Object #{object_key} #{exists ?", "'does' : 'does not'} exist.\"\nend\nrun_demo if $PROGRAM_NAME == __FILE__\n\u2022For API details, see HeadObject in AWS SDK for Ruby API Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nUse ListBucketAnalyticsConfigurations  with a CLI\nThe following code examples show how to use ListBucketAnalyticsConfigurations .\nCLI\nAWS CLI\nTo retrieve a list of analytics con\ufb01gurations for a bucket\nThe following list-bucket-analytics-configurations  retrieves a list of analytics \ncon\ufb01gurations for the speci\ufb01ed bucket.\naws s3api list-bucket-analytics-configurations \\ \n    --bucket my-bucket\nOutput:\n{ \n    \"AnalyticsConfigurationList\": [ \n        { \nBasics API Version 2006-03-01 2083Amazon Simple Storage Service API Reference\n            \"StorageClassAnalysis\": {}, \n            \"Id\": \"1\" \n        } \n    ], \n    \"IsTruncated\": false\n}\n\u2022For API details, see ListBucketAnalyticsCon\ufb01gurations in AWS CLI Command Reference.\nPowerShell\nTools for PowerShell\nExample 1: This command returns the \ufb01rst 100 analytics con\ufb01gurations of the given S3 \nbucket.\nGet-S3BucketAnalyticsConfigurationList -BucketName 'amzn-s3-demo-bucket'\n\u2022For API details, see ListBucketAnalyticsCon\ufb01gurations in AWS Tools for PowerShell Cmdlet \nReference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nUse ListBucketInventoryConfigurations  with a CLI\nThe following code examples show how to use ListBucketInventoryConfigurations .\nCLI\nAWS CLI\nTo retrieve a list of inventory con\ufb01gurations for a bucket\nThe following list-bucket-inventory-configurations  example lists the inventory \ncon\ufb01gurations for the speci\ufb01ed bucket.\naws s3api list-bucket-inventory-configurations \\ \n    --bucket my-bucket\nBasics API Version 2006-03-01 2084Amazon Simple Storage Service API Reference\nOutput:\n{ \n    \"InventoryConfigurationList\": [ \n        { \n            \"IsEnabled\": true, \n            \"Destination\": { \n                \"S3BucketDestination\": { \n                    \"Format\": \"ORC\", \n                    \"Bucket\": \"arn:aws:s3:::my-bucket\", \n                    \"AccountId\": \"123456789012\" \n                } \n            }, \n            \"IncludedObjectVersions\": \"Current\", \n            \"Id\": \"1\", \n            \"Schedule\": { \n                \"Frequency\": \"Weekly\" \n            } \n        }, \n        { \n            \"IsEnabled\": true, \n            \"Destination\": { \n                \"S3BucketDestination\": { \n                    \"Format\": \"CSV\", \n                    \"Bucket\": \"arn:aws:s3:::my-bucket\", \n                    \"AccountId\": \"123456789012\" \n                } \n            }, \n            \"IncludedObjectVersions\": \"Current\", \n            \"Id\": \"2\", \n            \"Schedule\": { \n                \"Frequency\": \"Daily\" \n            } \n        } \n    ], \n    \"IsTruncated\": false\n}\n\u2022For API details, see ListBucketInventoryCon\ufb01gurations in AWS CLI Command Reference.\nBasics API Version 2006-03-01 2085Amazon Simple Storage Service API Reference\nPowerShell\nTools for PowerShell\nExample 1: This command returns the \ufb01rst 100 inventory con\ufb01gurations of the given S3 \nbucket.\nGet-S3BucketInventoryConfigurationList -BucketName 'amzn-s3-demo-bucket'\n\u2022For API details, see ListBucketInventoryCon\ufb01gurations in AWS Tools for PowerShell Cmdlet \nReference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nUse ListBuckets  with an AWS SDK or CLI\nThe following code examples show how to use ListBuckets .\n.NET\nAWS SDK for .NET\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nnamespace ListBucketsExample\n{ \n    using System; \n    using System.Collections.Generic; \n    using System.Threading.Tasks; \n    using Amazon.S3; \n    using Amazon.S3.Model; \n    /// <summary> \n    /// This example uses the AWS SDK for .NET to list the Amazon Simple Storage \n    /// Service (Amazon S3) buckets belonging to the default account. \nBasics API Version 2006-03-01 2086Amazon Simple Storage Service API Reference\n    /// </summary> \n    public class ListBuckets \n    { \n        private static IAmazonS3 _s3Client; \n        /// <summary> \n        /// Get a list of the buckets owned by the default user. \n        /// </summary> \n        /// <param name=\"client\">An initialized Amazon S3 client object.</param> \n        /// <returns>The response from the ListingBuckets call that contains a \n        /// list of the buckets owned by the default user.</returns> \n        public static async Task<ListBucketsResponse> GetBuckets(IAmazonS3 \n client) \n        { \n            return await client.ListBucketsAsync(); \n        } \n        /// <summary> \n        /// This method lists the name and creation date for the buckets in \n        /// the passed List of S3 buckets. \n        /// </summary> \n        /// <param name=\"bucketList\">A List of S3 bucket objects.</param> \n        public static void DisplayBucketList(List<S3Bucket> bucketList) \n        { \n            bucketList \n                .ForEach(b => Console.WriteLine($\"Bucket name: {b.BucketName}, \n created on: {b.CreationDate}\")); \n        } \n        public static async Task Main() \n        { \n            // The client uses the AWS Region of the default user.", "\n            // If the Region where the buckets were created is different, \n            // pass the Region to the client constructor.", "For example: \n            // _s3Client = new AmazonS3Client(RegionEndpoint.USEast1); \n            _s3Client = new AmazonS3Client(); \n            var response = await GetBuckets(_s3Client); \n            DisplayBucketList(response.Buckets); \n        } \n    }\n}\nBasics API Version 2006-03-01 2087Amazon Simple Storage Service API Reference\n\u2022For API details, see ListBuckets in AWS SDK for .NET API Reference.\nC++\nSDK for C++\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nbool AwsDoc::S3::listBuckets(const Aws::S3::S3ClientConfiguration &clientConfig) \n { \n    Aws::S3::S3Client client(clientConfig); \n    auto outcome = client.ListBuckets(); \n    bool result = true; \n    if (!outcome.IsSuccess()) { \n        std::cerr << \"Failed with error: \" << outcome.GetError() << std::endl; \n        result = false; \n    } else { \n        std::cout << \"Found \" << outcome.GetResult().GetBuckets().size() << \" \n buckets\\n\"; \n        for (auto &&b: outcome.GetResult().GetBuckets()) { \n            std::cout << b.GetName() << std::endl; \n        } \n    } \n    return result;\n}\n\u2022For API details, see ListBuckets in AWS SDK for C++ API Reference.\nBasics API Version 2006-03-01 2088Amazon Simple Storage Service API Reference\nCLI\nAWS CLI\nThe following command uses the list-buckets  command to display the names of all your \nAmazon S3 buckets (across all regions):\naws s3api list-buckets --query \"Buckets[].Name\"\nThe query option \ufb01lters the output of list-buckets  down to only the bucket names.\nFor more information about buckets, see Working with Amazon S3 Buckets in the Amazon S3 \nDeveloper Guide .\n\u2022For API details, see ListBuckets in AWS CLI Command Reference.\nGo\nSDK for Go V2\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n// BucketBasics encapsulates the Amazon Simple Storage Service (Amazon S3) \n actions\n// used in the examples.\n// It contains S3Client, an Amazon S3 service client that is used to perform \n bucket\n// and object actions.\ntype BucketBasics struct { \n S3Client *s3.Client\n}\n// ListBuckets lists the buckets in the current account.\nfunc (basics BucketBasics) ListBuckets(ctx context.Context) ([]types.Bucket, \n error) { \nBasics API Version 2006-03-01 2089Amazon Simple Storage Service API Reference\n result, err := basics.S3Client.ListBuckets(ctx, &s3.ListBucketsInput{}) \n var buckets []types.Bucket \n if err != nil { \n  log.Printf(\"Couldn't list buckets for your account.", "Here's why: %v\\n\", err) \n } else { \n  buckets = result.Buckets \n } \n return buckets, err\n}\n\u2022For API details, see ListBuckets in AWS SDK for Go API Reference.\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nimport software.amazon.awssdk.regions.Region;\nimport software.amazon.awssdk.services.s3.S3Client;\nimport software.amazon.awssdk.services.s3.model.Bucket;\nimport software.amazon.awssdk.services.s3.model.ListBucketsResponse;\nimport java.util.List;\n/** \n * Before running this Java V2 code example, set up your development \n * environment, including your credentials. \n * \n * For more information, see the following documentation topic: \n * \n * https://docs.aws.amazon.com/sdk-for-java/latest/developer-guide/get-\nstarted.html \n */\npublic class ListBuckets { \n    public static void main(String[] args) { \n        Region region = Region.US_EAST_1; \nBasics API Version 2006-03-01 2090Amazon Simple Storage Service API Reference\n        S3Client s3 = S3Client.builder() \n            .region(region) \n            .build(); \n        listAllBuckets(s3); \n    } \n    /** \n     * Lists all the S3 buckets available in the current AWS account. \n     * \n     * @param s3 The {@link S3Client} instance to use for interacting with the \n Amazon S3 service.", "\n     */ \n    public static void listAllBuckets(S3Client s3) { \n        ListBucketsResponse response = s3.listBuckets(); \n        List<Bucket> bucketList = response.buckets(); \n        for (Bucket bucket: bucketList) { \n            System.out.println(\"Bucket name \"+bucket.name()); \n        } \n    }\n}\n\u2022For API details, see ListBuckets in AWS SDK for Java 2.x API Reference.\nJavaScript\nSDK for JavaScript (v3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nList the buckets.\nimport { \n  paginateListBuckets, \n  S3Client, \n  S3ServiceException,\nBasics API Version 2006-03-01 2091Amazon Simple Storage Service API Reference\n} from \"@aws-sdk/client-s3\";\n/** \n * List the Amazon S3 buckets in your account. \n */\nexport const main = async () => { \n  const client = new S3Client({}); \n  /** @type {?import('@aws-sdk/client-s3').Owner} */ \n  let Owner = null; \n  /** @type {import('@aws-sdk/client-s3').Bucket[]} */ \n  const Buckets = []; \n  try { \n    const paginator = paginateListBuckets({ client }, {}); \n    for await (const page of paginator) { \n      if (!Owner) { \n        Owner = page.Owner; \n      } \n      Buckets.push(...page.Buckets); \n    } \n    console.log( \n      `${Owner.DisplayName} owns ${Buckets.length} bucket${ \n        Buckets.length === 1 ? \"\" : \"s\" \n      }:`, \n    ); \n    console.log(`${Buckets.map((b) => ` \u2022 ${b.Name}`).join(\"\\n\")}`); \n  } catch (caught) { \n    if (caught instanceof S3ServiceException) { \n      console.error( \n        `Error from S3 while listing buckets. ${caught.name}: \n ${caught.message}`, \n      ); \n    } else { \n      throw caught; \n    } \n  }\n};\n\u2022For more information, see AWS SDK for JavaScript Developer Guide.\nBasics API Version 2006-03-01 2092Amazon Simple Storage Service API Reference\n\u2022For API details, see ListBuckets in AWS SDK for JavaScript API Reference.\nPowerShell\nTools for PowerShell\nExample 1: This command returns all S3 buckets.\nGet-S3Bucket\nExample 2: This command returns bucket named \"test-\ufb01les\"\nGet-S3Bucket -BucketName amzn-s3-demo-bucket\n\u2022For API details, see ListBuckets in AWS Tools for PowerShell Cmdlet Reference.\nPython\nSDK for Python (Boto3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nclass BucketWrapper: \n    \"\"\"Encapsulates S3 bucket actions.\"\"\" \n    def __init__(self, bucket): \n        \"\"\" \n        :param bucket: A Boto3 Bucket resource. This is a high-level resource in \n Boto3 \n                       that wraps bucket actions in a class-like structure.", "\n        \"\"\" \n        self.bucket = bucket \n        self.name = bucket.name \n    @staticmethod \nBasics API Version 2006-03-01 2093Amazon Simple Storage Service API Reference\n    def list(s3_resource): \n        \"\"\" \n        Get the buckets in all Regions for the current account.", "\n        :param s3_resource: A Boto3 S3 resource. This is a high-level resource in \n Boto3 \n                            that contains collections and factory methods to \n create \n                            other high-level S3 sub-resources.", "\n        :return: The list of buckets.", "\n        \"\"\" \n        try: \n            buckets = list(s3_resource.buckets.all()) \n            logger.info(\"Got buckets: %s.\", buckets) \n        except ClientError: \n            logger.exception(\"Couldn't get buckets.\") \n            raise \n        else: \n            return buckets\n\u2022For API details, see ListBuckets in AWS SDK for Python (Boto3) API Reference.\nRuby\nSDK for Ruby\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nrequire 'aws-sdk-s3'\n# Wraps Amazon S3 resource actions.\nclass BucketListWrapper \n  attr_reader :s3_resource \n  # @param s3_resource [Aws::S3::Resource] An Amazon S3 resource. \n  def initialize(s3_resource) \nBasics API Version 2006-03-01 2094Amazon Simple Storage Service API Reference\n    @s3_resource = s3_resource \n  end \n  # Lists buckets for the current account.", "\n  # \n  # @param count [Integer] The maximum number of buckets to list. \n  def list_buckets(count) \n    puts 'Found these buckets:' \n    @s3_resource.buckets.each do |bucket| \n      puts \"\\t#{bucket.name}\" \n      count -= 1 \n      break if count.zero?", "\n    end \n    true \n  rescue Aws::Errors::ServiceError => e \n    puts \"Couldn't list buckets. Here's why: #{e.message}\" \n    false \n  end\nend\n# Example usage:\ndef run_demo \n  wrapper = BucketListWrapper.new(Aws::S3::Resource.new) \n  wrapper.list_buckets(25)\nend\nrun_demo if $PROGRAM_NAME == __FILE__\n\u2022For API details, see ListBuckets in AWS SDK for Ruby API Reference.\nRust\nSDK for Rust\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nasync fn show_buckets( \nBasics API Version 2006-03-01 2095Amazon Simple Storage Service API Reference\n    strict: bool, \n    client: &Client, \n    region: BucketLocationConstraint,\n) -> Result<(), S3ExampleError> { \n    let mut buckets = client.list_buckets().into_paginator().send(); \n    let mut num_buckets = 0; \n    let mut in_region = 0; \n    while let Some(Ok(output)) = buckets.next().await { \n        for bucket in output.buckets() { \n            num_buckets += 1; \n            if strict { \n                let r = client \n                    .get_bucket_location() \n                    .bucket(bucket.name().unwrap_or_default()) \n                    .send() \n                    .await?; \n                if r.location_constraint() == Some(&region) { \n                    println!(\"{}\", bucket.name().unwrap_or_default()); \n                    in_region += 1; \n                } \n            } else { \n                println!(\"{}\", bucket.name().unwrap_or_default()); \n            } \n        } \n    } \n    println!(); \n    if strict { \n        println!( \n            \"Found {} buckets in the {} region out of a total of {} buckets.\", \n            in_region, region, num_buckets \n        ); \n    } else { \n        println!(\"Found {} buckets in all regions.\", num_buckets); \n    } \n    Ok(())\n}\n\u2022For API details, see ListBuckets in AWS SDK for Rust API reference.\nBasics API Version 2006-03-01 2096Amazon Simple Storage Service API Reference\nSwift\nSDK for Swift\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nimport AWSS3 \n    /// Return an array containing information about every available bucket. \n    /// \n    /// - Returns: An array of ``S3ClientTypes.Bucket`` objects describing \n    ///   each bucket. \n    public func getAllBuckets() async throws -> [S3ClientTypes.Bucket] { \n        return try await client.listBuckets(input: ListBucketsInput()) \n    }\n\u2022For API details, see ListBuckets in AWS SDK for Swift API reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs.", "This topic also includes information about getting started and details \nabout previous SDK versions.\nUse ListMultipartUploads  with an AWS SDK or CLI\nThe following code examples show how to use ListMultipartUploads .\nAction examples are code excerpts from larger programs and must be run in context. You can see \nthis action in context in the following code example:\n\u2022Delete incomplete multipart uploads\nBasics API Version 2006-03-01 2097Amazon Simple Storage Service API Reference\nCLI\nAWS CLI\nThe following command lists all of the active multipart uploads for a bucket named my-\nbucket :\naws s3api list-multipart-uploads --bucket my-bucket\nOutput:\n{ \n    \"Uploads\": [ \n        { \n            \"Initiator\": { \n                \"DisplayName\": \"username\", \n                \"ID\": \"arn:aws:iam::0123456789012:user/username\" \n            }, \n            \"Initiated\": \"2015-06-02T18:01:30.000Z\", \n            \"UploadId\": \n \"dfRtDYU0WWCCcH43C3WFbkRONycyCpTJJvxu2i5GYkZljF.Yxwh6XG7WfS2vC4to6HiV6Yjlx.cph0gtNBtJ8P3URCSbB7rjxI5iEwVDmgaXZOGgkk5nVTW16HOQ5l0R\", \n            \"StorageClass\": \"STANDARD\", \n            \"Key\": \"multipart/01\", \n            \"Owner\": { \n                \"DisplayName\": \"aws-account-name\", \n                \"ID\": \n \"100719349fc3b6dcd7c820a124bf7aecd408092c3d7b51b38494939801fc248b\" \n            } \n        } \n    ], \n    \"CommonPrefixes\": []\n}\nIn progress multipart uploads incur storage costs in Amazon S3. Complete or abort an active \nmultipart upload to remove its parts from your account.\n\u2022For API details, see ListMultipartUploads in AWS CLI Command Reference.\nBasics API Version 2006-03-01 2098Amazon Simple Storage Service API Reference\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nimport software.amazon.awssdk.regions.Region;\nimport software.amazon.awssdk.services.s3.S3Client;\nimport software.amazon.awssdk.services.s3.model.ListMultipartUploadsRequest;\nimport software.amazon.awssdk.services.s3.model.ListMultipartUploadsResponse;\nimport software.amazon.awssdk.services.s3.model.MultipartUpload;\nimport software.amazon.awssdk.services.s3.model.S3Exception;\nimport java.util.List;\n/** \n * Before running this Java V2 code example, set up your development \n * environment, including your credentials. \n * \n * For more information, see the following documentation topic: \n * \n * https://docs.aws.amazon.com/sdk-for-java/latest/developer-guide/get-\nstarted.html \n */\npublic class ListMultipartUploads { \n    public static void main(String[] args) { \n        final String usage = \"\"\" \n                Usage: \n                    <bucketName>\\s \n                Where: \n                    bucketName - The name of the Amazon S3 bucket where an in-\nprogress multipart upload is occurring. \n                \"\"\"; \n        if (args.length != 1) { \n            System.out.println(usage); \nBasics API Version 2006-03-01 2099Amazon Simple Storage Service API Reference\n            System.exit(1); \n        } \n        String bucketName = args[0]; \n        Region region = Region.US_EAST_1; \n        S3Client s3 = S3Client.builder() \n                .region(region) \n                .build(); \n        listUploads(s3, bucketName); \n        s3.close(); \n    } \n    /** \n     * Lists the multipart uploads currently in progress in the specified Amazon \n S3 bucket. \n     * \n     * @param s3 the S3Client object used to interact with Amazon S3 \n     * @param bucketName the name of the Amazon S3 bucket to list the multipart \n uploads for \n     */ \n    public static void listUploads(S3Client s3, String bucketName) { \n        try { \n            ListMultipartUploadsRequest listMultipartUploadsRequest = \n ListMultipartUploadsRequest.builder() \n                    .bucket(bucketName) \n                    .build(); \n            ListMultipartUploadsResponse response = \n s3.listMultipartUploads(listMultipartUploadsRequest); \n            List<MultipartUpload> uploads = response.uploads(); \n            for (MultipartUpload upload : uploads) { \n                System.out.println(\"Upload in progress: Key = \\\"\" + upload.key() \n + \"\\\", id = \" + upload.uploadId()); \n            } \n        } catch (S3Exception e) { \n            System.err.println(e.getMessage()); \n            System.exit(1); \n        } \n    }\n}\n\u2022For API details, see ListMultipartUploads in AWS SDK for Java 2.x API Reference.\nBasics API Version 2006-03-01 2100Amazon Simple Storage Service API Reference\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs.", "This topic also includes information about getting started and details \nabout previous SDK versions.\nUse ListObjectVersions  with an AWS SDK or CLI\nThe following code examples show how to use ListObjectVersions .\nAction examples are code excerpts from larger programs and must be run in context. You can see \nthis action in context in the following code example:\n\u2022Work with versioned objects\n.NET\nAWS SDK for .NET\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n    using System; \n    using System.Threading.Tasks; \n    using Amazon.S3; \n    using Amazon.S3.Model; \n    /// <summary> \n    /// This example lists the versions of the objects in a version enabled \n    /// Amazon Simple Storage Service (Amazon S3) bucket. \n    /// </summary> \n    public class ListObjectVersions \n    { \n        public static async Task Main() \n        { \n            string bucketName = \"amzn-s3-demo-bucket\"; \n            // If the AWS Region where your bucket is defined is different from \n            // the AWS Region where the Amazon S3 bucket is defined, pass the \n constant \nBasics API Version 2006-03-01 2101Amazon Simple Storage Service API Reference\n            // for the AWS Region to the client constructor like this: \n            //      var client = new AmazonS3Client(RegionEndpoint.USWest2); \n            IAmazonS3 client = new AmazonS3Client(); \n            await GetObjectListWithAllVersionsAsync(client, bucketName); \n        } \n        /// <summary> \n        /// This method lists all versions of the objects within an Amazon S3 \n        /// version enabled bucket. \n        /// </summary> \n        /// <param name=\"client\">The initialized client object used to call \n        /// ListVersionsAsync.</param> \n        /// <param name=\"bucketName\">The name of the version enabled Amazon S3 \n bucket \n        /// for which you want to list the versions of the contained objects.</\nparam> \n        public static async Task GetObjectListWithAllVersionsAsync(IAmazonS3 \n client, string bucketName) \n        { \n            try \n            { \n                // When you instantiate the ListVersionRequest, you can \n                // optionally specify a key name prefix in the request \n                // if you want a list of object versions of a specific object.", "\n                // For this example we set a small limit in MaxKeys to return \n                // a small list of versions.", "\n                ListVersionsRequest request = new ListVersionsRequest() \n                { \n                    BucketName = bucketName, \n                    MaxKeys = 2, \n                }; \n                do \n                { \n                    ListVersionsResponse response = await \n client.ListVersionsAsync(request); \n                    // Process response.", "\n                    foreach (S3ObjectVersion entry in response.Versions) \n                    { \n                        Console.WriteLine($\"key: {entry.Key} size: \n {entry.Size}\"); \n                    } \nBasics API Version 2006-03-01 2102Amazon Simple Storage Service API Reference\n                    // If response is truncated, set the marker to get the next \n                    // set of keys. \n                    if (response.IsTruncated) \n                    { \n                        request.KeyMarker = response.NextKeyMarker; \n                        request.VersionIdMarker = response.NextVersionIdMarker; \n                    } \n                    else \n                    { \n                        request = null; \n                    } \n                } \n                while (request != null); \n            } \n            catch (AmazonS3Exception ex) \n            { \n                Console.WriteLine($\"Error: '{ex.Message}'\"); \n            } \n        } \n    }\n\u2022For API details, see ListObjectVersions in AWS SDK for .NET API Reference.\nCLI\nAWS CLI\nThe following command retrieves version information for an object in a bucket named my-\nbucket :\naws s3api list-object-versions --bucket my-bucket  --prefix index.html\nOutput:\n{ \n    \"DeleteMarkers\": [ \n        { \n            \"Owner\": { \n                \"DisplayName\": \"my-username\", \nBasics API Version 2006-03-01 2103Amazon Simple Storage Service API Reference\n                \"ID\": \n \"7009a8971cd660687538875e7c86c5b672fe116bd438f46db45460ddcd036c32\" \n            }, \n            \"IsLatest\": true, \n            \"VersionId\": \"B2VsEK5saUNNHKcOAJj7hIE86RozToyq\", \n            \"Key\": \"index.html\", \n            \"LastModified\": \"2015-11-10T00:57:03.000Z\" \n        }, \n        { \n            \"Owner\": { \n                \"DisplayName\": \"my-username\", \n                \"ID\": \n \"7009a8971cd660687538875e7c86c5b672fe116bd438f46db45460ddcd036c32\" \n            }, \n            \"IsLatest\": false, \n            \"VersionId\": \".FLQEZscLIcfxSq.jsFJ.szUkmng2Yw6\", \n            \"Key\": \"index.html\", \n            \"LastModified\": \"2015-11-09T23:32:20.000Z\" \n        } \n    ], \n    \"Versions\": [ \n        { \n            \"LastModified\": \"2015-11-10T00:20:11.000Z\", \n            \"VersionId\": \"Rb_l2T8UHDkFEwCgJjhlgPOZC0qJ.vpD\", \n            \"ETag\": \"\\\"0622528de826c0df5db1258a23b80be5\\\"\", \n            \"StorageClass\": \"STANDARD\", \n            \"Key\": \"index.html\", \n            \"Owner\": { \n                \"DisplayName\": \"my-username\", \n                \"ID\": \n \"7009a8971cd660687538875e7c86c5b672fe116bd438f46db45460ddcd036c32\" \n            }, \n            \"IsLatest\": false, \n            \"Size\": 38 \n        }, \n        { \n            \"LastModified\": \"2015-11-09T23:26:41.000Z\", \n            \"VersionId\": \"rasWWGpgk9E4s0LyTJgusGeRQKLVIAFf\", \n            \"ETag\": \"\\\"06225825b8028de826c0df5db1a23be5\\\"\", \n            \"StorageClass\": \"STANDARD\", \n            \"Key\": \"index.html\", \n            \"Owner\": { \n                \"DisplayName\": \"my-username\", \nBasics API Version 2006-03-01 2104Amazon Simple Storage Service API Reference\n                \"ID\": \n \"7009a8971cd660687538875e7c86c5b672fe116bd438f46db45460ddcd036c32\" \n            }, \n            \"IsLatest\": false, \n            \"Size\": 38 \n        }, \n        { \n            \"LastModified\": \"2015-11-09T22:50:50.000Z\", \n            \"VersionId\": \"null\", \n            \"ETag\": \"\\\"d1f45267a863c8392e07d24dd592f1b9\\\"\", \n            \"StorageClass\": \"STANDARD\", \n            \"Key\": \"index.html\", \n            \"Owner\": { \n                \"DisplayName\": \"my-username\", \n                \"ID\": \n \"7009a8971cd660687538875e7c86c5b672fe116bd438f46db45460ddcd036c32\" \n            }, \n            \"IsLatest\": false, \n            \"Size\": 533823 \n        } \n    ]\n}\n\u2022For API details, see ListObjectVersions in AWS CLI Command Reference.\nGo\nSDK for Go V2\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n// S3Actions wraps S3 service actions.\ntype S3Actions struct { \n S3Client  *s3.Client \n S3Manager *manager.Uploader\n}\nBasics API Version 2006-03-01 2105Amazon Simple Storage Service API Reference\n// ListObjectVersions lists all versions of all objects in a bucket.\nfunc (actor S3Actions) ListObjectVersions(ctx context.Context, bucket string) \n ([]types.ObjectVersion, error) { \n var err error \n var output *s3.ListObjectVersionsOutput \n var versions []types.ObjectVersion \n input := &s3.ListObjectVersionsInput{Bucket: aws.String(bucket)} \n versionPaginator := s3.NewListObjectVersionsPaginator(actor.S3Client, input) \n for versionPaginator.HasMorePages() { \n  output, err = versionPaginator.NextPage(ctx) \n  if err != nil { \n   var noBucket *types.NoSuchBucket \n   if errors.As(err, &noBucket) { \n    log.Printf(\"Bucket %s does not exist.\\n\", bucket) \n    err = noBucket \n   } \n   break \n  } else { \n   versions = append(versions, output.Versions...) \n  } \n } \n return versions, err\n}\n\u2022For API details, see ListObjectVersions in AWS SDK for Go API Reference.\nRust\nSDK for Rust\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nasync fn show_versions(client: &Client, bucket: &str) -> Result<(), Error> { \n    let resp = client.list_object_versions().bucket(bucket).send().await?; \nBasics API Version 2006-03-01 2106Amazon Simple Storage Service API Reference\n    for version in resp.versions() { \n        println!(\"{}\", version.key().unwrap_or_default()); \n        println!(\"  version ID: {}\", version.version_id().unwrap_or_default()); \n        println!(); \n    } \n    Ok(())\n}\n\u2022For API details, see ListObjectVersions in AWS SDK for Rust API reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nUse ListObjects  with a CLI\nThe following code examples show how to use ListObjects .\nAction examples are code excerpts from larger programs and must be run in context.", "You can see \nthis action in context in the following code example:\n\u2022Create a web page that lists Amazon S3 objects\nCLI\nAWS CLI\nThe following example uses the list-objects  command to display the names of all the \nobjects in the speci\ufb01ed bucket:\naws s3api list-objects --bucket text-content  --query ' Contents[].{Key: Key, Size: \n Size}'\nThe example uses the --query argument to \ufb01lter the output of list-objects  down to \nthe key value and size for each object\nFor more information about objects, see Working with Amazon S3 Objects in the Amazon S3 \nDeveloper Guide .\nBasics API Version 2006-03-01 2107Amazon Simple Storage Service API Reference\n\u2022For API details, see ListObjects in AWS CLI Command Reference.\nPowerShell\nTools for PowerShell\nExample 1: This command retrieves the information about all of the items in the bucket \n\"test-\ufb01les\".\nGet-S3Object -BucketName amzn-s3-demo-bucket\nExample 2: This command retrieves the information about the item \"sample.txt\" from \nbucket \"test-\ufb01les\".\nGet-S3Object -BucketName amzn-s3-demo-bucket -Key sample.txt\nExample 3: This command retrieves the information about all items with the pre\ufb01x \n\"sample\" from bucket \"test-\ufb01les\".\nGet-S3Object -BucketName amzn-s3-demo-bucket -KeyPrefix sample\n\u2022For API details, see ListObjects in AWS Tools for PowerShell Cmdlet Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs.", "This topic also includes information about getting started and details \nabout previous SDK versions.\nUse ListObjectsV2  with an AWS SDK or CLI\nThe following code examples show how to use ListObjectsV2 .\nAction examples are code excerpts from larger programs and must be run in context.", "You can see \nthis action in context in the following code examples:\n\u2022Learn the basics\n\u2022Delete all objects in a bucket\nBasics API Version 2006-03-01 2108Amazon Simple Storage Service API Reference\n.NET\nAWS SDK for .NET\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n        /// <summary> \n        /// Shows how to list the objects in an Amazon S3 bucket. \n        /// </summary> \n        /// <param name=\"client\">An initialized Amazon S3 client object.</param> \n        /// <param name=\"bucketName\">The name of the bucket for which to list \n        /// the contents.</param> \n        /// <returns>A boolean value indicating the success or failure of the \n        /// copy operation.</returns> \n        public static async Task<bool> ListBucketContentsAsync(IAmazonS3 client, \n string bucketName) \n        { \n            try \n            { \n                var request = new ListObjectsV2Request \n                { \n                    BucketName = bucketName, \n                    MaxKeys = 5, \n                }; \n                Console.WriteLine(\"--------------------------------------\"); \n                Console.WriteLine($\"Listing the contents of {bucketName}:\"); \n                Console.WriteLine(\"--------------------------------------\"); \n                ListObjectsV2Response response; \n                do \n                { \n                    response = await client.ListObjectsV2Async(request); \n                    response.S3Objects \nBasics API Version 2006-03-01 2109Amazon Simple Storage Service API Reference\n                        .ForEach(obj => Console.WriteLine($\"{obj.Key,-35}\n{obj.LastModified.ToShortDateString(),10}{obj.Size,10}\")); \n                    // If the response is truncated, set the request \n ContinuationToken \n                    // from the NextContinuationToken property of the response. \n                    request.ContinuationToken = response.NextContinuationToken; \n                } \n                while (response.IsTruncated); \n                return true; \n            } \n            catch (AmazonS3Exception ex) \n            { \n                Console.WriteLine($\"Error encountered on server. \n Message:'{ex.Message}' getting list of objects.\"); \n                return false; \n            } \n        }\nList objects with a paginator.\n    using System; \n    using System.Threading.Tasks; \n    using Amazon.S3; \n    using Amazon.S3.Model; \n    /// <summary> \n    /// The following example lists objects in an Amazon Simple Storage \n    /// Service (Amazon S3) bucket. \n    /// </summary> \n    public class ListObjectsPaginator \n    { \n        private const string BucketName = \"amzn-s3-demo-bucket\"; \n        public static async Task Main() \n        { \n            IAmazonS3 s3Client = new AmazonS3Client(); \n            Console.WriteLine($\"Listing the objects contained in {BucketName}:\n\\n\"); \nBasics API Version 2006-03-01 2110Amazon Simple Storage Service API Reference\n            await ListingObjectsAsync(s3Client, BucketName); \n        } \n        /// <summary> \n        /// This method uses a paginator to retrieve the list of objects in an \n        /// an Amazon S3 bucket. \n        /// </summary> \n        /// <param name=\"client\">An Amazon S3 client object.</param> \n        /// <param name=\"bucketName\">The name of the S3 bucket whose objects \n        /// you want to list.</param> \n        public static async Task ListingObjectsAsync(IAmazonS3 client, string \n bucketName) \n        { \n            var listObjectsV2Paginator = client.Paginators.ListObjectsV2(new \n ListObjectsV2Request \n            { \n                BucketName = bucketName, \n            }); \n            await foreach (var response in listObjectsV2Paginator.Responses) \n            { \n                Console.WriteLine($\"HttpStatusCode: {response.HttpStatusCode}\"); \n                Console.WriteLine($\"Number of Keys: {response.KeyCount}\"); \n                foreach (var entry in response.S3Objects) \n                { \n                    Console.WriteLine($\"Key = {entry.Key} Size = {entry.Size}\"); \n                } \n            } \n        } \n    }\n\u2022For API details, see ListObjectsV2 in AWS SDK for .NET API Reference.\nBasics API Version 2006-03-01 2111Amazon Simple Storage Service API Reference\nBash\nAWS CLI with Bash script\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n###############################################################################\n# function errecho\n#\n# This function outputs everything sent to it to STDERR (standard error output).\n###############################################################################\nfunction errecho() { \n  printf \"%s\\n\" \"$*\" 1>&2\n}\n###############################################################################\n# function list_items_in_bucket\n#\n# This function displays a list of the files in the bucket with each file's\n# size. The function uses the --query parameter to retrieve only the key and\n# size fields from the Contents collection.\n#\n# Parameters:\n#       $1 - The name of the bucket.\n#\n# Returns:\n#       The list of files in text format.\n#     And:\n#       0 - If successful.\n#       1 - If it fails.\n###############################################################################\nfunction list_items_in_bucket() { \n  local bucket_name=$1 \n  local response \n  response=$(aws s3api list-objects \\ \n    --bucket \"$bucket_name\" \\ \n    --output text \\ \nBasics API Version 2006-03-01 2112Amazon Simple Storage Service API Reference\n    --query 'Contents[].{Key: Key, Size: Size}') \n  # shellcheck disable=SC2181 \n  if [[ ${?} -eq 0 ]]; then \n    echo \"$response\" \n  else \n    errecho \"ERROR: AWS reports s3api list-objects operation failed.\\n$response\" \n    return 1 \n  fi\n}\n\u2022For API details, see ListObjectsV2 in AWS CLI Command Reference.\nC++\nSDK for C++\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nbool AwsDoc::S3::listObjects(const Aws::String &bucketName, \n                             Aws::Vector<Aws::String> &keysResult, \n                             const Aws::S3::S3ClientConfiguration &clientConfig) \n { \n    Aws::S3::S3Client s3Client(clientConfig); \n    Aws::S3::Model::ListObjectsV2Request request; \n    request.WithBucket(bucketName); \n    Aws::String continuationToken; // Used for pagination. \n    Aws::Vector<Aws::S3::Model::Object> allObjects; \n    do { \n        if (!continuationToken.empty()) { \n            request.SetContinuationToken(continuationToken); \n        } \n        auto outcome = s3Client.ListObjectsV2(request); \nBasics API Version 2006-03-01 2113Amazon Simple Storage Service API Reference\n        if (!outcome.IsSuccess()) { \n            std::cerr << \"Error: listObjects: \" << \n                      outcome.GetError().GetMessage() << std::endl; \n            return false; \n        } else { \n            Aws::Vector<Aws::S3::Model::Object> objects = \n                    outcome.GetResult().GetContents(); \n            allObjects.insert(allObjects.end(), objects.begin(), objects.end()); \n            continuationToken = outcome.GetResult().GetNextContinuationToken(); \n        } \n    } while (!continuationToken.empty()); \n    std::cout << allObjects.size() << \" object(s) found:\" << std::endl; \n    for (const auto &object: allObjects) { \n        std::cout << \"  \" << object.GetKey() << std::endl; \n        keysResult.push_back(object.GetKey()); \n    } \n    return true;\n}\n\u2022For API details, see ListObjectsV2 in AWS SDK for C++ API Reference.\nCLI\nAWS CLI\nTo get a list of objects in a bucket\nThe following list-objects-v2  example lists the objects in the speci\ufb01ed bucket.\naws s3api list-objects-v2 \\ \n    --bucket my-bucket\nOutput:\n{ \n    \"Contents\": [ \nBasics API Version 2006-03-01 2114Amazon Simple Storage Service API Reference\n        { \n            \"LastModified\": \"2019-11-05T23:11:50.000Z\", \n            \"ETag\": \"\\\"621503c373607d548b37cff8778d992c\\\"\", \n            \"StorageClass\": \"STANDARD\", \n            \"Key\": \"doc1.rtf\", \n            \"Size\": 391 \n        }, \n        { \n            \"LastModified\": \"2019-11-05T23:11:50.000Z\", \n            \"ETag\": \"\\\"a2cecc36ab7c7fe3a71a273b9d45b1b5\\\"\", \n            \"StorageClass\": \"STANDARD\", \n            \"Key\": \"doc2.rtf\", \n            \"Size\": 373 \n        }, \n        { \n            \"LastModified\": \"2019-11-05T23:11:50.000Z\", \n            \"ETag\": \"\\\"08210852f65a2e9cb999972539a64d68\\\"\", \n            \"StorageClass\": \"STANDARD\", \n            \"Key\": \"doc3.rtf\", \n            \"Size\": 399 \n        }, \n        { \n            \"LastModified\": \"2019-11-05T23:11:50.000Z\", \n            \"ETag\": \"\\\"d1852dd683f404306569471af106988e\\\"\", \n            \"StorageClass\": \"STANDARD\", \n            \"Key\": \"doc4.rtf\", \n            \"Size\": 6225 \n        } \n    ]\n}\n\u2022For API details, see ListObjectsV2 in AWS CLI Command Reference.\nGo\nSDK for Go V2\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nBasics API Version 2006-03-01 2115Amazon Simple Storage Service API Reference\n// BucketBasics encapsulates the Amazon Simple Storage Service (Amazon S3) \n actions\n// used in the examples.\n// It contains S3Client, an Amazon S3 service client that is used to perform \n bucket\n// and object actions.\ntype BucketBasics struct { \n S3Client *s3.Client\n}\n// ListObjects lists the objects in a bucket.\nfunc (basics BucketBasics) ListObjects(ctx context.Context, bucketName string) \n ([]types.Object, error) { \n result, err := basics.S3Client.ListObjectsV2(ctx, &s3.ListObjectsV2Input{ \n  Bucket: aws.String(bucketName), \n }) \n var contents []types.Object \n if err != nil { \n  log.Printf(\"Couldn't list objects in bucket %v.", "Here's why: %v\\n\", bucketName, \n err) \n } else { \n  contents = result.Contents \n } \n return contents, err\n}\n\u2022For API details, see ListObjectsV2 in AWS SDK for Go API Reference.\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nBasics API Version 2006-03-01 2116Amazon Simple Storage Service API Reference\n    /** \n     * Asynchronously lists all objects in the specified S3 bucket. \n     * \n     * @param bucketName the name of the S3 bucket to list objects for \n     * @return a {@link CompletableFuture} that completes when all objects have \n been listed \n     */ \n    public CompletableFuture<Void> listAllObjectsAsync(String bucketName) { \n        ListObjectsV2Request initialRequest = ListObjectsV2Request.builder() \n            .bucket(bucketName) \n            .maxKeys(1) \n            .build(); \n        ListObjectsV2Publisher paginator = \n getAsyncClient().listObjectsV2Paginator(initialRequest); \n        return paginator.subscribe(response -> { \n            response.contents().forEach(s3Object -> { \n                logger.info(\"Object key: \" + s3Object.key()); \n            }); \n        }).thenRun(() -> { \n            logger.info(\"Successfully listed all objects in the bucket: \" + \n bucketName); \n        }).exceptionally(ex -> { \n            throw new RuntimeException(\"Failed to list objects\", ex); \n        }); \n    }\nList objects using pagination.\nimport software.amazon.awssdk.regions.Region;\nimport software.amazon.awssdk.services.s3.S3Client;\nimport software.amazon.awssdk.services.s3.model.ListObjectsV2Request;\nimport software.amazon.awssdk.services.s3.model.S3Exception;\nimport software.amazon.awssdk.services.s3.paginators.ListObjectsV2Iterable;\npublic class ListObjectsPaginated { \n    public static void main(String[] args) { \n        final String usage = \"\"\" \n            Usage: \nBasics API Version 2006-03-01 2117Amazon Simple Storage Service API Reference\n                <bucketName>\\s \n            Where: \n                bucketName - The Amazon S3 bucket from which objects are read.\\s \n            \"\"\"; \n        if (args.length != 1) { \n            System.out.println(usage); \n            System.exit(1); \n        } \n        String bucketName = args[0]; \n        Region region = Region.US_EAST_1; \n        S3Client s3 = S3Client.builder() \n            .region(region) \n            .build(); \n        listBucketObjects(s3, bucketName); \n        s3.close(); \n    } \n    /** \n     * Lists the objects in the specified S3 bucket. \n     * \n     * @param s3 the S3Client instance used to interact with Amazon S3 \n     * @param bucketName the name of the S3 bucket to list the objects from \n     */ \n    public static void listBucketObjects(S3Client s3, String bucketName) { \n        try { \n            ListObjectsV2Request listReq = ListObjectsV2Request.builder() \n                .bucket(bucketName) \n                .maxKeys(1) \n                .build(); \n            ListObjectsV2Iterable listRes = s3.listObjectsV2Paginator(listReq); \n            listRes.stream() \n                .flatMap(r -> r.contents().stream()) \n                .forEach(content -> System.out.println(\" Key: \" + content.key() + \n \" size = \" + content.size())); \n        } catch (S3Exception e) { \n            System.err.println(e.awsErrorDetails().errorMessage()); \n            System.exit(1); \n        } \nBasics API Version 2006-03-01 2118Amazon Simple Storage Service API Reference\n    }\n}\n\u2022For API details, see ListObjectsV2 in AWS SDK for Java 2.x API Reference.\nJavaScript\nSDK for JavaScript (v3)\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nList all of the objects in your bucket.", "If there is more than one object, IsTruncated and \nNextContinuationToken will be used to iterate over the full list.\nimport { \n  S3Client, \n  S3ServiceException, \n  // This command supersedes the ListObjectsCommand and is the recommended way to \n list objects. \n  paginateListObjectsV2,\n} from \"@aws-sdk/client-s3\";\n/** \n * Log all of the object keys in a bucket. \n * @param {{ bucketName: string, pageSize: string }} \n */\nexport const main = async ({ bucketName, pageSize }) => { \n  const client = new S3Client({}); \n  /** @type {string[][]} */ \n  const objects = []; \n  try { \n    const paginator = paginateListObjectsV2( \n      { client, /* Max items per page */ pageSize: Number.parseInt(pageSize) }, \n      { Bucket: bucketName }, \n    ); \n    for await (const page of paginator) { \nBasics API Version 2006-03-01 2119Amazon Simple Storage Service API Reference\n      objects.push(page.Contents.map((o) => o.Key)); \n    } \n    objects.forEach((objectList, pageNum) => { \n      console.log( \n        `Page ${pageNum + 1}\\n------\\n${objectList.map((o) => `\u2022 \n ${o}`).join(\"\\n\")}\\n`, \n      ); \n    }); \n  } catch (caught) { \n    if ( \n      caught instanceof S3ServiceException && \n      caught.name === \"NoSuchBucket\" \n    ) { \n      console.error( \n        `Error from S3 while listing objects for \"${bucketName}\". The bucket \n doesn't exist.`, \n      ); \n    } else if (caught instanceof S3ServiceException) { \n      console.error( \n        `Error from S3 while listing objects for \"${bucketName}\".", "\n ${caught.name}: ${caught.message}`, \n      ); \n    } else { \n      throw caught; \n    } \n  }\n};\n\u2022For API details, see ListObjectsV2 in AWS SDK for JavaScript API Reference.\nKotlin\nSDK for Kotlin\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nsuspend fun listBucketObjects(bucketName: String) { \nBasics API Version 2006-03-01 2120Amazon Simple Storage Service API Reference\n    val request = \n        ListObjectsRequest { \n            bucket = bucketName \n        } \n    S3Client { region = \"us-east-1\" }.use { s3 -> \n        val response = s3.listObjects(request) \n        response.contents?.forEach { myObject -> \n            println(\"The name of the key is ${myObject.key}\") \n            println(\"The object is ${myObject.size?.let { calKb(it) }} KBs\") \n            println(\"The owner is ${myObject.owner}\") \n        } \n    }\n}\nprivate fun calKb(intValue: Long): Long = intValue / 1024\n\u2022For API details, see ListObjectsV2 in AWS SDK for Kotlin API reference.\nPHP\nSDK for PHP\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nList objects in a bucket.\n        $s3client = new Aws\\S3\\S3Client(['region' => 'us-west-2']); \n        try { \n            $contents = $this->s3client->listObjectsV2([ \n                'Bucket' => $this->bucketName, \n            ]); \n            echo \"The contents of your bucket are: \\n\"; \n            foreach ($contents['Contents'] as $content) { \n                echo $content['Key'] .", "\"\\n\"; \n            } \nBasics API Version 2006-03-01 2121Amazon Simple Storage Service API Reference\n        } catch (Exception $exception) { \n            echo \"Failed to list objects in $this->bucketName with error: \" .", "\n $exception->getMessage(); \n            exit(\"Please fix error with listing objects before continuing.\"); \n        }\n\u2022For API details, see ListObjectsV2 in AWS SDK for PHP API Reference.\nPython\nSDK for Python (Boto3)\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nclass ObjectWrapper: \n    \"\"\"Encapsulates S3 object actions.\"\"\" \n    def __init__(self, s3_object): \n        \"\"\" \n        :param s3_object: A Boto3 Object resource. This is a high-level resource \n in Boto3 \n                          that wraps object actions in a class-like structure.", "\n        \"\"\" \n        self.object = s3_object \n        self.key = self.object.key \n    @staticmethod \n    def list(bucket, prefix=None): \n        \"\"\" \n        Lists the objects in a bucket, optionally filtered by a prefix.", "\n        :param bucket: The bucket to query.", "This is a Boto3 Bucket resource.", "\n        :param prefix: When specified, only objects that start with this prefix \n are listed. \n        :return: The list of objects.", "\n        \"\"\" \nBasics API Version 2006-03-01 2122Amazon Simple Storage Service API Reference\n        try: \n            if not prefix: \n                objects = list(bucket.objects.all()) \n            else: \n                objects = list(bucket.objects.filter(Prefix=prefix)) \n            logger.info( \n                \"Got objects %s from bucket '%s'\", [o.key for o in objects], \n bucket.name \n            ) \n        except ClientError: \n            logger.exception(\"Couldn't get objects for bucket '%s'.\", \n bucket.name) \n            raise \n        else: \n            return objects\n\u2022For API details, see ListObjectsV2 in AWS SDK for Python (Boto3) API Reference.\nRuby\nSDK for Ruby\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nrequire 'aws-sdk-s3'\n# Wraps Amazon S3 bucket actions.\nclass BucketListObjectsWrapper \n  attr_reader :bucket \n  # @param bucket [Aws::S3::Bucket] An existing Amazon S3 bucket.", "\n  def initialize(bucket) \n    @bucket = bucket \n  end \n  # Lists object in a bucket.", "\nBasics API Version 2006-03-01 2123Amazon Simple Storage Service API Reference\n  # \n  # @param max_objects [Integer] The maximum number of objects to list.", "\n  # @return [Integer] The number of objects listed.", "\n  def list_objects(max_objects) \n    count = 0 \n    puts \"The objects in #{@bucket.name} are:\" \n    @bucket.objects.each do |obj| \n      puts \"\\t#{obj.key}\" \n      count += 1 \n      break if count == max_objects \n    end \n    count \n  rescue Aws::Errors::ServiceError => e \n    puts \"Couldn't list objects in bucket #{bucket.name}. Here's why: \n #{e.message}\" \n    0 \n  end\nend\n# Example usage:\ndef run_demo\n<<<<<<< HEAD \n  bucket_name = \"amzn-s3-demo-bucket\"\n======= \n  bucket_name = 'doc-example-bucket'\n>>>>>>> 999c6133e (fixes) \n  wrapper = BucketListObjectsWrapper.new(Aws::S3::Bucket.new(bucket_name)) \n  count = wrapper.list_objects(25) \n  puts \"Listed #{count} objects.\"\nend\nrun_demo if $PROGRAM_NAME == __FILE__\n\u2022For API details, see ListObjectsV2 in AWS SDK for Ruby API Reference.\nBasics API Version 2006-03-01 2124Amazon Simple Storage Service API Reference\nRust\nSDK for Rust\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\npub async fn list_objects(client: &aws_sdk_s3::Client, bucket: &str) -> \n Result<(), S3ExampleError> { \n    let mut response = client \n        .list_objects_v2() \n        .bucket(bucket.to_owned()) \n        .max_keys(10) // In this example, go 10 at a time.", "\n        .into_paginator() \n        .send(); \n    while let Some(result) = response.next().await { \n        match result { \n            Ok(output) => { \n                for object in output.contents() { \n                    println!(\" - {}\", object.key().unwrap_or(\"Unknown\")); \n                } \n            } \n            Err(err) => { \n                eprintln!(\"{err:?}\") \n            } \n        } \n    } \n    Ok(())\n}\n\u2022For API details, see ListObjectsV2 in AWS SDK for Rust API reference.\nBasics API Version 2006-03-01 2125Amazon Simple Storage Service API Reference\nSAP ABAP\nSDK for SAP ABAP\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n    TRY.", "\n        oo_result = lo_s3->listobjectsv2(         \" oo_result is returned for \n testing purposes.", "\" \n          iv_bucket = iv_bucket_name \n        ).", "\n        MESSAGE 'Retrieved list of objects in S3 bucket.' TYPE 'I'.", "\n      CATCH /aws1/cx_s3_nosuchbucket.", "\n        MESSAGE 'Bucket does not exist.' TYPE 'E'.", "\n    ENDTRY.\n\u2022For API details, see ListObjectsV2 in AWS SDK for SAP ABAP API reference.\nSwift\nSDK for Swift\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nimport AWSS3 \n    public func listBucketFiles(bucket: String) async throws -> [String] { \n        do { \n            let input = ListObjectsV2Input( \n                bucket: bucket \n            ) \nBasics API Version 2006-03-01 2126Amazon Simple Storage Service API Reference\n            \n            // Use \"Paginated\" to get all the objects.", "\n            // This lets the SDK handle the 'continuationToken' in \n \"ListObjectsV2Output\". \n            let output = client.listObjectsV2Paginated(input: input) \n            var names: [String] = [] \n             \n            for try await page in output { \n                guard let objList = page.contents else { \n                    print(\"ERROR: listObjectsV2Paginated returned nil contents.\") \n                    continue \n                } \n                 \n                for obj in objList { \n                    if let objName = obj.key { \n                        names.append(objName) \n                    } \n                } \n            } \n             \n             \n            return names \n        } \n        catch { \n            print(\"ERROR: \", dump(error, name: \"Listing objects.\")) \n            throw error \n        } \n    }\n\u2022For API details, see ListObjectsV2 in AWS SDK for Swift API reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs.", "This topic also includes information about getting started and details \nabout previous SDK versions.\nUse PutBucketAccelerateConfiguration  with an AWS SDK or CLI\nThe following code examples show how to use PutBucketAccelerateConfiguration .\nBasics API Version 2006-03-01 2127Amazon Simple Storage Service API Reference\n.NET\nAWS SDK for .NET\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n    using System; \n    using System.Threading.Tasks; \n    using Amazon.S3; \n    using Amazon.S3.Model; \n    /// <summary> \n    /// Amazon Simple Storage Service (Amazon S3) Transfer Acceleration is a \n    /// bucket-level feature that enables you to perform faster data transfers \n    /// to Amazon S3.", "This example shows how to configure Transfer \n    /// Acceleration.", "\n    /// </summary> \n    public class TransferAcceleration \n    { \n        /// <summary> \n        /// The main method initializes the client object and sets the \n        /// Amazon Simple Storage Service (Amazon S3) bucket name before \n        /// calling EnableAccelerationAsync. \n        /// </summary> \n        public static async Task Main() \n        { \n            var s3Client = new AmazonS3Client(); \n            const string bucketName = \"amzn-s3-demo-bucket\"; \n            await EnableAccelerationAsync(s3Client, bucketName); \n        } \n        /// <summary> \n        /// This method sets the configuration to enable transfer acceleration \n        /// for the bucket referred to in the bucketName parameter. \n        /// </summary> \n        /// <param name=\"client\">An Amazon S3 client used to enable the \n        /// acceleration on an Amazon S3 bucket.</param> \nBasics API Version 2006-03-01 2128Amazon Simple Storage Service API Reference\n        /// <param name=\"bucketName\">The name of the Amazon S3 bucket for which \n the \n        /// method will be enabling acceleration.</param> \n        private static async Task EnableAccelerationAsync(AmazonS3Client client, \n string bucketName) \n        { \n            try \n            { \n                var putRequest = new PutBucketAccelerateConfigurationRequest \n                { \n                    BucketName = bucketName, \n                    AccelerateConfiguration = new AccelerateConfiguration \n                    { \n                        Status = BucketAccelerateStatus.Enabled, \n                    }, \n                }; \n                await client.PutBucketAccelerateConfigurationAsync(putRequest); \n                var getRequest = new GetBucketAccelerateConfigurationRequest \n                { \n                    BucketName = bucketName, \n                }; \n                var response = await \n client.GetBucketAccelerateConfigurationAsync(getRequest); \n                Console.WriteLine($\"Acceleration state = '{response.Status}' \"); \n            } \n            catch (AmazonS3Exception ex) \n            { \n                Console.WriteLine($\"Error occurred. Message:'{ex.Message}' when \n setting transfer acceleration\"); \n            } \n        } \n    }\n\u2022For API details, see PutBucketAccelerateCon\ufb01guration in AWS SDK for .NET API Reference.\nBasics API Version 2006-03-01 2129Amazon Simple Storage Service API Reference\nCLI\nAWS CLI\nTo set the accelerate con\ufb01guration of a bucket\nThe following put-bucket-accelerate-configuration  example enables the accelerate \ncon\ufb01guration for the speci\ufb01ed bucket.\naws s3api put-bucket-accelerate-configuration \\ \n    --bucket my-bucket  \\ \n    --accelerate-configuration Status=Enabled\nThis command produces no output.\n\u2022For API details, see PutBucketAccelerateCon\ufb01guration in AWS CLI Command Reference.\nPowerShell\nTools for PowerShell\nExample 1: This command enables the transfer acceleration for the given S3 bucket.\n$statusVal = New-Object Amazon.S3.BucketAccelerateStatus('Enabled')\nWrite-S3BucketAccelerateConfiguration -BucketName 'amzn-s3-demo-bucket' -\nAccelerateConfiguration_Status $statusVal\n\u2022For API details, see PutBucketAccelerateCon\ufb01guration in AWS Tools for PowerShell Cmdlet \nReference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs.", "This topic also includes information about getting started and details \nabout previous SDK versions.\nUse PutBucketAcl  with an AWS SDK or CLI\nThe following code examples show how to use PutBucketAcl .\nAction examples are code excerpts from larger programs and must be run in context.", "You can see \nthis action in context in the following code example:\nBasics API Version 2006-03-01 2130Amazon Simple Storage Service API Reference\n\u2022Manage access control lists (ACLs)\n.NET\nAWS SDK for .NET\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n        /// <summary> \n        /// Creates an Amazon S3 bucket with an ACL to control access to the \n        /// bucket and the objects stored in it.", "\n        /// </summary> \n        /// <param name=\"client\">The initialized client object used to create \n        /// an Amazon S3 bucket, with an ACL applied to the bucket. \n        /// </param> \n        /// <param name=\"region\">The AWS Region where the bucket will be \n created.</param> \n        /// <param name=\"newBucketName\">The name of the bucket to create.</param> \n        /// <returns>A boolean value indicating success or failure.</returns> \n        public static async Task<bool> CreateBucketUseCannedACLAsync(IAmazonS3 \n client, S3Region region, string newBucketName) \n        { \n            try \n            { \n                // Create a new Amazon S3 bucket with Canned ACL. \n                var putBucketRequest = new PutBucketRequest() \n                { \n                    BucketName = newBucketName, \n                    BucketRegion = region, \n                    CannedACL = S3CannedACL.LogDeliveryWrite, \n                }; \n                PutBucketResponse putBucketResponse = await \n client.PutBucketAsync(putBucketRequest); \n                return putBucketResponse.HttpStatusCode == \n System.Net.HttpStatusCode.OK; \nBasics API Version 2006-03-01 2131Amazon Simple Storage Service API Reference\n            } \n            catch (AmazonS3Exception ex) \n            { \n                Console.WriteLine($\"Amazon S3 error: {ex.Message}\"); \n            } \n            return false; \n        }\n\u2022For API details, see PutBucketAcl in AWS SDK for .NET API Reference.\nC++\nSDK for C++\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nbool AwsDoc::S3::putBucketAcl(const Aws::String &bucketName, const Aws::String \n &ownerID, \n                              const Aws::String &granteePermission, \n                              const Aws::String &granteeType, const Aws::String \n &granteeID, \n                              const Aws::String &granteeEmailAddress, \n                              const Aws::String &granteeURI, const \n Aws::S3::S3ClientConfiguration &clientConfig) { \n    Aws::S3::S3Client s3Client(clientConfig); \n    Aws::S3::Model::Owner owner; \n    owner.SetID(ownerID); \n    Aws::S3::Model::Grantee grantee; \n    grantee.SetType(setGranteeType(granteeType)); \n    if (!granteeEmailAddress.empty()) { \n        grantee.SetEmailAddress(granteeEmailAddress); \n    } \nBasics API Version 2006-03-01 2132Amazon Simple Storage Service API Reference\n    if (!granteeID.empty()) { \n        grantee.SetID(granteeID); \n    } \n    if (!granteeURI.empty()) { \n        grantee.SetURI(granteeURI); \n    } \n    Aws::S3::Model::Grant grant; \n    grant.SetGrantee(grantee); \n    grant.SetPermission(setGranteePermission(granteePermission)); \n    Aws::Vector<Aws::S3::Model::Grant> grants; \n    grants.push_back(grant); \n    Aws::S3::Model::AccessControlPolicy acp; \n    acp.SetOwner(owner); \n    acp.SetGrants(grants); \n    Aws::S3::Model::PutBucketAclRequest request; \n    request.SetAccessControlPolicy(acp); \n    request.SetBucket(bucketName); \n    Aws::S3::Model::PutBucketAclOutcome outcome = \n            s3Client.PutBucketAcl(request); \n    if (!outcome.IsSuccess()) { \n        const Aws::S3::S3Error &error = outcome.GetError(); \n        std::cerr << \"Error: putBucketAcl: \" << error.GetExceptionName() \n                  << \" - \" << error.GetMessage() << std::endl; \n    } else { \n        std::cout << \"Successfully added an ACL to the bucket '\" << bucketName \n                  << \"'.\" << std::endl; \n    } \n    return outcome.IsSuccess();\n}\n//!", "Routine which converts a human-readable string to a built-in type \n enumeration.\n/*!", "\n \\param access: Human readable string.", "\nBasics API Version 2006-03-01 2133Amazon Simple Storage Service API Reference\n \\return Permission: A Permission enum.\n*/\nAws::S3::Model::Permission setGranteePermission(const Aws::String &access) { \n    if (access == \"FULL_CONTROL\") \n        return Aws::S3::Model::Permission::FULL_CONTROL; \n    if (access == \"WRITE\") \n        return Aws::S3::Model::Permission::WRITE; \n    if (access == \"READ\") \n        return Aws::S3::Model::Permission::READ; \n    if (access == \"WRITE_ACP\") \n        return Aws::S3::Model::Permission::WRITE_ACP; \n    if (access == \"READ_ACP\") \n        return Aws::S3::Model::Permission::READ_ACP; \n    return Aws::S3::Model::Permission::NOT_SET;\n}\n//!", "Routine which converts a human-readable string to a built-in type \n enumeration.\n/*! \n \\param type: Human readable string.", "\n \\return Type: Type enumeration\n*/\nAws::S3::Model::Type setGranteeType(const Aws::String &type) { \n    if (type == \"Amazon customer by email\") \n        return Aws::S3::Model::Type::AmazonCustomerByEmail; \n    if (type == \"Canonical user\") \n        return Aws::S3::Model::Type::CanonicalUser; \n    if (type == \"Group\") \n        return Aws::S3::Model::Type::Group; \n    return Aws::S3::Model::Type::NOT_SET;\n}\n\u2022For API details, see PutBucketAcl in AWS SDK for C++ API Reference.\nCLI\nAWS CLI\nThis example grants full control  to two AWS users (user1@example.com and\nuser2@example.com) and read permission to everyone:\nBasics API Version 2006-03-01 2134Amazon Simple Storage Service API Reference\naws s3api put-bucket-acl --bucket MyBucket  --grant-full-\ncontrol emailaddress=user1@example.com,emailaddress=user2@example.com  --grant-\nread uri=http://acs.amazonaws.com/groups/global/AllUsers\nSee http://docs.aws.amazon.com/AmazonS3/latest/API/RESTBucketPUTacl.html for \ndetails on custom ACLs (the s3api ACL commands, such as put-bucket-acl , use the same \nshorthand argument notation).\n\u2022For API details, see PutBucketAcl in AWS CLI Command Reference.\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nimport software.amazon.awssdk.regions.Region;\nimport software.amazon.awssdk.services.s3.S3Client;\nimport software.amazon.awssdk.services.s3.model.AccessControlPolicy;\nimport software.amazon.awssdk.services.s3.model.Grant;\nimport software.amazon.awssdk.services.s3.model.Permission;\nimport software.amazon.awssdk.services.s3.model.PutBucketAclRequest;\nimport software.amazon.awssdk.services.s3.model.S3Exception;\nimport software.amazon.awssdk.services.s3.model.Type;\nimport java.util.ArrayList;\nimport java.util.List;\n/** \n * Before running this Java V2 code example, set up your development \n * environment, including your credentials. \n * <p> \n * For more information, see the following documentation topic: \n * <p> \n * https://docs.aws.amazon.com/sdk-for-java/latest/developer-guide/get-\nstarted.html \nBasics API Version 2006-03-01 2135Amazon Simple Storage Service API Reference\n */\npublic class SetAcl { \n    public static void main(String[] args) { \n        final String usage = \"\"\" \n            Usage: \n              <bucketName> <id>\\s \n            Where: \n              bucketName - The Amazon S3 bucket to grant permissions on.\\s \n              id - The ID of the owner of this bucket (you can get this value \n from the AWS Management Console). \n            \"\"\"; \n        if (args.length != 2) { \n            System.out.println(usage); \n            return; \n        } \n        String bucketName = args[0]; \n        String id = args[1]; \n        System.out.format(\"Setting access \\n\"); \n        System.out.println(\" in bucket: \" + bucketName); \n        Region region = Region.US_EAST_1; \n        S3Client s3 = S3Client.builder() \n            .region(region) \n            .build(); \n        setBucketAcl(s3, bucketName, id); \n        System.out.println(\"Done!\"); \n        s3.close(); \n    } \n    /** \n     * Sets the Access Control List (ACL) for an Amazon S3 bucket. \n     * \n     * @param s3 the S3Client instance to be used for the operation \n     * @param bucketName the name of the S3 bucket to set the ACL for \n     * @param id the ID of the AWS user or account that will be granted full \n control of the bucket \n     * @throws S3Exception if an error occurs while setting the bucket ACL \n     */ \n    public static void setBucketAcl(S3Client s3, String bucketName, String id) { \n        try { \nBasics API Version 2006-03-01 2136Amazon Simple Storage Service API Reference\n            Grant ownerGrant = Grant.builder() \n                .grantee(builder -> builder.id(id) \n                    .type(Type.CANONICAL_USER)) \n                .permission(Permission.FULL_CONTROL) \n                .build(); \n            List<Grant> grantList2 = new ArrayList<>(); \n            grantList2.add(ownerGrant); \n            AccessControlPolicy acl = AccessControlPolicy.builder() \n                .owner(builder -> builder.id(id)) \n                .grants(grantList2) \n                .build(); \n            PutBucketAclRequest putAclReq = PutBucketAclRequest.builder() \n                .bucket(bucketName) \n                .accessControlPolicy(acl) \n                .build(); \n            s3.putBucketAcl(putAclReq); \n        } catch (S3Exception e) { \n            e.printStackTrace(); \n            System.exit(1); \n        } \n    }\n}\n\u2022For API details, see PutBucketAcl in AWS SDK for Java 2.x API Reference.\nJavaScript\nSDK for JavaScript (v3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nPut the bucket ACL.\nBasics API Version 2006-03-01 2137Amazon Simple Storage Service API Reference\nimport { \n  PutBucketAclCommand, \n  S3Client, \n  S3ServiceException,\n} from \"@aws-sdk/client-s3\";\n/** \n * Grant read access to a user using their canonical AWS account ID. \n * \n * Most Amazon S3 use cases don't require the use of access control lists (ACLs).", "\n * We recommend that you disable ACLs, except in unusual circumstances where \n * you need to control access for each object individually. Consider a policy \n instead.", "\n * For more information see https://docs.aws.amazon.com/AmazonS3/latest/\nuserguide/bucket-policies.html. \n * @param {{ bucketName: string, granteeCanonicalUserId: string, \n ownerCanonicalUserId }} \n */\nexport const main = async ({ \n  bucketName, \n  granteeCanonicalUserId, \n  ownerCanonicalUserId,\n}) => { \n  const client = new S3Client({}); \n  const command = new PutBucketAclCommand({ \n    Bucket: bucketName, \n    AccessControlPolicy: { \n      Grants: [ \n        { \n          Grantee: { \n            // The canonical ID of the user.", "This ID is an obfuscated form of \n your AWS account number.", "\n            // It's unique to Amazon S3 and can't be found elsewhere. \n            // For more information, see https://docs.aws.amazon.com/AmazonS3/\nlatest/userguide/finding-canonical-user-id.html. \n            ID: granteeCanonicalUserId, \n            Type: \"CanonicalUser\", \n          }, \n          // One of FULL_CONTROL | READ | WRITE | READ_ACP | WRITE_ACP \n          // https://docs.aws.amazon.com/AmazonS3/latest/API/\nAPI_Grant.html#AmazonS3-Type-Grant-Permission \n          Permission: \"READ\", \n        }, \nBasics API Version 2006-03-01 2138Amazon Simple Storage Service API Reference\n      ], \n      Owner: { \n        ID: ownerCanonicalUserId, \n      }, \n    }, \n  }); \n  try { \n    await client.send(command); \n    console.log(`Granted READ access to ${bucketName}`); \n  } catch (caught) { \n    if ( \n      caught instanceof S3ServiceException && \n      caught.name === \"NoSuchBucket\" \n    ) { \n      console.error( \n        `Error from S3 while setting ACL for bucket ${bucketName}. The bucket \n doesn't exist.`, \n      ); \n    } else if (caught instanceof S3ServiceException) { \n      console.error( \n        `Error from S3 while setting ACL for bucket ${bucketName}.", "\n ${caught.name}: ${caught.message}`, \n      ); \n    } else { \n      throw caught; \n    } \n  }\n};\n\u2022For more information, see AWS SDK for JavaScript Developer Guide.\n\u2022For API details, see PutBucketAcl in AWS SDK for JavaScript API Reference.\nBasics API Version 2006-03-01 2139Amazon Simple Storage Service API Reference\nKotlin\nSDK for Kotlin\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nsuspend fun setBucketAcl( \n    bucketName: String, \n    idVal: String,\n) { \n    val myGrant = \n        Grantee { \n            id = idVal \n            type = Type.CanonicalUser \n        } \n    val ownerGrant = \n        Grant { \n            grantee = myGrant \n            permission = Permission.FullControl \n        } \n    val grantList = mutableListOf<Grant>() \n    grantList.add(ownerGrant) \n    val ownerOb = \n        Owner { \n            id = idVal \n        } \n    val acl = \n        AccessControlPolicy { \n            owner = ownerOb \n            grants = grantList \n        } \n    val request = \n        PutBucketAclRequest { \nBasics API Version 2006-03-01 2140Amazon Simple Storage Service API Reference\n            bucket = bucketName \n            accessControlPolicy = acl \n        } \n    S3Client { region = \"us-east-1\" }.use { s3 -> \n        s3.putBucketAcl(request) \n        println(\"An ACL was successfully set on $bucketName\") \n    }\n}\n\u2022For API details, see PutBucketAcl in AWS SDK for Kotlin API reference.\nPython\nSDK for Python (Boto3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nclass BucketWrapper: \n    \"\"\"Encapsulates S3 bucket actions.\"\"\" \n    def __init__(self, bucket): \n        \"\"\" \n        :param bucket: A Boto3 Bucket resource. This is a high-level resource in \n Boto3 \n                       that wraps bucket actions in a class-like structure.", "\n        \"\"\" \n        self.bucket = bucket \n        self.name = bucket.name \n    def grant_log_delivery_access(self): \n        \"\"\" \n        Grant the AWS Log Delivery group write access to the bucket so that \n        Amazon S3 can deliver access logs to the bucket. This is the only \n recommended \n        use of an S3 bucket ACL.", "\nBasics API Version 2006-03-01 2141Amazon Simple Storage Service API Reference\n        \"\"\" \n        try: \n            acl = self.bucket.Acl() \n            # Putting an ACL overwrites the existing ACL.", "If you want to preserve \n            # existing grants, append new grants to the list of existing grants.", "\n            grants = acl.grants if acl.grants else [] \n            grants.append( \n                { \n                    \"Grantee\": { \n                        \"Type\": \"Group\", \n                        \"URI\": \"http://acs.amazonaws.com/groups/s3/LogDelivery\", \n                    }, \n                    \"Permission\": \"WRITE\", \n                } \n            ) \n            acl.put(AccessControlPolicy={\"Grants\": grants, \"Owner\": acl.owner}) \n            logger.info(\"Granted log delivery access to bucket '%s'\", \n self.bucket.name) \n        except ClientError: \n            logger.exception(\"Couldn't add ACL to bucket '%s'.\", \n self.bucket.name) \n            raise\n\u2022For API details, see PutBucketAcl in AWS SDK for Python (Boto3) API Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs.", "This topic also includes information about getting started and details \nabout previous SDK versions.\nUse PutBucketCors  with an AWS SDK or CLI\nThe following code examples show how to use PutBucketCors .\nBasics API Version 2006-03-01 2142Amazon Simple Storage Service API Reference\n.NET\nAWS SDK for .NET\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n        /// <summary> \n        /// Add CORS configuration to the Amazon S3 bucket. \n        /// </summary> \n        /// <param name=\"client\">The initialized Amazon S3 client object used \n        /// to apply the CORS configuration to an Amazon S3 bucket.</param> \n        /// <param name=\"configuration\">The CORS configuration to apply.</param> \n        private static async Task PutCORSConfigurationAsync(AmazonS3Client \n client, CORSConfiguration configuration) \n        { \n            PutCORSConfigurationRequest request = new \n PutCORSConfigurationRequest() \n            { \n                BucketName = BucketName, \n                Configuration = configuration, \n            }; \n            _ = await client.PutCORSConfigurationAsync(request); \n        }\n\u2022For API details, see PutBucketCors in AWS SDK for .NET API Reference.\nCLI\nAWS CLI\nThe following example enables PUT, POST , and DELETE requests from www.example.com, \nand enables GET requests from any domain:\nBasics API Version 2006-03-01 2143Amazon Simple Storage Service API Reference\naws s3api put-bucket-cors --bucket MyBucket  --cors-configuration file://cors.json\ncors.json:\n{\n  \"CORSRules\": [\n    {\n      \"AllowedOrigins\": [\"http://www.example.com\"], \n      \"AllowedHeaders\": [\"*\"], \n      \"AllowedMethods\": [\"PUT\", \"POST\", \"DELETE\"], \n      \"MaxAgeSeconds\": 3000,\n      \"ExposeHeaders\": [\"x-amz-server-side-encryption\"] \n     },\n    {\n      \"AllowedOrigins\": [\"*\"], \n      \"AllowedHeaders\": [\"Authorization\"], \n      \"AllowedMethods\": [\"GET\"], \n      \"MaxAgeSeconds\": 3000\n    }\n  ]\n}\n\u2022For API details, see PutBucketCors in AWS CLI Command Reference.\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nimport software.amazon.awssdk.regions.Region;\nimport software.amazon.awssdk.services.s3.S3Client;\nimport java.util.ArrayList;\nimport java.util.List;\nimport software.amazon.awssdk.services.s3.model.GetBucketCorsRequest;\nBasics API Version 2006-03-01 2144Amazon Simple Storage Service API Reference\nimport software.amazon.awssdk.services.s3.model.GetBucketCorsResponse;\nimport software.amazon.awssdk.services.s3.model.DeleteBucketCorsRequest;\nimport software.amazon.awssdk.services.s3.model.S3Exception;\nimport software.amazon.awssdk.services.s3.model.CORSRule;\nimport software.amazon.awssdk.services.s3.model.CORSConfiguration;\nimport software.amazon.awssdk.services.s3.model.PutBucketCorsRequest;\n/** \n * Before running this Java V2 code example, set up your development \n * environment, including your credentials. \n * <p> \n * For more information, see the following documentation topic: \n * <p> \n * https://docs.aws.amazon.com/sdk-for-java/latest/developer-guide/get-\nstarted.html \n */\npublic class S3Cors { \n    public static void main(String[] args) { \n        final String usage = \"\"\" \n            Usage: \n                <bucketName> <accountId>\\s \n            Where: \n                bucketName - The Amazon S3 bucket to upload an object into. \n                accountId - The id of the account that owns the Amazon S3 bucket. \n            \"\"\"; \n        if (args.length != 2) { \n            System.out.println(usage); \n            System.exit(1); \n        } \n        String bucketName = args[0]; \n        String accountId = args[1]; \n        Region region = Region.US_EAST_1; \n        S3Client s3 = S3Client.builder() \n            .region(region) \n            .build(); \n        setCorsInformation(s3, bucketName, accountId); \n        getBucketCorsInformation(s3, bucketName, accountId); \n        deleteBucketCorsInformation(s3, bucketName, accountId); \n        s3.close(); \nBasics API Version 2006-03-01 2145Amazon Simple Storage Service API Reference\n    } \n    /** \n     * Deletes the CORS (Cross-Origin Resource Sharing) configuration for an \n Amazon S3 bucket. \n     * \n     * @param s3            the {@link S3Client} instance used to interact with \n the Amazon S3 service \n     * @param bucketName    the name of the Amazon S3 bucket for which the CORS \n configuration should be deleted \n     * @param accountId     the expected AWS account ID of the bucket owner \n     * \n     * @throws S3Exception if an error occurs while deleting the CORS \n configuration for the bucket \n     */ \n    public static void deleteBucketCorsInformation(S3Client s3, String \n bucketName, String accountId) { \n        try { \n            DeleteBucketCorsRequest bucketCorsRequest = \n DeleteBucketCorsRequest.builder() \n                .bucket(bucketName) \n                .expectedBucketOwner(accountId) \n                .build(); \n            s3.deleteBucketCors(bucketCorsRequest); \n        } catch (S3Exception e) { \n            System.err.println(e.awsErrorDetails().errorMessage()); \n            System.exit(1); \n        } \n    } \n    /** \n     * Retrieves the CORS (Cross-Origin Resource Sharing) configuration for the \n specified S3 bucket. \n     * \n     * @param s3 the S3Client instance to use for the operation \n     * @param bucketName the name of the S3 bucket to retrieve the CORS \n configuration for \n     * @param accountId the expected bucket owner's account ID \n     * \n     * @throws S3Exception if there is an error retrieving the CORS configuration \n     */ \nBasics API Version 2006-03-01 2146Amazon Simple Storage Service API Reference\n    public static void getBucketCorsInformation(S3Client s3, String bucketName, \n String accountId) { \n        try { \n            GetBucketCorsRequest bucketCorsRequest = \n GetBucketCorsRequest.builder() \n                .bucket(bucketName) \n                .expectedBucketOwner(accountId) \n                .build(); \n            GetBucketCorsResponse corsResponse = \n s3.getBucketCors(bucketCorsRequest); \n            List<CORSRule> corsRules = corsResponse.corsRules(); \n            for (CORSRule rule : corsRules) { \n                System.out.println(\"allowOrigins: \" + rule.allowedOrigins()); \n                System.out.println(\"AllowedMethod: \" + rule.allowedMethods()); \n            } \n        } catch (S3Exception e) { \n            System.err.println(e.awsErrorDetails().errorMessage()); \n            System.exit(1); \n        } \n    } \n    /** \n     * Sets the Cross-Origin Resource Sharing (CORS) rules for an Amazon S3 \n bucket. \n     * \n     * @param s3 The S3Client object used to interact with the Amazon S3 service. \n     * @param bucketName The name of the S3 bucket to set the CORS rules for.", "\n     * @param accountId The AWS account ID of the bucket owner.", "\n     */ \n    public static void setCorsInformation(S3Client s3, String bucketName, String \n accountId) { \n        List<String> allowMethods = new ArrayList<>(); \n        allowMethods.add(\"PUT\"); \n        allowMethods.add(\"POST\"); \n        allowMethods.add(\"DELETE\"); \n        List<String> allowOrigins = new ArrayList<>(); \n        allowOrigins.add(\"http://example.com\"); \n        try { \n            // Define CORS rules. \n            CORSRule corsRule = CORSRule.builder() \nBasics API Version 2006-03-01 2147Amazon Simple Storage Service API Reference\n                .allowedMethods(allowMethods) \n                .allowedOrigins(allowOrigins) \n                .build(); \n            List<CORSRule> corsRules = new ArrayList<>(); \n            corsRules.add(corsRule); \n            CORSConfiguration configuration = CORSConfiguration.builder() \n                .corsRules(corsRules) \n                .build(); \n            PutBucketCorsRequest putBucketCorsRequest = \n PutBucketCorsRequest.builder() \n                .bucket(bucketName) \n                .corsConfiguration(configuration) \n                .expectedBucketOwner(accountId) \n                .build(); \n            s3.putBucketCors(putBucketCorsRequest); \n        } catch (S3Exception e) { \n            System.err.println(e.awsErrorDetails().errorMessage()); \n            System.exit(1); \n        } \n    }\n}\n\u2022For API details, see PutBucketCors in AWS SDK for Java 2.x API Reference.\nJavaScript\nSDK for JavaScript (v3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nAdd a CORS rule.\nimport { \nBasics API Version 2006-03-01 2148Amazon Simple Storage Service API Reference\n  PutBucketCorsCommand, \n  S3Client, \n  S3ServiceException,\n} from \"@aws-sdk/client-s3\";\n/** \n * Allows cross-origin requests to an S3 bucket by setting the CORS \n configuration. \n * @param {{ bucketName: string }} \n */\nexport const main = async ({ bucketName }) => { \n  const client = new S3Client({}); \n  try { \n    await client.send( \n      new PutBucketCorsCommand({ \n        Bucket: bucketName, \n        CORSConfiguration: { \n          CORSRules: [ \n            { \n              // Allow all headers to be sent to this bucket.", "\n              AllowedHeaders: [\"*\"], \n              // Allow only GET and PUT methods to be sent to this bucket. \n              AllowedMethods: [\"GET\", \"PUT\"], \n              // Allow only requests from the specified origin. \n              AllowedOrigins: [\"https://www.example.com\"], \n              // Allow the entity tag (ETag) header to be returned in the \n response. The ETag header \n              // The entity tag represents a specific version of the object. The \n ETag reflects \n              // changes only to the contents of an object, not its metadata. \n              ExposeHeaders: [\"ETag\"], \n              // How long the requesting browser should cache the preflight \n response. After \n              // this time, the preflight request will have to be made again.", "\n              MaxAgeSeconds: 3600, \n            }, \n          ], \n        }, \n      }), \n    ); \n    console.log(`Successfully set CORS rules for bucket: ${bucketName}`); \n  } catch (caught) { \n    if ( \nBasics API Version 2006-03-01 2149Amazon Simple Storage Service API Reference\n      caught instanceof S3ServiceException && \n      caught.name === \"NoSuchBucket\" \n    ) { \n      console.error( \n        `Error from S3 while setting CORS rules for ${bucketName}. The bucket \n doesn't exist.`, \n      ); \n    } else if (caught instanceof S3ServiceException) { \n      console.error( \n        `Error from S3 while setting CORS rules for ${bucketName}.", "\n ${caught.name}: ${caught.message}`, \n      ); \n    } else { \n      throw caught; \n    } \n  }\n};\n\u2022For more information, see AWS SDK for JavaScript Developer Guide.\n\u2022For API details, see PutBucketCors in AWS SDK for JavaScript API Reference.\nPython\nSDK for Python (Boto3)\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nclass BucketWrapper: \n    \"\"\"Encapsulates S3 bucket actions.\"\"\" \n    def __init__(self, bucket): \n        \"\"\" \n        :param bucket: A Boto3 Bucket resource. This is a high-level resource in \n Boto3 \n                       that wraps bucket actions in a class-like structure.", "\n        \"\"\" \nBasics API Version 2006-03-01 2150Amazon Simple Storage Service API Reference\n        self.bucket = bucket \n        self.name = bucket.name \n    def put_cors(self, cors_rules): \n        \"\"\" \n        Apply CORS rules to the bucket.", "CORS rules specify the HTTP actions that \n are \n        allowed from other domains. \n        :param cors_rules: The CORS rules to apply.", "\n        \"\"\" \n        try: \n            self.bucket.Cors().put(CORSConfiguration={\"CORSRules\": cors_rules}) \n            logger.info( \n                \"Put CORS rules %s for bucket '%s'.\", cors_rules, \n self.bucket.name \n            ) \n        except ClientError: \n            logger.exception(\"Couldn't put CORS rules for bucket %s.\", \n self.bucket.name) \n            raise\n\u2022For API details, see PutBucketCors in AWS SDK for Python (Boto3) API Reference.\nRuby\nSDK for Ruby\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nrequire 'aws-sdk-s3'\n# Wraps Amazon S3 bucket CORS configuration.\nclass BucketCorsWrapper \n  attr_reader :bucket_cors \nBasics API Version 2006-03-01 2151Amazon Simple Storage Service API Reference\n  # @param bucket_cors [Aws::S3::BucketCors] A bucket CORS object configured with \n an existing bucket.", "\n  def initialize(bucket_cors) \n    @bucket_cors = bucket_cors \n  end \n  # Sets CORS rules on a bucket.", "\n  # \n  # @param allowed_methods [Array<String>] The types of HTTP requests to allow. \n  # @param allowed_origins [Array<String>] The origins to allow.", "\n  # @returns [Boolean] True if the CORS rules were set; otherwise, false.", "\n  def set_cors(allowed_methods, allowed_origins) \n    @bucket_cors.put( \n      cors_configuration: { \n        cors_rules: [ \n          { \n            allowed_methods: allowed_methods, \n            allowed_origins: allowed_origins, \n            allowed_headers: %w[*], \n            max_age_seconds: 3600 \n          } \n        ] \n      } \n    ) \n    true \n  rescue Aws::Errors::ServiceError => e \n    puts \"Couldn't set CORS rules for #{@bucket_cors.bucket.name}.", "Here's why: \n #{e.message}\" \n    false \n  end\nend\n\u2022For API details, see PutBucketCors in AWS SDK for Ruby API Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs.", "This topic also includes information about getting started and details \nabout previous SDK versions.\nBasics API Version 2006-03-01 2152Amazon Simple Storage Service API Reference\nUse PutBucketEncryption  with an AWS SDK or CLI\nThe following code examples show how to use PutBucketEncryption .\n.NET\nAWS SDK for .NET\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n    /// <summary> \n    /// Set the bucket server side encryption to use AWSKMS with a customer-\nmanaged key id. \n    /// </summary> \n    /// <param name=\"bucketName\">Name of the bucket.</param> \n    /// <param name=\"kmsKeyId\">The Id of the KMS Key.</param> \n    /// <returns>True if successful.</returns> \n    public static async Task<bool> SetBucketServerSideEncryption(string \n bucketName, string kmsKeyId) \n    { \n        var serverSideEncryptionByDefault = new ServerSideEncryptionConfiguration \n        { \n            ServerSideEncryptionRules = new List<ServerSideEncryptionRule> \n            { \n                new ServerSideEncryptionRule \n                { \n                    ServerSideEncryptionByDefault = new \n ServerSideEncryptionByDefault \n                    { \n                        ServerSideEncryptionAlgorithm = \n ServerSideEncryptionMethod.AWSKMS, \n                        ServerSideEncryptionKeyManagementServiceKeyId = kmsKeyId \n                    } \n                } \n            } \n        }; \n        try \n        { \nBasics API Version 2006-03-01 2153Amazon Simple Storage Service API Reference\n            var encryptionResponse = await _s3Client.PutBucketEncryptionAsync(new \n PutBucketEncryptionRequest \n            { \n                BucketName = bucketName, \n                ServerSideEncryptionConfiguration = \n serverSideEncryptionByDefault, \n            }); \n             \n            return encryptionResponse.HttpStatusCode == HttpStatusCode.OK; \n        } \n        catch (AmazonS3Exception ex) \n        { \n            Console.WriteLine(ex.ErrorCode == \"AccessDenied\" \n                ? $\"This account does not have permission to set encryption on \n {bucketName}, please try again.\" \n                : $\"Unable to set bucket encryption for bucket {bucketName}, \n {ex.Message}\"); \n        } \n        return false; \n    }\n\u2022For API details, see PutBucketEncryption in AWS SDK for .NET API Reference.\nCLI\nAWS CLI\nTo con\ufb01gure server-side encryption for a bucket\nThe following put-bucket-encryption  example sets AES256 encryption as the default \nfor the speci\ufb01ed bucket.\naws s3api put-bucket-encryption \\ \n    --bucket my-bucket  \\ \n    --server-side-encryption-configuration ' {\"Rules\": \n [{\"ApplyServerSideEncryptionByDefault\": {\"SSEAlgorithm\": \"AES256\"}}]} '\nThis command produces no output.\n\u2022For API details, see PutBucketEncryption in AWS CLI Command Reference.\nBasics API Version 2006-03-01 2154Amazon Simple Storage Service API Reference\nPowerShell\nTools for PowerShell\nExample 1: This command enables default AES256 server side encryption with Amazon \nS3 Managed Keys(SSE-S3) on the given bucket.\n$Encryptionconfig = @{ServerSideEncryptionByDefault = \n @{ServerSideEncryptionAlgorithm = \"AES256\"}}\nSet-S3BucketEncryption -BucketName 'amzn-s3-demo-bucket' -\nServerSideEncryptionConfiguration_ServerSideEncryptionRule $Encryptionconfig\n\u2022For API details, see PutBucketEncryption in AWS Tools for PowerShell Cmdlet Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nUse PutBucketLifecycleConfiguration  with an AWS SDK or CLI\nThe following code examples show how to use PutBucketLifecycleConfiguration .\nAction examples are code excerpts from larger programs and must be run in context.", "You can see \nthis action in context in the following code examples:\n\u2022Delete incomplete multipart uploads\n\u2022Work with versioned objects\n.NET\nAWS SDK for .NET\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n        /// <summary> \nBasics API Version 2006-03-01 2155Amazon Simple Storage Service API Reference\n        /// Adds lifecycle configuration information to the S3 bucket named in \n        /// the bucketName parameter. \n        /// </summary> \n        /// <param name=\"client\">The S3 client used to call the \n        /// PutLifecycleConfigurationAsync method.</param> \n        /// <param name=\"bucketName\">A string representing the S3 bucket to \n        /// which configuration information will be added.</param> \n        /// <param name=\"configuration\">A LifecycleConfiguration object that \n        /// will be applied to the S3 bucket.</param> \n        public static async Task AddExampleLifecycleConfigAsync(IAmazonS3 client, \n string bucketName, LifecycleConfiguration configuration) \n        { \n            var request = new PutLifecycleConfigurationRequest() \n            { \n                BucketName = bucketName, \n                Configuration = configuration, \n            }; \n            var response = await client.PutLifecycleConfigurationAsync(request); \n        }\n\u2022For API details, see PutBucketLifecycleCon\ufb01guration in AWS SDK for .NET API Reference.\nCLI\nAWS CLI\nThe following command applies a lifecycle con\ufb01guration to a bucket named my-bucket :\naws s3api put-bucket-lifecycle-configuration --bucket my-bucket  --lifecycle-\nconfiguration   file://lifecycle.json\nThe \ufb01le lifecycle.json  is a JSON document in the current folder that speci\ufb01es two rules:\n{ \n    \"Rules\": [ \n        { \n            \"ID\": \"Move rotated logs to Glacier\", \n            \"Prefix\": \"rotated/\", \n            \"Status\": \"Enabled\", \n            \"Transitions\": [ \nBasics API Version 2006-03-01 2156Amazon Simple Storage Service API Reference\n                { \n                    \"Date\": \"2015-11-10T00:00:00.000Z\", \n                    \"StorageClass\": \"GLACIER\" \n                } \n            ] \n        }, \n        { \n            \"Status\": \"Enabled\", \n            \"Prefix\": \"\", \n            \"NoncurrentVersionTransitions\": [ \n                { \n                    \"NoncurrentDays\": 2, \n                    \"StorageClass\": \"GLACIER\" \n                } \n            ], \n            \"ID\": \"Move old versions to Glacier\" \n        } \n    ]\n}\nThe \ufb01rst rule moves \ufb01les with the pre\ufb01x rotated  to Glacier on the speci\ufb01ed date.", "The \nsecond rule moves old object versions to Glacier when they are no longer current.", "For \ninformation on acceptable timestamp formats, see Specifying Parameter Values in the AWS \nCLI User Guide .\n\u2022For API details, see PutBucketLifecycleCon\ufb01guration in AWS CLI Command Reference.\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nimport software.amazon.awssdk.regions.Region;\nimport software.amazon.awssdk.services.s3.S3Client;\nimport software.amazon.awssdk.services.s3.model.LifecycleRuleFilter;\nBasics API Version 2006-03-01 2157Amazon Simple Storage Service API Reference\nimport software.amazon.awssdk.services.s3.model.Transition;\nimport \n software.amazon.awssdk.services.s3.model.GetBucketLifecycleConfigurationRequest;\nimport \n software.amazon.awssdk.services.s3.model.GetBucketLifecycleConfigurationResponse;\nimport software.amazon.awssdk.services.s3.model.DeleteBucketLifecycleRequest;\nimport software.amazon.awssdk.services.s3.model.TransitionStorageClass;\nimport software.amazon.awssdk.services.s3.model.LifecycleRule;\nimport software.amazon.awssdk.services.s3.model.ExpirationStatus;\nimport software.amazon.awssdk.services.s3.model.BucketLifecycleConfiguration;\nimport \n software.amazon.awssdk.services.s3.model.PutBucketLifecycleConfigurationRequest;\nimport software.amazon.awssdk.services.s3.model.S3Exception;\nimport java.util.ArrayList;\nimport java.util.List;\n/** \n * Before running this Java V2 code example, set up your development \n * environment, including your credentials. \n * <p> \n * For more information, see the following documentation topic: \n * <p> \n * https://docs.aws.amazon.com/sdk-for-java/latest/developer-guide/get-\nstarted.html \n */\npublic class LifecycleConfiguration { \n    public static void main(String[] args) { \n        final String usage = \"\"\" \n            Usage: \n              <bucketName> <accountId>\\s \n            Where: \n              bucketName - The Amazon Simple Storage Service (Amazon S3) bucket \n to upload an object into. \n              accountId - The id of the account that owns the Amazon S3 bucket. \n            \"\"\"; \n        if (args.length != 2) { \n            System.out.println(usage); \n            System.exit(1); \n        } \nBasics API Version 2006-03-01 2158Amazon Simple Storage Service API Reference\n        String bucketName = args[0]; \n        String accountId = args[1]; \n        Region region = Region.US_EAST_1; \n        S3Client s3 = S3Client.builder() \n            .region(region) \n            .build(); \n        setLifecycleConfig(s3, bucketName, accountId); \n        getLifecycleConfig(s3, bucketName, accountId); \n        deleteLifecycleConfig(s3, bucketName, accountId); \n        System.out.println(\"You have successfully created, updated, and deleted a \n Lifecycle configuration\"); \n        s3.close(); \n    } \n    /** \n     * Sets the lifecycle configuration for an Amazon S3 bucket. \n     * \n     * @param s3           The Amazon S3 client to use for the operation. \n     * @param bucketName   The name of the Amazon S3 bucket. \n     * @param accountId    The expected owner of the Amazon S3 bucket. \n     * \n     * @throws S3Exception if there is an error setting the lifecycle \n configuration. \n     */ \n    public static void setLifecycleConfig(S3Client s3, String bucketName, String \n accountId) { \n        try { \n            // Create a rule to archive objects with the \"glacierobjects/\" prefix \n to Amazon \n            // S3 Glacier.", "\n            LifecycleRuleFilter ruleFilter = LifecycleRuleFilter.builder() \n                .prefix(\"glacierobjects/\") \n                .build(); \n            Transition transition = Transition.builder() \n                .storageClass(TransitionStorageClass.GLACIER) \n                .days(0) \n                .build(); \n            LifecycleRule rule1 = LifecycleRule.builder() \n                .id(\"Archive immediately rule\") \n                .filter(ruleFilter) \n                .transitions(transition) \nBasics API Version 2006-03-01 2159Amazon Simple Storage Service API Reference\n                .status(ExpirationStatus.ENABLED) \n                .build(); \n            // Create a second rule. \n            Transition transition2 = Transition.builder() \n                .storageClass(TransitionStorageClass.GLACIER) \n                .days(0) \n                .build(); \n            List<Transition> transitionList = new ArrayList<>(); \n            transitionList.add(transition2); \n            LifecycleRuleFilter ruleFilter2 = LifecycleRuleFilter.builder() \n                .prefix(\"glacierobjects/\") \n                .build(); \n            LifecycleRule rule2 = LifecycleRule.builder() \n                .id(\"Archive and then delete rule\") \n                .filter(ruleFilter2) \n                .transitions(transitionList) \n                .status(ExpirationStatus.ENABLED) \n                .build(); \n            // Add the LifecycleRule objects to an ArrayList.", "\n            ArrayList<LifecycleRule> ruleList = new ArrayList<>(); \n            ruleList.add(rule1); \n            ruleList.add(rule2); \n            BucketLifecycleConfiguration lifecycleConfiguration = \n BucketLifecycleConfiguration.builder() \n                .rules(ruleList) \n                .build(); \n            PutBucketLifecycleConfigurationRequest \n putBucketLifecycleConfigurationRequest = PutBucketLifecycleConfigurationRequest \n                .builder() \n                .bucket(bucketName) \n                .lifecycleConfiguration(lifecycleConfiguration) \n                .expectedBucketOwner(accountId) \n                .build(); \n            \n s3.putBucketLifecycleConfiguration(putBucketLifecycleConfigurationRequest); \nBasics API Version 2006-03-01 2160Amazon Simple Storage Service API Reference\n        } catch (S3Exception e) { \n            System.err.println(e.awsErrorDetails().errorMessage()); \n            System.exit(1); \n        } \n    } \n    /** \n     * Retrieves the lifecycle configuration for an Amazon S3 bucket and adds a \n new lifecycle rule to it. \n     * \n     * @param s3 the S3Client instance used to interact with Amazon S3 \n     * @param bucketName the name of the Amazon S3 bucket \n     * @param accountId the expected owner of the Amazon S3 bucket \n     */ \n    public static void getLifecycleConfig(S3Client s3, String bucketName, String \n accountId) { \n        try { \n            GetBucketLifecycleConfigurationRequest \n getBucketLifecycleConfigurationRequest = GetBucketLifecycleConfigurationRequest \n                .builder() \n                .bucket(bucketName) \n                .expectedBucketOwner(accountId) \n                .build(); \n            GetBucketLifecycleConfigurationResponse response = s3 \n                \n .getBucketLifecycleConfiguration(getBucketLifecycleConfigurationRequest); \n            List<LifecycleRule> newList = new ArrayList<>(); \n            List<LifecycleRule> rules = response.rules(); \n            for (LifecycleRule rule : rules) { \n                newList.add(rule); \n            } \n            // Add a new rule with both a prefix predicate and a tag predicate.", "\n            LifecycleRuleFilter ruleFilter = LifecycleRuleFilter.builder() \n                .prefix(\"YearlyDocuments/\") \n                .build(); \n            Transition transition = Transition.builder() \n                .storageClass(TransitionStorageClass.GLACIER) \n                .days(3650) \n                .build(); \n            LifecycleRule rule1 = LifecycleRule.builder() \nBasics API Version 2006-03-01 2161Amazon Simple Storage Service API Reference\n                .id(\"NewRule\") \n                .filter(ruleFilter) \n                .transitions(transition) \n                .status(ExpirationStatus.ENABLED) \n                .build(); \n            // Add the new rule to the list.", "\n            newList.add(rule1); \n            BucketLifecycleConfiguration lifecycleConfiguration = \n BucketLifecycleConfiguration.builder() \n                .rules(newList) \n                .build(); \n            PutBucketLifecycleConfigurationRequest \n putBucketLifecycleConfigurationRequest = PutBucketLifecycleConfigurationRequest \n                .builder() \n                .bucket(bucketName) \n                .lifecycleConfiguration(lifecycleConfiguration) \n                .expectedBucketOwner(accountId) \n                .build(); \n            \n s3.putBucketLifecycleConfiguration(putBucketLifecycleConfigurationRequest); \n        } catch (S3Exception e) { \n            System.err.println(e.awsErrorDetails().errorMessage()); \n            System.exit(1); \n        } \n    } \n    /** \n     * Deletes the lifecycle configuration for an Amazon S3 bucket. \n     * \n     * @param s3 the {@link S3Client} to use for the operation \n     * @param bucketName the name of the S3 bucket \n     * @param accountId the expected account owner of the S3 bucket \n     * \n     * @throws S3Exception if an error occurs while deleting the lifecycle \n configuration \n     */ \n    public static void deleteLifecycleConfig(S3Client s3, String bucketName, \n String accountId) { \n        try { \nBasics API Version 2006-03-01 2162Amazon Simple Storage Service API Reference\n            DeleteBucketLifecycleRequest deleteBucketLifecycleRequest = \n DeleteBucketLifecycleRequest \n                .builder() \n                .bucket(bucketName) \n                .expectedBucketOwner(accountId) \n                .build(); \n            s3.deleteBucketLifecycle(deleteBucketLifecycleRequest); \n        } catch (S3Exception e) { \n            System.err.println(e.awsErrorDetails().errorMessage()); \n            System.exit(1); \n        } \n    }\n}\n\u2022For API details, see PutBucketLifecycleCon\ufb01guration in AWS SDK for Java 2.x API \nReference.\nPython\nSDK for Python (Boto3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nclass BucketWrapper: \n    \"\"\"Encapsulates S3 bucket actions.\"\"\" \n    def __init__(self, bucket): \n        \"\"\" \n        :param bucket: A Boto3 Bucket resource. This is a high-level resource in \n Boto3 \n                       that wraps bucket actions in a class-like structure.", "\n        \"\"\" \n        self.bucket = bucket \n        self.name = bucket.name \nBasics API Version 2006-03-01 2163Amazon Simple Storage Service API Reference\n    def put_lifecycle_configuration(self, lifecycle_rules): \n        \"\"\" \n        Apply a lifecycle configuration to the bucket. The lifecycle \n configuration can \n        be used to archive or delete the objects in the bucket according to \n specified \n        parameters, such as a number of days. \n        :param lifecycle_rules: The lifecycle rules to apply.", "\n        \"\"\" \n        try: \n            self.bucket.LifecycleConfiguration().put( \n                LifecycleConfiguration={\"Rules\": lifecycle_rules} \n            ) \n            logger.info( \n                \"Put lifecycle rules %s for bucket '%s'.\", \n                lifecycle_rules, \n                self.bucket.name, \n            ) \n        except ClientError: \n            logger.exception( \n                \"Couldn't put lifecycle rules for bucket '%s'.\", self.bucket.name \n            ) \n            raise\n\u2022For API details, see PutBucketLifecycleCon\ufb01guration in AWS SDK for Python (Boto3) API \nReference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs.", "This topic also includes information about getting started and details \nabout previous SDK versions.\nUse PutBucketLogging  with an AWS SDK or CLI\nThe following code examples show how to use PutBucketLogging .\nBasics API Version 2006-03-01 2164Amazon Simple Storage Service API Reference\n.NET\nAWS SDK for .NET\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n    using System; \n    using System.IO; \n    using System.Threading.Tasks; \n    using Amazon.S3; \n    using Amazon.S3.Model; \n    using Microsoft.Extensions.Configuration; \n    /// <summary> \n    /// This example shows how to enable logging on an Amazon Simple Storage \n    /// Service (Amazon S3) bucket. You need to have two Amazon S3 buckets for \n    /// this example.", "The first is the bucket for which you wish to enable \n    /// logging, and the second is the location where you want to store the \n    /// logs.", "\n    /// </summary> \n    public class ServerAccessLogging \n    { \n        private static IConfiguration _configuration = null!; \n        public static async Task Main() \n        { \n            LoadConfig(); \n            string bucketName = _configuration[\"BucketName\"]; \n            string logBucketName = _configuration[\"LogBucketName\"]; \n            string logObjectKeyPrefix = _configuration[\"LogObjectKeyPrefix\"]; \n            string accountId = _configuration[\"AccountId\"]; \n            // If the AWS Region defined for your default user is different \n            // from the Region where your Amazon S3 bucket is located, \n            // pass the Region name to the Amazon S3 client object's constructor.", "\n            // For example: RegionEndpoint.USWest2 or RegionEndpoint.USEast2.", "\n            IAmazonS3 client = new AmazonS3Client(); \nBasics API Version 2006-03-01 2165Amazon Simple Storage Service API Reference\n            try \n            { \n                // Update bucket policy for target bucket to allow delivery of \n logs to it.", "\n                await SetBucketPolicyToAllowLogDelivery( \n                    client, \n                    bucketName, \n                    logBucketName, \n                    logObjectKeyPrefix, \n                    accountId); \n                // Enable logging on the source bucket. \n                await EnableLoggingAsync( \n                    client, \n                    bucketName, \n                    logBucketName, \n                    logObjectKeyPrefix); \n            } \n            catch (AmazonS3Exception e) \n            { \n                Console.WriteLine($\"Error: {e.Message}\"); \n            } \n        } \n        /// <summary> \n        /// This method grants appropriate permissions for logging to the \n        /// Amazon S3 bucket where the logs will be stored. \n        /// </summary> \n        /// <param name=\"client\">The initialized Amazon S3 client which will be \n used \n        /// to apply the bucket policy.</param> \n        /// <param name=\"sourceBucketName\">The name of the source bucket.</param> \n        /// <param name=\"logBucketName\">The name of the bucket where logging \n        /// information will be stored.</param> \n        /// <param name=\"logPrefix\">The logging prefix where the logs should be \n delivered.</param> \n        /// <param name=\"accountId\">The account id of the account where the \n source bucket exists.</param> \n        /// <returns>Async task.</returns> \n        public static async Task SetBucketPolicyToAllowLogDelivery( \n            IAmazonS3 client, \n            string sourceBucketName, \n            string logBucketName, \nBasics API Version 2006-03-01 2166Amazon Simple Storage Service API Reference\n            string logPrefix, \n            string accountId) \n        { \n            var resourceArn = @\"\"\"arn:aws:s3:::\" + logBucketName + \"/\" + \n logPrefix + @\"*\"\"\"; \n            var newPolicy = @\"{ \n                                \"\"Statement\"\":[{ \n                                \"\"Sid\"\": \"\"S3ServerAccessLogsPolicy\"\", \n                                \"\"Effect\"\": \"\"Allow\"\", \n                                \"\"Principal\"\": { \"\"Service\"\": \n \"\"logging.s3.amazonaws.com\"\" }, \n                                \"\"Action\"\": [\"\"s3:PutObject\"\"], \n                                \"\"Resource\"\": [\" + resourceArn + @\"], \n                                \"\"Condition\"\": { \n                                \"\"ArnLike\"\": { \"\"aws:SourceArn\"\": \n \"\"arn:aws:s3:::\" + sourceBucketName + @\"\"\" }, \n                                \"\"StringEquals\"\": { \"\"aws:SourceAccount\"\": \"\"\" + \n accountId + @\"\"\" } \n                                        } \n                                    }] \n                                }\"; \n            Console.WriteLine($\"The policy to apply to bucket {logBucketName} to \n enable logging:\"); \n            Console.WriteLine(newPolicy); \n            PutBucketPolicyRequest putRequest = new PutBucketPolicyRequest \n            { \n                BucketName = logBucketName, \n                Policy = newPolicy, \n            }; \n            await client.PutBucketPolicyAsync(putRequest); \n            Console.WriteLine(\"Policy applied.\"); \n        } \n        /// <summary> \n        /// This method enables logging for an Amazon S3 bucket. Logs will be \n stored \n        /// in the bucket you selected for logging. Selected prefix \n        /// will be prepended to each log object.", "\n        /// </summary> \n        /// <param name=\"client\">The initialized Amazon S3 client which will be \n used \nBasics API Version 2006-03-01 2167Amazon Simple Storage Service API Reference\n        /// to configure and apply logging to the selected Amazon S3 bucket.</\nparam> \n        /// <param name=\"bucketName\">The name of the Amazon S3 bucket for which \n you \n        /// wish to enable logging.</param> \n        /// <param name=\"logBucketName\">The name of the Amazon S3 bucket where \n logging \n        /// information will be stored.</param> \n        /// <param name=\"logObjectKeyPrefix\">The prefix to prepend to each \n        /// object key.</param> \n        /// <returns>Async task.</returns> \n        public static async Task EnableLoggingAsync( \n            IAmazonS3 client, \n            string bucketName, \n            string logBucketName, \n            string logObjectKeyPrefix) \n        { \n            Console.WriteLine($\"Enabling logging for bucket {bucketName}.\"); \n            var loggingConfig = new S3BucketLoggingConfig \n            { \n                TargetBucketName = logBucketName, \n                TargetPrefix = logObjectKeyPrefix, \n            }; \n            var putBucketLoggingRequest = new PutBucketLoggingRequest \n            { \n                BucketName = bucketName, \n                LoggingConfig = loggingConfig, \n            }; \n            await client.PutBucketLoggingAsync(putBucketLoggingRequest); \n            Console.WriteLine($\"Logging enabled.\"); \n        } \n        /// <summary> \n        /// Loads configuration from settings files.", "\n        /// </summary> \n        public static void LoadConfig() \n        { \n            _configuration = new ConfigurationBuilder() \n                .SetBasePath(Directory.GetCurrentDirectory()) \n                .AddJsonFile(\"settings.json\") // Load settings from .json file. \n                .AddJsonFile(\"settings.local.json\", true) // Optionally, load \n local settings.", "\n                .Build(); \nBasics API Version 2006-03-01 2168Amazon Simple Storage Service API Reference\n        } \n    }\n\u2022For API details, see PutBucketLogging in AWS SDK for .NET API Reference.\nCLI\nAWS CLI\nExample 1: To set bucket policy logging\nThe following put-bucket-logging  example sets the logging policy for MyBucket . First, \ngrant the logging service principal permission in your bucket policy using the put-bucket-\npolicy command.\naws s3api put-bucket-policy \\ \n    --bucket MyBucket  \\ \n    --policy file://policy.json\nContents of policy.json :\n{ \n    \"Version\": \"2012-10-17\", \n    \"Statement\": [ \n        { \n            \"Sid\": \"S3ServerAccessLogsPolicy\", \n            \"Effect\": \"Allow\", \n            \"Principal\": {\"Service\": \"logging.s3.amazonaws.com\"}, \n            \"Action\": \"s3:PutObject\", \n            \"Resource\": \"arn:aws:s3:::MyBucket/Logs/*\", \n            \"Condition\": { \n                \"ArnLike\": {\"aws:SourceARN\": \"arn:aws:s3:::SOURCE-BUCKET-NAME\"}, \n                \"StringEquals\": {\"aws:SourceAccount\": \"SOURCE-AWS-ACCOUNT-ID\"} \n            } \n        } \n    ]\n}\nTo apply the logging policy, use put-bucket-logging .\nBasics API Version 2006-03-01 2169Amazon Simple Storage Service API Reference\naws s3api put-bucket-logging \\ \n    --bucket MyBucket  \\ \n    --bucket-logging-status file://logging.json\nContents of logging.json :\n{ \n     \"LoggingEnabled\": { \n         \"TargetBucket\": \"MyBucket\", \n         \"TargetPrefix\": \"Logs/\" \n     } \n }\nThe put-bucket-policy  command is required to grant s3:PutObject  permissions to the \nlogging service principal.\nFor more information, see Amazon S3 Server Access Logging in the Amazon S3 User Guide .\nExample 2: To set a bucket policy for logging access to only a single user\nThe following put-bucket-logging  example sets the logging policy for MyBucket .", "The \nAWS user bob@example.com will have full control over the log \ufb01les, and no one else has any \naccess. First, grant S3 permission with put-bucket-acl .\naws s3api put-bucket-acl \\ \n    --bucket MyBucket  \\ \n    --grant-write URI=http://acs.amazonaws.com/groups/s3/LogDelivery  \\ \n    --grant-read-acp URI=http://acs.amazonaws.com/groups/s3/LogDelivery\nThen apply the logging policy using put-bucket-logging .\naws s3api put-bucket-logging \\ \n    --bucket MyBucket  \\ \n    --bucket-logging-status file://logging.json\nContents of logging.json :\n{ \n    \"LoggingEnabled\": { \nBasics API Version 2006-03-01 2170Amazon Simple Storage Service API Reference\n        \"TargetBucket\": \"MyBucket\", \n        \"TargetPrefix\": \"MyBucketLogs/\", \n        \"TargetGrants\": [ \n            { \n                \"Grantee\": { \n                    \"Type\": \"AmazonCustomerByEmail\", \n                    \"EmailAddress\": \"bob@example.com\" \n                }, \n                \"Permission\": \"FULL_CONTROL\" \n            } \n        ] \n    }\n}\nthe put-bucket-acl  command is required to grant S3's log delivery system the necessary \npermissions (write and read-acp permissions).\nFor more information, see Amazon S3 Server Access Logging in the Amazon S3 Developer \nGuide .\n\u2022For API details, see PutBucketLogging in AWS CLI Command Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nUse PutBucketNotification  with a CLI\nThe following code examples show how to use PutBucketNotification .\nCLI\nAWS CLI\nThe applies a noti\ufb01cation con\ufb01guration to a bucket named my-bucket :\naws s3api put-bucket-notification --bucket my-bucket  --notification-\nconfiguration file://notification.json\nThe \ufb01le notification.json  is a JSON document in the current folder that speci\ufb01es an \nSNS topic and an event type to monitor:\nBasics API Version 2006-03-01 2171Amazon Simple Storage Service API Reference\n{ \n  \"TopicConfiguration\": { \n    \"Event\": \"s3:ObjectCreated:*\", \n    \"Topic\": \"arn:aws:sns:us-west-2:123456789012:s3-notification-topic\" \n  }\n}\nThe SNS topic must have an IAM policy attached to it that allows Amazon S3 to publish to it:\n{ \n \"Version\": \"2008-10-17\", \n \"Id\": \"example-ID\", \n \"Statement\": [ \n  { \n   \"Sid\": \"example-statement-ID\", \n   \"Effect\": \"Allow\", \n   \"Principal\": { \n     \"Service\": \"s3.amazonaws.com\" \n   }, \n   \"Action\": [ \n    \"SNS:Publish\" \n   ], \n   \"Resource\": \"arn:aws:sns:us-west-2:123456789012:my-bucket\", \n   \"Condition\": { \n      \"ArnLike\": { \n      \"aws:SourceArn\": \"arn:aws:s3:*:*:my-bucket\" \n    } \n   } \n  } \n ]\n}\n\u2022For API details, see PutBucketNoti\ufb01cation in AWS CLI Command Reference.\nPowerShell\nTools for PowerShell\nExample 1: This example con\ufb01gures the SNS topic con\ufb01guration for the S3 event \nObjectRemovedDelete and enables noti\ufb01cation for the given s3 bucket\n$topic =  [Amazon.S3.Model.TopicConfiguration] @{ \nBasics API Version 2006-03-01 2172Amazon Simple Storage Service API Reference\n  Id = \"delete-event\" \n  Topic = \"arn:aws:sns:eu-west-1:123456789012:topic-1\" \n  Event = [Amazon.S3.EventType]::ObjectRemovedDelete\n}\nWrite-S3BucketNotification -BucketName amzn-s3-demo-bucket -TopicConfiguration \n $topic\nExample 2: This example enables noti\ufb01cations of ObjectCreatedAll for the given bucket \nsending it to Lambda function.\n$lambdaConfig = [Amazon.S3.Model.LambdaFunctionConfiguration] @{ \n  Events = \"s3:ObjectCreated:*\" \n  FunctionArn = \"arn:aws:lambda:eu-west-1:123456789012:function:rdplock\" \n  Id = \"ObjectCreated-Lambda\" \n  Filter = @{ \n    S3KeyFilter = @{ \n      FilterRules = @( \n        @{Name=\"Prefix\";Value=\"dada\"} \n        @{Name=\"Suffix\";Value=\".pem\"} \n      ) \n    } \n  }\n}\nWrite-S3BucketNotification -BucketName amzn-s3-demo-bucket -\nLambdaFunctionConfiguration $lambdaConfig\nExample 3: This example creates 2 di\ufb00erent Lambda con\ufb01guration on the basis of \ndi\ufb00erent key-su\ufb03x and con\ufb01gured both in a single command.\n#Lambda Config 1\n$firstLambdaConfig = [Amazon.S3.Model.LambdaFunctionConfiguration] @{ \n  Events = \"s3:ObjectCreated:*\" \n  FunctionArn = \"arn:aws:lambda:eu-west-1:123456789012:function:verifynet\" \n  Id = \"ObjectCreated-dada-ps1\" \n  Filter = @{ \n    S3KeyFilter = @{ \n      FilterRules = @( \n        @{Name=\"Prefix\";Value=\"dada\"} \n        @{Name=\"Suffix\";Value=\".ps1\"} \nBasics API Version 2006-03-01 2173Amazon Simple Storage Service API Reference\n      ) \n    } \n  }\n}\n#Lambda Config 2\n$secondlambdaConfig = [Amazon.S3.Model.LambdaFunctionConfiguration] @{ \n  Events = [Amazon.S3.EventType]::ObjectCreatedAll \n  FunctionArn = \"arn:aws:lambda:eu-west-1:123456789012:function:verifyssm\" \n  Id = \"ObjectCreated-dada-json\" \n  Filter = @{ \n    S3KeyFilter = @{ \n      FilterRules = @( \n        @{Name=\"Prefix\";Value=\"dada\"} \n        @{Name=\"Suffix\";Value=\".json\"} \n      ) \n    } \n  }\n}\nWrite-S3BucketNotification -BucketName amzn-s3-demo-bucket -\nLambdaFunctionConfiguration $firstLambdaConfig,$secondlambdaConfig\n\u2022For API details, see PutBucketNoti\ufb01cation in AWS Tools for PowerShell Cmdlet Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nUse PutBucketNotificationConfiguration  with an AWS SDK or CLI\nThe following code examples show how to use PutBucketNotificationConfiguration .\nAction examples are code excerpts from larger programs and must be run in context.", "You can see \nthis action in context in the following code examples:\n\u2022Process S3 event noti\ufb01cations\n\u2022Send event noti\ufb01cations to EventBridge\nBasics API Version 2006-03-01 2174Amazon Simple Storage Service API Reference\n.NET\nAWS SDK for .NET\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n    using System; \n    using System.Collections.Generic; \n    using System.Threading.Tasks; \n    using Amazon.S3; \n    using Amazon.S3.Model; \n    /// <summary> \n    /// This example shows how to enable notifications for an Amazon Simple \n    /// Storage Service (Amazon S3) bucket. \n    /// </summary> \n    public class EnableNotifications \n    { \n        public static async Task Main() \n        { \n            const string bucketName = \"amzn-s3-demo-bucket1\"; \n            const string snsTopic = \"arn:aws:sns:us-east-2:0123456789ab:bucket-\nnotify\"; \n            const string sqsQueue = \"arn:aws:sqs:us-\neast-2:0123456789ab:Example_Queue\"; \n            IAmazonS3 client = new AmazonS3Client(Amazon.RegionEndpoint.USEast2); \n            await EnableNotificationAsync(client, bucketName, snsTopic, \n sqsQueue); \n        } \n        /// <summary> \n        /// This method makes the call to the PutBucketNotificationAsync method. \n        /// </summary> \n        /// <param name=\"client\">An initialized Amazon S3 client used to call \n        /// the PutBucketNotificationAsync method.</param> \n        /// <param name=\"bucketName\">The name of the bucket for which \n        /// notifications will be turned on.</param> \nBasics API Version 2006-03-01 2175Amazon Simple Storage Service API Reference\n        /// <param name=\"snsTopic\">The ARN for the Amazon Simple Notification \n        /// Service (Amazon SNS) topic associated with the S3 bucket.</param> \n        /// <param name=\"sqsQueue\">The ARN of the Amazon Simple Queue Service \n        /// (Amazon SQS) queue to which notifications will be pushed.</param> \n        public static async Task EnableNotificationAsync( \n            IAmazonS3 client, \n            string bucketName, \n            string snsTopic, \n            string sqsQueue) \n        { \n            try \n            { \n                // The bucket for which we are setting up notifications. \n                var request = new PutBucketNotificationRequest() \n                { \n                    BucketName = bucketName, \n                }; \n                // Defines the topic to use when sending a notification. \n                var topicConfig = new TopicConfiguration() \n                { \n                    Events = new List<EventType> { EventType.ObjectCreatedCopy }, \n                    Topic = snsTopic, \n                }; \n                request.TopicConfigurations = new List<TopicConfiguration> \n                { \n                    topicConfig, \n                }; \n                request.QueueConfigurations = new List<QueueConfiguration> \n                { \n                    new QueueConfiguration() \n                    { \n                        Events = new List<EventType> \n { EventType.ObjectCreatedPut }, \n                        Queue = sqsQueue, \n                    }, \n                }; \n                // Now apply the notification settings to the bucket. \n                PutBucketNotificationResponse response = await \n client.PutBucketNotificationAsync(request); \n            } \n            catch (AmazonS3Exception ex) \n            { \nBasics API Version 2006-03-01 2176Amazon Simple Storage Service API Reference\n                Console.WriteLine($\"Error: {ex.Message}\"); \n            } \n        } \n    }\n\u2022For API details, see PutBucketNoti\ufb01cationCon\ufb01guration in AWS SDK for .NET API Reference.\nCLI\nAWS CLI\nTo enable the speci\ufb01ed noti\ufb01cations to a bucket\nThe following put-bucket-notification-configuration  example applies a \nnoti\ufb01cation con\ufb01guration to a bucket named my-bucket . The \ufb01le notification.json\nis a JSON document in the current folder that speci\ufb01es an SNS topic and an event type to \nmonitor.\naws s3api put-bucket-notification-configuration \\ \n    --bucket my-bucket  \\ \n    --notification-configuration file://notification.json\nContents of notification.json :\n{ \n    \"TopicConfigurations\": [ \n        { \n            \"TopicArn\": \"arn:aws:sns:us-west-2:123456789012:s3-notification-\ntopic\", \n            \"Events\": [ \n                \"s3:ObjectCreated:*\" \n            ] \n        } \n    ]\n}\nThe SNS topic must have an IAM policy attached to it that allows Amazon S3 to publish to it.\n{ \nBasics API Version 2006-03-01 2177Amazon Simple Storage Service API Reference\n    \"Version\": \"2008-10-17\", \n    \"Id\": \"example-ID\", \n    \"Statement\": [ \n        { \n            \"Sid\": \"example-statement-ID\", \n            \"Effect\": \"Allow\", \n            \"Principal\": { \n                \"Service\": \"s3.amazonaws.com\" \n            }, \n            \"Action\": [ \n                \"SNS:Publish\" \n            ], \n            \"Resource\": \"arn:aws:sns:us-west-2:123456789012::s3-notification-\ntopic\", \n            \"Condition\": { \n                \"ArnLike\": { \n                    \"aws:SourceArn\": \"arn:aws:s3:*:*:my-bucket\" \n                } \n            } \n        } \n    ]\n}\n\u2022For API details, see PutBucketNoti\ufb01cationCon\ufb01guration in AWS CLI Command Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs.", "This topic also includes information about getting started and details \nabout previous SDK versions.\nUse PutBucketPolicy  with an AWS SDK or CLI\nThe following code examples show how to use PutBucketPolicy .\nC++\nSDK for C++\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nBasics API Version 2006-03-01 2178Amazon Simple Storage Service API Reference\nbool AwsDoc::S3::putBucketPolicy(const Aws::String &bucketName, \n                                 const Aws::String &policyBody, \n                                 const Aws::S3::S3ClientConfiguration \n &clientConfig) { \n    Aws::S3::S3Client s3Client(clientConfig); \n    std::shared_ptr<Aws::StringStream> request_body = \n            Aws::MakeShared<Aws::StringStream>(\"\"); \n    *request_body << policyBody; \n    Aws::S3::Model::PutBucketPolicyRequest request; \n    request.SetBucket(bucketName); \n    request.SetBody(request_body); \n    Aws::S3::Model::PutBucketPolicyOutcome outcome = \n            s3Client.PutBucketPolicy(request); \n    if (!outcome.IsSuccess()) { \n        std::cerr << \"Error: putBucketPolicy: \" \n                  << outcome.GetError().GetMessage() << std::endl; \n    } else { \n        std::cout << \"Set the following policy body for the bucket '\" << \n                  bucketName << \"':\" << std::endl << std::endl; \n        std::cout << policyBody << std::endl; \n    } \n    return outcome.IsSuccess();\n}\n//!", "Build a policy JSON string.\n/*!", "\n  \\param userArn: Aws user Amazon Resource Name (ARN). \n      For more information, see https://docs.aws.amazon.com/IAM/latest/UserGuide/\nreference_identifiers.html#identifiers-arns.", "\n  \\param bucketName: Name of a bucket.", "\n  \\return String: Policy as JSON string.\n*/\nAws::String getPolicyString(const Aws::String &userArn, \n                            const Aws::String &bucketName) { \n    return \n            \"{\\n\" \nBasics API Version 2006-03-01 2179Amazon Simple Storage Service API Reference\n            \"   \\\"Version\\\":\\\"2012-10-17\\\",\\n\" \n            \"   \\\"Statement\\\":[\\n\" \n            \"       {\\n\" \n            \"           \\\"Sid\\\": \\\"1\\\",\\n\" \n            \"           \\\"Effect\\\": \\\"Allow\\\",\\n\" \n            \"           \\\"Principal\\\": {\\n\" \n            \"               \\\"AWS\\\": \\\"\" \n            + userArn + \n            \"\\\"\\n\"\"           },\\n\" \n            \"           \\\"Action\\\": [ \\\"s3:getObject\\\" ],\\n\" \n            \"           \\\"Resource\\\": [ \\\"arn:aws:s3:::\" \n            + bucketName + \n            \"/*\\\" ]\\n\" \n            \"       }\\n\" \n            \"   ]\\n\" \n            \"}\";\n}\n\u2022For API details, see PutBucketPolicy in AWS SDK for C++ API Reference.\nCLI\nAWS CLI\nThis example allows all users to retrieve any object in MyBucket  except those in the\nMySecretFolder. It also grants put and delete permission to the root user of the AWS \naccount 1234-5678-9012 :\naws s3api put-bucket-policy --bucket MyBucket  --policy file://policy.json\npolicy.json:\n{\n   \"Statement\": [\n      {\n         \"Effect\": \"Allow\", \n         \"Principal\": \"*\", \n         \"Action\": \"s3:GetObject\", \n         \"Resource\": \"arn:aws:s3:::MyBucket/*\"\n      },\n      {\n         \"Effect\": \"Deny\", \nBasics API Version 2006-03-01 2180Amazon Simple Storage Service API Reference\n         \"Principal\": \"*\", \n         \"Action\": \"s3:GetObject\", \n         \"Resource\": \"arn:aws:s3:::MyBucket/MySecretFolder/*\"\n      },\n      {\n         \"Effect\": \"Allow\", \n         \"Principal\": {\n            \"AWS\": \"arn:aws:iam::123456789012:root\"\n         },\n         \"Action\": [\n            \"s3:DeleteObject\", \n             \"s3:PutObject\"\n         ],\n         \"Resource\": \"arn:aws:s3:::MyBucket/*\"\n      }\n \n  ]\n}\n\u2022For API details, see PutBucketPolicy in AWS CLI Command Reference.\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nimport software.amazon.awssdk.services.s3.S3Client;\nimport software.amazon.awssdk.services.s3.model.PutBucketPolicyRequest;\nimport software.amazon.awssdk.services.s3.model.S3Exception;\nimport software.amazon.awssdk.regions.Region;\nimport java.io.IOException;\nimport java.nio.charset.StandardCharsets;\nimport java.nio.file.Files;\nimport java.nio.file.Paths;\nimport java.util.List;\nBasics API Version 2006-03-01 2181Amazon Simple Storage Service API Reference\nimport com.fasterxml.jackson.core.JsonParser;\nimport com.fasterxml.jackson.databind.ObjectMapper;\n/** \n * Before running this Java V2 code example, set up your development \n * environment, including your credentials. \n * <p> \n * For more information, see the following documentation topic: \n * <p> \n * https://docs.aws.amazon.com/sdk-for-java/latest/developer-guide/get-\nstarted.html \n */\npublic class SetBucketPolicy { \n    public static void main(String[] args) { \n        final String usage = \"\"\" \n            Usage: \n                <bucketName> <polFile> \n            Where: \n                bucketName - The Amazon S3 bucket to set the policy on. \n                polFile - A JSON file containing the policy (see the Amazon S3 \n Readme for an example).\\s \n            \"\"\"; \n        if (args.length != 2) { \n            System.out.println(usage); \n            System.exit(1); \n        } \n        String bucketName = args[0]; \n        String polFile = args[1]; \n        String policyText = getBucketPolicyFromFile(polFile); \n        Region region = Region.US_EAST_1; \n        S3Client s3 = S3Client.builder() \n            .region(region) \n            .build(); \n        setPolicy(s3, bucketName, policyText); \n        s3.close(); \n    } \n    /** \nBasics API Version 2006-03-01 2182Amazon Simple Storage Service API Reference\n     * Sets the policy for an Amazon S3 bucket. \n     * \n     * @param s3         the {@link S3Client} object used to interact with the \n Amazon S3 service \n     * @param bucketName the name of the Amazon S3 bucket \n     * @param policyText the text of the policy to be set on the bucket \n     * @throws S3Exception if there is an error setting the bucket policy \n     */ \n    public static void setPolicy(S3Client s3, String bucketName, String \n policyText) { \n        System.out.println(\"Setting policy:\"); \n        System.out.println(\"----\"); \n        System.out.println(policyText); \n        System.out.println(\"----\"); \n        System.out.format(\"On Amazon S3 bucket: \\\"%s\\\"\\n\", bucketName); \n        try { \n            PutBucketPolicyRequest policyReq = PutBucketPolicyRequest.builder() \n                .bucket(bucketName) \n                .policy(policyText) \n                .build(); \n            s3.putBucketPolicy(policyReq); \n        } catch (S3Exception e) { \n            System.err.println(e.awsErrorDetails().errorMessage()); \n            System.exit(1); \n        } \n        System.out.println(\"Done!\"); \n    } \n    /** \n     * Retrieves the bucket policy from a specified file. \n     * \n     * @param policyFile the path to the file containing the bucket policy \n     * @return the content of the bucket policy file as a string \n     */ \n    public static String getBucketPolicyFromFile(String policyFile) { \n        StringBuilder fileText = new StringBuilder(); \n        try { \n            List<String> lines = Files.readAllLines(Paths.get(policyFile), \n StandardCharsets.UTF_8); \n            for (String line : lines) { \nBasics API Version 2006-03-01 2183Amazon Simple Storage Service API Reference\n                fileText.append(line); \n            } \n        } catch (IOException e) { \n            System.out.format(\"Problem reading file: \\\"%s\\\"\", policyFile); \n            System.out.println(e.getMessage()); \n        } \n        try { \n            final JsonParser parser = new \n ObjectMapper().getFactory().createParser(fileText.toString()); \n            while (parser.nextToken() != null) { \n            } \n        } catch (IOException jpe) { \n            jpe.printStackTrace(); \n        } \n        return fileText.toString(); \n    }\n}\n\u2022For API details, see PutBucketPolicy in AWS SDK for Java 2.x API Reference.\nJavaScript\nSDK for JavaScript (v3)\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nAdd the policy.\nimport { \n  PutBucketPolicyCommand, \n  S3Client, \n  S3ServiceException,\n} from \"@aws-sdk/client-s3\";\nBasics API Version 2006-03-01 2184Amazon Simple Storage Service API Reference\n/** \n * Grant an IAM role GetObject access to all of the objects \n * in the provided bucket. \n * @param {{ bucketName: string, iamRoleArn: string }} \n */\nexport const main = async ({ bucketName, iamRoleArn }) => { \n  const client = new S3Client({}); \n  const command = new PutBucketPolicyCommand({ \n    // This is a resource-based policy.", "For more information on resource-based \n policies, \n    // see https://docs.aws.amazon.com/IAM/latest/UserGuide/\naccess_policies.html#policies_resource-based. \n    Policy: JSON.stringify({ \n      Version: \"2012-10-17\", \n      Statement: [ \n        { \n          Effect: \"Allow\", \n          Principal: { \n            AWS: iamRoleArn, \n          }, \n          Action: \"s3:GetObject\", \n          Resource: `arn:aws:s3:::${bucketName}/*`, \n        }, \n      ], \n    }), \n    // Apply the preceding policy to this bucket. \n    Bucket: bucketName, \n  }); \n  try { \n    await client.send(command); \n    console.log( \n      `GetObject access to the bucket \"${bucketName}\" was granted to the provided \n IAM role.`, \n    ); \n  } catch (caught) { \n    if ( \n      caught instanceof S3ServiceException && \n      caught.name === \"MalformedPolicy\" \n    ) { \n      console.error( \n        `Error from S3 while setting the bucket policy for the bucket \n \"${bucketName}\". The policy was malformed.`, \n      ); \nBasics API Version 2006-03-01 2185Amazon Simple Storage Service API Reference\n    } else if (caught instanceof S3ServiceException) { \n      console.error( \n        `Error from S3 while setting the bucket policy for the bucket \n \"${bucketName}\".", "${caught.name}: ${caught.message}`, \n      ); \n    } else { \n      throw caught; \n    } \n  }\n};\n\u2022For more information, see AWS SDK for JavaScript Developer Guide.\n\u2022For API details, see PutBucketPolicy in AWS SDK for JavaScript API Reference.\nPython\nSDK for Python (Boto3)\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nclass BucketWrapper: \n    \"\"\"Encapsulates S3 bucket actions.\"\"\" \n    def __init__(self, bucket): \n        \"\"\" \n        :param bucket: A Boto3 Bucket resource. This is a high-level resource in \n Boto3 \n                       that wraps bucket actions in a class-like structure.", "\n        \"\"\" \n        self.bucket = bucket \n        self.name = bucket.name \n    def put_policy(self, policy): \n        \"\"\" \n        Apply a security policy to the bucket.", "Policies control users' ability \nBasics API Version 2006-03-01 2186Amazon Simple Storage Service API Reference\n        to perform specific actions, such as listing the objects in the bucket.", "\n        :param policy: The policy to apply to the bucket. \n        \"\"\" \n        try: \n            self.bucket.Policy().put(Policy=json.dumps(policy)) \n            logger.info(\"Put policy %s for bucket '%s'.\", policy, \n self.bucket.name) \n        except ClientError: \n            logger.exception(\"Couldn't apply policy to bucket '%s'.\", \n self.bucket.name) \n            raise\n\u2022For API details, see PutBucketPolicy in AWS SDK for Python (Boto3) API Reference.\nRuby\nSDK for Ruby\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n# Wraps an Amazon S3 bucket policy.\nclass BucketPolicyWrapper \n  attr_reader :bucket_policy \n  # @param bucket_policy [Aws::S3::BucketPolicy] A bucket policy object \n configured with an existing bucket.", "\n  def initialize(bucket_policy) \n    @bucket_policy = bucket_policy \n  end \n  # Sets a policy on a bucket. \n  # \n  def policy(policy) \n    @bucket_policy.put(policy: policy) \n    true \nBasics API Version 2006-03-01 2187Amazon Simple Storage Service API Reference\n  rescue Aws::Errors::ServiceError => e \n    puts \"Couldn't set the policy for #{@bucket_policy.bucket.name}.", "Here's why: \n #{e.message}\" \n    false \n  end\nend\n\u2022For API details, see PutBucketPolicy in AWS SDK for Ruby API Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nUse PutBucketReplication  with a CLI\nThe following code examples show how to use PutBucketReplication .\nCLI\nAWS CLI\nTo con\ufb01gure replication for an S3 bucket\nThe following put-bucket-replication  example applies a replication con\ufb01guration to \nthe speci\ufb01ed S3 bucket.\naws s3api put-bucket-replication \\ \n    --bucket AWSDOC-EXAMPLE-BUCKET1  \\ \n    --replication-configuration file://replication.json\nContents of replication.json :\n{ \n    \"Role\": \"arn:aws:iam::123456789012:role/s3-replication-role\", \n    \"Rules\": [ \n        { \n            \"Status\": \"Enabled\", \n            \"Priority\": 1, \n            \"DeleteMarkerReplication\": { \"Status\": \"Disabled\" }, \n            \"Filter\" : { \"Prefix\": \"\"}, \nBasics API Version 2006-03-01 2188Amazon Simple Storage Service API Reference\n            \"Destination\": { \n                \"Bucket\": \"arn:aws:s3:::AWSDOC-EXAMPLE-BUCKET2\" \n            } \n        } \n    ]\n}\nThe destination bucket must have versioning enabled. The speci\ufb01ed role must have \npermission to write to the destination bucket and have a trust relationship that allows \nAmazon S3 to assume the role.\nExample role permission policy:\n{ \n    \"Version\": \"2012-10-17\", \n    \"Statement\": [ \n        { \n            \"Effect\": \"Allow\", \n            \"Action\": [ \n                \"s3:GetReplicationConfiguration\", \n                \"s3:ListBucket\" \n            ], \n            \"Resource\": [ \n                \"arn:aws:s3:::AWSDOC-EXAMPLE-BUCKET1\" \n            ] \n        }, \n        { \n            \"Effect\": \"Allow\", \n            \"Action\": [ \n                \"s3:GetObjectVersion\", \n                \"s3:GetObjectVersionAcl\", \n                \"s3:GetObjectVersionTagging\" \n            ], \n            \"Resource\": [ \n                \"arn:aws:s3:::AWSDOC-EXAMPLE-BUCKET1/*\" \n            ] \n        }, \n        { \n            \"Effect\": \"Allow\", \n            \"Action\": [ \n                \"s3:ReplicateObject\", \n                \"s3:ReplicateDelete\", \n                \"s3:ReplicateTags\" \nBasics API Version 2006-03-01 2189Amazon Simple Storage Service API Reference\n            ], \n            \"Resource\": \"arn:aws:s3:::AWSDOC-EXAMPLE-BUCKET2/*\" \n        } \n    ]\n}\nExample trust relationship policy:\n{ \n    \"Version\": \"2012-10-17\", \n    \"Statement\": [ \n        { \n            \"Effect\": \"Allow\", \n            \"Principal\": { \n                \"Service\": \"s3.amazonaws.com\" \n            }, \n            \"Action\": \"sts:AssumeRole\" \n        } \n    ]\n}\nThis command produces no output.\nFor more information, see This is the topic title  in the Amazon Simple Storage Service Console \nUser Guide .\n\u2022For API details, see PutBucketReplication in AWS CLI Command Reference.\nPowerShell\nTools for PowerShell\nExample 1: This example sets a replication con\ufb01guration with a single rule enabling \nreplication to the 'exampletargetbucket' bucket any new objects created with the key \nname pre\ufb01x \"TaxDocs\" in the bucket 'examplebucket'.\n$rule1 = New-Object Amazon.S3.Model.ReplicationRule\n$rule1.ID = \"Rule-1\"\n$rule1.Status = \"Enabled\"\n$rule1.Prefix = \"TaxDocs\"\n$rule1.Destination = @{ BucketArn = \"arn:aws:s3:::amzn-s3-demo-destination-\nbucket\" } \nBasics API Version 2006-03-01 2190Amazon Simple Storage Service API Reference\n    \n$params = @{ \n    BucketName = \"amzn-s3-demo-bucket\" \n    Configuration_Role = \"arn:aws:iam::35667example:role/\nCrossRegionReplicationRoleForS3\" \n    Configuration_Rule = $rule1\n}\nWrite-S3BucketReplication @params\nExample 2: This example sets a replication con\ufb01guration with multiple rules enabling \nreplication to the 'exampletargetbucket' bucket any new objects created with either the \nkey name pre\ufb01x \"TaxDocs\" or \"OtherDocs\". The key pre\ufb01xes must not overlap.\n$rule1 = New-Object Amazon.S3.Model.ReplicationRule\n$rule1.ID = \"Rule-1\"\n$rule1.Status = \"Enabled\"\n$rule1.Prefix = \"TaxDocs\"\n$rule1.Destination = @{ BucketArn = \"arn:aws:s3:::amzn-s3-demo-destination-\nbucket\" } \n     \n$rule2 = New-Object Amazon.S3.Model.ReplicationRule\n$rule2.ID = \"Rule-2\"\n$rule2.Status = \"Enabled\"\n$rule2.Prefix = \"OtherDocs\"\n$rule2.Destination = @{ BucketArn = \"arn:aws:s3:::amzn-s3-demo-destination-\nbucket\" } \n     \n$params = @{ \n    BucketName = \"amzn-s3-demo-bucket\" \n    Configuration_Role = \"arn:aws:iam::35667example:role/\nCrossRegionReplicationRoleForS3\" \n    Configuration_Rule = $rule1,$rule2\n}\nWrite-S3BucketReplication @params\nExample 3: This example updates the replication con\ufb01guration on the speci\ufb01ed bucket to \ndisable the rule controlling replication of objects with the key name pre\ufb01x \"TaxDocs\" to \nthe bucket 'exampletargetbucket'.\n$rule1 = New-Object Amazon.S3.Model.ReplicationRule\nBasics API Version 2006-03-01 2191Amazon Simple Storage Service API Reference\n$rule1.ID = \"Rule-1\"\n$rule1.Status = \"Disabled\"\n$rule1.Prefix = \"TaxDocs\"\n$rule1.Destination = @{ BucketArn = \"arn:aws:s3:::amzn-s3-demo-destination-\nbucket\" } \n     \n$params = @{ \n    BucketName = \"amzn-s3-demo-bucket\" \n    Configuration_Role = \"arn:aws:iam::35667example:role/\nCrossRegionReplicationRoleForS3\" \n    Configuration_Rule = $rule1\n}\nWrite-S3BucketReplication @params\n\u2022For API details, see PutBucketReplication in AWS Tools for PowerShell Cmdlet Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs.", "This topic also includes information about getting started and details \nabout previous SDK versions.\nUse PutBucketRequestPayment  with a CLI\nThe following code examples show how to use PutBucketRequestPayment .\nCLI\nAWS CLI\nExample 1: To enable ``requester pays`` con\ufb01guration for a bucket\nThe following put-bucket-request-payment  example enables requester pays  for the \nspeci\ufb01ed bucket.\naws s3api put-bucket-request-payment \\ \n    --bucket my-bucket  \\ \n    --request-payment-configuration ' {\"Payer\":\"Requester\"} '\nThis command produces no output.\nExample 2: To disable ``requester pays`` con\ufb01guration for a bucket\nBasics API Version 2006-03-01 2192Amazon Simple Storage Service API Reference\nThe following put-bucket-request-payment  example disables requester pays  for \nthe speci\ufb01ed bucket.\naws s3api put-bucket-request-payment \\ \n    --bucket my-bucket  \\ \n    --request-payment-configuration ' {\"Payer\":\"BucketOwner\"} '\nThis command produces no output.\n\u2022For API details, see PutBucketRequestPayment in AWS CLI Command Reference.\nPowerShell\nTools for PowerShell\nExample 1: Updates the request payment con\ufb01guration for the bucket named 'mybucket' \nso that the person requesting downloads from the bucket will be charged for the \ndownload.", "By default the bucket owner pays for downloads.", "To set the request payment \nback to the default use 'BucketOwner' for the RequestPaymentCon\ufb01guration_Payer \nparameter.\nWrite-S3BucketRequestPayment -BucketName amzn-s3-demo-bucket -\nRequestPaymentConfiguration_Payer Requester\n\u2022For API details, see PutBucketRequestPayment in AWS Tools for PowerShell Cmdlet \nReference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nUse PutBucketTagging  with a CLI\nThe following code examples show how to use PutBucketTagging .\nCLI\nAWS CLI\nThe following command applies a tagging con\ufb01guration to a bucket named my-bucket :\nBasics API Version 2006-03-01 2193Amazon Simple Storage Service API Reference\naws s3api put-bucket-tagging --bucket my-bucket  --tagging file://tagging.json\nThe \ufb01le tagging.json  is a JSON document in the current folder that speci\ufb01es tags:\n{ \n   \"TagSet\": [ \n     { \n       \"Key\": \"organization\", \n       \"Value\": \"marketing\" \n     } \n   ]\n}\nOr apply a tagging con\ufb01guration to my-bucket  directly from the command line:\naws s3api put-bucket-tagging --bucket my-bucket  --tagging \n 'TagSet=[{Key=organization,Value=marketing}] '\n\u2022For API details, see PutBucketTagging in AWS CLI Command Reference.\nPowerShell\nTools for PowerShell\nExample 1: This command applies two tags to a bucket named cloudtrail-test-2018 : \na tag with a key of Stage and a value of Test, and a tag with a key of Environment \nand a value of Alpha. To verify that the tags were added to the bucket, run Get-\nS3BucketTagging -BucketName bucket_name .", "The results should show the tags that \nyou applied to the bucket in the \ufb01rst command.", "Note that Write-S3BucketTagging\noverwrites the entire existing tag set on a bucket.", "To add or delete individual tags, run \nthe Resource Groups and Tagging API cmdlets, Add-RGTResourceTag  and Remove-\nRGTResourceTag .", "Alternatively, use Tag Editor in the AWS Management Console to \nmanage S3 bucket tags.\nWrite-S3BucketTagging -BucketName amzn-s3-demo-bucket -TagSet @( @{ Key=\"Stage\"; \n Value=\"Test\" }, @{ Key=\"Environment\"; Value=\"Alpha\" } )\nExample 2: This command pipes a bucket named cloudtrail-test-2018  into \nthe Write-S3BucketTagging  cmdlet.", "It applies tags Stage:Production and \nBasics API Version 2006-03-01 2194Amazon Simple Storage Service API Reference\nDepartment:Finance to the bucket.", "Note that Write-S3BucketTagging  overwrites the \nentire existing tag set on a bucket.\nGet-S3Bucket -BucketName amzn-s3-demo-bucket | Write-S3BucketTagging \n -TagSet @( @{ Key=\"Stage\"; Value=\"Production\" }, @{ Key=\"Department\"; \n Value=\"Finance\" } )\n\u2022For API details, see PutBucketTagging in AWS Tools for PowerShell Cmdlet Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nUse PutBucketVersioning  with a CLI\nThe following code examples show how to use PutBucketVersioning .\nCLI\nAWS CLI\nThe following command enables versioning on a bucket named my-bucket :\naws s3api put-bucket-versioning --bucket my-bucket  --versioning-\nconfiguration Status=Enabled\nThe following command enables versioning, and uses an mfa code\naws s3api put-bucket-versioning --bucket my-bucket  --versioning-\nconfiguration Status=Enabled  --mfa \"SERIAL 123456\"\n\u2022For API details, see PutBucketVersioning in AWS CLI Command Reference.\nPowerShell\nTools for PowerShell\nExample 1: The command enables versioning for the given S3 bucket.\nBasics API Version 2006-03-01 2195Amazon Simple Storage Service API Reference\nWrite-S3BucketVersioning -BucketName 'amzn-s3-demo-bucket' -\nVersioningConfig_Status Enabled\n\u2022For API details, see PutBucketVersioning in AWS Tools for PowerShell Cmdlet Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nUse PutBucketWebsite  with an AWS SDK or CLI\nThe following code examples show how to use PutBucketWebsite .\n.NET\nAWS SDK for .NET\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n                // Put the website configuration. \n                PutBucketWebsiteRequest putRequest = new \n PutBucketWebsiteRequest() \n                { \n                    BucketName = bucketName, \n                    WebsiteConfiguration = new WebsiteConfiguration() \n                    { \n                        IndexDocumentSuffix = indexDocumentSuffix, \n                        ErrorDocument = errorDocument, \n                    }, \n                }; \n                PutBucketWebsiteResponse response = await \n client.PutBucketWebsiteAsync(putRequest);\n\u2022For API details, see PutBucketWebsite in AWS SDK for .NET API Reference.\nBasics API Version 2006-03-01 2196Amazon Simple Storage Service API Reference\nC++\nSDK for C++\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nbool AwsDoc::S3::putWebsiteConfig(const Aws::String &bucketName, \n                                  const Aws::String &indexPage, const Aws::String \n &errorPage, \n                                  const Aws::S3::S3ClientConfiguration \n &clientConfig) { \n    Aws::S3::S3Client client(clientConfig); \n    Aws::S3::Model::IndexDocument indexDocument; \n    indexDocument.SetSuffix(indexPage); \n    Aws::S3::Model::ErrorDocument errorDocument; \n    errorDocument.SetKey(errorPage); \n    Aws::S3::Model::WebsiteConfiguration websiteConfiguration; \n    websiteConfiguration.SetIndexDocument(indexDocument); \n    websiteConfiguration.SetErrorDocument(errorDocument); \n    Aws::S3::Model::PutBucketWebsiteRequest request; \n    request.SetBucket(bucketName); \n    request.SetWebsiteConfiguration(websiteConfiguration); \n    Aws::S3::Model::PutBucketWebsiteOutcome outcome = \n            client.PutBucketWebsite(request); \n    if (!outcome.IsSuccess()) { \n        std::cerr << \"Error: PutBucketWebsite: \" \n                  << outcome.GetError().GetMessage() << std::endl; \n    } else { \n        std::cout << \"Success: Set website configuration for bucket '\" \n                  << bucketName << \"'.\" << std::endl; \n    } \nBasics API Version 2006-03-01 2197Amazon Simple Storage Service API Reference\n    return outcome.IsSuccess();\n}\n\u2022For API details, see PutBucketWebsite in AWS SDK for C++ API Reference.\nCLI\nAWS CLI\nThe applies a static website con\ufb01guration to a bucket named my-bucket :\naws s3api put-bucket-website --bucket my-bucket  --website-configuration file://\nwebsite.json\nThe \ufb01le website.json  is a JSON document in the current folder that speci\ufb01es index and \nerror pages for the website:\n{ \n    \"IndexDocument\": { \n        \"Suffix\": \"index.html\" \n    }, \n    \"ErrorDocument\": { \n        \"Key\": \"error.html\" \n    }\n}\n\u2022For API details, see PutBucketWebsite in AWS CLI Command Reference.\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nBasics API Version 2006-03-01 2198Amazon Simple Storage Service API Reference\nimport software.amazon.awssdk.services.s3.S3Client;\nimport software.amazon.awssdk.services.s3.model.IndexDocument;\nimport software.amazon.awssdk.services.s3.model.PutBucketWebsiteRequest;\nimport software.amazon.awssdk.services.s3.model.WebsiteConfiguration;\nimport software.amazon.awssdk.services.s3.model.S3Exception;\nimport software.amazon.awssdk.regions.Region;\n/** \n * Before running this Java V2 code example, set up your development \n * environment, including your credentials. \n * <p> \n * For more information, see the following documentation topic: \n * <p> \n * https://docs.aws.amazon.com/sdk-for-java/latest/developer-guide/get-\nstarted.html \n */\npublic class SetWebsiteConfiguration { \n    public static void main(String[] args) { \n        final String usage = \"\"\" \n            Usage:    <bucketName> [indexdoc]\\s \n            Where: \n               bucketName   - The Amazon S3 bucket to set the website \n configuration on.\\s \n               indexdoc - The index document, ex.", "'index.html' \n                          If not specified, 'index.html' will be set.", "\n            \"\"\"; \n        if (args.length != 1) { \n            System.out.println(usage); \n            System.exit(1); \n        } \n        String bucketName = args[0]; \n        String indexDoc = \"index.html\"; \n        Region region = Region.US_EAST_1; \n        S3Client s3 = S3Client.builder() \n            .region(region) \n            .build(); \n        setWebsiteConfig(s3, bucketName, indexDoc); \n        s3.close(); \nBasics API Version 2006-03-01 2199Amazon Simple Storage Service API Reference\n    } \n    /** \n     * Sets the website configuration for an Amazon S3 bucket. \n     * \n     * @param s3 The {@link S3Client} instance to use for the AWS SDK operations. \n     * @param bucketName The name of the S3 bucket to configure.", "\n     * @param indexDoc The name of the index document to use for the website \n configuration.", "\n     */ \n    public static void setWebsiteConfig(S3Client s3, String bucketName, String \n indexDoc) { \n        try { \n            WebsiteConfiguration websiteConfig = WebsiteConfiguration.builder() \n                .indexDocument(IndexDocument.builder().suffix(indexDoc).build()) \n                .build(); \n            PutBucketWebsiteRequest pubWebsiteReq = \n PutBucketWebsiteRequest.builder() \n                .bucket(bucketName) \n                .websiteConfiguration(websiteConfig) \n                .build(); \n            s3.putBucketWebsite(pubWebsiteReq); \n            System.out.println(\"The call was successful\"); \n        } catch (S3Exception e) { \n            System.err.println(e.awsErrorDetails().errorMessage()); \n            System.exit(1); \n        } \n    }\n}\n\u2022For API details, see PutBucketWebsite in AWS SDK for Java 2.x API Reference.\nBasics API Version 2006-03-01 2200Amazon Simple Storage Service API Reference\nJavaScript\nSDK for JavaScript (v3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nSet the website con\ufb01guration.\nimport { \n  PutBucketWebsiteCommand, \n  S3Client, \n  S3ServiceException,\n} from \"@aws-sdk/client-s3\";\n/** \n * Configure an Amazon S3 bucket to serve a static website.", "\n * Website access must also be granted separately.", "For more information \n * on setting the permissions for website access, see \n * https://docs.aws.amazon.com/AmazonS3/latest/userguide/\nWebsiteAccessPermissionsReqd.html.", "\n * \n * @param {{ bucketName: string }} \n */\nexport const main = async ({ bucketName }) => { \n  const client = new S3Client({}); \n  const command = new PutBucketWebsiteCommand({ \n    Bucket: bucketName, \n    WebsiteConfiguration: { \n      ErrorDocument: { \n        // The object key name to use when a 4XX class error occurs.", "\n        Key: \"error.html\", \n      }, \n      IndexDocument: { \n        // A suffix that is appended to a request when the request is \n        // for a directory.", "\n        Suffix: \"index.html\", \n      }, \n    }, \n  }); \nBasics API Version 2006-03-01 2201Amazon Simple Storage Service API Reference\n  try { \n    await client.send(command); \n    console.log( \n      `The bucket \"${bucketName}\" has been configured as a static website.`, \n    ); \n  } catch (caught) { \n    if ( \n      caught instanceof S3ServiceException && \n      caught.name === \"NoSuchBucket\" \n    ) { \n      console.error( \n        `Error from S3 while configuring the bucket \"${bucketName}\" as a static \n website. The bucket doesn't exist.`, \n      ); \n    } else if (caught instanceof S3ServiceException) { \n      console.error( \n        `Error from S3 while configuring the bucket \"${bucketName}\" as a static \n website.", "${caught.name}: ${caught.message}`, \n      ); \n    } else { \n      throw caught; \n    } \n  }\n};\n\u2022For more information, see AWS SDK for JavaScript Developer Guide.\n\u2022For API details, see PutBucketWebsite in AWS SDK for JavaScript API Reference.\nPowerShell\nTools for PowerShell\nExample 1: The command enables website hosting for the given bucket with the index \ndocument as 'index.html' and error document as 'error.html'.\nWrite-S3BucketWebsite -BucketName 'amzn-s3-demo-bucket' \n -WebsiteConfiguration_IndexDocumentSuffix 'index.html' -\nWebsiteConfiguration_ErrorDocument 'error.html'\n\u2022For API details, see PutBucketWebsite in AWS Tools for PowerShell Cmdlet Reference.\nBasics API Version 2006-03-01 2202Amazon Simple Storage Service API Reference\nRuby\nSDK for Ruby\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nrequire 'aws-sdk-s3'\n# Wraps Amazon S3 bucket website actions.\nclass BucketWebsiteWrapper \n  attr_reader :bucket_website \n  # @param bucket_website [Aws::S3::BucketWebsite] A bucket website object \n configured with an existing bucket.", "\n  def initialize(bucket_website) \n    @bucket_website = bucket_website \n  end \n  # Sets a bucket as a static website.", "\n  # \n  # @param index_document [String] The name of the index document for the \n website.", "\n  # @param error_document [String] The name of the error document to show for 4XX \n errors.", "\n  # @return [Boolean] True when the bucket is configured as a website; otherwise, \n false. \n  def set_website(index_document, error_document) \n    @bucket_website.put( \n      website_configuration: { \n        index_document: { suffix: index_document }, \n        error_document: { key: error_document } \n      } \n    ) \n    true \n  rescue Aws::Errors::ServiceError => e \n    puts \"Couldn't configure #{@bucket_website.bucket.name} as a website. Here's \n why: #{e.message}\" \n    false \nBasics API Version 2006-03-01 2203Amazon Simple Storage Service API Reference\n  end\nend\n# Example usage:\ndef run_demo\n<<<<<<< HEAD \n  bucket_name = \"amzn-s3-demo-bucket\" \n  index_document = \"index.html\" \n  error_document = \"404.html\"\n======= \n  bucket_name = 'doc-example-bucket' \n  index_document = 'index.html' \n  error_document = '404.html'\n>>>>>>> 999c6133e (fixes) \n  wrapper = BucketWebsiteWrapper.new(Aws::S3::BucketWebsite.new(bucket_name)) \n  return unless wrapper.set_website(index_document, error_document) \n  puts \"Successfully configured bucket #{bucket_name} as a static website.\"\nend\nrun_demo if $PROGRAM_NAME == __FILE__\n\u2022For API details, see PutBucketWebsite in AWS SDK for Ruby API Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nUse PutObject  with an AWS SDK or CLI\nThe following code examples show how to use PutObject .\nAction examples are code excerpts from larger programs and must be run in context.", "You can see \nthis action in context in the following code examples:\n\u2022Learn the basics\n\u2022Track uploads and downloads\n\u2022Work with Amazon S3 object integrity\nBasics API Version 2006-03-01 2204Amazon Simple Storage Service API Reference\n.NET\nAWS SDK for .NET\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n        /// <summary> \n        /// Shows how to upload a file from the local computer to an Amazon S3 \n        /// bucket. \n        /// </summary> \n        /// <param name=\"client\">An initialized Amazon S3 client object.</param> \n        /// <param name=\"bucketName\">The Amazon S3 bucket to which the object \n        /// will be uploaded.</param> \n        /// <param name=\"objectName\">The object to upload.</param> \n        /// <param name=\"filePath\">The path, including file name, of the object \n        /// on the local computer to upload.</param> \n        /// <returns>A boolean value indicating the success or failure of the \n        /// upload procedure.</returns> \n        public static async Task<bool> UploadFileAsync( \n            IAmazonS3 client, \n            string bucketName, \n            string objectName, \n            string filePath) \n        { \n            var request = new PutObjectRequest \n            { \n                BucketName = bucketName, \n                Key = objectName, \n                FilePath = filePath, \n            }; \n            var response = await client.PutObjectAsync(request); \n            if (response.HttpStatusCode == System.Net.HttpStatusCode.OK) \n            { \n                Console.WriteLine($\"Successfully uploaded {objectName} to \n {bucketName}.\"); \n                return true; \nBasics API Version 2006-03-01 2205Amazon Simple Storage Service API Reference\n            } \n            else \n            { \n                Console.WriteLine($\"Could not upload {objectName} to \n {bucketName}.\"); \n                return false; \n            } \n        }\nUpload an object with server-side encryption.\n    using System; \n    using System.Threading.Tasks; \n    using Amazon.S3; \n    using Amazon.S3.Model; \n    /// <summary> \n    /// This example shows how to upload an object to an Amazon Simple Storage \n    /// Service (Amazon S3) bucket with server-side encryption enabled. \n    /// </summary> \n    public class ServerSideEncryption \n    { \n        public static async Task Main() \n        { \n            string bucketName = \"amzn-s3-demo-bucket\"; \n            string keyName = \"samplefile.txt\"; \n            // If the AWS Region defined for your default user is different \n            // from the Region where your Amazon S3 bucket is located, \n            // pass the Region name to the Amazon S3 client object's constructor.", "\n            // For example: RegionEndpoint.USWest2.", "\n            IAmazonS3 client = new AmazonS3Client(); \n            await WritingAnObjectAsync(client, bucketName, keyName); \n        } \n        /// <summary> \n        /// Upload a sample object include a setting for encryption. \n        /// </summary> \n        /// <param name=\"client\">The initialized Amazon S3 client object used to \n        /// to upload a file and apply server-side encryption.</param> \nBasics API Version 2006-03-01 2206Amazon Simple Storage Service API Reference\n        /// <param name=\"bucketName\">The name of the Amazon S3 bucket where the \n        /// encrypted object will reside.</param> \n        /// <param name=\"keyName\">The name for the object that you want to \n        /// create in the supplied bucket.</param> \n        public static async Task WritingAnObjectAsync(IAmazonS3 client, string \n bucketName, string keyName) \n        { \n            try \n            { \n                var putRequest = new PutObjectRequest \n                { \n                    BucketName = bucketName, \n                    Key = keyName, \n                    ContentBody = \"sample text\", \n                    ServerSideEncryptionMethod = \n ServerSideEncryptionMethod.AES256, \n                }; \n                var putResponse = await client.PutObjectAsync(putRequest); \n                // Determine the encryption state of an object. \n                GetObjectMetadataRequest metadataRequest = new \n GetObjectMetadataRequest \n                { \n                    BucketName = bucketName, \n                    Key = keyName, \n                }; \n                GetObjectMetadataResponse response = await \n client.GetObjectMetadataAsync(metadataRequest); \n                ServerSideEncryptionMethod objectEncryption = \n response.ServerSideEncryptionMethod; \n                Console.WriteLine($\"Encryption method used: {0}\", \n objectEncryption.ToString()); \n            } \n            catch (AmazonS3Exception ex) \n            { \n                Console.WriteLine($\"Error: '{ex.Message}' when writing an \n object\"); \n            } \n        } \n    }\nBasics API Version 2006-03-01 2207Amazon Simple Storage Service API Reference\n\u2022For API details, see PutObject in AWS SDK for .NET API Reference.\nBash\nAWS CLI with Bash script\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n###############################################################################\n# function errecho\n#\n# This function outputs everything sent to it to STDERR (standard error output).\n###############################################################################\nfunction errecho() { \n  printf \"%s\\n\" \"$*\" 1>&2\n}\n###############################################################################\n# function copy_file_to_bucket\n#\n# This function creates a file in the specified bucket.\n#\n# Parameters:\n#       $1 - The name of the bucket to copy the file to.\n#       $2 - The path and file name of the local file to copy to the bucket.\n#       $3 - The key (name) to call the copy of the file in the bucket.\n#\n# Returns:\n#       0 - If successful.\n#       1 - If it fails.\n###############################################################################\nfunction copy_file_to_bucket() { \n  local response bucket_name source_file destination_file_name \n  bucket_name=$1 \n  source_file=$2 \n  destination_file_name=$3 \nBasics API Version 2006-03-01 2208Amazon Simple Storage Service API Reference\n  response=$(aws s3api put-object \\ \n    --bucket \"$bucket_name\" \\ \n    --body \"$source_file\" \\ \n    --key \"$destination_file_name\") \n  # shellcheck disable=SC2181 \n  if [[ ${?} -ne 0 ]]; then \n    errecho \"ERROR: AWS reports put-object operation failed.\\n$response\" \n    return 1 \n  fi\n}\n\u2022For API details, see PutObject in AWS CLI Command Reference.\nC++\nSDK for C++\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nbool AwsDoc::S3::putObject(const Aws::String &bucketName, \n                           const Aws::String &fileName, \n                           const Aws::S3::S3ClientConfiguration &clientConfig) { \n    Aws::S3::S3Client s3Client(clientConfig); \n    Aws::S3::Model::PutObjectRequest request; \n    request.SetBucket(bucketName); \n    //We are using the name of the file as the key for the object in the bucket.", "\n    //However, this is just a string and can be set according to your retrieval \n needs.", "\n    request.SetKey(fileName); \n    std::shared_ptr<Aws::IOStream> inputData = \n            Aws::MakeShared<Aws::FStream>(\"SampleAllocationTag\", \n                                          fileName.c_str(), \nBasics API Version 2006-03-01 2209Amazon Simple Storage Service API Reference\n                                          std::ios_base::in | \n std::ios_base::binary); \n    if (!*inputData) { \n        std::cerr << \"Error unable to read file \" << fileName << std::endl; \n        return false; \n    } \n    request.SetBody(inputData); \n    Aws::S3::Model::PutObjectOutcome outcome = \n            s3Client.PutObject(request); \n    if (!outcome.IsSuccess()) { \n        std::cerr << \"Error: putObject: \" << \n                  outcome.GetError().GetMessage() << std::endl; \n    } else { \n        std::cout << \"Added object '\" << fileName << \"' to bucket '\" \n                  << bucketName << \"'.\"; \n    } \n    return outcome.IsSuccess();\n}\n\u2022For API details, see PutObject in AWS SDK for C++ API Reference.\nCLI\nAWS CLI\nThe following example uses the put-object  command to upload an object to Amazon S3:\naws s3api put-object --bucket text-content  --key dir-1/my_images.tar.bz2  --\nbody my_images.tar.bz2\nThe following example shows an upload of a video \ufb01le (The video \ufb01le is speci\ufb01ed using \nWindows \ufb01le system syntax.):\naws s3api put-object --bucket text-content  --key dir-1/big-video-file.mp4  --body \n e:\\media\\videos\\f-sharp-3-data-services.mp4\nBasics API Version 2006-03-01 2210Amazon Simple Storage Service API Reference\nFor more information about uploading objects, see Uploading Objects in the Amazon S3 \nDeveloper Guide .\n\u2022For API details, see PutObject in AWS CLI Command Reference.\nGo\nSDK for Go V2\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nPut an object in a bucket by using the low-level API.\n// BucketBasics encapsulates the Amazon Simple Storage Service (Amazon S3) \n actions\n// used in the examples.\n// It contains S3Client, an Amazon S3 service client that is used to perform \n bucket\n// and object actions.\ntype BucketBasics struct { \n S3Client *s3.Client\n}\n// UploadFile reads from a file and puts the data into an object in a bucket.\nfunc (basics BucketBasics) UploadFile(ctx context.Context, bucketName string, \n objectKey string, fileName string) error { \n file, err := os.Open(fileName) \n if err != nil { \n  log.Printf(\"Couldn't open file %v to upload. Here's why: %v\\n\", fileName, err) \n } else { \n  defer file.Close() \n  _, err = basics.S3Client.PutObject(ctx, &s3.PutObjectInput{ \n   Bucket: aws.String(bucketName), \n   Key:    aws.String(objectKey), \n   Body:   file, \nBasics API Version 2006-03-01 2211Amazon Simple Storage Service API Reference\n  }) \n  if err != nil { \n   log.Printf(\"Couldn't upload file %v to %v:%v. Here's why: %v\\n\", \n    fileName, bucketName, objectKey, err) \n  } \n } \n return err\n}\nUpload an object to a bucket by using a transfer manager.\n// S3Actions wraps S3 service actions.\ntype S3Actions struct { \n S3Client  *s3.Client \n S3Manager *manager.Uploader\n}\n// UploadObject uses the S3 upload manager to upload an object to a bucket.\nfunc (actor S3Actions) UploadObject(ctx context.Context, bucket string, key \n string, contents string) (string, error) { \n var outKey string \n input := &s3.PutObjectInput{ \n  Bucket:            aws.String(bucket), \n  Key:               aws.String(key), \n  Body:              bytes.NewReader([]byte(contents)), \n  ChecksumAlgorithm: types.ChecksumAlgorithmSha256, \n } \n output, err := actor.S3Manager.Upload(ctx, input) \n if err != nil { \n  var noBucket *types.NoSuchBucket \n  if errors.As(err, &noBucket) { \n   log.Printf(\"Bucket %s does not exist.\\n\", bucket) \n   err = noBucket \n  } \n } else { \n  err := s3.NewObjectExistsWaiter(actor.S3Client).Wait(ctx, &s3.HeadObjectInput{ \n   Bucket: aws.String(bucket), \n   Key:    aws.String(key), \nBasics API Version 2006-03-01 2212Amazon Simple Storage Service API Reference\n  }, time.Minute) \n  if err != nil { \n   log.Printf(\"Failed attempt to wait for object %s to exist in %s.\\n\", key, \n bucket) \n  } else { \n   outKey = *output.Key \n  } \n } \n return outKey, err\n}\n\u2022For API details, see PutObject in AWS SDK for Go API Reference.\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nUpload a \ufb01le to a bucket using an S3Client .\n    /** \n     * Uploads a local file to an AWS S3 bucket asynchronously. \n     * \n     * @param bucketName the name of the S3 bucket to upload the file to \n     * @param key        the key (object name) to use for the uploaded file \n     * @param objectPath the local file path of the file to be uploaded \n     * @return a {@link CompletableFuture} that completes with the {@link \n PutObjectResponse} when the upload is successful, or throws a {@link \n RuntimeException} if the upload fails \n     */ \n    public CompletableFuture<PutObjectResponse> uploadLocalFileAsync(String \n bucketName, String key, String objectPath) { \n        PutObjectRequest objectRequest = PutObjectRequest.builder() \n            .bucket(bucketName) \nBasics API Version 2006-03-01 2213Amazon Simple Storage Service API Reference\n            .key(key) \n            .build(); \n        CompletableFuture<PutObjectResponse> response = \n getAsyncClient().putObject(objectRequest, \n AsyncRequestBody.fromFile(Paths.get(objectPath))); \n        return response.whenComplete((resp, ex) -> { \n            if (ex != null) { \n                throw new RuntimeException(\"Failed to upload file\", ex); \n            } \n        }); \n    }\nUse an S3TransferManager to upload a \ufb01le  to a bucket. View the complete \ufb01le and test.\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\nimport software.amazon.awssdk.transfer.s3.S3TransferManager;\nimport software.amazon.awssdk.transfer.s3.model.CompletedFileUpload;\nimport software.amazon.awssdk.transfer.s3.model.FileUpload;\nimport software.amazon.awssdk.transfer.s3.model.UploadFileRequest;\nimport software.amazon.awssdk.transfer.s3.progress.LoggingTransferListener;\nimport java.net.URI;\nimport java.net.URISyntaxException;\nimport java.net.URL;\nimport java.nio.file.Paths;\nimport java.util.UUID; \n    public String uploadFile(S3TransferManager transferManager, String \n bucketName, \n                             String key, URI filePathURI) { \n        UploadFileRequest uploadFileRequest = UploadFileRequest.builder() \n            .putObjectRequest(b -> b.bucket(bucketName).key(key)) \n            .source(Paths.get(filePathURI)) \n            .build(); \n        FileUpload fileUpload = transferManager.uploadFile(uploadFileRequest); \n        CompletedFileUpload uploadResult = fileUpload.completionFuture().join(); \n        return uploadResult.response().eTag(); \n    }\nBasics API Version 2006-03-01 2214Amazon Simple Storage Service API Reference\nUpload an object to a bucket and set tags using an S3Client .\n    /** \n     * Puts tags on an Amazon S3 object. \n     * \n     * @param s3 An {@link S3Client} object that represents the Amazon S3 client. \n     * @param bucketName The name of the Amazon S3 bucket. \n     * @param objectKey The key of the Amazon S3 object.", "\n     * @param objectPath The file path of the object to be uploaded.", "\n     */ \n    public static void putS3ObjectTags(S3Client s3, String bucketName, String \n objectKey, String objectPath) { \n        try { \n            Tag tag1 = Tag.builder() \n                .key(\"Tag 1\") \n                .value(\"This is tag 1\") \n                .build(); \n            Tag tag2 = Tag.builder() \n                .key(\"Tag 2\") \n                .value(\"This is tag 2\") \n                .build(); \n            List<Tag> tags = new ArrayList<>(); \n            tags.add(tag1); \n            tags.add(tag2); \n            Tagging allTags = Tagging.builder() \n                .tagSet(tags) \n                .build(); \n            PutObjectRequest putOb = PutObjectRequest.builder() \n                .bucket(bucketName) \n                .key(objectKey) \n                .tagging(allTags) \n                .build(); \n            s3.putObject(putOb, \n RequestBody.fromBytes(getObjectFile(objectPath))); \n        } catch (S3Exception e) { \n            System.err.println(e.getMessage()); \n            System.exit(1); \n        } \nBasics API Version 2006-03-01 2215Amazon Simple Storage Service API Reference\n    } \n    /** \n     * Updates the tags associated with an object in an Amazon S3 bucket. \n     * \n     * @param s3 an instance of the S3Client class, which is used to interact \n with the Amazon S3 service \n     * @param bucketName the name of the S3 bucket containing the object \n     * @param objectKey the key (or name) of the object in the S3 bucket \n     * @throws S3Exception if there is an error updating the object's tags \n     */ \n    public static void updateObjectTags(S3Client s3, String bucketName, String \n objectKey) { \n        try { \n            GetObjectTaggingRequest taggingRequest = \n GetObjectTaggingRequest.builder() \n                .bucket(bucketName) \n                .key(objectKey) \n                .build(); \n            GetObjectTaggingResponse getTaggingRes = \n s3.getObjectTagging(taggingRequest); \n            List<Tag> obTags = getTaggingRes.tagSet(); \n            for (Tag sinTag : obTags) { \n                System.out.println(\"The tag key is: \" + sinTag.key()); \n                System.out.println(\"The tag value is: \" + sinTag.value()); \n            } \n            // Replace the object's tags with two new tags. \n            Tag tag3 = Tag.builder() \n                .key(\"Tag 3\") \n                .value(\"This is tag 3\") \n                .build(); \n            Tag tag4 = Tag.builder() \n                .key(\"Tag 4\") \n                .value(\"This is tag 4\") \n                .build(); \n            List<Tag> tags = new ArrayList<>(); \n            tags.add(tag3); \n            tags.add(tag4); \n            Tagging updatedTags = Tagging.builder() \nBasics API Version 2006-03-01 2216Amazon Simple Storage Service API Reference\n                .tagSet(tags) \n                .build(); \n            PutObjectTaggingRequest taggingRequest1 = \n PutObjectTaggingRequest.builder() \n                .bucket(bucketName) \n                .key(objectKey) \n                .tagging(updatedTags) \n                .build(); \n            s3.putObjectTagging(taggingRequest1); \n            GetObjectTaggingResponse getTaggingRes2 = \n s3.getObjectTagging(taggingRequest); \n            List<Tag> modTags = getTaggingRes2.tagSet(); \n            for (Tag sinTag : modTags) { \n                System.out.println(\"The tag key is: \" + sinTag.key()); \n                System.out.println(\"The tag value is: \" + sinTag.value()); \n            } \n        } catch (S3Exception e) { \n            System.err.println(e.getMessage()); \n            System.exit(1); \n        } \n    } \n    /** \n     * Retrieves the contents of a file as a byte array. \n     * \n     * @param filePath the path of the file to be read \n     * @return a byte array containing the contents of the file, or null if an \n error occurs \n     */ \n    private static byte[] getObjectFile(String filePath) { \n        FileInputStream fileInputStream = null; \n        byte[] bytesArray = null; \n        try { \n            File file = new File(filePath); \n            bytesArray = new byte[(int) file.length()]; \n            fileInputStream = new FileInputStream(file); \n            fileInputStream.read(bytesArray); \n        } catch (IOException e) { \n            e.printStackTrace(); \nBasics API Version 2006-03-01 2217Amazon Simple Storage Service API Reference\n        } finally { \n            if (fileInputStream != null) { \n                try { \n                    fileInputStream.close(); \n                } catch (IOException e) { \n                    e.printStackTrace(); \n                } \n            } \n        } \n        return bytesArray; \n    }\n}\nUpload an object to a bucket and set metadata using an S3Client .\nimport software.amazon.awssdk.core.sync.RequestBody;\nimport software.amazon.awssdk.regions.Region;\nimport software.amazon.awssdk.services.s3.S3Client;\nimport software.amazon.awssdk.services.s3.model.PutObjectRequest;\nimport software.amazon.awssdk.services.s3.model.S3Exception;\nimport java.io.File;\nimport java.util.HashMap;\nimport java.util.Map;\n/** \n * Before running this Java V2 code example, set up your development \n * environment, including your credentials. \n * <p> \n * For more information, see the following documentation topic: \n * <p> \n * https://docs.aws.amazon.com/sdk-for-java/latest/developer-guide/get-\nstarted.html \n */\npublic class PutObjectMetadata { \n    public static void main(String[] args) { \n        final String USAGE = \"\"\" \n            Usage: \n              <bucketName> <objectKey> <objectPath>\\s \nBasics API Version 2006-03-01 2218Amazon Simple Storage Service API Reference\n            Where: \n              bucketName - The Amazon S3 bucket to upload an object into.", "\n              objectKey - The object to upload (for example, book.pdf).", "\n              objectPath - The path where the file is located (for example, C:/\nAWS/book2.pdf).\\s \n            \"\"\"; \n        if (args.length != 3) { \n            System.out.println(USAGE); \n            System.exit(1); \n        } \n        String bucketName = args[0]; \n        String objectKey = args[1]; \n        String objectPath = args[2]; \n        System.out.println(\"Putting object \" + objectKey + \" into bucket \" + \n bucketName); \n        System.out.println(\"  in bucket: \" + bucketName); \n        Region region = Region.US_EAST_1; \n        S3Client s3 = S3Client.builder() \n            .region(region) \n            .build(); \n        putS3Object(s3, bucketName, objectKey, objectPath); \n        s3.close(); \n    } \n    /** \n     * Uploads an object to an Amazon S3 bucket with metadata. \n     * \n     * @param s3 the S3Client object used to interact with the Amazon S3 service \n     * @param bucketName the name of the S3 bucket to upload the object to \n     * @param objectKey the name of the object to be uploaded \n     * @param objectPath the local file path of the object to be uploaded \n     */ \n    public static void putS3Object(S3Client s3, String bucketName, String \n objectKey, String objectPath) { \n        try { \n            Map<String, String> metadata = new HashMap<>(); \n            metadata.put(\"author\", \"Mary Doe\"); \n            metadata.put(\"version\", \"1.0.0.0\"); \n            PutObjectRequest putOb = PutObjectRequest.builder() \nBasics API Version 2006-03-01 2219Amazon Simple Storage Service API Reference\n                .bucket(bucketName) \n                .key(objectKey) \n                .metadata(metadata) \n                .build(); \n            s3.putObject(putOb, RequestBody.fromFile(new File(objectPath))); \n            System.out.println(\"Successfully placed \" + objectKey + \" into bucket \n \" + bucketName); \n        } catch (S3Exception e) { \n            System.err.println(e.getMessage()); \n            System.exit(1); \n        } \n    }\n}\nUpload an object to a bucket and set an object retention value using an S3Client .\nimport software.amazon.awssdk.regions.Region;\nimport software.amazon.awssdk.services.s3.S3Client;\nimport software.amazon.awssdk.services.s3.model.PutObjectRetentionRequest;\nimport software.amazon.awssdk.services.s3.model.ObjectLockRetention;\nimport software.amazon.awssdk.services.s3.model.S3Exception;\nimport java.time.Instant;\nimport java.time.LocalDate;\nimport java.time.LocalDateTime;\nimport java.time.ZoneOffset;\n/** \n * Before running this Java V2 code example, set up your development \n * environment, including your credentials. \n * <p> \n * For more information, see the following documentation topic: \n * <p> \n * https://docs.aws.amazon.com/sdk-for-java/latest/developer-guide/get-\nstarted.html \n */\npublic class PutObjectRetention { \n    public static void main(String[] args) { \nBasics API Version 2006-03-01 2220Amazon Simple Storage Service API Reference\n        final String usage = \"\"\" \n            Usage: \n                <key> <bucketName>\\s \n            Where: \n                key - The name of the object (for example, book.pdf).\\s \n                bucketName - The Amazon S3 bucket name that contains the object \n (for example, bucket1).\\s \n            \"\"\"; \n        if (args.length != 2) { \n            System.out.println(usage); \n            System.exit(1); \n        } \n        String key = args[0]; \n        String bucketName = args[1]; \n        Region region = Region.US_EAST_1; \n        S3Client s3 = S3Client.builder() \n            .region(region) \n            .build(); \n        setRentionPeriod(s3, key, bucketName); \n        s3.close(); \n    } \n    /** \n     * Sets the retention period for an object in an Amazon S3 bucket. \n     * \n     * @param s3     the S3Client object used to interact with the Amazon S3 \n service \n     * @param key    the key (name) of the object in the S3 bucket \n     * @param bucket the name of the S3 bucket where the object is stored \n     * \n     * @throws S3Exception if an error occurs while setting the object retention \n period \n     */ \n    public static void setRentionPeriod(S3Client s3, String key, String bucket) { \n        try { \n            LocalDate localDate = LocalDate.parse(\"2020-07-17\"); \n            LocalDateTime localDateTime = localDate.atStartOfDay(); \n            Instant instant = localDateTime.toInstant(ZoneOffset.UTC); \nBasics API Version 2006-03-01 2221Amazon Simple Storage Service API Reference\n            ObjectLockRetention lockRetention = ObjectLockRetention.builder() \n                .mode(\"COMPLIANCE\") \n                .retainUntilDate(instant) \n                .build(); \n            PutObjectRetentionRequest retentionRequest = \n PutObjectRetentionRequest.builder() \n                .bucket(bucket) \n                .key(key) \n                .bypassGovernanceRetention(true) \n                .retention(lockRetention) \n                .build(); \n            // To set Retention on an object, the Amazon S3 bucket must support \n object \n            // locking, otherwise an exception is thrown. \n            s3.putObjectRetention(retentionRequest); \n            System.out.print(\"An object retention configuration was successfully \n placed on the object\"); \n        } catch (S3Exception e) { \n            System.err.println(e.awsErrorDetails().errorMessage()); \n            System.exit(1); \n        } \n    }\n}\n\u2022For API details, see PutObject in AWS SDK for Java 2.x API Reference.\nJavaScript\nSDK for JavaScript (v3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nUpload the object.\nBasics API Version 2006-03-01 2222Amazon Simple Storage Service API Reference\nimport { readFile } from \"node:fs/promises\";\nimport { \n  PutObjectCommand, \n  S3Client, \n  S3ServiceException,\n} from \"@aws-sdk/client-s3\";\n/** \n * Upload a file to an S3 bucket. \n * @param {{ bucketName: string, key: string, filePath: string }} \n */\nexport const main = async ({ bucketName, key, filePath }) => { \n  const client = new S3Client({}); \n  const command = new PutObjectCommand({ \n    Bucket: bucketName, \n    Key: key, \n    Body: await readFile(filePath), \n  }); \n  try { \n    const response = await client.send(command); \n    console.log(response); \n  } catch (caught) { \n    if ( \n      caught instanceof S3ServiceException && \n      caught.name === \"EntityTooLarge\" \n    ) { \n      console.error( \n        `Error from S3 while uploading object to ${bucketName}.", "\\\nThe object was too large.", "To upload objects larger than 5GB, use the S3 console \n (160GB max) \\\nor the multipart upload API (5TB max).`, \n      ); \n    } else if (caught instanceof S3ServiceException) { \n      console.error( \n        `Error from S3 while uploading object to ${bucketName}.", "${caught.name}: \n ${caught.message}`, \n      ); \n    } else { \n      throw caught; \n    } \n  }\nBasics API Version 2006-03-01 2223Amazon Simple Storage Service API Reference\n};\n\u2022For more information, see AWS SDK for JavaScript Developer Guide.\n\u2022For API details, see PutObject in AWS SDK for JavaScript API Reference.\nKotlin\nSDK for Kotlin\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nsuspend fun putS3Object( \n    bucketName: String, \n    objectKey: String, \n    objectPath: String,\n) { \n    val metadataVal = mutableMapOf<String, String>() \n    metadataVal[\"myVal\"] = \"test\" \n    val request = \n        PutObjectRequest { \n            bucket = bucketName \n            key = objectKey \n            metadata = metadataVal \n            body = File(objectPath).asByteStream() \n        } \n    S3Client { region = \"us-east-1\" }.use { s3 -> \n        val response = s3.putObject(request) \n        println(\"Tag information is ${response.eTag}\") \n    }\n}\n\u2022For API details, see PutObject in AWS SDK for Kotlin API reference.\nBasics API Version 2006-03-01 2224Amazon Simple Storage Service API Reference\nPHP\nSDK for PHP\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nUpload an object to a bucket.\n        $s3client = new Aws\\S3\\S3Client(['region' => 'us-west-2']); \n        $fileName = __DIR__ .", "\"/local-file-\" .", "uniqid(); \n        try { \n            $this->s3client->putObject([ \n                'Bucket' => $this->bucketName, \n                'Key' => $fileName, \n                'SourceFile' => __DIR__ .", "'/testfile.txt' \n            ]); \n            echo \"Uploaded $fileName to $this->bucketName.\\n\"; \n        } catch (Exception $exception) { \n            echo \"Failed to upload $fileName with error: \" . $exception-\n>getMessage(); \n            exit(\"Please fix error with file upload before continuing.\"); \n        }\n\u2022For API details, see PutObject in AWS SDK for PHP API Reference.\nPowerShell\nTools for PowerShell\nExample 1: This command uploads the single \ufb01le \"local-sample.txt\" to Amazon S3, \ncreating an object with key \"sample.txt\" in bucket \"test-\ufb01les\".\nWrite-S3Object -BucketName amzn-s3-demo-bucket -Key \"sample.txt\" -File .\\local-\nsample.txt\nBasics API Version 2006-03-01 2225Amazon Simple Storage Service API Reference\nExample 2: This command uploads the single \ufb01le \"sample.txt\" to Amazon S3, creating an \nobject with key \"sample.txt\" in bucket \"test-\ufb01les\". If the -Key parameter is not supplied, \nthe \ufb01lename is used as the S3 object key.\nWrite-S3Object -BucketName amzn-s3-demo-bucket -File .\\sample.txt\nExample 3: This command uploads the single \ufb01le \"local-sample.txt\" to Amazon S3, \ncreating an object with key \"pre\ufb01x/to/sample.txt\" in bucket \"test-\ufb01les\".\nWrite-S3Object -BucketName amzn-s3-demo-bucket -Key \"prefix/to/sample.txt\" -\nFile .\\local-sample.txt\nExample 4: This command uploads all \ufb01les in the subdirectory \"Scripts\" to the bucket \n\"test-\ufb01les\" and applies the common key pre\ufb01x \"SampleScripts\" to each object. Each \nuploaded \ufb01le will have a key of \"SampleScripts/\ufb01lename\" where '\ufb01lename' varies.\nWrite-S3Object -BucketName amzn-s3-demo-bucket -Folder .\\Scripts -KeyPrefix \n SampleScripts\\\nExample 5: This command uploads all *.ps1 \ufb01les in the local director \"Scripts\" to bucket \n\"test-\ufb01les\" and applies the common key pre\ufb01x \"SampleScripts\" to each object. Each \nuploaded \ufb01le will have a key of \"SampleScripts/\ufb01lename.ps1\" where '\ufb01lename' varies.\nWrite-S3Object -BucketName amzn-s3-demo-bucket -Folder .\\Scripts -KeyPrefix \n SampleScripts\\ -SearchPattern *.ps1\nExample 6: This command creates a new S3 object containing the speci\ufb01ed content string \nwith key 'sample.txt'.\nWrite-S3Object -BucketName amzn-s3-demo-bucket -Key \"sample.txt\" -Content \"object \n contents\"\nExample 7: This command uploads the speci\ufb01ed \ufb01le (the \ufb01lename is used as the key) and \napplies the speci\ufb01ed tags to the new object.\nWrite-S3Object -BucketName amzn-s3-demo-bucket -File \"sample.txt\" -TagSet \n @{Key=\"key1\";Value=\"value1\"},@{Key=\"key2\";Value=\"value2\"}\nBasics API Version 2006-03-01 2226Amazon Simple Storage Service API Reference\nExample 8: This command recursively uploads the speci\ufb01ed folder and applies the \nspeci\ufb01ed tags to all the new objects.\nWrite-S3Object -BucketName amzn-s3-demo-bucket -Folder .", "-KeyPrefix \"TaggedFiles\" \n -Recurse -TagSet @{Key=\"key1\";Value=\"value1\"},@{Key=\"key2\";Value=\"value2\"}\n\u2022For API details, see PutObject in AWS Tools for PowerShell Cmdlet Reference.\nPython\nSDK for Python (Boto3)\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nclass ObjectWrapper: \n    \"\"\"Encapsulates S3 object actions.\"\"\" \n    def __init__(self, s3_object): \n        \"\"\" \n        :param s3_object: A Boto3 Object resource. This is a high-level resource \n in Boto3 \n                          that wraps object actions in a class-like structure.", "\n        \"\"\" \n        self.object = s3_object \n        self.key = self.object.key \n    def put(self, data): \n        \"\"\" \n        Upload data to the object.", "\n        :param data: The data to upload.", "This can either be bytes or a string. \n When this \n                     argument is a string, it is interpreted as a file name, \n which is \n                     opened in read bytes mode. \n        \"\"\" \nBasics API Version 2006-03-01 2227Amazon Simple Storage Service API Reference\n        put_data = data \n        if isinstance(data, str): \n            try: \n                put_data = open(data, \"rb\") \n            except IOError: \n                logger.exception(\"Expected file name or binary data, got '%s'.\", \n data) \n                raise \n        try: \n            self.object.put(Body=put_data) \n            self.object.wait_until_exists() \n            logger.info( \n                \"Put object '%s' to bucket '%s'.\", \n                self.object.key, \n                self.object.bucket_name, \n            ) \n        except ClientError: \n            logger.exception( \n                \"Couldn't put object '%s' to bucket '%s'.\", \n                self.object.key, \n                self.object.bucket_name, \n            ) \n            raise \n        finally: \n            if getattr(put_data, \"close\", None): \n                put_data.close()\n\u2022For API details, see PutObject in AWS SDK for Python (Boto3) API Reference.\nRuby\nSDK for Ruby\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nBasics API Version 2006-03-01 2228Amazon Simple Storage Service API Reference\nUpload a \ufb01le using a managed uploader (Object.upload_\ufb01le).\nrequire 'aws-sdk-s3'\n# Wraps Amazon S3 object actions.\nclass ObjectUploadFileWrapper \n  attr_reader :object \n  # @param object [Aws::S3::Object] An existing Amazon S3 object. \n  def initialize(object) \n    @object = object \n  end \n  # Uploads a file to an Amazon S3 object by using a managed uploader.", "\n  # \n  # @param file_path [String] The path to the file to upload. \n  # @return [Boolean] True when the file is uploaded; otherwise false.", "\n  def upload_file(file_path) \n    @object.upload_file(file_path) \n    true \n  rescue Aws::Errors::ServiceError => e \n    puts \"Couldn't upload file #{file_path} to #{@object.key}. Here's why: \n #{e.message}\" \n    false \n  end\nend\n# Example usage:\ndef run_demo\n<<<<<<< HEAD \n  bucket_name = \"amzn-s3-demo-bucket\" \n  object_key = \"my-uploaded-file\" \n  file_path = \"object_upload_file.rb\"\n======= \n  bucket_name = 'doc-example-bucket' \n  object_key = 'my-uploaded-file' \n  file_path = 'object_upload_file.rb'\n>>>>>>> 999c6133e (fixes) \n  wrapper = ObjectUploadFileWrapper.new(Aws::S3::Object.new(bucket_name, \n object_key)) \n  return unless wrapper.upload_file(file_path) \n  puts \"File #{file_path} successfully uploaded to #{bucket_name}:#{object_key}.\"\nBasics API Version 2006-03-01 2229Amazon Simple Storage Service API Reference\nend\nrun_demo if $PROGRAM_NAME == __FILE__\nUpload a \ufb01le using Object.put.\nrequire 'aws-sdk-s3'\n# Wraps Amazon S3 object actions.\nclass ObjectPutWrapper \n  attr_reader :object \n  # @param object [Aws::S3::Object] An existing Amazon S3 object. \n  def initialize(object) \n    @object = object \n  end \n  def put_object(source_file_path) \n    File.open(source_file_path, 'rb') do |file| \n      @object.put(body: file) \n    end \n    true \n  rescue Aws::Errors::ServiceError => e \n    puts \"Couldn't put #{source_file_path} to #{object.key}. Here's why: \n #{e.message}\" \n    false \n  end\nend\n# Example usage:\ndef run_demo\n<<<<<<< HEAD \n  bucket_name = \"amzn-s3-demo-bucket\" \n  object_key = \"my-object-key\" \n  file_path = \"my-local-file.txt\"\n======= \n  bucket_name = 'doc-example-bucket' \n  object_key = 'my-object-key' \n  file_path = 'my-local-file.txt'\n>>>>>>> 999c6133e (fixes) \n  wrapper = ObjectPutWrapper.new(Aws::S3::Object.new(bucket_name, object_key)) \nBasics API Version 2006-03-01 2230Amazon Simple Storage Service API Reference\n  success = wrapper.put_object(file_path) \n  return unless success \n  puts \"Put file #{file_path} into #{object_key} in #{bucket_name}.\"\nend\nrun_demo if $PROGRAM_NAME == __FILE__\nUpload a \ufb01le using Object.put and add server-side encryption.\nrequire 'aws-sdk-s3'\n# Wraps Amazon S3 object actions.\nclass ObjectPutSseWrapper \n  attr_reader :object \n  # @param object [Aws::S3::Object] An existing Amazon S3 object.", "\n  def initialize(object) \n    @object = object \n  end \n  def put_object_encrypted(object_content, encryption) \n    @object.put(body: object_content, server_side_encryption: encryption) \n    true \n  rescue Aws::Errors::ServiceError => e \n    puts \"Couldn't put your content to #{object.key}. Here's why: #{e.message}\" \n    false \n  end\nend\n# Example usage:\ndef run_demo\n<<<<<<< HEAD \n  bucket_name = \"amzn-s3-demo-bucket\" \n  object_key = \"my-encrypted-content\" \n  object_content = \"This is my super-secret content.\" \n  encryption = \"AES256\"\n======= \n  bucket_name = 'doc-example-bucket' \n  object_key = 'my-encrypted-content' \n  object_content = 'This is my super-secret content.' \n  encryption = 'AES256'\nBasics API Version 2006-03-01 2231Amazon Simple Storage Service API Reference\n>>>>>>> 999c6133e (fixes) \n  wrapper = ObjectPutSseWrapper.new(Aws::S3::Object.new(bucket_name, \n object_content)) \n  return unless wrapper.put_object_encrypted(object_content, encryption) \n  puts \"Put your content into #{bucket_name}:#{object_key} and encrypted it with \n #{encryption}.\"\nend\nrun_demo if $PROGRAM_NAME == __FILE__\n\u2022For API details, see PutObject in AWS SDK for Ruby API Reference.\nRust\nSDK for Rust\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\npub async fn upload_object( \n    client: &aws_sdk_s3::Client, \n    bucket_name: &str, \n    file_name: &str, \n    key: &str,\n) -> Result<aws_sdk_s3::operation::put_object::PutObjectOutput, S3ExampleError> { \n    let body = \n aws_sdk_s3::primitives::ByteStream::from_path(std::path::Path::new(file_name)).await; \n    client \n        .put_object() \n        .bucket(bucket_name) \n        .key(key) \n        .body(body.unwrap()) \n        .send() \n        .await \n        .map_err(S3ExampleError::from)\n}\nBasics API Version 2006-03-01 2232Amazon Simple Storage Service API Reference\n\u2022For API details, see PutObject in AWS SDK for Rust API reference.\nSAP ABAP\nSDK for SAP ABAP\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n    \"Get contents of file from application server.\" \n    DATA lv_body TYPE xstring.", "\n    OPEN DATASET iv_file_name FOR INPUT IN BINARY MODE. \n    READ DATASET iv_file_name INTO lv_body. \n    CLOSE DATASET iv_file_name.", "\n    \"Upload/put an object to an S3 bucket.\" \n    TRY. \n        lo_s3->putobject( \n            iv_bucket = iv_bucket_name \n            iv_key = iv_file_name \n            iv_body = lv_body \n        ). \n        MESSAGE 'Object uploaded to S3 bucket.' TYPE 'I'.", "\n      CATCH /aws1/cx_s3_nosuchbucket.", "\n        MESSAGE 'Bucket does not exist.' TYPE 'E'.", "\n    ENDTRY.\n\u2022For API details, see PutObject in AWS SDK for SAP ABAP API reference.\nBasics API Version 2006-03-01 2233Amazon Simple Storage Service API Reference\nSwift\nSDK for Swift\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nimport AWSS3\nimport Smithy \n    public func uploadFile(bucket: String, key: String, file: String) async \n throws { \n        let fileUrl = URL(fileURLWithPath: file) \n        do { \n            let fileData = try Data(contentsOf: fileUrl) \n            let dataStream = ByteStream.data(fileData) \n            let input = PutObjectInput( \n                body: dataStream, \n                bucket: bucket, \n                key: key \n            ) \n            _ = try await client.putObject(input: input) \n        } \n        catch { \n            print(\"ERROR: \", dump(error, name: \"Putting an object.\")) \n            throw error \n        } \n    }\nimport AWSS3\nimport Smithy \n    public func createFile(bucket: String, key: String, withData data: Data) \n async throws { \n        let dataStream = ByteStream.data(data) \nBasics API Version 2006-03-01 2234Amazon Simple Storage Service API Reference\n        let input = PutObjectInput( \n            body: dataStream, \n            bucket: bucket, \n            key: key \n        ) \n        do { \n            _ = try await client.putObject(input: input) \n        } \n        catch { \n            print(\"ERROR: \", dump(error, name: \"Putting an object.\")) \n            throw error \n        } \n    }\n\u2022For API details, see PutObject in AWS SDK for Swift API reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nUse PutObjectAcl  with an AWS SDK or CLI\nThe following code examples show how to use PutObjectAcl .\nAction examples are code excerpts from larger programs and must be run in context.", "You can see \nthis action in context in the following code example:\n\u2022Manage access control lists (ACLs)\nC++\nSDK for C++\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nBasics API Version 2006-03-01 2235Amazon Simple Storage Service API Reference\nbool AwsDoc::S3::putObjectAcl(const Aws::String &bucketName, const Aws::String \n &objectKey, const Aws::String &ownerID, \n                              const Aws::String &granteePermission, const \n Aws::String &granteeType, \n                              const Aws::String &granteeID, const Aws::String \n &granteeEmailAddress, \n                              const Aws::String &granteeURI, const \n Aws::S3::S3ClientConfiguration &clientConfig) { \n    Aws::S3::S3Client s3Client(clientConfig); \n    Aws::S3::Model::Owner owner; \n    owner.SetID(ownerID); \n    Aws::S3::Model::Grantee grantee; \n    grantee.SetType(setGranteeType(granteeType)); \n    if (!granteeEmailAddress.empty()) { \n        grantee.SetEmailAddress(granteeEmailAddress); \n    } \n    if (!granteeID.empty()) { \n        grantee.SetID(granteeID); \n    } \n    if (!granteeURI.empty()) { \n        grantee.SetURI(granteeURI); \n    } \n    Aws::S3::Model::Grant grant; \n    grant.SetGrantee(grantee); \n    grant.SetPermission(setGranteePermission(granteePermission)); \n    Aws::Vector<Aws::S3::Model::Grant> grants; \n    grants.push_back(grant); \n    Aws::S3::Model::AccessControlPolicy acp; \n    acp.SetOwner(owner); \n    acp.SetGrants(grants); \n    Aws::S3::Model::PutObjectAclRequest request; \n    request.SetAccessControlPolicy(acp); \n    request.SetBucket(bucketName); \n    request.SetKey(objectKey); \nBasics API Version 2006-03-01 2236Amazon Simple Storage Service API Reference\n    Aws::S3::Model::PutObjectAclOutcome outcome = \n            s3Client.PutObjectAcl(request); \n    if (!outcome.IsSuccess()) { \n        auto error = outcome.GetError(); \n        std::cerr << \"Error: putObjectAcl: \" << error.GetExceptionName() \n                  << \" - \" << error.GetMessage() << std::endl; \n    } else { \n        std::cout << \"Successfully added an ACL to the object '\" << objectKey \n                  << \"' in the bucket '\" << bucketName << \"'.\" << std::endl; \n    } \n    return outcome.IsSuccess();\n}\n//!", "Routine which converts a human-readable string to a built-in type \n enumeration.\n/*!", "\n \\param access: Human readable string.", "\n \\return Permission: Permission enumeration.\n*/\nAws::S3::Model::Permission setGranteePermission(const Aws::String &access) { \n    if (access == \"FULL_CONTROL\") \n        return Aws::S3::Model::Permission::FULL_CONTROL; \n    if (access == \"WRITE\") \n        return Aws::S3::Model::Permission::WRITE; \n    if (access == \"READ\") \n        return Aws::S3::Model::Permission::READ; \n    if (access == \"WRITE_ACP\") \n        return Aws::S3::Model::Permission::WRITE_ACP; \n    if (access == \"READ_ACP\") \n        return Aws::S3::Model::Permission::READ_ACP; \n    return Aws::S3::Model::Permission::NOT_SET;\n}\n//!", "Routine which converts a human-readable string to a built-in type \n enumeration.\n/*! \n \\param type: Human readable string.", "\n \\return Type: Type enumeration.\n*/\nAws::S3::Model::Type setGranteeType(const Aws::String &type) { \n    if (type == \"Amazon customer by email\") \nBasics API Version 2006-03-01 2237Amazon Simple Storage Service API Reference\n        return Aws::S3::Model::Type::AmazonCustomerByEmail; \n    if (type == \"Canonical user\") \n        return Aws::S3::Model::Type::CanonicalUser; \n    if (type == \"Group\") \n        return Aws::S3::Model::Type::Group; \n    return Aws::S3::Model::Type::NOT_SET;\n}\n\u2022For API details, see PutObjectAcl in AWS SDK for C++ API Reference.\nCLI\nAWS CLI\nThe following command grants full control  to two AWS users (user1@example.com and\nuser2@example.com) and read permission to everyone:\naws s3api put-object-acl --bucket MyBucket  --key file.txt  --grant-full-\ncontrol emailaddress=user1@example.com,emailaddress=user2@example.com  --grant-\nread uri=http://acs.amazonaws.com/groups/global/AllUsers\nSee http://docs.aws.amazon.com/AmazonS3/latest/API/RESTBucketPUTacl.html for \ndetails on custom ACLs (the s3api ACL commands, such as put-object-acl , use the same \nshorthand argument notation).\n\u2022For API details, see PutObjectAcl in AWS CLI Command Reference.\nPython\nSDK for Python (Boto3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nclass ObjectWrapper: \nBasics API Version 2006-03-01 2238Amazon Simple Storage Service API Reference\n    \"\"\"Encapsulates S3 object actions.\"\"\" \n    def __init__(self, s3_object): \n        \"\"\" \n        :param s3_object: A Boto3 Object resource.", "This is a high-level resource \n in Boto3 \n                          that wraps object actions in a class-like structure.", "\n        \"\"\" \n        self.object = s3_object \n        self.key = self.object.key \n    def put_acl(self, email): \n        \"\"\" \n        Applies an ACL to the object that grants read access to an AWS user \n identified \n        by email address.", "\n        :param email: The email address of the user to grant access.", "\n        \"\"\" \n        try: \n            acl = self.object.Acl() \n            # Putting an ACL overwrites the existing ACL, so append new grants \n            # if you want to preserve existing grants. \n            grants = acl.grants if acl.grants else [] \n            grants.append( \n                { \n                    \"Grantee\": {\"Type\": \"AmazonCustomerByEmail\", \"EmailAddress\": \n email}, \n                    \"Permission\": \"READ\", \n                } \n            ) \n            acl.put(AccessControlPolicy={\"Grants\": grants, \"Owner\": acl.owner}) \n            logger.info(\"Granted read access to %s.\", email) \n        except ClientError: \n            logger.exception(\"Couldn't add ACL to object '%s'.\", self.object.key) \n            raise\n\u2022For API details, see PutObjectAcl in AWS SDK for Python (Boto3) API Reference.\nBasics API Version 2006-03-01 2239Amazon Simple Storage Service API Reference\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nUse PutObjectLegalHold  with an AWS SDK or CLI\nThe following code examples show how to use PutObjectLegalHold .\nAction examples are code excerpts from larger programs and must be run in context.", "You can see \nthis action in context in the following code example:\n\u2022Lock Amazon S3 objects\n.NET\nAWS SDK for .NET\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n    /// <summary> \n    /// Set or modify a legal hold on an object in an S3 bucket. \n    /// </summary> \n    /// <param name=\"bucketName\">The bucket of the object.</param> \n    /// <param name=\"objectKey\">The key of the object.</param> \n    /// <param name=\"holdStatus\">The On or Off status for the legal hold.</param> \n    /// <returns>True if successful.</returns> \n    public async Task<bool> ModifyObjectLegalHold(string bucketName, \n        string objectKey, ObjectLockLegalHoldStatus holdStatus) \n    { \n        try \n        { \n            var request = new PutObjectLegalHoldRequest() \n            { \n                BucketName = bucketName, \n                Key = objectKey, \n                LegalHold = new ObjectLockLegalHold() \n                { \nBasics API Version 2006-03-01 2240Amazon Simple Storage Service API Reference\n                    Status = holdStatus \n                } \n            }; \n            var response = await _amazonS3.PutObjectLegalHoldAsync(request); \n            Console.WriteLine($\"\\tModified legal hold for {objectKey} in \n {bucketName}.\"); \n            return response.HttpStatusCode == System.Net.HttpStatusCode.OK; \n        } \n        catch (AmazonS3Exception ex) \n        { \n            Console.WriteLine($\"\\tError modifying legal hold: '{ex.Message}'\"); \n            return false; \n        } \n    }\n\u2022For API details, see PutObjectLegalHold in AWS SDK for .NET API Reference.\nCLI\nAWS CLI\nTo apply a Legal Hold to an object\nThe following put-object-legal-hold  example sets a Legal Hold on the object\ndoc1.rtf .\naws s3api put-object-legal-hold \\ \n    --bucket my-bucket-with-object-lock  \\ \n    --key doc1.rtf  \\ \n    --legal-hold Status=ON\nThis command produces no output.\n\u2022For API details, see PutObjectLegalHold in AWS CLI Command Reference.\nBasics API Version 2006-03-01 2241Amazon Simple Storage Service API Reference\nGo\nSDK for Go V2\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n// S3Actions wraps S3 service actions.\ntype S3Actions struct { \n S3Client  *s3.Client \n S3Manager *manager.Uploader\n}\n// PutObjectLegalHold sets the legal hold configuration for an S3 object.\nfunc (actor S3Actions) PutObjectLegalHold(ctx context.Context, bucket string, key \n string, versionId string, legalHoldStatus types.ObjectLockLegalHoldStatus) error \n { \n input := &s3.PutObjectLegalHoldInput{ \n  Bucket: aws.String(bucket), \n  Key:    aws.String(key), \n  LegalHold: &types.ObjectLockLegalHold{ \n   Status: legalHoldStatus, \n  }, \n } \n if versionId != \"\" { \n  input.VersionId = aws.String(versionId) \n } \n _, err := actor.S3Client.PutObjectLegalHold(ctx, input) \n if err != nil { \n  var noKey *types.NoSuchKey \n  if errors.As(err, &noKey) { \n   log.Printf(\"Object %s does not exist in bucket %s.\\n\", key, bucket) \n   err = noKey \n  } \n } \nBasics API Version 2006-03-01 2242Amazon Simple Storage Service API Reference\n return err\n}\n\u2022For API details, see PutObjectLegalHold in AWS SDK for Go API Reference.\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n    // Set or modify a legal hold on an object in an S3 bucket.", "\n    public void modifyObjectLegalHold(String bucketName, String objectKey, \n boolean legalHoldOn) { \n        ObjectLockLegalHold legalHold ; \n        if (legalHoldOn) { \n            legalHold = ObjectLockLegalHold.builder() \n                .status(ObjectLockLegalHoldStatus.ON) \n                .build(); \n        } else { \n            legalHold = ObjectLockLegalHold.builder() \n                .status(ObjectLockLegalHoldStatus.OFF) \n                .build(); \n        } \n        PutObjectLegalHoldRequest legalHoldRequest = \n PutObjectLegalHoldRequest.builder() \n            .bucket(bucketName) \n            .key(objectKey) \n            .legalHold(legalHold) \n            .build(); \n        getClient().putObjectLegalHold(legalHoldRequest) ; \n        System.out.println(\"Modified legal hold for \"+ objectKey +\" in \n \"+bucketName +\".\"); \nBasics API Version 2006-03-01 2243Amazon Simple Storage Service API Reference\n    }\n\u2022For API details, see PutObjectLegalHold in AWS SDK for Java 2.x API Reference.\nJavaScript\nSDK for JavaScript (v3)\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nimport { \n  PutObjectLegalHoldCommand, \n  S3Client, \n  S3ServiceException,\n} from \"@aws-sdk/client-s3\";\n/** \n * Apply a legal hold configuration to the specified object.", "\n * @param {{ bucketName: string, objectKey: string, legalHoldStatus: \"ON\" | \n \"OFF\" }} \n */\nexport const main = async ({ bucketName, objectKey, legalHoldStatus }) => { \n  if (![\"OFF\", \"ON\"].includes(legalHoldStatus.toUpperCase())) { \n    throw new Error( \n      \"Invalid parameter. legalHoldStatus must be 'ON' or 'OFF'.\", \n    ); \n  } \n  const client = new S3Client({}); \n  const command = new PutObjectLegalHoldCommand({ \n    Bucket: bucketName, \n    Key: objectKey, \n    LegalHold: { \n      // Set the status to 'ON' to place a legal hold on the object.", "\n      // Set the status to 'OFF' to remove the legal hold.", "\n      Status: legalHoldStatus, \n    }, \nBasics API Version 2006-03-01 2244Amazon Simple Storage Service API Reference\n  }); \n  try { \n    await client.send(command); \n    console.log( \n      `Legal hold status set to \"${legalHoldStatus}\" for \"${objectKey}\" in \n \"${bucketName}\"`, \n    ); \n  } catch (caught) { \n    if ( \n      caught instanceof S3ServiceException && \n      caught.name === \"NoSuchBucket\" \n    ) { \n      console.error( \n        `Error from S3 while modifying legal hold status for \"${objectKey}\" in \n \"${bucketName}\". The bucket doesn't exist.`, \n      ); \n    } else if (caught instanceof S3ServiceException) { \n      console.error( \n        `Error from S3 while modifying legal hold status for \"${objectKey}\" in \n \"${bucketName}\".", "${caught.name}: ${caught.message}`, \n      ); \n    } else { \n      throw caught; \n    } \n  }\n};\n// Call function if run directly\nimport { parseArgs } from \"node:util\";\nimport { \n  isMain, \n  validateArgs,\n} from \"@aws-doc-sdk-examples/lib/utils/util-node.js\";\nconst loadArgs = () => { \n  const options = { \n    bucketName: { \n      type: \"string\", \n      required: true, \n    }, \n    objectKey: { \n      type: \"string\", \n      required: true, \nBasics API Version 2006-03-01 2245Amazon Simple Storage Service API Reference\n    }, \n    legalHoldStatus: { \n      type: \"string\", \n      default: \"ON\", \n    }, \n  }; \n  const results = parseArgs({ options }); \n  const { errors } = validateArgs({ options }, results); \n  return { errors, results };\n};\nif (isMain(import.meta.url)) { \n  const { errors, results } = loadArgs(); \n  if (!errors) { \n    main(results.values); \n  } else { \n    console.error(errors.join(\"\\n\")); \n  }\n}\n\u2022For API details, see PutObjectLegalHold in AWS SDK for JavaScript API Reference.\nPython\nSDK for Python (Boto3)\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nPut an object legal hold.\ndef set_legal_hold(s3_client, bucket: str, key: str) -> None: \n    \"\"\" \n    Set a legal hold on a specific file in a bucket. \n    Args: \n        s3_client: Boto3 S3 client.", "\n        bucket: The name of the bucket containing the file.", "\nBasics API Version 2006-03-01 2246Amazon Simple Storage Service API Reference\n        key: The key of the file to set the legal hold on.", "\n    \"\"\" \n    print() \n    logger.info(\"Setting legal hold on file [%s] in bucket [%s]\", key, bucket) \n    try: \n        before_status = \"OFF\" \n        after_status = \"ON\" \n        s3_client.put_object_legal_hold( \n            Bucket=bucket, Key=key, LegalHold={\"Status\": after_status} \n        ) \n        logger.debug( \n            \"Legal hold set successfully on file [%s] in bucket [%s]\", key, \n bucket \n        ) \n        _print_legal_hold_update(bucket, key, before_status, after_status) \n    except Exception as e: \n        logger.error( \n            \"Failed to set legal hold on file [%s] in bucket [%s]: %s\", key, \n bucket, e \n        )\n\u2022For API details, see PutObjectLegalHold in AWS SDK for Python (Boto3) API Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs.", "This topic also includes information about getting started and details \nabout previous SDK versions.\nUse PutObjectLockConfiguration  with an AWS SDK or CLI\nThe following code examples show how to use PutObjectLockConfiguration .\nAction examples are code excerpts from larger programs and must be run in context.", "You can see \nthis action in context in the following code example:\n\u2022Lock Amazon S3 objects\nBasics API Version 2006-03-01 2247Amazon Simple Storage Service API Reference\n.NET\nAWS SDK for .NET\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nSet the object lock con\ufb01guration of a bucket.\n    /// <summary> \n    /// Enable object lock on an existing bucket. \n    /// </summary> \n    /// <param name=\"bucketName\">The name of the bucket to modify.</param> \n    /// <returns>True if successful.</returns> \n    public async Task<bool> EnableObjectLockOnBucket(string bucketName) \n    { \n        try \n        { \n            // First, enable Versioning on the bucket. \n            await _amazonS3.PutBucketVersioningAsync(new \n PutBucketVersioningRequest() \n            { \n                BucketName = bucketName, \n                VersioningConfig = new S3BucketVersioningConfig() \n                { \n                    EnableMfaDelete = false, \n                    Status = VersionStatus.Enabled \n                } \n            }); \n            var request = new PutObjectLockConfigurationRequest() \n            { \n                BucketName = bucketName, \n                ObjectLockConfiguration = new ObjectLockConfiguration() \n                { \n                    ObjectLockEnabled = new ObjectLockEnabled(\"Enabled\"), \n                }, \n            }; \nBasics API Version 2006-03-01 2248Amazon Simple Storage Service API Reference\n            var response = await \n _amazonS3.PutObjectLockConfigurationAsync(request); \n            Console.WriteLine($\"\\tAdded an object lock policy to bucket \n {bucketName}.\"); \n            return response.HttpStatusCode == System.Net.HttpStatusCode.OK; \n        } \n        catch (AmazonS3Exception ex) \n        { \n            Console.WriteLine($\"Error modifying object lock: '{ex.Message}'\"); \n            return false; \n        } \n    }\nSet the default retention period of a bucket.\n    /// <summary> \n    /// Set or modify a retention period on an S3 bucket. \n    /// </summary> \n    /// <param name=\"bucketName\">The bucket to modify.</param> \n    /// <param name=\"retention\">The retention mode.</param> \n    /// <param name=\"retainUntilDate\">The date for retention until.</param> \n    /// <returns>True if successful.</returns> \n    public async Task<bool> ModifyBucketDefaultRetention(string bucketName, bool \n enableObjectLock, ObjectLockRetentionMode retention, DateTime retainUntilDate) \n    { \n        var enabledString = enableObjectLock ? \"Enabled\" : \"Disabled\"; \n        var timeDifference = retainUntilDate.Subtract(DateTime.Now); \n        try \n        { \n            // First, enable Versioning on the bucket. \n            await _amazonS3.PutBucketVersioningAsync(new \n PutBucketVersioningRequest() \n            { \n                BucketName = bucketName, \n                VersioningConfig = new S3BucketVersioningConfig() \n                { \n                    EnableMfaDelete = false, \n                    Status = VersionStatus.Enabled \n                } \n            }); \n            var request = new PutObjectLockConfigurationRequest() \nBasics API Version 2006-03-01 2249Amazon Simple Storage Service API Reference\n            { \n                BucketName = bucketName, \n                ObjectLockConfiguration = new ObjectLockConfiguration() \n                { \n                    ObjectLockEnabled = new ObjectLockEnabled(enabledString), \n                    Rule = new ObjectLockRule() \n                    { \n                        DefaultRetention = new DefaultRetention() \n                        { \n                            Mode = retention, \n                            Days = timeDifference.Days // Can be specified in \n days or years but not both. \n                        } \n                    } \n                } \n            }; \n            var response = await \n _amazonS3.PutObjectLockConfigurationAsync(request); \n            Console.WriteLine($\"\\tAdded a default retention to bucket \n {bucketName}.\"); \n            return response.HttpStatusCode == System.Net.HttpStatusCode.OK; \n        } \n        catch (AmazonS3Exception ex) \n        { \n            Console.WriteLine($\"\\tError modifying object lock: '{ex.Message}'\"); \n            return false; \n        } \n    }\n\u2022For API details, see PutObjectLockCon\ufb01guration in AWS SDK for .NET API Reference.\nCLI\nAWS CLI\nTo set an object lock con\ufb01guration on a bucket\nThe following put-object-lock-configuration  example sets a 50-day object lock on \nthe speci\ufb01ed bucket.\naws s3api put-object-lock-configuration \\ \nBasics API Version 2006-03-01 2250Amazon Simple Storage Service API Reference\n    --bucket my-bucket-with-object-lock  \\ \n    --object-lock-configuration ' { \"ObjectLockEnabled\": \"Enabled\", \"Rule\": \n { \"DefaultRetention\": { \"Mode\": \"COMPLIANCE\", \"Days\": 50 }}} '\nThis command produces no output.\n\u2022For API details, see PutObjectLockCon\ufb01guration in AWS CLI Command Reference.\nGo\nSDK for Go V2\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nSet the object lock con\ufb01guration of a bucket.\n// S3Actions wraps S3 service actions.\ntype S3Actions struct { \n S3Client  *s3.Client \n S3Manager *manager.Uploader\n}\n// EnableObjectLockOnBucket enables object locking on an existing bucket.\nfunc (actor S3Actions) EnableObjectLockOnBucket(ctx context.Context, bucket \n string) error { \n // Versioning must be enabled on the bucket before object locking is enabled. \n verInput := &s3.PutBucketVersioningInput{ \n  Bucket: aws.String(bucket), \n  VersioningConfiguration: &types.VersioningConfiguration{ \n   MFADelete: types.MFADeleteDisabled, \n   Status:    types.BucketVersioningStatusEnabled, \n  }, \n } \n _, err := actor.S3Client.PutBucketVersioning(ctx, verInput) \n if err != nil { \nBasics API Version 2006-03-01 2251Amazon Simple Storage Service API Reference\n  var noBucket *types.NoSuchBucket \n  if errors.As(err, &noBucket) { \n   log.Printf(\"Bucket %s does not exist.\\n\", bucket) \n   err = noBucket \n  } \n  return err \n } \n input := &s3.PutObjectLockConfigurationInput{ \n  Bucket: aws.String(bucket), \n  ObjectLockConfiguration: &types.ObjectLockConfiguration{ \n   ObjectLockEnabled: types.ObjectLockEnabledEnabled, \n  }, \n } \n _, err = actor.S3Client.PutObjectLockConfiguration(ctx, input) \n if err != nil { \n  var noBucket *types.NoSuchBucket \n  if errors.As(err, &noBucket) { \n   log.Printf(\"Bucket %s does not exist.\\n\", bucket) \n   err = noBucket \n  } \n } \n return err\n}\nSet the default retention period of a bucket.\n// S3Actions wraps S3 service actions.\ntype S3Actions struct { \n S3Client  *s3.Client \n S3Manager *manager.Uploader\n}\n// ModifyDefaultBucketRetention modifies the default retention period of an \n existing bucket.\nfunc (actor S3Actions) ModifyDefaultBucketRetention( \nBasics API Version 2006-03-01 2252Amazon Simple Storage Service API Reference\n ctx context.Context, bucket string, lockMode types.ObjectLockEnabled, \n retentionPeriod int32, retentionMode types.ObjectLockRetentionMode) error { \n input := &s3.PutObjectLockConfigurationInput{ \n  Bucket: aws.String(bucket), \n  ObjectLockConfiguration: &types.ObjectLockConfiguration{ \n   ObjectLockEnabled: lockMode, \n   Rule: &types.ObjectLockRule{ \n    DefaultRetention: &types.DefaultRetention{ \n     Days: aws.Int32(retentionPeriod), \n     Mode: retentionMode, \n    }, \n   }, \n  }, \n } \n _, err := actor.S3Client.PutObjectLockConfiguration(ctx, input) \n if err != nil { \n  var noBucket *types.NoSuchBucket \n  if errors.As(err, &noBucket) { \n   log.Printf(\"Bucket %s does not exist.\\n\", bucket) \n   err = noBucket \n  } \n } \n return err\n}\n\u2022For API details, see PutObjectLockCon\ufb01guration in AWS SDK for Go API Reference.\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nSet the object lock con\ufb01guration of a bucket.\nBasics API Version 2006-03-01 2253Amazon Simple Storage Service API Reference\n    // Enable object lock on an existing bucket. \n    public void enableObjectLockOnBucket(String bucketName) { \n        try { \n            VersioningConfiguration versioningConfiguration = \n VersioningConfiguration.builder() \n                .status(BucketVersioningStatus.ENABLED) \n                .build(); \n            PutBucketVersioningRequest putBucketVersioningRequest = \n PutBucketVersioningRequest.builder() \n                .bucket(bucketName) \n                .versioningConfiguration(versioningConfiguration) \n                .build(); \n            // Enable versioning on the bucket. \n            getClient().putBucketVersioning(putBucketVersioningRequest); \n            PutObjectLockConfigurationRequest request = \n PutObjectLockConfigurationRequest.builder() \n                .bucket(bucketName) \n                .objectLockConfiguration(ObjectLockConfiguration.builder() \n                    .objectLockEnabled(ObjectLockEnabled.ENABLED) \n                    .build()) \n                .build(); \n            getClient().putObjectLockConfiguration(request); \n            System.out.println(\"Successfully enabled object lock on \n \"+bucketName); \n        } catch (S3Exception ex) { \n            System.out.println(\"Error modifying object lock: '\" + ex.getMessage() \n + \"'\"); \n        } \n    }\nSet the default retention period of a bucket.\n    // Set or modify a retention period on an S3 bucket.", "\n    public void modifyBucketDefaultRetention(String bucketName) { \n        VersioningConfiguration versioningConfiguration = \n VersioningConfiguration.builder() \n            .mfaDelete(MFADelete.DISABLED) \n            .status(BucketVersioningStatus.ENABLED) \nBasics API Version 2006-03-01 2254Amazon Simple Storage Service API Reference\n            .build(); \n        PutBucketVersioningRequest versioningRequest = \n PutBucketVersioningRequest.builder() \n            .bucket(bucketName) \n            .versioningConfiguration(versioningConfiguration) \n            .build(); \n        getClient().putBucketVersioning(versioningRequest); \n        DefaultRetention rention = DefaultRetention.builder() \n            .days(1) \n            .mode(ObjectLockRetentionMode.GOVERNANCE) \n            .build(); \n        ObjectLockRule lockRule = ObjectLockRule.builder() \n            .defaultRetention(rention) \n            .build(); \n        ObjectLockConfiguration objectLockConfiguration = \n ObjectLockConfiguration.builder() \n            .objectLockEnabled(ObjectLockEnabled.ENABLED) \n            .rule(lockRule) \n            .build(); \n        PutObjectLockConfigurationRequest putObjectLockConfigurationRequest = \n PutObjectLockConfigurationRequest.builder() \n            .bucket(bucketName) \n            .objectLockConfiguration(objectLockConfiguration) \n            .build(); \n        \n getClient().putObjectLockConfiguration(putObjectLockConfigurationRequest) ; \n        System.out.println(\"Added a default retention to bucket \"+bucketName \n +\".\"); \n    }\n\u2022For API details, see PutObjectLockCon\ufb01guration in AWS SDK for Java 2.x API Reference.\nBasics API Version 2006-03-01 2255Amazon Simple Storage Service API Reference\nJavaScript\nSDK for JavaScript (v3)\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nSet the object lock con\ufb01guration of a bucket.\nimport { \n  PutObjectLockConfigurationCommand, \n  S3Client, \n  S3ServiceException,\n} from \"@aws-sdk/client-s3\";\n/** \n * Enable S3 Object Lock for an Amazon S3 bucket.", "\n * After you enable Object Lock on a bucket, you can't \n * disable Object Lock or suspend versioning for that bucket. \n * @param {{ bucketName: string, enabled: boolean }} \n */\nexport const main = async ({ bucketName }) => { \n  const client = new S3Client({}); \n  const command = new PutObjectLockConfigurationCommand({ \n    Bucket: bucketName, \n    // The Object Lock configuration that you want to apply to the specified \n bucket. \n    ObjectLockConfiguration: { \n      ObjectLockEnabled: \"Enabled\", \n    }, \n  }); \n  try { \n    await client.send(command); \n    console.log(`Object Lock for \"${bucketName}\" enabled.`); \n  } catch (caught) { \n    if ( \n      caught instanceof S3ServiceException && \n      caught.name === \"NoSuchBucket\" \n    ) { \nBasics API Version 2006-03-01 2256Amazon Simple Storage Service API Reference\n      console.error( \n        `Error from S3 while modifying the object lock configuration for the \n bucket \"${bucketName}\". The bucket doesn't exist.`, \n      ); \n    } else if (caught instanceof S3ServiceException) { \n      console.error( \n        `Error from S3 while modifying the object lock configuration for the \n bucket \"${bucketName}\".", "${caught.name}: ${caught.message}`, \n      ); \n    } else { \n      throw caught; \n    } \n  }\n};\n// Call function if run directly\nimport { parseArgs } from \"node:util\";\nimport { \n  isMain, \n  validateArgs,\n} from \"@aws-doc-sdk-examples/lib/utils/util-node.js\";\nconst loadArgs = () => { \n  const options = { \n    bucketName: { \n      type: \"string\", \n      required: true, \n    }, \n  }; \n  const results = parseArgs({ options }); \n  const { errors } = validateArgs({ options }, results); \n  return { errors, results };\n};\nif (isMain(import.meta.url)) { \n  const { errors, results } = loadArgs(); \n  if (!errors) { \n    main(results.values); \n  } else { \n    console.error(errors.join(\"\\n\")); \n  }\n}\nBasics API Version 2006-03-01 2257Amazon Simple Storage Service API Reference\nSet the default retention period of a bucket.\nimport { \n  PutObjectLockConfigurationCommand, \n  S3Client, \n  S3ServiceException,\n} from \"@aws-sdk/client-s3\";\n/** \n * Change the default retention settings for an object in an Amazon S3 bucket. \n * @param {{ bucketName: string, retentionDays: string }} \n */\nexport const main = async ({ bucketName, retentionDays }) => { \n  const client = new S3Client({}); \n  try { \n    await client.send( \n      new PutObjectLockConfigurationCommand({ \n        Bucket: bucketName, \n        // The Object Lock configuration that you want to apply to the specified \n bucket. \n        ObjectLockConfiguration: { \n          ObjectLockEnabled: \"Enabled\", \n          Rule: { \n            // The default Object Lock retention mode and period that you want to \n apply \n            // to new objects placed in the specified bucket. Bucket settings \n require \n            // both a mode and a period.", "The period can be either Days or Years \n but \n            // you must select one.", "\n            DefaultRetention: { \n              // In governance mode, users can't overwrite or delete an object \n version \n              // or alter its lock settings unless they have special permissions. \n With \n              // governance mode, you protect objects against being deleted by \n most users, \n              // but you can still grant some users permission to alter the \n retention settings \n              // or delete the objects if necessary. \n              Mode: \"GOVERNANCE\", \n              Days: Number.parseInt(retentionDays), \nBasics API Version 2006-03-01 2258Amazon Simple Storage Service API Reference\n            }, \n          }, \n        }, \n      }), \n    ); \n    console.log( \n      `Set default retention mode to \"GOVERNANCE\" with a retention period of \n ${retentionDays} day(s).`, \n    ); \n  } catch (caught) { \n    if ( \n      caught instanceof S3ServiceException && \n      caught.name === \"NoSuchBucket\" \n    ) { \n      console.error( \n        `Error from S3 while setting the default object retention for a bucket. \n The bucket doesn't exist.`, \n      ); \n    } else if (caught instanceof S3ServiceException) { \n      console.error( \n        `Error from S3 while setting the default object retention for a bucket.", "\n ${caught.name}: ${caught.message}`, \n      ); \n    } else { \n      throw caught; \n    } \n  }\n};\n// Call function if run directly\nimport { parseArgs } from \"node:util\";\nimport { \n  isMain, \n  validateArgs,\n} from \"@aws-doc-sdk-examples/lib/utils/util-node.js\";\nconst loadArgs = () => { \n  const options = { \n    bucketName: { \n      type: \"string\", \n      required: true, \n    }, \n    retentionDays: { \n      type: \"string\", \nBasics API Version 2006-03-01 2259Amazon Simple Storage Service API Reference\n      required: true, \n    }, \n  }; \n  const results = parseArgs({ options }); \n  const { errors } = validateArgs({ options }, results); \n  return { errors, results };\n};\nif (isMain(import.meta.url)) { \n  const { errors, results } = loadArgs(); \n  if (!errors) { \n    main(results.values); \n  } else { \n    console.error(errors.join(\"\\n\")); \n  }\n}\n\u2022For API details, see PutObjectLockCon\ufb01guration in AWS SDK for JavaScript API Reference.\nPython\nSDK for Python (Boto3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nPut object lock con\ufb01guration.\n        s3_client.put_object_lock_configuration( \n            Bucket=bucket, \n            ObjectLockConfiguration={\"ObjectLockEnabled\": \"Disabled\", \"Rule\": \n {}}, \n        )\n\u2022For API details, see PutObjectLockCon\ufb01guration in AWS SDK for Python (Boto3) API \nReference.\nBasics API Version 2006-03-01 2260Amazon Simple Storage Service API Reference\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs.", "This topic also includes information about getting started and details \nabout previous SDK versions.\nUse PutObjectRetention  with an AWS SDK or CLI\nThe following code examples show how to use PutObjectRetention .\nAction examples are code excerpts from larger programs and must be run in context.", "You can see \nthis action in context in the following code example:\n\u2022Lock Amazon S3 objects\n.NET\nAWS SDK for .NET\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n    /// <summary> \n    /// Set or modify a retention period on an object in an S3 bucket. \n    /// </summary> \n    /// <param name=\"bucketName\">The bucket of the object.</param> \n    /// <param name=\"objectKey\">The key of the object.</param> \n    /// <param name=\"retention\">The retention mode.</param> \n    /// <param name=\"retainUntilDate\">The date retention expires.</param> \n    /// <returns>True if successful.</returns> \n    public async Task<bool> ModifyObjectRetentionPeriod(string bucketName, \n        string objectKey, ObjectLockRetentionMode retention, DateTime \n retainUntilDate) \n    { \n        try \n        { \n            var request = new PutObjectRetentionRequest() \n            { \n                BucketName = bucketName, \n                Key = objectKey, \nBasics API Version 2006-03-01 2261Amazon Simple Storage Service API Reference\n                Retention = new ObjectLockRetention() \n                { \n                    Mode = retention, \n                    RetainUntilDate = retainUntilDate \n                } \n            }; \n            var response = await _amazonS3.PutObjectRetentionAsync(request); \n            Console.WriteLine($\"\\tSet retention for {objectKey} in {bucketName} \n until {retainUntilDate:d}.\"); \n            return response.HttpStatusCode == System.Net.HttpStatusCode.OK; \n        } \n        catch (AmazonS3Exception ex) \n        { \n            Console.WriteLine($\"\\tError modifying retention period: \n '{ex.Message}'\"); \n            return false; \n        } \n    }\n\u2022For API details, see PutObjectRetention in AWS SDK for .NET API Reference.\nCLI\nAWS CLI\nTo set an object retention con\ufb01guration for an object\nThe following put-object-retention  example sets an object retention con\ufb01guration for \nthe speci\ufb01ed object until 2025-01-01.\naws s3api put-object-retention \\ \n    --bucket my-bucket-with-object-lock  \\ \n    --key doc1.rtf  \\ \n    --retention ' { \"Mode\": \"GOVERNANCE\", \"RetainUntilDate\": \n \"2025-01-01T00:00:00\" } '\nThis command produces no output.\n\u2022For API details, see PutObjectRetention in AWS CLI Command Reference.\nBasics API Version 2006-03-01 2262Amazon Simple Storage Service API Reference\nGo\nSDK for Go V2\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n// S3Actions wraps S3 service actions.\ntype S3Actions struct { \n S3Client  *s3.Client \n S3Manager *manager.Uploader\n}\n// PutObjectRetention sets the object retention configuration for an S3 object.\nfunc (actor S3Actions) PutObjectRetention(ctx context.Context, bucket string, key \n string, retentionMode types.ObjectLockRetentionMode, retentionPeriodDays int32) \n error { \n input := &s3.PutObjectRetentionInput{ \n  Bucket: aws.String(bucket), \n  Key:    aws.String(key), \n  Retention: &types.ObjectLockRetention{ \n   Mode:            retentionMode, \n   RetainUntilDate: aws.Time(time.Now().AddDate(0, 0, int(retentionPeriodDays))), \n  }, \n  BypassGovernanceRetention: aws.Bool(true), \n } \n _, err := actor.S3Client.PutObjectRetention(ctx, input) \n if err != nil { \n  var noKey *types.NoSuchKey \n  if errors.As(err, &noKey) { \n   log.Printf(\"Object %s does not exist in bucket %s.\\n\", key, bucket) \n   err = noKey \n  } \n } \nBasics API Version 2006-03-01 2263Amazon Simple Storage Service API Reference\n return err\n}\n\u2022For API details, see PutObjectRetention in AWS SDK for Go API Reference.\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n    // Set or modify a retention period on an object in an S3 bucket.", "\n    public void modifyObjectRetentionPeriod(String bucketName, String objectKey) \n { \n        // Calculate the instant one day from now.", "\n        Instant futureInstant = Instant.now().plus(1, ChronoUnit.DAYS); \n        // Convert the Instant to a ZonedDateTime object with a specific time \n zone.", "\n        ZonedDateTime zonedDateTime = \n futureInstant.atZone(ZoneId.systemDefault()); \n        // Define a formatter for human-readable output. \n        DateTimeFormatter formatter = DateTimeFormatter.ofPattern(\"yyyy-MM-dd \n HH:mm:ss\"); \n        // Format the ZonedDateTime object to a human-readable date string. \n        String humanReadableDate = formatter.format(zonedDateTime); \n        // Print the formatted date string.", "\n        System.out.println(\"Formatted Date: \" + humanReadableDate); \n        ObjectLockRetention retention = ObjectLockRetention.builder() \n            .mode(ObjectLockRetentionMode.GOVERNANCE) \n            .retainUntilDate(futureInstant) \n            .build(); \nBasics API Version 2006-03-01 2264Amazon Simple Storage Service API Reference\n        PutObjectRetentionRequest retentionRequest = \n PutObjectRetentionRequest.builder() \n            .bucket(bucketName) \n            .key(objectKey) \n            .retention(retention) \n            .build(); \n        getClient().putObjectRetention(retentionRequest); \n        System.out.println(\"Set retention for \"+objectKey +\" in \" +bucketName +\" \n until \"+ humanReadableDate +\".\"); \n    }\n\u2022For API details, see PutObjectRetention in AWS SDK for Java 2.x API Reference.\nJavaScript\nSDK for JavaScript (v3)\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nimport { \n  PutObjectRetentionCommand, \n  S3Client, \n  S3ServiceException,\n} from \"@aws-sdk/client-s3\";\n/** \n * Place a 24-hour retention period on an object in an Amazon S3 bucket. \n * @param {{ bucketName: string, key: string }} \n */\nexport const main = async ({ bucketName, key }) => { \n  const client = new S3Client({}); \n  const command = new PutObjectRetentionCommand({ \n    Bucket: bucketName, \n    Key: key, \n    BypassGovernanceRetention: false, \n    Retention: { \nBasics API Version 2006-03-01 2265Amazon Simple Storage Service API Reference\n      // In governance mode, users can't overwrite or delete an object version \n      // or alter its lock settings unless they have special permissions.", "With \n      // governance mode, you protect objects against being deleted by most \n users, \n      // but you can still grant some users permission to alter the retention \n settings \n      // or delete the objects if necessary. \n      Mode: \"GOVERNANCE\", \n      RetainUntilDate: new Date(new Date().getTime() + 24 * 60 * 60 * 1000), \n    }, \n  }); \n  try { \n    await client.send(command); \n    console.log(\"Object Retention settings updated.\"); \n  } catch (caught) { \n    if ( \n      caught instanceof S3ServiceException && \n      caught.name === \"NoSuchBucket\" \n    ) { \n      console.error( \n        `Error from S3 while modifying the governance mode and retention period \n on an object. The bucket doesn't exist.`, \n      ); \n    } else if (caught instanceof S3ServiceException) { \n      console.error( \n        `Error from S3 while modifying the governance mode and retention period \n on an object.", "${caught.name}: ${caught.message}`, \n      ); \n    } else { \n      throw caught; \n    } \n  }\n};\n// Call function if run directly\nimport { parseArgs } from \"node:util\";\nimport { \n  isMain, \n  validateArgs,\n} from \"@aws-doc-sdk-examples/lib/utils/util-node.js\";\nconst loadArgs = () => { \n  const options = { \nBasics API Version 2006-03-01 2266Amazon Simple Storage Service API Reference\n    bucketName: { \n      type: \"string\", \n      required: true, \n    }, \n    key: { \n      type: \"string\", \n      required: true, \n    }, \n  }; \n  const results = parseArgs({ options }); \n  const { errors } = validateArgs({ options }, results); \n  return { errors, results };\n};\nif (isMain(import.meta.url)) { \n  const { errors, results } = loadArgs(); \n  if (!errors) { \n    main(results.values); \n  } else { \n    console.error(errors.join(\"\\n\")); \n  }\n}\n\u2022For API details, see PutObjectRetention in AWS SDK for JavaScript API Reference.\nPowerShell\nTools for PowerShell\nExample 1: The command enables governance retention mode untill the date '31st Dec \n2019 00:00:00' for 'test\ufb01le.txt' object in the given S3 bucket.\nWrite-S3ObjectRetention -BucketName 'amzn-s3-demo-bucket' -Key 'testfile.txt' -\nRetention_Mode GOVERNANCE -Retention_RetainUntilDate \"2019-12-31T00:00:00\"\n\u2022For API details, see PutObjectRetention in AWS Tools for PowerShell Cmdlet Reference.\nBasics API Version 2006-03-01 2267Amazon Simple Storage Service API Reference\nPython\nSDK for Python (Boto3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nPut an object retention.\n            s3_client.put_object_retention( \n                Bucket=bucket, \n                Key=key, \n                VersionId=version_id, \n                Retention={\"Mode\": \"GOVERNANCE\", \"RetainUntilDate\": \n far_future_date}, \n                BypassGovernanceRetention=True, \n            )\n\u2022For API details, see PutObjectRetention in AWS SDK for Python (Boto3) API Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs.", "This topic also includes information about getting started and details \nabout previous SDK versions.\nUse RestoreObject  with an AWS SDK or CLI\nThe following code examples show how to use RestoreObject .\n.NET\nAWS SDK for .NET\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nBasics API Version 2006-03-01 2268Amazon Simple Storage Service API Reference\n    using System; \n    using System.Threading.Tasks; \n    using Amazon; \n    using Amazon.S3; \n    using Amazon.S3.Model; \n    /// <summary> \n    /// This example shows how to restore an archived object in an Amazon \n    /// Simple Storage Service (Amazon S3) bucket. \n    /// </summary> \n    public class RestoreArchivedObject \n    { \n        public static void Main() \n        { \n            string bucketName = \"amzn-s3-demo-bucket\"; \n            string objectKey = \"archived-object.txt\"; \n            // Specify your bucket region (an example region is shown). \n            RegionEndpoint bucketRegion = RegionEndpoint.USWest2; \n            IAmazonS3 client = new AmazonS3Client(bucketRegion); \n            RestoreObjectAsync(client, bucketName, objectKey).Wait(); \n        } \n        /// <summary> \n        /// This method restores an archived object from an Amazon S3 bucket. \n        /// </summary> \n        /// <param name=\"client\">The initialized Amazon S3 client object used to \n call \n        /// RestoreObjectAsync.</param> \n        /// <param name=\"bucketName\">A string representing the name of the \n        /// bucket where the object was located before it was archived.</param> \n        /// <param name=\"objectKey\">A string representing the name of the \n        /// archived object to restore.</param> \n        public static async Task RestoreObjectAsync(IAmazonS3 client, string \n bucketName, string objectKey) \n        { \n            try \n            { \n                var restoreRequest = new RestoreObjectRequest \n                { \n                    BucketName = bucketName, \n                    Key = objectKey, \nBasics API Version 2006-03-01 2269Amazon Simple Storage Service API Reference\n                    Days = 2, \n                }; \n                RestoreObjectResponse response = await \n client.RestoreObjectAsync(restoreRequest); \n                // Check the status of the restoration. \n                await CheckRestorationStatusAsync(client, bucketName, objectKey); \n            } \n            catch (AmazonS3Exception amazonS3Exception) \n            { \n                Console.WriteLine($\"Error: {amazonS3Exception.Message}\"); \n            } \n        } \n        /// <summary> \n        /// This method retrieves the status of the object's restoration. \n        /// </summary> \n        /// <param name=\"client\">The initialized Amazon S3 client object used to \n call \n        /// GetObjectMetadataAsync.</param> \n        /// <param name=\"bucketName\">A string representing the name of the Amazon \n        /// S3 bucket which contains the archived object.</param> \n        /// <param name=\"objectKey\">A string representing the name of the \n        /// archived object you want to restore.</param> \n        public static async Task CheckRestorationStatusAsync(IAmazonS3 client, \n string bucketName, string objectKey) \n        { \n            GetObjectMetadataRequest metadataRequest = new \n GetObjectMetadataRequest() \n            { \n                BucketName = bucketName, \n                Key = objectKey, \n            }; \n            GetObjectMetadataResponse response = await \n client.GetObjectMetadataAsync(metadataRequest); \n            var restStatus = response.RestoreInProgress ? \"in-progress\" : \n \"finished or failed\"; \n            Console.WriteLine($\"Restoration status: {restStatus}\"); \n        } \n    }\nBasics API Version 2006-03-01 2270Amazon Simple Storage Service API Reference\n\u2022For API details, see RestoreObject in AWS SDK for .NET API Reference.\nCLI\nAWS CLI\nTo create a restore request for an object\nThe following restore-object  example restores the speci\ufb01ed Amazon S3 Glacier object \nfor the bucket my-glacier-bucket  for 10 days.\naws s3api restore-object \\ \n    --bucket my-glacier-bucket  \\ \n    --key doc1.rtf  \\ \n    --restore-request Days=10\nThis command produces no output.\n\u2022For API details, see RestoreObject in AWS CLI Command Reference.\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nimport software.amazon.awssdk.regions.Region;\nimport software.amazon.awssdk.services.s3.S3Client;\nimport software.amazon.awssdk.services.s3.model.RestoreRequest;\nimport software.amazon.awssdk.services.s3.model.GlacierJobParameters;\nimport software.amazon.awssdk.services.s3.model.RestoreObjectRequest;\nimport software.amazon.awssdk.services.s3.model.S3Exception;\nimport software.amazon.awssdk.services.s3.model.Tier;\nBasics API Version 2006-03-01 2271Amazon Simple Storage Service API Reference\n/* \n *  For more information about restoring an object, see \"Restoring an archived \n object\" at \n *  https://docs.aws.amazon.com/AmazonS3/latest/userguide/restoring-objects.html \n * \n *  Before running this Java V2 code example, set up your development \n environment, including your credentials. \n * \n *  For more information, see the following documentation topic: \n * \n *  https://docs.aws.amazon.com/sdk-for-java/latest/developer-guide/get-\nstarted.html \n */\npublic class RestoreObject { \n    public static void main(String[] args) { \n        final String usage = \"\"\" \n            Usage: \n                <bucketName> <keyName> <expectedBucketOwner> \n            Where: \n                bucketName - The Amazon S3 bucket name.\\s \n                keyName - The key name of an object with a Storage class value of \n Glacier.\\s \n                expectedBucketOwner - The account that owns the bucket (you can \n obtain this value from the AWS Management Console).\\s \n            \"\"\"; \n        if (args.length != 3) { \n            System.out.println(usage); \n            System.exit(1); \n        } \n        String bucketName = args[0]; \n        String keyName = args[1]; \n        String expectedBucketOwner = args[2]; \n        Region region = Region.US_EAST_1; \n        S3Client s3 = S3Client.builder() \n            .region(region) \n            .build(); \n        restoreS3Object(s3, bucketName, keyName, expectedBucketOwner); \n        s3.close(); \n    } \nBasics API Version 2006-03-01 2272Amazon Simple Storage Service API Reference\n    /** \n     * Restores an S3 object from the Glacier storage class. \n     * \n     * @param s3                   an instance of the {@link S3Client} to be used \n for interacting with Amazon S3 \n     * @param bucketName           the name of the S3 bucket where the object is \n stored \n     * @param keyName              the key (object name) of the S3 object to be \n restored \n     * @param expectedBucketOwner  the AWS account ID of the expected bucket \n owner \n     */ \n    public static void restoreS3Object(S3Client s3, String bucketName, String \n keyName, String expectedBucketOwner) { \n        try { \n            RestoreRequest restoreRequest = RestoreRequest.builder() \n                .days(10) \n                \n .glacierJobParameters(GlacierJobParameters.builder().tier(Tier.STANDARD).build()) \n                .build(); \n            RestoreObjectRequest objectRequest = RestoreObjectRequest.builder() \n                .expectedBucketOwner(expectedBucketOwner) \n                .bucket(bucketName) \n                .key(keyName) \n                .restoreRequest(restoreRequest) \n                .build(); \n            s3.restoreObject(objectRequest); \n        } catch (S3Exception e) { \n            System.err.println(e.awsErrorDetails().errorMessage()); \n            System.exit(1); \n        } \n    }\n}\n\u2022For API details, see RestoreObject in AWS SDK for Java 2.x API Reference.\nBasics API Version 2006-03-01 2273Amazon Simple Storage Service API Reference\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nUse SelectObjectContent  with an AWS SDK or CLI\nThe following code examples show how to use SelectObjectContent .\nCLI\nAWS CLI\nTo \ufb01lter the contents of an Amazon S3 object based on an SQL statement\nThe following select-object-content  example \ufb01lters the object my-data-file.csv\nwith the speci\ufb01ed SQL statement and sends output to a \ufb01le.\naws s3api select-object-content \\ \n    --bucket my-bucket  \\ \n    --key my-data-file.csv  \\ \n    --expression \"select * from s3object limit 100\"  \\ \n    --expression-type ' SQL' \\ \n    --input-serialization ' {\"CSV\": {}, \"CompressionType\": \"NONE\"} ' \\ \n    --output-serialization ' {\"CSV\": {}} ' \"output.csv\"\nThis command produces no output.\n\u2022For API details, see SelectObjectContent in AWS CLI Command Reference.\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nThe following example shows a query using a JSON object. The complete example also \nshows the use of a CSV object.\nBasics API Version 2006-03-01 2274Amazon Simple Storage Service API Reference\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\nimport software.amazon.awssdk.core.async.AsyncRequestBody;\nimport software.amazon.awssdk.core.async.BlockingInputStreamAsyncRequestBody;\nimport software.amazon.awssdk.core.exception.SdkException;\nimport software.amazon.awssdk.services.s3.S3AsyncClient;\nimport software.amazon.awssdk.services.s3.model.CSVInput;\nimport software.amazon.awssdk.services.s3.model.CSVOutput;\nimport software.amazon.awssdk.services.s3.model.CompressionType;\nimport software.amazon.awssdk.services.s3.model.ExpressionType;\nimport software.amazon.awssdk.services.s3.model.FileHeaderInfo;\nimport software.amazon.awssdk.services.s3.model.InputSerialization;\nimport software.amazon.awssdk.services.s3.model.JSONInput;\nimport software.amazon.awssdk.services.s3.model.JSONOutput;\nimport software.amazon.awssdk.services.s3.model.JSONType;\nimport software.amazon.awssdk.services.s3.model.ObjectIdentifier;\nimport software.amazon.awssdk.services.s3.model.OutputSerialization;\nimport software.amazon.awssdk.services.s3.model.Progress;\nimport software.amazon.awssdk.services.s3.model.PutObjectResponse;\nimport software.amazon.awssdk.services.s3.model.SelectObjectContentRequest;\nimport \n software.amazon.awssdk.services.s3.model.SelectObjectContentResponseHandler;\nimport software.amazon.awssdk.services.s3.model.Stats;\nimport java.io.IOException;\nimport java.net.URL;\nimport java.util.ArrayList;\nimport java.util.List;\nimport java.util.UUID;\nimport java.util.concurrent.CompletableFuture;\npublic class SelectObjectContentExample { \n    static final Logger logger = \n LoggerFactory.getLogger(SelectObjectContentExample.class); \n    static final String BUCKET_NAME = \"amzn-s3-demo-bucket-\" + UUID.randomUUID(); \n    static final S3AsyncClient s3AsyncClient = S3AsyncClient.create(); \n    static String FILE_CSV = \"csv\"; \n    static String FILE_JSON = \"json\"; \n    static String URL_CSV = \"https://raw.githubusercontent.com/mledoze/countries/\nmaster/dist/countries.csv\"; \n    static String URL_JSON = \"https://raw.githubusercontent.com/mledoze/\ncountries/master/dist/countries.json\"; \nBasics API Version 2006-03-01 2275Amazon Simple Storage Service API Reference\n    public static void main(String[] args) { \n        SelectObjectContentExample selectObjectContentExample = new \n SelectObjectContentExample(); \n        try { \n            SelectObjectContentExample.setUp(); \n            selectObjectContentExample.runSelectObjectContentMethodForJSON(); \n            selectObjectContentExample.runSelectObjectContentMethodForCSV(); \n        } catch (SdkException e) { \n            logger.error(e.getMessage(), e); \n            System.exit(1); \n        } finally { \n            SelectObjectContentExample.tearDown(); \n        } \n    } \n    EventStreamInfo runSelectObjectContentMethodForJSON() { \n        // Set up request parameters.", "\n        final String queryExpression = \"select * from s3object[*][*] c where \n c.area < 350000\"; \n        final String fileType = FILE_JSON; \n        InputSerialization inputSerialization = InputSerialization.builder() \n                .json(JSONInput.builder().type(JSONType.DOCUMENT).build()) \n                .compressionType(CompressionType.NONE) \n                .build(); \n        OutputSerialization outputSerialization = OutputSerialization.builder() \n                .json(JSONOutput.builder().recordDelimiter(null).build()) \n                .build(); \n        // Build the SelectObjectContentRequest.", "\n        SelectObjectContentRequest select = SelectObjectContentRequest.builder() \n                .bucket(BUCKET_NAME) \n                .key(FILE_JSON) \n                .expression(queryExpression) \n                .expressionType(ExpressionType.SQL) \n                .inputSerialization(inputSerialization) \n                .outputSerialization(outputSerialization) \n                .build(); \n        EventStreamInfo eventStreamInfo = new EventStreamInfo(); \n        // Call the selectObjectContent method with the request and a response \n handler.", "\nBasics API Version 2006-03-01 2276Amazon Simple Storage Service API Reference\n        // Supply an EventStreamInfo object to the response handler to gather \n records and information from the response.", "\n        s3AsyncClient.selectObjectContent(select, \n buildResponseHandler(eventStreamInfo)).join(); \n        // Log out information gathered while processing the response stream.", "\n        long recordCount = eventStreamInfo.getRecords().stream().mapToInt(record \n -> \n                record.split(\"\\n\").length \n        ).sum(); \n        logger.info(\"Total records {}: {}\", fileType, recordCount); \n        logger.info(\"Visitor onRecords for fileType {} called {} times\", \n fileType, eventStreamInfo.getCountOnRecordsCalled()); \n        logger.info(\"Visitor onStats for fileType {}, {}\", fileType, \n eventStreamInfo.getStats()); \n        logger.info(\"Visitor onContinuations for fileType {}, {}\", fileType, \n eventStreamInfo.getCountContinuationEvents()); \n        return eventStreamInfo; \n    } \n    static SelectObjectContentResponseHandler \n buildResponseHandler(EventStreamInfo eventStreamInfo) { \n        // Use a Visitor to process the response stream. This visitor logs \n information and gathers details while processing. \n        final SelectObjectContentResponseHandler.Visitor visitor = \n SelectObjectContentResponseHandler.Visitor.builder() \n                .onRecords(r -> { \n                    logger.info(\"Record event received.\"); \n                    eventStreamInfo.addRecord(r.payload().asUtf8String()); \n                    eventStreamInfo.incrementOnRecordsCalled(); \n                }) \n                .onCont(ce -> { \n                    logger.info(\"Continuation event received.\"); \n                    eventStreamInfo.incrementContinuationEvents(); \n                }) \n                .onProgress(pe -> { \n                    Progress progress = pe.details(); \n                    logger.info(\"Progress event received:\\n bytesScanned:\n{}\\nbytesProcessed: {}\\nbytesReturned:{}\", \n                            progress.bytesScanned(), \n                            progress.bytesProcessed(), \n                            progress.bytesReturned()); \n                }) \n                .onEnd(ee -> logger.info(\"End event received.\")) \nBasics API Version 2006-03-01 2277Amazon Simple Storage Service API Reference\n                .onStats(se -> { \n                    logger.info(\"Stats event received.\"); \n                    eventStreamInfo.addStats(se.details()); \n                }) \n                .build(); \n        // Build the SelectObjectContentResponseHandler with the visitor that \n processes the stream. \n        return SelectObjectContentResponseHandler.builder() \n                .subscriber(visitor).build(); \n    } \n    // The EventStreamInfo class is used to store information gathered while \n processing the response stream.", "\n    static class EventStreamInfo { \n        private final List<String> records = new ArrayList<>(); \n        private Integer countOnRecordsCalled = 0; \n        private Integer countContinuationEvents = 0; \n        private Stats stats; \n        void incrementOnRecordsCalled() { \n            countOnRecordsCalled++; \n        } \n        void incrementContinuationEvents() { \n            countContinuationEvents++; \n        } \n        void addRecord(String record) { \n            records.add(record); \n        } \n        void addStats(Stats stats) { \n            this.stats = stats; \n        } \n        public List<String> getRecords() { \n            return records; \n        } \n        public Integer getCountOnRecordsCalled() { \n            return countOnRecordsCalled; \n        } \nBasics API Version 2006-03-01 2278Amazon Simple Storage Service API Reference\n        public Integer getCountContinuationEvents() { \n            return countContinuationEvents; \n        } \n        public Stats getStats() { \n            return stats; \n        } \n    }\n\u2022For API details, see SelectObjectContent in AWS SDK for Java 2.x API Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs.", "This topic also includes information about getting started and details \nabout previous SDK versions.\nUse UploadPart  with an AWS SDK or CLI\nThe following code examples show how to use UploadPart .\nAction examples are code excerpts from larger programs and must be run in context.", "You can see \nthis action in context in the following code examples:\n\u2022Perform a multipart upload\n\u2022Use checksums\n\u2022Work with Amazon S3 object integrity\nC++\nSDK for C++\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n//!", "Upload a part to an S3 bucket.\n/*! \n    \\param bucket: The name of the S3 bucket where the object will be uploaded. \nBasics API Version 2006-03-01 2279Amazon Simple Storage Service API Reference\n    \\param key: The unique identifier (key) for the object within the S3 bucket.", "\n    \\param uploadID: An upload ID string.", "\n    \\param partNumber: \n    \\param checksumAlgorithm: Checksum algorithm, ignored when NOT_SET. \n    \\param calculatedHash: A data integrity hash to set, depending on the \n checksum algorithm, \n                            ignored when it is an empty string.", "\n    \\param body: An shared_ptr IOStream of the data to be uploaded.", "\n    \\param client: The S3 client instance used to perform the upload operation. \n    \\return UploadPartOutcome: The outcome.\n*/\nAws::S3::Model::UploadPartOutcome AwsDoc::S3::uploadPart(const Aws::String \n &bucket, \n                                                         const Aws::String &key, \n                                                         const Aws::String \n &uploadID, \n                                                         int partNumber, \n                                                         \n Aws::S3::Model::ChecksumAlgorithm checksumAlgorithm, \n                                                         const Aws::String \n &calculatedHash, \n                                                         const \n std::shared_ptr<Aws::IOStream> &body, \n                                                         const Aws::S3::S3Client \n &client) { \n    Aws::S3::Model::UploadPartRequest request; \n    request.SetBucket(bucket); \n    request.SetKey(key); \n    request.SetUploadId(uploadID); \n    request.SetPartNumber(partNumber); \n    if (checksumAlgorithm != Aws::S3::Model::ChecksumAlgorithm::NOT_SET) { \n        request.SetChecksumAlgorithm(checksumAlgorithm); \n    } \n    request.SetBody(body); \n    if (!calculatedHash.empty()) { \n        switch (checksumAlgorithm) { \n            case Aws::S3::Model::ChecksumAlgorithm::NOT_SET: \n                request.SetContentMD5(calculatedHash); \n                break; \n            case Aws::S3::Model::ChecksumAlgorithm::CRC32: \n                request.SetChecksumCRC32(calculatedHash); \n                break; \nBasics API Version 2006-03-01 2280Amazon Simple Storage Service API Reference\n            case Aws::S3::Model::ChecksumAlgorithm::CRC32C: \n                request.SetChecksumCRC32C(calculatedHash); \n                break; \n            case Aws::S3::Model::ChecksumAlgorithm::SHA1: \n                request.SetChecksumSHA1(calculatedHash); \n                break; \n            case Aws::S3::Model::ChecksumAlgorithm::SHA256: \n                request.SetChecksumSHA256(calculatedHash); \n                break; \n        } \n    } \n    return client.UploadPart(request);\n}\n\u2022For API details, see UploadPart in AWS SDK for C++ API Reference.\nCLI\nAWS CLI\nThe following command uploads the \ufb01rst part in a multipart upload initiated with the\ncreate-multipart-upload  command:\naws s3api upload-part --bucket my-bucket  --key ' multipart/01 ' --part-number 1 --\nbody part01 --upload-id \n   \"dfRtDYU0WWCCcH43C3WFbkRONycyCpTJJvxu2i5GYkZljF.Yxwh6XG7WfS2vC4to6HiV6Yjlx.cph0gtNBtJ8P3URCSbB7rjxI5iEwVDmgaXZOGgkk5nVTW16HOQ5l0R\"\nThe body option takes the name or path of a local \ufb01le for upload (do not use the \ufb01le:// \npre\ufb01x).", "The minimum part size is 5 MB.", "Upload ID is returned by create-multipart-\nupload and can also be retrieved with list-multipart-uploads .", "Bucket and key are \nspeci\ufb01ed when you create the multipart upload.\nOutput:\n{ \n    \"ETag\": \"\\\"e868e0f4719e394144ef36531ee6824c\\\"\"\n}\nBasics API Version 2006-03-01 2281Amazon Simple Storage Service API Reference\nSave the ETag value of each part for later.", "They are required to complete the multipart \nupload.\n\u2022For API details, see UploadPart in AWS CLI Command Reference.\nRust\nSDK for Rust\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n    let mut upload_parts: Vec<aws_sdk_s3::types::CompletedPart> = Vec::new(); \n    for chunk_index in 0..chunk_count { \n        let this_chunk = if chunk_count - 1 == chunk_index { \n            size_of_last_chunk \n        } else { \n            CHUNK_SIZE \n        }; \n        let stream = ByteStream::read_from() \n            .path(path) \n            .offset(chunk_index * CHUNK_SIZE) \n            .length(Length::Exact(this_chunk)) \n            .build() \n            .await \n            .unwrap(); \n        // Chunk index needs to start at 0, but part numbers start at 1. \n        let part_number = (chunk_index as i32) + 1; \n        let upload_part_res = client \n            .upload_part() \n            .key(&key) \n            .bucket(&bucket_name) \n            .upload_id(upload_id) \n            .body(stream) \n            .part_number(part_number) \n            .send() \n            .await?; \nBasics API Version 2006-03-01 2282Amazon Simple Storage Service API Reference\n        upload_parts.push( \n            CompletedPart::builder() \n                .e_tag(upload_part_res.e_tag.unwrap_or_default()) \n                .part_number(part_number) \n                .build(), \n        ); \n    }\n    // Create a multipart upload.", "Use UploadPart and CompleteMultipartUpload to \n    // upload the file. \n    let multipart_upload_res: CreateMultipartUploadOutput = client \n        .create_multipart_upload() \n        .bucket(&bucket_name) \n        .key(&key) \n        .send() \n        .await?; \n    let upload_id = multipart_upload_res.upload_id().ok_or(S3ExampleError::new( \n        \"Missing upload_id after CreateMultipartUpload\", \n    ))?;\n    // upload_parts: Vec<aws_sdk_s3::types::CompletedPart> \n    let completed_multipart_upload: CompletedMultipartUpload = \n CompletedMultipartUpload::builder() \n        .set_parts(Some(upload_parts)) \n        .build(); \n    let _complete_multipart_upload_res = client \n        .complete_multipart_upload() \n        .bucket(&bucket_name) \n        .key(&key) \n        .multipart_upload(completed_multipart_upload) \n        .upload_id(upload_id) \n        .send() \n        .await?;\n\u2022For API details, see UploadPart in AWS SDK for Rust API reference.\nBasics API Version 2006-03-01 2283Amazon Simple Storage Service API Reference\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nScenarios for Amazon S3 using AWS SDKs\nThe following code examples show you how to implement common scenarios in Amazon S3 with \nAWS SDKs. These scenarios show you how to accomplish speci\ufb01c tasks by calling multiple functions \nwithin Amazon S3 or combined with other AWS services. Each scenario includes a link to the \ncomplete source code, where you can \ufb01nd instructions on how to set up and run the code.\nScenarios target an intermediate level of experience to help you understand service actions in \ncontext.\nExamples\n\u2022Convert text to speech and back to text using an AWS SDK\n\u2022Create a presigned URL for Amazon S3 using an AWS SDK\n\u2022Create a photo asset management application that lets users manage photos using labels\n\u2022A web page that lists Amazon S3 objects using an AWS SDK\n\u2022Create an Amazon Textract explorer application\n\u2022Delete all objects in a given Amazon S3 bucket using an AWS SDK.\n\u2022Delete incomplete multipart uploads to Amazon S3 using an AWS SDK\n\u2022Detect PPE in images with Amazon Rekognition using an AWS SDK\n\u2022Detect entities in text extracted from an image using an AWS SDK\n\u2022Detect faces in an image using an AWS SDK\n\u2022Detect objects in images with Amazon Rekognition using an AWS SDK\n\u2022Detect people and objects in a video with Amazon Rekognition using an AWS SDK\n\u2022Download all objects in an Amazon Simple Storage Service (Amazon S3) bucket to a local \ndirectory\n\u2022Get an Amazon S3 object from a Multi-Region Access Point by using an AWS SDK\n\u2022Get an object from an Amazon S3 bucket using an AWS SDK, specifying an If-Modi\ufb01ed-Since \nheader\n\u2022Get started with encryption for Amazon S3 objects using an AWS SDK\n\u2022Get started with tags for Amazon S3 objects using an AWS SDK\nScenarios API Version 2006-03-01 2284Amazon Simple Storage Service API Reference\n\u2022Work with Amazon S3 object lock features using an AWS SDK\n\u2022Manage access control lists (ACLs) for Amazon S3 buckets using an AWS SDK\n\u2022Manage versioned Amazon S3 objects in batches with a Lambda function using an AWS SDK\n\u2022Parse Amazon S3 URIs using an AWS SDK\n\u2022Perform a multipart copy of an Amazon S3 object using an AWS SDK\n\u2022Perform a multipart upload of an Amazon S3 object using an AWS SDK\n\u2022Receive and process Amazon S3 event noti\ufb01cations by using an AWS SDK.\n\u2022Save EXIF and other image information using an AWS SDK\n\u2022Send S3 event noti\ufb01cations to Amazon EventBridge using an AWS SDK\n\u2022Track an Amazon S3 object upload or download using an AWS SDK\n\u2022Transform data for your application with S3 Object Lambda\n\u2022Example approaches for unit and integration testing with an AWS SDK\n\u2022Recursively upload a local directory to an Amazon Simple Storage Service (Amazon S3) bucket\n\u2022Upload or download large \ufb01les to and from Amazon S3 using an AWS SDK\n\u2022Upload a stream of unknown size to an Amazon S3 object using an AWS SDK\n\u2022Use checksums to work with an Amazon S3 object using an AWS SDK\n\u2022Work with Amazon S3 object integrity features using an AWS SDK\n\u2022Work with Amazon S3 versioned objects using an AWS SDK\nConvert text to speech and back to text using an AWS SDK\nThe following code example shows how to:\n\u2022Use Amazon Polly to synthesize a plain text (UTF-8) input \ufb01le to an audio \ufb01le.\n\u2022Upload the audio \ufb01le to an Amazon S3 bucket.\n\u2022Use Amazon Transcribe to convert the audio \ufb01le to text.\n\u2022Display the text.\nScenarios API Version 2006-03-01 2285Amazon Simple Storage Service API Reference\nRust\nSDK for Rust\nUse Amazon Polly to synthesize a plain text (UTF-8) input \ufb01le to an audio \ufb01le, upload the \naudio \ufb01le to an Amazon S3 bucket, use Amazon Transcribe to convert that audio \ufb01le to text, \nand display the text.\nFor complete source code and instructions on how to set up and run, see the full example on\nGitHub .\nServices used in this example\n\u2022Amazon Polly\n\u2022Amazon S3\n\u2022Amazon Transcribe\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nCreate a presigned URL for Amazon S3 using an AWS SDK\nThe following code examples show how to create a presigned URL for Amazon S3 and upload an \nobject.\n.NET\nAWS SDK for .NET\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nGenerate a presigned URL that can perform an Amazon S3 action for a limited time.\n    using System; \n    using Amazon; \n    using Amazon.S3; \nScenarios API Version 2006-03-01 2286Amazon Simple Storage Service API Reference\n    using Amazon.S3.Model; \n    public class GenPresignedUrl \n    { \n        public static void Main() \n        { \n            const string bucketName = \"amzn-s3-demo-bucket\"; \n            const string objectKey = \"sample.txt\"; \n            // Specify how long the presigned URL lasts, in hours \n            const double timeoutDuration = 12; \n            // Specify the AWS Region of your Amazon S3 bucket.", "If it is \n            // different from the Region defined for the default user, \n            // pass the Region to the constructor for the client.", "For \n            // example: new AmazonS3Client(RegionEndpoint.USEast1); \n            // If using the Region us-east-1, and server-side encryption with AWS \n KMS, you must specify Signature Version 4.", "\n            // Region us-east-1 defaults to Signature Version 2 unless explicitly \n set to Version 4 as shown below.", "\n            // For more details, see https://docs.aws.amazon.com/AmazonS3/latest/\nuserguide/UsingAWSSDK.html#specify-signature-version \n            // and https://docs.aws.amazon.com/sdkfornet/v3/apidocs/items/Amazon/\nTAWSConfigsS3.html \n            AWSConfigsS3.UseSignatureVersion4 = true; \n            IAmazonS3 s3Client = new AmazonS3Client(RegionEndpoint.USEast1); \n            string urlString = GeneratePresignedURL(s3Client, bucketName, \n objectKey, timeoutDuration); \n            Console.WriteLine($\"The generated URL is: {urlString}.\"); \n        } \n        /// <summary> \n        /// Generate a presigned URL that can be used to access the file named \n        /// in the objectKey parameter for the amount of time specified in the \n        /// duration parameter. \n        /// </summary> \n        /// <param name=\"client\">An initialized S3 client object used to call \n        /// the GetPresignedUrl method.</param> \n        /// <param name=\"bucketName\">The name of the S3 bucket containing the \n        /// object for which to create the presigned URL.</param> \n        /// <param name=\"objectKey\">The name of the object to access with the \n        /// presigned URL.</param> \nScenarios API Version 2006-03-01 2287Amazon Simple Storage Service API Reference\n        /// <param name=\"duration\">The length of time for which the presigned \n        /// URL will be valid.</param> \n        /// <returns>A string representing the generated presigned URL.</returns> \n        public static string GeneratePresignedURL(IAmazonS3 client, string \n bucketName, string objectKey, double duration) \n        { \n            string urlString = string.Empty; \n            try \n            { \n                var request = new GetPreSignedUrlRequest() \n                { \n                    BucketName = bucketName, \n                    Key = objectKey, \n                    Expires = DateTime.UtcNow.AddHours(duration), \n                }; \n                urlString = client.GetPreSignedURL(request); \n            } \n            catch (AmazonS3Exception ex) \n            { \n                Console.WriteLine($\"Error:'{ex.Message}'\"); \n            } \n            return urlString; \n        } \n    }\nGenerate a presigned URL and perform an upload using that URL.\n    using System; \n    using System.IO; \n    using System.Net.Http; \n    using System.Threading.Tasks; \n    using Amazon; \n    using Amazon.S3; \n    using Amazon.S3.Model; \n    /// <summary> \n    /// This example shows how to upload an object to an Amazon Simple Storage \n    /// Service (Amazon S3) bucket using a presigned URL. The code first \n    /// creates a presigned URL and then uses it to upload an object to an \n    /// Amazon S3 bucket using that URL. \nScenarios API Version 2006-03-01 2288Amazon Simple Storage Service API Reference\n    /// </summary> \n    public class UploadUsingPresignedURL \n    { \n        private static HttpClient httpClient = new HttpClient(); \n        public static async Task Main() \n        { \n            string bucketName = \"amzn-s3-demo-bucket\"; \n            string keyName = \"samplefile.txt\"; \n            string filePath = $\"source\\\\{keyName}\"; \n            // Specify how long the signed URL will be valid in hours.", "\n            double timeoutDuration = 12; \n            // Specify the AWS Region of your Amazon S3 bucket.", "If it is \n            // different from the Region defined for the default user, \n            // pass the Region to the constructor for the client.", "For \n            // example: new AmazonS3Client(RegionEndpoint.USEast1); \n            // If using the Region us-east-1, and server-side encryption with AWS \n KMS, you must specify Signature Version 4.", "\n            // Region us-east-1 defaults to Signature Version 2 unless explicitly \n set to Version 4 as shown below.", "\n            // For more details, see https://docs.aws.amazon.com/AmazonS3/latest/\nuserguide/UsingAWSSDK.html#specify-signature-version \n            // and https://docs.aws.amazon.com/sdkfornet/v3/apidocs/items/Amazon/\nTAWSConfigsS3.html \n            AWSConfigsS3.UseSignatureVersion4 = true; \n            IAmazonS3 client = new AmazonS3Client(RegionEndpoint.USEast1); \n            var url = GeneratePreSignedURL(client, bucketName, keyName, \n timeoutDuration); \n            var success = await UploadObject(filePath, url); \n            if (success) \n            { \n                Console.WriteLine(\"Upload succeeded.\"); \n            } \n            else \n            { \n                Console.WriteLine(\"Upload failed.\"); \n            } \n        } \nScenarios API Version 2006-03-01 2289Amazon Simple Storage Service API Reference\n        /// <summary> \n        /// Uploads an object to an Amazon S3 bucket using the presigned URL \n passed in \n        /// the url parameter. \n        /// </summary> \n        /// <param name=\"filePath\">The path (including file name) to the local \n        /// file you want to upload.</param> \n        /// <param name=\"url\">The presigned URL that will be used to upload the \n        /// file to the Amazon S3 bucket.</param> \n        /// <returns>A Boolean value indicating the success or failure of the \n        /// operation, based on the HttpWebResponse.</returns> \n        public static async Task<bool> UploadObject(string filePath, string url) \n        { \n            using var streamContent = new StreamContent( \n                new FileStream(filePath, FileMode.Open, FileAccess.Read)); \n            var response = await httpClient.PutAsync(url, streamContent); \n            return response.IsSuccessStatusCode; \n        } \n        /// <summary> \n        /// Generates a presigned URL which will be used to upload an object to \n        /// an Amazon S3 bucket. \n        /// </summary> \n        /// <param name=\"client\">The initialized Amazon S3 client object used to \n call \n        /// GetPreSignedURL.</param> \n        /// <param name=\"bucketName\">The name of the Amazon S3 bucket to which \n the \n        /// presigned URL will point.</param> \n        /// <param name=\"objectKey\">The name of the file that will be uploaded.</\nparam> \n        /// <param name=\"duration\">How long (in hours) the presigned URL will \n        /// be valid.</param> \n        /// <returns>The generated URL.</returns> \n        public static string GeneratePreSignedURL( \n            IAmazonS3 client, \n            string bucketName, \n            string objectKey, \n            double duration) \n        { \n            var request = new GetPreSignedUrlRequest \n            { \n                BucketName = bucketName, \nScenarios API Version 2006-03-01 2290Amazon Simple Storage Service API Reference\n                Key = objectKey, \n                Verb = HttpVerb.PUT, \n                Expires = DateTime.UtcNow.AddHours(duration), \n            }; \n            string url = client.GetPreSignedURL(request); \n            return url; \n        } \n    }\nC++\nSDK for C++\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nGenerate a pre-signed URL to download an object.\n//! Routine which demonstrates creating a pre-signed URL to download an object \n from an\n//!", "Amazon Simple Storage Service (Amazon S3) bucket.\n/*!", "\n  \\param bucketName: Name of the bucket.", "\n  \\param key: Name of an object key.", "\n  \\param expirationSeconds: Expiration in seconds for pre-signed URL.", "\n  \\param clientConfig: Aws client configuration. \n  \\return Aws::String: A pre-signed URL.\n*/\nAws::String AwsDoc::S3::generatePreSignedGetObjectUrl(const Aws::String \n &bucketName, \n                                                      const Aws::String &key, \n                                                      uint64_t expirationSeconds, \n                                                      const \n Aws::S3::S3ClientConfiguration &clientConfig) { \n    Aws::S3::S3Client client(clientConfig); \nScenarios API Version 2006-03-01 2291Amazon Simple Storage Service API Reference\n    return client.GeneratePresignedUrl(bucketName, key, \n Aws::Http::HttpMethod::HTTP_GET, \n                                       expirationSeconds);\n}\nDownload using libcurl.\nstatic size_t myCurlWriteBack(char *buffer, size_t size, size_t nitems, void \n *userdata) { \n    Aws::StringStream *str = (Aws::StringStream *) userdata; \n    if (nitems > 0) { \n        str->write(buffer, size * nitems); \n    } \n    return size * nitems;\n}\n//!", "Utility routine to test getObject with a pre-signed URL.\n/*!", "\n  \\param presignedURL: A pre-signed URL to get an object from a bucket.", "\n  \\param resultString: A string to hold the result.", "\n  \\return bool: Function succeeded.\n*/\nbool AwsDoc::S3::getObjectWithPresignedObjectUrl(const Aws::String &presignedURL, \n                                                 Aws::String &resultString) { \n    CURL *curl = curl_easy_init(); \n    CURLcode result; \n    std::stringstream outWriteString; \n    result = curl_easy_setopt(curl, CURLOPT_WRITEDATA, &outWriteString); \n    if (result != CURLE_OK) { \n        std::cerr << \"Failed to set CURLOPT_WRITEDATA \" << std::endl; \n        return false; \n    } \n    result = curl_easy_setopt(curl, CURLOPT_WRITEFUNCTION, myCurlWriteBack); \n    if (result != CURLE_OK) { \n        std::cerr << \"Failed to set CURLOPT_WRITEFUNCTION\" << std::endl; \n        return false; \nScenarios API Version 2006-03-01 2292Amazon Simple Storage Service API Reference\n    } \n    result = curl_easy_setopt(curl, CURLOPT_URL, presignedURL.c_str()); \n    if (result != CURLE_OK) { \n        std::cerr << \"Failed to set CURLOPT_URL\" << std::endl; \n        return false; \n    } \n    result = curl_easy_perform(curl); \n    if (result != CURLE_OK) { \n        std::cerr << \"Failed to perform CURL request\" << std::endl; \n        return false; \n    } \n    resultString = outWriteString.str(); \n    if (resultString.find(\"<?xml\") == 0) { \n        std::cerr << \"Failed to get object, response:\\n\" << resultString << \n std::endl; \n        return false; \n    } \n    return true;\n}\nGenerate a pre-signed URL to upload an object.\n//!", "Routine which demonstrates creating a pre-signed URL to upload an object to \n an\n//!", "Amazon Simple Storage Service (Amazon S3) bucket.\n/*!", "\n  \\param bucketName: Name of the bucket.", "\n  \\param key: Name of an object key.", "\n  \\param clientConfig: Aws client configuration. \n  \\return Aws::String: A pre-signed URL.\n*/\nAws::String AwsDoc::S3::generatePreSignedPutObjectUrl(const Aws::String \n &bucketName, \n                                                      const Aws::String &key, \n                                                      uint64_t expirationSeconds, \nScenarios API Version 2006-03-01 2293Amazon Simple Storage Service API Reference\n                                                      const \n Aws::S3::S3ClientConfiguration &clientConfig) { \n    Aws::S3::S3Client client(clientConfig); \n    return client.GeneratePresignedUrl(bucketName, key, \n Aws::Http::HttpMethod::HTTP_PUT, \n                                       expirationSeconds);\n}\nUpload using libcurl.\nstatic size_t myCurlReadBack(char *buffer, size_t size, size_t nitems, void \n *userdata) { \n    Aws::StringStream *str = (Aws::StringStream *) userdata; \n    str->read(buffer, size * nitems); \n    return str->gcount();\n}\nstatic size_t myCurlWriteBack(char *buffer, size_t size, size_t nitems, void \n *userdata) { \n    Aws::StringStream *str = (Aws::StringStream *) userdata; \n    if (nitems > 0) { \n        str->write(buffer, size * nitems); \n    } \n    return size * nitems;\n}\n//!", "Utility routine to test putObject with a pre-signed URL.\n/*!", "\n  \\param presignedURL: A pre-signed URL to put an object in a bucket.", "\n  \\param data: Body of the putObject request.", "\n  \\return bool: Function succeeded.\n*/\nbool AwsDoc::S3::PutStringWithPresignedObjectURL(const Aws::String &presignedURL, \n                                                 const Aws::String &data) { \n    CURL *curl = curl_easy_init(); \n    CURLcode result; \n    Aws::StringStream readStringStream; \n    readStringStream << data; \nScenarios API Version 2006-03-01 2294Amazon Simple Storage Service API Reference\n    result = curl_easy_setopt(curl, CURLOPT_READFUNCTION, myCurlReadBack); \n    if (result != CURLE_OK) { \n        std::cerr << \"Failed to set CURLOPT_READFUNCTION\" << std::endl; \n        return false; \n    } \n    result = curl_easy_setopt(curl, CURLOPT_READDATA, &readStringStream); \n    if (result != CURLE_OK) { \n        std::cerr << \"Failed to set CURLOPT_READDATA\" << std::endl; \n        return false; \n    } \n    result = curl_easy_setopt(curl, CURLOPT_INFILESIZE_LARGE, \n                              (curl_off_t) data.size()); \n    if (result != CURLE_OK) { \n        std::cerr << \"Failed to set CURLOPT_INFILESIZE_LARGE\" << std::endl; \n        return false; \n    } \n    result = curl_easy_setopt(curl, CURLOPT_WRITEFUNCTION, myCurlWriteBack); \n    if (result != CURLE_OK) { \n        std::cerr << \"Failed to set CURLOPT_WRITEFUNCTION\" << std::endl; \n        return false; \n    } \n    std::stringstream outWriteString; \n    result = curl_easy_setopt(curl, CURLOPT_WRITEDATA, &outWriteString); \n    if (result != CURLE_OK) { \n        std::cerr << \"Failed to set CURLOPT_WRITEDATA \" << std::endl; \n        return false; \n    } \n    result = curl_easy_setopt(curl, CURLOPT_URL, presignedURL.c_str()); \n    if (result != CURLE_OK) { \n        std::cerr << \"Failed to set CURLOPT_URL\" << std::endl; \n        return false; \n    } \nScenarios API Version 2006-03-01 2295Amazon Simple Storage Service API Reference\n    result = curl_easy_setopt(curl, CURLOPT_UPLOAD, 1L); \n    if (result != CURLE_OK) { \n        std::cerr << \"Failed to set CURLOPT_PUT\" << std::endl; \n        return false; \n    } \n    result = curl_easy_perform(curl); \n    if (result != CURLE_OK) { \n        std::cerr << \"Failed to perform CURL request\" << std::endl; \n        return false; \n    } \n    std::string outString = outWriteString.str(); \n    if (outString.empty()) { \n        std::cout << \"Successfully put object.\" << std::endl; \n        return true; \n    } else { \n        std::cout << \"A server error was encountered, output:\\n\" << outString \n                  << std::endl; \n        return false; \n    }\n}\nGo\nSDK for Go V2\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nCreate functions that wrap S3 presigning actions.\n// Presigner encapsulates the Amazon Simple Storage Service (Amazon S3) presign \n actions\n// used in the examples.\nScenarios API Version 2006-03-01 2296Amazon Simple Storage Service API Reference\n// It contains PresignClient, a client that is used to presign requests to Amazon \n S3.\n// Presigned requests contain temporary credentials and can be made from any HTTP \n client.\ntype Presigner struct { \n PresignClient *s3.PresignClient\n}\n// GetObject makes a presigned request that can be used to get an object from a \n bucket.\n// The presigned request is valid for the specified number of seconds.\nfunc (presigner Presigner) GetObject( \n ctx context.Context, bucketName string, objectKey string, lifetimeSecs int64) \n (*v4.PresignedHTTPRequest, error) { \n request, err := presigner.PresignClient.PresignGetObject(ctx, \n &s3.GetObjectInput{ \n  Bucket: aws.String(bucketName), \n  Key:    aws.String(objectKey), \n }, func(opts *s3.PresignOptions) { \n  opts.Expires = time.Duration(lifetimeSecs * int64(time.Second)) \n }) \n if err != nil { \n  log.Printf(\"Couldn't get a presigned request to get %v:%v. Here's why: %v\\n\", \n   bucketName, objectKey, err) \n } \n return request, err\n}\n// PutObject makes a presigned request that can be used to put an object in a \n bucket.\n// The presigned request is valid for the specified number of seconds.\nfunc (presigner Presigner) PutObject( \n ctx context.Context, bucketName string, objectKey string, lifetimeSecs int64) \n (*v4.PresignedHTTPRequest, error) { \n request, err := presigner.PresignClient.PresignPutObject(ctx, \n &s3.PutObjectInput{ \n  Bucket: aws.String(bucketName), \n  Key:    aws.String(objectKey), \n }, func(opts *s3.PresignOptions) { \n  opts.Expires = time.Duration(lifetimeSecs * int64(time.Second)) \nScenarios API Version 2006-03-01 2297Amazon Simple Storage Service API Reference\n }) \n if err != nil { \n  log.Printf(\"Couldn't get a presigned request to put %v:%v. Here's why: %v\\n\", \n   bucketName, objectKey, err) \n } \n return request, err\n}\n// DeleteObject makes a presigned request that can be used to delete an object \n from a bucket.\nfunc (presigner Presigner) DeleteObject(ctx context.Context, bucketName string, \n objectKey string) (*v4.PresignedHTTPRequest, error) { \n request, err := presigner.PresignClient.PresignDeleteObject(ctx, \n &s3.DeleteObjectInput{ \n  Bucket: aws.String(bucketName), \n  Key:    aws.String(objectKey), \n }) \n if err != nil { \n  log.Printf(\"Couldn't get a presigned request to delete object %v. Here's why: \n %v\\n\", objectKey, err) \n } \n return request, err\n}\nfunc (presigner Presigner) PresignPostObject(ctx context.Context, bucketName \n string, objectKey string, lifetimeSecs int64) (*s3.PresignedPostRequest, error) \n { \n request, err := presigner.PresignClient.PresignPostObject(ctx, \n &s3.PutObjectInput{ \n  Bucket: aws.String(bucketName), \n  Key:    aws.String(objectKey), \n }, func(options *s3.PresignPostOptions) { \n  options.Expires = time.Duration(lifetimeSecs) * time.Second \n }) \n if err != nil { \n  log.Printf(\"Couldn't get a presigned post request to put %v:%v. Here's why: %v\n\\n\", bucketName, objectKey, err) \n } \n return request, nil\n}\nScenarios API Version 2006-03-01 2298Amazon Simple Storage Service API Reference\nRun an interactive example that generates and uses presigned URLs to upload, download, \nand delete an S3 object.\n// RunPresigningScenario is an interactive example that shows you how to get \n presigned\n// HTTP requests that you can use to move data into and out of Amazon Simple \n Storage\n// Service (Amazon S3).", "The presigned requests contain temporary credentials and \n can\n// be used by an HTTP client.\n//\n// 1.", "Get a presigned request to put an object in a bucket.\n// 2. Use the net/http package to use the presigned request to upload a local \n file to the bucket.\n// 3. Get a presigned request to get an object from a bucket.\n// 4.", "Use the net/http package to use the presigned request to download the \n object to a local file.\n// 5.", "Get a presigned request to delete an object from a bucket.\n// 6. Use the net/http package to use the presigned request to delete the object.\n//\n// This example creates an Amazon S3 presign client from the specified sdkConfig \n so that\n// you can replace it with a mocked or stubbed config for unit testing.\n//\n// It uses a questioner from the `demotools` package to get input during the \n example.\n// This package can be found in the ..\\..\\demotools folder of this repo.\n//\n// It uses an IHttpRequester interface to abstract HTTP requests so they can be \n mocked\n// during testing.\nfunc RunPresigningScenario(ctx context.Context, sdkConfig aws.Config, questioner \n demotools.IQuestioner, httpRequester IHttpRequester) { \n defer func() { \n  if r := recover(); r != nil { \n   fmt.Printf(\"Something went wrong with the demo\") \n  } \n }() \nScenarios API Version 2006-03-01 2299Amazon Simple Storage Service API Reference\n log.Println(strings.Repeat(\"-\", 88)) \n log.Println(\"Welcome to the Amazon S3 presigning demo.\") \n log.Println(strings.Repeat(\"-\", 88)) \n s3Client := s3.NewFromConfig(sdkConfig) \n bucketBasics := actions.BucketBasics{S3Client: s3Client} \n presignClient := s3.NewPresignClient(s3Client) \n presigner := actions.Presigner{PresignClient: presignClient} \n bucketName := questioner.Ask(\"We'll need a bucket. Enter a name for a bucket \"+ \n  \"you own or one you want to create:\", demotools.NotEmpty{}) \n bucketExists, err := bucketBasics.BucketExists(ctx, bucketName) \n if err != nil { \n  panic(err) \n } \n if !bucketExists { \n  err = bucketBasics.CreateBucket(ctx, bucketName, sdkConfig.Region) \n  if err != nil { \n   panic(err) \n  } else { \n   log.Println(\"Bucket created.\") \n  } \n } \n log.Println(strings.Repeat(\"-\", 88)) \n log.Printf(\"Let's presign a request to upload a file to your bucket.\") \n uploadFilename := questioner.Ask(\"Enter the path to a file you want to upload:\", \n  demotools.NotEmpty{}) \n uploadKey := questioner.Ask(\"What would you like to name the uploaded object?\", \n  demotools.NotEmpty{}) \n uploadFile, err := os.Open(uploadFilename) \n if err != nil { \n  panic(err) \n } \n defer uploadFile.Close() \n presignedPutRequest, err := presigner.PutObject(ctx, bucketName, uploadKey, 60) \n if err != nil { \n  panic(err) \n } \n log.Printf(\"Got a presigned %v request to URL:\\n\\t%v\\n\", \n presignedPutRequest.Method, \n  presignedPutRequest.URL) \n log.Println(\"Using net/http to send the request...\") \nScenarios API Version 2006-03-01 2300Amazon Simple Storage Service API Reference\n info, err := uploadFile.Stat() \n if err != nil { \n  panic(err) \n } \n putResponse, err := httpRequester.Put(presignedPutRequest.URL, info.Size(), \n uploadFile) \n if err != nil { \n  panic(err) \n } \n log.Printf(\"%v object %v with presigned URL returned %v.\", \n presignedPutRequest.Method, \n  uploadKey, putResponse.StatusCode) \n log.Println(strings.Repeat(\"-\", 88)) \n log.Printf(\"Let's presign a request to download the object.\") \n questioner.Ask(\"Press Enter when you're ready.\") \n presignedGetRequest, err := presigner.GetObject(ctx, bucketName, uploadKey, 60) \n if err != nil { \n  panic(err) \n } \n log.Printf(\"Got a presigned %v request to URL:\\n\\t%v\\n\", \n presignedGetRequest.Method, \n  presignedGetRequest.URL) \n log.Println(\"Using net/http to send the request...\") \n getResponse, err := httpRequester.Get(presignedGetRequest.URL) \n if err != nil { \n  panic(err) \n } \n log.Printf(\"%v object %v with presigned URL returned %v.\", \n presignedGetRequest.Method, \n  uploadKey, getResponse.StatusCode) \n defer getResponse.Body.Close() \n downloadBody, err := io.ReadAll(getResponse.Body) \n if err != nil { \n  panic(err) \n } \n log.Printf(\"Downloaded %v bytes. Here are the first 100 of them:\\n\", \n len(downloadBody)) \n log.Println(strings.Repeat(\"-\", 88)) \n log.Println(string(downloadBody[:100])) \n log.Println(strings.Repeat(\"-\", 88)) \n log.Println(\"Now we'll create a new request to put the same object using a \n presigned post request\") \nScenarios API Version 2006-03-01 2301Amazon Simple Storage Service API Reference\n questioner.Ask(\"Press Enter when you're ready.\") \n presignPostRequest, err := presigner.PresignPostObject(ctx, bucketName, \n uploadKey, 60) \n if err != nil { \n  panic(err) \n } \n log.Printf(\"Got a presigned post request to url %v with values %v\\n\", \n presignPostRequest.URL, presignPostRequest.Values) \n log.Println(\"Using net/http multipart to send the request...\") \n uploadFile, err = os.Open(uploadFilename) \n if err != nil { \n  panic(err) \n } \n defer uploadFile.Close() \n multiPartResponse, err := sendMultipartRequest(presignPostRequest.URL, \n presignPostRequest.Values, uploadFile, uploadKey, httpRequester) \n if err != nil { \n  panic(err) \n } \n log.Printf(\"Presign post object %v with presigned URL returned %v.\", uploadKey, \n multiPartResponse.StatusCode) \n log.Println(\"Let's presign a request to delete the object.\") \n questioner.Ask(\"Press Enter when you're ready.\") \n presignedDelRequest, err := presigner.DeleteObject(ctx, bucketName, uploadKey) \n if err != nil { \n  panic(err) \n } \n log.Printf(\"Got a presigned %v request to URL:\\n\\t%v\\n\", \n presignedDelRequest.Method, \n  presignedDelRequest.URL) \n log.Println(\"Using net/http to send the request...\") \n delResponse, err := httpRequester.Delete(presignedDelRequest.URL) \n if err != nil { \n  panic(err) \n } \n log.Printf(\"%v object %v with presigned URL returned %v.\\n\", \n presignedDelRequest.Method, \n  uploadKey, delResponse.StatusCode) \n log.Println(strings.Repeat(\"-\", 88)) \n log.Println(\"Thanks for watching!\") \n log.Println(strings.Repeat(\"-\", 88))\n}\nScenarios API Version 2006-03-01 2302Amazon Simple Storage Service API Reference\nDe\ufb01ne an HTTP request wrapper used by the example to make HTTP requests.\n// IHttpRequester abstracts HTTP requests into an interface so it can be mocked \n during\n// unit testing.\ntype IHttpRequester interface { \n Get(url string) (resp *http.Response, err error) \n Post(url, contentType string, body io.Reader) (resp *http.Response, err error) \n Put(url string, contentLength int64, body io.Reader) (resp *http.Response, err \n error) \n Delete(url string) (resp *http.Response, err error)\n}\n// HttpRequester uses the net/http package to make HTTP requests during the \n scenario.\ntype HttpRequester struct{}\nfunc (httpReq HttpRequester) Get(url string) (resp *http.Response, err error) { \n return http.Get(url)\n}\nfunc (httpReq HttpRequester) Post(url, contentType string, body io.Reader) (resp \n *http.Response, err error) { \n postRequest, err := http.NewRequest(\"POST\", url, body) \n if err != nil { \n  return nil, err \n } \n postRequest.Header.Set(\"Content-Type\", contentType) \n return http.DefaultClient.Do(postRequest)\n}\nfunc (httpReq HttpRequester) Put(url string, contentLength int64, body io.Reader) \n (resp *http.Response, err error) { \n putRequest, err := http.NewRequest(\"PUT\", url, body) \n if err != nil { \n  return nil, err \n } \n putRequest.ContentLength = contentLength \n return http.DefaultClient.Do(putRequest)\n}\nScenarios API Version 2006-03-01 2303Amazon Simple Storage Service API Reference\nfunc (httpReq HttpRequester) Delete(url string) (resp *http.Response, err error) \n { \n delRequest, err := http.NewRequest(\"DELETE\", url, nil) \n if err != nil { \n  return nil, err \n } \n return http.DefaultClient.Do(delRequest)\n}\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nGenerate a pre-signed URL for an object, then download it (GET request).\nImports.\nimport com.example.s3.util.PresignUrlUtils;\nimport org.slf4j.Logger;\nimport software.amazon.awssdk.http.HttpExecuteRequest;\nimport software.amazon.awssdk.http.HttpExecuteResponse;\nimport software.amazon.awssdk.http.SdkHttpClient;\nimport software.amazon.awssdk.http.SdkHttpMethod;\nimport software.amazon.awssdk.http.SdkHttpRequest;\nimport software.amazon.awssdk.http.apache.ApacheHttpClient;\nimport software.amazon.awssdk.services.s3.S3Client;\nimport software.amazon.awssdk.services.s3.model.GetObjectRequest;\nimport software.amazon.awssdk.services.s3.model.S3Exception;\nimport software.amazon.awssdk.services.s3.presigner.S3Presigner;\nimport \n software.amazon.awssdk.services.s3.presigner.model.GetObjectPresignRequest;\nimport \n software.amazon.awssdk.services.s3.presigner.model.PresignedGetObjectRequest;\nimport software.amazon.awssdk.utils.IoUtils;\nScenarios API Version 2006-03-01 2304Amazon Simple Storage Service API Reference\nimport java.io.ByteArrayOutputStream;\nimport java.io.File;\nimport java.io.IOException;\nimport java.io.InputStream;\nimport java.net.HttpURLConnection;\nimport java.net.URISyntaxException;\nimport java.net.URL;\nimport java.net.http.HttpClient;\nimport java.net.http.HttpRequest;\nimport java.net.http.HttpResponse;\nimport java.nio.file.Paths;\nimport java.time.Duration;\nimport java.util.UUID;\nGenerate the URL.\n    /* Create a pre-signed URL to download an object in a subsequent GET request.", "\n */ \n    public String createPresignedGetUrl(String bucketName, String keyName) { \n        try (S3Presigner presigner = S3Presigner.create()) { \n            GetObjectRequest objectRequest = GetObjectRequest.builder() \n                    .bucket(bucketName) \n                    .key(keyName) \n                    .build(); \n            GetObjectPresignRequest presignRequest = \n GetObjectPresignRequest.builder() \n                    .signatureDuration(Duration.ofMinutes(10))  // The URL will \n expire in 10 minutes.", "\n                    .getObjectRequest(objectRequest) \n                    .build(); \n            PresignedGetObjectRequest presignedRequest = \n presigner.presignGetObject(presignRequest); \n            logger.info(\"Presigned URL: [{}]\", \n presignedRequest.url().toString()); \n            logger.info(\"HTTP method: [{}]\", \n presignedRequest.httpRequest().method()); \n            return presignedRequest.url().toExternalForm(); \nScenarios API Version 2006-03-01 2305Amazon Simple Storage Service API Reference\n        } \n    }\nDownload the object by using any one of the following three approaches.\nUse JDK HttpURLConnection  (since v1.1) class to do the download.\n    /* Use the JDK HttpURLConnection (since v1.1) class to do the download. */ \n    public byte[] useHttpUrlConnectionToGet(String presignedUrlString) { \n        ByteArrayOutputStream byteArrayOutputStream = new \n ByteArrayOutputStream(); // Capture the response body to a byte array. \n        try { \n            URL presignedUrl = new URL(presignedUrlString); \n            HttpURLConnection connection = (HttpURLConnection) \n presignedUrl.openConnection(); \n            connection.setRequestMethod(\"GET\"); \n            // Download the result of executing the request.", "\n            try (InputStream content = connection.getInputStream()) { \n                IoUtils.copy(content, byteArrayOutputStream); \n            } \n            logger.info(\"HTTP response code is \" + connection.getResponseCode()); \n        } catch (S3Exception | IOException e) { \n            logger.error(e.getMessage(), e); \n        } \n        return byteArrayOutputStream.toByteArray(); \n    }\nUse JDK HttpClient  (since v11) class to do the download.\n    /* Use the JDK HttpClient (since v11) class to do the download.", "*/ \n    public byte[] useHttpClientToGet(String presignedUrlString) { \n        ByteArrayOutputStream byteArrayOutputStream = new \n ByteArrayOutputStream(); // Capture the response body to a byte array. \n        HttpRequest.Builder requestBuilder = HttpRequest.newBuilder(); \n        HttpClient httpClient = HttpClient.newHttpClient(); \n        try { \n            URL presignedUrl = new URL(presignedUrlString); \n            HttpResponse<InputStream> response = httpClient.send(requestBuilder \nScenarios API Version 2006-03-01 2306Amazon Simple Storage Service API Reference\n                            .uri(presignedUrl.toURI()) \n                            .GET() \n                            .build(), \n                    HttpResponse.BodyHandlers.ofInputStream()); \n            IoUtils.copy(response.body(), byteArrayOutputStream); \n            logger.info(\"HTTP response code is \" + response.statusCode()); \n        } catch (URISyntaxException | InterruptedException | IOException e) { \n            logger.error(e.getMessage(), e); \n        } \n        return byteArrayOutputStream.toByteArray(); \n    }\nUse the AWS SDK for Java SdkHttpClient  class to do the download.\n    /* Use the AWS SDK for Java SdkHttpClient class to do the download. */ \n    public byte[] useSdkHttpClientToPut(String presignedUrlString) { \n        ByteArrayOutputStream byteArrayOutputStream = new \n ByteArrayOutputStream(); // Capture the response body to a byte array. \n        try { \n            URL presignedUrl = new URL(presignedUrlString); \n            SdkHttpRequest request = SdkHttpRequest.builder() \n                    .method(SdkHttpMethod.GET) \n                    .uri(presignedUrl.toURI()) \n                    .build(); \n            HttpExecuteRequest executeRequest = HttpExecuteRequest.builder() \n                    .request(request) \n                    .build(); \n            try (SdkHttpClient sdkHttpClient = ApacheHttpClient.create()) { \n                HttpExecuteResponse response = \n sdkHttpClient.prepareRequest(executeRequest).call(); \n                response.responseBody().ifPresentOrElse( \n                        abortableInputStream -> { \n                            try { \n                                IoUtils.copy(abortableInputStream, \n byteArrayOutputStream); \n                            } catch (IOException e) { \nScenarios API Version 2006-03-01 2307Amazon Simple Storage Service API Reference\n                                throw new RuntimeException(e); \n                            } \n                        }, \n                        () -> logger.error(\"No response body.\")); \n                logger.info(\"HTTP Response code is {}\", \n response.httpResponse().statusCode()); \n            } \n        } catch (URISyntaxException | IOException e) { \n            logger.error(e.getMessage(), e); \n        } \n        return byteArrayOutputStream.toByteArray(); \n    }\nGenerate a pre-signed URL for an upload, then upload a \ufb01le (PUT request).\nImports.\nimport com.example.s3.util.PresignUrlUtils;\nimport org.slf4j.Logger;\nimport software.amazon.awssdk.core.internal.sync.FileContentStreamProvider;\nimport software.amazon.awssdk.http.HttpExecuteRequest;\nimport software.amazon.awssdk.http.HttpExecuteResponse;\nimport software.amazon.awssdk.http.SdkHttpClient;\nimport software.amazon.awssdk.http.SdkHttpMethod;\nimport software.amazon.awssdk.http.SdkHttpRequest;\nimport software.amazon.awssdk.http.apache.ApacheHttpClient;\nimport software.amazon.awssdk.services.s3.S3Client;\nimport software.amazon.awssdk.services.s3.model.PutObjectRequest;\nimport software.amazon.awssdk.services.s3.model.S3Exception;\nimport software.amazon.awssdk.services.s3.presigner.S3Presigner;\nimport \n software.amazon.awssdk.services.s3.presigner.model.PresignedPutObjectRequest;\nimport \n software.amazon.awssdk.services.s3.presigner.model.PutObjectPresignRequest;\nimport java.io.File;\nimport java.io.IOException;\nimport java.io.OutputStream;\nimport java.io.RandomAccessFile;\nimport java.net.HttpURLConnection;\nimport java.net.URISyntaxException;\nimport java.net.URL;\nScenarios API Version 2006-03-01 2308Amazon Simple Storage Service API Reference\nimport java.net.http.HttpClient;\nimport java.net.http.HttpRequest;\nimport java.net.http.HttpResponse;\nimport java.nio.ByteBuffer;\nimport java.nio.channels.FileChannel;\nimport java.nio.file.Path;\nimport java.nio.file.Paths;\nimport java.time.Duration;\nimport java.util.Map;\nimport java.util.UUID;\nGenerate the URL.\n    /* Create a presigned URL to use in a subsequent PUT request */ \n    public String createPresignedUrl(String bucketName, String keyName, \n Map<String, String> metadata) { \n        try (S3Presigner presigner = S3Presigner.create()) { \n            PutObjectRequest objectRequest = PutObjectRequest.builder() \n                    .bucket(bucketName) \n                    .key(keyName) \n                    .metadata(metadata) \n                    .build(); \n            PutObjectPresignRequest presignRequest = \n PutObjectPresignRequest.builder() \n                    .signatureDuration(Duration.ofMinutes(10))  // The URL \n expires in 10 minutes. \n                    .putObjectRequest(objectRequest) \n                    .build(); \n            PresignedPutObjectRequest presignedRequest = \n presigner.presignPutObject(presignRequest); \n            String myURL = presignedRequest.url().toString(); \n            logger.info(\"Presigned URL to upload a file to: [{}]\", myURL); \n            logger.info(\"HTTP method: [{}]\", \n presignedRequest.httpRequest().method()); \n            return presignedRequest.url().toExternalForm(); \n        } \n    }\nScenarios API Version 2006-03-01 2309Amazon Simple Storage Service API Reference\nUpload a \ufb01le object by using any one of the following three approaches.\nUse the JDK HttpURLConnection  (since v1.1) class to do the upload.\n    /* Use the JDK HttpURLConnection (since v1.1) class to do the upload. */ \n    public void useHttpUrlConnectionToPut(String presignedUrlString, File \n fileToPut, Map<String, String> metadata) { \n        logger.info(\"Begin [{}] upload\", fileToPut.toString()); \n        try { \n            URL presignedUrl = new URL(presignedUrlString); \n            HttpURLConnection connection = (HttpURLConnection) \n presignedUrl.openConnection(); \n            connection.setDoOutput(true); \n            metadata.forEach((k, v) -> connection.setRequestProperty(\"x-amz-\nmeta-\" + k, v)); \n            connection.setRequestMethod(\"PUT\"); \n            OutputStream out = connection.getOutputStream(); \n            try (RandomAccessFile file = new RandomAccessFile(fileToPut, \"r\"); \n                 FileChannel inChannel = file.getChannel()) { \n                ByteBuffer buffer = ByteBuffer.allocate(8192); //Buffer size is \n 8k \n                while (inChannel.read(buffer) > 0) { \n                    buffer.flip(); \n                    for (int i = 0; i < buffer.limit(); i++) { \n                        out.write(buffer.get()); \n                    } \n                    buffer.clear(); \n                } \n            } catch (IOException e) { \n                logger.error(e.getMessage(), e); \n            } \n            out.close(); \n            connection.getResponseCode(); \n            logger.info(\"HTTP response code is \" + connection.getResponseCode()); \n        } catch (S3Exception | IOException e) { \n            logger.error(e.getMessage(), e); \n        } \n    }\nScenarios API Version 2006-03-01 2310Amazon Simple Storage Service API Reference\nUse the JDK HttpClient  (since v11) class to do the upload.\n    /* Use the JDK HttpClient (since v11) class to do the upload. */ \n    public void useHttpClientToPut(String presignedUrlString, File fileToPut, \n Map<String, String> metadata) { \n        logger.info(\"Begin [{}] upload\", fileToPut.toString()); \n        HttpRequest.Builder requestBuilder = HttpRequest.newBuilder(); \n        metadata.forEach((k, v) -> requestBuilder.header(\"x-amz-meta-\" + k, v)); \n        HttpClient httpClient = HttpClient.newHttpClient(); \n        try { \n            final HttpResponse<Void> response = httpClient.send(requestBuilder \n                            .uri(new URL(presignedUrlString).toURI()) \n                            \n .PUT(HttpRequest.BodyPublishers.ofFile(Path.of(fileToPut.toURI()))) \n                            .build(), \n                    HttpResponse.BodyHandlers.discarding()); \n            logger.info(\"HTTP response code is \" + response.statusCode()); \n        } catch (URISyntaxException | InterruptedException | IOException e) { \n            logger.error(e.getMessage(), e); \n        } \n    }\nUse the AWS for Java V2 SdkHttpClient  class to do the upload.\n    /* Use the AWS SDK for Java V2 SdkHttpClient class to do the upload.", "*/ \n    public void useSdkHttpClientToPut(String presignedUrlString, File fileToPut, \n Map<String, String> metadata) { \n        logger.info(\"Begin [{}] upload\", fileToPut.toString()); \n        try { \n            URL presignedUrl = new URL(presignedUrlString); \n            SdkHttpRequest.Builder requestBuilder = SdkHttpRequest.builder() \n                    .method(SdkHttpMethod.PUT) \n                    .uri(presignedUrl.toURI()); \n            // Add headers \nScenarios API Version 2006-03-01 2311Amazon Simple Storage Service API Reference\n            metadata.forEach((k, v) -> requestBuilder.putHeader(\"x-amz-meta-\" + \n k, v)); \n            // Finish building the request. \n            SdkHttpRequest request = requestBuilder.build(); \n            HttpExecuteRequest executeRequest = HttpExecuteRequest.builder() \n                    .request(request) \n                    .contentStreamProvider(new \n FileContentStreamProvider(fileToPut.toPath())) \n                    .build(); \n            try (SdkHttpClient sdkHttpClient = ApacheHttpClient.create()) { \n                HttpExecuteResponse response = \n sdkHttpClient.prepareRequest(executeRequest).call(); \n                logger.info(\"Response code: {}\", \n response.httpResponse().statusCode()); \n            } \n        } catch (URISyntaxException | IOException e) { \n            logger.error(e.getMessage(), e); \n        } \n    }\nJavaScript\nSDK for JavaScript (v3)\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nCreate a presigned URL to upload an object to a bucket.\nimport https from \"node:https\";\nimport { XMLParser } from \"fast-xml-parser\";\nimport { PutObjectCommand, S3Client } from \"@aws-sdk/client-s3\";\nimport { fromIni } from \"@aws-sdk/credential-providers\";\nimport { HttpRequest } from \"@smithy/protocol-http\";\nimport { \nScenarios API Version 2006-03-01 2312Amazon Simple Storage Service API Reference\n  getSignedUrl, \n  S3RequestPresigner,\n} from \"@aws-sdk/s3-request-presigner\";\nimport { parseUrl } from \"@smithy/url-parser\";\nimport { formatUrl } from \"@aws-sdk/util-format-url\";\nimport { Hash } from \"@smithy/hash-node\";\nconst createPresignedUrlWithoutClient = async ({ region, bucket, key }) => { \n  const url = parseUrl(`https://${bucket}.s3.${region}.amazonaws.com/${key}`); \n  const presigner = new S3RequestPresigner({ \n    credentials: fromIni(), \n    region, \n    sha256: Hash.bind(null, \"sha256\"), \n  }); \n  const signedUrlObject = await presigner.presign( \n    new HttpRequest({ ...url, method: \"PUT\" }), \n  ); \n  return formatUrl(signedUrlObject);\n};\nconst createPresignedUrlWithClient = ({ region, bucket, key }) => { \n  const client = new S3Client({ region }); \n  const command = new PutObjectCommand({ Bucket: bucket, Key: key }); \n  return getSignedUrl(client, command, { expiresIn: 3600 });\n};\n/** \n * Make a PUT request to the provided URL. \n * \n * @param {string} url \n * @param {string} data \n */\nconst put = (url, data) => { \n  return new Promise((resolve, reject) => { \n    const req = https.request( \n      url, \n      { method: \"PUT\", headers: { \"Content-Length\": new Blob([data]).size } }, \n      (res) => { \n        let responseBody = \"\"; \n        res.on(\"data\", (chunk) => { \n          responseBody += chunk; \n        }); \n        res.on(\"end\", () => { \nScenarios API Version 2006-03-01 2313Amazon Simple Storage Service API Reference\n          const parser = new XMLParser(); \n          if (res.statusCode >= 200 && res.statusCode <= 299) { \n            resolve(parser.parse(responseBody, true)); \n          } else { \n            reject(parser.parse(responseBody, true)); \n          } \n        }); \n      }, \n    ); \n    req.on(\"error\", (err) => { \n      reject(err); \n    }); \n    req.write(data); \n    req.end(); \n  });\n};\n/** \n * Create two presigned urls for uploading an object to an S3 bucket.", "\n * The first presigned URL is created with credentials from the shared INI file \n * in the current environment.", "The second presigned URL is created using an \n * existing S3Client instance that has already been provided with credentials.", "\n * @param {{ bucketName: string, key: string, region: string }} \n */\nexport const main = async ({ bucketName, key, region }) => { \n  try { \n    const noClientUrl = await createPresignedUrlWithoutClient({ \n      bucket: bucketName, \n      key, \n      region, \n    }); \n    const clientUrl = await createPresignedUrlWithClient({ \n      bucket: bucketName, \n      region, \n      key, \n    }); \n    // After you get the presigned URL, you can provide your own file \n    // data.", "Refer to put() above. \n    console.log(\"Calling PUT using presigned URL without client\"); \n    await put(noClientUrl, \"Hello World\"); \n    console.log(\"Calling PUT using presigned URL with client\"); \nScenarios API Version 2006-03-01 2314Amazon Simple Storage Service API Reference\n    await put(clientUrl, \"Hello World\"); \n    console.log(\"\\nDone.", "Check your S3 console.\"); \n  } catch (caught) { \n    if (caught instanceof Error && caught.name === \"CredentialsProviderError\") { \n      console.error( \n        `There was an error getting your credentials. Are your local credentials \n configured?\\n${caught.name}: ${caught.message}`, \n      ); \n    } else { \n      throw caught; \n    } \n  }\n};\nCreate a presigned URL to download an object from a bucket.\nimport { GetObjectCommand, S3Client } from \"@aws-sdk/client-s3\";\nimport { fromIni } from \"@aws-sdk/credential-providers\";\nimport { HttpRequest } from \"@smithy/protocol-http\";\nimport { \n  getSignedUrl, \n  S3RequestPresigner,\n} from \"@aws-sdk/s3-request-presigner\";\nimport { parseUrl } from \"@smithy/url-parser\";\nimport { formatUrl } from \"@aws-sdk/util-format-url\";\nimport { Hash } from \"@smithy/hash-node\";\nconst createPresignedUrlWithoutClient = async ({ region, bucket, key }) => { \n  const url = parseUrl(`https://${bucket}.s3.${region}.amazonaws.com/${key}`); \n  const presigner = new S3RequestPresigner({ \n    credentials: fromIni(), \n    region, \n    sha256: Hash.bind(null, \"sha256\"), \n  }); \n  const signedUrlObject = await presigner.presign(new HttpRequest(url)); \n  return formatUrl(signedUrlObject);\n};\nconst createPresignedUrlWithClient = ({ region, bucket, key }) => { \n  const client = new S3Client({ region }); \nScenarios API Version 2006-03-01 2315Amazon Simple Storage Service API Reference\n  const command = new GetObjectCommand({ Bucket: bucket, Key: key }); \n  return getSignedUrl(client, command, { expiresIn: 3600 });\n};\n/** \n * Create two presigned urls for downloading an object from an S3 bucket.", "\n * The first presigned URL is created with credentials from the shared INI file \n * in the current environment.", "The second presigned URL is created using an \n * existing S3Client instance that has already been provided with credentials.", "\n * @param {{ bucketName: string, key: string, region: string }} \n */\nexport const main = async ({ bucketName, key, region }) => { \n  try { \n    const noClientUrl = await createPresignedUrlWithoutClient({ \n      bucket: bucketName, \n      region, \n      key, \n    }); \n    const clientUrl = await createPresignedUrlWithClient({ \n      bucket: bucketName, \n      region, \n      key, \n    }); \n    console.log(\"Presigned URL without client\"); \n    console.log(noClientUrl); \n    console.log(\"\\n\"); \n    console.log(\"Presigned URL with client\"); \n    console.log(clientUrl); \n  } catch (caught) { \n    if (caught instanceof Error && caught.name === \"CredentialsProviderError\") { \n      console.error( \n        `There was an error getting your credentials.", "Are your local credentials \n configured?\\n${caught.name}: ${caught.message}`, \n      ); \n    } else { \n      throw caught; \n    } \n  }\n};\nScenarios API Version 2006-03-01 2316Amazon Simple Storage Service API Reference\n\u2022For more information, see AWS SDK for JavaScript Developer Guide.\nKotlin\nSDK for Kotlin\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nCreate a GetObject  presigned request and use the URL to download an object.\nsuspend fun getObjectPresigned( \n    s3: S3Client, \n    bucketName: String, \n    keyName: String,\n): String { \n    // Create a GetObjectRequest.", "\n    val unsignedRequest = \n        GetObjectRequest { \n            bucket = bucketName \n            key = keyName \n        } \n    // Presign the GetObject request.", "\n    val presignedRequest = s3.presignGetObject(unsignedRequest, 24.hours) \n    // Use the URL from the presigned HttpRequest in a subsequent HTTP GET \n request to retrieve the object. \n    val objectContents = URL(presignedRequest.url.toString()).readText() \n    return objectContents\n}\nCreate a GetObject  presigned request with advanced options.\nsuspend fun getObjectPresignedMoreOptions( \n    s3: S3Client, \nScenarios API Version 2006-03-01 2317Amazon Simple Storage Service API Reference\n    bucketName: String, \n    keyName: String,\n): HttpRequest { \n    // Create a GetObjectRequest.", "\n    val unsignedRequest = \n        GetObjectRequest { \n            bucket = bucketName \n            key = keyName \n        } \n    // Presign the GetObject request.", "\n    val presignedRequest = \n        s3.presignGetObject(unsignedRequest, signer = CrtAwsSigner) { \n            signingDate = Instant.now() + 12.hours // Presigned request can be \n used 12 hours from now.", "\n            algorithm = AwsSigningAlgorithm.SIGV4_ASYMMETRIC \n            signatureType = AwsSignatureType.HTTP_REQUEST_VIA_QUERY_PARAMS \n            expiresAfter = 8.hours // Presigned request expires 8 hours later.", "\n        } \n    return presignedRequest\n}\nCreate a PutObject  presigned request and use it to upload an object.\nsuspend fun putObjectPresigned( \n    s3: S3Client, \n    bucketName: String, \n    keyName: String, \n    content: String,\n) { \n    // Create a PutObjectRequest.", "\n    val unsignedRequest = \n        PutObjectRequest { \n            bucket = bucketName \n            key = keyName \n        } \n    // Presign the request.", "\n    val presignedRequest = s3.presignPutObject(unsignedRequest, 24.hours) \n    // Use the URL and any headers from the presigned HttpRequest in a subsequent \n HTTP PUT request to retrieve the object.", "\nScenarios API Version 2006-03-01 2318Amazon Simple Storage Service API Reference\n    // Create a PUT request using the OKHttpClient API.", "\n    val putRequest = \n        Request \n            .Builder() \n            .url(presignedRequest.url.toString()) \n            .apply { \n                presignedRequest.headers.forEach { key, values -> \n                    header(key, values.joinToString(\", \")) \n                } \n            }.put(content.toRequestBody()) \n            .build() \n    val response = OkHttpClient().newCall(putRequest).execute() \n    assert(response.isSuccessful)\n}\n\u2022For more information, see AWS SDK for Kotlin developer guide.\nPHP\nSDK for PHP\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nnamespace S3;\nuse Aws\\Exception\\AwsException;\nuse AwsUtilities\\PrintableLineBreak;\nuse AwsUtilities\\TestableReadline;\nuse DateTime;\nrequire 'vendor/autoload.php';\nclass PresignedURL\n{ \n    use PrintableLineBreak; \n    use TestableReadline; \nScenarios API Version 2006-03-01 2319Amazon Simple Storage Service API Reference\n    public function run() \n    { \n        $s3Service = new S3Service(); \n        $expiration = new DateTime(\"+20 minutes\"); \n        $linebreak = $this->getLineBreak(); \n        echo $linebreak; \n        echo (\"Welcome to the Amazon S3 presigned URL demo.\\n\"); \n        echo $linebreak; \n        $bucket = $this->testable_readline(\"First, please enter the name of the \n S3 bucket to use: \"); \n        $key = $this->testable_readline(\"Next, provide the key of an object in \n the given bucket: \"); \n        echo $linebreak; \n        $command = $s3Service->getClient()->getCommand('GetObject', [ \n            'Bucket' => $bucket, \n            'Key' => $key, \n        ]); \n        try { \n            $preSignedUrl = $s3Service->preSignedUrl($command, $expiration); \n            echo \"Your preSignedUrl is \\n$preSignedUrl\\nand will be good for the \n next 20 minutes.\\n\"; \n            echo $linebreak; \n            echo \"Thanks for trying the Amazon S3 presigned URL demo.\\n\"; \n        } catch (AwsException $exception) { \n            echo $linebreak; \n            echo \"Something went wrong: $exception\"; \n            die(); \n        } \n    }\n}\n$runner = new PresignedURL();\n$runner->run();\nScenarios API Version 2006-03-01 2320Amazon Simple Storage Service API Reference\nPython\nSDK for Python (Boto3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nGenerate a presigned URL that can perform an S3 action for a limited time. Use the \nRequests package to make a request with the URL.\nimport argparse\nimport logging\nimport boto3\nfrom botocore.exceptions import ClientError\nimport requests\nlogger = logging.getLogger(__name__)\ndef generate_presigned_url(s3_client, client_method, method_parameters, \n expires_in): \n    \"\"\" \n    Generate a presigned Amazon S3 URL that can be used to perform an action. \n    :param s3_client: A Boto3 Amazon S3 client.", "\n    :param client_method: The name of the client method that the URL performs. \n    :param method_parameters: The parameters of the specified client method. \n    :param expires_in: The number of seconds the presigned URL is valid for. \n    :return: The presigned URL.", "\n    \"\"\" \n    try: \n        url = s3_client.generate_presigned_url( \n            ClientMethod=client_method, Params=method_parameters, \n ExpiresIn=expires_in \n        ) \n        logger.info(\"Got presigned URL: %s\", url) \n    except ClientError: \n        logger.exception( \n            \"Couldn't get a presigned URL for client method '%s'.\", client_method \nScenarios API Version 2006-03-01 2321Amazon Simple Storage Service API Reference\n        ) \n        raise \n    return url\ndef usage_demo(): \n    logging.basicConfig(level=logging.INFO, format=\"%(levelname)s: %(message)s\") \n    print(\"-\" * 88) \n    print(\"Welcome to the Amazon S3 presigned URL demo.\") \n    print(\"-\" * 88) \n    parser = argparse.ArgumentParser() \n    parser.add_argument(\"bucket\", help=\"The name of the bucket.\") \n    parser.add_argument( \n        \"key\", \n        help=\"For a GET operation, the key of the object in Amazon S3. For a \" \n        \"PUT operation, the name of a file to upload.\", \n    ) \n    parser.add_argument(\"action\", choices=(\"get\", \"put\"), help=\"The action to \n perform.\") \n    args = parser.parse_args() \n    s3_client = boto3.client(\"s3\") \n    client_action = \"get_object\" if args.action == \"get\" else \"put_object\" \n    url = generate_presigned_url( \n        s3_client, client_action, {\"Bucket\": args.bucket, \"Key\": args.key}, 1000 \n    ) \n    print(\"Using the Requests package to send a request to the URL.\") \n    response = None \n    if args.action == \"get\": \n        response = requests.get(url) \n        if response.status_code == 200: \n            with open(args.key.split(\"/\")[-1], 'wb') as object_file: \n                object_file.write(response.content) \n    elif args.action == \"put\": \n        print(\"Putting data to the URL.\") \n        try: \n            with open(args.key, \"rb\") as object_file: \n                object_text = object_file.read() \n            response = requests.put(url, data=object_text) \n        except FileNotFoundError: \n            print( \nScenarios API Version 2006-03-01 2322Amazon Simple Storage Service API Reference\n                f\"Couldn't find {args.key}. For a PUT operation, the key must be \n the \" \n                f\"name of a file that exists on your computer.\" \n            ) \n    if response is not None: \n        print(f\"Status: {response.status_code}\\nReason: {response.reason}\") \n    print(\"-\" * 88)\nif __name__ == \"__main__\": \n    usage_demo()\nGenerate a presigned POST request to upload a \ufb01le.\nclass BucketWrapper: \n    \"\"\"Encapsulates S3 bucket actions.\"\"\" \n    def __init__(self, bucket): \n        \"\"\" \n        :param bucket: A Boto3 Bucket resource. This is a high-level resource in \n Boto3 \n                       that wraps bucket actions in a class-like structure. \n        \"\"\" \n        self.bucket = bucket \n        self.name = bucket.name \n    def generate_presigned_post(self, object_key, expires_in): \n        \"\"\" \n        Generate a presigned Amazon S3 POST request to upload a file. \n        A presigned POST can be used for a limited time to let someone without an \n AWS \n        account upload a file to a bucket.", "\n        :param object_key: The object key to identify the uploaded object.", "\n        :param expires_in: The number of seconds the presigned POST is valid.", "\n        :return: A dictionary that contains the URL and form fields that contain \n                 required access data.", "\n        \"\"\" \n        try: \nScenarios API Version 2006-03-01 2323Amazon Simple Storage Service API Reference\n            response = self.bucket.meta.client.generate_presigned_post( \n                Bucket=self.bucket.name, Key=object_key, ExpiresIn=expires_in \n            ) \n            logger.info(\"Got presigned POST URL: %s\", response[\"url\"]) \n        except ClientError: \n            logger.exception( \n                \"Couldn't get a presigned POST URL for bucket '%s' and object \n '%s'\", \n                self.bucket.name, \n                object_key, \n            ) \n            raise \n        return response\nRuby\nSDK for Ruby\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nrequire 'aws-sdk-s3'\nrequire 'net/http'\n# Creates a presigned URL that can be used to upload content to an object.\n#\n# @param bucket [Aws::S3::Bucket] An existing Amazon S3 bucket.\n# @param object_key [String] The key to give the uploaded object.\n# @return [URI, nil] The parsed URI if successful; otherwise nil.\ndef get_presigned_url(bucket, object_key) \n  url = bucket.object(object_key).presigned_url(:put) \n  puts \"Created presigned URL: #{url}\" \n  URI(url)\nrescue Aws::Errors::ServiceError => e \nScenarios API Version 2006-03-01 2324Amazon Simple Storage Service API Reference\n  puts \"Couldn't create presigned URL for #{bucket.name}:#{object_key}. Here's \n why: #{e.message}\"\nend\n# Example usage:\ndef run_demo\n<<<<<<< HEAD \n  bucket_name = \"amzn-s3-demo-bucket\" \n  object_key = \"my-file.txt\" \n  object_content = \"This is the content of my-file.txt.\"\n======= \n  bucket_name = 'doc-example-bucket' \n  object_key = 'my-file.txt' \n  object_content = 'This is the content of my-file.txt.'\n>>>>>>> 999c6133e (fixes) \n  bucket = Aws::S3::Bucket.new(bucket_name) \n  presigned_url = get_presigned_url(bucket, object_key) \n  return unless presigned_url \n  response = Net::HTTP.start(presigned_url.host) do |http| \n    http.send_request('PUT', presigned_url.request_uri, object_content, \n 'content_type' => '') \n  end \n  case response \n  when Net::HTTPSuccess \n    puts 'Content uploaded!' \n  else \n    puts response.value \n  end\nend\nrun_demo if $PROGRAM_NAME == __FILE__\nScenarios API Version 2006-03-01 2325Amazon Simple Storage Service API Reference\nRust\nSDK for Rust\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nCreate presigning requests to GET S3 objects.\n/// Generate a URL for a presigned GET request.\nasync fn get_object( \n    client: &Client, \n    bucket: &str, \n    object: &str, \n    expires_in: u64,\n) -> Result<(), Box<dyn Error>> { \n    let expires_in = Duration::from_secs(expires_in); \n    let presigned_request = client \n        .get_object() \n        .bucket(bucket) \n        .key(object) \n        .presigned(PresigningConfig::expires_in(expires_in)?) \n        .await?; \n    println!(\"Object URI: {}\", presigned_request.uri()); \n    let valid_until = chrono::offset::Local::now() + expires_in; \n    println!(\"Valid until: {valid_until}\"); \n    Ok(())\n}\nCreate presigning requests to PUT S3 objects.\nasync fn put_object( \n    client: &Client, \n    bucket: &str, \n    object: &str, \n    expires_in: u64,\nScenarios API Version 2006-03-01 2326Amazon Simple Storage Service API Reference\n) -> Result<String, S3ExampleError> { \n    let expires_in: std::time::Duration = \n std::time::Duration::from_secs(expires_in); \n    let expires_in: aws_sdk_s3::presigning::PresigningConfig = \n        PresigningConfig::expires_in(expires_in).map_err(|err| { \n            S3ExampleError::new(format!( \n                \"Failed to convert expiration to PresigningConfig: {err:?}\" \n            )) \n        })?; \n    let presigned_request = client \n        .put_object() \n        .bucket(bucket) \n        .key(object) \n        .presigned(expires_in) \n        .await?; \n    Ok(presigned_request.uri().into())\n}\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nCreate a photo asset management application that lets users manage photos \nusing labels\nThe following code examples show how to create a serverless application that lets users manage \nphotos using labels.\n.NET\nAWS SDK for .NET\nShows how to develop a photo asset management application that detects labels in images \nusing Amazon Rekognition and stores them for later retrieval.\nFor complete source code and instructions on how to set up and run, see the full example on\nGitHub .\nFor a deep dive into the origin of this example see the post on AWS Community.\nScenarios API Version 2006-03-01 2327Amazon Simple Storage Service API Reference\nServices used in this example\n\u2022API Gateway\n\u2022DynamoDB\n\u2022Lambda\n\u2022Amazon Rekognition\n\u2022Amazon S3\n\u2022Amazon SNS\nC++\nSDK for C++\nShows how to develop a photo asset management application that detects labels in images \nusing Amazon Rekognition and stores them for later retrieval.\nFor complete source code and instructions on how to set up and run, see the full example on\nGitHub .\nFor a deep dive into the origin of this example see the post on AWS Community.\nServices used in this example\n\u2022API Gateway\n\u2022DynamoDB\n\u2022Lambda\n\u2022Amazon Rekognition\n\u2022Amazon S3\n\u2022Amazon SNS\nJava\nSDK for Java 2.x\nShows how to develop a photo asset management application that detects labels in images \nusing Amazon Rekognition and stores them for later retrieval.\nFor complete source code and instructions on how to set up and run, see the full example on\nGitHub .\nScenarios API Version 2006-03-01 2328Amazon Simple Storage Service API Reference\nFor a deep dive into the origin of this example see the post on AWS Community.\nServices used in this example\n\u2022API Gateway\n\u2022DynamoDB\n\u2022Lambda\n\u2022Amazon Rekognition\n\u2022Amazon S3\n\u2022Amazon SNS\nJavaScript\nSDK for JavaScript (v3)\nShows how to develop a photo asset management application that detects labels in images \nusing Amazon Rekognition and stores them for later retrieval.\nFor complete source code and instructions on how to set up and run, see the full example on\nGitHub .\nFor a deep dive into the origin of this example see the post on AWS Community.\nServices used in this example\n\u2022API Gateway\n\u2022DynamoDB\n\u2022Lambda\n\u2022Amazon Rekognition\n\u2022Amazon S3\n\u2022Amazon SNS\nKotlin\nSDK for Kotlin\nShows how to develop a photo asset management application that detects labels in images \nusing Amazon Rekognition and stores them for later retrieval.\nScenarios API Version 2006-03-01 2329Amazon Simple Storage Service API Reference\nFor complete source code and instructions on how to set up and run, see the full example on\nGitHub .\nFor a deep dive into the origin of this example see the post on AWS Community.\nServices used in this example\n\u2022API Gateway\n\u2022DynamoDB\n\u2022Lambda\n\u2022Amazon Rekognition\n\u2022Amazon S3\n\u2022Amazon SNS\nPHP\nSDK for PHP\nShows how to develop a photo asset management application that detects labels in images \nusing Amazon Rekognition and stores them for later retrieval.\nFor complete source code and instructions on how to set up and run, see the full example on\nGitHub .\nFor a deep dive into the origin of this example see the post on AWS Community.\nServices used in this example\n\u2022API Gateway\n\u2022DynamoDB\n\u2022Lambda\n\u2022Amazon Rekognition\n\u2022Amazon S3\n\u2022Amazon SNS\nScenarios API Version 2006-03-01 2330Amazon Simple Storage Service API Reference\nRust\nSDK for Rust\nShows how to develop a photo asset management application that detects labels in images \nusing Amazon Rekognition and stores them for later retrieval.\nFor complete source code and instructions on how to set up and run, see the full example on\nGitHub .\nFor a deep dive into the origin of this example see the post on AWS Community.\nServices used in this example\n\u2022API Gateway\n\u2022DynamoDB\n\u2022Lambda\n\u2022Amazon Rekognition\n\u2022Amazon S3\n\u2022Amazon SNS\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs.", "This topic also includes information about getting started and details \nabout previous SDK versions.\nA web page that lists Amazon S3 objects using an AWS SDK\nThe following code example shows how to list Amazon S3 objects in a web page.\nJavaScript\nSDK for JavaScript (v3)\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nScenarios API Version 2006-03-01 2331Amazon Simple Storage Service API Reference\nThe following code is the relevant React component that makes calls to the AWS SDK.", "\nA runnable version of the application containing this component can be found at the \npreceding GitHub link.\nimport { useEffect, useState } from \"react\";\nimport { \n  ListObjectsCommand, \n  type ListObjectsCommandOutput, \n  S3Client,\n} from \"@aws-sdk/client-s3\";\nimport { fromCognitoIdentityPool } from \"@aws-sdk/credential-providers\";\nimport \"./App.css\";\nfunction App() { \n  const [objects, setObjects] = useState< \n    Required<ListObjectsCommandOutput>[\"Contents\"] \n  >([]); \n  useEffect(() => { \n    const client = new S3Client({ \n      region: \"us-east-1\", \n      // Unless you have a public bucket, you'll need access to a private bucket. \n      // One way to do this is to create an Amazon Cognito identity pool, attach \n a role to the pool, \n      // and grant the role access to the 's3:GetObject' action.", "\n      // \n      // You'll also need to configure the CORS settings on the bucket to allow \n traffic from \n      // this example site.", "Here's an example configuration that allows all \n origins.", "Don't \n      // do this in production.", "\n      //[ \n      //  { \n      //    \"AllowedHeaders\": [\"*\"], \n      //    \"AllowedMethods\": [\"GET\"], \n      //    \"AllowedOrigins\": [\"*\"], \n      //    \"ExposeHeaders\": [], \n      //  }, \n      //] \n      // \n      credentials: fromCognitoIdentityPool({ \n        clientConfig: { region: \"us-east-1\" }, \n        identityPoolId: \"<YOUR_IDENTITY_POOL_ID>\", \nScenarios API Version 2006-03-01 2332Amazon Simple Storage Service API Reference\n      }), \n    }); \n    const command = new ListObjectsCommand({ Bucket: \"bucket-name\" }); \n    client.send(command).then(({ Contents }) => setObjects(Contents || [])); \n  }, []); \n  return ( \n    <div className=\"App\"> \n      {objects.map((o) => ( \n        <div key={o.ETag}>{o.Key}</div> \n      ))} \n    </div> \n  );\n}\nexport default App;\n\u2022For API details, see ListObjects in AWS SDK for JavaScript API Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nCreate an Amazon Textract explorer application\nThe following code examples show how to explore Amazon Textract output through an interactive \napplication.\nJavaScript\nSDK for JavaScript (v3)\nShows how to use the AWS SDK for JavaScript to build a React application that uses Amazon \nTextract to extract data from a document image and display it in an interactive web page. \nThis example runs in a web browser and requires an authenticated Amazon Cognito identity \nfor credentials.", "It uses Amazon Simple Storage Service (Amazon S3) for storage, and \nfor noti\ufb01cations it polls an Amazon Simple Queue Service (Amazon SQS) queue that is \nsubscribed to an Amazon Simple Noti\ufb01cation Service (Amazon SNS) topic.\nScenarios API Version 2006-03-01 2333Amazon Simple Storage Service API Reference\nFor complete source code and instructions on how to set up and run, see the full example on\nGitHub .\nServices used in this example\n\u2022Amazon Cognito Identity\n\u2022Amazon S3\n\u2022Amazon SNS\n\u2022Amazon SQS\n\u2022Amazon Textract\nPython\nSDK for Python (Boto3)\nShows how to use the AWS SDK for Python (Boto3) with Amazon Textract to detect text, \nform, and table elements in a document image. The input image and Amazon Textract \noutput are shown in a Tkinter application that lets you explore the detected elements.\n\u2022Submit a document image to Amazon Textract and explore the output of detected \nelements.\n\u2022Submit images directly to Amazon Textract or through an Amazon Simple Storage Service \n(Amazon S3) bucket.\n\u2022Use asynchronous APIs to start a job that publishes a noti\ufb01cation to an Amazon Simple \nNoti\ufb01cation Service (Amazon SNS) topic when the job completes.\n\u2022Poll an Amazon Simple Queue Service (Amazon SQS) queue for a job completion message \nand display the results.\nFor complete source code and instructions on how to set up and run, see the full example on\nGitHub .\nServices used in this example\n\u2022Amazon S3\n\u2022Amazon SNS\n\u2022Amazon SQS\n\u2022Amazon Textract\nScenarios API Version 2006-03-01 2334Amazon Simple Storage Service API Reference\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nDelete all objects in a given Amazon S3 bucket using an AWS SDK.\nThe following code example shows how to delete all of the objects in an Amazon S3 bucket.\nJavaScript\nSDK for JavaScript (v3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nDelete all objects for a given Amazon S3 bucket.\nimport { \n  DeleteObjectsCommand, \n  paginateListObjectsV2, \n  S3Client,\n} from \"@aws-sdk/client-s3\";\n/** \n * \n * @param {{ bucketName: string }} config \n */\nexport const main = async ({ bucketName }) => { \n  const client = new S3Client({}); \n  try { \n    console.log(`Deleting all objects in bucket: ${bucketName}`); \n    const paginator = paginateListObjectsV2( \n      { client }, \n      { \n        Bucket: bucketName, \n      }, \n    ); \nScenarios API Version 2006-03-01 2335Amazon Simple Storage Service API Reference\n    const objectKeys = []; \n    for await (const { Contents } of paginator) { \n      objectKeys.push(...Contents.map((obj) => ({ Key: obj.Key }))); \n    } \n    const deleteCommand = new DeleteObjectsCommand({ \n      Bucket: bucketName, \n      Delete: { Objects: objectKeys }, \n    }); \n    await client.send(deleteCommand); \n    console.log(`All objects deleted from bucket: ${bucketName}`); \n  } catch (caught) { \n    if (caught instanceof Error) { \n      console.error( \n        `Failed to empty ${bucketName}. ${caught.name}: ${caught.message}`, \n      ); \n    } \n  }\n};\n// Call function if run directly.\nimport { fileURLToPath } from \"node:url\";\nimport { parseArgs } from \"node:util\";\nif (process.argv[1] === fileURLToPath(import.meta.url)) { \n  const options = { \n    bucketName: { \n      type: \"string\", \n    }, \n  }; \n  const { values } = parseArgs({ options }); \n  main(values);\n}\n\u2022For API details, see the following topics in AWS SDK for JavaScript API Reference.\n\u2022DeleteObjects\n\u2022ListObjectsV2\nScenarios API Version 2006-03-01 2336Amazon Simple Storage Service API Reference\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs.", "This topic also includes information about getting started and details \nabout previous SDK versions.\nDelete incomplete multipart uploads to Amazon S3 using an AWS SDK\nThe following code example shows how to how to delete or stop incomplete Amazon S3 multipart \nuploads.\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nTo stop multipart uploads that are in-progress or incomplete for any reason, you can get a \nlist uploads and then delete them as shown in the following example.\n    /** \n     * Aborts all incomplete multipart uploads from the specified S3 bucket. \n     * <p> \n     * This method retrieves a list of all incomplete multipart uploads in the \n specified S3 bucket, \n     * and then aborts each of those uploads. \n     */ \n    public static void abortIncompleteMultipartUploadsFromList() { \n        ListMultipartUploadsRequest listMultipartUploadsRequest = \n ListMultipartUploadsRequest.builder() \n            .bucket(bucketName) \n            .build(); \n        ListMultipartUploadsResponse response = \n s3Client.listMultipartUploads(listMultipartUploadsRequest); \n        List<MultipartUpload> uploads = response.uploads(); \n        AbortMultipartUploadRequest abortMultipartUploadRequest; \n        for (MultipartUpload upload : uploads) { \n            abortMultipartUploadRequest = AbortMultipartUploadRequest.builder() \nScenarios API Version 2006-03-01 2337Amazon Simple Storage Service API Reference\n                .bucket(bucketName) \n                .key(upload.key()) \n                .expectedBucketOwner(accountId) \n                .uploadId(upload.uploadId()) \n                .build(); \n            AbortMultipartUploadResponse abortMultipartUploadResponse = \n s3Client.abortMultipartUpload(abortMultipartUploadRequest); \n            if (abortMultipartUploadResponse.sdkHttpResponse().isSuccessful()) { \n                logger.info(\"Upload ID [{}] to bucket [{}] successfully \n aborted.\", upload.uploadId(), bucketName); \n            } \n        } \n    }\nTo delete incomplete multipart uploads that were initiated before or after a date, you can \nselectively delete multipart uploads based on a point in time as shown in the following \nexample.\n    static void abortIncompleteMultipartUploadsOlderThan(Instant pointInTime) { \n        ListMultipartUploadsRequest listMultipartUploadsRequest = \n ListMultipartUploadsRequest.builder() \n            .bucket(bucketName) \n            .build(); \n        ListMultipartUploadsResponse response = \n s3Client.listMultipartUploads(listMultipartUploadsRequest); \n        List<MultipartUpload> uploads = response.uploads(); \n        AbortMultipartUploadRequest abortMultipartUploadRequest; \n        for (MultipartUpload upload : uploads) { \n            logger.info(\"Found multipartUpload with upload ID [{}], initiated \n [{}]\", upload.uploadId(), upload.initiated()); \n            if (upload.initiated().isBefore(pointInTime)) { \n                abortMultipartUploadRequest = \n AbortMultipartUploadRequest.builder() \n                    .bucket(bucketName) \n                    .key(upload.key()) \n                    .expectedBucketOwner(accountId) \n                    .uploadId(upload.uploadId()) \n                    .build(); \nScenarios API Version 2006-03-01 2338Amazon Simple Storage Service API Reference\n                AbortMultipartUploadResponse abortMultipartUploadResponse = \n s3Client.abortMultipartUpload(abortMultipartUploadRequest); \n                if \n (abortMultipartUploadResponse.sdkHttpResponse().isSuccessful()) { \n                    logger.info(\"Upload ID [{}] to bucket [{}] successfully \n aborted.\", upload.uploadId(), bucketName); \n                } \n            } \n        } \n    }\nIf you have access to the upload ID after you begin a multipart upload, you can delete the in-\nprogress upload by using the ID.\n    static void abortMultipartUploadUsingUploadId() { \n        String uploadId = startUploadReturningUploadId(); \n        AbortMultipartUploadResponse response = s3Client.abortMultipartUpload(b -\n> b \n            .uploadId(uploadId) \n            .bucket(bucketName) \n            .key(key)); \n        if (response.sdkHttpResponse().isSuccessful()) { \n            logger.info(\"Upload ID [{}] to bucket [{}] successfully aborted.\", \n uploadId, bucketName); \n        } \n    }\nTo consistently delete incomplete multipart uploads older that a certain number of days, \nset up a bucket lifecycle con\ufb01guration for the bucket. The following example shows how to \ncreate a rule to delete incomplete uploads older than 7 days.\n    static void abortMultipartUploadsUsingLifecycleConfig() { \n        Collection<LifecycleRule> lifeCycleRules = \n List.of(LifecycleRule.builder() \n            .abortIncompleteMultipartUpload(b -> b.", "\n                daysAfterInitiation(7)) \n            .status(\"Enabled\") \n            .filter(SdkBuilder::build) // Filter element is required.", "\n            .build()); \nScenarios API Version 2006-03-01 2339Amazon Simple Storage Service API Reference\n        // If the action is successful, the service sends back an HTTP 200 \n response with an empty HTTP body.", "\n        PutBucketLifecycleConfigurationResponse response = \n s3Client.putBucketLifecycleConfiguration(b -> b \n            .bucket(bucketName) \n            .lifecycleConfiguration(b1 -> b1.rules(lifeCycleRules))); \n        if (response.sdkHttpResponse().isSuccessful()) { \n            logger.info(\"Rule to abort incomplete multipart uploads added to \n bucket.\"); \n        } else { \n            logger.error(\"Unsuccessfully applied rule. HTTP status code is [{}]\", \n response.sdkHttpResponse().statusCode()); \n        } \n    }\n\u2022For API details, see the following topics in AWS SDK for Java 2.x API Reference.\n\u2022AbortMultipartUpload\n\u2022ListMultipartUploads\n\u2022PutBucketLifecycleCon\ufb01guration\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nDetect PPE in images with Amazon Rekognition using an AWS SDK\nThe following code example shows how to build an app that uses Amazon Rekognition to detect \nPersonal Protective Equipment (PPE) in images.\nJava\nSDK for Java 2.x\nShows how to create an AWS Lambda function that detects images with Personal Protective \nEquipment.\nFor complete source code and instructions on how to set up and run, see the full example on\nGitHub .\nScenarios API Version 2006-03-01 2340Amazon Simple Storage Service API Reference\nServices used in this example\n\u2022DynamoDB\n\u2022Amazon Rekognition\n\u2022Amazon S3\n\u2022Amazon SES\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nDetect entities in text extracted from an image using an AWS SDK\nThe following code example shows how to use Amazon Comprehend to detect entities in text \nextracted by Amazon Textract from an image that is stored in Amazon S3.\nPython\nSDK for Python (Boto3)\nShows how to use the AWS SDK for Python (Boto3) in a Jupyter notebook to detect entities \nin text that is extracted from an image. This example uses Amazon Textract to extract \ntext from an image stored in Amazon Simple Storage Service (Amazon S3) and Amazon \nComprehend to detect entities in the extracted text.\nThis example is a Jupyter notebook and must be run in an environment that can host \nnotebooks. For instructions on how to run the example using Amazon SageMaker, see the \ndirections in TextractAndComprehendNotebook.ipynb.\nFor complete source code and instructions on how to set up and run, see the full example on\nGitHub .\nServices used in this example\n\u2022Amazon Comprehend\n\u2022Amazon S3\n\u2022Amazon Textract\nScenarios API Version 2006-03-01 2341Amazon Simple Storage Service API Reference\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nDetect faces in an image using an AWS SDK\nThe following code example shows how to:\n\u2022Save an image in an Amazon S3 bucket.\n\u2022Use Amazon Rekognition to detect facial details, such as age range, gender, and emotion (such as \nsmiling).\n\u2022Display those details.\nRust\nSDK for Rust\nSave the image in an Amazon S3 bucket with an uploads pre\ufb01x, use Amazon Rekognition \nto detect facial details, such as age range, gender, and emotion (smiling, etc.), and display \nthose details.\nFor complete source code and instructions on how to set up and run, see the full example on\nGitHub .\nServices used in this example\n\u2022Amazon Rekognition\n\u2022Amazon S3\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nDetect objects in images with Amazon Rekognition using an AWS SDK\nThe following code examples show how to build an app that uses Amazon Rekognition to detect \nobjects by category in images.\nScenarios API Version 2006-03-01 2342Amazon Simple Storage Service API Reference\n.NET\nAWS SDK for .NET\nShows how to use Amazon Rekognition .NET API to create an app that uses Amazon \nRekognition to identify objects by category in images located in an Amazon Simple Storage \nService (Amazon S3) bucket. The app sends the admin an email noti\ufb01cation with the results \nusing Amazon Simple Email Service (Amazon SES).\nFor complete source code and instructions on how to set up and run, see the full example on\nGitHub .\nServices used in this example\n\u2022Amazon Rekognition\n\u2022Amazon S3\n\u2022Amazon SES\nJava\nSDK for Java 2.x\nShows how to use Amazon Rekognition Java API to create an app that uses Amazon \nRekognition to identify objects by category in images located in an Amazon Simple Storage \nService (Amazon S3) bucket. The app sends the admin an email noti\ufb01cation with the results \nusing Amazon Simple Email Service (Amazon SES).\nFor complete source code and instructions on how to set up and run, see the full example on\nGitHub .\nServices used in this example\n\u2022Amazon Rekognition\n\u2022Amazon S3\n\u2022Amazon SES\nScenarios API Version 2006-03-01 2343Amazon Simple Storage Service API Reference\nJavaScript\nSDK for JavaScript (v3)\nShows how to use Amazon Rekognition with the AWS SDK for JavaScript to create an app \nthat uses Amazon Rekognition to identify objects by category in images located in an \nAmazon Simple Storage Service (Amazon S3) bucket. The app sends the admin an email \nnoti\ufb01cation with the results using Amazon Simple Email Service (Amazon SES).\nLearn how to:\n\u2022Create an unauthenticated user using Amazon Cognito.\n\u2022Analyze images for objects using Amazon Rekognition.\n\u2022Verify an email address for Amazon SES.\n\u2022Send an email noti\ufb01cation using Amazon SES.\nFor complete source code and instructions on how to set up and run, see the full example on\nGitHub .\nServices used in this example\n\u2022Amazon Rekognition\n\u2022Amazon S3\n\u2022Amazon SES\nKotlin\nSDK for Kotlin\nShows how to use Amazon Rekognition Kotlin API to create an app that uses Amazon \nRekognition to identify objects by category in images located in an Amazon Simple Storage \nService (Amazon S3) bucket. The app sends the admin an email noti\ufb01cation with the results \nusing Amazon Simple Email Service (Amazon SES).\nFor complete source code and instructions on how to set up and run, see the full example on\nGitHub .\nServices used in this example\n\u2022Amazon Rekognition\nScenarios API Version 2006-03-01 2344Amazon Simple Storage Service API Reference\n\u2022Amazon S3\n\u2022Amazon SES\nPython\nSDK for Python (Boto3)\nShows you how to use the AWS SDK for Python (Boto3) to create a web application that lets \nyou do the following:\n\u2022Upload photos to an Amazon Simple Storage Service (Amazon S3) bucket.\n\u2022Use Amazon Rekognition to analyze and label the photos.\n\u2022Use Amazon Simple Email Service (Amazon SES) to send email reports of image analysis.\nThis example contains two main components: a webpage written in JavaScript that is built \nwith React, and a REST service written in Python that is built with Flask-RESTful.\nYou can use the React webpage to:\n\u2022Display a list of images that are stored in your S3 bucket.\n\u2022Upload images from your computer to your S3 bucket.\n\u2022Display images and labels that identify items that are detected in the image.\n\u2022Get a report of all images in your S3 bucket and send an email of the report.\nThe webpage calls the REST service. The service sends requests to AWS to perform the \nfollowing actions:\n\u2022Get and \ufb01lter the list of images in your S3 bucket.\n\u2022Upload photos to your S3 bucket.\n\u2022Use Amazon Rekognition to analyze individual photos and get a list of labels that identify \nitems that are detected in the photo.\n\u2022Analyze all photos in your S3 bucket and use Amazon SES to email a report.\nFor complete source code and instructions on how to set up and run, see the full example on\nGitHub .\nServices used in this example\n\u2022Amazon Rekognition\nScenarios API Version 2006-03-01 2345Amazon Simple Storage Service API Reference\n\u2022Amazon S3\n\u2022Amazon SES\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs.", "This topic also includes information about getting started and details \nabout previous SDK versions.\nDetect people and objects in a video with Amazon Rekognition using an AWS SDK\nThe following code examples show how to detect people and objects in a video with Amazon \nRekognition.\nJava\nSDK for Java 2.x\nShows how to use Amazon Rekognition Java API to create an app to detect faces and \nobjects in videos located in an Amazon Simple Storage Service (Amazon S3) bucket.", "The app \nsends the admin an email noti\ufb01cation with the results using Amazon Simple Email Service \n(Amazon SES).\nFor complete source code and instructions on how to set up and run, see the full example on\nGitHub .\nServices used in this example\n\u2022Amazon Rekognition\n\u2022Amazon S3\n\u2022Amazon SES\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs.", "This topic also includes information about getting started and details \nabout previous SDK versions.\nDownload all objects in an Amazon Simple Storage Service (Amazon S3) bucket to \na local directory\nThe following code example shows how to download all objects in an Amazon Simple Storage \nService (Amazon S3) bucket to a local directory.\nScenarios API Version 2006-03-01 2346Amazon Simple Storage Service API Reference\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nUse an S3TransferManager to download all S3 objects in the same S3 bucket. View the\ncomplete \ufb01le and test.\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\nimport software.amazon.awssdk.core.sync.RequestBody;\nimport software.amazon.awssdk.services.s3.model.ObjectIdentifier;\nimport software.amazon.awssdk.transfer.s3.S3TransferManager;\nimport software.amazon.awssdk.transfer.s3.model.CompletedDirectoryDownload;\nimport software.amazon.awssdk.transfer.s3.model.DirectoryDownload;\nimport software.amazon.awssdk.transfer.s3.model.DownloadDirectoryRequest;\nimport java.io.IOException;\nimport java.net.URI;\nimport java.net.URISyntaxException;\nimport java.nio.file.Files;\nimport java.nio.file.Path;\nimport java.nio.file.Paths;\nimport java.util.HashSet;\nimport java.util.Set;\nimport java.util.UUID;\nimport java.util.stream.Collectors; \n    public Integer downloadObjectsToDirectory(S3TransferManager transferManager, \n            URI destinationPathURI, String bucketName) { \n        DirectoryDownload directoryDownload = \n transferManager.downloadDirectory(DownloadDirectoryRequest.builder() \n                .destination(Paths.get(destinationPathURI)) \n                .bucket(bucketName) \n                .build()); \n        CompletedDirectoryDownload completedDirectoryDownload = \n directoryDownload.completionFuture().join(); \nScenarios API Version 2006-03-01 2347Amazon Simple Storage Service API Reference\n        completedDirectoryDownload.failedTransfers() \n                .forEach(fail -> logger.warn(\"Object [{}] failed to transfer\", \n fail.toString())); \n        return completedDirectoryDownload.failedTransfers().size(); \n    }\n\u2022For API details, see DownloadDirectory in AWS SDK for Java 2.x API Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nGet an Amazon S3 object from a Multi-Region Access Point by using an AWS SDK\nThe following code example shows how to get an object from a Multi-Region Access Point.\nKotlin\nSDK for Kotlin\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nCon\ufb01gure the S3 client to use the Asymmetric Sigv4 (Sigv4a) signing algorithm.\n        suspend fun createS3Client(): S3Client { \n            // Configure your S3Client to use the Asymmetric Sigv4 (Sigv4a) \n signing algorithm. \n            val sigV4AScheme = SigV4AsymmetricAuthScheme(CrtAwsSigner) \n            val s3 = S3Client.fromEnvironment { \n                authSchemes = listOf(sigV4AScheme) \n            } \n            return s3 \n        }\nUse the Multi-Region Access Point ARN instead of a bucket name to retrieve the object.\nScenarios API Version 2006-03-01 2348Amazon Simple Storage Service API Reference\n    suspend fun getObjectFromMrap( \n        s3: S3Client, \n        mrapArn: String, \n        keyName: String, \n    ): String?", "{ \n        val request = GetObjectRequest { \n            bucket = mrapArn // Use the ARN instead of the bucket name for object \n operations.", "\n            key = keyName \n        } \n        var stringObj: String?", "= null \n        s3.getObject(request) { resp -> \n            stringObj = resp.body?.decodeToString() \n            if (stringObj != null) { \n                println(\"Successfully read $keyName from $mrapArn\") \n            } \n        } \n        return stringObj \n    }\n\u2022For more information, see AWS SDK for Kotlin developer guide.\n\u2022For API details, see GetObject in AWS SDK for Kotlin API reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nGet an object from an Amazon S3 bucket using an AWS SDK, specifying an If-\nModi\ufb01ed-Since header\nThe following code example shows how to read data from an object in an S3 bucket, but only if \nthat bucket has not been modi\ufb01ed since the last retrieval time.\nScenarios API Version 2006-03-01 2349Amazon Simple Storage Service API Reference\nRust\nSDK for Rust\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nuse aws_sdk_s3::{ \n    error::SdkError, \n    primitives::{ByteStream, DateTime, DateTimeFormat}, \n    Client,\n};\nuse s3_code_examples::error::S3ExampleError;\nuse tracing::{error, warn};\nconst KEY: &str = \"key\";\nconst BODY: &str = \"Hello, world!\";\n/// Demonstrate how `if-modified-since` reports that matching objects haven't\n/// changed.\n///\n/// # Steps\n/// - Create a bucket.\n/// - Put an object in the bucket.\n/// - Get the bucket headers.\n/// - Get the bucket headers again but only if modified.\n/// - Delete the bucket.\n#[tokio::main]\nasync fn main() -> Result<(), S3ExampleError> { \n    tracing_subscriber::fmt::init(); \n    // Get a new UUID to use when creating a unique bucket name.", "\n    let uuid = uuid::Uuid::new_v4(); \n    // Load the AWS configuration from the environment. \n    let client = Client::new(&aws_config::load_from_env().await); \n    // Generate a unique bucket name using the previously generated UUID. \n    // Then create a new bucket with that name. \nScenarios API Version 2006-03-01 2350Amazon Simple Storage Service API Reference\n    let bucket_name = format!(\"if-modified-since-{uuid}\"); \n    client \n        .create_bucket() \n        .bucket(bucket_name.clone()) \n        .send() \n        .await?; \n    // Create a new object in the bucket whose name is `KEY` and whose \n    // contents are `BODY`. \n    let put_object_output = client \n        .put_object() \n        .bucket(bucket_name.as_str()) \n        .key(KEY) \n        .body(ByteStream::from_static(BODY.as_bytes())) \n        .send() \n        .await; \n    // If the `PutObject` succeeded, get the eTag string from it.", "Otherwise, \n    // report an error and return an empty string. \n    let e_tag_1 = match put_object_output { \n        Ok(put_object) => put_object.e_tag.unwrap(), \n        Err(err) => { \n            error!(\"{err:?}\"); \n            String::new() \n        } \n    }; \n    // Request the object's headers.", "\n    let head_object_output = client \n        .head_object() \n        .bucket(bucket_name.as_str()) \n        .key(KEY) \n        .send() \n        .await; \n    // If the `HeadObject` request succeeded, create a tuple containing the \n    // values of the headers `last-modified` and `etag`.", "If the request \n    // failed, return the error in a tuple instead.", "\n    let (last_modified, e_tag_2) = match head_object_output { \n        Ok(head_object) => ( \n            Ok(head_object.last_modified().cloned().unwrap()), \n            head_object.e_tag.unwrap(), \n        ), \n        Err(err) => (Err(err), String::new()), \nScenarios API Version 2006-03-01 2351Amazon Simple Storage Service API Reference\n    }; \n    warn!(\"last modified: {last_modified:?}\"); \n    assert_eq!( \n        e_tag_1, e_tag_2, \n        \"PutObject and first GetObject had differing eTags\" \n    ); \n    println!(\"First value of last_modified: {last_modified:?}\"); \n    println!(\"First tag: {}\\n\", e_tag_1); \n    // Send a second `HeadObject` request. This time, the `if_modified_since` \n    // option is specified, giving the `last_modified` value returned by the \n    // first call to `HeadObject`.", "\n    // \n    // Since the object hasn't been changed, and there are no other objects in \n    // the bucket, there should be no matching objects. \n    let head_object_output = client \n        .head_object() \n        .bucket(bucket_name.as_str()) \n        .key(KEY) \n        .if_modified_since(last_modified.unwrap()) \n        .send() \n        .await; \n    // If the `HeadObject` request succeeded, the result is a typle containing \n    // the `last_modified` and `e_tag_1` properties. This is _not_ the expected \n    // result.", "\n    // \n    // The _expected_ result of the second call to `HeadObject` is an \n    // `SdkError::ServiceError` containing the HTTP error response.", "If that's \n    // the case and the HTTP status is 304 (not modified), the output is a \n    // tuple containing the values of the HTTP `last-modified` and `etag` \n    // headers. \n    // \n    // If any other HTTP error occurred, the error is returned as an \n    // `SdkError::ServiceError`. \n    let (last_modified, e_tag_2) = match head_object_output { \n        Ok(head_object) => ( \n            Ok(head_object.last_modified().cloned().unwrap()), \n            head_object.e_tag.unwrap(), \n        ), \nScenarios API Version 2006-03-01 2352Amazon Simple Storage Service API Reference\n        Err(err) => match err { \n            SdkError::ServiceError(err) => { \n                // Get the raw HTTP response.", "If its status is 304, the \n                // object has not changed.", "This is the expected code path.", "\n                let http = err.raw(); \n                match http.status().as_u16() { \n                    // If the HTTP status is 304: Not Modified, return a \n                    // tuple containing the values of the HTTP \n                    // `last-modified` and `etag` headers. \n                    304 => ( \n                        Ok(DateTime::from_str( \n                            http.headers().get(\"last-modified\").unwrap(), \n                            DateTimeFormat::HttpDate, \n                        ) \n                        .unwrap()), \n                        http.headers().get(\"etag\").map(|t| t.into()).unwrap(), \n                    ), \n                    // Any other HTTP status code is returned as an \n                    // `SdkError::ServiceError`.", "\n                    _ => (Err(SdkError::ServiceError(err)), String::new()), \n                } \n            } \n            // Any other kind of error is returned in a tuple containing the \n            // error and an empty string.", "\n            _ => (Err(err), String::new()), \n        }, \n    }; \n    warn!(\"last modified: {last_modified:?}\"); \n    assert_eq!( \n        e_tag_1, e_tag_2, \n        \"PutObject and second HeadObject had different eTags\" \n    ); \n    println!(\"Second value of last modified: {last_modified:?}\"); \n    println!(\"Second tag: {}\", e_tag_2); \n    // Clean up by deleting the object and the bucket.", "\n    client \n        .delete_object() \n        .bucket(bucket_name.as_str()) \n        .key(KEY) \n        .send() \n        .await?; \nScenarios API Version 2006-03-01 2353Amazon Simple Storage Service API Reference\n    client \n        .delete_bucket() \n        .bucket(bucket_name.as_str()) \n        .send() \n        .await?; \n    Ok(())\n}\n\u2022For API details, see GetObject in AWS SDK for Rust API reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs.", "This topic also includes information about getting started and details \nabout previous SDK versions.\nGet started with encryption for Amazon S3 objects using an AWS SDK\nThe following code example shows how to get started with encryption for Amazon S3 objects.\n.NET\nAWS SDK for .NET\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n    using System; \n    using System.IO; \n    using System.Security.Cryptography; \n    using System.Threading.Tasks; \n    using Amazon.S3; \n    using Amazon.S3.Model; \n    /// <summary> \n    /// This example shows how to apply client encryption to an object in an \n    /// Amazon Simple Storage Service (Amazon S3) bucket. \nScenarios API Version 2006-03-01 2354Amazon Simple Storage Service API Reference\n    /// </summary> \n    public class SSEClientEncryption \n    { \n        public static async Task Main() \n        { \n            string bucketName = \"amzn-s3-demo-bucket\"; \n            string keyName = \"exampleobject.txt\"; \n            string copyTargetKeyName = \"examplecopy.txt\"; \n            // If the AWS Region defined for your default user is different \n            // from the Region where your Amazon S3 bucket is located, \n            // pass the Region name to the Amazon S3 client object's constructor.", "\n            // For example: RegionEndpoint.USWest2.", "\n            IAmazonS3 client = new AmazonS3Client(); \n            try \n            { \n                // Create an encryption key.", "\n                Aes aesEncryption = Aes.Create(); \n                aesEncryption.KeySize = 256; \n                aesEncryption.GenerateKey(); \n                string base64Key = Convert.ToBase64String(aesEncryption.Key); \n                // Upload the object.", "\n                PutObjectRequest putObjectRequest = await \n UploadObjectAsync(client, bucketName, keyName, base64Key); \n                // Download the object and verify that its contents match what \n you uploaded. \n                await DownloadObjectAsync(client, bucketName, keyName, base64Key, \n putObjectRequest); \n                // Get object metadata and verify that the object uses AES-256 \n encryption. \n                await GetObjectMetadataAsync(client, bucketName, keyName, \n base64Key); \n                // Copy both the source and target objects using server-side \n encryption with \n                // an encryption key. \n                await CopyObjectAsync(client, bucketName, keyName, \n copyTargetKeyName, aesEncryption, base64Key); \n            } \n            catch (AmazonS3Exception ex) \nScenarios API Version 2006-03-01 2355Amazon Simple Storage Service API Reference\n            { \n                Console.WriteLine($\"Error: {ex.Message}\"); \n            } \n        } \n        /// <summary> \n        /// Uploads an object to an Amazon S3 bucket. \n        /// </summary> \n        /// <param name=\"client\">The initialized Amazon S3 client object used to \n call \n        /// PutObjectAsync.</param> \n        /// <param name=\"bucketName\">The name of the Amazon S3 bucket to which \n the \n        /// object will be uploaded.</param> \n        /// <param name=\"keyName\">The name of the object to upload to the Amazon \n S3 \n        /// bucket.</param> \n        /// <param name=\"base64Key\">The encryption key.</param> \n        /// <returns>The PutObjectRequest object for use by \n DownloadObjectAsync.</returns> \n        public static async Task<PutObjectRequest> UploadObjectAsync( \n            IAmazonS3 client, \n            string bucketName, \n            string keyName, \n            string base64Key) \n        { \n            PutObjectRequest putObjectRequest = new PutObjectRequest \n            { \n                BucketName = bucketName, \n                Key = keyName, \n                ContentBody = \"sample text\", \n                ServerSideEncryptionCustomerMethod = \n ServerSideEncryptionCustomerMethod.AES256, \n                ServerSideEncryptionCustomerProvidedKey = base64Key, \n            }; \n            PutObjectResponse putObjectResponse = await \n client.PutObjectAsync(putObjectRequest); \n            return putObjectRequest; \n        } \n        /// <summary> \n        /// Downloads an encrypted object from an Amazon S3 bucket. \n        /// </summary> \nScenarios API Version 2006-03-01 2356Amazon Simple Storage Service API Reference\n        /// <param name=\"client\">The initialized Amazon S3 client object used to \n call \n        /// GetObjectAsync.</param> \n        /// <param name=\"bucketName\">The name of the Amazon S3 bucket where the \n object \n        /// is located.</param> \n        /// <param name=\"keyName\">The name of the Amazon S3 object to download.</\nparam> \n        /// <param name=\"base64Key\">The encryption key used to encrypt the \n        /// object.</param> \n        /// <param name=\"putObjectRequest\">The PutObjectRequest used to upload \n        /// the object.</param> \n        public static async Task DownloadObjectAsync( \n            IAmazonS3 client, \n            string bucketName, \n            string keyName, \n            string base64Key, \n            PutObjectRequest putObjectRequest) \n        { \n            GetObjectRequest getObjectRequest = new GetObjectRequest \n            { \n                BucketName = bucketName, \n                Key = keyName, \n                // Provide encryption information for the object stored in Amazon \n S3. \n                ServerSideEncryptionCustomerMethod = \n ServerSideEncryptionCustomerMethod.AES256, \n                ServerSideEncryptionCustomerProvidedKey = base64Key, \n            }; \n            using (GetObjectResponse getResponse = await \n client.GetObjectAsync(getObjectRequest)) \n            using (StreamReader reader = new \n StreamReader(getResponse.ResponseStream)) \n            { \n                string content = reader.ReadToEnd(); \n                if (string.Compare(putObjectRequest.ContentBody, content) == 0) \n                { \n                    Console.WriteLine(\"Object content is same as we uploaded\"); \n                } \n                else \n                { \n                    Console.WriteLine(\"Error...Object content is not same.\"); \nScenarios API Version 2006-03-01 2357Amazon Simple Storage Service API Reference\n                } \n                if (getResponse.ServerSideEncryptionCustomerMethod == \n ServerSideEncryptionCustomerMethod.AES256) \n                { \n                    Console.WriteLine(\"Object encryption method is AES256, same \n as we set\"); \n                } \n                else \n                { \n                    Console.WriteLine(\"Error...Object encryption method is not \n the same as AES256 we set\"); \n                } \n            } \n        } \n        /// <summary> \n        /// Retrieves the metadata associated with an Amazon S3 object. \n        /// </summary> \n        /// <param name=\"client\">The initialized Amazon S3 client object used \n        /// to call GetObjectMetadataAsync.</param> \n        /// <param name=\"bucketName\">The name of the Amazon S3 bucket containing \n the \n        /// object for which we want to retrieve metadata.</param> \n        /// <param name=\"keyName\">The name of the object for which we wish to \n        /// retrieve the metadata.</param> \n        /// <param name=\"base64Key\">The encryption key associated with the \n        /// object.</param> \n        public static async Task GetObjectMetadataAsync( \n            IAmazonS3 client, \n            string bucketName, \n            string keyName, \n            string base64Key) \n        { \n            GetObjectMetadataRequest getObjectMetadataRequest = new \n GetObjectMetadataRequest \n            { \n                BucketName = bucketName, \n                Key = keyName, \n                // The object stored in Amazon S3 is encrypted, so provide the \n necessary encryption information. \n                ServerSideEncryptionCustomerMethod = \n ServerSideEncryptionCustomerMethod.AES256, \nScenarios API Version 2006-03-01 2358Amazon Simple Storage Service API Reference\n                ServerSideEncryptionCustomerProvidedKey = base64Key, \n            }; \n            GetObjectMetadataResponse getObjectMetadataResponse = await \n client.GetObjectMetadataAsync(getObjectMetadataRequest); \n            Console.WriteLine(\"The object metadata show encryption method used \n is: {0}\", getObjectMetadataResponse.ServerSideEncryptionCustomerMethod); \n        } \n        /// <summary> \n        /// Copies an encrypted object from one Amazon S3 bucket to another. \n        /// </summary> \n        /// <param name=\"client\">The initialized Amazon S3 client object used to \n call \n        /// CopyObjectAsync.</param> \n        /// <param name=\"bucketName\">The Amazon S3 bucket containing the object \n        /// to copy.</param> \n        /// <param name=\"keyName\">The name of the object to copy.</param> \n        /// <param name=\"copyTargetKeyName\">The Amazon S3 bucket to which the \n object \n        /// will be copied.</param> \n        /// <param name=\"aesEncryption\">The encryption type to use.</param> \n        /// <param name=\"base64Key\">The encryption key to use.</param> \n        public static async Task CopyObjectAsync( \n            IAmazonS3 client, \n            string bucketName, \n            string keyName, \n            string copyTargetKeyName, \n            Aes aesEncryption, \n            string base64Key) \n        { \n            aesEncryption.GenerateKey(); \n            string copyBase64Key = Convert.ToBase64String(aesEncryption.Key); \n            CopyObjectRequest copyRequest = new CopyObjectRequest \n            { \n                SourceBucket = bucketName, \n                SourceKey = keyName, \n                DestinationBucket = bucketName, \n                DestinationKey = copyTargetKeyName, \n                // Information about the source object's encryption.", "\n                CopySourceServerSideEncryptionCustomerMethod = \n ServerSideEncryptionCustomerMethod.AES256, \nScenarios API Version 2006-03-01 2359Amazon Simple Storage Service API Reference\n                CopySourceServerSideEncryptionCustomerProvidedKey = base64Key, \n                // Information about the target object's encryption. \n                ServerSideEncryptionCustomerMethod = \n ServerSideEncryptionCustomerMethod.AES256, \n                ServerSideEncryptionCustomerProvidedKey = copyBase64Key, \n            }; \n            await client.CopyObjectAsync(copyRequest); \n        } \n    }\n\u2022For API details, see the following topics in AWS SDK for .NET API Reference.\n\u2022CopyObject\n\u2022GetObject\n\u2022GetObjectMetadata\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nGet started with tags for Amazon S3 objects using an AWS SDK\nThe following code example shows how to get started with tags for Amazon S3 objects.\n.NET\nAWS SDK for .NET\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n    using System; \n    using System.Collections.Generic; \n    using System.Threading.Tasks; \n    using Amazon; \nScenarios API Version 2006-03-01 2360Amazon Simple Storage Service API Reference\n    using Amazon.S3; \n    using Amazon.S3.Model; \n    /// <summary> \n    /// This example shows how to work with tags in Amazon Simple Storage \n    /// Service (Amazon S3) objects. \n    /// </summary> \n    public class ObjectTag \n    { \n        public static async Task Main() \n        { \n            string bucketName = \"amzn-s3-demo-bucket\"; \n            string keyName = \"newobject.txt\"; \n            string filePath = @\"*** file path ***\"; \n            // Specify your bucket region (an example region is shown). \n            RegionEndpoint bucketRegion = RegionEndpoint.USWest2; \n            var client = new AmazonS3Client(bucketRegion); \n            await PutObjectsWithTagsAsync(client, bucketName, keyName, filePath); \n        } \n        /// <summary> \n        /// This method uploads an object with tags.", "It then shows the tag \n        /// values, changes the tags, and shows the new tags.", "\n        /// </summary> \n        /// <param name=\"client\">The Initialized Amazon S3 client object used \n        /// to call the methods to create and change an objects tags.</param> \n        /// <param name=\"bucketName\">A string representing the name of the \n        /// bucket where the object will be stored.</param> \n        /// <param name=\"keyName\">A string representing the key name of the \n        /// object to be tagged.</param> \n        /// <param name=\"filePath\">The directory location and file name of the \n        /// object to be uploaded to the Amazon S3 bucket.</param> \n        public static async Task PutObjectsWithTagsAsync(IAmazonS3 client, string \n bucketName, string keyName, string filePath) \n        { \n            try \n            { \n                // Create an object with tags.", "\n                var putRequest = new PutObjectRequest \n                { \n                    BucketName = bucketName, \n                    Key = keyName, \nScenarios API Version 2006-03-01 2361Amazon Simple Storage Service API Reference\n                    FilePath = filePath, \n                    TagSet = new List<Tag> \n                    { \n                        new Tag { Key = \"Keyx1\", Value = \"Value1\" }, \n                        new Tag { Key = \"Keyx2\", Value = \"Value2\" }, \n                    }, \n                }; \n                PutObjectResponse response = await \n client.PutObjectAsync(putRequest); \n                // Now retrieve the new object's tags. \n                GetObjectTaggingRequest getTagsRequest = new \n GetObjectTaggingRequest() \n                { \n                    BucketName = bucketName, \n                    Key = keyName, \n                }; \n                GetObjectTaggingResponse objectTags = await \n client.GetObjectTaggingAsync(getTagsRequest); \n                // Display the tag values. \n                objectTags.Tagging \n                    .ForEach(t => Console.WriteLine($\"Key: {t.Key}, Value: \n {t.Value}\")); \n                Tagging newTagSet = new Tagging() \n                { \n                    TagSet = new List<Tag> \n                    { \n                        new Tag { Key = \"Key3\", Value = \"Value3\" }, \n                        new Tag { Key = \"Key4\", Value = \"Value4\" }, \n                    }, \n                }; \n                PutObjectTaggingRequest putObjTagsRequest = new \n PutObjectTaggingRequest() \n                { \n                    BucketName = bucketName, \n                    Key = keyName, \n                    Tagging = newTagSet, \n                }; \nScenarios API Version 2006-03-01 2362Amazon Simple Storage Service API Reference\n                PutObjectTaggingResponse response2 = await \n client.PutObjectTaggingAsync(putObjTagsRequest); \n                // Retrieve the tags again and show the values. \n                GetObjectTaggingRequest getTagsRequest2 = new \n GetObjectTaggingRequest() \n                { \n                    BucketName = bucketName, \n                    Key = keyName, \n                }; \n                GetObjectTaggingResponse objectTags2 = await \n client.GetObjectTaggingAsync(getTagsRequest2); \n                objectTags2.Tagging \n                    .ForEach(t => Console.WriteLine($\"Key: {t.Key}, Value: \n {t.Value}\")); \n            } \n            catch (AmazonS3Exception ex) \n            { \n                Console.WriteLine( \n                        $\"Error: '{ex.Message}'\"); \n            } \n        } \n    }\n\u2022For API details, see GetObjectTagging in AWS SDK for .NET API Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nWork with Amazon S3 object lock features using an AWS SDK\nThe following code examples show how to work with S3 object lock features.\nScenarios API Version 2006-03-01 2363Amazon Simple Storage Service API Reference\n.NET\nAWS SDK for .NET\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nRun an interactive scenario demonstrating Amazon S3 object lock features.\nusing Amazon.S3;\nusing Amazon.S3.Model;\nusing Microsoft.Extensions.Configuration;\nusing Microsoft.Extensions.DependencyInjection;\nusing Microsoft.Extensions.Hosting;\nusing Microsoft.Extensions.Logging;\nusing Microsoft.Extensions.Logging.Console;\nusing Microsoft.Extensions.Logging.Debug;\nnamespace S3ObjectLockScenario;\npublic static class S3ObjectLockWorkflow\n{ \n    /* \n    Before running this .NET code example, set up your development environment, \n including your credentials.", "\n    This .NET example performs the following tasks: \n        1.", "Create test Amazon Simple Storage Service (S3) buckets with different \n lock policies.", "\n        2.", "Upload sample objects to each bucket.", "\n        3.", "Set some Legal Hold and Retention Periods on objects and buckets.", "\n        4.", "Investigate lock policies by viewing settings or attempting to delete \n or overwrite objects.", "\n        5.", "Clean up objects and buckets.", "\n   */ \n    public static S3ActionsWrapper _s3ActionsWrapper = null!; \n    public static IConfiguration _configuration = null!; \n    private static string _resourcePrefix = null!; \nScenarios API Version 2006-03-01 2364Amazon Simple Storage Service API Reference\n    private static string noLockBucketName = null!; \n    private static string lockEnabledBucketName = null!; \n    private static string retentionAfterCreationBucketName = null!; \n    private static List<string> bucketNames = new List<string>(); \n    private static List<string> fileNames = new List<string>(); \n    public static async Task Main(string[] args) \n    { \n        // Set up dependency injection for the Amazon service. \n        using var host = Host.CreateDefaultBuilder(args) \n            .ConfigureLogging(logging => \n                logging.AddFilter(\"System\", LogLevel.Debug) \n                    .AddFilter<DebugLoggerProvider>(\"Microsoft\", \n LogLevel.Information) \n                    .AddFilter<ConsoleLoggerProvider>(\"Microsoft\", \n LogLevel.Trace)) \n            .ConfigureServices((_, services) => \n                services.AddAWSService<IAmazonS3>() \n                    .AddTransient<S3ActionsWrapper>() \n            ) \n            .Build(); \n        _configuration = new ConfigurationBuilder() \n            .SetBasePath(Directory.GetCurrentDirectory()) \n            .AddJsonFile(\"settings.json\") // Load settings from .json file.", "\n            .AddJsonFile(\"settings.local.json\", \n                true) // Optionally, load local settings.", "\n            .Build(); \n        ConfigurationSetup(); \n        ServicesSetup(host); \n        try \n        { \n            Console.WriteLine(new string('-', 80)); \n            Console.WriteLine(\"Welcome to the Amazon Simple Storage Service (S3) \n Object Locking Workflow Scenario.\"); \n            Console.WriteLine(new string('-', 80)); \n            await Setup(true); \n            await DemoActionChoices(); \n            Console.WriteLine(new string('-', 80)); \nScenarios API Version 2006-03-01 2365Amazon Simple Storage Service API Reference\n            Console.WriteLine(\"Cleaning up resources.\"); \n            Console.WriteLine(new string('-', 80)); \n            await Cleanup(true); \n            Console.WriteLine(new string('-', 80)); \n            Console.WriteLine(\"Amazon S3 Object Locking Workflow is complete.\"); \n            Console.WriteLine(new string('-', 80)); \n        } \n        catch (Exception ex) \n        { \n            Console.WriteLine(new string('-', 80)); \n            Console.WriteLine($\"There was a problem: {ex.Message}\"); \n            await Cleanup(true); \n            Console.WriteLine(new string('-', 80)); \n        } \n    } \n    /// <summary> \n    /// Populate the services for use within the console application. \n    /// </summary> \n    /// <param name=\"host\">The services host.</param> \n    private static void ServicesSetup(IHost host) \n    { \n        _s3ActionsWrapper = host.Services.GetRequiredService<S3ActionsWrapper>(); \n    } \n    /// <summary> \n    /// Any setup operations needed.", "\n    /// </summary> \n    public static void ConfigurationSetup() \n    { \n        _resourcePrefix = _configuration[\"resourcePrefix\"] ??", "\"dotnet-example\"; \n        noLockBucketName = _resourcePrefix + \"-no-lock\"; \n        lockEnabledBucketName = _resourcePrefix + \"-lock-enabled\"; \n        retentionAfterCreationBucketName = _resourcePrefix + \"-retention-after-\ncreation\"; \n        bucketNames.Add(noLockBucketName); \n        bucketNames.Add(lockEnabledBucketName); \n        bucketNames.Add(retentionAfterCreationBucketName); \n    } \n    // <summary> \nScenarios API Version 2006-03-01 2366Amazon Simple Storage Service API Reference\n    /// Deploy necessary resources for the scenario. \n    /// </summary> \n    /// <param name=\"interactive\">True to run as interactive.</param> \n    /// <returns>True if successful.</returns> \n    public static async Task<bool> Setup(bool interactive) \n    { \n        Console.WriteLine( \n            \"\\nFor this workflow, we will use the AWS SDK for .NET to create \n several S3\\n\" + \n            \"buckets and files to demonstrate working with S3 locking features.\n\\n\"); \n        Console.WriteLine(new string('-', 80)); \n        Console.WriteLine(\"Press Enter when you are ready to start.\"); \n        if (interactive) \n            Console.ReadLine(); \n        Console.WriteLine(\"\\nS3 buckets can be created either with or without \n object lock enabled.\"); \n        await _s3ActionsWrapper.CreateBucketWithObjectLock(noLockBucketName, \n false); \n        await _s3ActionsWrapper.CreateBucketWithObjectLock(lockEnabledBucketName, \n true); \n        await \n _s3ActionsWrapper.CreateBucketWithObjectLock(retentionAfterCreationBucketName, \n false); \n        Console.WriteLine(\"Press Enter to continue.\"); \n        if (interactive) \n            Console.ReadLine(); \n        Console.WriteLine(\"\\nA bucket can be configured to use object locking \n with a default retention period.\"); \n        await \n _s3ActionsWrapper.ModifyBucketDefaultRetention(retentionAfterCreationBucketName, \n true, \n            ObjectLockRetentionMode.Governance, DateTime.UtcNow.AddDays(1)); \n        Console.WriteLine(\"Press Enter to continue.\"); \n        if (interactive) \n            Console.ReadLine(); \n        Console.WriteLine(\"\\nObject lock policies can also be added to existing \n buckets.\"); \nScenarios API Version 2006-03-01 2367Amazon Simple Storage Service API Reference\n        await _s3ActionsWrapper.EnableObjectLockOnBucket(lockEnabledBucketName); \n         \n        Console.WriteLine(\"Press Enter to continue.\"); \n        if (interactive) \n            Console.ReadLine(); \n        // Upload some files to the buckets.", "\n        Console.WriteLine(\"\\nNow let's add some test files:\"); \n        var fileName = _configuration[\"exampleFileName\"] ??", "\"exampleFile.txt\"; \n        int fileCount = 2; \n        // Create the file if it does not already exist.", "\n        if (!File.Exists(fileName)) \n        { \n            await using StreamWriter sw = File.CreateText(fileName); \n            await sw.WriteLineAsync( \n                \"This is a sample file for uploading to a bucket.\"); \n        } \n        foreach (var bucketName in bucketNames) \n        { \n            for (int i = 0; i < fileCount; i++) \n            { \n                var numberedFileName = Path.GetFileNameWithoutExtension(fileName) \n + i + Path.GetExtension(fileName); \n                fileNames.Add(numberedFileName); \n                await _s3ActionsWrapper.UploadFileAsync(bucketName, \n numberedFileName, fileName); \n            } \n        } \n        Console.WriteLine(\"Press Enter to continue.\"); \n        if (interactive) \n            Console.ReadLine(); \n        if (!interactive) \n            return true; \n        Console.WriteLine(\"\\nNow we can set some object lock policies on \n individual files:\"); \n        foreach (var bucketName in bucketNames) \n        { \n            for (int i = 0; i < fileNames.Count; i++) \n            { \n                // No modifications to the objects in the first bucket. \n                if (bucketName != bucketNames[0]) \n                { \nScenarios API Version 2006-03-01 2368Amazon Simple Storage Service API Reference\n                    var exampleFileName = fileNames[i]; \n                    switch (i) \n                    { \n                        case 0: \n                            { \n                                var question = \n                                    $\"\\nWould you like to add a legal hold to \n {exampleFileName} in {bucketName}?", "(y/n)\"; \n                                if (GetYesNoResponse(question)) \n                                { \n                                    // Set a legal hold.", "\n                                    await \n _s3ActionsWrapper.ModifyObjectLegalHold(bucketName, exampleFileName, \n ObjectLockLegalHoldStatus.On); \n                                } \n                                break; \n                            } \n                        case 1: \n                            { \n                                var question = \n                                    $\"\\nWould you like to add a 1 day Governance \n retention period to {exampleFileName} in {bucketName}? (y/n)\" + \n                                    \"\\nReminder: Only a user with the \n s3:BypassGovernanceRetention permission will be able to delete this file or its \n bucket until the retention period has expired.\"; \n                                if (GetYesNoResponse(question)) \n                                { \n                                    // Set a Governance mode retention period for \n 1 day. \n                                    await \n _s3ActionsWrapper.ModifyObjectRetentionPeriod( \n                                        bucketName, exampleFileName, \n                                        ObjectLockRetentionMode.Governance, \n                                        DateTime.UtcNow.AddDays(1)); \n                                } \n                                break; \n                            } \n                    } \n                } \n            } \n        } \n        Console.WriteLine(new string('-', 80)); \n        return true; \nScenarios API Version 2006-03-01 2369Amazon Simple Storage Service API Reference\n    } \n    // <summary> \n    /// List all of the current buckets and objects. \n    /// </summary> \n    /// <param name=\"interactive\">True to run as interactive.</param> \n    /// <returns>The list of buckets and objects.</returns> \n    public static async Task<List<S3ObjectVersion>> ListBucketsAndObjects(bool \n interactive) \n    { \n        var allObjects = new List<S3ObjectVersion>(); \n        foreach (var bucketName in bucketNames) \n        { \n            var objectsInBucket = await \n _s3ActionsWrapper.ListBucketObjectsAndVersions(bucketName); \n            foreach (var objectKey in objectsInBucket.Versions) \n            { \n                allObjects.Add(objectKey); \n            } \n        } \n        if (interactive) \n        { \n            Console.WriteLine(\"\\nCurrent buckets and objects:\\n\"); \n            int i = 0; \n            foreach (var bucketObject in allObjects) \n            { \n                i++; \n                Console.WriteLine( \n                    $\"{i}: {bucketObject.Key} \\n\\tBucket: \n {bucketObject.BucketName}\\n\\tVersion: {bucketObject.VersionId}\"); \n            } \n        } \n        return allObjects; \n    } \n    /// <summary> \n    /// Present the user with the demo action choices. \n    /// </summary> \n    /// <returns>Async task.</returns> \n    public static async Task<bool> DemoActionChoices() \n    { \n        var choices = new string[]{ \nScenarios API Version 2006-03-01 2370Amazon Simple Storage Service API Reference\n            \"List all files in buckets.\", \n            \"Attempt to delete a file.\", \n            \"Attempt to delete a file with retention period bypass.\", \n            \"Attempt to overwrite a file.\", \n            \"View the object and bucket retention settings for a file.\", \n            \"View the legal hold settings for a file.\", \n            \"Finish the workflow.\"}; \n        var choice = 0; \n        // Keep asking the user until they choose to move on. \n        while (choice != 6) \n        { \n            Console.WriteLine(new string('-', 80)); \n            choice = GetChoiceResponse( \n                \"\\nExplore the S3 locking features by selecting one of the \n following choices:\" \n                , choices); \n            Console.WriteLine(new string('-', 80)); \n            switch (choice) \n            { \n                case 0: \n                    { \n                        await ListBucketsAndObjects(true); \n                        break; \n                    } \n                case 1: \n                    { \n                        Console.WriteLine(\"\\nEnter the number of the object to \n delete:\"); \n                        var allFiles = await ListBucketsAndObjects(true); \n                        var fileChoice = GetChoiceResponse(null, \n allFiles.Select(f => f.Key).ToArray()); \n                        await \n _s3ActionsWrapper.DeleteObjectFromBucket(allFiles[fileChoice].BucketName, \n allFiles[fileChoice].Key, false, allFiles[fileChoice].VersionId); \n                        break; \n                    } \n                case 2: \n                    { \n                        Console.WriteLine(\"\\nEnter the number of the object to \n delete:\"); \n                        var allFiles = await ListBucketsAndObjects(true); \n                        var fileChoice = GetChoiceResponse(null, \n allFiles.Select(f => f.Key).ToArray()); \nScenarios API Version 2006-03-01 2371Amazon Simple Storage Service API Reference\n                        await \n _s3ActionsWrapper.DeleteObjectFromBucket(allFiles[fileChoice].BucketName, \n allFiles[fileChoice].Key, true, allFiles[fileChoice].VersionId); \n                        break; \n                    } \n                case 3: \n                    { \n                        var allFiles = await ListBucketsAndObjects(true); \n                        Console.WriteLine(\"\\nEnter the number of the object to \n overwrite:\"); \n                        var fileChoice = GetChoiceResponse(null, \n allFiles.Select(f => f.Key).ToArray()); \n                        // Create the file if it does not already exist.", "\n                        if (!File.Exists(allFiles[fileChoice].Key)) \n                        { \n                            await using StreamWriter sw = \n File.CreateText(allFiles[fileChoice].Key); \n                            await sw.WriteLineAsync( \n                                \"This is a sample file for uploading to a \n bucket.\"); \n                        } \n                        await \n _s3ActionsWrapper.UploadFileAsync(allFiles[fileChoice].BucketName, \n allFiles[fileChoice].Key, allFiles[fileChoice].Key); \n                        break; \n                    } \n                case 4: \n                    { \n                        var allFiles = await ListBucketsAndObjects(true); \n                        Console.WriteLine(\"\\nEnter the number of the object and \n bucket to view:\"); \n                        var fileChoice = GetChoiceResponse(null, \n allFiles.Select(f => f.Key).ToArray()); \n                        await \n _s3ActionsWrapper.GetObjectRetention(allFiles[fileChoice].BucketName, \n allFiles[fileChoice].Key); \n                        await \n _s3ActionsWrapper.GetBucketObjectLockConfiguration(allFiles[fileChoice].BucketName); \n                        break; \n                    } \n                case 5: \n                    { \n                        var allFiles = await ListBucketsAndObjects(true); \nScenarios API Version 2006-03-01 2372Amazon Simple Storage Service API Reference\n                        Console.WriteLine(\"\\nEnter the number of the object to \n view:\"); \n                        var fileChoice = GetChoiceResponse(null, \n allFiles.Select(f => f.Key).ToArray()); \n                        await \n _s3ActionsWrapper.GetObjectLegalHold(allFiles[fileChoice].BucketName, \n allFiles[fileChoice].Key); \n                        break; \n                    } \n            } \n        } \n        return true; \n    } \n    // <summary> \n    /// Clean up the resources from the scenario. \n    /// </summary> \n    /// <param name=\"interactive\">True to run as interactive.</param> \n    /// <returns>True if successful.</returns> \n    public static async Task<bool> Cleanup(bool interactive) \n    { \n        Console.WriteLine(new string('-', 80)); \n        if (!interactive || GetYesNoResponse(\"Do you want to clean up all files \n and buckets? (y/n) \")) \n        { \n            // Remove all locks and delete all buckets and objects.", "\n            var allFiles = await ListBucketsAndObjects(false); \n            foreach (var fileInfo in allFiles) \n            { \n                // Check for a legal hold.", "\n                var legalHold = await \n _s3ActionsWrapper.GetObjectLegalHold(fileInfo.BucketName, fileInfo.Key); \n                if (legalHold?.Status?.Value == ObjectLockLegalHoldStatus.On) \n                { \n                    await \n _s3ActionsWrapper.ModifyObjectLegalHold(fileInfo.BucketName, fileInfo.Key, \n ObjectLockLegalHoldStatus.Off); \n                } \n                // Check for a retention period. \n                var retention = await \n _s3ActionsWrapper.GetObjectRetention(fileInfo.BucketName, fileInfo.Key); \nScenarios API Version 2006-03-01 2373Amazon Simple Storage Service API Reference\n                var hasRetentionPeriod = retention?.Mode == \n ObjectLockRetentionMode.Governance && retention.RetainUntilDate > \n DateTime.UtcNow.Date; \n                await \n _s3ActionsWrapper.DeleteObjectFromBucket(fileInfo.BucketName, fileInfo.Key, \n hasRetentionPeriod, fileInfo.VersionId); \n            } \n            foreach (var bucketName in bucketNames) \n            { \n                await _s3ActionsWrapper.DeleteBucketByName(bucketName); \n            } \n        } \n        else \n        { \n            Console.WriteLine( \n                \"Ok, we'll leave the resources intact.\\n\" + \n                \"Don't forget to delete them when you're done with them or you \n might incur unexpected charges.\" \n            ); \n        } \n        Console.WriteLine(new string('-', 80)); \n        return true; \n    } \n    /// <summary> \n    /// Helper method to get a yes or no response from the user.", "\n    /// </summary> \n    /// <param name=\"question\">The question string to print on the console.</\nparam> \n    /// <returns>True if the user responds with a yes.</returns> \n    private static bool GetYesNoResponse(string question) \n    { \n        Console.WriteLine(question); \n        var ynResponse = Console.ReadLine(); \n        var response = ynResponse != null && ynResponse.Equals(\"y\", \n StringComparison.InvariantCultureIgnoreCase); \n        return response; \n    } \n    /// <summary> \n    /// Helper method to get a choice response from the user. \nScenarios API Version 2006-03-01 2374Amazon Simple Storage Service API Reference\n    /// </summary> \n    /// <param name=\"question\">The question string to print on the console.</\nparam> \n    /// <param name=\"choices\">The choices to print on the console.</param> \n    /// <returns>The index of the selected choice</returns> \n    private static int GetChoiceResponse(string?", "question, string[] choices) \n    { \n        if (question != null) \n        { \n            Console.WriteLine(question); \n            for (int i = 0; i < choices.Length; i++) \n            { \n                Console.WriteLine($\"\\t{i + 1}.", "{choices[i]}\"); \n            } \n        } \n        var choiceNumber = 0; \n        while (choiceNumber < 1 || choiceNumber > choices.Length) \n        { \n            var choice = Console.ReadLine(); \n            Int32.TryParse(choice, out choiceNumber); \n        } \n        return choiceNumber - 1; \n    }\n}\nA wrapper class for S3 functions.\nusing System.Net;\nusing Amazon.S3;\nusing Amazon.S3.Model;\nusing Microsoft.Extensions.Configuration;\nnamespace S3ObjectLockScenario;\n/// <summary>\n/// Encapsulate the Amazon S3 operations.\n/// </summary>\npublic class S3ActionsWrapper\nScenarios API Version 2006-03-01 2375Amazon Simple Storage Service API Reference\n{ \n    private readonly IAmazonS3 _amazonS3; \n    /// <summary> \n    /// Constructor for the S3ActionsWrapper. \n    /// </summary> \n    /// <param name=\"amazonS3\">The injected S3 client.</param> \n    public S3ActionsWrapper(IAmazonS3 amazonS3, IConfiguration configuration) \n    { \n        _amazonS3 = amazonS3; \n    } \n    /// <summary> \n    /// Create a new Amazon S3 bucket with object lock actions.", "\n    /// </summary> \n    /// <param name=\"bucketName\">The name of the bucket to create.</param> \n    /// <param name=\"enableObjectLock\">True to enable object lock on the \n bucket.</param> \n    /// <returns>True if successful.</returns> \n    public async Task<bool> CreateBucketWithObjectLock(string bucketName, bool \n enableObjectLock) \n    { \n        Console.WriteLine($\"\\tCreating bucket {bucketName} with object lock \n {enableObjectLock}.\"); \n        try \n        { \n            var request = new PutBucketRequest \n            { \n                BucketName = bucketName, \n                UseClientRegion = true, \n                ObjectLockEnabledForBucket = enableObjectLock, \n            }; \n            var response = await _amazonS3.PutBucketAsync(request); \n            return response.HttpStatusCode == System.Net.HttpStatusCode.OK; \n        } \n        catch (AmazonS3Exception ex) \n        { \n            Console.WriteLine($\"Error creating bucket: '{ex.Message}'\"); \n            return false; \n        } \n    } \nScenarios API Version 2006-03-01 2376Amazon Simple Storage Service API Reference\n    /// <summary> \n    /// Enable object lock on an existing bucket. \n    /// </summary> \n    /// <param name=\"bucketName\">The name of the bucket to modify.</param> \n    /// <returns>True if successful.</returns> \n    public async Task<bool> EnableObjectLockOnBucket(string bucketName) \n    { \n        try \n        { \n            // First, enable Versioning on the bucket. \n            await _amazonS3.PutBucketVersioningAsync(new \n PutBucketVersioningRequest() \n            { \n                BucketName = bucketName, \n                VersioningConfig = new S3BucketVersioningConfig() \n                { \n                    EnableMfaDelete = false, \n                    Status = VersionStatus.Enabled \n                } \n            }); \n            var request = new PutObjectLockConfigurationRequest() \n            { \n                BucketName = bucketName, \n                ObjectLockConfiguration = new ObjectLockConfiguration() \n                { \n                    ObjectLockEnabled = new ObjectLockEnabled(\"Enabled\"), \n                }, \n            }; \n            var response = await \n _amazonS3.PutObjectLockConfigurationAsync(request); \n            Console.WriteLine($\"\\tAdded an object lock policy to bucket \n {bucketName}.\"); \n            return response.HttpStatusCode == System.Net.HttpStatusCode.OK; \n        } \n        catch (AmazonS3Exception ex) \n        { \n            Console.WriteLine($\"Error modifying object lock: '{ex.Message}'\"); \n            return false; \n        } \n    } \n    /// <summary> \nScenarios API Version 2006-03-01 2377Amazon Simple Storage Service API Reference\n    /// Set or modify a retention period on an object in an S3 bucket. \n    /// </summary> \n    /// <param name=\"bucketName\">The bucket of the object.</param> \n    /// <param name=\"objectKey\">The key of the object.</param> \n    /// <param name=\"retention\">The retention mode.</param> \n    /// <param name=\"retainUntilDate\">The date retention expires.</param> \n    /// <returns>True if successful.</returns> \n    public async Task<bool> ModifyObjectRetentionPeriod(string bucketName, \n        string objectKey, ObjectLockRetentionMode retention, DateTime \n retainUntilDate) \n    { \n        try \n        { \n            var request = new PutObjectRetentionRequest() \n            { \n                BucketName = bucketName, \n                Key = objectKey, \n                Retention = new ObjectLockRetention() \n                { \n                    Mode = retention, \n                    RetainUntilDate = retainUntilDate \n                } \n            }; \n            var response = await _amazonS3.PutObjectRetentionAsync(request); \n            Console.WriteLine($\"\\tSet retention for {objectKey} in {bucketName} \n until {retainUntilDate:d}.\"); \n            return response.HttpStatusCode == System.Net.HttpStatusCode.OK; \n        } \n        catch (AmazonS3Exception ex) \n        { \n            Console.WriteLine($\"\\tError modifying retention period: \n '{ex.Message}'\"); \n            return false; \n        } \n    } \n    /// <summary> \n    /// Set or modify a retention period on an S3 bucket. \n    /// </summary> \n    /// <param name=\"bucketName\">The bucket to modify.</param> \n    /// <param name=\"retention\">The retention mode.</param> \n    /// <param name=\"retainUntilDate\">The date for retention until.</param> \n    /// <returns>True if successful.</returns> \nScenarios API Version 2006-03-01 2378Amazon Simple Storage Service API Reference\n    public async Task<bool> ModifyBucketDefaultRetention(string bucketName, bool \n enableObjectLock, ObjectLockRetentionMode retention, DateTime retainUntilDate) \n    { \n        var enabledString = enableObjectLock ? \"Enabled\" : \"Disabled\"; \n        var timeDifference = retainUntilDate.Subtract(DateTime.Now); \n        try \n        { \n            // First, enable Versioning on the bucket. \n            await _amazonS3.PutBucketVersioningAsync(new \n PutBucketVersioningRequest() \n            { \n                BucketName = bucketName, \n                VersioningConfig = new S3BucketVersioningConfig() \n                { \n                    EnableMfaDelete = false, \n                    Status = VersionStatus.Enabled \n                } \n            }); \n            var request = new PutObjectLockConfigurationRequest() \n            { \n                BucketName = bucketName, \n                ObjectLockConfiguration = new ObjectLockConfiguration() \n                { \n                    ObjectLockEnabled = new ObjectLockEnabled(enabledString), \n                    Rule = new ObjectLockRule() \n                    { \n                        DefaultRetention = new DefaultRetention() \n                        { \n                            Mode = retention, \n                            Days = timeDifference.Days // Can be specified in \n days or years but not both. \n                        } \n                    } \n                } \n            }; \n            var response = await \n _amazonS3.PutObjectLockConfigurationAsync(request); \n            Console.WriteLine($\"\\tAdded a default retention to bucket \n {bucketName}.\"); \n            return response.HttpStatusCode == System.Net.HttpStatusCode.OK; \n        } \n        catch (AmazonS3Exception ex) \nScenarios API Version 2006-03-01 2379Amazon Simple Storage Service API Reference\n        { \n            Console.WriteLine($\"\\tError modifying object lock: '{ex.Message}'\"); \n            return false; \n        } \n    } \n    /// <summary> \n    /// Get the retention period for an S3 object. \n    /// </summary> \n    /// <param name=\"bucketName\">The bucket of the object.</param> \n    /// <param name=\"objectKey\">The object key.</param> \n    /// <returns>The object retention details.</returns> \n    public async Task<ObjectLockRetention> GetObjectRetention(string bucketName, \n        string objectKey) \n    { \n        try \n        { \n            var request = new GetObjectRetentionRequest() \n            { \n                BucketName = bucketName, \n                Key = objectKey \n            }; \n            var response = await _amazonS3.GetObjectRetentionAsync(request); \n            Console.WriteLine($\"\\tObject retention for {objectKey} in \n {bucketName}: \" + \n                              $\"\\n\\t{response.Retention.Mode} until \n {response.Retention.RetainUntilDate:d}.\"); \n            return response.Retention; \n        } \n        catch (AmazonS3Exception ex) \n        { \n            Console.WriteLine($\"\\tUnable to fetch object lock retention: \n '{ex.Message}'\"); \n            return new ObjectLockRetention(); \n        } \n    } \n    /// <summary> \n    /// Set or modify a legal hold on an object in an S3 bucket. \n    /// </summary> \n    /// <param name=\"bucketName\">The bucket of the object.</param> \n    /// <param name=\"objectKey\">The key of the object.</param> \n    /// <param name=\"holdStatus\">The On or Off status for the legal hold.</param> \nScenarios API Version 2006-03-01 2380Amazon Simple Storage Service API Reference\n    /// <returns>True if successful.</returns> \n    public async Task<bool> ModifyObjectLegalHold(string bucketName, \n        string objectKey, ObjectLockLegalHoldStatus holdStatus) \n    { \n        try \n        { \n            var request = new PutObjectLegalHoldRequest() \n            { \n                BucketName = bucketName, \n                Key = objectKey, \n                LegalHold = new ObjectLockLegalHold() \n                { \n                    Status = holdStatus \n                } \n            }; \n            var response = await _amazonS3.PutObjectLegalHoldAsync(request); \n            Console.WriteLine($\"\\tModified legal hold for {objectKey} in \n {bucketName}.\"); \n            return response.HttpStatusCode == System.Net.HttpStatusCode.OK; \n        } \n        catch (AmazonS3Exception ex) \n        { \n            Console.WriteLine($\"\\tError modifying legal hold: '{ex.Message}'\"); \n            return false; \n        } \n    } \n    /// <summary> \n    /// Get the legal hold details for an S3 object. \n    /// </summary> \n    /// <param name=\"bucketName\">The bucket of the object.</param> \n    /// <param name=\"objectKey\">The object key.</param> \n    /// <returns>The object legal hold details.</returns> \n    public async Task<ObjectLockLegalHold> GetObjectLegalHold(string bucketName, \n        string objectKey) \n    { \n        try \n        { \n            var request = new GetObjectLegalHoldRequest() \n            { \n                BucketName = bucketName, \n                Key = objectKey \n            }; \nScenarios API Version 2006-03-01 2381Amazon Simple Storage Service API Reference\n            var response = await _amazonS3.GetObjectLegalHoldAsync(request); \n            Console.WriteLine($\"\\tObject legal hold for {objectKey} in \n {bucketName}: \" + \n                              $\"\\n\\tStatus: {response.LegalHold.Status}\"); \n            return response.LegalHold; \n        } \n        catch (AmazonS3Exception ex) \n        { \n            Console.WriteLine($\"\\tUnable to fetch legal hold: '{ex.Message}'\"); \n            return new ObjectLockLegalHold(); \n        } \n    } \n    /// <summary> \n    /// Get the object lock configuration details for an S3 bucket. \n    /// </summary> \n    /// <param name=\"bucketName\">The bucket to get details.</param> \n    /// <returns>The bucket's object lock configuration details.</returns> \n    public async Task<ObjectLockConfiguration> \n GetBucketObjectLockConfiguration(string bucketName) \n    { \n        try \n        { \n            var request = new GetObjectLockConfigurationRequest() \n            { \n                BucketName = bucketName \n            }; \n            var response = await \n _amazonS3.GetObjectLockConfigurationAsync(request); \n            Console.WriteLine($\"\\tBucket object lock config for {bucketName} in \n {bucketName}: \" + \n                              $\"\\n\\tEnabled: \n {response.ObjectLockConfiguration.ObjectLockEnabled}\" + \n                              $\"\\n\\tRule: \n {response.ObjectLockConfiguration.Rule?.DefaultRetention}\"); \n            return response.ObjectLockConfiguration; \n        } \n        catch (AmazonS3Exception ex) \n        { \n            Console.WriteLine($\"\\tUnable to fetch object lock config: \n '{ex.Message}'\"); \nScenarios API Version 2006-03-01 2382Amazon Simple Storage Service API Reference\n            return new ObjectLockConfiguration(); \n        } \n    } \n    /// <summary> \n    /// Upload a file from the local computer to an Amazon S3 bucket. \n    /// </summary> \n    /// <param name=\"bucketName\">The Amazon S3 bucket to use.</param> \n    /// <param name=\"objectName\">The object to upload.</param> \n    /// <param name=\"filePath\">The path, including file name, of the object to \n upload.</param> \n    /// <returns>True if success.<returns> \n    public async Task<bool> UploadFileAsync(string bucketName, string objectName, \n string filePath) \n    { \n        var request = new PutObjectRequest \n        { \n            BucketName = bucketName, \n            Key = objectName, \n            FilePath = filePath, \n            ChecksumAlgorithm = ChecksumAlgorithm.SHA256 \n        }; \n        var response = await _amazonS3.PutObjectAsync(request); \n        if (response.HttpStatusCode == System.Net.HttpStatusCode.OK) \n        { \n            Console.WriteLine($\"\\tSuccessfully uploaded {objectName} to \n {bucketName}.\"); \n            return true; \n        } \n        else \n        { \n            Console.WriteLine($\"\\tCould not upload {objectName} to \n {bucketName}.\"); \n            return false; \n        } \n    } \n    /// <summary> \n    /// List bucket objects and versions. \n    /// </summary> \n    /// <param name=\"bucketName\">The Amazon S3 bucket to use.</param> \n    /// <returns>The list of objects and versions.</returns> \nScenarios API Version 2006-03-01 2383Amazon Simple Storage Service API Reference\n    public async Task<ListVersionsResponse> ListBucketObjectsAndVersions(string \n bucketName) \n    { \n        var request = new ListVersionsRequest() \n        { \n            BucketName = bucketName \n        }; \n        var response = await _amazonS3.ListVersionsAsync(request); \n        return response; \n    } \n    /// <summary> \n    /// Delete an object from a specific bucket. \n    /// </summary> \n    /// <param name=\"bucketName\">The Amazon S3 bucket to use.</param> \n    /// <param name=\"objectKey\">The key of the object to delete.</param> \n    /// <param name=\"hasRetention\">True if the object has retention settings.</\nparam> \n    /// <param name=\"versionId\">Optional versionId.</param> \n    /// <returns>True if successful.</returns> \n    public async Task<bool> DeleteObjectFromBucket(string bucketName, string \n objectKey, bool hasRetention, string? versionId = null) \n    { \n        try \n        { \n            var request = new DeleteObjectRequest() \n            { \n                BucketName = bucketName, \n                Key = objectKey, \n                VersionId = versionId, \n            }; \n            if (hasRetention) \n            { \n                // Set the BypassGovernanceRetention header \n                // if the file has retention settings. \n                request.BypassGovernanceRetention = true; \n            } \n            await _amazonS3.DeleteObjectAsync(request); \n            Console.WriteLine( \n                $\"Deleted {objectKey} in {bucketName}.\"); \n            return true; \n        } \n        catch (AmazonS3Exception ex) \nScenarios API Version 2006-03-01 2384Amazon Simple Storage Service API Reference\n        { \n            Console.WriteLine($\"\\tUnable to delete object {objectKey} in bucket \n {bucketName}: \" + ex.Message); \n            return false; \n        } \n    } \n    /// <summary> \n    /// Delete a specific bucket. \n    /// </summary> \n    /// <param name=\"bucketName\">The Amazon S3 bucket to use.</param> \n    /// <param name=\"objectKey\">The key of the object to delete.</param> \n    /// <param name=\"versionId\">Optional versionId.</param> \n    /// <returns>True if successful.</returns> \n    public async Task<bool> DeleteBucketByName(string bucketName) \n    { \n        try \n        { \n            var request = new DeleteBucketRequest() { BucketName = bucketName, }; \n            var response = await _amazonS3.DeleteBucketAsync(request); \n            Console.WriteLine($\"\\tDelete for {bucketName} complete.\"); \n            return response.HttpStatusCode == HttpStatusCode.OK; \n        } \n        catch (AmazonS3Exception ex) \n        { \n            Console.WriteLine($\"\\tUnable to delete bucket {bucketName}: \" + \n ex.Message); \n            return false; \n        } \n    }\n}\n\u2022For API details, see the following topics in AWS SDK for .NET API Reference.\n\u2022GetObjectLegalHold\n\u2022GetObjectLockCon\ufb01guration\n\u2022GetObjectRetention\n\u2022PutObjectLegalHold\n\u2022PutObjectLockCon\ufb01guration\nScenarios API Version 2006-03-01 2385Amazon Simple Storage Service API Reference\n\u2022PutObjectRetention\nGo\nSDK for Go V2\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nRun an interactive scenario demonstrating Amazon S3 object lock features.\n// ObjectLockScenario contains the steps to run the S3 Object Lock workflow.\ntype ObjectLockScenario struct { \n questioner demotools.IQuestioner \n resources  Resources \n s3Actions  *actions.S3Actions \n sdkConfig  aws.Config\n}\n// NewObjectLockScenario constructs a new ObjectLockScenario instance.\nfunc NewObjectLockScenario(sdkConfig aws.Config, questioner \n demotools.IQuestioner) ObjectLockScenario { \n scenario := ObjectLockScenario{ \n  questioner: questioner, \n  resources:  Resources{}, \n  s3Actions:  &actions.S3Actions{S3Client: s3.NewFromConfig(sdkConfig)}, \n  sdkConfig:  sdkConfig, \n } \n scenario.s3Actions.S3Manager = manager.NewUploader(scenario.s3Actions.S3Client) \n scenario.resources.init(scenario.s3Actions, questioner) \n return scenario\n}\ntype nameLocked struct { \n name   string \n locked bool\n}\nScenarios API Version 2006-03-01 2386Amazon Simple Storage Service API Reference\nvar createInfo = []nameLocked{ \n {\"standard-bucket\", false}, \n {\"lock-bucket\", true}, \n {\"retention-bucket\", false},\n}\n// CreateBuckets creates the S3 buckets required for the workflow.\nfunc (scenario *ObjectLockScenario) CreateBuckets(ctx context.Context) { \n log.Println(\"Let's create some S3 buckets to use for this workflow.\") \n success := false \n for !success { \n  prefix := scenario.questioner.Ask( \n   \"This example creates three buckets. Enter a prefix to name your buckets \n (remember bucket names must be globally unique):\") \n  for _, info := range createInfo { \n   log.Println(fmt.Sprintf(\"%s.%s\", prefix, info.name)) \n   bucketName, err := scenario.s3Actions.CreateBucketWithLock(ctx, \n fmt.Sprintf(\"%s.%s\", prefix, info.name), scenario.sdkConfig.Region, info.locked) \n   if err != nil { \n    switch err.(type) { \n    case *types.BucketAlreadyExists, *types.BucketAlreadyOwnedByYou: \n     log.Printf(\"Couldn't create bucket %s.\\n\", bucketName) \n    default: \n     panic(err) \n    } \n    break \n   } \n   scenario.resources.demoBuckets[info.name] = &DemoBucket{ \n    name:       bucketName, \n    objectKeys: []string{}, \n   } \n   log.Printf(\"Created bucket %s.\\n\", bucketName) \n  } \n  if len(scenario.resources.demoBuckets) < len(createInfo) { \n   scenario.resources.deleteBuckets(ctx) \n  } else { \n   success = true \n  } \n } \n log.Println(\"S3 buckets created.\") \n log.Println(strings.Repeat(\"-\", 88))\nScenarios API Version 2006-03-01 2387Amazon Simple Storage Service API Reference\n}\n// EnableLockOnBucket enables object locking on an existing bucket.\nfunc (scenario *ObjectLockScenario) EnableLockOnBucket(ctx context.Context) { \n log.Println(\"\\nA bucket can be configured to use object locking.\") \n scenario.questioner.Ask(\"Press Enter to continue.\") \n var err error \n bucket := scenario.resources.demoBuckets[\"retention-bucket\"] \n err = scenario.s3Actions.EnableObjectLockOnBucket(ctx, bucket.name) \n if err != nil { \n  switch err.(type) { \n  case *types.NoSuchBucket: \n   log.Printf(\"Couldn't enable object locking on bucket %s.\\n\", bucket.name) \n  default: \n   panic(err) \n  } \n } else { \n  log.Printf(\"Object locking enabled on bucket %s.\", bucket.name) \n } \n log.Println(strings.Repeat(\"-\", 88))\n}\n// SetDefaultRetentionPolicy sets a default retention governance policy on a \n bucket.\nfunc (scenario *ObjectLockScenario) SetDefaultRetentionPolicy(ctx \n context.Context) { \n log.Println(\"\\nA bucket can be configured to use object locking with a default \n retention period.\") \n bucket := scenario.resources.demoBuckets[\"retention-bucket\"] \n retentionPeriod := scenario.questioner.AskInt(\"Enter the default retention \n period in days: \") \n err := scenario.s3Actions.ModifyDefaultBucketRetention(ctx, \n bucket.name, types.ObjectLockEnabledEnabled, int32(retentionPeriod), \n types.ObjectLockRetentionModeGovernance) \n if err != nil { \n  switch err.(type) { \n  case *types.NoSuchBucket: \n   log.Printf(\"Couldn't configure a default retention period on bucket %s.\\n\", \n bucket.name) \n  default: \n   panic(err) \nScenarios API Version 2006-03-01 2388Amazon Simple Storage Service API Reference\n  } \n } else { \n  log.Printf(\"Default retention policy set on bucket %s with %d day retention \n period.\", bucket.name, retentionPeriod) \n  bucket.retentionEnabled = true \n } \n log.Println(strings.Repeat(\"-\", 88))\n}\n// UploadTestObjects uploads test objects to the S3 buckets.\nfunc (scenario *ObjectLockScenario) UploadTestObjects(ctx context.Context) { \n log.Println(\"Uploading test objects to S3 buckets.\") \n for _, info := range createInfo { \n  bucket := scenario.resources.demoBuckets[info.name] \n  for i := 0; i < 2; i++ { \n   key, err := scenario.s3Actions.UploadObject(ctx, bucket.name, \n fmt.Sprintf(\"example-%d\", i), \n    fmt.Sprintf(\"Example object content #%d in bucket %s.\", i, bucket.name)) \n   if err != nil { \n    switch err.(type) { \n    case *types.NoSuchBucket: \n     log.Printf(\"Couldn't upload %s to bucket %s.\\n\", key, bucket.name) \n    default: \n     panic(err) \n    } \n   } else { \n    log.Printf(\"Uploaded %s to bucket %s.\\n\", key, bucket.name) \n    bucket.objectKeys = append(bucket.objectKeys, key) \n   } \n  } \n } \n scenario.questioner.Ask(\"Test objects uploaded. Press Enter to continue.\") \n log.Println(strings.Repeat(\"-\", 88))\n}\n// SetObjectLockConfigurations sets object lock configurations on the test \n objects.\nfunc (scenario *ObjectLockScenario) SetObjectLockConfigurations(ctx \n context.Context) { \n log.Println(\"Now let's set object lock configurations on individual objects.\") \nScenarios API Version 2006-03-01 2389Amazon Simple Storage Service API Reference\n buckets := []*DemoBucket{scenario.resources.demoBuckets[\"lock-bucket\"], \n scenario.resources.demoBuckets[\"retention-bucket\"]} \n for _, bucket := range buckets { \n  for index, objKey := range bucket.objectKeys { \n   switch index { \n   case 0: \n    if scenario.questioner.AskBool(fmt.Sprintf(\"\\nDo you want to add a legal hold \n to %s in %s (y/n)? \", objKey, bucket.name), \"y\") { \n     err := scenario.s3Actions.PutObjectLegalHold(ctx, bucket.name, objKey, \"\", \n types.ObjectLockLegalHoldStatusOn) \n     if err != nil { \n      switch err.(type) { \n      case *types.NoSuchKey: \n       log.Printf(\"Couldn't set legal hold on %s.\\n\", objKey) \n      default: \n       panic(err) \n      } \n     } else { \n      log.Printf(\"Legal hold set on %s.\\n\", objKey) \n     } \n    } \n   case 1: \n    q := fmt.Sprintf(\"\\nDo you want to add a 1 day Governance retention period to \n %s in %s?\\n\"+ \n     \"Reminder: Only a user with the s3:BypassGovernanceRetention permission is \n able to delete this object\\n\"+ \n     \"or its bucket until the retention period has expired. (y/n) \", objKey, \n bucket.name) \n    if scenario.questioner.AskBool(q, \"y\") { \n     err := scenario.s3Actions.PutObjectRetention(ctx, bucket.name, objKey, \n types.ObjectLockRetentionModeGovernance, 1) \n     if err != nil { \n      switch err.(type) { \n      case *types.NoSuchKey: \n       log.Printf(\"Couldn't set retention period on %s in %s.\\n\", objKey, \n bucket.name) \n      default: \n       panic(err) \n      } \n     } else { \n      log.Printf(\"Retention period set to 1 for %s.\", objKey) \n      bucket.retentionEnabled = true \n     } \n    } \nScenarios API Version 2006-03-01 2390Amazon Simple Storage Service API Reference\n   } \n  } \n } \n log.Println(strings.Repeat(\"-\", 88))\n}\nconst ( \n ListAll = iota \n DeleteObject \n DeleteRetentionObject \n OverwriteObject \n ViewRetention \n ViewLegalHold \n Finish\n)\n// InteractWithObjects allows the user to interact with the objects and test the \n object lock configurations.\nfunc (scenario *ObjectLockScenario) InteractWithObjects(ctx context.Context) { \n log.Println(\"Now you can interact with the objects to explore the object lock \n configurations.\") \n interactiveChoices := []string{ \n  \"List all objects and buckets.\", \n  \"Attempt to delete an object.\", \n  \"Attempt to delete an object with retention period bypass.\", \n  \"Attempt to overwrite a file.\", \n  \"View the retention settings for an object.\", \n  \"View the legal hold settings for an object.\", \n  \"Finish the workflow.\"} \n choice := ListAll \n for choice != Finish { \n  objList := scenario.GetAllObjects(ctx) \n  objChoices := scenario.makeObjectChoiceList(objList) \n  choice = scenario.questioner.AskChoice(\"Choose an action from the menu:\\n\", \n interactiveChoices) \n  switch choice { \n  case ListAll: \n   log.Println(\"The current objects in the example buckets are:\") \n   for _, objChoice := range objChoices { \n    log.Println(\"\\t\", objChoice) \n   } \n  case DeleteObject, DeleteRetentionObject: \nScenarios API Version 2006-03-01 2391Amazon Simple Storage Service API Reference\n   objChoice := scenario.questioner.AskChoice(\"Enter the number of the object to \n delete:\\n\", objChoices) \n   obj := objList[objChoice] \n   deleted, err := scenario.s3Actions.DeleteObject(ctx, obj.bucket, obj.key, \n obj.versionId, choice == DeleteRetentionObject) \n   if err != nil { \n    switch err.(type) { \n    case *types.NoSuchKey: \n     log.Println(\"Nothing to delete.\") \n    default: \n     panic(err) \n    } \n   } else if deleted { \n    log.Printf(\"Object %s deleted.\\n\", obj.key) \n   } \n  case OverwriteObject: \n   objChoice := scenario.questioner.AskChoice(\"Enter the number of the object to \n overwrite:\\n\", objChoices) \n   obj := objList[objChoice] \n   _, err := scenario.s3Actions.UploadObject(ctx, obj.bucket, obj.key, \n fmt.Sprintf(\"New content in object %s.\", obj.key)) \n   if err != nil { \n    switch err.(type) { \n    case *types.NoSuchBucket: \n     log.Println(\"Couldn't upload to nonexistent bucket.\") \n    default: \n     panic(err) \n    } \n   } else { \n    log.Printf(\"Uploaded new content to object %s.\\n\", obj.key) \n   } \n  case ViewRetention: \n   objChoice := scenario.questioner.AskChoice(\"Enter the number of the object to \n view:\\n\", objChoices) \n   obj := objList[objChoice] \n   retention, err := scenario.s3Actions.GetObjectRetention(ctx, obj.bucket, \n obj.key) \n   if err != nil { \n    switch err.(type) { \n    case *types.NoSuchKey: \n     log.Printf(\"Can't get retention configuration for %s.\\n\", obj.key) \n    default: \n     panic(err) \n    } \nScenarios API Version 2006-03-01 2392Amazon Simple Storage Service API Reference\n   } else if retention != nil { \n    log.Printf(\"Object %s has retention mode %s until %v.\\n\", obj.key, \n retention.Mode, retention.RetainUntilDate) \n   } else { \n    log.Printf(\"Object %s does not have object retention configured.\\n\", obj.key) \n   } \n  case ViewLegalHold: \n   objChoice := scenario.questioner.AskChoice(\"Enter the number of the object to \n view:\\n\", objChoices) \n   obj := objList[objChoice] \n   legalHold, err := scenario.s3Actions.GetObjectLegalHold(ctx, obj.bucket, \n obj.key, obj.versionId) \n   if err != nil { \n    switch err.(type) { \n    case *types.NoSuchKey: \n     log.Printf(\"Can't get legal hold configuration for %s.\\n\", obj.key) \n    default: \n     panic(err) \n    } \n   } else if legalHold != nil { \n    log.Printf(\"Object %s has legal hold %v.\", obj.key, *legalHold) \n   } else { \n    log.Printf(\"Object %s does not have legal hold configured.\", obj.key) \n   } \n  case Finish: \n   log.Println(\"Let's clean up.\") \n  } \n  log.Println(strings.Repeat(\"-\", 88)) \n }\n}\ntype BucketKeyVersionId struct { \n bucket    string \n key       string \n versionId string\n}\n// GetAllObjects gets the object versions in the example S3 buckets and returns \n them in a flattened list.\nfunc (scenario *ObjectLockScenario) GetAllObjects(ctx context.Context) \n []BucketKeyVersionId { \n var objectList []BucketKeyVersionId \n for _, info := range createInfo { \n  bucket := scenario.resources.demoBuckets[info.name] \nScenarios API Version 2006-03-01 2393Amazon Simple Storage Service API Reference\n  versions, err := scenario.s3Actions.ListObjectVersions(ctx, bucket.name) \n  if err != nil { \n   switch err.(type) { \n   case *types.NoSuchBucket: \n    log.Printf(\"Couldn't get object versions for %s.\\n\", bucket.name) \n   default: \n    panic(err) \n   } \n  } else { \n   for _, version := range versions { \n    objectList = append(objectList, \n     BucketKeyVersionId{bucket: bucket.name, key: *version.Key, versionId: \n *version.VersionId}) \n   } \n  } \n } \n return objectList\n}\n// makeObjectChoiceList makes the object version list into a list of strings that \n are displayed\n// as choices.\nfunc (scenario *ObjectLockScenario) makeObjectChoiceList(bucketObjects \n []BucketKeyVersionId) []string { \n choices := make([]string, len(bucketObjects)) \n for i := 0; i < len(bucketObjects); i++ { \n  choices[i] = fmt.Sprintf(\"%s in %s with VersionId %s.\", \n   bucketObjects[i].key, bucketObjects[i].bucket, bucketObjects[i].versionId) \n } \n return choices\n}\n// Run runs the S3 Object Lock workflow scenario.\nfunc (scenario *ObjectLockScenario) Run(ctx context.Context) { \n defer func() { \n  if r := recover(); r != nil { \n   log.Println(\"Something went wrong with the demo.\") \n   _, isMock := scenario.questioner.(*demotools.MockQuestioner) \n   if isMock || scenario.questioner.AskBool(\"Do you want to see the full error \n message (y/n)?\", \"y\") { \n    log.Println(r) \n   } \n   scenario.resources.Cleanup(ctx) \n  } \nScenarios API Version 2006-03-01 2394Amazon Simple Storage Service API Reference\n }() \n log.Println(strings.Repeat(\"-\", 88)) \n log.Println(\"Welcome to the Amazon S3 Object Lock Workflow Scenario.\") \n log.Println(strings.Repeat(\"-\", 88)) \n scenario.CreateBuckets(ctx) \n scenario.EnableLockOnBucket(ctx) \n scenario.SetDefaultRetentionPolicy(ctx) \n scenario.UploadTestObjects(ctx) \n scenario.SetObjectLockConfigurations(ctx) \n scenario.InteractWithObjects(ctx) \n scenario.resources.Cleanup(ctx) \n log.Println(strings.Repeat(\"-\", 88)) \n log.Println(\"Thanks for watching!\") \n log.Println(strings.Repeat(\"-\", 88))\n}\nDe\ufb01ne a struct that wraps S3 actions used in this example.\n// S3Actions wraps S3 service actions.\ntype S3Actions struct { \n S3Client  *s3.Client \n S3Manager *manager.Uploader\n}\n// CreateBucketWithLock creates a new S3 bucket with optional object locking \n enabled\n// and waits for the bucket to exist before returning.\nfunc (actor S3Actions) CreateBucketWithLock(ctx context.Context, bucket string, \n region string, enableObjectLock bool) (string, error) { \n input := &s3.CreateBucketInput{ \n  Bucket: aws.String(bucket), \n  CreateBucketConfiguration: &types.CreateBucketConfiguration{ \n   LocationConstraint: types.BucketLocationConstraint(region), \n  }, \nScenarios API Version 2006-03-01 2395Amazon Simple Storage Service API Reference\n } \n if enableObjectLock { \n  input.ObjectLockEnabledForBucket = aws.Bool(true) \n } \n _, err := actor.S3Client.CreateBucket(ctx, input) \n if err != nil { \n  var owned *types.BucketAlreadyOwnedByYou \n  var exists *types.BucketAlreadyExists \n  if errors.As(err, &owned) { \n   log.Printf(\"You already own bucket %s.\\n\", bucket) \n   err = owned \n  } else if errors.As(err, &exists) { \n   log.Printf(\"Bucket %s already exists.\\n\", bucket) \n   err = exists \n  } \n } else { \n  err = s3.NewBucketExistsWaiter(actor.S3Client).Wait( \n   ctx, &s3.HeadBucketInput{Bucket: aws.String(bucket)}, time.Minute) \n  if err != nil { \n   log.Printf(\"Failed attempt to wait for bucket %s to exist.\\n\", bucket) \n  } \n } \n return bucket, err\n}\n// GetObjectLegalHold retrieves the legal hold status for an S3 object.\nfunc (actor S3Actions) GetObjectLegalHold(ctx context.Context, bucket string, key \n string, versionId string) (*types.ObjectLockLegalHoldStatus, error) { \n var status *types.ObjectLockLegalHoldStatus \n input := &s3.GetObjectLegalHoldInput{ \n  Bucket:    aws.String(bucket), \n  Key:       aws.String(key), \n  VersionId: aws.String(versionId), \n } \n output, err := actor.S3Client.GetObjectLegalHold(ctx, input) \n if err != nil { \n  var noSuchKeyErr *types.NoSuchKey \n  var apiErr *smithy.GenericAPIError \nScenarios API Version 2006-03-01 2396Amazon Simple Storage Service API Reference\n  if errors.As(err, &noSuchKeyErr) { \n   log.Printf(\"Object %s does not exist in bucket %s.\\n\", key, bucket) \n   err = noSuchKeyErr \n  } else if errors.As(err, &apiErr) { \n   switch apiErr.ErrorCode() { \n   case \"NoSuchObjectLockConfiguration\": \n    log.Printf(\"Object %s does not have an object lock configuration.\\n\", key) \n    err = nil \n   case \"InvalidRequest\": \n    log.Printf(\"Bucket %s does not have an object lock configuration.\\n\", bucket) \n    err = nil \n   } \n  } \n } else { \n  status = &output.LegalHold.Status \n } \n return status, err\n}\n// GetObjectLockConfiguration retrieves the object lock configuration for an S3 \n bucket.\nfunc (actor S3Actions) GetObjectLockConfiguration(ctx context.Context, bucket \n string) (*types.ObjectLockConfiguration, error) { \n var lockConfig *types.ObjectLockConfiguration \n input := &s3.GetObjectLockConfigurationInput{ \n  Bucket: aws.String(bucket), \n } \n output, err := actor.S3Client.GetObjectLockConfiguration(ctx, input) \n if err != nil { \n  var noBucket *types.NoSuchBucket \n  var apiErr *smithy.GenericAPIError \n  if errors.As(err, &noBucket) { \n   log.Printf(\"Bucket %s does not exist.\\n\", bucket) \n   err = noBucket \n  } else if errors.As(err, &apiErr) && apiErr.ErrorCode() == \n \"ObjectLockConfigurationNotFoundError\" { \n   log.Printf(\"Bucket %s does not have an object lock configuration.\\n\", bucket) \n   err = nil \n  } \n } else { \nScenarios API Version 2006-03-01 2397Amazon Simple Storage Service API Reference\n  lockConfig = output.ObjectLockConfiguration \n } \n return lockConfig, err\n}\n// GetObjectRetention retrieves the object retention configuration for an S3 \n object.\nfunc (actor S3Actions) GetObjectRetention(ctx context.Context, bucket string, key \n string) (*types.ObjectLockRetention, error) { \n var retention *types.ObjectLockRetention \n input := &s3.GetObjectRetentionInput{ \n  Bucket: aws.String(bucket), \n  Key:    aws.String(key), \n } \n output, err := actor.S3Client.GetObjectRetention(ctx, input) \n if err != nil { \n  var noKey *types.NoSuchKey \n  var apiErr *smithy.GenericAPIError \n  if errors.As(err, &noKey) { \n   log.Printf(\"Object %s does not exist in bucket %s.\\n\", key, bucket) \n   err = noKey \n  } else if errors.As(err, &apiErr) { \n   switch apiErr.ErrorCode() { \n   case \"NoSuchObjectLockConfiguration\": \n    err = nil \n   case \"InvalidRequest\": \n    log.Printf(\"Bucket %s does not have locking enabled.\", bucket) \n    err = nil \n   } \n  } \n } else { \n  retention = output.Retention \n } \n return retention, err\n}\n// PutObjectLegalHold sets the legal hold configuration for an S3 object.\nScenarios API Version 2006-03-01 2398Amazon Simple Storage Service API Reference\nfunc (actor S3Actions) PutObjectLegalHold(ctx context.Context, bucket string, key \n string, versionId string, legalHoldStatus types.ObjectLockLegalHoldStatus) error \n { \n input := &s3.PutObjectLegalHoldInput{ \n  Bucket: aws.String(bucket), \n  Key:    aws.String(key), \n  LegalHold: &types.ObjectLockLegalHold{ \n   Status: legalHoldStatus, \n  }, \n } \n if versionId != \"\" { \n  input.VersionId = aws.String(versionId) \n } \n _, err := actor.S3Client.PutObjectLegalHold(ctx, input) \n if err != nil { \n  var noKey *types.NoSuchKey \n  if errors.As(err, &noKey) { \n   log.Printf(\"Object %s does not exist in bucket %s.\\n\", key, bucket) \n   err = noKey \n  } \n } \n return err\n}\n// ModifyDefaultBucketRetention modifies the default retention period of an \n existing bucket.\nfunc (actor S3Actions) ModifyDefaultBucketRetention( \n ctx context.Context, bucket string, lockMode types.ObjectLockEnabled, \n retentionPeriod int32, retentionMode types.ObjectLockRetentionMode) error { \n input := &s3.PutObjectLockConfigurationInput{ \n  Bucket: aws.String(bucket), \n  ObjectLockConfiguration: &types.ObjectLockConfiguration{ \n   ObjectLockEnabled: lockMode, \n   Rule: &types.ObjectLockRule{ \n    DefaultRetention: &types.DefaultRetention{ \n     Days: aws.Int32(retentionPeriod), \n     Mode: retentionMode, \n    }, \n   }, \nScenarios API Version 2006-03-01 2399Amazon Simple Storage Service API Reference\n  }, \n } \n _, err := actor.S3Client.PutObjectLockConfiguration(ctx, input) \n if err != nil { \n  var noBucket *types.NoSuchBucket \n  if errors.As(err, &noBucket) { \n   log.Printf(\"Bucket %s does not exist.\\n\", bucket) \n   err = noBucket \n  } \n } \n return err\n}\n// EnableObjectLockOnBucket enables object locking on an existing bucket.\nfunc (actor S3Actions) EnableObjectLockOnBucket(ctx context.Context, bucket \n string) error { \n // Versioning must be enabled on the bucket before object locking is enabled. \n verInput := &s3.PutBucketVersioningInput{ \n  Bucket: aws.String(bucket), \n  VersioningConfiguration: &types.VersioningConfiguration{ \n   MFADelete: types.MFADeleteDisabled, \n   Status:    types.BucketVersioningStatusEnabled, \n  }, \n } \n _, err := actor.S3Client.PutBucketVersioning(ctx, verInput) \n if err != nil { \n  var noBucket *types.NoSuchBucket \n  if errors.As(err, &noBucket) { \n   log.Printf(\"Bucket %s does not exist.\\n\", bucket) \n   err = noBucket \n  } \n  return err \n } \n input := &s3.PutObjectLockConfigurationInput{ \n  Bucket: aws.String(bucket), \n  ObjectLockConfiguration: &types.ObjectLockConfiguration{ \n   ObjectLockEnabled: types.ObjectLockEnabledEnabled, \n  }, \n } \n _, err = actor.S3Client.PutObjectLockConfiguration(ctx, input) \nScenarios API Version 2006-03-01 2400Amazon Simple Storage Service API Reference\n if err != nil { \n  var noBucket *types.NoSuchBucket \n  if errors.As(err, &noBucket) { \n   log.Printf(\"Bucket %s does not exist.\\n\", bucket) \n   err = noBucket \n  } \n } \n return err\n}\n// PutObjectRetention sets the object retention configuration for an S3 object.\nfunc (actor S3Actions) PutObjectRetention(ctx context.Context, bucket string, key \n string, retentionMode types.ObjectLockRetentionMode, retentionPeriodDays int32) \n error { \n input := &s3.PutObjectRetentionInput{ \n  Bucket: aws.String(bucket), \n  Key:    aws.String(key), \n  Retention: &types.ObjectLockRetention{ \n   Mode:            retentionMode, \n   RetainUntilDate: aws.Time(time.Now().AddDate(0, 0, int(retentionPeriodDays))), \n  }, \n  BypassGovernanceRetention: aws.Bool(true), \n } \n _, err := actor.S3Client.PutObjectRetention(ctx, input) \n if err != nil { \n  var noKey *types.NoSuchKey \n  if errors.As(err, &noKey) { \n   log.Printf(\"Object %s does not exist in bucket %s.\\n\", key, bucket) \n   err = noKey \n  } \n } \n return err\n}\n// UploadObject uses the S3 upload manager to upload an object to a bucket.\nfunc (actor S3Actions) UploadObject(ctx context.Context, bucket string, key \n string, contents string) (string, error) { \nScenarios API Version 2006-03-01 2401Amazon Simple Storage Service API Reference\n var outKey string \n input := &s3.PutObjectInput{ \n  Bucket:            aws.String(bucket), \n  Key:               aws.String(key), \n  Body:              bytes.NewReader([]byte(contents)), \n  ChecksumAlgorithm: types.ChecksumAlgorithmSha256, \n } \n output, err := actor.S3Manager.Upload(ctx, input) \n if err != nil { \n  var noBucket *types.NoSuchBucket \n  if errors.As(err, &noBucket) { \n   log.Printf(\"Bucket %s does not exist.\\n\", bucket) \n   err = noBucket \n  } \n } else { \n  err := s3.NewObjectExistsWaiter(actor.S3Client).Wait(ctx, &s3.HeadObjectInput{ \n   Bucket: aws.String(bucket), \n   Key:    aws.String(key), \n  }, time.Minute) \n  if err != nil { \n   log.Printf(\"Failed attempt to wait for object %s to exist in %s.\\n\", key, \n bucket) \n  } else { \n   outKey = *output.Key \n  } \n } \n return outKey, err\n}\n// ListObjectVersions lists all versions of all objects in a bucket.\nfunc (actor S3Actions) ListObjectVersions(ctx context.Context, bucket string) \n ([]types.ObjectVersion, error) { \n var err error \n var output *s3.ListObjectVersionsOutput \n var versions []types.ObjectVersion \n input := &s3.ListObjectVersionsInput{Bucket: aws.String(bucket)} \n versionPaginator := s3.NewListObjectVersionsPaginator(actor.S3Client, input) \n for versionPaginator.HasMorePages() { \n  output, err = versionPaginator.NextPage(ctx) \n  if err != nil { \n   var noBucket *types.NoSuchBucket \n   if errors.As(err, &noBucket) { \nScenarios API Version 2006-03-01 2402Amazon Simple Storage Service API Reference\n    log.Printf(\"Bucket %s does not exist.\\n\", bucket) \n    err = noBucket \n   } \n   break \n  } else { \n   versions = append(versions, output.Versions...) \n  } \n } \n return versions, err\n}\n// DeleteObject deletes an object from a bucket.\nfunc (actor S3Actions) DeleteObject(ctx context.Context, bucket string, key \n string, versionId string, bypassGovernance bool) (bool, error) { \n deleted := false \n input := &s3.DeleteObjectInput{ \n  Bucket: aws.String(bucket), \n  Key:    aws.String(key), \n } \n if versionId != \"\" { \n  input.VersionId = aws.String(versionId) \n } \n if bypassGovernance { \n  input.BypassGovernanceRetention = aws.Bool(true) \n } \n _, err := actor.S3Client.DeleteObject(ctx, input) \n if err != nil { \n  var noKey *types.NoSuchKey \n  var apiErr *smithy.GenericAPIError \n  if errors.As(err, &noKey) { \n   log.Printf(\"Object %s does not exist in %s.\\n\", key, bucket) \n   err = noKey \n  } else if errors.As(err, &apiErr) { \n   switch apiErr.ErrorCode() { \n   case \"AccessDenied\": \n    log.Printf(\"Access denied: cannot delete object %s from %s.\\n\", key, bucket) \n    err = nil \n   case \"InvalidArgument\": \n    if bypassGovernance { \n     log.Printf(\"You cannot specify bypass governance on a bucket without lock \n enabled.\") \n     err = nil \nScenarios API Version 2006-03-01 2403Amazon Simple Storage Service API Reference\n    } \n   } \n  } \n } else { \n  deleted = true \n } \n return deleted, err\n}\n// DeleteObjects deletes a list of objects from a bucket.\nfunc (actor S3Actions) DeleteObjects(ctx context.Context, bucket string, objects \n []types.ObjectIdentifier, bypassGovernance bool) error { \n if len(objects) == 0 { \n  return nil \n } \n input := s3.DeleteObjectsInput{ \n  Bucket: aws.String(bucket), \n  Delete: &types.Delete{ \n   Objects: objects, \n   Quiet:   aws.Bool(true), \n  }, \n } \n if bypassGovernance { \n  input.BypassGovernanceRetention = aws.Bool(true) \n } \n delOut, err := actor.S3Client.DeleteObjects(ctx, &input) \n if err != nil || len(delOut.Errors) > 0 { \n  log.Printf(\"Error deleting objects from bucket %s.\\n\", bucket) \n  if err != nil { \n   var noBucket *types.NoSuchBucket \n   if errors.As(err, &noBucket) { \n    log.Printf(\"Bucket %s does not exist.\\n\", bucket) \n    err = noBucket \n   } \n  } else if len(delOut.Errors) > 0 { \n   for _, outErr := range delOut.Errors { \n    log.Printf(\"%s: %s\\n\", *outErr.Key, *outErr.Message) \n   } \n   err = fmt.Errorf(\"%s\", *delOut.Errors[0].Message) \n  } \n } \nScenarios API Version 2006-03-01 2404Amazon Simple Storage Service API Reference\n return err\n}\nClean up resources.\n// DemoBucket contains metadata for buckets used in this example.\ntype DemoBucket struct { \n name             string \n retentionEnabled bool \n objectKeys       []string\n}\n// Resources keeps track of AWS resources created during the ObjectLockScenario \n and handles\n// cleanup when the scenario finishes.\ntype Resources struct { \n demoBuckets map[string]*DemoBucket \n s3Actions  *actions.S3Actions \n questioner demotools.IQuestioner\n}\n// init initializes objects in the Resources struct.\nfunc (resources *Resources) init(s3Actions *actions.S3Actions, questioner \n demotools.IQuestioner) { \n resources.s3Actions = s3Actions \n resources.questioner = questioner \n resources.demoBuckets = map[string]*DemoBucket{}\n}\n// Cleanup deletes all AWS resources created during the ObjectLockScenario.\nfunc (resources *Resources) Cleanup(ctx context.Context) { \n defer func() { \n  if r := recover(); r != nil { \n   log.Printf(\"Something went wrong during cleanup.\\n%v\\n\", r) \n   log.Println(\"Use the AWS Management Console to remove any remaining resources \n \" + \n    \"that were created for this scenario.\") \n  } \nScenarios API Version 2006-03-01 2405Amazon Simple Storage Service API Reference\n }() \n wantDelete := resources.questioner.AskBool(\"Do you want to remove all of the AWS \n resources that were created \"+ \n  \"during this demo (y/n)?\", \"y\") \n if !wantDelete { \n  log.Println(\"Be sure to remove resources when you're done with them to avoid \n unexpected charges!\") \n  return \n } \n log.Println(\"Removing objects from S3 buckets and deleting buckets...\") \n resources.deleteBuckets(ctx) \n //resources.deleteRetentionObjects(resources.retentionBucket, \n resources.retentionObjects) \n log.Println(\"Cleanup complete.\")\n}\n// deleteBuckets empties and then deletes all buckets created during the \n ObjectLockScenario.\nfunc (resources *Resources) deleteBuckets(ctx context.Context) { \n for _, info := range createInfo { \n  bucket := resources.demoBuckets[info.name] \n  resources.deleteObjects(ctx, bucket) \n  _, err := resources.s3Actions.S3Client.DeleteBucket(ctx, &s3.DeleteBucketInput{ \n   Bucket: aws.String(bucket.name), \n  }) \n  if err != nil { \n   panic(err) \n  } \n } \n resources.demoBuckets = map[string]*DemoBucket{}\n}\n// deleteObjects deletes all objects in the specified bucket.\nfunc (resources *Resources) deleteObjects(ctx context.Context, bucket \n *DemoBucket) { \n lockConfig, err := resources.s3Actions.GetObjectLockConfiguration(ctx, \n bucket.name) \n if err != nil { \n  panic(err) \n } \n versions, err := resources.s3Actions.ListObjectVersions(ctx, bucket.name) \nScenarios API Version 2006-03-01 2406Amazon Simple Storage Service API Reference\n if err != nil { \n  switch err.(type) { \n  case *types.NoSuchBucket: \n   log.Printf(\"No objects to get from %s.\\n\", bucket.name) \n  default: \n   panic(err) \n  } \n } \n delObjects := make([]types.ObjectIdentifier, len(versions)) \n for i, version := range versions { \n  if lockConfig != nil && lockConfig.ObjectLockEnabled == \n types.ObjectLockEnabledEnabled { \n   status, err := resources.s3Actions.GetObjectLegalHold(ctx, bucket.name, \n *version.Key, *version.VersionId) \n   if err != nil { \n    switch err.(type) { \n    case *types.NoSuchKey: \n     log.Printf(\"Couldn't determine legal hold status for %s in %s.\\n\", \n *version.Key, bucket.name) \n    default: \n     panic(err) \n    } \n   } else if status != nil && *status == types.ObjectLockLegalHoldStatusOn { \n    err = resources.s3Actions.PutObjectLegalHold(ctx, bucket.name, *version.Key, \n *version.VersionId, types.ObjectLockLegalHoldStatusOff) \n    if err != nil { \n     switch err.(type) { \n     case *types.NoSuchKey: \n      log.Printf(\"Couldn't turn off legal hold for %s in %s.\\n\", *version.Key, \n bucket.name) \n     default: \n      panic(err) \n     } \n    } \n   } \n  } \n  delObjects[i] = types.ObjectIdentifier{Key: version.Key, VersionId: \n version.VersionId} \n } \n err = resources.s3Actions.DeleteObjects(ctx, bucket.name, delObjects, \n bucket.retentionEnabled) \n if err != nil { \n  switch err.(type) { \n  case *types.NoSuchBucket: \nScenarios API Version 2006-03-01 2407Amazon Simple Storage Service API Reference\n   log.Println(\"Nothing to delete.\") \n  default: \n   panic(err) \n  } \n }\n}\n\u2022For API details, see the following topics in AWS SDK for Go API Reference.\n\u2022GetObjectLegalHold\n\u2022GetObjectLockCon\ufb01guration\n\u2022GetObjectRetention\n\u2022PutObjectLegalHold\n\u2022PutObjectLockCon\ufb01guration\n\u2022PutObjectRetention\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nRun an interactive scenario demonstrating Amazon S3 object lock features.\nimport software.amazon.awssdk.services.s3.model.ObjectLockLegalHold;\nimport software.amazon.awssdk.services.s3.model.ObjectLockRetention;\nimport java.io.BufferedWriter;\nimport java.io.IOException;\nimport java.util.ArrayList;\nimport java.util.List;\nimport java.util.Scanner;\nimport java.util.stream.Collectors;\n/* \nScenarios API Version 2006-03-01 2408Amazon Simple Storage Service API Reference\n Before running this Java V2 code example, set up your development \n environment, including your credentials. \n For more information, see the following documentation topic: \n https://docs.aws.amazon.com/sdk-for-java/latest/developer-guide/setup.html \n This Java example performs the following tasks: \n    1.", "Create test Amazon Simple Storage Service (S3) buckets with different lock \n policies.", "\n    2.", "Upload sample objects to each bucket.", "\n    3.", "Set some Legal Hold and Retention Periods on objects and buckets.", "\n    4.", "Investigate lock policies by viewing settings or attempting to delete or \n overwrite objects.", "\n    5.", "Clean up objects and buckets.", "\n */\npublic class S3ObjectLockWorkflow { \n    public static final String DASHES = new String(new char[80]).replace(\"\\0\", \n \"-\"); \n    static String bucketName; \n    static S3LockActions s3LockActions; \n    private static final List<String> bucketNames = new ArrayList<>(); \n    private static final List<String> fileNames = new ArrayList<>(); \n    public static void main(String[] args) { \n        final String usage = \"\"\" \n            Usage: \n                <bucketName> \\s \n            Where: \n                bucketName - The Amazon S3 bucket name. \n           \"\"\"; \n        if (args.length != 1) { \n            System.out.println(usage); \n            System.exit(1); \n        } \n        s3LockActions = new S3LockActions(); \n        bucketName = args[0]; \n        Scanner scanner = new Scanner(System.in); \n        System.out.println(DASHES); \n        System.out.println(\"Welcome to the Amazon Simple Storage Service (S3) \n Object Locking Workflow Scenario.\"); \nScenarios API Version 2006-03-01 2409Amazon Simple Storage Service API Reference\n        System.out.println(\"Press Enter to continue...\"); \n        scanner.nextLine(); \n        configurationSetup(); \n        System.out.println(DASHES); \n        System.out.println(DASHES); \n        setup(); \n        System.out.println(\"Setup is complete.", "Press Enter to continue...\"); \n        scanner.nextLine(); \n        System.out.println(DASHES); \n        System.out.println(DASHES); \n        System.out.println(\"Lets present the user with choices.\"); \n        System.out.println(\"Press Enter to continue...\"); \n        scanner.nextLine(); \n        demoActionChoices() ; \n        System.out.println(DASHES); \n        System.out.println(DASHES); \n        System.out.println(\"Would you like to clean up the resources? (y/n)\"); \n        String delAns = scanner.nextLine().trim(); \n        if (delAns.equalsIgnoreCase(\"y\")) { \n            cleanup(); \n            System.out.println(\"Clean up is complete.\"); \n        } \n        System.out.println(\"Press Enter to continue...\"); \n        scanner.nextLine(); \n        System.out.println(DASHES); \n        System.out.println(DASHES); \n        System.out.println(\"Amazon S3 Object Locking Workflow is complete.\"); \n        System.out.println(DASHES); \n    } \n    // Present the user with the demo action choices. \n    public static void demoActionChoices() { \n        String[] choices = { \n            \"List all files in buckets.\", \n            \"Attempt to delete a file.\", \n            \"Attempt to delete a file with retention period bypass.\", \n            \"Attempt to overwrite a file.\", \n            \"View the object and bucket retention settings for a file.\", \n            \"View the legal hold settings for a file.\", \nScenarios API Version 2006-03-01 2410Amazon Simple Storage Service API Reference\n            \"Finish the workflow.\" \n        }; \n        int choice = 0; \n        while (true) { \n            System.out.println(DASHES); \n            choice = getChoiceResponse(\"Explore the S3 locking features by \n selecting one of the following choices:\", choices); \n            System.out.println(DASHES); \n            System.out.println(\"You selected \"+choices[choice]); \n            switch (choice) { \n                case 0 -> { \n                    s3LockActions.listBucketsAndObjects(bucketNames, true); \n                } \n                case 1 -> { \n                    System.out.println(\"Enter the number of the object to \n delete:\"); \n                    List<S3InfoObject> allFiles = \n s3LockActions.listBucketsAndObjects(bucketNames, true); \n                    List<String> fileKeys = allFiles.stream().map(f -> \n f.getKeyName()).collect(Collectors.toList()); \n                    String[] fileKeysArray = fileKeys.toArray(new String[0]); \n                    int fileChoice = getChoiceResponse(null, fileKeysArray); \n                    String objectKey = fileKeys.get(fileChoice); \n                    String bucketName = allFiles.get(fileChoice).getBucketName(); \n                    String version = allFiles.get(fileChoice).getVersion(); \n                    s3LockActions.deleteObjectFromBucket(bucketName, objectKey, \n false, version); \n                } \n                case 2 -> { \n                    System.out.println(\"Enter the number of the object to \n delete:\"); \n                    List<S3InfoObject> allFiles = \n s3LockActions.listBucketsAndObjects(bucketNames, true); \n                    List<String> fileKeys = allFiles.stream().map(f -> \n f.getKeyName()).collect(Collectors.toList()); \n                    String[] fileKeysArray = fileKeys.toArray(new String[0]); \n                    int fileChoice = getChoiceResponse(null, fileKeysArray); \n                    String objectKey = fileKeys.get(fileChoice); \n                    String bucketName = allFiles.get(fileChoice).getBucketName(); \n                    String version = allFiles.get(fileChoice).getVersion(); \nScenarios API Version 2006-03-01 2411Amazon Simple Storage Service API Reference\n                    s3LockActions.deleteObjectFromBucket(bucketName, objectKey, \n true, version); \n                } \n                case 3 -> { \n                    System.out.println(\"Enter the number of the object to \n overwrite:\"); \n                    List<S3InfoObject> allFiles = \n s3LockActions.listBucketsAndObjects(bucketNames, true); \n                    List<String> fileKeys = allFiles.stream().map(f -> \n f.getKeyName()).collect(Collectors.toList()); \n                    String[] fileKeysArray = fileKeys.toArray(new String[0]); \n                    int fileChoice = getChoiceResponse(null, fileKeysArray); \n                    String objectKey = fileKeys.get(fileChoice); \n                    String bucketName = allFiles.get(fileChoice).getBucketName(); \n                    // Attempt to overwrite the file. \n                    try (BufferedWriter writer = new BufferedWriter(new \n java.io.FileWriter(objectKey))) { \n                        writer.write(\"This is a modified text.\"); \n                    } catch (IOException e) { \n                        e.printStackTrace(); \n                    } \n                    s3LockActions.uploadFile(bucketName, objectKey, objectKey); \n                } \n                case 4 -> { \n                    System.out.println(\"Enter the number of the object to \n overwrite:\"); \n                    List<S3InfoObject> allFiles = \n s3LockActions.listBucketsAndObjects(bucketNames, true); \n                    List<String> fileKeys = allFiles.stream().map(f -> \n f.getKeyName()).collect(Collectors.toList()); \n                    String[] fileKeysArray = fileKeys.toArray(new String[0]); \n                    int fileChoice = getChoiceResponse(null, fileKeysArray); \n                    String objectKey = fileKeys.get(fileChoice); \n                    String bucketName = allFiles.get(fileChoice).getBucketName(); \n                    s3LockActions.getObjectRetention(bucketName, objectKey); \n                } \n                case 5 -> { \n                    System.out.println(\"Enter the number of the object to \n view:\"); \nScenarios API Version 2006-03-01 2412Amazon Simple Storage Service API Reference\n                    List<S3InfoObject> allFiles = \n s3LockActions.listBucketsAndObjects(bucketNames, true); \n                    List<String> fileKeys = allFiles.stream().map(f -> \n f.getKeyName()).collect(Collectors.toList()); \n                    String[] fileKeysArray = fileKeys.toArray(new String[0]); \n                    int fileChoice = getChoiceResponse(null, fileKeysArray); \n                    String objectKey = fileKeys.get(fileChoice); \n                    String bucketName = allFiles.get(fileChoice).getBucketName(); \n                    s3LockActions.getObjectLegalHold(bucketName, objectKey); \n                    s3LockActions.getBucketObjectLockConfiguration(bucketName); \n                } \n                case 6 -> { \n                    System.out.println(\"Exiting the workflow...\"); \n                    return; \n                } \n                default -> { \n                    System.out.println(\"Invalid choice.", "Please select again.\"); \n                } \n            } \n        } \n    } \n    // Clean up the resources from the scenario.", "\n    private static void cleanup() { \n        List<S3InfoObject> allFiles = \n s3LockActions.listBucketsAndObjects(bucketNames, false); \n        for (S3InfoObject fileInfo : allFiles) { \n            String bucketName = fileInfo.getBucketName(); \n            String key = fileInfo.getKeyName(); \n            String version = fileInfo.getVersion(); \n            if (bucketName.contains(\"lock-enabled\") || \n (bucketName.contains(\"retention-after-creation\"))) { \n                ObjectLockLegalHold legalHold = \n s3LockActions.getObjectLegalHold(bucketName, key); \n                if (legalHold != null) { \n                    String holdStatus = legalHold.status().name(); \n                    System.out.println(holdStatus); \n                    if (holdStatus.compareTo(\"ON\") == 0) { \n                        s3LockActions.modifyObjectLegalHold(bucketName, key, \n false); \n                    } \n                } \nScenarios API Version 2006-03-01 2413Amazon Simple Storage Service API Reference\n                // Check for a retention period. \n                ObjectLockRetention retention = \n s3LockActions.getObjectRetention(bucketName, key); \n                boolean hasRetentionPeriod ; \n                hasRetentionPeriod = retention != null; \n                s3LockActions.deleteObjectFromBucket(bucketName, \n key,hasRetentionPeriod, version); \n            } else { \n                System.out.println(bucketName +\" objects do not have a legal \n lock\"); \n                s3LockActions.deleteObjectFromBucket(bucketName, key,false, \n version); \n            } \n        } \n        // Delete the buckets. \n        System.out.println(\"Delete \"+bucketName); \n        for (String bucket : bucketNames){ \n            s3LockActions.deleteBucketByName(bucket); \n        } \n    } \n    private static void setup() { \n        Scanner scanner = new Scanner(System.in); \n        System.out.println(\"\"\" \n                For this workflow, we will use the AWS SDK for Java to create \n several S3 \n                buckets and files to demonstrate working with S3 locking \n features. \n                \"\"\"); \n        System.out.println(\"S3 buckets can be created either with or without \n object lock enabled.\"); \n        System.out.println(\"Press Enter to continue...\"); \n        scanner.nextLine(); \n        // Create three S3 buckets. \n        s3LockActions.createBucketWithLockOptions(false, bucketNames.get(0)); \n        s3LockActions.createBucketWithLockOptions(true, bucketNames.get(1)); \n        s3LockActions.createBucketWithLockOptions(false, bucketNames.get(2)); \n        System.out.println(\"Press Enter to continue.\"); \n        scanner.nextLine(); \nScenarios API Version 2006-03-01 2414Amazon Simple Storage Service API Reference\n        System.out.println(\"Bucket \"+bucketNames.get(2) +\" will be configured to \n use object locking with a default retention period.\"); \n        s3LockActions.modifyBucketDefaultRetention(bucketNames.get(2)); \n        System.out.println(\"Press Enter to continue.\"); \n        scanner.nextLine(); \n        System.out.println(\"Object lock policies can also be added to existing \n buckets. For this example, we will use \"+bucketNames.get(1)); \n        s3LockActions.enableObjectLockOnBucket(bucketNames.get(1)); \n        System.out.println(\"Press Enter to continue.\"); \n        scanner.nextLine(); \n        // Upload some files to the buckets.", "\n        System.out.println(\"Now let's add some test files:\"); \n        String fileName = \"exampleFile.txt\"; \n        int fileCount = 2; \n        try (BufferedWriter writer = new BufferedWriter(new \n java.io.FileWriter(fileName))) { \n            writer.write(\"This is a sample file for uploading to a bucket.\"); \n        } catch (IOException e) { \n            e.printStackTrace(); \n        } \n        for (String bucketName : bucketNames){ \n            for (int i = 0; i < fileCount; i++) { \n                // Get the file name without extension. \n                String fileNameWithoutExtension = \n java.nio.file.Paths.get(fileName).getFileName().toString(); \n                int extensionIndex = fileNameWithoutExtension.lastIndexOf('.'); \n                if (extensionIndex > 0) { \n                    fileNameWithoutExtension = \n fileNameWithoutExtension.substring(0, extensionIndex); \n                } \n                // Create the numbered file names.", "\n                String numberedFileName = fileNameWithoutExtension + i + \n getFileExtension(fileName); \n                fileNames.add(numberedFileName); \n                s3LockActions.uploadFile(bucketName, numberedFileName, fileName); \n            } \n        } \n        String question = null; \nScenarios API Version 2006-03-01 2415Amazon Simple Storage Service API Reference\n        System.out.print(\"Press Enter to continue...\"); \n        scanner.nextLine(); \n        System.out.println(\"Now we can set some object lock policies on \n individual files:\"); \n        for (String bucketName : bucketNames) { \n            for (int i = 0; i < fileNames.size(); i++){ \n                // No modifications to the objects in the first bucket. \n                if (!bucketName.equals(bucketNames.get(0))) { \n                    String exampleFileName = fileNames.get(i); \n                    switch (i) { \n                        case 0 -> { \n                            question = \"Would you like to add a legal hold to \" + \n exampleFileName + \" in \" + bucketName + \" (y/n)?\"; \n                            System.out.println(question); \n                            String ans = scanner.nextLine().trim(); \n                            if (ans.equalsIgnoreCase(\"y\")) { \n                                System.out.println(\"**** You have selected to put \n a legal hold \" + exampleFileName); \n                                // Set a legal hold.", "\n                                s3LockActions.modifyObjectLegalHold(bucketName, \n exampleFileName, true); \n                            } \n                        } \n                        case 1 -> { \n                            \"\"\" \n                                Would you like to add a 1 day Governance \n retention period to %s in %s (y/n)? \n                                Reminder: Only a user with the \n s3:BypassGovernanceRetention permission will be able to delete this file or its \n bucket until the retention period has expired. \n                                \"\"\".formatted(exampleFileName, bucketName); \n                            System.out.println(question); \n                            String ans2 = scanner.nextLine().trim(); \n                            if (ans2.equalsIgnoreCase(\"y\")) { \n                                \n s3LockActions.modifyObjectRetentionPeriod(bucketName, exampleFileName); \n                            } \n                        } \n                    } \n                } \n            } \n        } \nScenarios API Version 2006-03-01 2416Amazon Simple Storage Service API Reference\n    } \n    // Get file extension. \n    private static String getFileExtension(String fileName) { \n        int dotIndex = fileName.lastIndexOf('.'); \n        if (dotIndex > 0) { \n            return fileName.substring(dotIndex); \n        } \n        return \"\"; \n    } \n    public static void configurationSetup() { \n        String noLockBucketName = bucketName + \"-no-lock\"; \n        String lockEnabledBucketName = bucketName + \"-lock-enabled\"; \n        String retentionAfterCreationBucketName = bucketName + \"-retention-after-\ncreation\"; \n        bucketNames.add(noLockBucketName); \n        bucketNames.add(lockEnabledBucketName); \n        bucketNames.add(retentionAfterCreationBucketName); \n    } \n    public static int getChoiceResponse(String question, String[] choices) { \n        Scanner scanner = new Scanner(System.in); \n        if (question != null) { \n            System.out.println(question); \n            for (int i = 0; i < choices.length; i++) { \n                System.out.println(\"\\t\" + (i + 1) + \".", "\" + choices[i]); \n            } \n        } \n        int choiceNumber = 0; \n        while (choiceNumber < 1 || choiceNumber > choices.length) { \n            String choice = scanner.nextLine(); \n            try { \n                choiceNumber = Integer.parseInt(choice); \n            } catch (NumberFormatException e) { \n                System.out.println(\"Invalid choice.", "Please enter a valid \n number.\"); \n            } \n        } \n        return choiceNumber - 1; \n    }\n}\nScenarios API Version 2006-03-01 2417Amazon Simple Storage Service API Reference\nA wrapper class for S3 functions.\nimport software.amazon.awssdk.regions.Region;\nimport software.amazon.awssdk.services.s3.S3Client;\nimport software.amazon.awssdk.services.s3.model.BucketVersioningStatus;\nimport software.amazon.awssdk.services.s3.model.ChecksumAlgorithm;\nimport software.amazon.awssdk.services.s3.model.CreateBucketRequest;\nimport software.amazon.awssdk.services.s3.model.DefaultRetention;\nimport software.amazon.awssdk.services.s3.model.DeleteBucketRequest;\nimport software.amazon.awssdk.services.s3.model.DeleteObjectRequest;\nimport software.amazon.awssdk.services.s3.model.GetObjectLegalHoldRequest;\nimport software.amazon.awssdk.services.s3.model.GetObjectLegalHoldResponse;\nimport \n software.amazon.awssdk.services.s3.model.GetObjectLockConfigurationRequest;\nimport \n software.amazon.awssdk.services.s3.model.GetObjectLockConfigurationResponse;\nimport software.amazon.awssdk.services.s3.model.GetObjectRetentionRequest;\nimport software.amazon.awssdk.services.s3.model.GetObjectRetentionResponse;\nimport software.amazon.awssdk.services.s3.model.HeadBucketRequest;\nimport software.amazon.awssdk.services.s3.model.ListObjectVersionsRequest;\nimport software.amazon.awssdk.services.s3.model.ListObjectVersionsResponse;\nimport software.amazon.awssdk.services.s3.model.MFADelete;\nimport software.amazon.awssdk.services.s3.model.ObjectLockConfiguration;\nimport software.amazon.awssdk.services.s3.model.ObjectLockEnabled;\nimport software.amazon.awssdk.services.s3.model.ObjectLockLegalHold;\nimport software.amazon.awssdk.services.s3.model.ObjectLockLegalHoldStatus;\nimport software.amazon.awssdk.services.s3.model.ObjectLockRetention;\nimport software.amazon.awssdk.services.s3.model.ObjectLockRetentionMode;\nimport software.amazon.awssdk.services.s3.model.ObjectLockRule;\nimport software.amazon.awssdk.services.s3.model.PutBucketVersioningRequest;\nimport software.amazon.awssdk.services.s3.model.PutObjectLegalHoldRequest;\nimport \n software.amazon.awssdk.services.s3.model.PutObjectLockConfigurationRequest;\nimport software.amazon.awssdk.services.s3.model.PutObjectRequest;\nimport software.amazon.awssdk.services.s3.model.PutObjectResponse;\nimport software.amazon.awssdk.services.s3.model.PutObjectRetentionRequest;\nimport software.amazon.awssdk.services.s3.model.S3Exception;\nimport software.amazon.awssdk.services.s3.model.VersioningConfiguration;\nimport software.amazon.awssdk.services.s3.waiters.S3Waiter;\nimport java.nio.file.Path;\nimport java.nio.file.Paths;\nScenarios API Version 2006-03-01 2418Amazon Simple Storage Service API Reference\nimport java.time.Instant;\nimport java.time.ZoneId;\nimport java.time.ZonedDateTime;\nimport java.time.format.DateTimeFormatter;\nimport java.time.temporal.ChronoUnit;\nimport java.util.List;\nimport java.util.concurrent.atomic.AtomicInteger;\nimport java.util.stream.Collectors;\n// Contains application logic for the Amazon S3 operations used in this workflow.\npublic class S3LockActions { \n    private static S3Client getClient() { \n        return S3Client.builder() \n            .region(Region.US_EAST_1) \n            .build(); \n    } \n    // Set or modify a retention period on an object in an S3 bucket.", "\n    public void modifyObjectRetentionPeriod(String bucketName, String objectKey) \n { \n        // Calculate the instant one day from now.", "\n        Instant futureInstant = Instant.now().plus(1, ChronoUnit.DAYS); \n        // Convert the Instant to a ZonedDateTime object with a specific time \n zone.", "\n        ZonedDateTime zonedDateTime = \n futureInstant.atZone(ZoneId.systemDefault()); \n        // Define a formatter for human-readable output. \n        DateTimeFormatter formatter = DateTimeFormatter.ofPattern(\"yyyy-MM-dd \n HH:mm:ss\"); \n        // Format the ZonedDateTime object to a human-readable date string. \n        String humanReadableDate = formatter.format(zonedDateTime); \n        // Print the formatted date string.", "\n        System.out.println(\"Formatted Date: \" + humanReadableDate); \n        ObjectLockRetention retention = ObjectLockRetention.builder() \n            .mode(ObjectLockRetentionMode.GOVERNANCE) \n            .retainUntilDate(futureInstant) \n            .build(); \nScenarios API Version 2006-03-01 2419Amazon Simple Storage Service API Reference\n        PutObjectRetentionRequest retentionRequest = \n PutObjectRetentionRequest.builder() \n            .bucket(bucketName) \n            .key(objectKey) \n            .retention(retention) \n            .build(); \n        getClient().putObjectRetention(retentionRequest); \n        System.out.println(\"Set retention for \"+objectKey +\" in \" +bucketName +\" \n until \"+ humanReadableDate +\".\"); \n    } \n    // Get the legal hold details for an S3 object. \n    public ObjectLockLegalHold getObjectLegalHold(String bucketName, String \n objectKey) { \n        try { \n            GetObjectLegalHoldRequest legalHoldRequest = \n GetObjectLegalHoldRequest.builder() \n                .bucket(bucketName) \n                .key(objectKey) \n                .build(); \n            GetObjectLegalHoldResponse response = \n getClient().getObjectLegalHold(legalHoldRequest); \n            System.out.println(\"Object legal hold for \" + objectKey + \" in \" + \n bucketName + \n                \":\\n\\tStatus: \" + response.legalHold().status()); \n            return response.legalHold(); \n        } catch (S3Exception ex) { \n            System.out.println(\"\\tUnable to fetch legal hold: '\" + \n ex.getMessage() + \"'\"); \n        } \n        return null; \n    } \n    // Create a new Amazon S3 bucket with object lock options. \n    public void createBucketWithLockOptions(boolean enableObjectLock, String \n bucketName) { \n        S3Waiter s3Waiter = getClient().waiter(); \n        CreateBucketRequest bucketRequest = CreateBucketRequest.builder() \n            .bucket(bucketName) \n            .objectLockEnabledForBucket(enableObjectLock) \nScenarios API Version 2006-03-01 2420Amazon Simple Storage Service API Reference\n            .build(); \n        getClient().createBucket(bucketRequest); \n        HeadBucketRequest bucketRequestWait = HeadBucketRequest.builder() \n            .bucket(bucketName) \n            .build(); \n        // Wait until the bucket is created and print out the response. \n        s3Waiter.waitUntilBucketExists(bucketRequestWait); \n        System.out.println(bucketName + \" is ready\"); \n    } \n    public List<S3InfoObject> listBucketsAndObjects(List<String> bucketNames, \n Boolean interactive) { \n        AtomicInteger counter = new AtomicInteger(0); // Initialize counter. \n        return bucketNames.stream() \n            .flatMap(bucketName -> \n listBucketObjectsAndVersions(bucketName).versions().stream() \n                .map(version -> { \n                    S3InfoObject s3InfoObject = new S3InfoObject(); \n                    s3InfoObject.setBucketName(bucketName); \n                    s3InfoObject.setVersion(version.versionId()); \n                    s3InfoObject.setKeyName(version.key()); \n                    return s3InfoObject; \n                })) \n            .peek(s3InfoObject -> { \n                int i = counter.incrementAndGet(); // Increment and get the \n updated value. \n                if (interactive) { \n                    System.out.println(i + \": \"+ s3InfoObject.getKeyName()); \n                    System.out.printf(\"%5s Bucket name: %s\\n\", \"\", \n s3InfoObject.getBucketName()); \n                    System.out.printf(\"%5s Version: %s\\n\", \"\", \n s3InfoObject.getVersion()); \n                } \n            }) \n            .collect(Collectors.toList()); \n    } \n    public ListObjectVersionsResponse listBucketObjectsAndVersions(String \n bucketName) { \n        ListObjectVersionsRequest versionsRequest = \n ListObjectVersionsRequest.builder() \n            .bucket(bucketName) \nScenarios API Version 2006-03-01 2421Amazon Simple Storage Service API Reference\n            .build(); \n        return getClient().listObjectVersions(versionsRequest); \n    } \n    // Set or modify a retention period on an S3 bucket. \n    public void modifyBucketDefaultRetention(String bucketName) { \n        VersioningConfiguration versioningConfiguration = \n VersioningConfiguration.builder() \n            .mfaDelete(MFADelete.DISABLED) \n            .status(BucketVersioningStatus.ENABLED) \n            .build(); \n        PutBucketVersioningRequest versioningRequest = \n PutBucketVersioningRequest.builder() \n            .bucket(bucketName) \n            .versioningConfiguration(versioningConfiguration) \n            .build(); \n        getClient().putBucketVersioning(versioningRequest); \n        DefaultRetention rention = DefaultRetention.builder() \n            .days(1) \n            .mode(ObjectLockRetentionMode.GOVERNANCE) \n            .build(); \n        ObjectLockRule lockRule = ObjectLockRule.builder() \n            .defaultRetention(rention) \n            .build(); \n        ObjectLockConfiguration objectLockConfiguration = \n ObjectLockConfiguration.builder() \n            .objectLockEnabled(ObjectLockEnabled.ENABLED) \n            .rule(lockRule) \n            .build(); \n        PutObjectLockConfigurationRequest putObjectLockConfigurationRequest = \n PutObjectLockConfigurationRequest.builder() \n            .bucket(bucketName) \n            .objectLockConfiguration(objectLockConfiguration) \n            .build(); \n        \n getClient().putObjectLockConfiguration(putObjectLockConfigurationRequest) ; \nScenarios API Version 2006-03-01 2422Amazon Simple Storage Service API Reference\n        System.out.println(\"Added a default retention to bucket \"+bucketName \n +\".\"); \n    } \n    // Enable object lock on an existing bucket. \n    public void enableObjectLockOnBucket(String bucketName) { \n        try { \n            VersioningConfiguration versioningConfiguration = \n VersioningConfiguration.builder() \n                .status(BucketVersioningStatus.ENABLED) \n                .build(); \n            PutBucketVersioningRequest putBucketVersioningRequest = \n PutBucketVersioningRequest.builder() \n                .bucket(bucketName) \n                .versioningConfiguration(versioningConfiguration) \n                .build(); \n            // Enable versioning on the bucket. \n            getClient().putBucketVersioning(putBucketVersioningRequest); \n            PutObjectLockConfigurationRequest request = \n PutObjectLockConfigurationRequest.builder() \n                .bucket(bucketName) \n                .objectLockConfiguration(ObjectLockConfiguration.builder() \n                    .objectLockEnabled(ObjectLockEnabled.ENABLED) \n                    .build()) \n                .build(); \n            getClient().putObjectLockConfiguration(request); \n            System.out.println(\"Successfully enabled object lock on \n \"+bucketName); \n        } catch (S3Exception ex) { \n            System.out.println(\"Error modifying object lock: '\" + ex.getMessage() \n + \"'\"); \n        } \n    } \n    public void uploadFile(String bucketName, String objectName, String filePath) \n { \n        Path file = Paths.get(filePath); \n        PutObjectRequest request = PutObjectRequest.builder() \n            .bucket(bucketName) \n            .key(objectName) \nScenarios API Version 2006-03-01 2423Amazon Simple Storage Service API Reference\n            .checksumAlgorithm(ChecksumAlgorithm.SHA256) \n            .build(); \n        PutObjectResponse response = getClient().putObject(request, file); \n        if (response != null) { \n            System.out.println(\"\\tSuccessfully uploaded \" + objectName + \" to \" + \n bucketName + \".\"); \n        } else { \n            System.out.println(\"\\tCould not upload \" + objectName + \" to \" + \n bucketName + \".\"); \n        } \n    } \n    // Set or modify a legal hold on an object in an S3 bucket. \n    public void modifyObjectLegalHold(String bucketName, String objectKey, \n boolean legalHoldOn) { \n        ObjectLockLegalHold legalHold ; \n        if (legalHoldOn) { \n            legalHold = ObjectLockLegalHold.builder() \n                .status(ObjectLockLegalHoldStatus.ON) \n                .build(); \n        } else { \n            legalHold = ObjectLockLegalHold.builder() \n                .status(ObjectLockLegalHoldStatus.OFF) \n                .build(); \n        } \n        PutObjectLegalHoldRequest legalHoldRequest = \n PutObjectLegalHoldRequest.builder() \n            .bucket(bucketName) \n            .key(objectKey) \n            .legalHold(legalHold) \n            .build(); \n        getClient().putObjectLegalHold(legalHoldRequest) ; \n        System.out.println(\"Modified legal hold for \"+ objectKey +\" in \n \"+bucketName +\".\"); \n    } \n    // Delete an object from a specific bucket. \n    public void deleteObjectFromBucket(String bucketName, String objectKey, \n boolean hasRetention, String versionId) { \n        try { \n            DeleteObjectRequest objectRequest; \nScenarios API Version 2006-03-01 2424Amazon Simple Storage Service API Reference\n            if (hasRetention) { \n                objectRequest = DeleteObjectRequest.builder() \n                    .bucket(bucketName) \n                    .key(objectKey) \n                    .versionId(versionId) \n                    .bypassGovernanceRetention(true) \n                    .build(); \n            } else { \n                objectRequest = DeleteObjectRequest.builder() \n                    .bucket(bucketName) \n                    .key(objectKey) \n                    .versionId(versionId) \n                    .build(); \n            } \n            getClient().deleteObject(objectRequest) ; \n            System.out.println(\"The object was successfully deleted\"); \n        } catch (S3Exception e) { \n            System.err.println(e.awsErrorDetails().errorMessage()); \n        } \n    } \n    // Get the retention period for an S3 object. \n    public ObjectLockRetention getObjectRetention(String bucketName, String key){ \n        try { \n            GetObjectRetentionRequest retentionRequest = \n GetObjectRetentionRequest.builder() \n                .bucket(bucketName) \n                .key(key) \n                .build(); \n            GetObjectRetentionResponse response = \n getClient().getObjectRetention(retentionRequest); \n            System.out.println(\"tObject retention for \"+key +\" \n in \"+ bucketName +\": \" + response.retention().mode() +\" until \"+ \n response.retention().retainUntilDate() +\".\"); \n            return response.retention(); \n        } catch (S3Exception e) { \n            System.err.println(e.awsErrorDetails().errorMessage()); \n            return null; \n        } \n    } \nScenarios API Version 2006-03-01 2425Amazon Simple Storage Service API Reference\n    public void deleteBucketByName(String bucketName) { \n        try { \n            DeleteBucketRequest request = DeleteBucketRequest.builder() \n                .bucket(bucketName) \n                .build(); \n            getClient().deleteBucket(request); \n            System.out.println(bucketName +\" was deleted.\"); \n        } catch (S3Exception e) { \n            System.err.println(e.awsErrorDetails().errorMessage()); \n        } \n    } \n    // Get the object lock configuration details for an S3 bucket.", "\n    public void getBucketObjectLockConfiguration(String bucketName) { \n        GetObjectLockConfigurationRequest objectLockConfigurationRequest = \n GetObjectLockConfigurationRequest.builder() \n            .bucket(bucketName) \n            .build(); \n        GetObjectLockConfigurationResponse response = \n getClient().getObjectLockConfiguration(objectLockConfigurationRequest); \n        System.out.println(\"Bucket object lock config for \"+bucketName +\":  \"); \n        System.out.println(\"\\tEnabled: \n \"+response.objectLockConfiguration().objectLockEnabled()); \n        System.out.println(\"\\tRule: \"+ \n response.objectLockConfiguration().rule().defaultRetention()); \n    }\n}\n\u2022For API details, see the following topics in AWS SDK for Java 2.x API Reference.\n\u2022GetObjectLegalHold\n\u2022GetObjectLockCon\ufb01guration\n\u2022GetObjectRetention\n\u2022PutObjectLegalHold\n\u2022PutObjectLockCon\ufb01guration\n\u2022PutObjectRetention\nScenarios API Version 2006-03-01 2426Amazon Simple Storage Service API Reference\nJavaScript\nSDK for JavaScript (v3)\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nindex.js - Entrypoint for the work\ufb02ow.", "This orchestrates all of the steps.", "Visit GitHub to see \nthe implementation details for Scenario, ScenarioInput, ScenarioOutput, and ScenarioAction.\nimport * as Scenarios from \"@aws-doc-sdk-examples/lib/scenario/index.js\";\nimport { \n  exitOnFalse, \n  loadState, \n  saveState,\n} from \"@aws-doc-sdk-examples/lib/scenario/steps-common.js\";\nimport { welcome, welcomeContinue } from \"./welcome.steps.js\";\nimport { \n  confirmCreateBuckets, \n  confirmPopulateBuckets, \n  confirmSetLegalHoldFileEnabled, \n  confirmSetLegalHoldFileRetention, \n  confirmSetRetentionPeriodFileEnabled, \n  confirmSetRetentionPeriodFileRetention, \n  confirmUpdateLockPolicy, \n  confirmUpdateRetention, \n  createBuckets, \n  createBucketsAction, \n  getBucketPrefix, \n  populateBuckets, \n  populateBucketsAction, \n  setLegalHoldFileEnabledAction, \n  setLegalHoldFileRetentionAction, \n  setRetentionPeriodFileEnabledAction, \n  setRetentionPeriodFileRetentionAction, \n  updateLockPolicy, \n  updateLockPolicyAction, \n  updateRetention, \nScenarios API Version 2006-03-01 2427Amazon Simple Storage Service API Reference\n  updateRetentionAction,\n} from \"./setup.steps.js\";\n/** \n * @param {Scenarios} scenarios \n * @param {Record<string, any>} initialState \n */\nexport const getWorkflowStages = (scenarios, initialState = {}) => { \n  const client = new S3Client({}); \n  return { \n    deploy: new scenarios.Scenario( \n      \"S3 Object Locking - Deploy\", \n      [ \n        welcome(scenarios), \n        welcomeContinue(scenarios), \n        exitOnFalse(scenarios, \"welcomeContinue\"), \n        getBucketPrefix(scenarios), \n        createBuckets(scenarios), \n        confirmCreateBuckets(scenarios), \n        exitOnFalse(scenarios, \"confirmCreateBuckets\"), \n        createBucketsAction(scenarios, client), \n        updateRetention(scenarios), \n        confirmUpdateRetention(scenarios), \n        exitOnFalse(scenarios, \"confirmUpdateRetention\"), \n        updateRetentionAction(scenarios, client), \n        populateBuckets(scenarios), \n        confirmPopulateBuckets(scenarios), \n        exitOnFalse(scenarios, \"confirmPopulateBuckets\"), \n        populateBucketsAction(scenarios, client), \n        updateLockPolicy(scenarios), \n        confirmUpdateLockPolicy(scenarios), \n        exitOnFalse(scenarios, \"confirmUpdateLockPolicy\"), \n        updateLockPolicyAction(scenarios, client), \n        confirmSetLegalHoldFileEnabled(scenarios), \n        setLegalHoldFileEnabledAction(scenarios, client), \n        confirmSetRetentionPeriodFileEnabled(scenarios), \n        setRetentionPeriodFileEnabledAction(scenarios, client), \n        confirmSetLegalHoldFileRetention(scenarios), \n        setLegalHoldFileRetentionAction(scenarios, client), \n        confirmSetRetentionPeriodFileRetention(scenarios), \n        setRetentionPeriodFileRetentionAction(scenarios, client), \n        saveState, \n      ], \nScenarios API Version 2006-03-01 2428Amazon Simple Storage Service API Reference\n      initialState, \n    ), \n    demo: new scenarios.Scenario( \n      \"S3 Object Locking - Demo\", \n      [loadState, replAction(scenarios, client)], \n      initialState, \n    ), \n    clean: new scenarios.Scenario( \n      \"S3 Object Locking - Destroy\", \n      [ \n        loadState, \n        confirmCleanup(scenarios), \n        exitOnFalse(scenarios, \"confirmCleanup\"), \n        cleanupAction(scenarios, client), \n      ], \n      initialState, \n    ), \n  };\n};\n// Call function if run directly\nimport { fileURLToPath } from \"node:url\";\nimport { S3Client } from \"@aws-sdk/client-s3\";\nimport { cleanupAction, confirmCleanup } from \"./clean.steps.js\";\nimport { replAction } from \"./repl.steps.js\";\nif (process.argv[1] === fileURLToPath(import.meta.url)) { \n  const objectLockingScenarios = getWorkflowStages(Scenarios); \n  Scenarios.parseScenarioArgs(objectLockingScenarios);\n}\nwelcome.steps.js - Output welcome messages to the console.\n/** \n * @typedef {import(\"@aws-doc-sdk-examples/lib/scenario/index.js\")} Scenarios \n */\n/** \n * @param {Scenarios} scenarios \n */\nconst welcome = (scenarios) => \n  new scenarios.ScenarioOutput( \nScenarios API Version 2006-03-01 2429Amazon Simple Storage Service API Reference\n    \"welcome\", \n    \"Welcome to the Amazon Simple Storage Service (S3) Object Locking Workflow \n Scenario. For this workflow, we will use the AWS SDK for JavaScript to create \n several S3 buckets and files to demonstrate working with S3 locking features.\", \n    { header: true }, \n  );\n/** \n * @param {Scenarios} scenarios \n */\nconst welcomeContinue = (scenarios) => \n  new scenarios.ScenarioInput( \n    \"welcomeContinue\", \n    \"Press Enter when you are ready to start.\", \n    { type: \"confirm\" }, \n  );\nexport { welcome, welcomeContinue };\nsetup.steps.js - Deploy buckets, objects, and \ufb01le settings.\nimport { \n  BucketVersioningStatus, \n  ChecksumAlgorithm, \n  CreateBucketCommand, \n  MFADeleteStatus, \n  PutBucketVersioningCommand, \n  PutObjectCommand, \n  PutObjectLockConfigurationCommand, \n  PutObjectLegalHoldCommand, \n  PutObjectRetentionCommand, \n  ObjectLockLegalHoldStatus, \n  ObjectLockRetentionMode, \n  GetBucketVersioningCommand, \n  BucketAlreadyExists, \n  BucketAlreadyOwnedByYou, \n  S3ServiceException, \n  waitUntilBucketExists,\n} from \"@aws-sdk/client-s3\";\nimport { retry } from \"@aws-doc-sdk-examples/lib/utils/util-timers.js\";\nScenarios API Version 2006-03-01 2430Amazon Simple Storage Service API Reference\n/** \n * @typedef {import(\"@aws-doc-sdk-examples/lib/scenario/index.js\")} Scenarios \n */\n/** \n * @typedef {import(\"@aws-sdk/client-s3\").S3Client} S3Client \n */\n/** \n * @param {Scenarios} scenarios \n */\nconst getBucketPrefix = (scenarios) => \n  new scenarios.ScenarioInput( \n    \"bucketPrefix\", \n    \"Provide a prefix that will be used for bucket creation.\", \n    { type: \"input\", default: \"amzn-s3-demo-bucket\" }, \n  );\n/** \n * @param {Scenarios} scenarios \n */\nconst createBuckets = (scenarios) => \n  new scenarios.ScenarioOutput( \n    \"createBuckets\", \n    (state) => `The following buckets will be created: \n         ${state.bucketPrefix}-no-lock with object lock False. \n         ${state.bucketPrefix}-lock-enabled with object lock True. \n         ${state.bucketPrefix}-retention-after-creation with object lock False.`, \n    { preformatted: true }, \n  );\n/** \n * @param {Scenarios} scenarios \n */\nconst confirmCreateBuckets = (scenarios) => \n  new scenarios.ScenarioInput(\"confirmCreateBuckets\", \"Create the buckets?\", { \n    type: \"confirm\", \n  });\n/** \n * @param {Scenarios} scenarios \n * @param {S3Client} client \n */\nconst createBucketsAction = (scenarios, client) => \nScenarios API Version 2006-03-01 2431Amazon Simple Storage Service API Reference\n  new scenarios.ScenarioAction(\"createBucketsAction\", async (state) => { \n    const noLockBucketName = `${state.bucketPrefix}-no-lock`; \n    const lockEnabledBucketName = `${state.bucketPrefix}-lock-enabled`; \n    const retentionBucketName = `${state.bucketPrefix}-retention-after-creation`; \n    try { \n      await client.send(new CreateBucketCommand({ Bucket: noLockBucketName })); \n      await waitUntilBucketExists({ client }, { Bucket: noLockBucketName }); \n      await client.send( \n        new CreateBucketCommand({ \n          Bucket: lockEnabledBucketName, \n          ObjectLockEnabledForBucket: true, \n        }), \n      ); \n      await waitUntilBucketExists( \n        { client }, \n        { Bucket: lockEnabledBucketName }, \n      ); \n      await client.send( \n        new CreateBucketCommand({ Bucket: retentionBucketName }), \n      ); \n      await waitUntilBucketExists({ client }, { Bucket: retentionBucketName }); \n      state.noLockBucketName = noLockBucketName; \n      state.lockEnabledBucketName = lockEnabledBucketName; \n      state.retentionBucketName = retentionBucketName; \n    } catch (caught) { \n      if ( \n        caught instanceof BucketAlreadyExists || \n        caught instanceof BucketAlreadyOwnedByYou \n      ) { \n        console.error(`${caught.name}: ${caught.message}`); \n        state.earlyExit = true; \n      } else { \n        throw caught; \n      } \n    } \n  });\n/** \n * @param {Scenarios} scenarios \n */\nconst populateBuckets = (scenarios) => \n  new scenarios.ScenarioOutput( \nScenarios API Version 2006-03-01 2432Amazon Simple Storage Service API Reference\n    \"populateBuckets\", \n    (state) => `The following test files will be created: \n         file0.txt in ${state.bucketPrefix}-no-lock. \n         file1.txt in ${state.bucketPrefix}-no-lock. \n         file0.txt in ${state.bucketPrefix}-lock-enabled. \n         file1.txt in ${state.bucketPrefix}-lock-enabled. \n         file0.txt in ${state.bucketPrefix}-retention-after-creation. \n         file1.txt in ${state.bucketPrefix}-retention-after-creation.`, \n    { preformatted: true }, \n  );\n/** \n * @param {Scenarios} scenarios \n */\nconst confirmPopulateBuckets = (scenarios) => \n  new scenarios.ScenarioInput( \n    \"confirmPopulateBuckets\", \n    \"Populate the buckets?\", \n    { type: \"confirm\" }, \n  );\n/** \n * @param {Scenarios} scenarios \n * @param {S3Client} client \n */\nconst populateBucketsAction = (scenarios, client) => \n  new scenarios.ScenarioAction(\"populateBucketsAction\", async (state) => { \n    try { \n      await client.send( \n        new PutObjectCommand({ \n          Bucket: state.noLockBucketName, \n          Key: \"file0.txt\", \n          Body: \"Content\", \n          ChecksumAlgorithm: ChecksumAlgorithm.SHA256, \n        }), \n      ); \n      await client.send( \n        new PutObjectCommand({ \n          Bucket: state.noLockBucketName, \n          Key: \"file1.txt\", \n          Body: \"Content\", \n          ChecksumAlgorithm: ChecksumAlgorithm.SHA256, \n        }), \n      ); \nScenarios API Version 2006-03-01 2433Amazon Simple Storage Service API Reference\n      await client.send( \n        new PutObjectCommand({ \n          Bucket: state.lockEnabledBucketName, \n          Key: \"file0.txt\", \n          Body: \"Content\", \n          ChecksumAlgorithm: ChecksumAlgorithm.SHA256, \n        }), \n      ); \n      await client.send( \n        new PutObjectCommand({ \n          Bucket: state.lockEnabledBucketName, \n          Key: \"file1.txt\", \n          Body: \"Content\", \n          ChecksumAlgorithm: ChecksumAlgorithm.SHA256, \n        }), \n      ); \n      await client.send( \n        new PutObjectCommand({ \n          Bucket: state.retentionBucketName, \n          Key: \"file0.txt\", \n          Body: \"Content\", \n          ChecksumAlgorithm: ChecksumAlgorithm.SHA256, \n        }), \n      ); \n      await client.send( \n        new PutObjectCommand({ \n          Bucket: state.retentionBucketName, \n          Key: \"file1.txt\", \n          Body: \"Content\", \n          ChecksumAlgorithm: ChecksumAlgorithm.SHA256, \n        }), \n      ); \n    } catch (caught) { \n      if (caught instanceof S3ServiceException) { \n        console.error( \n          `Error from S3 while uploading object. ${caught.name}: \n ${caught.message}`, \n        ); \n      } else { \n        throw caught; \n      } \n    } \n  });\nScenarios API Version 2006-03-01 2434Amazon Simple Storage Service API Reference\n/** \n * @param {Scenarios} scenarios \n */\nconst updateRetention = (scenarios) => \n  new scenarios.ScenarioOutput( \n    \"updateRetention\", \n    (state) => `A bucket can be configured to use object locking with a default \n retention period.\nA default retention period will be configured for ${state.bucketPrefix}-\nretention-after-creation.`, \n    { preformatted: true }, \n  );\n/** \n * @param {Scenarios} scenarios \n */\nconst confirmUpdateRetention = (scenarios) => \n  new scenarios.ScenarioInput( \n    \"confirmUpdateRetention\", \n    \"Configure default retention period?\", \n    { type: \"confirm\" }, \n  );\n/** \n * @param {Scenarios} scenarios \n * @param {S3Client} client \n */\nconst updateRetentionAction = (scenarios, client) => \n  new scenarios.ScenarioAction(\"updateRetentionAction\", async (state) => { \n    await client.send( \n      new PutBucketVersioningCommand({ \n        Bucket: state.retentionBucketName, \n        VersioningConfiguration: { \n          MFADelete: MFADeleteStatus.Disabled, \n          Status: BucketVersioningStatus.Enabled, \n        }, \n      }), \n    ); \n    const getBucketVersioning = new GetBucketVersioningCommand({ \n      Bucket: state.retentionBucketName, \n    }); \n    await retry({ intervalInMs: 500, maxRetries: 10 }, async () => { \nScenarios API Version 2006-03-01 2435Amazon Simple Storage Service API Reference\n      const { Status } = await client.send(getBucketVersioning); \n      if (Status !== \"Enabled\") { \n        throw new Error(\"Bucket versioning is not enabled.\"); \n      } \n    }); \n    await client.send( \n      new PutObjectLockConfigurationCommand({ \n        Bucket: state.retentionBucketName, \n        ObjectLockConfiguration: { \n          ObjectLockEnabled: \"Enabled\", \n          Rule: { \n            DefaultRetention: { \n              Mode: \"GOVERNANCE\", \n              Years: 1, \n            }, \n          }, \n        }, \n      }), \n    ); \n  });\n/** \n * @param {Scenarios} scenarios \n */\nconst updateLockPolicy = (scenarios) => \n  new scenarios.ScenarioOutput( \n    \"updateLockPolicy\", \n    (state) => `Object lock policies can also be added to existing buckets.\nAn object lock policy will be added to ${state.bucketPrefix}-lock-enabled.`, \n    { preformatted: true }, \n  );\n/** \n * @param {Scenarios} scenarios \n */\nconst confirmUpdateLockPolicy = (scenarios) => \n  new scenarios.ScenarioInput( \n    \"confirmUpdateLockPolicy\", \n    \"Add object lock policy?\", \n    { type: \"confirm\" }, \n  );\n/** \nScenarios API Version 2006-03-01 2436Amazon Simple Storage Service API Reference\n * @param {Scenarios} scenarios \n * @param {S3Client} client \n */\nconst updateLockPolicyAction = (scenarios, client) => \n  new scenarios.ScenarioAction(\"updateLockPolicyAction\", async (state) => { \n    await client.send( \n      new PutObjectLockConfigurationCommand({ \n        Bucket: state.lockEnabledBucketName, \n        ObjectLockConfiguration: { \n          ObjectLockEnabled: \"Enabled\", \n        }, \n      }), \n    ); \n  });\n/** \n * @param {Scenarios} scenarios \n * @param {S3Client} client \n */\nconst confirmSetLegalHoldFileEnabled = (scenarios) => \n  new scenarios.ScenarioInput( \n    \"confirmSetLegalHoldFileEnabled\", \n    (state) => \n      `Would you like to add a legal hold to file0.txt in \n ${state.lockEnabledBucketName}?`, \n    { \n      type: \"confirm\", \n    }, \n  );\n/** \n * @param {Scenarios} scenarios \n * @param {S3Client} client \n */\nconst setLegalHoldFileEnabledAction = (scenarios, client) => \n  new scenarios.ScenarioAction( \n    \"setLegalHoldFileEnabledAction\", \n    async (state) => { \n      await client.send( \n        new PutObjectLegalHoldCommand({ \n          Bucket: state.lockEnabledBucketName, \n          Key: \"file0.txt\", \n          LegalHold: { \n            Status: ObjectLockLegalHoldStatus.ON, \nScenarios API Version 2006-03-01 2437Amazon Simple Storage Service API Reference\n          }, \n        }), \n      ); \n      console.log( \n        `Modified legal hold for file0.txt in ${state.lockEnabledBucketName}.`, \n      ); \n    }, \n    { skipWhen: (state) => !state.confirmSetLegalHoldFileEnabled }, \n  );\n/** \n * @param {Scenarios} scenarios \n * @param {S3Client} client \n */\nconst confirmSetRetentionPeriodFileEnabled = (scenarios) => \n  new scenarios.ScenarioInput( \n    \"confirmSetRetentionPeriodFileEnabled\", \n    (state) => \n      `Would you like to add a 1 day Governance retention period to file1.txt in \n ${state.lockEnabledBucketName}? \nReminder: Only a user with the s3:BypassGovernanceRetention permission will be \n able to delete this file or its bucket until the retention period has expired.`, \n    { \n      type: \"confirm\", \n    }, \n  );\n/** \n * @param {Scenarios} scenarios \n * @param {S3Client} client \n */\nconst setRetentionPeriodFileEnabledAction = (scenarios, client) => \n  new scenarios.ScenarioAction( \n    \"setRetentionPeriodFileEnabledAction\", \n    async (state) => { \n      const retentionDate = new Date(); \n      retentionDate.setDate(retentionDate.getDate() + 1); \n      await client.send( \n        new PutObjectRetentionCommand({ \n          Bucket: state.lockEnabledBucketName, \n          Key: \"file1.txt\", \n          Retention: { \n            Mode: ObjectLockRetentionMode.GOVERNANCE, \n            RetainUntilDate: retentionDate, \nScenarios API Version 2006-03-01 2438Amazon Simple Storage Service API Reference\n          }, \n        }), \n      ); \n      console.log( \n        `Set retention for file1.txt in ${state.lockEnabledBucketName} until \n ${retentionDate.toISOString().split(\"T\")[0]}.`, \n      ); \n    }, \n    { skipWhen: (state) => !state.confirmSetRetentionPeriodFileEnabled }, \n  );\n/** \n * @param {Scenarios} scenarios \n * @param {S3Client} client \n */\nconst confirmSetLegalHoldFileRetention = (scenarios) => \n  new scenarios.ScenarioInput( \n    \"confirmSetLegalHoldFileRetention\", \n    (state) => \n      `Would you like to add a legal hold to file0.txt in \n ${state.retentionBucketName}?`, \n    { \n      type: \"confirm\", \n    }, \n  );\n/** \n * @param {Scenarios} scenarios \n * @param {S3Client} client \n */\nconst setLegalHoldFileRetentionAction = (scenarios, client) => \n  new scenarios.ScenarioAction( \n    \"setLegalHoldFileRetentionAction\", \n    async (state) => { \n      await client.send( \n        new PutObjectLegalHoldCommand({ \n          Bucket: state.retentionBucketName, \n          Key: \"file0.txt\", \n          LegalHold: { \n            Status: ObjectLockLegalHoldStatus.ON, \n          }, \n        }), \n      ); \n      console.log( \nScenarios API Version 2006-03-01 2439Amazon Simple Storage Service API Reference\n        `Modified legal hold for file0.txt in ${state.retentionBucketName}.`, \n      ); \n    }, \n    { skipWhen: (state) => !state.confirmSetLegalHoldFileRetention }, \n  );\n/** \n * @param {Scenarios} scenarios \n */\nconst confirmSetRetentionPeriodFileRetention = (scenarios) => \n  new scenarios.ScenarioInput( \n    \"confirmSetRetentionPeriodFileRetention\", \n    (state) => \n      `Would you like to add a 1 day Governance retention period to file1.txt in \n ${state.retentionBucketName}?\nReminder: Only a user with the s3:BypassGovernanceRetention permission will be \n able to delete this file or its bucket until the retention period has expired.`, \n    { \n      type: \"confirm\", \n    }, \n  );\n/** \n * @param {Scenarios} scenarios \n * @param {S3Client} client \n */\nconst setRetentionPeriodFileRetentionAction = (scenarios, client) => \n  new scenarios.ScenarioAction( \n    \"setRetentionPeriodFileRetentionAction\", \n    async (state) => { \n      const retentionDate = new Date(); \n      retentionDate.setDate(retentionDate.getDate() + 1); \n      await client.send( \n        new PutObjectRetentionCommand({ \n          Bucket: state.retentionBucketName, \n          Key: \"file1.txt\", \n          Retention: { \n            Mode: ObjectLockRetentionMode.GOVERNANCE, \n            RetainUntilDate: retentionDate, \n          }, \n          BypassGovernanceRetention: true, \n        }), \n      ); \n      console.log( \nScenarios API Version 2006-03-01 2440Amazon Simple Storage Service API Reference\n        `Set retention for file1.txt in ${state.retentionBucketName} until \n ${retentionDate.toISOString().split(\"T\")[0]}.`, \n      ); \n    }, \n    { skipWhen: (state) => !state.confirmSetRetentionPeriodFileRetention }, \n  );\nexport { \n  getBucketPrefix, \n  createBuckets, \n  confirmCreateBuckets, \n  createBucketsAction, \n  populateBuckets, \n  confirmPopulateBuckets, \n  populateBucketsAction, \n  updateRetention, \n  confirmUpdateRetention, \n  updateRetentionAction, \n  updateLockPolicy, \n  confirmUpdateLockPolicy, \n  updateLockPolicyAction, \n  confirmSetLegalHoldFileEnabled, \n  setLegalHoldFileEnabledAction, \n  confirmSetRetentionPeriodFileEnabled, \n  setRetentionPeriodFileEnabledAction, \n  confirmSetLegalHoldFileRetention, \n  setLegalHoldFileRetentionAction, \n  confirmSetRetentionPeriodFileRetention, \n  setRetentionPeriodFileRetentionAction,\n};\nrepl.steps.js - View and delete \ufb01les in the buckets.\nimport { \n  ChecksumAlgorithm, \n  DeleteObjectCommand, \n  GetObjectLegalHoldCommand, \n  GetObjectLockConfigurationCommand, \n  GetObjectRetentionCommand, \n  ListObjectVersionsCommand, \n  PutObjectCommand,\n} from \"@aws-sdk/client-s3\";\nScenarios API Version 2006-03-01 2441Amazon Simple Storage Service API Reference\n/** \n * @typedef {import(\"@aws-doc-sdk-examples/lib/scenario/index.js\")} Scenarios \n */\n/** \n * @typedef {import(\"@aws-sdk/client-s3\").S3Client} S3Client \n */\nconst choices = { \n  EXIT: 0, \n  LIST_ALL_FILES: 1, \n  DELETE_FILE: 2, \n  DELETE_FILE_WITH_RETENTION: 3, \n  OVERWRITE_FILE: 4, \n  VIEW_RETENTION_SETTINGS: 5, \n  VIEW_LEGAL_HOLD_SETTINGS: 6,\n};\n/** \n * @param {Scenarios} scenarios \n */\nconst replInput = (scenarios) => \n  new scenarios.ScenarioInput( \n    \"replChoice\", \n    \"Explore the S3 locking features by selecting one of the following choices\", \n    { \n      type: \"select\", \n      choices: [ \n        { name: \"List all files in buckets\", value: choices.LIST_ALL_FILES }, \n        { name: \"Attempt to delete a file.\", value: choices.DELETE_FILE }, \n        { \n          name: \"Attempt to delete a file with retention period bypass.\", \n          value: choices.DELETE_FILE_WITH_RETENTION, \n        }, \n        { name: \"Attempt to overwrite a file.\", value: choices.OVERWRITE_FILE }, \n        { \n          name: \"View the object and bucket retention settings for a file.\", \n          value: choices.VIEW_RETENTION_SETTINGS, \n        }, \n        { \n          name: \"View the legal hold settings for a file.\", \n          value: choices.VIEW_LEGAL_HOLD_SETTINGS, \n        }, \nScenarios API Version 2006-03-01 2442Amazon Simple Storage Service API Reference\n        { name: \"Finish the workflow.\", value: choices.EXIT }, \n      ], \n    }, \n  );\n/** \n * @param {S3Client} client \n * @param {string[]} buckets \n */\nconst getAllFiles = async (client, buckets) => { \n  /** @type {{bucket: string, key: string, version: string}[]} */ \n  const files = []; \n  for (const bucket of buckets) { \n    const objectsResponse = await client.send( \n      new ListObjectVersionsCommand({ Bucket: bucket }), \n    ); \n    for (const version of objectsResponse.Versions || []) { \n      const { Key, VersionId } = version; \n      files.push({ bucket, key: Key, version: VersionId }); \n    } \n  } \n  return files;\n};\n/** \n * @param {Scenarios} scenarios \n * @param {S3Client} client \n */\nconst replAction = (scenarios, client) => \n  new scenarios.ScenarioAction( \n    \"replAction\", \n    async (state) => { \n      const files = await getAllFiles(client, [ \n        state.noLockBucketName, \n        state.lockEnabledBucketName, \n        state.retentionBucketName, \n      ]); \n      const fileInput = new scenarios.ScenarioInput( \n        \"selectedFile\", \n        \"Select a file:\", \n        { \n          type: \"select\", \nScenarios API Version 2006-03-01 2443Amazon Simple Storage Service API Reference\n          choices: files.map((file, index) => ({ \n            name: `${index + 1}: ${file.bucket}: ${file.key} (version: ${ \n              file.version \n            })`, \n            value: index, \n          })), \n        }, \n      ); \n      const { replChoice } = state; \n      switch (replChoice) { \n        case choices.LIST_ALL_FILES: { \n          const files = await getAllFiles(client, [ \n            state.noLockBucketName, \n            state.lockEnabledBucketName, \n            state.retentionBucketName, \n          ]); \n          state.replOutput = files \n            .map( \n              (file) => \n                `${file.bucket}: ${file.key} (version: ${file.version})`, \n            ) \n            .join(\"\\n\"); \n          break; \n        } \n        case choices.DELETE_FILE: { \n          /** @type {number} */ \n          const fileToDelete = await fileInput.handle(state); \n          const selectedFile = files[fileToDelete]; \n          try { \n            await client.send( \n              new DeleteObjectCommand({ \n                Bucket: selectedFile.bucket, \n                Key: selectedFile.key, \n                VersionId: selectedFile.version, \n              }), \n            ); \n            state.replOutput = `Deleted ${selectedFile.key} in \n ${selectedFile.bucket}.`; \n          } catch (err) { \n            state.replOutput = `Unable to delete object ${selectedFile.key} in \n bucket ${selectedFile.bucket}: ${err.message}`; \n          } \nScenarios API Version 2006-03-01 2444Amazon Simple Storage Service API Reference\n          break; \n        } \n        case choices.DELETE_FILE_WITH_RETENTION: { \n          /** @type {number} */ \n          const fileToDelete = await fileInput.handle(state); \n          const selectedFile = files[fileToDelete]; \n          try { \n            await client.send( \n              new DeleteObjectCommand({ \n                Bucket: selectedFile.bucket, \n                Key: selectedFile.key, \n                VersionId: selectedFile.version, \n                BypassGovernanceRetention: true, \n              }), \n            ); \n            state.replOutput = `Deleted ${selectedFile.key} in \n ${selectedFile.bucket}.`; \n          } catch (err) { \n            state.replOutput = `Unable to delete object ${selectedFile.key} in \n bucket ${selectedFile.bucket}: ${err.message}`; \n          } \n          break; \n        } \n        case choices.OVERWRITE_FILE: { \n          /** @type {number} */ \n          const fileToOverwrite = await fileInput.handle(state); \n          const selectedFile = files[fileToOverwrite]; \n          try { \n            await client.send( \n              new PutObjectCommand({ \n                Bucket: selectedFile.bucket, \n                Key: selectedFile.key, \n                Body: \"New content\", \n                ChecksumAlgorithm: ChecksumAlgorithm.SHA256, \n              }), \n            ); \n            state.replOutput = `Overwrote ${selectedFile.key} in \n ${selectedFile.bucket}.`; \n          } catch (err) { \n            state.replOutput = `Unable to overwrite object ${selectedFile.key} in \n bucket ${selectedFile.bucket}: ${err.message}`; \n          } \n          break; \n        } \nScenarios API Version 2006-03-01 2445Amazon Simple Storage Service API Reference\n        case choices.VIEW_RETENTION_SETTINGS: { \n          /** @type {number} */ \n          const fileToView = await fileInput.handle(state); \n          const selectedFile = files[fileToView]; \n          try { \n            const retention = await client.send( \n              new GetObjectRetentionCommand({ \n                Bucket: selectedFile.bucket, \n                Key: selectedFile.key, \n                VersionId: selectedFile.version, \n              }), \n            ); \n            const bucketConfig = await client.send( \n              new GetObjectLockConfigurationCommand({ \n                Bucket: selectedFile.bucket, \n              }), \n            ); \n            state.replOutput = `Object retention for ${selectedFile.key} \n in ${selectedFile.bucket}: ${retention.Retention?.Mode} until \n ${retention.Retention?.RetainUntilDate?.toISOString()}.\nBucket object lock config for ${selectedFile.bucket} in ${selectedFile.bucket}:\nEnabled: ${bucketConfig.ObjectLockConfiguration?.ObjectLockEnabled}\nRule: \n ${JSON.stringify(bucketConfig.ObjectLockConfiguration?.Rule?.DefaultRetention)}`; \n          } catch (err) { \n            state.replOutput = `Unable to fetch object lock retention: \n '${err.message}'`; \n          } \n          break; \n        } \n        case choices.VIEW_LEGAL_HOLD_SETTINGS: { \n          /** @type {number} */ \n          const fileToView = await fileInput.handle(state); \n          const selectedFile = files[fileToView]; \n          try { \n            const legalHold = await client.send( \n              new GetObjectLegalHoldCommand({ \n                Bucket: selectedFile.bucket, \n                Key: selectedFile.key, \n                VersionId: selectedFile.version, \n              }), \n            ); \n            state.replOutput = `Object legal hold for ${selectedFile.key} in \n ${selectedFile.bucket}: Status: ${legalHold.LegalHold?.Status}`; \nScenarios API Version 2006-03-01 2446Amazon Simple Storage Service API Reference\n          } catch (err) { \n            state.replOutput = `Unable to fetch legal hold: '${err.message}'`; \n          } \n          break; \n        } \n        default: \n          throw new Error(`Invalid replChoice: ${replChoice}`); \n      } \n    }, \n    { \n      whileConfig: { \n        whileFn: ({ replChoice }) => replChoice !== choices.EXIT, \n        input: replInput(scenarios), \n        output: new scenarios.ScenarioOutput( \n          \"REPL output\", \n          (state) => state.replOutput, \n          { preformatted: true }, \n        ), \n      }, \n    }, \n  );\nexport { replInput, replAction, choices };\nclean.steps.js - Destroy all created resources.\nimport { \n  DeleteObjectCommand, \n  DeleteBucketCommand, \n  ListObjectVersionsCommand, \n  GetObjectLegalHoldCommand, \n  GetObjectRetentionCommand, \n  PutObjectLegalHoldCommand,\n} from \"@aws-sdk/client-s3\";\n/** \n * @typedef {import(\"@aws-doc-sdk-examples/lib/scenario/index.js\")} Scenarios \n */\n/** \n * @typedef {import(\"@aws-sdk/client-s3\").S3Client} S3Client \n */\nScenarios API Version 2006-03-01 2447Amazon Simple Storage Service API Reference\n/** \n * @param {Scenarios} scenarios \n */\nconst confirmCleanup = (scenarios) => \n  new scenarios.ScenarioInput(\"confirmCleanup\", \"Clean up resources?\", { \n    type: \"confirm\", \n  });\n/** \n * @param {Scenarios} scenarios \n * @param {S3Client} client \n */\nconst cleanupAction = (scenarios, client) => \n  new scenarios.ScenarioAction(\"cleanupAction\", async (state) => { \n    const { noLockBucketName, lockEnabledBucketName, retentionBucketName } = \n      state; \n    const buckets = [ \n      noLockBucketName, \n      lockEnabledBucketName, \n      retentionBucketName, \n    ]; \n    for (const bucket of buckets) { \n      /** @type {import(\"@aws-sdk/client-s3\").ListObjectVersionsCommandOutput} */ \n      let objectsResponse; \n      try { \n        objectsResponse = await client.send( \n          new ListObjectVersionsCommand({ \n            Bucket: bucket, \n          }), \n        ); \n      } catch (e) { \n        if (e instanceof Error && e.name === \"NoSuchBucket\") { \n          console.log(\"Object's bucket has already been deleted.\"); \n          continue; \n        } \n        throw e; \n      } \n      for (const version of objectsResponse.Versions || []) { \n        const { Key, VersionId } = version; \nScenarios API Version 2006-03-01 2448Amazon Simple Storage Service API Reference\n        try { \n          const legalHold = await client.send( \n            new GetObjectLegalHoldCommand({ \n              Bucket: bucket, \n              Key, \n              VersionId, \n            }), \n          ); \n          if (legalHold.LegalHold?.Status === \"ON\") { \n            await client.send( \n              new PutObjectLegalHoldCommand({ \n                Bucket: bucket, \n                Key, \n                VersionId, \n                LegalHold: { \n                  Status: \"OFF\", \n                }, \n              }), \n            ); \n          } \n        } catch (err) { \n          console.log( \n            `Unable to fetch legal hold for ${Key} in ${bucket}: \n '${err.message}'`, \n          ); \n        } \n        try { \n          const retention = await client.send( \n            new GetObjectRetentionCommand({ \n              Bucket: bucket, \n              Key, \n              VersionId, \n            }), \n          ); \n          if (retention.Retention?.Mode === \"GOVERNANCE\") { \n            await client.send( \n              new DeleteObjectCommand({ \n                Bucket: bucket, \n                Key, \n                VersionId, \nScenarios API Version 2006-03-01 2449Amazon Simple Storage Service API Reference\n                BypassGovernanceRetention: true, \n              }), \n            ); \n          } \n        } catch (err) { \n          console.log( \n            `Unable to fetch object lock retention for ${Key} in ${bucket}: \n '${err.message}'`, \n          ); \n        } \n        await client.send( \n          new DeleteObjectCommand({ \n            Bucket: bucket, \n            Key, \n            VersionId, \n          }), \n        ); \n      } \n      await client.send(new DeleteBucketCommand({ Bucket: bucket })); \n      console.log(`Delete for ${bucket} complete.`); \n    } \n  });\nexport { confirmCleanup, cleanupAction };\n\u2022For API details, see the following topics in AWS SDK for JavaScript API Reference.\n\u2022GetObjectLegalHold\n\u2022GetObjectLockCon\ufb01guration\n\u2022GetObjectRetention\n\u2022PutObjectLegalHold\n\u2022PutObjectLockCon\ufb01guration\n\u2022PutObjectRetention\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nScenarios API Version 2006-03-01 2450Amazon Simple Storage Service API Reference\nManage access control lists (ACLs) for Amazon S3 buckets using an AWS SDK\nThe following code example shows how to manage access control lists (ACLs) for Amazon S3 \nbuckets.\n.NET\nAWS SDK for .NET\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n    using System; \n    using System.Collections.Generic; \n    using System.Threading.Tasks; \n    using Amazon.S3; \n    using Amazon.S3.Model; \n    /// <summary> \n    /// This example shows how to manage Amazon Simple Storage Service \n    /// (Amazon S3) access control lists (ACLs) to control Amazon S3 bucket \n    /// access. \n    /// </summary> \n    public class ManageACLs \n    { \n        public static async Task Main() \n        { \n            string bucketName = \"amzn-s3-demo-bucket1\"; \n            string newBucketName = \"amzn-s3-demo-bucket2\"; \n            string keyName = \"sample-object.txt\"; \n            string emailAddress = \"someone@example.com\"; \n            // If the AWS Region where your bucket is located is different from \n            // the Region defined for the default user, pass the Amazon S3 \n bucket's \n            // name to the client constructor. It should look like this: \n            // RegionEndpoint bucketRegion = RegionEndpoint.USEast1; \n            IAmazonS3 client = new AmazonS3Client(); \nScenarios API Version 2006-03-01 2451Amazon Simple Storage Service API Reference\n            await TestBucketObjectACLsAsync(client, bucketName, newBucketName, \n keyName, emailAddress); \n        } \n        /// <summary> \n        /// Creates a new Amazon S3 bucket with a canned ACL, then retrieves the \n ACL \n        /// information and then adds a new ACL to one of the objects in the \n        /// Amazon S3 bucket. \n        /// </summary> \n        /// <param name=\"client\">The initialized Amazon S3 client object used to \n call \n        /// methods to create a bucket, get an ACL, and add a different ACL to \n        /// one of the objects.</param> \n        /// <param name=\"bucketName\">A string representing the original Amazon S3 \n        /// bucket name.</param> \n        /// <param name=\"newBucketName\">A string representing the name of the \n        /// new bucket that will be created.</param> \n        /// <param name=\"keyName\">A string representing the key name of an Amazon \n S3 \n        /// object for which we will change the ACL.</param> \n        /// <param name=\"emailAddress\">A string representing the email address \n        /// belonging to the person to whom access to the Amazon S3 bucket will \n be \n        /// granted.</param> \n        public static async Task TestBucketObjectACLsAsync( \n            IAmazonS3 client, \n            string bucketName, \n            string newBucketName, \n            string keyName, \n            string emailAddress) \n        { \n            try \n            { \n                // Create a new Amazon S3 bucket and specify canned ACL.", "\n                var success = await CreateBucketWithCannedACLAsync(client, \n newBucketName); \n                // Get the ACL on a bucket. \n                await GetBucketACLAsync(client, bucketName); \n                // Add (replace) the ACL on an object in a bucket. \n                await AddACLToExistingObjectAsync(client, bucketName, keyName, \n emailAddress); \nScenarios API Version 2006-03-01 2452Amazon Simple Storage Service API Reference\n            } \n            catch (AmazonS3Exception amazonS3Exception) \n            { \n                Console.WriteLine($\"Exception: {amazonS3Exception.Message}\"); \n            } \n        } \n        /// <summary> \n        /// Creates a new Amazon S3 bucket with a canned ACL attached. \n        /// </summary> \n        /// <param name=\"client\">The initialized client object used to call \n        /// PutBucketAsync.</param> \n        /// <param name=\"newBucketName\">A string representing the name of the \n        /// new Amazon S3 bucket.</param> \n        /// <returns>Returns a boolean value indicating success or failure.</\nreturns> \n        public static async Task<bool> CreateBucketWithCannedACLAsync(IAmazonS3 \n client, string newBucketName) \n        { \n            var request = new PutBucketRequest() \n            { \n                BucketName = newBucketName, \n                BucketRegion = S3Region.EUWest1, \n                // Add a canned ACL. \n                CannedACL = S3CannedACL.LogDeliveryWrite, \n            }; \n            var response = await client.PutBucketAsync(request); \n            return response.HttpStatusCode == System.Net.HttpStatusCode.OK; \n        } \n        /// <summary> \n        /// Retrieves the ACL associated with the Amazon S3 bucket name in the \n        /// bucketName parameter. \n        /// </summary> \n        /// <param name=\"client\">The initialized client object used to call \n        /// PutBucketAsync.</param> \n        /// <param name=\"bucketName\">The Amazon S3 bucket for which we want to \n get the \n        /// ACL list.</param> \n        /// <returns>Returns an S3AccessControlList returned from the call to \n        /// GetACLAsync.</returns> \nScenarios API Version 2006-03-01 2453Amazon Simple Storage Service API Reference\n        public static async Task<S3AccessControlList> GetBucketACLAsync(IAmazonS3 \n client, string bucketName) \n        { \n            GetACLResponse response = await client.GetACLAsync(new GetACLRequest \n            { \n                BucketName = bucketName, \n            }); \n            return response.AccessControlList; \n        } \n        /// <summary> \n        /// Adds a new ACL to an existing object in the Amazon S3 bucket. \n        /// </summary> \n        /// <param name=\"client\">The initialized client object used to call \n        /// PutBucketAsync.</param> \n        /// <param name=\"bucketName\">A string representing the name of the Amazon \n S3 \n        /// bucket containing the object to which we want to apply a new ACL.</\nparam> \n        /// <param name=\"keyName\">A string representing the name of the object \n        /// to which we want to apply the new ACL.</param> \n        /// <param name=\"emailAddress\">The email address of the person to whom \n        /// we will be applying to whom access will be granted.</param> \n        public static async Task AddACLToExistingObjectAsync(IAmazonS3 client, \n string bucketName, string keyName, string emailAddress) \n        { \n            // Retrieve the ACL for an object. \n            GetACLResponse aclResponse = await client.GetACLAsync(new \n GetACLRequest \n            { \n                BucketName = bucketName, \n                Key = keyName, \n            }); \n            S3AccessControlList acl = aclResponse.AccessControlList; \n            // Retrieve the owner.", "\n            Owner owner = acl.Owner; \n            // Clear existing grants.", "\n            acl.Grants.Clear(); \nScenarios API Version 2006-03-01 2454Amazon Simple Storage Service API Reference\n            // Add a grant to reset the owner's full permission \n            // (the previous clear statement removed all permissions).", "\n            var fullControlGrant = new S3Grant \n            { \n                Grantee = new S3Grantee { CanonicalUser = acl.Owner.Id }, \n            }; \n            acl.AddGrant(fullControlGrant.Grantee, S3Permission.FULL_CONTROL); \n            // Specify email to identify grantee for granting permissions. \n            var grantUsingEmail = new S3Grant \n            { \n                Grantee = new S3Grantee { EmailAddress = emailAddress }, \n                Permission = S3Permission.WRITE_ACP, \n            }; \n            // Specify log delivery group as grantee. \n            var grantLogDeliveryGroup = new S3Grant \n            { \n                Grantee = new S3Grantee { URI = \"http://acs.amazonaws.com/groups/\ns3/LogDelivery\" }, \n                Permission = S3Permission.WRITE, \n            }; \n            // Create a new ACL. \n            var newAcl = new S3AccessControlList \n            { \n                Grants = new List<S3Grant> { grantUsingEmail, \n grantLogDeliveryGroup }, \n                Owner = owner, \n            }; \n            // Set the new ACL.", "We're throwing away the response here.", "\n            _ = await client.PutACLAsync(new PutACLRequest \n            { \n                BucketName = bucketName, \n                Key = keyName, \n                AccessControlList = newAcl, \n            }); \n        } \n    }\nScenarios API Version 2006-03-01 2455Amazon Simple Storage Service API Reference\n\u2022For API details, see the following topics in AWS SDK for .NET API Reference.\n\u2022GetBucketAcl\n\u2022GetObjectAcl\n\u2022PutBucketAcl\n\u2022PutObjectAcl\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nManage versioned Amazon S3 objects in batches with a Lambda function using an \nAWS SDK\nThe following code example shows how to manage versioned S3 objects in batches with a Lambda \nfunction.\nPython\nSDK for Python (Boto3)\nShows how to manipulate Amazon Simple Storage Service (Amazon S3) versioned objects \nin batches by creating jobs that call AWS Lambda functions to perform processing. This \nexample creates a version-enabled bucket, uploads the stanzas from the poem You Are Old, \nFather William by Lewis Carroll, and uses Amazon S3 batch jobs to twist the poem in various \nways.\nLearn how to:\n\u2022Create Lambda functions that operate on versioned objects.\n\u2022Create a manifest of objects to update.\n\u2022Create batch jobs that invoke Lambda functions to update objects.\n\u2022Delete Lambda functions.\n\u2022Empty and delete a versioned bucket.\nThis example is best viewed on GitHub.", "For complete source code and instructions on how to \nset up and run, see the full example on GitHub .\nScenarios API Version 2006-03-01 2456Amazon Simple Storage Service API Reference\nServices used in this example\n\u2022Amazon S3\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nParse Amazon S3 URIs using an AWS SDK\nThe following code example shows how to parse Amazon S3 URIs to extract important components \nlike the bucket name and object key.\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nParse an Amazon S3 URI by using the S3Uri  class.\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\nimport software.amazon.awssdk.regions.Region;\nimport software.amazon.awssdk.services.s3.S3Client;\nimport software.amazon.awssdk.services.s3.S3Uri;\nimport software.amazon.awssdk.services.s3.S3Utilities;\nimport java.net.URI;\nimport java.util.List;\nimport java.util.Map; \n    /** \n     * \n     * @param s3Client    - An S3Client through which you acquire an S3Uri \n instance. \n     * @param s3ObjectUrl - A complex URL (String) that is used to demonstrate \n S3Uri \nScenarios API Version 2006-03-01 2457Amazon Simple Storage Service API Reference\n     *                    capabilities. \n     */ \n    public static void parseS3UriExample(S3Client s3Client, String s3ObjectUrl) { \n        logger.info(s3ObjectUrl); \n        // Console output: \n        // 'https://s3.us-west-1.amazonaws.com/myBucket/resources/doc.txt?\nversionId=abc123&partNumber=77&partNumber=88'. \n        // Create an S3Utilities object using the configuration of the s3Client. \n        S3Utilities s3Utilities = s3Client.utilities(); \n        // From a String URL create a URI object to pass to the parseUri() \n method. \n        URI uri = URI.create(s3ObjectUrl); \n        S3Uri s3Uri = s3Utilities.parseUri(uri); \n        // If the URI contains no value for the Region, bucket or key, the SDK \n returns \n        // an empty Optional.", "\n        // The SDK returns decoded URI values.", "\n        Region region = s3Uri.region().orElse(null); \n        log(\"region\", region); \n        // Console output: 'region: us-west-1'. \n        String bucket = s3Uri.bucket().orElse(null); \n        log(\"bucket\", bucket); \n        // Console output: 'bucket: myBucket'. \n        String key = s3Uri.key().orElse(null); \n        log(\"key\", key); \n        // Console output: 'key: resources/doc.txt'. \n        Boolean isPathStyle = s3Uri.isPathStyle(); \n        log(\"isPathStyle\", isPathStyle); \n        // Console output: 'isPathStyle: true'.", "\n        // If the URI contains no query parameters, the SDK returns an empty map.", "\n        Map<String, List<String>> queryParams = s3Uri.rawQueryParameters(); \n        log(\"rawQueryParameters\", queryParams); \n        // Console output: 'rawQueryParameters: {versionId=[abc123], \n partNumber=[77, \n        // 88]}'.", "\nScenarios API Version 2006-03-01 2458Amazon Simple Storage Service API Reference\n        // Retrieve the first or all values for a query parameter as shown in the \n        // following code.", "\n        String versionId = \n s3Uri.firstMatchingRawQueryParameter(\"versionId\").orElse(null); \n        log(\"firstMatchingRawQueryParameter-versionId\", versionId); \n        // Console output: 'firstMatchingRawQueryParameter-versionId: abc123'. \n        String partNumber = \n s3Uri.firstMatchingRawQueryParameter(\"partNumber\").orElse(null); \n        log(\"firstMatchingRawQueryParameter-partNumber\", partNumber); \n        // Console output: 'firstMatchingRawQueryParameter-partNumber: 77'. \n        List<String> partNumbers = \n s3Uri.firstMatchingRawQueryParameters(\"partNumber\"); \n        log(\"firstMatchingRawQueryParameter\", partNumbers); \n        // Console output: 'firstMatchingRawQueryParameter: [77, 88]'.", "\n        /* \n         * Object keys and query parameters with reserved or unsafe characters, \n must be \n         * URL-encoded.", "\n         * For example replace whitespace \" \" with \"%20\".", "\n         * Valid: \n         * \"https://s3.us-west-1.amazonaws.com/myBucket/object%20key?query=\n%5Bbrackets%5D\" \n         * Invalid: \n         * \"https://s3.us-west-1.amazonaws.com/myBucket/object key?\nquery=[brackets]\" \n         *  \n         * Virtual-hosted-style URIs with bucket names that contain a dot, \".\", \n the dot \n         * must not be URL-encoded. \n         * Valid: \"https://my.Bucket.s3.us-west-1.amazonaws.com/key\" \n         * Invalid: \"https://my%2EBucket.s3.us-west-1.amazonaws.com/key\" \n         */ \n    } \n    private static void log(String s3UriElement, Object element) { \n        if (element == null) { \n            logger.info(\"{}: {}\", s3UriElement, \"null\"); \n        } else { \n            logger.info(\"{}: {}\", s3UriElement, element); \n        } \n    }\nScenarios API Version 2006-03-01 2459Amazon Simple Storage Service API Reference\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nPerform a multipart copy of an Amazon S3 object using an AWS SDK\nThe following code example shows how to perform a multipart copy of an Amazon S3 object.\n.NET\nAWS SDK for .NET\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n    using System; \n    using System.Collections.Generic; \n    using System.Threading.Tasks; \n    using Amazon.S3; \n    using Amazon.S3.Model; \n    /// <summary> \n    /// This example shows how to perform a multi-part copy from one Amazon \n    /// Simple Storage Service (Amazon S3) bucket to another.", "\n    /// </summary> \n    public class MPUapiCopyObj \n    { \n        private const string SourceBucket = \"amzn-s3-demo-bucket1\"; \n        private const string TargetBucket = \"amzn-s3-demo-bucket2\"; \n        private const string SourceObjectKey = \"example.mov\"; \n        private const string TargetObjectKey = \"copied_video_file.mov\"; \n        /// <summary> \n        /// This method starts the multi-part upload.", "\n        /// </summary> \n        public static async Task Main() \nScenarios API Version 2006-03-01 2460Amazon Simple Storage Service API Reference\n        { \n            var s3Client = new AmazonS3Client(); \n            Console.WriteLine(\"Copying object...\"); \n            await MPUCopyObjectAsync(s3Client); \n        } \n        /// <summary> \n        /// This method uses the passed client object to perform a multipart \n        /// copy operation. \n        /// </summary> \n        /// <param name=\"client\">An Amazon S3 client object that will be used \n        /// to perform the copy.</param> \n        public static async Task MPUCopyObjectAsync(AmazonS3Client client) \n        { \n            // Create a list to store the copy part responses.", "\n            var copyResponses = new List<CopyPartResponse>(); \n            // Setup information required to initiate the multipart upload.", "\n            var initiateRequest = new InitiateMultipartUploadRequest \n            { \n                BucketName = TargetBucket, \n                Key = TargetObjectKey, \n            }; \n            // Initiate the upload. \n            InitiateMultipartUploadResponse initResponse = \n                await client.InitiateMultipartUploadAsync(initiateRequest); \n            // Save the upload ID. \n            string uploadId = initResponse.UploadId; \n            try \n            { \n                // Get the size of the object.", "\n                var metadataRequest = new GetObjectMetadataRequest \n                { \n                    BucketName = SourceBucket, \n                    Key = SourceObjectKey, \n                }; \n                GetObjectMetadataResponse metadataResponse = \n                    await client.GetObjectMetadataAsync(metadataRequest); \n                var objectSize = metadataResponse.ContentLength; // Length in \n bytes.", "\nScenarios API Version 2006-03-01 2461Amazon Simple Storage Service API Reference\n                // Copy the parts.", "\n                var partSize = 5 * (long)Math.Pow(2, 20); // Part size is 5 MB.", "\n                long bytePosition = 0; \n                for (int i = 1; bytePosition < objectSize; i++) \n                { \n                    var copyRequest = new CopyPartRequest \n                    { \n                        DestinationBucket = TargetBucket, \n                        DestinationKey = TargetObjectKey, \n                        SourceBucket = SourceBucket, \n                        SourceKey = SourceObjectKey, \n                        UploadId = uploadId, \n                        FirstByte = bytePosition, \n                        LastByte = bytePosition + partSize - 1 >= objectSize ?", "\n objectSize - 1 : bytePosition + partSize - 1, \n                        PartNumber = i, \n                    }; \n                    copyResponses.Add(await client.CopyPartAsync(copyRequest)); \n                    bytePosition += partSize; \n                } \n                // Set up to complete the copy.", "\n                var completeRequest = new CompleteMultipartUploadRequest \n                { \n                    BucketName = TargetBucket, \n                    Key = TargetObjectKey, \n                    UploadId = initResponse.UploadId, \n                }; \n                completeRequest.AddPartETags(copyResponses); \n                // Complete the copy. \n                CompleteMultipartUploadResponse completeUploadResponse = \n                    await client.CompleteMultipartUploadAsync(completeRequest); \n            } \n            catch (AmazonS3Exception e) \n            { \n                Console.WriteLine($\"Error encountered on server.", "\n Message:'{e.Message}' when writing an object\"); \n            } \n            catch (Exception e) \nScenarios API Version 2006-03-01 2462Amazon Simple Storage Service API Reference\n            { \n                Console.WriteLine($\"Unknown encountered on server.", "\n Message:'{e.Message}' when writing an object\"); \n            } \n        } \n    }\n\u2022For API details, see the following topics in AWS SDK for .NET API Reference.\n\u2022CompleteMultipartUpload\n\u2022CreateMultipartUpload\n\u2022GetObjectMetadata\n\u2022UploadPartCopy\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nPerform a multipart upload of an Amazon S3 object using an AWS SDK\nThe following code example shows how to perform a multipart upload to an Amazon S3 object.\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nThe code examples use the following imports.\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\nimport software.amazon.awssdk.core.exception.SdkException;\nimport software.amazon.awssdk.core.sync.RequestBody;\nScenarios API Version 2006-03-01 2463Amazon Simple Storage Service API Reference\nimport software.amazon.awssdk.services.s3.S3AsyncClient;\nimport software.amazon.awssdk.services.s3.S3Client;\nimport software.amazon.awssdk.services.s3.model.CompletedMultipartUpload;\nimport software.amazon.awssdk.services.s3.model.CompletedPart;\nimport software.amazon.awssdk.services.s3.model.CreateMultipartUploadResponse;\nimport software.amazon.awssdk.services.s3.model.PutObjectResponse;\nimport software.amazon.awssdk.services.s3.model.UploadPartRequest;\nimport software.amazon.awssdk.services.s3.model.UploadPartResponse;\nimport software.amazon.awssdk.services.s3.waiters.S3Waiter;\nimport software.amazon.awssdk.transfer.s3.S3TransferManager;\nimport software.amazon.awssdk.transfer.s3.model.FileUpload;\nimport software.amazon.awssdk.transfer.s3.model.UploadFileRequest;\nimport java.io.IOException;\nimport java.io.RandomAccessFile;\nimport java.net.URISyntaxException;\nimport java.net.URL;\nimport java.nio.ByteBuffer;\nimport java.nio.file.Paths;\nimport java.util.ArrayList;\nimport java.util.List;\nimport java.util.Objects;\nimport java.util.UUID;\nimport java.util.concurrent.CompletableFuture;\nUse the S3 Transfer Manager on top of the AWS CRT-based S3 client to transparently \nperform a multipart upload when the size of the content exceeds a threshold. The default \nthreshold size is 8 MB.\n    /** \n     * Uploads a file to an Amazon S3 bucket using the S3TransferManager. \n     * \n     * @param filePath the file path of the file to be uploaded \n     */ \n    public void multipartUploadWithTransferManager(String filePath) { \n        S3TransferManager transferManager = S3TransferManager.create(); \n        UploadFileRequest uploadFileRequest = UploadFileRequest.builder() \n            .putObjectRequest(b -> b \n                .bucket(bucketName) \n                .key(key)) \n            .source(Paths.get(filePath)) \n            .build(); \nScenarios API Version 2006-03-01 2464Amazon Simple Storage Service API Reference\n        FileUpload fileUpload = transferManager.uploadFile(uploadFileRequest); \n        fileUpload.completionFuture().join(); \n        transferManager.close(); \n    }\nUse the S3Client API  to perform a multipart upload.\n    /** \n     * Performs a multipart upload to Amazon S3 using the provided S3 client. \n     * \n     * @param filePath the path to the file to be uploaded \n     */ \n    public void multipartUploadWithS3Client(String filePath) { \n        // Initiate the multipart upload. \n        CreateMultipartUploadResponse createMultipartUploadResponse = \n s3Client.createMultipartUpload(b -> b \n            .bucket(bucketName) \n            .key(key)); \n        String uploadId = createMultipartUploadResponse.uploadId(); \n        // Upload the parts of the file.", "\n        int partNumber = 1; \n        List<CompletedPart> completedParts = new ArrayList<>(); \n        ByteBuffer bb = ByteBuffer.allocate(1024 * 1024 * 5); // 5 MB byte buffer \n        try (RandomAccessFile file = new RandomAccessFile(filePath, \"r\")) { \n            long fileSize = file.length(); \n            long position = 0; \n            while (position < fileSize) { \n                file.seek(position); \n                long read = file.getChannel().read(bb); \n                bb.flip(); // Swap position and limit before reading from the \n buffer.", "\n                UploadPartRequest uploadPartRequest = UploadPartRequest.builder() \n                    .bucket(bucketName) \n                    .key(key) \n                    .uploadId(uploadId) \n                    .partNumber(partNumber) \n                    .build(); \nScenarios API Version 2006-03-01 2465Amazon Simple Storage Service API Reference\n                UploadPartResponse partResponse = s3Client.uploadPart( \n                    uploadPartRequest, \n                    RequestBody.fromByteBuffer(bb)); \n                CompletedPart part = CompletedPart.builder() \n                    .partNumber(partNumber) \n                    .eTag(partResponse.eTag()) \n                    .build(); \n                completedParts.add(part); \n                bb.clear(); \n                position += read; \n                partNumber++; \n            } \n        } catch (IOException e) { \n            logger.error(e.getMessage()); \n        } \n        // Complete the multipart upload. \n        s3Client.completeMultipartUpload(b -> b \n            .bucket(bucketName) \n            .key(key) \n            .uploadId(uploadId) \n            \n .multipartUpload(CompletedMultipartUpload.builder().parts(completedParts).build())); \n    }\nUse the S3AsyncClient API  with multipart support enabled to perform a multipart upload.\n    /** \n     * Uploads a file to an S3 bucket using the S3AsyncClient and enabling \n multipart support. \n     * \n     * @param filePath the local file path of the file to be uploaded \n     */ \n    public void multipartUploadWithS3AsyncClient(String filePath) { \n        // Enable multipart support. \n        S3AsyncClient s3AsyncClient = S3AsyncClient.builder() \n            .multipartEnabled(true) \n            .build(); \nScenarios API Version 2006-03-01 2466Amazon Simple Storage Service API Reference\n        CompletableFuture<PutObjectResponse> response = s3AsyncClient.putObject(b \n -> b \n                .bucket(bucketName) \n                .key(key), \n            Paths.get(filePath)); \n        response.join(); \n        logger.info(\"File uploaded in multiple 8 MiB parts using \n S3AsyncClient.\"); \n    }\n\u2022For API details, see the following topics in AWS SDK for Java 2.x API Reference.\n\u2022CompleteMultipartUpload\n\u2022CreateMultipartUpload\n\u2022UploadPart\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nReceive and process Amazon S3 event noti\ufb01cations by using an AWS SDK.\nThe following code example shows how to work with S3 event noti\ufb01cations in an object-oriented \nway.\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nThis example show how to process S3 noti\ufb01cation event by using Amazon SQS.\n    /** \n     * This method receives S3 event notifications by using an SqsAsyncClient.", "\nScenarios API Version 2006-03-01 2467Amazon Simple Storage Service API Reference\n     * After the client receives the messages it deserializes the JSON payload \n and logs them.", "It uses \n     * the S3EventNotification class (part of the S3 event notification API for \n Java) to deserialize \n     * the JSON payload and access the messages in an object-oriented way. \n     * \n     * @param queueUrl The URL of the AWS SQS queue that receives the S3 event \n notifications. \n     * @see <a href=\"https://sdk.amazonaws.com/java/api/latest/software/amazon/\nawssdk/eventnotifications/s3/model/package-summary.html\">S3EventNotification \n API</a>. \n     * <p> \n     * To use S3 event notification serialization/deserialization to objects, add \n the following \n     * dependency to your Maven pom.xml file. \n     * <dependency> \n     * <groupId>software.amazon.awssdk</groupId> \n     * <artifactId>s3-event-notifications</artifactId> \n     * <version><LATEST></version> \n     * </dependency> \n     * <p> \n     * The S3 event notification API became available with version 2.25.11 of the \n Java SDK. \n     * <p> \n     * This example shows the use of the API with AWS SQS, but it can be used to \n process S3 event notifications \n     * in AWS SNS or AWS Lambda as well. \n     * <p> \n     * Note: The S3EventNotification class does not work with messages routed \n through AWS EventBridge.", "\n     */ \n    static void processS3Events(String bucketName, String queueUrl, String \n queueArn) { \n        try { \n            // Configure the bucket to send Object Created and Object Tagging \n notifications to an existing SQS queue. \n            s3Client.putBucketNotificationConfiguration(b -> b \n                    .notificationConfiguration(ncb -> ncb \n                            .queueConfigurations(qcb -> qcb \n                                    .events(Event.S3_OBJECT_CREATED, \n Event.S3_OBJECT_TAGGING) \n                                    .queueArn(queueArn))) \n                            .bucket(bucketName) \n            ).join(); \nScenarios API Version 2006-03-01 2468Amazon Simple Storage Service API Reference\n            triggerS3EventNotifications(bucketName); \n            // Wait for event notifications to propagate.", "\n            Thread.sleep(Duration.ofSeconds(5).toMillis()); \n            boolean didReceiveMessages = true; \n            while (didReceiveMessages) { \n                // Display the number of messages that are available in the \n queue. \n                sqsClient.getQueueAttributes(b -> b \n                                .queueUrl(queueUrl) \n                                \n .attributeNames(QueueAttributeName.APPROXIMATE_NUMBER_OF_MESSAGES) \n                        ).thenAccept(attributeResponse -> \n                                logger.info(\"Approximate number of messages in \n the queue: {}\", \n                                        \n attributeResponse.attributes().get(QueueAttributeName.APPROXIMATE_NUMBER_OF_MESSAGES))) \n                        .join(); \n                // Receive the messages. \n                ReceiveMessageResponse response = sqsClient.receiveMessage(b -> b \n                        .queueUrl(queueUrl) \n                ).get(); \n                logger.info(\"Count of received messages: {}\", \n response.messages().size()); \n                didReceiveMessages = !response.messages().isEmpty(); \n                // Create a collection to hold the received message for deletion \n                // after we log the messages. \n                HashSet<DeleteMessageBatchRequestEntry> messagesToDelete = new \n HashSet<>(); \n                // Process each message.", "\n                response.messages().forEach(message -> { \n                    logger.info(\"Message id: {}\", message.messageId()); \n                    // Deserialize JSON message body to a S3EventNotification \n object \n                    // to access messages in an object-oriented way. \n                    S3EventNotification event = \n S3EventNotification.fromJson(message.body()); \n                    // Log the S3 event notification record details.", "\n                    if (event.getRecords() != null) { \n                        event.getRecords().forEach(record -> { \nScenarios API Version 2006-03-01 2469Amazon Simple Storage Service API Reference\n                            String eventName = record.getEventName(); \n                            String key = record.getS3().getObject().getKey(); \n                            logger.info(record.toString()); \n                            logger.info(\"Event name is {} and key is {}\", \n eventName, key); \n                        }); \n                    } \n                    // Add logged messages to collection for batch deletion.", "\n                    messagesToDelete.add(DeleteMessageBatchRequestEntry.builder() \n                            .id(message.messageId()) \n                            .receiptHandle(message.receiptHandle()) \n                            .build()); \n                }); \n                // Delete messages. \n                if (!messagesToDelete.isEmpty()) { \n                    \n sqsClient.deleteMessageBatch(DeleteMessageBatchRequest.builder() \n                            .queueUrl(queueUrl) \n                            .entries(messagesToDelete) \n                            .build() \n                    ).join(); \n                } \n            } // End of while block.", "\n        } catch (InterruptedException | ExecutionException e) { \n            throw new RuntimeException(e); \n        } \n    }\n\u2022For API details, see the following topics in AWS SDK for Java 2.x API Reference.\n\u2022DeleteMessageBatch\n\u2022GetQueueAttributes\n\u2022PutBucketNoti\ufb01cationCon\ufb01guration\n\u2022ReceiveMessage\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nScenarios API Version 2006-03-01 2470Amazon Simple Storage Service API Reference\nSave EXIF and other image information using an AWS SDK\nThe following code example shows how to:\n\u2022Get EXIF information from a a JPG, JPEG, or PNG \ufb01le.\n\u2022Upload the image \ufb01le to an Amazon S3 bucket.\n\u2022Use Amazon Rekognition to identify the three top attributes (labels) in the \ufb01le.\n\u2022Add the EXIF and label information to an Amazon DynamoDB table in the Region.\nRust\nSDK for Rust\nGet EXIF information from a JPG, JPEG, or PNG \ufb01le, upload the image \ufb01le to an Amazon \nS3 bucket, use Amazon Rekognition to identify the three top attributes (labels  in Amazon \nRekognition) in the \ufb01le, and add the EXIF and label information to a Amazon DynamoDB \ntable in the Region.\nFor complete source code and instructions on how to set up and run, see the full example on\nGitHub .\nServices used in this example\n\u2022DynamoDB\n\u2022Amazon Rekognition\n\u2022Amazon S3\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nSend S3 event noti\ufb01cations to Amazon EventBridge using an AWS SDK\nThe following code example shows how to enable a bucket to send S3 event noti\ufb01cations to \nEventBridge and route noti\ufb01cations to an Amazon SNS topic and Amazon SQS queue.\nScenarios API Version 2006-03-01 2471Amazon Simple Storage Service API Reference\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n    /** This method configures a bucket to send events to AWS EventBridge and \n creates a rule \n     * to route the S3 object created events to a topic and a queue. \n     * \n     * @param bucketName Name of existing bucket \n     * @param topicArn ARN of existing topic to receive S3 event notifications \n     * @param queueArn ARN of existing queue to receive S3 event notifications \n     * \n     *  An AWS CloudFormation stack sets up the bucket, queue, topic before the \n method runs. \n     */ \n    public static String setBucketNotificationToEventBridge(String bucketName, \n String topicArn, String queueArn) { \n        try { \n            // Enable bucket to emit S3 Event notifications to EventBridge. \n            s3Client.putBucketNotificationConfiguration(b -> b \n                    .bucket(bucketName) \n                    .notificationConfiguration(b1 -> b1 \n                            .eventBridgeConfiguration( \n                                    SdkBuilder::build) \n                    ).build()).join(); \n            // Create an EventBridge rule to route Object Created notifications. \n            PutRuleRequest putRuleRequest = PutRuleRequest.builder() \n                    .name(RULE_NAME) \n                    .eventPattern(\"\"\" \n                            { \n                              \"source\": [\"aws.s3\"], \n                              \"detail-type\": [\"Object Created\"], \n                              \"detail\": { \n                                \"bucket\": { \n                                  \"name\": [\"%s\"] \nScenarios API Version 2006-03-01 2472Amazon Simple Storage Service API Reference\n                                } \n                              } \n                            } \n                            \"\"\".formatted(bucketName)) \n                    .build(); \n            // Add the rule to the default event bus. \n            PutRuleResponse putRuleResponse = \n eventBridgeClient.putRule(putRuleRequest) \n                    .whenComplete((r, t) -> { \n                        if (t != null) { \n                            logger.error(\"Error creating event bus rule: \" + \n t.getMessage(), t); \n                            throw new RuntimeException(t.getCause().getMessage(), \n t); \n                        } \n                        logger.info(\"Event bus rule creation request sent \n successfully.", "ARN is: {}\", r.ruleArn()); \n                    }).join(); \n            // Add the existing SNS topic and SQS queue as targets to the rule.", "\n            eventBridgeClient.putTargets(b -> b \n                    .eventBusName(\"default\") \n                    .rule(RULE_NAME) \n                    .targets(List.of ( \n                            Target.builder() \n                                    .arn(queueArn) \n                                    .id(\"Queue\") \n                                    .build(), \n                            Target.builder() \n                                    .arn(topicArn) \n                                    .id(\"Topic\") \n                                    .build()) \n                            ) \n                    ).join(); \n            return putRuleResponse.ruleArn(); \n        } catch (S3Exception e) { \n            System.err.println(e.awsErrorDetails().errorMessage()); \n            System.exit(1); \n        } \n        return null; \n    }\nScenarios API Version 2006-03-01 2473Amazon Simple Storage Service API Reference\n\u2022For API details, see the following topics in AWS SDK for Java 2.x API Reference.\n\u2022PutBucketNoti\ufb01cationCon\ufb01guration\n\u2022PutRule\n\u2022PutTargets\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs.", "This topic also includes information about getting started and details \nabout previous SDK versions.\nTrack an Amazon S3 object upload or download using an AWS SDK\nThe following code example shows how to track an Amazon S3 object upload or download.\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nTrack the progress of a \ufb01le upload.\n    public void trackUploadFile(S3TransferManager transferManager, String \n bucketName, \n                             String key, URI filePathURI) { \n        UploadFileRequest uploadFileRequest = UploadFileRequest.builder() \n                .putObjectRequest(b -> b.bucket(bucketName).key(key)) \n                .addTransferListener(LoggingTransferListener.create())  // Add \n listener.", "\n                .source(Paths.get(filePathURI)) \n                .build(); \n        FileUpload fileUpload = transferManager.uploadFile(uploadFileRequest); \n        fileUpload.completionFuture().join(); \n        /* \nScenarios API Version 2006-03-01 2474Amazon Simple Storage Service API Reference\n            The SDK provides a LoggingTransferListener implementation of the \n TransferListener interface.", "\n            You can also implement the interface to provide your own logic.", "\n            Configure log4J2 with settings such as the following.", "\n                <Configuration status=\"WARN\"> \n                    <Appenders> \n                        <Console name=\"AlignedConsoleAppender\" \n target=\"SYSTEM_OUT\"> \n                            <PatternLayout pattern=\"%m%n\"/> \n                        </Console> \n                    </Appenders> \n                    <Loggers> \n                        <logger \n name=\"software.amazon.awssdk.transfer.s3.progress.LoggingTransferListener\" \n level=\"INFO\" additivity=\"false\"> \n                            <AppenderRef ref=\"AlignedConsoleAppender\"/> \n                        </logger> \n                    </Loggers> \n                </Configuration> \n            Log4J2 logs the progress.", "The following is example output for a 21.3 \n MB file upload.", "\n                Transfer initiated... \n                |                    | 0.0% \n                |====                | 21.1% \n                |============        | 60.5% \n                |====================| 100.0% \n                Transfer complete!", "\n        */ \n    }\nTrack the progress of a \ufb01le download.\n    public void trackDownloadFile(S3TransferManager transferManager, String \n bucketName, \n                             String key, String downloadedFileWithPath) { \n        DownloadFileRequest downloadFileRequest = DownloadFileRequest.builder() \n                .getObjectRequest(b -> b.bucket(bucketName).key(key)) \n                .addTransferListener(LoggingTransferListener.create())  // Add \n listener.", "\nScenarios API Version 2006-03-01 2475Amazon Simple Storage Service API Reference\n                .destination(Paths.get(downloadedFileWithPath)) \n                .build(); \n        FileDownload downloadFile = \n transferManager.downloadFile(downloadFileRequest); \n        CompletedFileDownload downloadResult = \n downloadFile.completionFuture().join(); \n        /* \n            The SDK provides a LoggingTransferListener implementation of the \n TransferListener interface.", "\n            You can also implement the interface to provide your own logic.", "\n            Configure log4J2 with settings such as the following.", "\n                <Configuration status=\"WARN\"> \n                    <Appenders> \n                        <Console name=\"AlignedConsoleAppender\" \n target=\"SYSTEM_OUT\"> \n                            <PatternLayout pattern=\"%m%n\"/> \n                        </Console> \n                    </Appenders> \n                    <Loggers> \n                        <logger \n name=\"software.amazon.awssdk.transfer.s3.progress.LoggingTransferListener\" \n level=\"INFO\" additivity=\"false\"> \n                            <AppenderRef ref=\"AlignedConsoleAppender\"/> \n                        </logger> \n                    </Loggers> \n                </Configuration> \n            Log4J2 logs the progress.", "The following is example output for a 21.3 \n MB file download.", "\n                Transfer initiated... \n                |=======             | 39.4% \n                |===============     | 78.8% \n                |====================| 100.0% \n                Transfer complete!", "\n        */ \n    }\n\u2022For API details, see the following topics in AWS SDK for Java 2.x API Reference.\nScenarios API Version 2006-03-01 2476Amazon Simple Storage Service API Reference\n\u2022GetObject\n\u2022PutObject\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nTransform data for your application with S3 Object Lambda\nThe following code example shows how to transform data for your application with S3 Object \nLambda.\n.NET\nAWS SDK for .NET\nShows how to add custom code to standard S3 GET requests to modify the requested object \nretrieved from S3 so that the object suit the needs of the requesting client or application.\nFor complete source code and instructions on how to set up and run, see the full example on\nGitHub .\nServices used in this example\n\u2022Lambda\n\u2022Amazon S3\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs.", "This topic also includes information about getting started and details \nabout previous SDK versions.\nExample approaches for unit and integration testing with an AWS SDK\nThe following code example shows how to examples for best-practice techniques when writing unit \nand integration tests using an AWS SDK.\nScenarios API Version 2006-03-01 2477Amazon Simple Storage Service API Reference\nRust\nSDK for Rust\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nCargo.toml for testing examples.\n[package]\nname = \"testing-examples\"\nversion = \"0.1.0\"\nauthors = [ \n  \"John Disanti <jdisanti@amazon.com>\", \n  \"Doug Schwartz <dougsch@amazon.com>\",\n]\nedition = \"2021\"\n[dependencies]\nasync-trait = \"0.1.51\"\naws-config = { version = \"1.0.1\", features = [\"behavior-version-latest\"] }\naws-credential-types = { version = \"1.0.1\", features = [ \"hardcoded-\ncredentials\", ] }\naws-sdk-s3 = { version = \"1.4.0\" }\naws-smithy-types = { version = \"1.0.1\" }\naws-smithy-runtime = { version = \"1.0.1\", features = [\"test-util\"] }\naws-smithy-runtime-api = { version = \"1.0.1\", features = [\"test-util\"] }\naws-types = { version = \"1.0.1\" }\nclap = { version = \"~4.4\", features = [\"derive\"] }\nhttp = \"0.2.9\"\nmockall = \"0.11.4\"\nserde_json = \"1\"\ntokio = { version = \"1.20.1\", features = [\"full\"] }\ntracing-subscriber = { version = \"0.3.15\", features = [\"env-filter\"] }\n[[bin]]\nname = \"main\"\npath = \"src/main.rs\"\nScenarios API Version 2006-03-01 2478Amazon Simple Storage Service API Reference\nUnit testing example using automock and a service wrapper.\nuse aws_sdk_s3 as s3;\n#[allow(unused_imports)]\nuse mockall::automock;\nuse s3::operation::list_objects_v2::{ListObjectsV2Error, ListObjectsV2Output};\n#[cfg(test)]\npub use MockS3Impl as S3;\n#[cfg(not(test))]\npub use S3Impl as S3;\n#[allow(dead_code)]\npub struct S3Impl { \n    inner: s3::Client,\n}\n#[cfg_attr(test, automock)]\nimpl S3Impl { \n    #[allow(dead_code)] \n    pub fn new(inner: s3::Client) -> Self { \n        Self { inner } \n    } \n    #[allow(dead_code)] \n    pub async fn list_objects( \n        &self, \n        bucket: &str, \n        prefix: &str, \n        continuation_token: Option<String>, \n    ) -> Result<ListObjectsV2Output, s3::error::SdkError<ListObjectsV2Error>> { \n        self.inner \n            .list_objects_v2() \n            .bucket(bucket) \n            .prefix(prefix) \n            .set_continuation_token(continuation_token) \n            .send() \n            .await \n    }\n}\n#[allow(dead_code)]\nScenarios API Version 2006-03-01 2479Amazon Simple Storage Service API Reference\npub async fn determine_prefix_file_size( \n    // Now we take a reference to our trait object instead of the S3 client \n    // s3_list: ListObjectsService, \n    s3_list: S3, \n    bucket: &str, \n    prefix: &str,\n) -> Result<usize, s3::Error> { \n    let mut next_token: Option<String> = None; \n    let mut total_size_bytes = 0; \n    loop { \n        let result = s3_list \n            .list_objects(bucket, prefix, next_token.take()) \n            .await?; \n        // Add up the file sizes we got back \n        for object in result.contents() { \n            total_size_bytes += object.size().unwrap_or(0) as usize; \n        } \n        // Handle pagination, and break the loop if there are no more pages \n        next_token = result.next_continuation_token.clone(); \n        if next_token.is_none() { \n            break; \n        } \n    } \n    Ok(total_size_bytes)\n}\n#[cfg(test)]\nmod test { \n    use super::*; \n    use mockall::predicate::eq; \n    #[tokio::test] \n    async fn test_single_page() { \n        let mut mock = MockS3Impl::default(); \n        mock.expect_list_objects() \n            .with(eq(\"test-bucket\"), eq(\"test-prefix\"), eq(None)) \n            .return_once(|_, _, _| { \n                Ok(ListObjectsV2Output::builder() \n                    .set_contents(Some(vec![ \n                        // Mock content for ListObjectsV2 response \n                        s3::types::Object::builder().size(5).build(), \n                        s3::types::Object::builder().size(2).build(), \nScenarios API Version 2006-03-01 2480Amazon Simple Storage Service API Reference\n                    ])) \n                    .build()) \n            }); \n        // Run the code we want to test with it \n        let size = determine_prefix_file_size(mock, \"test-bucket\", \"test-prefix\") \n            .await \n            .unwrap(); \n        // Verify we got the correct total size back \n        assert_eq!(7, size); \n    } \n    #[tokio::test] \n    async fn test_multiple_pages() { \n        // Create the Mock instance with two pages of objects now \n        let mut mock = MockS3Impl::default(); \n        mock.expect_list_objects() \n            .with(eq(\"test-bucket\"), eq(\"test-prefix\"), eq(None)) \n            .return_once(|_, _, _| { \n                Ok(ListObjectsV2Output::builder() \n                    .set_contents(Some(vec![ \n                        // Mock content for ListObjectsV2 response \n                        s3::types::Object::builder().size(5).build(), \n                        s3::types::Object::builder().size(2).build(), \n                    ])) \n                    .set_next_continuation_token(Some(\"next\".to_string())) \n                    .build()) \n            }); \n        mock.expect_list_objects() \n            .with( \n                eq(\"test-bucket\"), \n                eq(\"test-prefix\"), \n                eq(Some(\"next\".to_string())), \n            ) \n            .return_once(|_, _, _| { \n                Ok(ListObjectsV2Output::builder() \n                    .set_contents(Some(vec![ \n                        // Mock content for ListObjectsV2 response \n                        s3::types::Object::builder().size(3).build(), \n                        s3::types::Object::builder().size(9).build(), \n                    ])) \n                    .build()) \n            }); \nScenarios API Version 2006-03-01 2481Amazon Simple Storage Service API Reference\n        // Run the code we want to test with it \n        let size = determine_prefix_file_size(mock, \"test-bucket\", \"test-prefix\") \n            .await \n            .unwrap(); \n        assert_eq!(19, size); \n    }\n}\nIntegration testing example using StaticReplayClient.\nuse aws_sdk_s3 as s3;\n#[allow(dead_code)]\npub async fn determine_prefix_file_size( \n    // Now we take a reference to our trait object instead of the S3 client \n    // s3_list: ListObjectsService, \n    s3: s3::Client, \n    bucket: &str, \n    prefix: &str,\n) -> Result<usize, s3::Error> { \n    let mut next_token: Option<String> = None; \n    let mut total_size_bytes = 0; \n    loop { \n        let result = s3 \n            .list_objects_v2() \n            .prefix(prefix) \n            .bucket(bucket) \n            .set_continuation_token(next_token.take()) \n            .send() \n            .await?; \n        // Add up the file sizes we got back \n        for object in result.contents() { \n            total_size_bytes += object.size().unwrap_or(0) as usize; \n        } \n        // Handle pagination, and break the loop if there are no more pages \n        next_token = result.next_continuation_token.clone(); \n        if next_token.is_none() { \nScenarios API Version 2006-03-01 2482Amazon Simple Storage Service API Reference\n            break; \n        } \n    } \n    Ok(total_size_bytes)\n}\n#[allow(dead_code)]\nfn make_s3_test_credentials() -> s3::config::Credentials { \n    s3::config::Credentials::new( \n        \"ATESTCLIENT\", \n        \"astestsecretkey\", \n        Some(\"atestsessiontoken\".to_string()), \n        None, \n        \"\", \n    )\n}\n#[cfg(test)]\nmod test { \n    use super::*; \n    use aws_config::BehaviorVersion; \n    use aws_sdk_s3 as s3; \n    use aws_smithy_runtime::client::http::test_util::{ReplayEvent, \n StaticReplayClient}; \n    use aws_smithy_types::body::SdkBody; \n    #[tokio::test] \n    async fn test_single_page() { \n        let page_1 = ReplayEvent::new( \n                http::Request::builder() \n                    .method(\"GET\") \n                    .uri(\"https://test-bucket.s3.us-east-1.amazonaws.com/?list-\ntype=2&prefix=test-prefix\") \n                    .body(SdkBody::empty()) \n                    .unwrap(), \n                http::Response::builder() \n                    .status(200) \n                    .body(SdkBody::from(include_str!(\"./testing/\nresponse_1.xml\"))) \n                    .unwrap(), \n            ); \n        let replay_client = StaticReplayClient::new(vec![page_1]); \n        let client: s3::Client = s3::Client::from_conf( \n            s3::Config::builder() \nScenarios API Version 2006-03-01 2483Amazon Simple Storage Service API Reference\n                .behavior_version(BehaviorVersion::latest()) \n                .credentials_provider(make_s3_test_credentials()) \n                .region(s3::config::Region::new(\"us-east-1\")) \n                .http_client(replay_client.clone()) \n                .build(), \n        ); \n        // Run the code we want to test with it \n        let size = determine_prefix_file_size(client, \"test-bucket\", \"test-\nprefix\") \n            .await \n            .unwrap(); \n        // Verify we got the correct total size back \n        assert_eq!(7, size); \n        replay_client.assert_requests_match(&[]); \n    } \n    #[tokio::test] \n    async fn test_multiple_pages() { \n        let page_1 = ReplayEvent::new( \n                http::Request::builder() \n                    .method(\"GET\") \n                    .uri(\"https://test-bucket.s3.us-east-1.amazonaws.com/?list-\ntype=2&prefix=test-prefix\") \n                    .body(SdkBody::empty()) \n                    .unwrap(), \n                http::Response::builder() \n                    .status(200) \n                    .body(SdkBody::from(include_str!(\"./testing/\nresponse_multi_1.xml\"))) \n                    .unwrap(), \n            ); \n        let page_2 = ReplayEvent::new( \n                http::Request::builder() \n                    .method(\"GET\") \n                    .uri(\"https://test-bucket.s3.us-east-1.amazonaws.com/?list-\ntype=2&prefix=test-prefix&continuation-token=next\") \n                    .body(SdkBody::empty()) \n                    .unwrap(), \n                http::Response::builder() \n                    .status(200) \n                    .body(SdkBody::from(include_str!(\"./testing/\nresponse_multi_2.xml\"))) \nScenarios API Version 2006-03-01 2484Amazon Simple Storage Service API Reference\n                    .unwrap(), \n            ); \n        let replay_client = StaticReplayClient::new(vec![page_1, page_2]); \n        let client: s3::Client = s3::Client::from_conf( \n            s3::Config::builder() \n                .behavior_version(BehaviorVersion::latest()) \n                .credentials_provider(make_s3_test_credentials()) \n                .region(s3::config::Region::new(\"us-east-1\")) \n                .http_client(replay_client.clone()) \n                .build(), \n        ); \n        // Run the code we want to test with it \n        let size = determine_prefix_file_size(client, \"test-bucket\", \"test-\nprefix\") \n            .await \n            .unwrap(); \n        assert_eq!(19, size); \n        replay_client.assert_requests_match(&[]); \n    }\n}\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs.", "This topic also includes information about getting started and details \nabout previous SDK versions.\nRecursively upload a local directory to an Amazon Simple Storage Service \n(Amazon S3) bucket\nThe following code example shows how to upload a local directory recursively to an Amazon \nSimple Storage Service (Amazon S3) bucket.\nScenarios API Version 2006-03-01 2485Amazon Simple Storage Service API Reference\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nUse an S3TransferManager to upload a local directory. View the complete \ufb01le and test.\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\nimport software.amazon.awssdk.services.s3.model.ObjectIdentifier;\nimport software.amazon.awssdk.transfer.s3.S3TransferManager;\nimport software.amazon.awssdk.transfer.s3.model.CompletedDirectoryUpload;\nimport software.amazon.awssdk.transfer.s3.model.DirectoryUpload;\nimport software.amazon.awssdk.transfer.s3.model.UploadDirectoryRequest;\nimport java.net.URI;\nimport java.net.URISyntaxException;\nimport java.net.URL;\nimport java.nio.file.Paths;\nimport java.util.UUID; \n    public Integer uploadDirectory(S3TransferManager transferManager, \n            URI sourceDirectory, String bucketName) { \n        DirectoryUpload directoryUpload = \n transferManager.uploadDirectory(UploadDirectoryRequest.builder() \n                .source(Paths.get(sourceDirectory)) \n                .bucket(bucketName) \n                .build()); \n        CompletedDirectoryUpload completedDirectoryUpload = \n directoryUpload.completionFuture().join(); \n        completedDirectoryUpload.failedTransfers() \n                .forEach(fail -> logger.warn(\"Object [{}] failed to transfer\", \n fail.toString())); \n        return completedDirectoryUpload.failedTransfers().size(); \n    }\nScenarios API Version 2006-03-01 2486Amazon Simple Storage Service API Reference\n\u2022For API details, see UploadDirectory in AWS SDK for Java 2.x API Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nUpload or download large \ufb01les to and from Amazon S3 using an AWS SDK\nThe following code examples show how to upload or download large \ufb01les to and from Amazon S3.\nFor more information, see Uploading an object using multipart upload.\n.NET\nAWS SDK for .NET\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nCall functions that transfer \ufb01les to and from an S3 bucket using the Amazon S3 \nTransferUtility.\nglobal using System.Text;\nglobal using Amazon.S3;\nglobal using Amazon.S3.Model;\nglobal using Amazon.S3.Transfer;\nglobal using TransferUtilityBasics;\n// This Amazon S3 client uses the default user credentials\n// defined for this computer.\nusing Microsoft.Extensions.Configuration;\nIAmazonS3 client = new AmazonS3Client();\nvar transferUtil = new TransferUtility(client);\nIConfiguration _configuration;\n_configuration = new ConfigurationBuilder() \nScenarios API Version 2006-03-01 2487Amazon Simple Storage Service API Reference\n    .SetBasePath(Directory.GetCurrentDirectory()) \n    .AddJsonFile(\"settings.json\") // Load test settings from JSON file.", "\n    .AddJsonFile(\"settings.local.json\", \n        true) // Optionally load local settings.", "\n    .Build();\n// Edit the values in settings.json to use an S3 bucket and files that\n// exist on your AWS account and on the local computer where you\n// run this scenario.\nvar bucketName = _configuration[\"BucketName\"];\nvar localPath = \n $\"{Environment.GetFolderPath(Environment.SpecialFolder.ApplicationData)}\\\n\\TransferFolder\";\nDisplayInstructions();\nPressEnter();\nConsole.WriteLine();\n// Upload a single file to an S3 bucket.\nDisplayTitle(\"Upload a single file\");\nvar fileToUpload = _configuration[\"FileToUpload\"];\nConsole.WriteLine($\"Uploading {fileToUpload} to the S3 bucket, {bucketName}.\");\nvar success = await TransferMethods.UploadSingleFileAsync(transferUtil, \n bucketName, fileToUpload, localPath);\nif (success)\n{ \n    Console.WriteLine($\"Successfully uploaded the file, {fileToUpload} to \n {bucketName}.\");\n}\nPressEnter();\n// Upload a local directory to an S3 bucket.\nDisplayTitle(\"Upload all files from a local directory\");\nConsole.WriteLine(\"Upload all the files in a local folder to an S3 bucket.\");\nconst string keyPrefix = \"UploadFolder\";\nvar uploadPath = $\"{localPath}\\\\UploadFolder\";\nConsole.WriteLine($\"Uploading the files in {uploadPath} to {bucketName}\");\nDisplayTitle($\"{uploadPath} files\");\nScenarios API Version 2006-03-01 2488Amazon Simple Storage Service API Reference\nDisplayLocalFiles(uploadPath);\nConsole.WriteLine();\nPressEnter();\nsuccess = await TransferMethods.UploadFullDirectoryAsync(transferUtil, \n bucketName, keyPrefix, uploadPath);\nif (success)\n{ \n    Console.WriteLine($\"Successfully uploaded the files in {uploadPath} to \n {bucketName}.\"); \n    Console.WriteLine($\"{bucketName} currently contains the following files:\"); \n    await DisplayBucketFiles(client, bucketName, keyPrefix); \n    Console.WriteLine();\n}\nPressEnter();\n// Download a single file from an S3 bucket.\nDisplayTitle(\"Download a single file\");\nConsole.WriteLine(\"Now we will download a single file from an S3 bucket.\");\nvar keyName = _configuration[\"FileToDownload\"];\nConsole.WriteLine($\"Downloading {keyName} from {bucketName}.\");\nsuccess = await TransferMethods.DownloadSingleFileAsync(transferUtil, bucketName, \n keyName, localPath);\nif (success)\n{ \n    Console.WriteLine(\"$Successfully downloaded the file, {keyName} from \n {bucketName}.\");\n}\nPressEnter();\n// Download the contents of a directory from an S3 bucket.\nDisplayTitle(\"Download the contents of an S3 bucket\");\nvar s3Path = _configuration[\"S3Path\"];\nvar downloadPath = $\"{localPath}\\\\{s3Path}\";\nConsole.WriteLine($\"Downloading the contents of {bucketName}\\\\{s3Path}\");\nConsole.WriteLine($\"{bucketName}\\\\{s3Path} contains the following files:\");\nawait DisplayBucketFiles(client, bucketName, s3Path);\nScenarios API Version 2006-03-01 2489Amazon Simple Storage Service API Reference\nConsole.WriteLine();\nsuccess = await TransferMethods.DownloadS3DirectoryAsync(transferUtil, \n bucketName, s3Path, downloadPath);\nif (success)\n{ \n    Console.WriteLine($\"Downloaded the files in {bucketName} to \n {downloadPath}.\"); \n    Console.WriteLine($\"{downloadPath} now contains the following files:\"); \n    DisplayLocalFiles(downloadPath);\n}\nConsole.WriteLine(\"\\nThe TransferUtility Basics application has completed.\");\nPressEnter();\n// Displays the title for a section of the scenario.\nstatic void DisplayTitle(string titleText)\n{ \n    var sepBar = new string('-', Console.WindowWidth); \n    Console.WriteLine(sepBar); \n    Console.WriteLine(CenterText(titleText)); \n    Console.WriteLine(sepBar);\n}\n// Displays a description of the actions to be performed by the scenario.\nstatic void DisplayInstructions()\n{ \n    var sepBar = new string('-', Console.WindowWidth); \n    DisplayTitle(\"Amazon S3 Transfer Utility Basics\"); \n    Console.WriteLine(\"This program shows how to use the Amazon S3 Transfer \n Utility.\"); \n    Console.WriteLine(\"It performs the following actions:\"); \n    Console.WriteLine(\"\\t1. Upload a single object to an S3 bucket.\"); \n    Console.WriteLine(\"\\t2. Upload an entire directory from the local computer to \n an\\n\\t  S3 bucket.\"); \n    Console.WriteLine(\"\\t3. Download a single object from an S3 bucket.\"); \n    Console.WriteLine(\"\\t4. Download the objects in an S3 bucket to a local \n directory.\"); \n    Console.WriteLine($\"\\n{sepBar}\");\n}\n// Pauses the scenario.\nScenarios API Version 2006-03-01 2490Amazon Simple Storage Service API Reference\nstatic void PressEnter()\n{ \n    Console.WriteLine(\"Press <Enter> to continue.\"); \n    _ = Console.ReadLine(); \n    Console.WriteLine(\"\\n\");\n}\n// Returns the string textToCenter, padded on the left with spaces\n// that center the text on the console display.\nstatic string CenterText(string textToCenter)\n{ \n    var centeredText = new StringBuilder(); \n    var screenWidth = Console.WindowWidth; \n    centeredText.Append(new string(' ', (int)(screenWidth - \n textToCenter.Length) / 2)); \n    centeredText.Append(textToCenter); \n    return centeredText.ToString();\n}\n// Displays a list of file names included in the specified path.\nstatic void DisplayLocalFiles(string localPath)\n{ \n    var fileList = Directory.GetFiles(localPath); \n    if (fileList.Length > 0) \n    { \n        foreach (var fileName in fileList) \n        { \n            Console.WriteLine(fileName); \n        } \n    }\n}\n// Displays a list of the files in the specified S3 bucket and prefix.\nstatic async Task DisplayBucketFiles(IAmazonS3 client, string bucketName, string \n s3Path)\n{ \n    ListObjectsV2Request request = new() \n    { \n        BucketName = bucketName, \n        Prefix = s3Path, \n        MaxKeys = 5, \n    }; \n    var response = new ListObjectsV2Response(); \nScenarios API Version 2006-03-01 2491Amazon Simple Storage Service API Reference\n    do \n    { \n        response = await client.ListObjectsV2Async(request); \n        response.S3Objects \n            .ForEach(obj => Console.WriteLine($\"{obj.Key}\")); \n        // If the response is truncated, set the request ContinuationToken \n        // from the NextContinuationToken property of the response. \n        request.ContinuationToken = response.NextContinuationToken; \n    } while (response.IsTruncated);\n}\nUpload a single \ufb01le.\n        /// <summary> \n        /// Uploads a single file from the local computer to an S3 bucket. \n        /// </summary> \n        /// <param name=\"transferUtil\">The transfer initialized TransferUtility \n        /// object.</param> \n        /// <param name=\"bucketName\">The name of the S3 bucket where the file \n        /// will be stored.</param> \n        /// <param name=\"fileName\">The name of the file to upload.</param> \n        /// <param name=\"localPath\">The local path where the file is stored.</\nparam> \n        /// <returns>A boolean value indicating the success of the action.</\nreturns> \n        public static async Task<bool> UploadSingleFileAsync( \n            TransferUtility transferUtil, \n            string bucketName, \n            string fileName, \n            string localPath) \n        { \n            if (File.Exists($\"{localPath}\\\\{fileName}\")) \n            { \n                try \n                { \n                    await transferUtil.UploadAsync(new \n TransferUtilityUploadRequest \nScenarios API Version 2006-03-01 2492Amazon Simple Storage Service API Reference\n                    { \n                        BucketName = bucketName, \n                        Key = fileName, \n                        FilePath = $\"{localPath}\\\\{fileName}\", \n                    }); \n                    return true; \n                } \n                catch (AmazonS3Exception s3Ex) \n                { \n                    Console.WriteLine($\"Could not upload {fileName} from \n {localPath} because:\"); \n                    Console.WriteLine(s3Ex.Message); \n                    return false; \n                } \n            } \n            else \n            { \n                Console.WriteLine($\"{fileName} does not exist in {localPath}\"); \n                return false; \n            } \n        }\nUpload an entire local directory.\n        /// <summary> \n        /// Uploads all the files in a local directory to a directory in an S3 \n        /// bucket. \n        /// </summary> \n        /// <param name=\"transferUtil\">The transfer initialized TransferUtility \n        /// object.</param> \n        /// <param name=\"bucketName\">The name of the S3 bucket where the files \n        /// will be stored.</param> \n        /// <param name=\"keyPrefix\">The key prefix is the S3 directory where \n        /// the files will be stored.</param> \n        /// <param name=\"localPath\">The local directory that contains the files \n        /// to be uploaded.</param> \n        /// <returns>A Boolean value representing the success of the action.</\nreturns> \n        public static async Task<bool> UploadFullDirectoryAsync( \n            TransferUtility transferUtil, \nScenarios API Version 2006-03-01 2493Amazon Simple Storage Service API Reference\n            string bucketName, \n            string keyPrefix, \n            string localPath) \n        { \n            if (Directory.Exists(localPath)) \n            { \n                try \n                { \n                    await transferUtil.UploadDirectoryAsync(new \n TransferUtilityUploadDirectoryRequest \n                    { \n                        BucketName = bucketName, \n                        KeyPrefix = keyPrefix, \n                        Directory = localPath, \n                    }); \n                    return true; \n                } \n                catch (AmazonS3Exception s3Ex) \n                { \n                    Console.WriteLine($\"Can't upload the contents of {localPath} \n because:\"); \n                    Console.WriteLine(s3Ex?.Message); \n                    return false; \n                } \n            } \n            else \n            { \n                Console.WriteLine($\"The directory {localPath} does not exist.\"); \n                return false; \n            } \n        }\nDownload a single \ufb01le.\n        /// <summary> \n        /// Download a single file from an S3 bucket to the local computer. \n        /// </summary> \n        /// <param name=\"transferUtil\">The transfer initialized TransferUtility \n        /// object.</param> \nScenarios API Version 2006-03-01 2494Amazon Simple Storage Service API Reference\n        /// <param name=\"bucketName\">The name of the S3 bucket containing the \n        /// file to download.</param> \n        /// <param name=\"keyName\">The name of the file to download.</param> \n        /// <param name=\"localPath\">The path on the local computer where the \n        /// downloaded file will be saved.</param> \n        /// <returns>A Boolean value indicating the results of the action.</\nreturns> \n        public static async Task<bool> DownloadSingleFileAsync( \n        TransferUtility transferUtil, \n            string bucketName, \n            string keyName, \n            string localPath) \n        { \n            await transferUtil.DownloadAsync(new TransferUtilityDownloadRequest \n            { \n                BucketName = bucketName, \n                Key = keyName, \n                FilePath = $\"{localPath}\\\\{keyName}\", \n            }); \n            return (File.Exists($\"{localPath}\\\\{keyName}\")); \n        }\nDownload contents of an S3 bucket.\n        /// <summary> \n        /// Downloads the contents of a directory in an S3 bucket to a \n        /// directory on the local computer. \n        /// </summary> \n        /// <param name=\"transferUtil\">The transfer initialized TransferUtility \n        /// object.</param> \n        /// <param name=\"bucketName\">The bucket containing the files to \n download.</param> \n        /// <param name=\"s3Path\">The S3 directory where the files are located.</\nparam> \n        /// <param name=\"localPath\">The local path to which the files will be \n        /// saved.</param> \n        /// <returns>A Boolean value representing the success of the action.</\nreturns> \n        public static async Task<bool> DownloadS3DirectoryAsync( \nScenarios API Version 2006-03-01 2495Amazon Simple Storage Service API Reference\n            TransferUtility transferUtil, \n            string bucketName, \n            string s3Path, \n            string localPath) \n        { \n            int fileCount = 0; \n            // If the directory doesn't exist, it will be created. \n            if (Directory.Exists(s3Path)) \n            { \n                var files = Directory.GetFiles(localPath); \n                fileCount = files.Length; \n            } \n            await transferUtil.DownloadDirectoryAsync(new \n TransferUtilityDownloadDirectoryRequest \n            { \n                BucketName = bucketName, \n                LocalDirectory = localPath, \n                S3Directory = s3Path, \n            }); \n            if (Directory.Exists(localPath)) \n            { \n                var files = Directory.GetFiles(localPath); \n                if (files.Length > fileCount) \n                { \n                    return true; \n                } \n                // No change in the number of files.", "Assume \n                // the download failed.", "\n                return false; \n            } \n            // The local directory doesn't exist.", "No files \n            // were downloaded.", "\n            return false; \n        }\nTrack the progress of an upload using the TransferUtility.\nScenarios API Version 2006-03-01 2496Amazon Simple Storage Service API Reference\n    using System; \n    using System.Threading.Tasks; \n    using Amazon.S3; \n    using Amazon.S3.Transfer; \n    /// <summary> \n    /// This example shows how to track the progress of a multipart upload \n    /// using the Amazon Simple Storage Service (Amazon S3) TransferUtility to \n    /// upload to an Amazon S3 bucket. \n    /// </summary> \n    public class TrackMPUUsingHighLevelAPI \n    { \n        public static async Task Main() \n        { \n            string bucketName = \"amzn-s3-demo-bucket\"; \n            string keyName = \"sample_pic.png\"; \n            string path = \"filepath/directory/\"; \n            string filePath = $\"{path}{keyName}\"; \n            // If the AWS Region defined for your default user is different \n            // from the Region where your Amazon S3 bucket is located, \n            // pass the Region name to the Amazon S3 client object's constructor.", "\n            // For example: RegionEndpoint.USWest2 or RegionEndpoint.USEast2.", "\n            IAmazonS3 client = new AmazonS3Client(); \n            await TrackMPUAsync(client, bucketName, filePath, keyName); \n        } \n        /// <summary> \n        /// Starts an Amazon S3 multipart upload and assigns an event handler to \n        /// track the progress of the upload. \n        /// </summary> \n        /// <param name=\"client\">The initialized Amazon S3 client object used to \n        /// perform the multipart upload.</param> \n        /// <param name=\"bucketName\">The name of the bucket to which to upload \n        /// the file.</param> \n        /// <param name=\"filePath\">The path, including the file name of the \n        /// file to be uploaded to the Amazon S3 bucket.</param> \n        /// <param name=\"keyName\">The file name to be used in the \n        /// destination Amazon S3 bucket.</param> \n        public static async Task TrackMPUAsync( \n            IAmazonS3 client, \n            string bucketName, \nScenarios API Version 2006-03-01 2497Amazon Simple Storage Service API Reference\n            string filePath, \n            string keyName) \n        { \n            try \n            { \n                var fileTransferUtility = new TransferUtility(client); \n                // Use TransferUtilityUploadRequest to configure options.", "\n                // In this example we subscribe to an event.", "\n                var uploadRequest = \n                    new TransferUtilityUploadRequest \n                    { \n                        BucketName = bucketName, \n                        FilePath = filePath, \n                        Key = keyName, \n                    }; \n                uploadRequest.UploadProgressEvent += \n                    new EventHandler<UploadProgressArgs>( \n                        UploadRequest_UploadPartProgressEvent); \n                await fileTransferUtility.UploadAsync(uploadRequest); \n                Console.WriteLine(\"Upload completed\"); \n            } \n            catch (AmazonS3Exception ex) \n            { \n                Console.WriteLine($\"Error:: {ex.Message}\"); \n            } \n        } \n        /// <summary> \n        /// Event handler to check the progress of the multipart upload. \n        /// </summary> \n        /// <param name=\"sender\">The object that raised the event.</param> \n        /// <param name=\"e\">The object that contains multipart upload \n        /// information.</param> \n        public static void UploadRequest_UploadPartProgressEvent(object sender, \n UploadProgressArgs e) \n        { \n            // Process event.", "\n            Console.WriteLine($\"{e.TransferredBytes}/{e.TotalBytes}\"); \n        } \n    }\nScenarios API Version 2006-03-01 2498Amazon Simple Storage Service API Reference\nUpload an object with encryption.\n    using System; \n    using System.Collections.Generic; \n    using System.IO; \n    using System.Security.Cryptography; \n    using System.Threading.Tasks; \n    using Amazon.S3; \n    using Amazon.S3.Model; \n    /// <summary> \n    /// Uses the Amazon Simple Storage Service (Amazon S3) low level API to \n    /// perform a multipart upload to an Amazon S3 bucket. \n    /// </summary> \n    public class SSECLowLevelMPUcopyObject \n    { \n        public static async Task Main() \n        { \n            string existingBucketName = \"amzn-s3-demo-bucket\"; \n            string sourceKeyName = \"sample_file.txt\"; \n            string targetKeyName = \"sample_file_copy.txt\"; \n            string filePath = $\"sample\\\\{targetKeyName}\"; \n            // If the AWS Region defined for your default user is different \n            // from the Region where your Amazon S3 bucket is located, \n            // pass the Region name to the Amazon S3 client object's constructor.", "\n            // For example: RegionEndpoint.USEast1.", "\n            IAmazonS3 client = new AmazonS3Client(); \n            // Create the encryption key.", "\n            var base64Key = CreateEncryptionKey(); \n            await CreateSampleObjUsingClientEncryptionKeyAsync( \n                client, \n                existingBucketName, \n                sourceKeyName, \n                filePath, \n                base64Key); \n        } \n        /// <summary> \nScenarios API Version 2006-03-01 2499Amazon Simple Storage Service API Reference\n        /// Creates the encryption key to use with the multipart upload. \n        /// </summary> \n        /// <returns>A string containing the base64-encoded key for encrypting \n        /// the multipart upload.</returns> \n        public static string CreateEncryptionKey() \n        { \n            Aes aesEncryption = Aes.Create(); \n            aesEncryption.KeySize = 256; \n            aesEncryption.GenerateKey(); \n            string base64Key = Convert.ToBase64String(aesEncryption.Key); \n            return base64Key; \n        } \n        /// <summary> \n        /// Creates and uploads an object using a multipart upload. \n        /// </summary> \n        /// <param name=\"client\">The initialized Amazon S3 object used to \n        /// initialize and perform the multipart upload.</param> \n        /// <param name=\"existingBucketName\">The name of the bucket to which \n        /// the object will be uploaded.</param> \n        /// <param name=\"sourceKeyName\">The source object name.</param> \n        /// <param name=\"filePath\">The location of the source object.</param> \n        /// <param name=\"base64Key\">The encryption key to use with the upload.</\nparam> \n        public static async Task CreateSampleObjUsingClientEncryptionKeyAsync( \n            IAmazonS3 client, \n            string existingBucketName, \n            string sourceKeyName, \n            string filePath, \n            string base64Key) \n        { \n            List<UploadPartResponse> uploadResponses = new \n List<UploadPartResponse>(); \n            InitiateMultipartUploadRequest initiateRequest = new \n InitiateMultipartUploadRequest \n            { \n                BucketName = existingBucketName, \n                Key = sourceKeyName, \n                ServerSideEncryptionCustomerMethod = \n ServerSideEncryptionCustomerMethod.AES256, \n                ServerSideEncryptionCustomerProvidedKey = base64Key, \n            }; \nScenarios API Version 2006-03-01 2500Amazon Simple Storage Service API Reference\n            InitiateMultipartUploadResponse initResponse = \n               await client.InitiateMultipartUploadAsync(initiateRequest); \n            long contentLength = new FileInfo(filePath).Length; \n            long partSize = 5 * (long)Math.Pow(2, 20); // 5 MB \n            try \n            { \n                long filePosition = 0; \n                for (int i = 1; filePosition < contentLength; i++) \n                { \n                    UploadPartRequest uploadRequest = new UploadPartRequest \n                    { \n                        BucketName = existingBucketName, \n                        Key = sourceKeyName, \n                        UploadId = initResponse.UploadId, \n                        PartNumber = i, \n                        PartSize = partSize, \n                        FilePosition = filePosition, \n                        FilePath = filePath, \n                        ServerSideEncryptionCustomerMethod = \n ServerSideEncryptionCustomerMethod.AES256, \n                        ServerSideEncryptionCustomerProvidedKey = base64Key, \n                    }; \n                    // Upload part and add response to our list. \n                    uploadResponses.Add(await \n client.UploadPartAsync(uploadRequest)); \n                    filePosition += partSize; \n                } \n                CompleteMultipartUploadRequest completeRequest = new \n CompleteMultipartUploadRequest \n                { \n                    BucketName = existingBucketName, \n                    Key = sourceKeyName, \n                    UploadId = initResponse.UploadId, \n                }; \n                completeRequest.AddPartETags(uploadResponses); \n                CompleteMultipartUploadResponse completeUploadResponse = \n                    await client.CompleteMultipartUploadAsync(completeRequest); \n            } \nScenarios API Version 2006-03-01 2501Amazon Simple Storage Service API Reference\n            catch (Exception exception) \n            { \n                Console.WriteLine($\"Exception occurred: {exception.Message}\"); \n                // If there was an error, abort the multipart upload. \n                AbortMultipartUploadRequest abortMPURequest = new \n AbortMultipartUploadRequest \n                { \n                    BucketName = existingBucketName, \n                    Key = sourceKeyName, \n                    UploadId = initResponse.UploadId, \n                }; \n                await client.AbortMultipartUploadAsync(abortMPURequest); \n            } \n        } \n    }\nGo\nSDK for Go V2\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nUpload a large object by using an upload manager to break the data into parts and upload \nthem concurrently.\n// BucketBasics encapsulates the Amazon Simple Storage Service (Amazon S3) \n actions\n// used in the examples.\n// It contains S3Client, an Amazon S3 service client that is used to perform \n bucket\n// and object actions.\ntype BucketBasics struct { \nScenarios API Version 2006-03-01 2502Amazon Simple Storage Service API Reference\n S3Client *s3.Client\n}\n// UploadLargeObject uses an upload manager to upload data to an object in a \n bucket.\n// The upload manager breaks large data into parts and uploads the parts \n concurrently.\nfunc (basics BucketBasics) UploadLargeObject(ctx context.Context, bucketName \n string, objectKey string, largeObject []byte) error { \n largeBuffer := bytes.NewReader(largeObject) \n var partMiBs int64 = 10 \n uploader := manager.NewUploader(basics.S3Client, func(u *manager.Uploader) { \n  u.PartSize = partMiBs * 1024 * 1024 \n }) \n _, err := uploader.Upload(ctx, &s3.PutObjectInput{ \n  Bucket: aws.String(bucketName), \n  Key:    aws.String(objectKey), \n  Body:   largeBuffer, \n }) \n if err != nil { \n  log.Printf(\"Couldn't upload large object to %v:%v. Here's why: %v\\n\", \n   bucketName, objectKey, err) \n } \n return err\n}\nDownload a large object by using a download manager to get the data in parts and \ndownload them concurrently.\n// DownloadLargeObject uses a download manager to download an object from a \n bucket.\n// The download manager gets the data in parts and writes them to a buffer until \n all of\n// the data has been downloaded.\nfunc (basics BucketBasics) DownloadLargeObject(ctx context.Context, bucketName \n string, objectKey string) ([]byte, error) { \n var partMiBs int64 = 10 \nScenarios API Version 2006-03-01 2503Amazon Simple Storage Service API Reference\n downloader := manager.NewDownloader(basics.S3Client, func(d *manager.Downloader) \n { \n  d.PartSize = partMiBs * 1024 * 1024 \n }) \n buffer := manager.NewWriteAtBuffer([]byte{}) \n _, err := downloader.Download(ctx, buffer, &s3.GetObjectInput{ \n  Bucket: aws.String(bucketName), \n  Key:    aws.String(objectKey), \n }) \n if err != nil { \n  log.Printf(\"Couldn't download large object from %v:%v. Here's why: %v\\n\", \n   bucketName, objectKey, err) \n } \n return buffer.Bytes(), err\n}\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nCall functions that transfer \ufb01les to and from an S3 bucket using the S3TransferManager.\n    public Integer downloadObjectsToDirectory(S3TransferManager transferManager, \n            URI destinationPathURI, String bucketName) { \n        DirectoryDownload directoryDownload = \n transferManager.downloadDirectory(DownloadDirectoryRequest.builder() \n                .destination(Paths.get(destinationPathURI)) \n                .bucket(bucketName) \n                .build()); \n        CompletedDirectoryDownload completedDirectoryDownload = \n directoryDownload.completionFuture().join(); \n        completedDirectoryDownload.failedTransfers() \nScenarios API Version 2006-03-01 2504Amazon Simple Storage Service API Reference\n                .forEach(fail -> logger.warn(\"Object [{}] failed to transfer\", \n fail.toString())); \n        return completedDirectoryDownload.failedTransfers().size(); \n    }\nUpload an entire local directory.\n    public Integer uploadDirectory(S3TransferManager transferManager, \n            URI sourceDirectory, String bucketName) { \n        DirectoryUpload directoryUpload = \n transferManager.uploadDirectory(UploadDirectoryRequest.builder() \n                .source(Paths.get(sourceDirectory)) \n                .bucket(bucketName) \n                .build()); \n        CompletedDirectoryUpload completedDirectoryUpload = \n directoryUpload.completionFuture().join(); \n        completedDirectoryUpload.failedTransfers() \n                .forEach(fail -> logger.warn(\"Object [{}] failed to transfer\", \n fail.toString())); \n        return completedDirectoryUpload.failedTransfers().size(); \n    }\nUpload a single \ufb01le.\n    public String uploadFile(S3TransferManager transferManager, String \n bucketName, \n                             String key, URI filePathURI) { \n        UploadFileRequest uploadFileRequest = UploadFileRequest.builder() \n            .putObjectRequest(b -> b.bucket(bucketName).key(key)) \n            .source(Paths.get(filePathURI)) \n            .build(); \n        FileUpload fileUpload = transferManager.uploadFile(uploadFileRequest); \n        CompletedFileUpload uploadResult = fileUpload.completionFuture().join(); \n        return uploadResult.response().eTag(); \n    }\nScenarios API Version 2006-03-01 2505Amazon Simple Storage Service API Reference\nJavaScript\nSDK for JavaScript (v3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nUpload a large \ufb01le.\nimport { S3Client } from \"@aws-sdk/client-s3\";\nimport { Upload } from \"@aws-sdk/lib-storage\";\nimport { ProgressBar } from \"@aws-doc-sdk-examples/lib/utils/util-log.js\";\nconst twentyFiveMB = 25 * 1024 * 1024;\nexport const createString = (size = twentyFiveMB) => { \n  return \"x\".repeat(size);\n};\n/** \n * Create a 25MB file and upload it in parts to the specified \n * Amazon S3 bucket. \n * @param {{ bucketName: string, key: string }} \n */\nexport const main = async ({ bucketName, key }) => { \n  const str = createString(); \n  const buffer = Buffer.from(str, \"utf8\"); \n  const progressBar = new ProgressBar({ \n    description: `Uploading \"${key}\" to \"${bucketName}\"`, \n    barLength: 30, \n  }); \n  try { \n    const upload = new Upload({ \n      client: new S3Client({}), \n      params: { \n        Bucket: bucketName, \n        Key: key, \n        Body: buffer, \nScenarios API Version 2006-03-01 2506Amazon Simple Storage Service API Reference\n      }, \n    }); \n    upload.on(\"httpUploadProgress\", ({ loaded, total }) => { \n      progressBar.update({ current: loaded, total }); \n    }); \n    await upload.done(); \n  } catch (caught) { \n    if (caught instanceof Error && caught.name === \"AbortError\") { \n      console.error(`Multipart upload was aborted. ${caught.message}`); \n    } else { \n      throw caught; \n    } \n  }\n};\nDownload a large \ufb01le.\nimport { GetObjectCommand, NoSuchKey, S3Client } from \"@aws-sdk/client-s3\";\nimport { createWriteStream, rmSync } from \"node:fs\";\nconst s3Client = new S3Client({});\nconst oneMB = 1024 * 1024;\nexport const getObjectRange = ({ bucket, key, start, end }) => { \n  const command = new GetObjectCommand({ \n    Bucket: bucket, \n    Key: key, \n    Range: `bytes=${start}-${end}`, \n  }); \n  return s3Client.send(command);\n};\n/** \n * @param {string | undefined} contentRange \n */\nexport const getRangeAndLength = (contentRange) => { \n  const [range, length] = contentRange.split(\"/\"); \n  const [start, end] = range.split(\"-\"); \nScenarios API Version 2006-03-01 2507Amazon Simple Storage Service API Reference\n  return { \n    start: Number.parseInt(start), \n    end: Number.parseInt(end), \n    length: Number.parseInt(length), \n  };\n};\nexport const isComplete = ({ end, length }) => end === length - 1;\nconst downloadInChunks = async ({ bucket, key }) => { \n  const writeStream = createWriteStream( \n    fileURLToPath(new URL(`./${key}`, import.meta.url)), \n  ).on(\"error\", (err) => console.error(err)); \n  let rangeAndLength = { start: -1, end: -1, length: -1 }; \n  while (!isComplete(rangeAndLength)) { \n    const { end } = rangeAndLength; \n    const nextRange = { start: end + 1, end: end + oneMB }; \n    const { ContentRange, Body } = await getObjectRange({ \n      bucket, \n      key, \n      ...nextRange, \n    }); \n    console.log(`Downloaded bytes ${nextRange.start} to ${nextRange.end}`); \n    writeStream.write(await Body.transformToByteArray()); \n    rangeAndLength = getRangeAndLength(ContentRange); \n  }\n};\n/** \n * Download a large object from and Amazon S3 bucket.", "\n * \n * When downloading a large file, you might want to break it down into \n * smaller pieces.", "Amazon S3 accepts a Range header to specify the start \n * and end of the byte range to be downloaded.", "\n * \n * @param {{ bucketName: string, key: string }} \n */\nexport const main = async ({ bucketName, key }) => { \n  try { \n    await downloadInChunks({ \nScenarios API Version 2006-03-01 2508Amazon Simple Storage Service API Reference\n      bucket: bucketName, \n      key: key, \n    }); \n  } catch (caught) { \n    if (caught instanceof NoSuchKey) { \n      console.error(`Failed to download object.", "No such key \"${key}\".`); \n      rmSync(key); \n    } \n  }\n};\nPython\nSDK for Python (Boto3)\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nCreate functions that transfer \ufb01les using several of the available transfer manager settings.", "\nUse a callback class to write callback progress during \ufb01le transfer.\nimport sys\nimport threading\nimport boto3\nfrom boto3.s3.transfer import TransferConfig\nMB = 1024 * 1024\ns3 = boto3.resource(\"s3\")\nclass TransferCallback: \n    \"\"\" \n    Handle callbacks from the transfer manager.", "\n    The transfer manager periodically calls the __call__ method throughout \nScenarios API Version 2006-03-01 2509Amazon Simple Storage Service API Reference\n    the upload and download process so that it can take action, such as \n    displaying progress to the user and collecting data about the transfer.", "\n    \"\"\" \n    def __init__(self, target_size): \n        self._target_size = target_size \n        self._total_transferred = 0 \n        self._lock = threading.Lock() \n        self.thread_info = {} \n    def __call__(self, bytes_transferred): \n        \"\"\" \n        The callback method that is called by the transfer manager.", "\n        Display progress during file transfer and collect per-thread transfer \n        data.", "This method can be called by multiple threads, so shared instance \n        data is protected by a thread lock.", "\n        \"\"\" \n        thread = threading.current_thread() \n        with self._lock: \n            self._total_transferred += bytes_transferred \n            if thread.ident not in self.thread_info.keys(): \n                self.thread_info[thread.ident] = bytes_transferred \n            else: \n                self.thread_info[thread.ident] += bytes_transferred \n            target = self._target_size * MB \n            sys.stdout.write( \n                f\"\\r{self._total_transferred} of {target} transferred \" \n                f\"({(self._total_transferred / target) * 100:.2f}%).\" \n            ) \n            sys.stdout.flush()\ndef upload_with_default_configuration( \n    local_file_path, bucket_name, object_key, file_size_mb\n): \n    \"\"\" \n    Upload a file from a local folder to an Amazon S3 bucket, using the default \n    configuration. \n    \"\"\" \n    transfer_callback = TransferCallback(file_size_mb) \n    s3.Bucket(bucket_name).upload_file( \n        local_file_path, object_key, Callback=transfer_callback \nScenarios API Version 2006-03-01 2510Amazon Simple Storage Service API Reference\n    ) \n    return transfer_callback.thread_info\ndef upload_with_chunksize_and_meta( \n    local_file_path, bucket_name, object_key, file_size_mb, metadata=None\n): \n    \"\"\" \n    Upload a file from a local folder to an Amazon S3 bucket, setting a \n    multipart chunk size and adding metadata to the Amazon S3 object.", "\n    The multipart chunk size controls the size of the chunks of data that are \n    sent in the request. A smaller chunk size typically results in the transfer \n    manager using more threads for the upload.", "\n    The metadata is a set of key-value pairs that are stored with the object \n    in Amazon S3. \n    \"\"\" \n    transfer_callback = TransferCallback(file_size_mb) \n    config = TransferConfig(multipart_chunksize=1 * MB) \n    extra_args = {\"Metadata\": metadata} if metadata else None \n    s3.Bucket(bucket_name).upload_file( \n        local_file_path, \n        object_key, \n        Config=config, \n        ExtraArgs=extra_args, \n        Callback=transfer_callback, \n    ) \n    return transfer_callback.thread_info\ndef upload_with_high_threshold(local_file_path, bucket_name, object_key, \n file_size_mb): \n    \"\"\" \n    Upload a file from a local folder to an Amazon S3 bucket, setting a \n    multipart threshold larger than the size of the file.", "\n    Setting a multipart threshold larger than the size of the file results \n    in the transfer manager sending the file as a standard upload instead of \n    a multipart upload.", "\n    \"\"\" \n    transfer_callback = TransferCallback(file_size_mb) \n    config = TransferConfig(multipart_threshold=file_size_mb * 2 * MB) \nScenarios API Version 2006-03-01 2511Amazon Simple Storage Service API Reference\n    s3.Bucket(bucket_name).upload_file( \n        local_file_path, object_key, Config=config, Callback=transfer_callback \n    ) \n    return transfer_callback.thread_info\ndef upload_with_sse( \n    local_file_path, bucket_name, object_key, file_size_mb, sse_key=None\n): \n    \"\"\" \n    Upload a file from a local folder to an Amazon S3 bucket, adding server-side \n    encryption with customer-provided encryption keys to the object. \n    When this kind of encryption is specified, Amazon S3 encrypts the object \n    at rest and allows downloads only when the expected encryption key is \n    provided in the download request. \n    \"\"\" \n    transfer_callback = TransferCallback(file_size_mb) \n    if sse_key: \n        extra_args = {\"SSECustomerAlgorithm\": \"AES256\", \"SSECustomerKey\": \n sse_key} \n    else: \n        extra_args = None \n    s3.Bucket(bucket_name).upload_file( \n        local_file_path, object_key, ExtraArgs=extra_args, \n Callback=transfer_callback \n    ) \n    return transfer_callback.thread_info\ndef download_with_default_configuration( \n    bucket_name, object_key, download_file_path, file_size_mb\n): \n    \"\"\" \n    Download a file from an Amazon S3 bucket to a local folder, using the \n    default configuration. \n    \"\"\" \n    transfer_callback = TransferCallback(file_size_mb) \n    s3.Bucket(bucket_name).Object(object_key).download_file( \n        download_file_path, Callback=transfer_callback \n    ) \n    return transfer_callback.thread_info\nScenarios API Version 2006-03-01 2512Amazon Simple Storage Service API Reference\ndef download_with_single_thread( \n    bucket_name, object_key, download_file_path, file_size_mb\n): \n    \"\"\" \n    Download a file from an Amazon S3 bucket to a local folder, using a \n    single thread. \n    \"\"\" \n    transfer_callback = TransferCallback(file_size_mb) \n    config = TransferConfig(use_threads=False) \n    s3.Bucket(bucket_name).Object(object_key).download_file( \n        download_file_path, Config=config, Callback=transfer_callback \n    ) \n    return transfer_callback.thread_info\ndef download_with_high_threshold( \n    bucket_name, object_key, download_file_path, file_size_mb\n): \n    \"\"\" \n    Download a file from an Amazon S3 bucket to a local folder, setting a \n    multipart threshold larger than the size of the file.", "\n    Setting a multipart threshold larger than the size of the file results \n    in the transfer manager sending the file as a standard download instead \n    of a multipart download.", "\n    \"\"\" \n    transfer_callback = TransferCallback(file_size_mb) \n    config = TransferConfig(multipart_threshold=file_size_mb * 2 * MB) \n    s3.Bucket(bucket_name).Object(object_key).download_file( \n        download_file_path, Config=config, Callback=transfer_callback \n    ) \n    return transfer_callback.thread_info\ndef download_with_sse( \n    bucket_name, object_key, download_file_path, file_size_mb, sse_key\n): \n    \"\"\" \n    Download a file from an Amazon S3 bucket to a local folder, adding a \n    customer-provided encryption key to the request. \n    When this kind of encryption is specified, Amazon S3 encrypts the object \n    at rest and allows downloads only when the expected encryption key is \n    provided in the download request.", "\nScenarios API Version 2006-03-01 2513Amazon Simple Storage Service API Reference\n    \"\"\" \n    transfer_callback = TransferCallback(file_size_mb) \n    if sse_key: \n        extra_args = {\"SSECustomerAlgorithm\": \"AES256\", \"SSECustomerKey\": \n sse_key} \n    else: \n        extra_args = None \n    s3.Bucket(bucket_name).Object(object_key).download_file( \n        download_file_path, ExtraArgs=extra_args, Callback=transfer_callback \n    ) \n    return transfer_callback.thread_info\nDemonstrate the transfer manager functions and report results.\nimport hashlib\nimport os\nimport platform\nimport shutil\nimport time\nimport boto3\nfrom boto3.s3.transfer import TransferConfig\nfrom botocore.exceptions import ClientError\nfrom botocore.exceptions import ParamValidationError\nfrom botocore.exceptions import NoCredentialsError\nimport file_transfer\nMB = 1024 * 1024\n# These configuration attributes affect both uploads and downloads.\nCONFIG_ATTRS = ( \n    \"multipart_threshold\", \n    \"multipart_chunksize\", \n    \"max_concurrency\", \n    \"use_threads\",\n)\n# These configuration attributes affect only downloads.\nDOWNLOAD_CONFIG_ATTRS = (\"max_io_queue\", \"io_chunksize\", \"num_download_attempts\")\nScenarios API Version 2006-03-01 2514Amazon Simple Storage Service API Reference\nclass TransferDemoManager: \n    \"\"\" \n    Manages the demonstration.", "Collects user input from a command line, reports \n    transfer results, maintains a list of artifacts created during the \n    demonstration, and cleans them up after the demonstration is completed.", "\n    \"\"\" \n    def __init__(self): \n        self._s3 = boto3.resource(\"s3\") \n        self._chore_list = [] \n        self._create_file_cmd = None \n        self._size_multiplier = 0 \n        self.file_size_mb = 30 \n        self.demo_folder = None \n        self.demo_bucket = None \n        self._setup_platform_specific() \n        self._terminal_width = shutil.get_terminal_size(fallback=(80, 80))[0] \n    def collect_user_info(self): \n        \"\"\" \n        Collect local folder and Amazon S3 bucket name from the user.", "These \n        locations are used to store files during the demonstration. \n        \"\"\" \n        while not self.demo_folder: \n            self.demo_folder = input( \n                \"Which file folder do you want to use to store \" \"demonstration \n files? \" \n            ) \n            if not os.path.isdir(self.demo_folder): \n                print(f\"{self.demo_folder} isn't a folder!\") \n                self.demo_folder = None \n        while not self.demo_bucket: \n            self.demo_bucket = input( \n                \"Which Amazon S3 bucket do you want to use to store \" \n                \"demonstration files? \" \n            ) \n            try: \n                self._s3.meta.client.head_bucket(Bucket=self.demo_bucket) \n            except ParamValidationError as err: \n                print(err) \n                self.demo_bucket = None \n            except ClientError as err: \nScenarios API Version 2006-03-01 2515Amazon Simple Storage Service API Reference\n                print(err) \n                print( \n                    f\"Either {self.demo_bucket} doesn't exist or you don't \" \n                    f\"have access to it.\" \n                ) \n                self.demo_bucket = None \n    def demo( \n        self, question, upload_func, download_func, upload_args=None, \n download_args=None \n    ): \n        \"\"\"Run a demonstration.", "\n        Ask the user if they want to run this specific demonstration.", "\n        If they say yes, create a file on the local path, upload it \n        using the specified upload function, then download it using the \n        specified download function. \n        \"\"\" \n        if download_args is None: \n            download_args = {} \n        if upload_args is None: \n            upload_args = {} \n        question = question.format(self.file_size_mb) \n        answer = input(f\"{question} (y/n)\") \n        if answer.lower() == \"y\": \n            local_file_path, object_key, download_file_path = \n self._create_demo_file() \n            file_transfer.TransferConfig = self._config_wrapper( \n                TransferConfig, CONFIG_ATTRS \n            ) \n            self._report_transfer_params( \n                \"Uploading\", local_file_path, object_key, **upload_args \n            ) \n            start_time = time.perf_counter() \n            thread_info = upload_func( \n                local_file_path, \n                self.demo_bucket, \n                object_key, \n                self.file_size_mb, \n                **upload_args, \n            ) \n            end_time = time.perf_counter() \n            self._report_transfer_result(thread_info, end_time - start_time) \nScenarios API Version 2006-03-01 2516Amazon Simple Storage Service API Reference\n            file_transfer.TransferConfig = self._config_wrapper( \n                TransferConfig, CONFIG_ATTRS + DOWNLOAD_CONFIG_ATTRS \n            ) \n            self._report_transfer_params( \n                \"Downloading\", object_key, download_file_path, **download_args \n            ) \n            start_time = time.perf_counter() \n            thread_info = download_func( \n                self.demo_bucket, \n                object_key, \n                download_file_path, \n                self.file_size_mb, \n                **download_args, \n            ) \n            end_time = time.perf_counter() \n            self._report_transfer_result(thread_info, end_time - start_time) \n    def last_name_set(self): \n        \"\"\"Get the name set used for the last demo.\"\"\" \n        return self._chore_list[-1] \n    def cleanup(self): \n        \"\"\" \n        Remove files from the demo folder, and uploaded objects from the \n        Amazon S3 bucket. \n        \"\"\" \n        print(\"-\" * self._terminal_width) \n        for local_file_path, s3_object_key, downloaded_file_path in \n self._chore_list: \n            print(f\"Removing {local_file_path}\") \n            try: \n                os.remove(local_file_path) \n            except FileNotFoundError as err: \n                print(err) \n            print(f\"Removing {downloaded_file_path}\") \n            try: \n                os.remove(downloaded_file_path) \n            except FileNotFoundError as err: \n                print(err) \n            if self.demo_bucket: \n                print(f\"Removing {self.demo_bucket}:{s3_object_key}\") \nScenarios API Version 2006-03-01 2517Amazon Simple Storage Service API Reference\n                try: \n                    \n self._s3.Bucket(self.demo_bucket).Object(s3_object_key).delete() \n                except ClientError as err: \n                    print(err) \n    def _setup_platform_specific(self): \n        \"\"\"Set up platform-specific command used to create a large file.\"\"\" \n        if platform.system() == \"Windows\": \n            self._create_file_cmd = \"fsutil file createnew {} {}\" \n            self._size_multiplier = MB \n        elif platform.system() == \"Linux\" or platform.system() == \"Darwin\": \n            self._create_file_cmd = f\"dd if=/dev/urandom of={{}} \" f\"bs={MB} \n count={{}}\" \n            self._size_multiplier = 1 \n        else: \n            raise EnvironmentError( \n                f\"Demo of platform {platform.system()} isn't supported.\" \n            ) \n    def _create_demo_file(self): \n        \"\"\" \n        Create a file in the demo folder specified by the user.", "Store the local \n        path, object name, and download path for later cleanup. \n        Only the local file is created by this method.", "The Amazon S3 object and \n        download file are created later during the demonstration.", "\n        Returns: \n        A tuple that contains the local file path, object name, and download \n        file path. \n        \"\"\" \n        file_name_template = \"TestFile{}-{}.demo\" \n        local_suffix = \"local\" \n        object_suffix = \"s3object\" \n        download_suffix = \"downloaded\" \n        file_tag = len(self._chore_list) + 1 \n        local_file_path = os.path.join( \n            self.demo_folder, file_name_template.format(file_tag, local_suffix) \n        ) \n        s3_object_key = file_name_template.format(file_tag, object_suffix) \nScenarios API Version 2006-03-01 2518Amazon Simple Storage Service API Reference\n        downloaded_file_path = os.path.join( \n            self.demo_folder, file_name_template.format(file_tag, \n download_suffix) \n        ) \n        filled_cmd = self._create_file_cmd.format( \n            local_file_path, self.file_size_mb * self._size_multiplier \n        ) \n        print( \n            f\"Creating file of size {self.file_size_mb} MB \" \n            f\"in {self.demo_folder} by running:\" \n        ) \n        print(f\"{'':4}{filled_cmd}\") \n        os.system(filled_cmd) \n        chore = (local_file_path, s3_object_key, downloaded_file_path) \n        self._chore_list.append(chore) \n        return chore \n    def _report_transfer_params(self, verb, source_name, dest_name, **kwargs): \n        \"\"\"Report configuration and extra arguments used for a file transfer.\"\"\" \n        print(\"-\" * self._terminal_width) \n        print(f\"{verb} {source_name} ({self.file_size_mb} MB) to {dest_name}\") \n        if kwargs: \n            print(\"With extra args:\") \n            for arg, value in kwargs.items(): \n                print(f'{\"\":4}{arg:<20}: {value}') \n    @staticmethod \n    def ask_user(question): \n        \"\"\" \n        Ask the user a yes or no question.", "\n        Returns: \n        True when the user answers 'y' or 'Y'; otherwise, False. \n        \"\"\" \n        answer = input(f\"{question} (y/n) \") \n        return answer.lower() == \"y\" \n    @staticmethod \n    def _config_wrapper(func, config_attrs): \n        def wrapper(*args, **kwargs): \n            config = func(*args, **kwargs) \nScenarios API Version 2006-03-01 2519Amazon Simple Storage Service API Reference\n            print(\"With configuration:\") \n            for attr in config_attrs: \n                print(f'{\"\":4}{attr:<20}: {getattr(config, attr)}') \n            return config \n        return wrapper \n    @staticmethod \n    def _report_transfer_result(thread_info, elapsed): \n        \"\"\"Report the result of a transfer, including per-thread data.\"\"\" \n        print(f\"\\nUsed {len(thread_info)} threads.\") \n        for ident, byte_count in thread_info.items(): \n            print(f\"{'':4}Thread {ident} copied {byte_count} bytes.\") \n        print(f\"Your transfer took {elapsed:.2f} seconds.\")\ndef main(): \n    \"\"\" \n    Run the demonstration script for s3_file_transfer.", "\n    \"\"\" \n    demo_manager = TransferDemoManager() \n    demo_manager.collect_user_info() \n    # Upload and download with default configuration.", "Because the file is 30 MB \n    # and the default multipart_threshold is 8 MB, both upload and download are \n    # multipart transfers. \n    demo_manager.demo( \n        \"Do you want to upload and download a {} MB file \" \n        \"using the default configuration?\", \n        file_transfer.upload_with_default_configuration, \n        file_transfer.download_with_default_configuration, \n    ) \n    # Upload and download with multipart_threshold set higher than the size of \n    # the file. This causes the transfer manager to use standard transfers \n    # instead of multipart transfers. \n    demo_manager.demo( \n        \"Do you want to upload and download a {} MB file \" \n        \"as a standard (not multipart) transfer?\", \n        file_transfer.upload_with_high_threshold, \n        file_transfer.download_with_high_threshold, \n    ) \n    # Upload with specific chunk size and additional metadata.", "\nScenarios API Version 2006-03-01 2520Amazon Simple Storage Service API Reference\n    # Download with a single thread.", "\n    demo_manager.demo( \n        \"Do you want to upload a {} MB file with a smaller chunk size and \" \n        \"then download the same file using a single thread?\", \n        file_transfer.upload_with_chunksize_and_meta, \n        file_transfer.download_with_single_thread, \n        upload_args={ \n            \"metadata\": { \n                \"upload_type\": \"chunky\", \n                \"favorite_color\": \"aqua\", \n                \"size\": \"medium\", \n            } \n        }, \n    ) \n    # Upload using server-side encryption with customer-provided \n    # encryption keys.", "\n    # Generate a 256-bit key from a passphrase.", "\n    sse_key = hashlib.sha256(\"demo_passphrase\".encode(\"utf-8\")).digest() \n    demo_manager.demo( \n        \"Do you want to upload and download a {} MB file using \" \n        \"server-side encryption?\", \n        file_transfer.upload_with_sse, \n        file_transfer.download_with_sse, \n        upload_args={\"sse_key\": sse_key}, \n        download_args={\"sse_key\": sse_key}, \n    ) \n    # Download without specifying an encryption key to show that the \n    # encryption key must be included to download an encrypted object. \n    if demo_manager.ask_user( \n        \"Do you want to try to download the encrypted \" \n        \"object without sending the required key?\" \n    ): \n        try: \n            _, object_key, download_file_path = demo_manager.last_name_set() \n            file_transfer.download_with_default_configuration( \n                demo_manager.demo_bucket, \n                object_key, \n                download_file_path, \n                demo_manager.file_size_mb, \n            ) \n        except ClientError as err: \n            print( \nScenarios API Version 2006-03-01 2521Amazon Simple Storage Service API Reference\n                \"Got expected error when trying to download an encrypted \" \n                \"object without specifying encryption info:\" \n            ) \n            print(f\"{'':4}{err}\") \n    # Remove all created and downloaded files, remove all objects from \n    # S3 storage.", "\n    if demo_manager.ask_user( \n        \"Demonstration complete.", "Do you want to remove local files \" \"and S3 \n objects?\" \n    ): \n        demo_manager.cleanup()\nif __name__ == \"__main__\": \n    try: \n        main() \n    except NoCredentialsError as error: \n        print(error) \n        print( \n            \"To run this example, you must have valid credentials in \" \n            \"a shared credential file or set in environment variables.\" \n        )\nRust\nSDK for Rust\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nuse std::fs::File;\nuse std::io::prelude::*;\nuse std::path::Path;\nuse aws_config::meta::region::RegionProviderChain;\nScenarios API Version 2006-03-01 2522Amazon Simple Storage Service API Reference\nuse aws_sdk_s3::error::DisplayErrorContext;\nuse aws_sdk_s3::operation::{ \n    create_multipart_upload::CreateMultipartUploadOutput, \n get_object::GetObjectOutput,\n};\nuse aws_sdk_s3::types::{CompletedMultipartUpload, CompletedPart};\nuse aws_sdk_s3::{config::Region, Client as S3Client};\nuse aws_smithy_types::byte_stream::{ByteStream, Length};\nuse rand::distributions::Alphanumeric;\nuse rand::{thread_rng, Rng};\nuse s3_code_examples::error::S3ExampleError;\nuse std::process;\nuse uuid::Uuid;\n//In bytes, minimum chunk size of 5MB. Increase CHUNK_SIZE to send larger chunks.\nconst CHUNK_SIZE: u64 = 1024 * 1024 * 5;\nconst MAX_CHUNKS: u64 = 10000;\n#[tokio::main]\npub async fn main() { \n    if let Err(err) = run_example().await { \n        eprintln!(\"Error: {}\", DisplayErrorContext(err)); \n        process::exit(1); \n    }\n}\nasync fn run_example() -> Result<(), S3ExampleError> { \n    let shared_config = aws_config::load_from_env().await; \n    let client = S3Client::new(&shared_config); \n    let bucket_name = format!(\"amzn-s3-demo-bucket-{}\", Uuid::new_v4()); \n    let region_provider = RegionProviderChain::first_try(Region::new(\"us-\nwest-2\")); \n    let region = region_provider.region().await.unwrap(); \n    s3_code_examples::create_bucket(&client, &bucket_name, &region).await?; \n    let key = \"sample.txt\".to_string(); \n    // Create a multipart upload.", "Use UploadPart and CompleteMultipartUpload to \n    // upload the file.", "\n    let multipart_upload_res: CreateMultipartUploadOutput = client \n        .create_multipart_upload() \n        .bucket(&bucket_name) \n        .key(&key) \n        .send() \nScenarios API Version 2006-03-01 2523Amazon Simple Storage Service API Reference\n        .await?; \n    let upload_id = multipart_upload_res.upload_id().ok_or(S3ExampleError::new( \n        \"Missing upload_id after CreateMultipartUpload\", \n    ))?; \n    //Create a file of random characters for the upload.", "\n    let mut file = File::create(&key).expect(\"Could not create sample file.\"); \n    // Loop until the file is 5 chunks. \n    while file.metadata().unwrap().len() <= CHUNK_SIZE * 4 { \n        let rand_string: String = thread_rng() \n            .sample_iter(&Alphanumeric) \n            .take(256) \n            .map(char::from) \n            .collect(); \n        let return_string: String = \"\\n\".to_string(); \n        file.write_all(rand_string.as_ref()) \n            .expect(\"Error writing to file.\"); \n        file.write_all(return_string.as_ref()) \n            .expect(\"Error writing to file.\"); \n    } \n    let path = Path::new(&key); \n    let file_size = tokio::fs::metadata(path) \n        .await \n        .expect(\"it exists I swear\") \n        .len(); \n    let mut chunk_count = (file_size / CHUNK_SIZE) + 1; \n    let mut size_of_last_chunk = file_size % CHUNK_SIZE; \n    if size_of_last_chunk == 0 { \n        size_of_last_chunk = CHUNK_SIZE; \n        chunk_count -= 1; \n    } \n    if file_size == 0 { \n        return Err(S3ExampleError::new(\"Bad file size.\")); \n    } \n    if chunk_count > MAX_CHUNKS { \n        return Err(S3ExampleError::new( \n            \"Too many chunks! Try increasing your chunk size.\", \n        )); \n    } \nScenarios API Version 2006-03-01 2524Amazon Simple Storage Service API Reference\n    let mut upload_parts: Vec<aws_sdk_s3::types::CompletedPart> = Vec::new(); \n    for chunk_index in 0..chunk_count { \n        let this_chunk = if chunk_count - 1 == chunk_index { \n            size_of_last_chunk \n        } else { \n            CHUNK_SIZE \n        }; \n        let stream = ByteStream::read_from() \n            .path(path) \n            .offset(chunk_index * CHUNK_SIZE) \n            .length(Length::Exact(this_chunk)) \n            .build() \n            .await \n            .unwrap(); \n        // Chunk index needs to start at 0, but part numbers start at 1. \n        let part_number = (chunk_index as i32) + 1; \n        let upload_part_res = client \n            .upload_part() \n            .key(&key) \n            .bucket(&bucket_name) \n            .upload_id(upload_id) \n            .body(stream) \n            .part_number(part_number) \n            .send() \n            .await?; \n        upload_parts.push( \n            CompletedPart::builder() \n                .e_tag(upload_part_res.e_tag.unwrap_or_default()) \n                .part_number(part_number) \n                .build(), \n        ); \n    } \n    // upload_parts: Vec<aws_sdk_s3::types::CompletedPart> \n    let completed_multipart_upload: CompletedMultipartUpload = \n CompletedMultipartUpload::builder() \n        .set_parts(Some(upload_parts)) \n        .build(); \n    let _complete_multipart_upload_res = client \n        .complete_multipart_upload() \nScenarios API Version 2006-03-01 2525Amazon Simple Storage Service API Reference\n        .bucket(&bucket_name) \n        .key(&key) \n        .multipart_upload(completed_multipart_upload) \n        .upload_id(upload_id) \n        .send() \n        .await?; \n    let data: GetObjectOutput = \n        s3_code_examples::download_object(&client, &bucket_name, &key).await?; \n    let data_length: u64 = data \n        .content_length() \n        .unwrap_or_default() \n        .try_into() \n        .unwrap(); \n    if file.metadata().unwrap().len() == data_length { \n        println!(\"Data lengths match.\"); \n    } else { \n        println!(\"The data was not the same size!\"); \n    } \n    s3_code_examples::clear_bucket(&client, &bucket_name) \n        .await \n        .expect(\"Error emptying bucket.\"); \n    s3_code_examples::delete_bucket(&client, &bucket_name) \n        .await \n        .expect(\"Error deleting bucket.\"); \n    Ok(())\n}\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nUpload a stream of unknown size to an Amazon S3 object using an AWS SDK\nThe following code example shows how to upload a stream of unknown size to an Amazon S3 \nobject.\nScenarios API Version 2006-03-01 2526Amazon Simple Storage Service API Reference\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nUse the AWS CRT-based S3 Client.\nimport com.example.s3.util.AsyncExampleUtils;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\nimport software.amazon.awssdk.core.async.AsyncRequestBody;\nimport software.amazon.awssdk.core.async.BlockingInputStreamAsyncRequestBody;\nimport software.amazon.awssdk.core.exception.SdkException;\nimport software.amazon.awssdk.services.s3.S3AsyncClient;\nimport software.amazon.awssdk.services.s3.model.PutObjectResponse;\nimport java.io.ByteArrayInputStream;\nimport java.util.UUID;\nimport java.util.concurrent.CompletableFuture; \n    /** \n     * @param s33CrtAsyncClient - To upload content from a stream of unknown \n size, use the AWS CRT-based S3 client. For more information, see \n     *                          https://docs.aws.amazon.com/sdk-for-java/latest/\ndeveloper-guide/crt-based-s3-client.html.", "\n     * @param bucketName - The name of the bucket.", "\n     * @param key - The name of the object.", "\n     * @return software.amazon.awssdk.services.s3.model.PutObjectResponse - \n Returns metadata pertaining to the put object operation. \n     */ \n    public PutObjectResponse putObjectFromStream(S3AsyncClient s33CrtAsyncClient, \n String bucketName, String key) { \n        BlockingInputStreamAsyncRequestBody body = \n                AsyncRequestBody.forBlockingInputStream(null); // 'null' \n indicates a stream will be provided later. \n        CompletableFuture<PutObjectResponse> responseFuture = \nScenarios API Version 2006-03-01 2527Amazon Simple Storage Service API Reference\n                s33CrtAsyncClient.putObject(r -> r.bucket(bucketName).key(key), \n body); \n        // AsyncExampleUtils.randomString() returns a random string up to 100 \n characters.", "\n        String randomString = AsyncExampleUtils.randomString(); \n        logger.info(\"random string to upload: {}: length={}\", randomString, \n randomString.length()); \n        // Provide the stream of data to be uploaded.", "\n        body.writeInputStream(new ByteArrayInputStream(randomString.getBytes())); \n        PutObjectResponse response = responseFuture.join(); // Wait for the \n response.", "\n        logger.info(\"Object {} uploaded to bucket {}.\", key, bucketName); \n        return response; \n    }\n}\nUse the Amazon S3 Transfer Manager.\nimport com.example.s3.util.AsyncExampleUtils;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\nimport software.amazon.awssdk.core.async.AsyncRequestBody;\nimport software.amazon.awssdk.core.async.BlockingInputStreamAsyncRequestBody;\nimport software.amazon.awssdk.core.exception.SdkException;\nimport software.amazon.awssdk.transfer.s3.S3TransferManager;\nimport software.amazon.awssdk.transfer.s3.model.CompletedUpload;\nimport software.amazon.awssdk.transfer.s3.model.Upload;\nimport java.io.ByteArrayInputStream;\nimport java.util.UUID; \n    /** \n     * @param transferManager - To upload content from a stream of unknown size, \n use the S3TransferManager based on the AWS CRT-based S3 client. \n     *                       For more information, see https://\ndocs.aws.amazon.com/sdk-for-java/latest/developer-guide/transfer-manager.html.", "\n     * @param bucketName - The name of the bucket.", "\n     * @param key - The name of the object.", "\nScenarios API Version 2006-03-01 2528Amazon Simple Storage Service API Reference\n     * @return - software.amazon.awssdk.transfer.s3.model.CompletedUpload - The \n result of the completed upload. \n     */ \n    public CompletedUpload uploadStream(S3TransferManager transferManager, String \n bucketName, String key) { \n        BlockingInputStreamAsyncRequestBody body = \n                AsyncRequestBody.forBlockingInputStream(null); // 'null' \n indicates a stream will be provided later.", "\n        Upload upload = transferManager.upload(builder -> builder \n                .requestBody(body) \n                .putObjectRequest(req -> req.bucket(bucketName).key(key)) \n                .build()); \n        // AsyncExampleUtils.randomString() returns a random string up to 100 \n characters. \n        String randomString = AsyncExampleUtils.randomString(); \n        logger.info(\"random string to upload: {}: length={}\", randomString, \n randomString.length()); \n        // Provide the stream of data to be uploaded.", "\n        body.writeInputStream(new ByteArrayInputStream(randomString.getBytes())); \n        return upload.completionFuture().join(); \n    }\n}\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nUse checksums to work with an Amazon S3 object using an AWS SDK\nThe following code example shows how to use checksums to work with an Amazon S3 object.\nScenarios API Version 2006-03-01 2529Amazon Simple Storage Service API Reference\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nThe code examples use a subset of the following imports.\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\nimport software.amazon.awssdk.core.exception.SdkException;\nimport software.amazon.awssdk.core.sync.RequestBody;\nimport software.amazon.awssdk.services.s3.S3Client;\nimport software.amazon.awssdk.services.s3.model.ChecksumAlgorithm;\nimport software.amazon.awssdk.services.s3.model.ChecksumMode;\nimport software.amazon.awssdk.services.s3.model.CompletedMultipartUpload;\nimport software.amazon.awssdk.services.s3.model.CompletedPart;\nimport software.amazon.awssdk.services.s3.model.CreateMultipartUploadResponse;\nimport software.amazon.awssdk.services.s3.model.GetObjectResponse;\nimport software.amazon.awssdk.services.s3.model.UploadPartRequest;\nimport software.amazon.awssdk.services.s3.model.UploadPartResponse;\nimport software.amazon.awssdk.services.s3.waiters.S3Waiter;\nimport software.amazon.awssdk.transfer.s3.S3TransferManager;\nimport software.amazon.awssdk.transfer.s3.model.FileUpload;\nimport software.amazon.awssdk.transfer.s3.model.UploadFileRequest;\nimport java.io.FileInputStream;\nimport java.io.IOException;\nimport java.io.RandomAccessFile;\nimport java.net.URISyntaxException;\nimport java.net.URL;\nimport java.nio.ByteBuffer;\nimport java.nio.file.Paths;\nimport java.security.DigestInputStream;\nimport java.security.MessageDigest;\nimport java.security.NoSuchAlgorithmException;\nimport java.util.ArrayList;\nimport java.util.Base64;\nScenarios API Version 2006-03-01 2530Amazon Simple Storage Service API Reference\nimport java.util.List;\nimport java.util.Objects;\nimport java.util.UUID;\nSpecify a checksum algorithm for the putObject  method when you build the\nPutObjectRequest .\n    public void putObjectWithChecksum() { \n        s3Client.putObject(b -> b \n                .bucket(bucketName) \n                .key(key) \n                .checksumAlgorithm(ChecksumAlgorithm.CRC32), \n            RequestBody.fromString(\"This is a test\")); \n    }\nVerify the checksum for the getObject  method when you build the GetObjectRequest.\n    public GetObjectResponse getObjectWithChecksum() { \n        return s3Client.getObject(b -> b \n                .bucket(bucketName) \n                .key(key) \n                .checksumMode(ChecksumMode.ENABLED)) \n            .response(); \n    }\nPre-calculate a checksum for the putObject  method when you build the\nPutObjectRequest .\n    public void putObjectWithPrecalculatedChecksum(String filePath) { \n        String checksum = calculateChecksum(filePath, \"SHA-256\"); \n        s3Client.putObject((b -> b \n                .bucket(bucketName) \n                .key(key) \n                .checksumSHA256(checksum)), \n            RequestBody.fromFile(Paths.get(filePath))); \n    }\nScenarios API Version 2006-03-01 2531Amazon Simple Storage Service API Reference\nUse the S3 Transfer Manager on top of the AWS CRT-based S3 client to transparently \nperform a multipart upload when the size of the content exceeds a threshold.", "The default \nthreshold size is 8 MB.\nYou can specify a checksum algorithm for the SDK to use.", "By default, the SDK uses the \nCRC32 algorithm.\n    public void multipartUploadWithChecksumTm(String filePath) { \n        S3TransferManager transferManager = S3TransferManager.create(); \n        UploadFileRequest uploadFileRequest = UploadFileRequest.builder() \n            .putObjectRequest(b -> b \n                .bucket(bucketName) \n                .key(key) \n                .checksumAlgorithm(ChecksumAlgorithm.SHA1)) \n            .source(Paths.get(filePath)) \n            .build(); \n        FileUpload fileUpload = transferManager.uploadFile(uploadFileRequest); \n        fileUpload.completionFuture().join(); \n        transferManager.close(); \n    }\nUse the S3Client API  or (S3AsyncClient API) to perform a multipart upload.", "If you specify \nan additional checksum, you must specify the algorithm to use on the initiation of the \nupload. You must also specify the algorithm for each part request and provide the checksum \ncalculated for each part after it is uploaded.\n    public void multipartUploadWithChecksumS3Client(String filePath) { \n        ChecksumAlgorithm algorithm = ChecksumAlgorithm.CRC32; \n        // Initiate the multipart upload.", "\n        CreateMultipartUploadResponse createMultipartUploadResponse = \n s3Client.createMultipartUpload(b -> b \n            .bucket(bucketName) \n            .key(key) \n            .checksumAlgorithm(algorithm)); // Checksum specified on initiation.", "\n        String uploadId = createMultipartUploadResponse.uploadId(); \n        // Upload the parts of the file.", "\n        int partNumber = 1; \n        List<CompletedPart> completedParts = new ArrayList<>(); \n        ByteBuffer bb = ByteBuffer.allocate(1024 * 1024 * 5); // 5 MB byte buffer \nScenarios API Version 2006-03-01 2532Amazon Simple Storage Service API Reference\n        try (RandomAccessFile file = new RandomAccessFile(filePath, \"r\")) { \n            long fileSize = file.length(); \n            long position = 0; \n            while (position < fileSize) { \n                file.seek(position); \n                long read = file.getChannel().read(bb); \n                bb.flip(); // Swap position and limit before reading from the \n buffer.", "\n                UploadPartRequest uploadPartRequest = UploadPartRequest.builder() \n                    .bucket(bucketName) \n                    .key(key) \n                    .uploadId(uploadId) \n                    .checksumAlgorithm(algorithm) // Checksum specified on each \n part.", "\n                    .partNumber(partNumber) \n                    .build(); \n                UploadPartResponse partResponse = s3Client.uploadPart( \n                    uploadPartRequest, \n                    RequestBody.fromByteBuffer(bb)); \n                CompletedPart part = CompletedPart.builder() \n                    .partNumber(partNumber) \n                    .checksumCRC32(partResponse.checksumCRC32()) // Provide the \n calculated checksum.", "\n                    .eTag(partResponse.eTag()) \n                    .build(); \n                completedParts.add(part); \n                bb.clear(); \n                position += read; \n                partNumber++; \n            } \n        } catch (IOException e) { \n            System.err.println(e.getMessage()); \n        } \n        // Complete the multipart upload.", "\n        s3Client.completeMultipartUpload(b -> b \n            .bucket(bucketName) \n            .key(key) \n            .uploadId(uploadId) \nScenarios API Version 2006-03-01 2533Amazon Simple Storage Service API Reference\n           \n .multipartUpload(CompletedMultipartUpload.builder().parts(completedParts).build())); \n    }\n\u2022For API details, see the following topics in AWS SDK for Java 2.x API Reference.\n\u2022CompleteMultipartUpload\n\u2022CreateMultipartUpload\n\u2022UploadPart\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nWork with Amazon S3 object integrity features using an AWS SDK\nThe following code example shows how to work with S3 object integrity features.\nC++\nSDK for C++\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nRun an interactive scenario demonstrating Amazon S3 object integrity features.\n//! Routine which runs the S3 object integrity workflow.\n/*!", "\n   \\param clientConfig: Aws client configuration.", "\n   \\return bool: Function succeeded.\n*/\nbool AwsDoc::S3::s3ObjectIntegrityWorkflow( \n        const Aws::S3::S3ClientConfiguration &clientConfiguration) { \n    /* \n     * Create a large file to be used for multipart uploads.", "\nScenarios API Version 2006-03-01 2534Amazon Simple Storage Service API Reference\n     */ \n    if (!createLargeFileIfNotExists()) { \n        std::cerr << \"Workflow exiting because large file creation failed.\" << \n std::endl; \n        return false; \n    } \n    Aws::String bucketName = TEST_BUCKET_PREFIX; \n    bucketName += Aws::Utils::UUID::RandomUUID(); \n    bucketName = Aws::Utils::StringUtils::ToLower(bucketName.c_str()); \n    bucketName.resize(std::min(bucketName.size(), MAX_BUCKET_NAME_LENGTH)); \n    introductoryExplanations(bucketName); \n    if (!AwsDoc::S3::createBucket(bucketName, clientConfiguration)) { \n        std::cerr << \"Workflow exiting because bucket creation failed.\" << \n std::endl; \n        return false; \n    } \n    Aws::S3::S3ClientConfiguration s3ClientConfiguration(clientConfiguration); \n    std::shared_ptr<Aws::S3::S3Client> client = \n Aws::MakeShared<Aws::S3::S3Client>(\"S3Client\", s3ClientConfiguration); \n    printAsterisksLine(); \n    std::cout << \"Choose from one of the following checksum algorithms.\" \n              << std::endl; \n    for (HASH_METHOD hashMethod = DEFAULT; hashMethod <= SHA256; ++hashMethod) { \n        std::cout << \"  \" << hashMethod << \" - \" << \n stringForHashMethod(hashMethod) \n                  << std::endl; \n    } \n    HASH_METHOD chosenHashMethod = askQuestionForIntRange(\"Enter an index: \", \n DEFAULT, \n                                                          SHA256); \n    gUseCalculatedChecksum = !askYesNoQuestion( \n            \"Let the SDK calculate the checksum for you?", "(y/n) \"); \n    printAsterisksLine(); \nScenarios API Version 2006-03-01 2535Amazon Simple Storage Service API Reference\n    std::cout << \"The workflow will now upload a file using PutObject.\" \n              << std::endl; \n    std::cout << \"Object integrity will be verified using the \" \n              << stringForHashMethod(chosenHashMethod) << \" algorithm.\" \n              << std::endl; \n    if (gUseCalculatedChecksum) { \n        std::cout \n                << \"A checksum computed by this workflow will be used for object \n integrity verification,\" \n                << std::endl; \n        std::cout << \"except for the TransferManager upload.\" << std::endl; \n    } else { \n        std::cout \n                << \"A checksum computed by the SDK will be used for object \n integrity verification.\" \n                << std::endl; \n    } \n    pressEnterToContinue(); \n    printAsterisksLine(); \n    std::shared_ptr<Aws::IOStream> inputData = \n            Aws::MakeShared<Aws::FStream>(\"SampleAllocationTag\", \n                                          TEST_FILE, \n                                          std::ios_base::in | \n                                          std::ios_base::binary); \n    if (!*inputData) { \n        std::cerr << \"Error unable to read file \" << TEST_FILE << std::endl; \n        cleanUp(bucketName, clientConfiguration); \n        return false; \n    } \n    Hasher hasher; \n    HASH_METHOD putObjectHashMethod = chosenHashMethod; \n    if (putObjectHashMethod == DEFAULT) { \n        putObjectHashMethod = MD5; // MD5 is the default hash method for \n PutObject. \n        std::cout << \"The default checksum algorithm for PutObject is \" \n                  << stringForHashMethod(putObjectHashMethod) \n                  << std::endl; \n    } \nScenarios API Version 2006-03-01 2536Amazon Simple Storage Service API Reference\n    // Demonstrate in code how the hash is computed. \n    if (!hasher.calculateObjectHash(*inputData, putObjectHashMethod)) { \n        std::cerr << \"Error calculating hash for file \" << TEST_FILE << \n std::endl; \n        cleanUp(bucketName, clientConfiguration); \n        return false; \n    } \n    Aws::String key = stringForHashMethod(putObjectHashMethod); \n    key += \"_\"; \n    key += TEST_FILE_KEY; \n    Aws::String localHash = hasher.getBase64HashString(); \n    // Upload the object with PutObject \n    if (!putObjectWithHash(bucketName, key, localHash, putObjectHashMethod, \n                           inputData, chosenHashMethod == DEFAULT, \n                           *client)) { \n        std::cerr << \"Error putting file \" << TEST_FILE << \" to bucket \" \n                  << bucketName << \" with key \" << key << std::endl; \n        cleanUp(bucketName, clientConfiguration); \n        return false; \n    } \n    Aws::String retrievedHash; \n    if (!retrieveObjectHash(bucketName, key, \n                            putObjectHashMethod, retrievedHash, \n                            nullptr, *client)) { \n        std::cerr << \"Error getting file \" << TEST_FILE << \" from bucket \" \n                  << bucketName << \" with key \" << key << std::endl; \n        cleanUp(bucketName, clientConfiguration); \n        return false; \n    } \n    explainPutObjectResults(); \n    verifyHashingResults(retrievedHash, hasher, \n                         \"PutObject upload\", putObjectHashMethod); \n    printAsterisksLine(); \n    pressEnterToContinue(); \n    key = \"tr_\"; \n    key += stringForHashMethod(chosenHashMethod) + \"_\" + MULTI_PART_TEST_FILE; \nScenarios API Version 2006-03-01 2537Amazon Simple Storage Service API Reference\n    introductoryTransferManagerUploadExplanations(key); \n    HASH_METHOD transferManagerHashMethod = chosenHashMethod; \n    if (transferManagerHashMethod == DEFAULT) { \n        transferManagerHashMethod = CRC32;  // The default hash method for the \n TransferManager is CRC32.", "\n        std::cout << \"The default checksum algorithm for TransferManager is \" \n                  << stringForHashMethod(transferManagerHashMethod) \n                  << std::endl; \n    } \n    // Upload the large file using the transfer manager. \n    if (!doTransferManagerUpload(bucketName, key, transferManagerHashMethod, \n chosenHashMethod == DEFAULT, \n                                 client)) { \n        std::cerr << \"Exiting because of an error in doTransferManagerUpload.\" << \n std::endl; \n        cleanUp(bucketName, clientConfiguration); \n        return false; \n    } \n    std::vector<Aws::String> retrievedTransferManagerPartHashes; \n    Aws::String retrievedTransferManagerFinalHash; \n    // Retrieve all the hashes for the TransferManager upload. \n    if (!retrieveObjectHash(bucketName, key, \n                            transferManagerHashMethod, \n                            retrievedTransferManagerFinalHash, \n                            &retrievedTransferManagerPartHashes, *client)) { \n        std::cerr << \"Exiting because of an error in retrieveObjectHash for \n TransferManager.\" << std::endl; \n        cleanUp(bucketName, clientConfiguration); \n        return false; \n    } \n    AwsDoc::S3::Hasher locallyCalculatedFinalHash; \n    std::vector<Aws::String> locallyCalculatedPartHashes; \n    // Calculate the hashes locally to demonstrate how TransferManager hashes are \n computed. \n    if (!calculatePartHashesForFile(transferManagerHashMethod, \n MULTI_PART_TEST_FILE, \n                                    UPLOAD_BUFFER_SIZE, \nScenarios API Version 2006-03-01 2538Amazon Simple Storage Service API Reference\n                                    locallyCalculatedFinalHash, \n                                    locallyCalculatedPartHashes)) { \n        std::cerr << \"Exiting because of an error in calculatePartHashesForFile.\" \n << std::endl; \n        cleanUp(bucketName, clientConfiguration); \n        return false; \n    } \n    verifyHashingResults(retrievedTransferManagerFinalHash, \n                         locallyCalculatedFinalHash, \"TransferManager upload\", \n                         transferManagerHashMethod, \n                         retrievedTransferManagerPartHashes, \n                         locallyCalculatedPartHashes); \n    printAsterisksLine(); \n    key = \"mp_\"; \n    key += stringForHashMethod(chosenHashMethod) + \"_\" + MULTI_PART_TEST_FILE; \n    multiPartUploadExplanations(key, chosenHashMethod); \n    pressEnterToContinue(); \n    std::shared_ptr<Aws::IOStream> largeFileInputData = \n            Aws::MakeShared<Aws::FStream>(\"SampleAllocationTag\", \n                                          MULTI_PART_TEST_FILE, \n                                          std::ios_base::in | \n                                          std::ios_base::binary); \n    if (!largeFileInputData->good()) { \n        std::cerr << \"Error unable to read file \" << TEST_FILE << std::endl; \n        cleanUp(bucketName, clientConfiguration); \n        return false; \n    } \n    HASH_METHOD multipartUploadHashMethod = chosenHashMethod; \n    if (multipartUploadHashMethod == DEFAULT) { \n        multipartUploadHashMethod = MD5;  // The default hash method for \n multipart uploads is MD5. \n        std::cout << \"The default checksum algorithm for multipart upload is \" \n                  << stringForHashMethod(putObjectHashMethod) \n                  << std::endl; \n    } \nScenarios API Version 2006-03-01 2539Amazon Simple Storage Service API Reference\n    AwsDoc::S3::Hasher hashData; \n    std::vector<Aws::String> partHashes; \n    if (!doMultipartUpload(bucketName, key, \n                           multipartUploadHashMethod, \n                           largeFileInputData, chosenHashMethod == DEFAULT, \n                           hashData, \n                           partHashes, \n                           *client)) { \n        std::cerr << \"Exiting because of an error in doMultipartUpload.\" << \n std::endl; \n        cleanUp(bucketName, clientConfiguration); \n        return false; \n    } \n    std::cout << \"Finished multipart upload of with hash method \" << \n              stringForHashMethod(multipartUploadHashMethod) << std::endl; \n    std::cout << \"Now we will retrieve the checksums from the server.\" << \n std::endl; \n    retrievedHash.clear(); \n    std::vector<Aws::String> retrievedPartHashes; \n    if (!retrieveObjectHash(bucketName, key, \n                            multipartUploadHashMethod, \n                            retrievedHash, &retrievedPartHashes, *client)) { \n        std::cerr << \"Exiting because of an error in retrieveObjectHash for \n multipart.\" << std::endl; \n        cleanUp(bucketName, clientConfiguration); \n        return false; \n    } \n    verifyHashingResults(retrievedHash, hashData, \"MultiPart upload\", \n                         multipartUploadHashMethod, \n                         retrievedPartHashes, partHashes); \n    printAsterisksLine(); \n    if (askYesNoQuestion(\"Would you like to delete the resources created in this \n workflow? (y/n)\")) { \n        return cleanUp(bucketName, clientConfiguration); \n    } else { \nScenarios API Version 2006-03-01 2540Amazon Simple Storage Service API Reference\n        std::cout << \"The bucket \" << bucketName << \" was not deleted.\" << \n std::endl; \n        return true; \n    }\n}\n//!", "Routine which uploads an object to an S3 bucket with different object \n integrity hashing methods.\n/*! \n   \\param bucket: The name of the S3 bucket where the object will be uploaded. \n   \\param key: The unique identifier (key) for the object within the S3 bucket.", "\n   \\param hashData: The hash value that will be associated with the uploaded \n object. \n   \\param hashMethod: The hashing algorithm to use when calculating the hash \n value.", "\n   \\param body: The data content of the object being uploaded.", "\n   \\param useDefaultHashMethod: A flag indicating whether to use the default hash \n method or the one specified in the hashMethod parameter.", "\n   \\param client: The S3 client instance used to perform the upload operation.", "\n   \\return bool: Function succeeded.\n*/\nbool AwsDoc::S3::putObjectWithHash(const Aws::String &bucket, const Aws::String \n &key, \n                                   const Aws::String &hashData, \n                                   AwsDoc::S3::HASH_METHOD hashMethod, \n                                   const std::shared_ptr<Aws::IOStream> &body, \n                                   bool useDefaultHashMethod, \n                                   const Aws::S3::S3Client &client) { \n    Aws::S3::Model::PutObjectRequest request; \n    request.SetBucket(bucket); \n    request.SetKey(key); \n    if (!useDefaultHashMethod) { \n        if (hashMethod != MD5) { \n            \n request.SetChecksumAlgorithm(getChecksumAlgorithmForHashMethod(hashMethod)); \n        } \n    } \n    if (gUseCalculatedChecksum) { \n        switch (hashMethod) { \n            case AwsDoc::S3::MD5: \n                request.SetContentMD5(hashData); \n                break; \n            case AwsDoc::S3::SHA1: \nScenarios API Version 2006-03-01 2541Amazon Simple Storage Service API Reference\n                request.SetChecksumSHA1(hashData); \n                break; \n            case AwsDoc::S3::SHA256: \n                request.SetChecksumSHA256(hashData); \n                break; \n            case AwsDoc::S3::CRC32: \n                request.SetChecksumCRC32(hashData); \n                break; \n            case AwsDoc::S3::CRC32C: \n                request.SetChecksumCRC32C(hashData); \n                break; \n            default: \n                std::cerr << \"Unknown hash method.\" << std::endl; \n                return false; \n        } \n    } \n    request.SetBody(body); \n    Aws::S3::Model::PutObjectOutcome outcome = client.PutObject(request); \n    body->seekg(0, body->beg); \n    if (outcome.IsSuccess()) { \n        std::cout << \"Object successfully uploaded.\" << std::endl; \n    } else { \n        std::cerr << \"Error uploading object.\" << \n                  outcome.GetError().GetMessage() << std::endl; \n    } \n    return outcome.IsSuccess();\n}\n// ! Routine which retrieves the hash value of an object stored in an S3 bucket.\n/*! \n   \\param bucket: The name of the S3 bucket where the object is stored. \n   \\param key: The unique identifier (key) of the object within the S3 bucket.", "\n   \\param hashMethod: The hashing algorithm used to calculate the hash value of \n the object. \n   \\param[out] hashData: The retrieved hash. \n   \\param[out] partHashes: The part hashes if available.", "\n   \\param client: The S3 client instance used to retrieve the object.", "\n   \\return bool: Function succeeded.\n*/\nbool AwsDoc::S3::retrieveObjectHash(const Aws::String &bucket, const Aws::String \n &key, \n                                    AwsDoc::S3::HASH_METHOD hashMethod, \n                                    Aws::String &hashData, \nScenarios API Version 2006-03-01 2542Amazon Simple Storage Service API Reference\n                                    std::vector<Aws::String> *partHashes, \n                                    const Aws::S3::S3Client &client) { \n    Aws::S3::Model::GetObjectAttributesRequest request; \n    request.SetBucket(bucket); \n    request.SetKey(key); \n    if (hashMethod == MD5) { \n        Aws::Vector<Aws::S3::Model::ObjectAttributes> attributes; \n        attributes.push_back(Aws::S3::Model::ObjectAttributes::ETag); \n        request.SetObjectAttributes(attributes); \n        Aws::S3::Model::GetObjectAttributesOutcome outcome = \n client.GetObjectAttributes( \n                request); \n        if (outcome.IsSuccess()) { \n            const Aws::S3::Model::GetObjectAttributesResult &result = \n outcome.GetResult(); \n            hashData = result.GetETag(); \n        } else { \n            std::cerr << \"Error retrieving object etag attributes.\" << \n                      outcome.GetError().GetMessage() << std::endl; \n            return false; \n        } \n    } else { // hashMethod != MD5 \n        Aws::Vector<Aws::S3::Model::ObjectAttributes> attributes; \n        attributes.push_back(Aws::S3::Model::ObjectAttributes::Checksum); \n        request.SetObjectAttributes(attributes); \n        Aws::S3::Model::GetObjectAttributesOutcome outcome = \n client.GetObjectAttributes( \n                request); \n        if (outcome.IsSuccess()) { \n            const Aws::S3::Model::GetObjectAttributesResult &result = \n outcome.GetResult(); \n            switch (hashMethod) { \n                case AwsDoc::S3::DEFAULT: // NOLINT(*-branch-clone) \n                    break;  // Default is not supported.\n#pragma clang diagnostic push\n#pragma ide diagnostic ignored \"UnreachableCode\" \n                case AwsDoc::S3::MD5: \n                    break;  // MD5 is not supported.\n#pragma clang diagnostic pop \n                case AwsDoc::S3::SHA1: \n                    hashData = result.GetChecksum().GetChecksumSHA1(); \nScenarios API Version 2006-03-01 2543Amazon Simple Storage Service API Reference\n                    break; \n                case AwsDoc::S3::SHA256: \n                    hashData = result.GetChecksum().GetChecksumSHA256(); \n                    break; \n                case AwsDoc::S3::CRC32: \n                    hashData = result.GetChecksum().GetChecksumCRC32(); \n                    break; \n                case AwsDoc::S3::CRC32C: \n                    hashData = result.GetChecksum().GetChecksumCRC32C(); \n                    break; \n                default: \n                    std::cerr << \"Unknown hash method.\" << std::endl; \n                    return false; \n            } \n        } else { \n            std::cerr << \"Error retrieving object checksum attributes.\" << \n                      outcome.GetError().GetMessage() << std::endl; \n            return false; \n        } \n        if (nullptr != partHashes) { \n            attributes.clear(); \n            attributes.push_back(Aws::S3::Model::ObjectAttributes::ObjectParts); \n            request.SetObjectAttributes(attributes); \n            outcome = client.GetObjectAttributes(request); \n            if (outcome.IsSuccess()) { \n                const Aws::S3::Model::GetObjectAttributesResult &result = \n outcome.GetResult(); \n                const Aws::Vector<Aws::S3::Model::ObjectPart> parts = \n result.GetObjectParts().GetParts(); \n                for (const Aws::S3::Model::ObjectPart &part: parts) { \n                    switch (hashMethod) { \n                        case AwsDoc::S3::DEFAULT: // Default is not supported.", "\n NOLINT(*-branch-clone) \n                            break; \n                        case AwsDoc::S3::MD5: // MD5 is not supported.", "\n                            break; \n                        case AwsDoc::S3::SHA1: \n                            partHashes->push_back(part.GetChecksumSHA1()); \n                            break; \n                        case AwsDoc::S3::SHA256: \n                            partHashes->push_back(part.GetChecksumSHA256()); \n                            break; \n                        case AwsDoc::S3::CRC32: \nScenarios API Version 2006-03-01 2544Amazon Simple Storage Service API Reference\n                            partHashes->push_back(part.GetChecksumCRC32()); \n                            break; \n                        case AwsDoc::S3::CRC32C: \n                            partHashes->push_back(part.GetChecksumCRC32C()); \n                            break; \n                        default: \n                            std::cerr << \"Unknown hash method.\" << std::endl; \n                            return false; \n                    } \n                } \n            } else { \n                std::cerr << \"Error retrieving object attributes for object \n parts.\" << \n                          outcome.GetError().GetMessage() << std::endl; \n                return false; \n            } \n        } \n    } \n    return true;\n}\n//!", "Verifies the hashing results between the retrieved and local hashes.\n/*! \n \\param retrievedHash The hash value retrieved from the remote source. \n \\param localHash The hash value calculated locally.", "\n \\param uploadtype The type of upload (e.g., \"multipart\", \"single-part\").", "\n \\param hashMethod The hashing method used (e.g., MD5, SHA-256). \n \\param retrievedPartHashes (Optional) The list of hashes for the individual \n parts retrieved from the remote source. \n \\param localPartHashes (Optional) The list of hashes for the individual parts \n calculated locally. \n */\nvoid AwsDoc::S3::verifyHashingResults(const Aws::String &retrievedHash, \n                                      const Hasher &localHash, \n                                      const Aws::String &uploadtype, \n                                      HASH_METHOD hashMethod, \n                                      const std::vector<Aws::String> \n &retrievedPartHashes, \n                                      const std::vector<Aws::String> \n &localPartHashes) { \n    std::cout << \"For \" << uploadtype << \" retrieved hash is \" << retrievedHash \n << std::endl; \n    if (!retrievedPartHashes.empty()) { \nScenarios API Version 2006-03-01 2545Amazon Simple Storage Service API Reference\n        std::cout << retrievedPartHashes.size() << \" part hash(es) were also \n retrieved.\" \n                  << std::endl; \n        for (auto &retrievedPartHash: retrievedPartHashes) { \n            std::cout << \"  Part hash \" << retrievedPartHash << std::endl; \n        } \n    } \n    Aws::String hashString; \n    if (hashMethod == MD5) { \n        hashString = localHash.getHexHashString(); \n        if (!localPartHashes.empty()) { \n            hashString += \"-\" + std::to_string(localPartHashes.size()); \n        } \n    } else { \n        hashString = localHash.getBase64HashString(); \n    } \n    bool allMatch = true; \n    if (hashString != retrievedHash) { \n        std::cerr << \"For \" << uploadtype << \", the main hashes do not match\" << \n std::endl; \n        std::cerr << \"Local hash- '\" << hashString << \"'\" << std::endl; \n        std::cerr << \"Remote hash - '\" << retrievedHash << \"'\" << std::endl; \n        allMatch = false; \n    } \n    if (hashMethod != MD5) { \n        if (localPartHashes.size() != retrievedPartHashes.size()) { \n            std::cerr << \"For \" << uploadtype << \", the number of part hashes do \n not match\" << std::endl; \n            std::cerr << \"Local number of hashes- '\" << localPartHashes.size() << \n \"'\" \n                      << std::endl; \n            std::cerr << \"Remote number of hashes - '\" \n                      << retrievedPartHashes.size() \n                      << \"'\" << std::endl; \n        } \n        for (int i = 0; i < localPartHashes.size(); ++i) { \n            if (localPartHashes[i] != retrievedPartHashes[i]) { \n                std::cerr << \"For \" << uploadtype << \", the part hashes do not \n match for part \" << i + 1 \n                          << \".\" << std::endl; \n                std::cerr << \"Local hash- '\" << localPartHashes[i] << \"'\" \nScenarios API Version 2006-03-01 2546Amazon Simple Storage Service API Reference\n                          << std::endl; \n                std::cerr << \"Remote hash - '\" << retrievedPartHashes[i] << \"'\" \n                          << std::endl; \n                allMatch = false; \n            } \n        } \n    } \n    if (allMatch) { \n        std::cout << \"For \" << uploadtype << \", locally and remotely calculated \n hashes all match!\" << std::endl; \n    }\n}\nstatic void transferManagerErrorCallback(const Aws::Transfer::TransferManager *, \n                                         const std::shared_ptr<const \n Aws::Transfer::TransferHandle> &, \n                                         const \n Aws::Client::AWSError<Aws::S3::S3Errors> &err) { \n    std::cerr << \"Error during transfer: '\" << err.GetMessage() << \"'\" << \n std::endl;\n}\nstatic void transferManagerStatusCallback(const Aws::Transfer::TransferManager *, \n                                          const std::shared_ptr<const \n Aws::Transfer::TransferHandle> &handle) { \n    if (handle->GetStatus() == Aws::Transfer::TransferStatus::IN_PROGRESS) { \n        std::cout << \"Bytes transferred: \" << handle->GetBytesTransferred() << \n std::endl; \n    }\n}\n//!", "Routine which uploads an object to an S3 bucket using the AWS C++ SDK's \n Transfer Manager.\n/*! \n   \\param bucket: The name of the S3 bucket where the object will be uploaded. \n   \\param key: The unique identifier (key) for the object within the S3 bucket.", "\n   \\param hashMethod: The hashing algorithm to use when calculating the hash \n value. \n   \\param useDefaultHashMethod: A flag indicating whether to use the default hash \n method or the one specified in the hashMethod parameter.", "\n   \\param client: The S3 client instance used to perform the upload operation. \n   \\return bool: Function succeeded.\nScenarios API Version 2006-03-01 2547Amazon Simple Storage Service API Reference\n*/\nbool\nAwsDoc::S3::doTransferManagerUpload(const Aws::String &bucket, const Aws::String \n &key, \n                                    AwsDoc::S3::HASH_METHOD hashMethod, \n                                    bool useDefaultHashMethod, \n                                    const std::shared_ptr<Aws::S3::S3Client> \n &client) { \n    std::shared_ptr<Aws::Utils::Threading::PooledThreadExecutor> executor = \n Aws::MakeShared<Aws::Utils::Threading::PooledThreadExecutor>( \n            \"executor\", 25); \n    Aws::Transfer::TransferManagerConfiguration transfer_config(executor.get()); \n    transfer_config.s3Client = client; \n    transfer_config.bufferSize = UPLOAD_BUFFER_SIZE; \n    if (!useDefaultHashMethod) { \n        if (hashMethod == MD5) { \n            transfer_config.computeContentMD5 = true; \n        } else { \n            transfer_config.checksumAlgorithm = \n getChecksumAlgorithmForHashMethod( \n                    hashMethod); \n        } \n    } \n    transfer_config.errorCallback = transferManagerErrorCallback; \n    transfer_config.transferStatusUpdatedCallback = \n transferManagerStatusCallback; \n    std::shared_ptr<Aws::Transfer::TransferManager> transfer_manager = \n Aws::Transfer::TransferManager::Create( \n            transfer_config); \n    std::cout << \"Uploading the file...\" << std::endl; \n    std::shared_ptr<Aws::Transfer::TransferHandle> uploadHandle = \n transfer_manager->UploadFile(MULTI_PART_TEST_FILE, \n                                                                                  \n              bucket, key, \n                                                                                  \n              \"text/plain\", \n                                                                                  \n              Aws::Map<Aws::String, Aws::String>()); \n    uploadHandle->WaitUntilFinished(); \n    bool success = \n            uploadHandle->GetStatus() == \n Aws::Transfer::TransferStatus::COMPLETED; \nScenarios API Version 2006-03-01 2548Amazon Simple Storage Service API Reference\n    if (!success) { \n        Aws::Client::AWSError<Aws::S3::S3Errors> err = uploadHandle-\n>GetLastError(); \n        std::cerr << \"File upload failed:  \" << err.GetMessage() << std::endl; \n    } \n    return success;\n}\n//! Routine which calculates the hash values for each part of a file being \n uploaded to an S3 bucket.\n/*!", "\n   \\param hashMethod: The hashing algorithm to use when calculating the hash \n values. \n   \\param fileName: The path to the file for which the part hashes will be \n calculated. \n   \\param bufferSize: The size of the buffer to use when reading the file.", "\n   \\param[out] hashDataResult: The Hasher object that will store the concatenated \n hash value. \n   \\param[out] partHashes: The vector that will store the calculated hash values \n for each part of the file. \n   \\return bool: Function succeeded.\n*/\nbool AwsDoc::S3::calculatePartHashesForFile(AwsDoc::S3::HASH_METHOD hashMethod, \n                                            const Aws::String &fileName, \n                                            size_t bufferSize, \n                                            AwsDoc::S3::Hasher &hashDataResult, \n                                            std::vector<Aws::String> &partHashes) \n { \n    std::ifstream fileStream(fileName.c_str(), std::ifstream::binary); \n    fileStream.seekg(0, std::ifstream::end); \n    size_t objectSize = fileStream.tellg(); \n    fileStream.seekg(0, std::ifstream::beg); \n    std::vector<unsigned char> totalHashBuffer; \n    size_t uploadedBytes = 0; \n    while (uploadedBytes < objectSize) { \n        std::vector<unsigned char> buffer(bufferSize); \n        std::streamsize bytesToRead = \n static_cast<std::streamsize>(std::min(buffer.size(), objectSize - \n uploadedBytes)); \n        fileStream.read((char *) buffer.data(), bytesToRead); \nScenarios API Version 2006-03-01 2549Amazon Simple Storage Service API Reference\n        Aws::Utils::Stream::PreallocatedStreamBuf \n preallocatedStreamBuf(buffer.data(), \n                                                                        \n bytesToRead); \n        std::shared_ptr<Aws::IOStream> body = \n                Aws::MakeShared<Aws::IOStream>(\"SampleAllocationTag\", \n                                               &preallocatedStreamBuf); \n        Hasher hasher; \n        if (!hasher.calculateObjectHash(*body, hashMethod)) { \n            std::cerr << \"Error calculating hash.\" << std::endl; \n            return false; \n        } \n        Aws::String base64HashString = hasher.getBase64HashString(); \n        partHashes.push_back(base64HashString); \n        Aws::Utils::ByteBuffer hashBuffer = hasher.getByteBufferHash(); \n        totalHashBuffer.insert(totalHashBuffer.end(), \n hashBuffer.GetUnderlyingData(), \n                               hashBuffer.GetUnderlyingData() + \n hashBuffer.GetLength()); \n        uploadedBytes += bytesToRead; \n    } \n    return hashDataResult.calculateObjectHash(totalHashBuffer, hashMethod);\n}\n//!", "Create a multipart upload.\n/*!", "\n    \\param bucket: The name of the S3 bucket where the object will be uploaded. \n    \\param key: The unique identifier (key) for the object within the S3 bucket. \n    \\param client: The S3 client instance used to perform the upload operation. \n    \\return Aws::String: Upload ID or empty string if failed.\n*/\nAws::String\nAwsDoc::S3::createMultipartUpload(const Aws::String &bucket, const Aws::String \n &key, \n                                  Aws::S3::Model::ChecksumAlgorithm \n checksumAlgorithm, \n                                  const Aws::S3::S3Client &client) { \n    Aws::S3::Model::CreateMultipartUploadRequest request; \n    request.SetBucket(bucket); \n    request.SetKey(key); \nScenarios API Version 2006-03-01 2550Amazon Simple Storage Service API Reference\n    if (checksumAlgorithm != Aws::S3::Model::ChecksumAlgorithm::NOT_SET) { \n        request.SetChecksumAlgorithm(checksumAlgorithm); \n    } \n    Aws::S3::Model::CreateMultipartUploadOutcome outcome = \n            client.CreateMultipartUpload(request); \n    Aws::String uploadID; \n    if (outcome.IsSuccess()) { \n        uploadID = outcome.GetResult().GetUploadId(); \n    } else { \n        std::cerr << \"Error creating multipart upload: \" << \n outcome.GetError().GetMessage() << std::endl; \n    } \n    return uploadID;\n}\n//! Upload a part to an S3 bucket.\n/*! \n    \\param bucket: The name of the S3 bucket where the object will be uploaded. \n    \\param key: The unique identifier (key) for the object within the S3 bucket.", "\n    \\param uploadID: An upload ID string.", "\n    \\param partNumber: \n    \\param checksumAlgorithm: Checksum algorithm, ignored when NOT_SET. \n    \\param calculatedHash: A data integrity hash to set, depending on the \n checksum algorithm, \n                            ignored when it is an empty string.", "\n    \\param body: An shared_ptr IOStream of the data to be uploaded.", "\n    \\param client: The S3 client instance used to perform the upload operation.", "\n    \\return UploadPartOutcome: The outcome.\n*/\nAws::S3::Model::UploadPartOutcome AwsDoc::S3::uploadPart(const Aws::String \n &bucket, \n                                                         const Aws::String &key, \n                                                         const Aws::String \n &uploadID, \n                                                         int partNumber, \n                                                         \n Aws::S3::Model::ChecksumAlgorithm checksumAlgorithm, \n                                                         const Aws::String \n &calculatedHash, \nScenarios API Version 2006-03-01 2551Amazon Simple Storage Service API Reference\n                                                         const \n std::shared_ptr<Aws::IOStream> &body, \n                                                         const Aws::S3::S3Client \n &client) { \n    Aws::S3::Model::UploadPartRequest request; \n    request.SetBucket(bucket); \n    request.SetKey(key); \n    request.SetUploadId(uploadID); \n    request.SetPartNumber(partNumber); \n    if (checksumAlgorithm != Aws::S3::Model::ChecksumAlgorithm::NOT_SET) { \n        request.SetChecksumAlgorithm(checksumAlgorithm); \n    } \n    request.SetBody(body); \n    if (!calculatedHash.empty()) { \n        switch (checksumAlgorithm) { \n            case Aws::S3::Model::ChecksumAlgorithm::NOT_SET: \n                request.SetContentMD5(calculatedHash); \n                break; \n            case Aws::S3::Model::ChecksumAlgorithm::CRC32: \n                request.SetChecksumCRC32(calculatedHash); \n                break; \n            case Aws::S3::Model::ChecksumAlgorithm::CRC32C: \n                request.SetChecksumCRC32C(calculatedHash); \n                break; \n            case Aws::S3::Model::ChecksumAlgorithm::SHA1: \n                request.SetChecksumSHA1(calculatedHash); \n                break; \n            case Aws::S3::Model::ChecksumAlgorithm::SHA256: \n                request.SetChecksumSHA256(calculatedHash); \n                break; \n        } \n    } \n    return client.UploadPart(request);\n}\n//! Abort a multipart upload to an S3 bucket.\n/*! \n    \\param bucket: The name of the S3 bucket where the object will be uploaded. \n    \\param key: The unique identifier (key) for the object within the S3 bucket.", "\n    \\param uploadID: An upload ID string.", "\n    \\param client: The S3 client instance used to perform the upload operation. \n    \\return bool: Function succeeded.\nScenarios API Version 2006-03-01 2552Amazon Simple Storage Service API Reference\n*/\nbool AwsDoc::S3::abortMultipartUpload(const Aws::String &bucket, \n                                      const Aws::String &key, \n                                      const Aws::String &uploadID, \n                                      const Aws::S3::S3Client &client) { \n    Aws::S3::Model::AbortMultipartUploadRequest request; \n    request.SetBucket(bucket); \n    request.SetKey(key); \n    request.SetUploadId(uploadID); \n    Aws::S3::Model::AbortMultipartUploadOutcome outcome = \n            client.AbortMultipartUpload(request); \n    if (outcome.IsSuccess()) { \n        std::cout << \"Multipart upload aborted.\" << std::endl; \n    } else { \n        std::cerr << \"Error aborting multipart upload: \" << \n outcome.GetError().GetMessage() << std::endl; \n    } \n    return outcome.IsSuccess();\n}\n//! Complete a multipart upload to an S3 bucket.\n/*! \n    \\param bucket: The name of the S3 bucket where the object will be uploaded. \n    \\param key: The unique identifier (key) for the object within the S3 bucket.", "\n    \\param uploadID: An upload ID string.", "\n    \\param parts: A vector of CompleteParts.", "\n    \\param client: The S3 client instance used to perform the upload operation. \n    \\return CompleteMultipartUploadOutcome: The request outcome.\n*/\nAws::S3::Model::CompleteMultipartUploadOutcome \n AwsDoc::S3::completeMultipartUpload(const Aws::String &bucket, \n                                                                                  \n  const Aws::String &key, \n                                                                                  \n  const Aws::String &uploadID, \n                                                                                  \n  const Aws::Vector<Aws::S3::Model::CompletedPart> &parts, \n                                                                                  \n  const Aws::S3::S3Client &client) { \n    Aws::S3::Model::CompletedMultipartUpload completedMultipartUpload; \nScenarios API Version 2006-03-01 2553Amazon Simple Storage Service API Reference\n    completedMultipartUpload.SetParts(parts); \n    Aws::S3::Model::CompleteMultipartUploadRequest request; \n    request.SetBucket(bucket); \n    request.SetKey(key); \n    request.SetUploadId(uploadID); \n    request.SetMultipartUpload(completedMultipartUpload); \n    Aws::S3::Model::CompleteMultipartUploadOutcome outcome = \n            client.CompleteMultipartUpload(request); \n    if (!outcome.IsSuccess()) { \n        std::cerr << \"Error completing multipart upload: \" << \n outcome.GetError().GetMessage() << std::endl; \n    } \n    return outcome;\n}\n//!", "Routine which performs a multi-part upload.\n/*!", "\n    \\param bucket: The name of the S3 bucket where the object will be uploaded. \n    \\param key: The unique identifier (key) for the object within the S3 bucket.", "\n    \\param hashMethod: The hashing algorithm to use when calculating the hash \n value.", "\n    \\param ioStream: An IOStream for the data to be uploaded.", "\n    \\param useDefaultHashMethod: A flag indicating whether to use the default \n hash method or the one specified in the hashMethod parameter. \n    \\param[out] hashDataResult: The Hasher object that will store the \n concatenated hash value. \n    \\param[out] partHashes: The vector that will store the calculated hash values \n for each part of the file.", "\n    \\param client: The S3 client instance used to perform the upload operation. \n    \\return bool: Function succeeded.\n*/\nbool AwsDoc::S3::doMultipartUpload(const Aws::String &bucket, \n                                   const Aws::String &key, \n                                   AwsDoc::S3::HASH_METHOD hashMethod, \n                                   const std::shared_ptr<Aws::IOStream> \n &ioStream, \n                                   bool useDefaultHashMethod, \n                                   AwsDoc::S3::Hasher &hashDataResult, \n                                   std::vector<Aws::String> &partHashes, \n                                   const Aws::S3::S3Client &client) { \n    // Get object size. \nScenarios API Version 2006-03-01 2554Amazon Simple Storage Service API Reference\n    ioStream->seekg(0, ioStream->end); \n    size_t objectSize = ioStream->tellg(); \n    ioStream->seekg(0, ioStream->beg); \n    Aws::S3::Model::ChecksumAlgorithm checksumAlgorithm = \n Aws::S3::Model::ChecksumAlgorithm::NOT_SET; \n    if (!useDefaultHashMethod) { \n        if (hashMethod != MD5) { \n            checksumAlgorithm = getChecksumAlgorithmForHashMethod(hashMethod); \n        } \n    } \n    Aws::String uploadID = createMultipartUpload(bucket, key, checksumAlgorithm, \n client); \n    if (uploadID.empty()) { \n        return false; \n    } \n    std::vector<unsigned char> totalHashBuffer; \n    bool uploadSucceeded = true; \n    std::streamsize uploadedBytes = 0; \n    int partNumber = 1; \n    Aws::Vector<Aws::S3::Model::CompletedPart> parts; \n    while (uploadedBytes < objectSize) { \n        std::cout << \"Uploading part \" << partNumber << \".\" << std::endl; \n        std::vector<unsigned char> buffer(UPLOAD_BUFFER_SIZE); \n        std::streamsize bytesToRead = \n static_cast<std::streamsize>(std::min(buffer.size(), \n                                                                            \n objectSize - uploadedBytes)); \n        ioStream->read((char *) buffer.data(), bytesToRead); \n        Aws::Utils::Stream::PreallocatedStreamBuf \n preallocatedStreamBuf(buffer.data(), \n                                                                        \n bytesToRead); \n        std::shared_ptr<Aws::IOStream> body = \n                Aws::MakeShared<Aws::IOStream>(\"SampleAllocationTag\", \n                                               &preallocatedStreamBuf); \n        Hasher hasher; \n        if (!hasher.calculateObjectHash(*body, hashMethod)) { \n            std::cerr << \"Error calculating hash.\" << std::endl; \n            uploadSucceeded = false; \n            break; \nScenarios API Version 2006-03-01 2555Amazon Simple Storage Service API Reference\n        } \n        Aws::String base64HashString = hasher.getBase64HashString(); \n        partHashes.push_back(base64HashString); \n        Aws::Utils::ByteBuffer hashBuffer = hasher.getByteBufferHash(); \n        totalHashBuffer.insert(totalHashBuffer.end(), \n hashBuffer.GetUnderlyingData(), \n                               hashBuffer.GetUnderlyingData() + \n hashBuffer.GetLength()); \n        Aws::String calculatedHash; \n        if (gUseCalculatedChecksum) { \n            calculatedHash = base64HashString; \n        } \n        Aws::S3::Model::UploadPartOutcome uploadPartOutcome = uploadPart(bucket, \n key, uploadID, partNumber, \n                                                                         \n checksumAlgorithm, base64HashString, body, \n                                                                         client); \n        if (uploadPartOutcome.IsSuccess()) { \n            const Aws::S3::Model::UploadPartResult &uploadPartResult = \n uploadPartOutcome.GetResult(); \n            Aws::S3::Model::CompletedPart completedPart; \n            completedPart.SetETag(uploadPartResult.GetETag()); \n            completedPart.SetPartNumber(partNumber); \n            switch (hashMethod) { \n                case AwsDoc::S3::MD5: \n                    break; // Do nothing. \n                case AwsDoc::S3::SHA1: \n                    \n completedPart.SetChecksumSHA1(uploadPartResult.GetChecksumSHA1()); \n                    break; \n                case AwsDoc::S3::SHA256: \n                    \n completedPart.SetChecksumSHA256(uploadPartResult.GetChecksumSHA256()); \n                    break; \n                case AwsDoc::S3::CRC32: \n                    \n completedPart.SetChecksumCRC32(uploadPartResult.GetChecksumCRC32()); \n                    break; \n                case AwsDoc::S3::CRC32C: \nScenarios API Version 2006-03-01 2556Amazon Simple Storage Service API Reference\n                   \n completedPart.SetChecksumCRC32C(uploadPartResult.GetChecksumCRC32C()); \n                    break; \n                default: \n                    std::cerr << \"Unhandled hash method for completedPart.\" << \n std::endl; \n                    break; \n            } \n            parts.push_back(completedPart); \n        } else { \n            std::cerr << \"Error uploading part. \" << \n                      uploadPartOutcome.GetError().GetMessage() << std::endl; \n            uploadSucceeded = false; \n            break; \n        } \n        uploadedBytes += bytesToRead; \n        partNumber++; \n    } \n    if (!uploadSucceeded) { \n        abortMultipartUpload(bucket, key, uploadID, client); \n        return false; \n    } else { \n        Aws::S3::Model::CompleteMultipartUploadOutcome \n completeMultipartUploadOutcome = completeMultipartUpload(bucket, \n                                                                                  \n                               key, \n                                                                                  \n                               uploadID, \n                                                                                  \n                               parts, \n                                                                                  \n                               client); \n        if (completeMultipartUploadOutcome.IsSuccess()) { \n            std::cout << \"Multipart upload completed.\" << std::endl; \n            if (!hashDataResult.calculateObjectHash(totalHashBuffer, hashMethod)) \n { \n                std::cerr << \"Error calculating hash.\" << std::endl; \n                return false; \n            } \nScenarios API Version 2006-03-01 2557Amazon Simple Storage Service API Reference\n        } else { \n            std::cerr << \"Error completing multipart upload.\" << \n                      completeMultipartUploadOutcome.GetError().GetMessage() \n                      << std::endl; \n        } \n        return completeMultipartUploadOutcome.IsSuccess(); \n    }\n}\n//!", "Routine which retrieves the string for a HASH_METHOD constant.\n/*! \n    \\param: hashMethod: A HASH_METHOD constant. \n    \\return: String: A string description of the hash method.\n*/\nAws::String AwsDoc::S3::stringForHashMethod(AwsDoc::S3::HASH_METHOD hashMethod) { \n    switch (hashMethod) { \n        case AwsDoc::S3::DEFAULT: \n            return \"Default\"; \n        case AwsDoc::S3::MD5: \n            return \"MD5\"; \n        case AwsDoc::S3::SHA1: \n            return \"SHA1\"; \n        case AwsDoc::S3::SHA256: \n            return \"SHA256\"; \n        case AwsDoc::S3::CRC32: \n            return \"CRC32\"; \n        case AwsDoc::S3::CRC32C: \n            return \"CRC32C\"; \n        default: \n            return \"Unknown\"; \n    }\n}\n//! Routine that returns the ChecksumAlgorithm for a HASH_METHOD constant.\n/*! \n    \\param: hashMethod: A HASH_METHOD constant.", "\n    \\return: ChecksumAlgorithm: The ChecksumAlgorithm enum.\n*/\nAws::S3::Model::ChecksumAlgorithm\nAwsDoc::S3::getChecksumAlgorithmForHashMethod(AwsDoc::S3::HASH_METHOD hashMethod) \n { \n    Aws::S3::Model::ChecksumAlgorithm result = \n Aws::S3::Model::ChecksumAlgorithm::NOT_SET; \nScenarios API Version 2006-03-01 2558Amazon Simple Storage Service API Reference\n    switch (hashMethod) { \n        case AwsDoc::S3::DEFAULT: \n            std::cerr << \"getChecksumAlgorithmForHashMethod- DEFAULT is not \n valid.\" << std::endl; \n            break;  // Default is not supported. \n        case AwsDoc::S3::MD5: \n            break; // Ignore MD5. \n        case AwsDoc::S3::SHA1: \n            result = Aws::S3::Model::ChecksumAlgorithm::SHA1; \n            break; \n        case AwsDoc::S3::SHA256: \n            result = Aws::S3::Model::ChecksumAlgorithm::SHA256; \n            break; \n        case AwsDoc::S3::CRC32: \n            result = Aws::S3::Model::ChecksumAlgorithm::CRC32; \n            break; \n        case AwsDoc::S3::CRC32C: \n            result = Aws::S3::Model::ChecksumAlgorithm::CRC32C; \n            break; \n        default: \n            std::cerr << \"Unknown hash method.\" << std::endl; \n            break; \n    } \n    return result;\n}\n//!", "Routine which cleans up after the example is complete.\n/*!", "\n    \\param bucket: The name of the S3 bucket where the object was uploaded. \n    \\param clientConfiguration: The client configuration for the S3 client. \n    \\return bool: Function succeeded.\n*/\nbool AwsDoc::S3::cleanUp(const Aws::String &bucketName, \n                         const Aws::S3::S3ClientConfiguration \n &clientConfiguration) { \n    Aws::Vector<Aws::String> keysResult; \n    bool result = true; \n    if (AwsDoc::S3::listObjects(bucketName, keysResult, clientConfiguration)) { \n        if (!keysResult.empty()) { \n            result = AwsDoc::S3::deleteObjects(keysResult, bucketName, \n                                               clientConfiguration); \nScenarios API Version 2006-03-01 2559Amazon Simple Storage Service API Reference\n        } \n    } else { \n        result = false; \n    } \n    return result && AwsDoc::S3::deleteBucket(bucketName, clientConfiguration);\n}\n//!", "Console interaction introducing the workflow.\n/*!", "\n  \\param bucketName: The name of the S3 bucket to use.\n*/\nvoid AwsDoc::S3::introductoryExplanations(const Aws::String &bucketName) { \n    std::cout \n            << \"Welcome to the Amazon Simple Storage Service (Amazon S3) object \n integrity workflow.\" \n            << std::endl; \n    printAsterisksLine(); \n    std::cout \n            << \"This workflow demonstrates how Amazon S3 uses checksum values to \n verify the integrity of data\\n\"; \n    std::cout << \"uploaded to Amazon S3 buckets\" << std::endl; \n    std::cout \n            << \"The AWS SDK for C++ automatically handles checksums.\\n\"; \n    std::cout \n            << \"By default it calculates a checksum that is uploaded with an \n object.\\n\" \n            << \"The default checksum algorithm for PutObject and MultiPart upload \n is an MD5 hash.\\n\" \n            << \"The default checksum algorithm for TransferManager uploads is a \n CRC32 checksum.\" \n            << std::endl; \n    std::cout \n            << \"You can override the default behavior, requiring one of the \n following checksums,\\n\"; \n    std::cout << \"MD5, CRC32, CRC32C, SHA-1 or SHA-256.\" << std::endl; \n    std::cout << \"You can also set the checksum hash value, instead of letting \n the SDK calculate the value.\" \n              << std::endl; \n    std::cout \n            << \"For more information, see https://docs.aws.amazon.com/AmazonS3/\nlatest/userguide/checking-object-integrity.html.\" \n            << std::endl; \nScenarios API Version 2006-03-01 2560Amazon Simple Storage Service API Reference\n    std::cout \n            << \"This workflow will locally compute checksums for files uploaded \n to an Amazon S3 bucket,\\n\"; \n    std::cout << \"even when the SDK also computes the checksum.\" << std::endl; \n    std::cout \n            << \"This is done to provide demonstration code for how the checksums \n are calculated.\" \n            << std::endl; \n    std::cout << \"A bucket named '\" << bucketName << \"' will be created for the \n object uploads.\" \n              << std::endl;\n}\n//! Console interaction which explains the PutObject results.\n/*!\n*/\nvoid AwsDoc::S3::explainPutObjectResults() { \n    std::cout << \"The upload was successful.\\n\"; \n    std::cout << \"If the checksums had not matched, the upload would have \n failed.\" \n              << std::endl; \n    std::cout \n            << \"The checksums calculated by the server have been retrieved using \n the GetObjectAttributes.\" \n            << std::endl; \n    std::cout \n            << \"The locally calculated checksums have been verified against the \n retrieved checksums.\" \n            << std::endl;\n}\n//!", "Console interaction explaining transfer manager uploads.\n/*!", "\n  \\param objectKey: The key for the object being uploaded.\n*/\nvoid AwsDoc::S3::introductoryTransferManagerUploadExplanations( \n        const Aws::String &objectKey) { \n    std::cout \n            << \"Now the workflow will demonstrate object integrity for \n TransferManager multi-part uploads.\" \n            << std::endl; \n    std::cout \nScenarios API Version 2006-03-01 2561Amazon Simple Storage Service API Reference\n            << \"The AWS C++ SDK has a TransferManager class which simplifies \n multipart uploads.\" \n            << std::endl; \n    std::cout \n            << \"The following code lets the TransferManager handle much of the \n checksum configuration.\" \n            << std::endl; \n    std::cout << \"An object with the key '\" << objectKey \n              << \" will be uploaded by the TransferManager using a \" \n              << BUFFER_SIZE_IN_MEGABYTES << \" MB buffer.\" << std::endl; \n    if (gUseCalculatedChecksum) { \n        std::cout << \"For TransferManager uploads, this demo always lets the SDK \n calculate the hash value.\" \n                  << std::endl; \n    } \n    pressEnterToContinue(); \n    printAsterisksLine();\n}\n//! Console interaction explaining multi-part uploads.\n/*! \n  \\param objectKey: The key for the object being uploaded.", "\n  \\param chosenHashMethod: The hash method selected by the user.\n*/\nvoid AwsDoc::S3::multiPartUploadExplanations(const Aws::String &objectKey, \n                                             HASH_METHOD chosenHashMethod) { \n    std::cout \n            << \"Now we will provide an in-depth demonstration of multi-part \n uploading by calling the multi-part upload APIs directly.\" \n            << std::endl; \n    std::cout << \"These are the same APIs used by the TransferManager when \n uploading large files.\" \n              << std::endl; \n    std::cout \n            << \"In the following code, the checksums are also calculated locally \n and then compared.\" \n            << std::endl; \n    std::cout \n            << \"For multi-part uploads, a checksum is uploaded with each part. \n The final checksum is a concatenation of\" \n            << std::endl; \n    std::cout << \"the checksums for each part.\" << std::endl; \nScenarios API Version 2006-03-01 2562Amazon Simple Storage Service API Reference\n    std::cout \n            << \"This is explained in the user guide, https://docs.aws.amazon.com/\nAmazonS3/latest/userguide/checking-object-integrity.html,\\\"\" \n            << \" in the section \\\"Using part-level checksums for multipart \n uploads\\\".\" << std::endl; \n    std::cout << \"Starting multipart upload of with hash method \" << \n              stringForHashMethod(chosenHashMethod) << \" uploading to with object \n key\\n\" \n              << \"'\" << objectKey << \"',\" << std::endl;\n}\n//! Create a large file for doing multi-part uploads.\n/*!\n*/\nbool AwsDoc::S3::createLargeFileIfNotExists() { \n    // Generate a large file by writing this source file multiple times to a new \n file. \n    if (std::filesystem::exists(MULTI_PART_TEST_FILE)) { \n        return true; \n    } \n    std::ofstream newFile(MULTI_PART_TEST_FILE, std::ios::out \n                                                | std::ios::binary); \n    if (!newFile) { \n        std::cerr << \"createLargeFileIfNotExists- Error creating file \" << \n MULTI_PART_TEST_FILE << \n                  std::endl; \n        return false; \n    } \n    std::ifstream input(TEST_FILE, std::ios::in \n                                   | std::ios::binary); \n    if (!input) { \n        std::cerr << \"Error opening file \" << TEST_FILE << \n                  std::endl; \n        return false; \n    } \n    std::stringstream buffer; \n    buffer << input.rdbuf(); \nScenarios API Version 2006-03-01 2563Amazon Simple Storage Service API Reference\n    input.close(); \n    while (newFile.tellp() < LARGE_FILE_SIZE && !newFile.bad()) { \n        buffer.seekg(std::stringstream::beg); \n        newFile << buffer.rdbuf(); \n    } \n    newFile.close(); \n    return true;\n}\n\u2022For API details, see the following topics in AWS SDK for C++ API Reference.\n\u2022AbortMultipartUpload\n\u2022CompleteMultipartUpload\n\u2022CreateMultipartUpload\n\u2022DeleteObject\n\u2022GetObjectAttributes\n\u2022PutObject\n\u2022UploadPart\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs.", "This topic also includes information about getting started and details \nabout previous SDK versions.\nWork with Amazon S3 versioned objects using an AWS SDK\nThe following code example shows how to:\n\u2022Create a versioned S3 bucket.\n\u2022Get all versions of an object.\n\u2022Roll an object back to a previous version.\n\u2022Delete and restore a versioned object.\n\u2022Permanently delete all versions of an object.\nScenarios API Version 2006-03-01 2564Amazon Simple Storage Service API Reference\nPython\nSDK for Python (Boto3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nCreate functions that wrap S3 actions.\ndef create_versioned_bucket(bucket_name, prefix): \n    \"\"\" \n    Creates an Amazon S3 bucket, enables it for versioning, and configures a \n lifecycle \n    that expires noncurrent object versions after 7 days.", "\n    Adding a lifecycle configuration to a versioned bucket is a best practice. \n    It helps prevent objects in the bucket from accumulating a large number of \n    noncurrent versions, which can slow down request performance.", "\n    Usage is shown in the usage_demo_single_object function at the end of this \n module.", "\n    :param bucket_name: The name of the bucket to create.", "\n    :param prefix: Identifies which objects are automatically expired under the \n                   configured lifecycle rules.", "\n    :return: The newly created bucket. \n    \"\"\" \n    try: \n        bucket = s3.create_bucket( \n            Bucket=bucket_name, \n            CreateBucketConfiguration={ \n                \"LocationConstraint\": s3.meta.client.meta.region_name \n            }, \n        ) \n        logger.info(\"Created bucket %s.\", bucket.name) \n    except ClientError as error: \n        if error.response[\"Error\"][\"Code\"] == \"BucketAlreadyOwnedByYou\": \n            logger.warning(\"Bucket %s already exists! Using it.\", bucket_name) \n            bucket = s3.Bucket(bucket_name) \n        else: \nScenarios API Version 2006-03-01 2565Amazon Simple Storage Service API Reference\n            logger.exception(\"Couldn't create bucket %s.\", bucket_name) \n            raise \n    try: \n        bucket.Versioning().enable() \n        logger.info(\"Enabled versioning on bucket %s.\", bucket.name) \n    except ClientError: \n        logger.exception(\"Couldn't enable versioning on bucket %s.\", bucket.name) \n        raise \n    try: \n        expiration = 7 \n        bucket.LifecycleConfiguration().put( \n            LifecycleConfiguration={ \n                \"Rules\": [ \n                    { \n                        \"Status\": \"Enabled\", \n                        \"Prefix\": prefix, \n                        \"NoncurrentVersionExpiration\": {\"NoncurrentDays\": \n expiration}, \n                    } \n                ] \n            } \n        ) \n        logger.info( \n            \"Configured lifecycle to expire noncurrent versions after %s days \" \n            \"on bucket %s.\", \n            expiration, \n            bucket.name, \n        ) \n    except ClientError as error: \n        logger.warning( \n            \"Couldn't configure lifecycle on bucket %s because %s. \" \n            \"Continuing anyway.\", \n            bucket.name, \n            error, \n        ) \n    return bucket\ndef rollback_object(bucket, object_key, version_id): \n    \"\"\" \nScenarios API Version 2006-03-01 2566Amazon Simple Storage Service API Reference\n    Rolls back an object to an earlier version by deleting all versions that \n    occurred after the specified rollback version.", "\n    Usage is shown in the usage_demo_single_object function at the end of this \n module.", "\n    :param bucket: The bucket that holds the object to roll back. \n    :param object_key: The object to roll back. \n    :param version_id: The version ID to roll back to.", "\n    \"\"\" \n    # Versions must be sorted by last_modified date because delete markers are \n    # at the end of the list even when they are interspersed in time. \n    versions = sorted( \n        bucket.object_versions.filter(Prefix=object_key), \n        key=attrgetter(\"last_modified\"), \n        reverse=True, \n    ) \n    logger.debug( \n        \"Got versions:\\n%s\", \n        \"\\n\".join( \n            [ \n                f\"\\t{version.version_id}, last modified {version.last_modified}\" \n                for version in versions \n            ] \n        ), \n    ) \n    if version_id in [ver.version_id for ver in versions]: \n        print(f\"Rolling back to version {version_id}\") \n        for version in versions: \n            if version.version_id != version_id: \n                version.delete() \n                print(f\"Deleted version {version.version_id}\") \n            else: \n                break \n        print(f\"Active version is now {bucket.Object(object_key).version_id}\") \n    else: \n        raise KeyError( \n            f\"{version_id} was not found in the list of versions for \" \n f\"{object_key}.\" \n        )\nScenarios API Version 2006-03-01 2567Amazon Simple Storage Service API Reference\ndef revive_object(bucket, object_key): \n    \"\"\" \n    Revives a versioned object that was deleted by removing the object's active \n    delete marker.", "\n    A versioned object presents as deleted when its latest version is a delete \n marker. \n    By removing the delete marker, we make the previous version the latest \n version \n    and the object then presents as *not* deleted.", "\n    Usage is shown in the usage_demo_single_object function at the end of this \n module.", "\n    :param bucket: The bucket that contains the object.", "\n    :param object_key: The object to revive. \n    \"\"\" \n    # Get the latest version for the object.", "\n    response = s3.meta.client.list_object_versions( \n        Bucket=bucket.name, Prefix=object_key, MaxKeys=1 \n    ) \n    if \"DeleteMarkers\" in response: \n        latest_version = response[\"DeleteMarkers\"][0] \n        if latest_version[\"IsLatest\"]: \n            logger.info( \n                \"Object %s was indeed deleted on %s. Let's revive it.\", \n                object_key, \n                latest_version[\"LastModified\"], \n            ) \n            obj = bucket.Object(object_key) \n            obj.Version(latest_version[\"VersionId\"]).delete() \n            logger.info( \n                \"Revived %s, active version is now %s  with body '%s'\", \n                object_key, \n                obj.version_id, \n                obj.get()[\"Body\"].read(), \n            ) \n        else: \n            logger.warning( \n                \"Delete marker is not the latest version for %s!\", object_key \n            ) \n    elif \"Versions\" in response: \nScenarios API Version 2006-03-01 2568Amazon Simple Storage Service API Reference\n        logger.warning(\"Got an active version for %s, nothing to do.\", \n object_key) \n    else: \n        logger.error(\"Couldn't get any version info for %s.\", object_key)\ndef permanently_delete_object(bucket, object_key): \n    \"\"\" \n    Permanently deletes a versioned object by deleting all of its versions.", "\n    Usage is shown in the usage_demo_single_object function at the end of this \n module.", "\n    :param bucket: The bucket that contains the object.", "\n    :param object_key: The object to delete.", "\n    \"\"\" \n    try: \n        bucket.object_versions.filter(Prefix=object_key).delete() \n        logger.info(\"Permanently deleted all versions of object %s.\", object_key) \n    except ClientError: \n        logger.exception(\"Couldn't delete all versions of %s.\", object_key) \n        raise\nUpload the stanza of a poem to a versioned object and perform a series of actions on it.\ndef usage_demo_single_object(obj_prefix=\"demo-versioning/\"): \n    \"\"\" \n    Demonstrates usage of versioned object functions. This demo uploads a stanza \n    of a poem and performs a series of revisions, deletions, and revivals on it.", "\n    :param obj_prefix: The prefix to assign to objects created by this demo.", "\n    \"\"\" \n    with open(\"father_william.txt\") as file: \n        stanzas = file.read().split(\"\\n\\n\") \n    width = get_terminal_size((80, 20))[0] \n    print(\"-\" * width) \n    print(\"Welcome to the usage demonstration of Amazon S3 versioning.\") \n    print( \nScenarios API Version 2006-03-01 2569Amazon Simple Storage Service API Reference\n        \"This demonstration uploads a single stanza of a poem to an Amazon \" \n        \"S3 bucket and then applies various revisions to it.\" \n    ) \n    print(\"-\" * width) \n    print(\"Creating a version-enabled bucket for the demo...\") \n    bucket = create_versioned_bucket(\"bucket-\" + str(uuid.uuid1()), obj_prefix) \n    print(\"\\nThe initial version of our stanza:\") \n    print(stanzas[0]) \n    # Add the first stanza and revise it a few times. \n    print(\"\\nApplying some revisions to the stanza...\") \n    obj_stanza_1 = bucket.Object(f\"{obj_prefix}stanza-1\") \n    obj_stanza_1.put(Body=bytes(stanzas[0], \"utf-8\")) \n    obj_stanza_1.put(Body=bytes(stanzas[0].upper(), \"utf-8\")) \n    obj_stanza_1.put(Body=bytes(stanzas[0].lower(), \"utf-8\")) \n    obj_stanza_1.put(Body=bytes(stanzas[0][::-1], \"utf-8\")) \n    print( \n        \"The latest version of the stanza is now:\", \n        obj_stanza_1.get()[\"Body\"].read().decode(\"utf-8\"), \n        sep=\"\\n\", \n    ) \n    # Versions are returned in order, most recent first. \n    obj_stanza_1_versions = \n bucket.object_versions.filter(Prefix=obj_stanza_1.key) \n    print( \n        \"The version data of the stanza revisions:\", \n        *[ \n            f\"    {version.version_id}, last modified {version.last_modified}\" \n            for version in obj_stanza_1_versions \n        ], \n        sep=\"\\n\", \n    ) \n    # Rollback two versions. \n    print(\"\\nRolling back two versions...\") \n    rollback_object(bucket, obj_stanza_1.key, list(obj_stanza_1_versions)\n[2].version_id) \n    print( \n        \"The latest version of the stanza:\", \n        obj_stanza_1.get()[\"Body\"].read().decode(\"utf-8\"), \n        sep=\"\\n\", \n    ) \nScenarios API Version 2006-03-01 2570Amazon Simple Storage Service API Reference\n    # Delete the stanza \n    print(\"\\nDeleting the stanza...\") \n    obj_stanza_1.delete() \n    try: \n        obj_stanza_1.get() \n    except ClientError as error: \n        if error.response[\"Error\"][\"Code\"] == \"NoSuchKey\": \n            print(\"The stanza is now deleted (as expected).\") \n        else: \n            raise \n    # Revive the stanza \n    print(\"\\nRestoring the stanza...\") \n    revive_object(bucket, obj_stanza_1.key) \n    print( \n        \"The stanza is restored! The latest version is again:\", \n        obj_stanza_1.get()[\"Body\"].read().decode(\"utf-8\"), \n        sep=\"\\n\", \n    ) \n    # Permanently delete all versions of the object. This cannot be undone!", "\n    print(\"\\nPermanently deleting all versions of the stanza...\") \n    permanently_delete_object(bucket, obj_stanza_1.key) \n    obj_stanza_1_versions = \n bucket.object_versions.filter(Prefix=obj_stanza_1.key) \n    if len(list(obj_stanza_1_versions)) == 0: \n        print(\"The stanza has been permanently deleted and now has no versions.\") \n    else: \n        print(\"Something went wrong. The stanza still exists!\") \n    print(f\"\\nRemoving {bucket.name}...\") \n    bucket.delete() \n    print(f\"{bucket.name} deleted.\") \n    print(\"Demo done!\")\n\u2022For API details, see the following topics in AWS SDK for Python (Boto3) API Reference.\n\u2022CreateBucket\n\u2022DeleteObject\nScenarios API Version 2006-03-01 2571Amazon Simple Storage Service API Reference\n\u2022ListObjectVersions\n\u2022PutBucketLifecycleCon\ufb01guration\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nServerless examples for Amazon S3 using AWS SDKs\nThe following code examples show how to use Amazon S3 with AWS SDKs.\nExamples\n\u2022Invoke a Lambda function from an Amazon S3 trigger\nInvoke a Lambda function from an Amazon S3 trigger\nThe following code examples show how to implement a Lambda function that receives an event \ntriggered by uploading an object to an S3 bucket. The function retrieves the S3 bucket name and \nobject key from the event parameter and calls the Amazon S3 API to retrieve and log the content \ntype of the object.\n.NET\nAWS SDK for .NET\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the Serverless examples repository.\nConsuming an S3 event with Lambda using .NET.\n// Copyright Amazon.com, Inc.", "or its affiliates.", "All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0 \nusing System.Threading.Tasks;\nusing Amazon.Lambda.Core;\nusing Amazon.S3;\nusing System;\nServerless examples API Version 2006-03-01 2572Amazon Simple Storage Service API Reference\nusing Amazon.Lambda.S3Events;\nusing System.Web;\n// Assembly attribute to enable the Lambda function's JSON input to be converted \n into a .NET class.\n[assembly: \n LambdaSerializer(typeof(Amazon.Lambda.Serialization.SystemTextJson.DefaultLambdaJsonSerializer))]\nnamespace S3Integration\n{ \n    public class Function \n    { \n        private static AmazonS3Client _s3Client; \n        public Function() : this(null) \n        { \n        } \n        internal Function(AmazonS3Client s3Client) \n        { \n            _s3Client = s3Client ?? new AmazonS3Client(); \n        } \n        public async Task<string> Handler(S3Event evt, ILambdaContext context) \n        { \n            try \n            { \n                if (evt.Records.Count <= 0) \n                { \n                    context.Logger.LogLine(\"Empty S3 Event received\"); \n                    return string.Empty; \n                } \n                var bucket = evt.Records[0].S3.Bucket.Name; \n                var key = HttpUtility.UrlDecode(evt.Records[0].S3.Object.Key); \n                context.Logger.LogLine($\"Request is for {bucket} and {key}\"); \n                var objectResult = await _s3Client.GetObjectAsync(bucket, key); \n                context.Logger.LogLine($\"Returning {objectResult.Key}\"); \n                return objectResult.Key; \n            } \n            catch (Exception e) \nServerless examples API Version 2006-03-01 2573Amazon Simple Storage Service API Reference\n            { \n                context.Logger.LogLine($\"Error processing request - \n {e.Message}\"); \n                return string.Empty; \n            } \n        } \n    }\n}\nGo\nSDK for Go V2\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the Serverless examples repository.\nConsuming an S3 event with Lambda using Go.\n// Copyright Amazon.com, Inc.", "or its affiliates.", "All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\npackage main\nimport ( \n \"context\" \n \"log\" \n \"github.com/aws/aws-lambda-go/events\" \n \"github.com/aws/aws-lambda-go/lambda\" \n \"github.com/aws/aws-sdk-go-v2/config\" \n \"github.com/aws/aws-sdk-go-v2/service/s3\"\n)\nfunc handler(ctx context.Context, s3Event events.S3Event) error { \n sdkConfig, err := config.LoadDefaultConfig(ctx) \n if err != nil { \n  log.Printf(\"failed to load default config: %s\", err) \n  return err \n } \nServerless examples API Version 2006-03-01 2574Amazon Simple Storage Service API Reference\n s3Client := s3.NewFromConfig(sdkConfig) \n for _, record := range s3Event.Records { \n  bucket := record.S3.Bucket.Name \n  key := record.S3.Object.URLDecodedKey \n  headOutput, err := s3Client.HeadObject(ctx, &s3.HeadObjectInput{ \n   Bucket: &bucket, \n   Key:    &key, \n  }) \n  if err != nil { \n   log.Printf(\"error getting head of object %s/%s: %s\", bucket, key, err) \n   return err \n  } \n  log.Printf(\"successfully retrieved %s/%s of type %s\", bucket, key, \n *headOutput.ContentType) \n } \n return nil\n}\nfunc main() { \n lambda.Start(handler)\n}\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the Serverless examples repository.\nConsuming an S3 event with Lambda using Java.\n// Copyright Amazon.com, Inc.", "or its affiliates.", "All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\npackage example;\nimport software.amazon.awssdk.services.s3.model.HeadObjectRequest;\nServerless examples API Version 2006-03-01 2575Amazon Simple Storage Service API Reference\nimport software.amazon.awssdk.services.s3.model.HeadObjectResponse;\nimport software.amazon.awssdk.services.s3.S3Client;\nimport com.amazonaws.services.lambda.runtime.Context;\nimport com.amazonaws.services.lambda.runtime.RequestHandler;\nimport com.amazonaws.services.lambda.runtime.events.S3Event;\nimport \n com.amazonaws.services.lambda.runtime.events.models.s3.S3EventNotification.S3EventNotificationRecord;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\npublic class Handler implements RequestHandler<S3Event, String> { \n    private static final Logger logger = LoggerFactory.getLogger(Handler.class); \n    @Override \n    public String handleRequest(S3Event s3event, Context context) { \n        try { \n          S3EventNotificationRecord record = s3event.getRecords().get(0); \n          String srcBucket = record.getS3().getBucket().getName(); \n          String srcKey = record.getS3().getObject().getUrlDecodedKey(); \n          S3Client s3Client = S3Client.builder().build(); \n          HeadObjectResponse headObject = getHeadObject(s3Client, srcBucket, \n srcKey); \n          logger.info(\"Successfully retrieved \" + srcBucket + \"/\" + srcKey + \" of \n type \" + headObject.contentType()); \n          return \"Ok\"; \n        } catch (Exception e) { \n          throw new RuntimeException(e); \n        } \n    } \n    private HeadObjectResponse getHeadObject(S3Client s3Client, String bucket, \n String key) { \n        HeadObjectRequest headObjectRequest = HeadObjectRequest.builder() \n                .bucket(bucket) \n                .key(key) \n                .build(); \n        return s3Client.headObject(headObjectRequest); \n    }\n}\nServerless examples API Version 2006-03-01 2576Amazon Simple Storage Service API Reference\nJavaScript\nSDK for JavaScript (v3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the Serverless examples repository.\nConsuming an S3 event with Lambda using JavaScript.\nimport { S3Client, HeadObjectCommand } from \"@aws-sdk/client-s3\";\nconst client = new S3Client();\nexport const handler = async (event, context) => { \n    // Get the object from the event and show its content type \n    const bucket = event.Records[0].s3.bucket.name; \n    const key = decodeURIComponent(event.Records[0].s3.object.key.replace(/\\+/g, \n ' ')); \n    try { \n        const { ContentType } = await client.send(new HeadObjectCommand({ \n            Bucket: bucket, \n            Key: key, \n        })); \n        console.log('CONTENT TYPE:', ContentType); \n        return ContentType; \n    } catch (err) { \n        console.log(err); \n        const message = `Error getting object ${key} from bucket ${bucket}. Make \n sure they exist and your bucket is in the same region as this function.`; \n        console.log(message); \n        throw new Error(message); \n    }\n};\nServerless examples API Version 2006-03-01 2577Amazon Simple Storage Service API Reference\nConsuming an S3 event with Lambda using TypeScript.\n// Copyright Amazon.com, Inc.", "or its affiliates.", "All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nimport { S3Event } from 'aws-lambda';\nimport { S3Client, HeadObjectCommand } from '@aws-sdk/client-s3';\nconst s3 = new S3Client({ region: process.env.AWS_REGION });\nexport const handler = async (event: S3Event): Promise<string | undefined> => { \n  // Get the object from the event and show its content type \n  const bucket = event.Records[0].s3.bucket.name; \n  const key = decodeURIComponent(event.Records[0].s3.object.key.replace(/\\+/g, ' \n ')); \n  const params = { \n    Bucket: bucket, \n    Key: key, \n  }; \n  try { \n    const { ContentType } = await s3.send(new HeadObjectCommand(params)); \n    console.log('CONTENT TYPE:', ContentType); \n    return ContentType; \n  } catch (err) { \n    console.log(err); \n    const message = `Error getting object ${key} from bucket ${bucket}.", "Make sure \n they exist and your bucket is in the same region as this function.`; \n    console.log(message); \n    throw new Error(message); \n  }\n};\nPHP\nSDK for PHP\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the Serverless examples repository.\nServerless examples API Version 2006-03-01 2578Amazon Simple Storage Service API Reference\nConsuming an S3 event with Lambda using PHP.\n<?php\nuse Bref\\Context\\Context;\nuse Bref\\Event\\S3\\S3Event;\nuse Bref\\Event\\S3\\S3Handler;\nuse Bref\\Logger\\StderrLogger;\nrequire __DIR__ . '/vendor/autoload.php';\nclass Handler extends S3Handler  \n{ \n    private StderrLogger $logger; \n    public function __construct(StderrLogger $logger) \n    { \n        $this->logger = $logger; \n    } \n     \n    public function handleS3(S3Event $event, Context $context) : void \n    { \n        $this->logger->info(\"Processing S3 records\"); \n        // Get the object from the event and show its content type \n        $records = $event->getRecords(); \n         \n        foreach ($records as $record)  \n        { \n            $bucket = $record->getBucket()->getName(); \n            $key = urldecode($record->getObject()->getKey()); \n            try { \n                $fileSize = urldecode($record->getObject()->getSize()); \n                echo \"File Size: \" .", "$fileSize .", "\"\\n\"; \n                // TODO: Implement your custom processing logic here \n            } catch (Exception $e) { \n                echo $e->getMessage() . \"\\n\"; \n                echo 'Error getting object ' .", "$key .", "' from bucket ' . \n $bucket .", "'.", "Make sure they exist and your bucket is in the same region as this \n function.' .", "\"\\n\"; \n                throw $e; \n            } \n        } \nServerless examples API Version 2006-03-01 2579Amazon Simple Storage Service API Reference\n    }\n}\n$logger = new StderrLogger();\nreturn new Handler($logger);\nPython\nSDK for Python (Boto3)\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the Serverless examples repository.\nConsuming an S3 event with Lambda using Python.\n# Copyright Amazon.com, Inc.", "or its affiliates.", "All Rights Reserved.\n# SPDX-License-Identifier: Apache-2.0\nimport json\nimport urllib.parse\nimport boto3\nprint('Loading function')\ns3 = boto3.client('s3')\ndef lambda_handler(event, context): \n    #print(\"Received event: \" + json.dumps(event, indent=2)) \n    # Get the object from the event and show its content type \n    bucket = event['Records'][0]['s3']['bucket']['name'] \n    key = urllib.parse.unquote_plus(event['Records'][0]['s3']['object']['key'], \n encoding='utf-8') \n    try: \n        response = s3.get_object(Bucket=bucket, Key=key) \n        print(\"CONTENT TYPE: \" + response['ContentType']) \n        return response['ContentType'] \n    except Exception as e: \nServerless examples API Version 2006-03-01 2580Amazon Simple Storage Service API Reference\n        print(e) \n        print('Error getting object {} from bucket {}.", "Make sure they exist and \n your bucket is in the same region as this function.'.format(key, bucket)) \n        raise e \n               \nRuby\nSDK for Ruby\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the Serverless examples repository.\nConsuming an S3 event with Lambda using Ruby.\nrequire 'json'\nrequire 'uri'\nrequire 'aws-sdk'\nputs 'Loading function'\ndef lambda_handler(event:, context:) \n  s3 = Aws::S3::Client.new(region: 'region') # Your AWS region \n  # puts \"Received event: #{JSON.dump(event)}\" \n  # Get the object from the event and show its content type \n  bucket = event['Records'][0]['s3']['bucket']['name'] \n  key = URI.decode_www_form_component(event['Records'][0]['s3']['object']['key'], \n Encoding::UTF_8) \n  begin \n    response = s3.get_object(bucket: bucket, key: key) \n    puts \"CONTENT TYPE: #{response.content_type}\" \n    return response.content_type \n  rescue StandardError => e \n    puts e.message \n    puts \"Error getting object #{key} from bucket #{bucket}.", "Make sure they exist \n and your bucket is in the same region as this function.\" \n    raise e \n  end\nServerless examples API Version 2006-03-01 2581Amazon Simple Storage Service API Reference\nend\nRust\nSDK for Rust\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the Serverless examples repository.\nConsuming an S3 event with Lambda using Rust.\n// Copyright Amazon.com, Inc.", "or its affiliates.", "All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nuse aws_lambda_events::event::s3::S3Event;\nuse aws_sdk_s3::{Client};\nuse lambda_runtime::{run, service_fn, Error, LambdaEvent};\n/// Main function\n#[tokio::main]\nasync fn main() -> Result<(), Error> { \n    tracing_subscriber::fmt() \n        .with_max_level(tracing::Level::INFO) \n        .with_target(false) \n        .without_time() \n        .init(); \n    // Initialize the AWS SDK for Rust \n    let config = aws_config::load_from_env().await; \n    let s3_client = Client::new(&config); \n    let res = run(service_fn(|request: LambdaEvent<S3Event>| { \n        function_handler(&s3_client, request) \n    })).await; \n    res\n}\nServerless examples API Version 2006-03-01 2582Amazon Simple Storage Service API Reference\nasync fn function_handler( \n    s3_client: &Client, \n    evt: LambdaEvent<S3Event>\n) -> Result<(), Error> { \n    tracing::info!(records = ?evt.payload.records.len(), \"Received request from \n SQS\"); \n    if evt.payload.records.len() == 0 { \n        tracing::info!(\"Empty S3 event received\"); \n    } \n    let bucket = evt.payload.records[0].s3.bucket.name.as_ref().expect(\"Bucket \n name to exist\"); \n    let key = evt.payload.records[0].s3.object.key.as_ref().expect(\"Object key to \n exist\"); \n    tracing::info!(\"Request is for {} and object {}\", bucket, key); \n    let s3_get_object_result = s3_client \n        .get_object() \n        .bucket(bucket) \n        .key(key) \n        .send() \n        .await; \n    match s3_get_object_result { \n        Ok(_) => tracing::info!(\"S3 Get Object success, the s3GetObjectResult \n contains a 'body' property of type ByteStream\"), \n        Err(_) => tracing::info!(\"Failure with S3 Get Object request\") \n    } \n    Ok(())\n}\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nServerless examples API Version 2006-03-01 2583Amazon Simple Storage Service API Reference\nCode examples for Amazon S3 Control using AWS SDKs\nThe following code examples show how to use Amazon S3 Control with an AWS software \ndevelopment kit (SDK).\nBasics  are code examples that show you how to perform the essential operations within a service.\nActions  are code excerpts from larger programs and must be run in context. While actions show you \nhow to call individual service functions, you can see actions in context in their related scenarios.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nGet started\nHello Amazon S3 Control\nThe following code example shows how to get started using 'Amazon S3 Control'\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nimport \n software.amazon.awssdk.auth.credentials.EnvironmentVariableCredentialsProvider;\nimport software.amazon.awssdk.core.client.config.ClientOverrideConfiguration;\nimport software.amazon.awssdk.core.retry.RetryMode;\nimport software.amazon.awssdk.core.retry.RetryPolicy;\nimport software.amazon.awssdk.http.async.SdkAsyncHttpClient;\nimport software.amazon.awssdk.http.nio.netty.NettyNioAsyncHttpClient;\nimport software.amazon.awssdk.regions.Region;\nimport software.amazon.awssdk.services.s3control.S3ControlAsyncClient;\nimport software.amazon.awssdk.services.s3control.model.JobListDescriptor;\nimport software.amazon.awssdk.services.s3control.model.JobStatus;\nimport software.amazon.awssdk.services.s3control.model.ListJobsRequest;\nAmazon S3 Control API Version 2006-03-01 2584Amazon Simple Storage Service API Reference\nimport software.amazon.awssdk.services.s3control.paginators.ListJobsPublisher;\nimport java.time.Duration;\nimport java.util.List;\nimport java.util.concurrent.CompletableFuture;\nimport java.util.concurrent.CompletionException;\n/** \n * Before running this example: \n * <p/> \n * The SDK must be able to authenticate AWS requests on your behalf. If you have \n not configured \n * authentication for SDKs and tools,see https://docs.aws.amazon.com/sdkref/\nlatest/guide/access.html in the AWS SDKs and Tools Reference Guide.", "\n * <p/> \n * You must have a runtime environment configured with the Java SDK. \n * See https://docs.aws.amazon.com/sdk-for-java/latest/developer-guide/setup.html \n in the Developer Guide if this is not set up.", "\n */\npublic class HelloS3Batch { \n    private static S3ControlAsyncClient asyncClient; \n    public static void main(String[] args) { \n        S3BatchActions actions = new S3BatchActions(); \n        String accountId = actions.getAccountId(); \n        try { \n            listBatchJobsAsync(accountId) \n                .exceptionally(ex -> { \n                    System.err.println(\"List batch jobs failed: \" + \n ex.getMessage()); \n                    return null; \n                }) \n                .join(); \n        } catch (CompletionException ex) { \n            System.err.println(\"Failed to list batch jobs: \" + ex.getMessage()); \n        } \n    } \n    /** \n     * Retrieves the asynchronous S3 Control client instance. \n     * <p> \n     * This method creates and returns a singleton instance of the {@link \n S3ControlAsyncClient}. If the instance \nAmazon S3 Control API Version 2006-03-01 2585Amazon Simple Storage Service API Reference\n     * has not been created yet, it will be initialized with the following \n configuration: \n     * <ul> \n     *   <li>Maximum concurrency: 100</li> \n     *   <li>Connection timeout: 60 seconds</li> \n     *   <li>Read timeout: 60 seconds</li> \n     *   <li>Write timeout: 60 seconds</li> \n     *   <li>API call timeout: 2 minutes</li> \n     *   <li>API call attempt timeout: 90 seconds</li> \n     *   <li>Retry policy: 3 retries</li> \n     *   <li>Region: US_EAST_1</li> \n     *   <li>Credentials provider: {@link \n EnvironmentVariableCredentialsProvider}</li> \n     * </ul> \n     * \n     * @return the asynchronous S3 Control client instance \n     */ \n    private static S3ControlAsyncClient getAsyncClient() { \n        if (asyncClient == null) { \n            SdkAsyncHttpClient httpClient = NettyNioAsyncHttpClient.builder() \n                .maxConcurrency(100) \n                .connectionTimeout(Duration.ofSeconds(60)) \n                .readTimeout(Duration.ofSeconds(60)) \n                .writeTimeout(Duration.ofSeconds(60)) \n                .build(); \n            ClientOverrideConfiguration overrideConfig = \n ClientOverrideConfiguration.builder() \n                .apiCallTimeout(Duration.ofMinutes(2)) \n                .apiCallAttemptTimeout(Duration.ofSeconds(90)) \n                .retryStrategy(RetryMode.STANDARD) \n                .build(); \n            asyncClient = S3ControlAsyncClient.builder() \n                .region(Region.US_EAST_1) \n                .httpClient(httpClient) \n                .overrideConfiguration(overrideConfig) \n                \n .credentialsProvider(EnvironmentVariableCredentialsProvider.create()) \n                .build(); \n        } \n        return asyncClient; \n    } \nAmazon S3 Control API Version 2006-03-01 2586Amazon Simple Storage Service API Reference\n    /** \n     * Asynchronously lists batch jobs that have completed for the specified \n account. \n     * \n     * @param accountId the ID of the account to list jobs for \n     * @return a CompletableFuture that completes when the job listing operation \n is finished \n     */ \n    public static CompletableFuture<Void> listBatchJobsAsync(String accountId) { \n        ListJobsRequest jobsRequest = ListJobsRequest.builder() \n            .jobStatuses(JobStatus.COMPLETE) \n            .accountId(accountId) \n            .maxResults(10) \n            .build(); \n        ListJobsPublisher publisher = \n getAsyncClient().listJobsPaginator(jobsRequest); \n        return publisher.subscribe(response -> { \n            List<JobListDescriptor> jobs = response.jobs(); \n            for (JobListDescriptor job : jobs) { \n                System.out.println(\"The job id is \" + job.jobId()); \n                System.out.println(\"The job priority is \" + job.priority()); \n            } \n        }).thenAccept(response -> { \n            System.out.println(\"Listing batch jobs completed\"); \n        }).exceptionally(ex -> { \n            System.err.println(\"Failed to list batch jobs: \" + ex.getMessage()); \n            throw new RuntimeException(ex); \n        }); \n    }\n\u2022For API details, see ListJobsPaginator in AWS SDK for Java 2.x API Reference.\nCode examples\n\u2022Basic examples for Amazon S3 Control using AWS SDKs\n\u2022Hello Amazon S3 Control\n\u2022Learn the basics of Amazon S3 Control with an AWS SDK\n\u2022Actions for Amazon S3 Control using AWS SDKs\n\u2022Use CreateJob with an AWS SDK or CLI\nAmazon S3 Control API Version 2006-03-01 2587Amazon Simple Storage Service API Reference\n\u2022Use DeleteJobTagging with an AWS SDK\n\u2022Use DescribeJob with an AWS SDK or CLI\n\u2022Use GetJobTagging with an AWS SDK\n\u2022Use PutJobTagging with an AWS SDK\n\u2022Use UpdateJobPriority with an AWS SDK or CLI\n\u2022Use UpdateJobStatus with an AWS SDK or CLI\nBasic examples for Amazon S3 Control using AWS SDKs\nThe following code examples show how to use the basics of Amazon S3 Control with AWS SDKs.\nExamples\n\u2022Hello Amazon S3 Control\n\u2022Learn the basics of Amazon S3 Control with an AWS SDK\n\u2022Actions for Amazon S3 Control using AWS SDKs\n\u2022Use CreateJob with an AWS SDK or CLI\n\u2022Use DeleteJobTagging with an AWS SDK\n\u2022Use DescribeJob with an AWS SDK or CLI\n\u2022Use GetJobTagging with an AWS SDK\n\u2022Use PutJobTagging with an AWS SDK\n\u2022Use UpdateJobPriority with an AWS SDK or CLI\n\u2022Use UpdateJobStatus with an AWS SDK or CLI\nHello Amazon S3 Control\nThe following code example shows how to get started using 'Amazon S3 Control'\nBasics API Version 2006-03-01 2588Amazon Simple Storage Service API Reference\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nimport \n software.amazon.awssdk.auth.credentials.EnvironmentVariableCredentialsProvider;\nimport software.amazon.awssdk.core.client.config.ClientOverrideConfiguration;\nimport software.amazon.awssdk.core.retry.RetryMode;\nimport software.amazon.awssdk.core.retry.RetryPolicy;\nimport software.amazon.awssdk.http.async.SdkAsyncHttpClient;\nimport software.amazon.awssdk.http.nio.netty.NettyNioAsyncHttpClient;\nimport software.amazon.awssdk.regions.Region;\nimport software.amazon.awssdk.services.s3control.S3ControlAsyncClient;\nimport software.amazon.awssdk.services.s3control.model.JobListDescriptor;\nimport software.amazon.awssdk.services.s3control.model.JobStatus;\nimport software.amazon.awssdk.services.s3control.model.ListJobsRequest;\nimport software.amazon.awssdk.services.s3control.paginators.ListJobsPublisher;\nimport java.time.Duration;\nimport java.util.List;\nimport java.util.concurrent.CompletableFuture;\nimport java.util.concurrent.CompletionException;\n/** \n * Before running this example: \n * <p/> \n * The SDK must be able to authenticate AWS requests on your behalf. If you have \n not configured \n * authentication for SDKs and tools,see https://docs.aws.amazon.com/sdkref/\nlatest/guide/access.html in the AWS SDKs and Tools Reference Guide.", "\n * <p/> \n * You must have a runtime environment configured with the Java SDK. \n * See https://docs.aws.amazon.com/sdk-for-java/latest/developer-guide/setup.html \n in the Developer Guide if this is not set up.", "\n */\npublic class HelloS3Batch { \n    private static S3ControlAsyncClient asyncClient; \nBasics API Version 2006-03-01 2589Amazon Simple Storage Service API Reference\n    public static void main(String[] args) { \n        S3BatchActions actions = new S3BatchActions(); \n        String accountId = actions.getAccountId(); \n        try { \n            listBatchJobsAsync(accountId) \n                .exceptionally(ex -> { \n                    System.err.println(\"List batch jobs failed: \" + \n ex.getMessage()); \n                    return null; \n                }) \n                .join(); \n        } catch (CompletionException ex) { \n            System.err.println(\"Failed to list batch jobs: \" + ex.getMessage()); \n        } \n    } \n    /** \n     * Retrieves the asynchronous S3 Control client instance. \n     * <p> \n     * This method creates and returns a singleton instance of the {@link \n S3ControlAsyncClient}.", "If the instance \n     * has not been created yet, it will be initialized with the following \n configuration: \n     * <ul> \n     *   <li>Maximum concurrency: 100</li> \n     *   <li>Connection timeout: 60 seconds</li> \n     *   <li>Read timeout: 60 seconds</li> \n     *   <li>Write timeout: 60 seconds</li> \n     *   <li>API call timeout: 2 minutes</li> \n     *   <li>API call attempt timeout: 90 seconds</li> \n     *   <li>Retry policy: 3 retries</li> \n     *   <li>Region: US_EAST_1</li> \n     *   <li>Credentials provider: {@link \n EnvironmentVariableCredentialsProvider}</li> \n     * </ul> \n     * \n     * @return the asynchronous S3 Control client instance \n     */ \n    private static S3ControlAsyncClient getAsyncClient() { \n        if (asyncClient == null) { \n            SdkAsyncHttpClient httpClient = NettyNioAsyncHttpClient.builder() \n                .maxConcurrency(100) \nBasics API Version 2006-03-01 2590Amazon Simple Storage Service API Reference\n                .connectionTimeout(Duration.ofSeconds(60)) \n                .readTimeout(Duration.ofSeconds(60)) \n                .writeTimeout(Duration.ofSeconds(60)) \n                .build(); \n            ClientOverrideConfiguration overrideConfig = \n ClientOverrideConfiguration.builder() \n                .apiCallTimeout(Duration.ofMinutes(2)) \n                .apiCallAttemptTimeout(Duration.ofSeconds(90)) \n                .retryStrategy(RetryMode.STANDARD) \n                .build(); \n            asyncClient = S3ControlAsyncClient.builder() \n                .region(Region.US_EAST_1) \n                .httpClient(httpClient) \n                .overrideConfiguration(overrideConfig) \n                \n .credentialsProvider(EnvironmentVariableCredentialsProvider.create()) \n                .build(); \n        } \n        return asyncClient; \n    } \n    /** \n     * Asynchronously lists batch jobs that have completed for the specified \n account. \n     * \n     * @param accountId the ID of the account to list jobs for \n     * @return a CompletableFuture that completes when the job listing operation \n is finished \n     */ \n    public static CompletableFuture<Void> listBatchJobsAsync(String accountId) { \n        ListJobsRequest jobsRequest = ListJobsRequest.builder() \n            .jobStatuses(JobStatus.COMPLETE) \n            .accountId(accountId) \n            .maxResults(10) \n            .build(); \n        ListJobsPublisher publisher = \n getAsyncClient().listJobsPaginator(jobsRequest); \n        return publisher.subscribe(response -> { \n            List<JobListDescriptor> jobs = response.jobs(); \n            for (JobListDescriptor job : jobs) { \n                System.out.println(\"The job id is \" + job.jobId()); \nBasics API Version 2006-03-01 2591Amazon Simple Storage Service API Reference\n                System.out.println(\"The job priority is \" + job.priority()); \n            } \n        }).thenAccept(response -> { \n            System.out.println(\"Listing batch jobs completed\"); \n        }).exceptionally(ex -> { \n            System.err.println(\"Failed to list batch jobs: \" + ex.getMessage()); \n            throw new RuntimeException(ex); \n        }); \n    }\n\u2022For API details, see ListJobsPaginator in AWS SDK for Java 2.x API Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs.", "This topic also includes information about getting started and details \nabout previous SDK versions.\nLearn the basics of Amazon S3 Control with an AWS SDK\nThe following code example shows how to learn core operations for'Amazon S3 Control'.\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nLearn core operations.\npackage com.example.s3.batch;\nimport software.amazon.awssdk.services.s3.model.S3Exception;\nimport java.io.IOException;\nimport java.util.Map;\nimport java.util.Scanner;\nimport java.util.UUID;\nimport java.util.concurrent.CompletionException;\nBasics API Version 2006-03-01 2592Amazon Simple Storage Service API Reference\npublic class S3BatchScenario { \n    public static final String DASHES = new String(new char[80]).replace(\"\\0\", \n \"-\"); \n    private static final String STACK_NAME = \"MyS3Stack\"; \n    public static void main(String[] args) throws IOException { \n        S3BatchActions actions = new S3BatchActions(); \n        String accountId = actions.getAccountId(); \n        String uuid = java.util.UUID.randomUUID().toString(); \n        Scanner scanner = new Scanner(System.in); \n        System.out.println(DASHES); \n        System.out.println(\"Welcome to the Amazon S3 Batch basics scenario.\"); \n        System.out.println(\"\"\" \n            S3 Batch operations enables efficient and cost-effective processing \n of large-scale  \n            data stored in Amazon S3.", "It automatically scales resources to handle \n varying workloads  \n            without the need for manual intervention.", "\n                         \n            One of the key features of S3 Batch is its ability to perform tagging \n operations on objects stored in  \n            S3 buckets. Users can leverage S3 Batch to apply, update, or remove \n tags on thousands or millions of  \n            objects in a single operation, streamlining the management and \n organization of their data.", "\n                         \n            This can be particularly useful for tasks such as cost allocation, \n lifecycle management, or  \n            metadata-driven workflows, where consistent and accurate tagging is \n essential.", "\n            S3 Batch's scalability and serverless nature make it an ideal \n solution for organizations with  \n            growing data volumes and complex data management requirements. \n                         \n            This Java program walks you through Amazon S3 Batch operations.", "\n                         \n            Let's get started...", "\n                    \n            \"\"\"); \n        waitForInputToContinue(scanner); \n        // Use CloudFormation to stand up the resource required for this \n scenario.", "\nBasics API Version 2006-03-01 2593Amazon Simple Storage Service API Reference\n        System.out.println(\"Use CloudFormation to stand up the resource required \n for this scenario.\"); \n        CloudFormationHelper.deployCloudFormationStack(STACK_NAME); \n        Map<String, String> stackOutputs = \n CloudFormationHelper.getStackOutputs(STACK_NAME); \n        String iamRoleArn = stackOutputs.get(\"S3BatchRoleArn\"); \n        System.out.println(DASHES); \n        System.out.println(DASHES); \n        System.out.println(\"Setup the required bucket for this scenario.\"); \n        waitForInputToContinue(scanner); \n        String bucketName = \"amzn-s3-demo-bucket-\" + UUID.randomUUID(); // Change \n bucket name. \n        actions.createBucket(bucketName); \n        String reportBucketName = \"arn:aws:s3:::\"+bucketName; \n        String manifestLocation = \"arn:aws:s3:::\"+bucketName+\"/job-manifest.csv\"; \n        System.out.println(\"Populate the bucket with the required files.\"); \n        String[] fileNames = {\"job-manifest.csv\", \"object-key-1.txt\", \"object-\nkey-2.txt\", \"object-key-3.txt\", \"object-key-4.txt\"}; \n        actions.uploadFilesToBucket(bucketName, fileNames, actions); \n        waitForInputToContinue(scanner); \n        System.out.println(DASHES); \n        System.out.println(DASHES); \n        System.out.println(\"1. Create a S3 Batch Job\"); \n        System.out.println(\"This job tags all objects listed in the manifest file \n with tags\"); \n        waitForInputToContinue(scanner); \n        String jobId ; \n        try { \n            jobId = actions.createS3JobAsync(accountId, iamRoleArn, \n manifestLocation, reportBucketName, uuid).join(); \n            System.out.println(\"The Job id is \" + jobId); \n        } catch (S3Exception e) { \n            System.err.println(\"SSM error: \" + e.getMessage()); \n            return; \n        } catch (RuntimeException e) { \n            System.err.println(\"Unexpected error: \" + e.getMessage()); \n            return; \n        } \n        waitForInputToContinue(scanner); \nBasics API Version 2006-03-01 2594Amazon Simple Storage Service API Reference\n        System.out.println(DASHES); \n        System.out.println(DASHES); \n        System.out.println(\"2. Update an existing S3 Batch Operations job's \n priority\"); \n        System.out.println(\"\"\" \n             In this step, we modify the job priority value.", "The higher the \n number, the higher the priority. \n             So, a job with a priority of `30` would have a higher priority than \n a job with  \n             a priority of `20`. This is a common way to represent the priority \n of a task  \n             or job, with higher numbers indicating a higher priority. \n              \n             Ensure that the job status allows for priority updates. Jobs in \n certain  \n             states (e.g., Cancelled, Failed, or Completed) cannot have their \n priorities  \n             updated. Only jobs in the Active or Suspended state typically allow \n priority  \n             updates. \n             \"\"\"); \n        try { \n            actions.updateJobPriorityAsync(jobId, accountId) \n                .exceptionally(ex -> { \n                    System.err.println(\"Update job priority failed: \" + \n ex.getMessage()); \n                    return null; \n                }) \n                .join(); \n        } catch (CompletionException ex) { \n            System.err.println(\"Failed to update job priority: \" + \n ex.getMessage()); \n        } \n        waitForInputToContinue(scanner); \n        System.out.println(DASHES); \n        System.out.println(DASHES); \n        System.out.println(\"3.", "Cancel the S3 Batch job\"); \n        System.out.print(\"Do you want to cancel the Batch job?", "(y/n): \"); \n        String cancelAns = scanner.nextLine(); \n        if (cancelAns != null && cancelAns.trim().equalsIgnoreCase(\"y\")) { \n            try { \nBasics API Version 2006-03-01 2595Amazon Simple Storage Service API Reference\n                actions.cancelJobAsync(jobId, accountId) \n                    .exceptionally(ex -> { \n                        System.err.println(\"Cancel job failed: \" + \n ex.getMessage()); \n                        return null; \n                    }) \n                    .join(); \n            } catch (CompletionException ex) { \n                System.err.println(\"Failed to cancel job: \" + ex.getMessage()); \n            } \n        } else { \n            System.out.println(\"Job \" +jobId +\" was not canceled.\"); \n        } \n        System.out.println(DASHES); \n        System.out.println(DASHES); \n        System.out.println(\"4. Describe the job that was just created\"); \n        waitForInputToContinue(scanner); \n        try { \n            actions.describeJobAsync(jobId, accountId) \n                .exceptionally(ex -> { \n                    System.err.println(\"Describe job failed: \" + \n ex.getMessage()); \n                    return null; \n                }) \n                .join(); \n        } catch (CompletionException ex) { \n            System.err.println(\"Failed to describe job: \" + ex.getMessage()); \n        } \n        System.out.println(DASHES); \n        System.out.println(DASHES); \n        System.out.println(\"5. Describe the tags associated with the job\"); \n        waitForInputToContinue(scanner); \n        try { \n            actions.getJobTagsAsync(jobId, accountId) \n                .exceptionally(ex -> { \n                    System.err.println(\"Get job tags failed: \" + \n ex.getMessage()); \n                    return null; \n                }) \n                .join(); \n        } catch (CompletionException ex) { \n            System.err.println(\"Failed to get job tags: \" + ex.getMessage()); \nBasics API Version 2006-03-01 2596Amazon Simple Storage Service API Reference\n        } \n        System.out.println(DASHES); \n        System.out.println(DASHES); \n        System.out.println(\"6. Update Batch Job Tags\"); \n        waitForInputToContinue(scanner); \n        try { \n            actions.putJobTaggingAsync(jobId, accountId) \n                .exceptionally(ex -> { \n                    System.err.println(\"Put job tagging failed: \" + \n ex.getMessage()); \n                    return null; \n                }) \n                .join(); \n        } catch (CompletionException ex) { \n            System.err.println(\"Failed to put job tagging: \" + ex.getMessage()); \n        } \n        System.out.println(DASHES); \n        System.out.println(DASHES); \n        System.out.println(\"7.", "Delete the Amazon S3 Batch job tagging.\"); \n        System.out.print(\"Do you want to delete Batch job tagging? (y/n)\"); \n        String delAns = scanner.nextLine(); \n        if (delAns != null && delAns.trim().equalsIgnoreCase(\"y\")) { \n            try { \n                actions.deleteBatchJobTagsAsync(jobId, accountId) \n                    .exceptionally(ex -> { \n                        System.err.println(\"Delete batch job tags failed: \" + \n ex.getMessage()); \n                        return null; \n                    }) \n                    .join(); \n            } catch (CompletionException ex) { \n                System.err.println(\"Failed to delete batch job tags: \" + \n ex.getMessage()); \n            } \n        } else { \n            System.out.println(\"Tagging was not deleted.\"); \n        } \n        System.out.println(DASHES); \n        System.out.println(DASHES); \n        System.out.print(\"Do you want to delete the AWS resources used in this \n scenario? (y/n)\"); \nBasics API Version 2006-03-01 2597Amazon Simple Storage Service API Reference\n        String delResAns = scanner.nextLine(); \n        if (delResAns != null && delResAns.trim().equalsIgnoreCase(\"y\")) { \n            actions.deleteFilesFromBucket(bucketName, fileNames, actions); \n            actions.deleteBucketFolderAsync(bucketName); \n            actions.deleteBucket(bucketName) \n                .thenRun(() -> System.out.println(\"Bucket deletion completed\")) \n                .exceptionally(ex -> { \n                    System.err.println(\"Error occurred: \" + ex.getMessage()); \n                    return null; \n                }); \n            CloudFormationHelper.destroyCloudFormationStack(STACK_NAME); \n        } else { \n            System.out.println(\"The AWS resources were not deleted.\"); \n        } \n        System.out.println(\"The Amazon S3 Batch scenario has successfully \n completed.\"); \n        System.out.println(DASHES); \n    } \n    private static void waitForInputToContinue(Scanner scanner) { \n        while (true) { \n            System.out.println(); \n            System.out.println(\"Enter 'c' followed by <ENTER> to continue:\"); \n            String input = scanner.nextLine(); \n            if (input.trim().equalsIgnoreCase(\"c\")) { \n                System.out.println(\"Continuing with the program...\"); \n                System.out.println(); \n                break; \n            } else { \n                // Handle invalid input.", "\n                System.out.println(\"Invalid input.", "Please try again.\"); \n            } \n        } \n    }\n}\nAn action class that wraps operations.\npublic class S3BatchActions { \nBasics API Version 2006-03-01 2598Amazon Simple Storage Service API Reference\n    private static S3ControlAsyncClient asyncClient; \n    private static S3AsyncClient s3AsyncClient ; \n    /** \n     * Retrieves the asynchronous S3 Control client instance. \n     * <p> \n     * This method creates and returns a singleton instance of the {@link \n S3ControlAsyncClient}. If the instance \n     * has not been created yet, it will be initialized with the following \n configuration: \n     * <ul> \n     *   <li>Maximum concurrency: 100</li> \n     *   <li>Connection timeout: 60 seconds</li> \n     *   <li>Read timeout: 60 seconds</li> \n     *   <li>Write timeout: 60 seconds</li> \n     *   <li>API call timeout: 2 minutes</li> \n     *   <li>API call attempt timeout: 90 seconds</li> \n     *   <li>Retry policy: 3 retries</li> \n     *   <li>Region: US_EAST_1</li> \n     *   <li>Credentials provider: {@link \n EnvironmentVariableCredentialsProvider}</li> \n     * </ul> \n     * \n     * @return the asynchronous S3 Control client instance \n     */ \n    private static S3ControlAsyncClient getAsyncClient() { \n        if (asyncClient == null) { \n            SdkAsyncHttpClient httpClient = NettyNioAsyncHttpClient.builder() \n                .maxConcurrency(100) \n                .connectionTimeout(Duration.ofSeconds(60)) \n                .readTimeout(Duration.ofSeconds(60)) \n                .writeTimeout(Duration.ofSeconds(60)) \n                .build(); \n            ClientOverrideConfiguration overrideConfig = \n ClientOverrideConfiguration.builder() \n                .apiCallTimeout(Duration.ofMinutes(2)) \n                .apiCallAttemptTimeout(Duration.ofSeconds(90)) \n                .retryPolicy(RetryPolicy.builder() \n                    .numRetries(3) \n                    .build()) \n                .build(); \nBasics API Version 2006-03-01 2599Amazon Simple Storage Service API Reference\n            asyncClient = S3ControlAsyncClient.builder() \n                .region(Region.US_EAST_1) \n                .httpClient(httpClient) \n                .overrideConfiguration(overrideConfig) \n                \n .credentialsProvider(EnvironmentVariableCredentialsProvider.create()) \n                .build(); \n        } \n        return asyncClient; \n    } \n    private static S3AsyncClient getS3AsyncClient() { \n        if (asyncClient == null) { \n            SdkAsyncHttpClient httpClient = NettyNioAsyncHttpClient.builder() \n                .maxConcurrency(100) \n                .connectionTimeout(Duration.ofSeconds(60)) \n                .readTimeout(Duration.ofSeconds(60)) \n                .writeTimeout(Duration.ofSeconds(60)) \n                .build(); \n            ClientOverrideConfiguration overrideConfig = \n ClientOverrideConfiguration.builder() \n                .apiCallTimeout(Duration.ofMinutes(2)) \n                .apiCallAttemptTimeout(Duration.ofSeconds(90)) \n                .retryStrategy(RetryMode.STANDARD) \n                .build(); \n            s3AsyncClient = S3AsyncClient.builder() \n                .region(Region.US_EAST_1) \n                .httpClient(httpClient) \n                .overrideConfiguration(overrideConfig) \n                \n .credentialsProvider(EnvironmentVariableCredentialsProvider.create()) \n                .build(); \n        } \n        return s3AsyncClient; \n    } \n    /** \n     * Cancels a job asynchronously.", "\n     * \n     * @param jobId The ID of the job to be canceled. \n     * @param accountId The ID of the account associated with the job.", "\nBasics API Version 2006-03-01 2600Amazon Simple Storage Service API Reference\n     * @return A {@link CompletableFuture} that completes when the job status has \n been updated to \"CANCELLED\".", "\n     *         If an error occurs during the update, the returned future will \n complete exceptionally.", "\n     */ \n    public CompletableFuture<Void> cancelJobAsync(String jobId, String accountId) \n { \n        UpdateJobStatusRequest updateJobStatusRequest = \n UpdateJobStatusRequest.builder() \n            .accountId(accountId) \n            .jobId(jobId) \n            .requestedJobStatus(String.valueOf(JobStatus.CANCELLED)) \n            .build(); \n        return asyncClient.updateJobStatus(updateJobStatusRequest) \n            .thenAccept(updateJobStatusResponse -> { \n                System.out.println(\"Job status updated to: \" + \n updateJobStatusResponse.status()); \n            }) \n            .exceptionally(ex -> { \n                System.err.println(\"Failed to cancel job: \" + ex.getMessage()); \n                throw new RuntimeException(ex); // Propagate the exception \n            }); \n    } \n    /** \n     * Updates the priority of a job asynchronously. \n     * \n     * @param jobId     the ID of the job to update \n     * @param accountId the ID of the account associated with the job \n     * @return a {@link CompletableFuture} that represents the asynchronous \n operation, which completes when the job priority has been updated or an error \n has occurred \n     */ \n    public CompletableFuture<Void> updateJobPriorityAsync(String jobId, String \n accountId) { \n        UpdateJobPriorityRequest priorityRequest = \n UpdateJobPriorityRequest.builder() \n            .accountId(accountId) \n            .jobId(jobId) \n            .priority(60) \n            .build(); \n        CompletableFuture<Void> future = new CompletableFuture<>(); \nBasics API Version 2006-03-01 2601Amazon Simple Storage Service API Reference\n        getAsyncClient().updateJobPriority(priorityRequest) \n            .thenAccept(response -> { \n                System.out.println(\"The job priority was updated\"); \n                future.complete(null); // Complete the CompletableFuture on \n successful execution \n            }) \n            .exceptionally(ex -> { \n                System.err.println(\"Failed to update job priority: \" + \n ex.getMessage()); \n                future.completeExceptionally(ex); // Complete the \n CompletableFuture exceptionally on error \n                return null; // Return null to handle the exception \n            }); \n        return future; \n    } \n    /** \n     * Asynchronously retrieves the tags associated with a specific job in an AWS \n account. \n     * \n     * @param jobId     the ID of the job for which to retrieve the tags \n     * @param accountId the ID of the AWS account associated with the job \n     * @return a {@link CompletableFuture} that completes when the job tags have \n been retrieved, or with an exception if the operation fails \n     * @throws RuntimeException if an error occurs while retrieving the job tags \n     */ \n    public CompletableFuture<Void> getJobTagsAsync(String jobId, String \n accountId) { \n        GetJobTaggingRequest request = GetJobTaggingRequest.builder() \n            .jobId(jobId) \n            .accountId(accountId) \n            .build(); \n        return asyncClient.getJobTagging(request) \n            .thenAccept(response -> { \n                List<S3Tag> tags = response.tags(); \n                if (tags.isEmpty()) { \n                    System.out.println(\"No tags found for job ID: \" + jobId); \n                } else { \n                    for (S3Tag tag : tags) { \n                        System.out.println(\"Tag key is: \" + tag.key()); \n                        System.out.println(\"Tag value is: \" + tag.value()); \n                    } \nBasics API Version 2006-03-01 2602Amazon Simple Storage Service API Reference\n                } \n            }) \n            .exceptionally(ex -> { \n                System.err.println(\"Failed to get job tags: \" + ex.getMessage()); \n                throw new RuntimeException(ex); // Propagate the exception \n            }); \n    } \n    /** \n     * Asynchronously deletes the tags associated with a specific batch job. \n     * \n     * @param jobId     The ID of the batch job whose tags should be deleted. \n     * @param accountId The ID of the account associated with the batch job.", "\n     * @return A CompletableFuture that completes when the job tags have been \n successfully deleted, or an exception is thrown if the deletion fails. \n     */ \n    public CompletableFuture<Void> deleteBatchJobTagsAsync(String jobId, String \n accountId) { \n        DeleteJobTaggingRequest jobTaggingRequest = \n DeleteJobTaggingRequest.builder() \n            .accountId(accountId) \n            .jobId(jobId) \n            .build(); \n        return asyncClient.deleteJobTagging(jobTaggingRequest) \n            .thenAccept(response -> { \n                System.out.println(\"You have successfully deleted \" + jobId + \" \n tagging.\"); \n            }) \n            .exceptionally(ex -> { \n                System.err.println(\"Failed to delete job tags: \" + \n ex.getMessage()); \n                throw new RuntimeException(ex); \n            }); \n    } \n    /** \n     * Asynchronously describes the specified job. \n     * \n     * @param jobId     the ID of the job to describe \n     * @param accountId the ID of the AWS account associated with the job \n     * @return a {@link CompletableFuture} that completes when the job \n description is available \n     * @throws RuntimeException if an error occurs while describing the job \nBasics API Version 2006-03-01 2603Amazon Simple Storage Service API Reference\n     */ \n    public CompletableFuture<Void> describeJobAsync(String jobId, String \n accountId) { \n        DescribeJobRequest jobRequest = DescribeJobRequest.builder() \n            .jobId(jobId) \n            .accountId(accountId) \n            .build(); \n        return getAsyncClient().describeJob(jobRequest) \n            .thenAccept(response -> { \n                System.out.println(\"Job ID: \" + response.job().jobId()); \n                System.out.println(\"Description: \" + \n response.job().description()); \n                System.out.println(\"Status: \" + response.job().statusAsString()); \n                System.out.println(\"Role ARN: \" + response.job().roleArn()); \n                System.out.println(\"Priority: \" + response.job().priority()); \n                System.out.println(\"Progress Summary: \" + \n response.job().progressSummary()); \n                // Print out details about the job manifest. \n                JobManifest manifest = response.job().manifest(); \n                System.out.println(\"Manifest Location: \" + \n manifest.location().objectArn()); \n                System.out.println(\"Manifest ETag: \" + \n manifest.location().eTag()); \n                // Print out details about the job operation.", "\n                JobOperation operation = response.job().operation(); \n                if (operation.s3PutObjectTagging() != null) { \n                    System.out.println(\"Operation: S3 Put Object Tagging\"); \n                    System.out.println(\"Tag Set: \" + \n operation.s3PutObjectTagging().tagSet()); \n                } \n                // Print out details about the job report. \n                JobReport report = response.job().report(); \n                System.out.println(\"Report Bucket: \" + report.bucket()); \n                System.out.println(\"Report Prefix: \" + report.prefix()); \n                System.out.println(\"Report Format: \" + report.format()); \n                System.out.println(\"Report Enabled: \" + report.enabled()); \n                System.out.println(\"Report Scope: \" + \n report.reportScopeAsString()); \n            }) \n            .exceptionally(ex -> { \nBasics API Version 2006-03-01 2604Amazon Simple Storage Service API Reference\n                System.err.println(\"Failed to describe job: \" + ex.getMessage()); \n                throw new RuntimeException(ex); \n            }); \n    } \n    /** \n     * Creates an asynchronous S3 job using the AWS Java SDK. \n     * \n     * @param accountId         the AWS account ID associated with the job \n     * @param iamRoleArn        the ARN of the IAM role to be used for the job \n     * @param manifestLocation  the location of the job manifest file in S3 \n     * @param reportBucketName  the name of the S3 bucket to store the job report \n     * @param uuid              a unique identifier for the job \n     * @return a CompletableFuture that represents the asynchronous creation of \n the S3 job.", "\n     *         The CompletableFuture will return the job ID if the job is created \n successfully, \n     *         or throw an exception if there is an error.", "\n     */ \n    public CompletableFuture<String> createS3JobAsync(String accountId, String \n iamRoleArn, \n                                                      String manifestLocation, \n String reportBucketName, String uuid) { \n        String[] bucketName = new String[]{\"\"}; \n        String[] parts = reportBucketName.split(\":::\"); \n        if (parts.length > 1) { \n            bucketName[0] = parts[1]; \n        } else { \n            System.out.println(\"The input string does not contain the expected \n format.\"); \n        } \n        return CompletableFuture.supplyAsync(() -> getETag(bucketName[0], \"job-\nmanifest.csv\")) \n            .thenCompose(eTag -> { \n                  ArrayList<S3Tag> tagSet = new ArrayList<>(); \n                S3Tag s3Tag = S3Tag.builder() \n                    .key(\"keyOne\") \n                    .value(\"ValueOne\") \n                    .build(); \n                S3Tag s3Tag2 = S3Tag.builder() \n                    .key(\"keyTwo\") \n                    .value(\"ValueTwo\") \nBasics API Version 2006-03-01 2605Amazon Simple Storage Service API Reference\n                    .build(); \n                tagSet.add(s3Tag); \n                tagSet.add(s3Tag2); \n                S3SetObjectTaggingOperation objectTaggingOperation = \n S3SetObjectTaggingOperation.builder() \n                    .tagSet(tagSet) \n                    .build(); \n                JobOperation jobOperation = JobOperation.builder() \n                    .s3PutObjectTagging(objectTaggingOperation) \n                    .build(); \n                JobManifestLocation jobManifestLocation = \n JobManifestLocation.builder() \n                    .objectArn(manifestLocation) \n                    .eTag(eTag) \n                    .build(); \n                JobManifestSpec manifestSpec = JobManifestSpec.builder() \n                    .fieldsWithStrings(\"Bucket\", \"Key\") \n                    .format(\"S3BatchOperations_CSV_20180820\") \n                    .build(); \n                JobManifest jobManifest = JobManifest.builder() \n                    .spec(manifestSpec) \n                    .location(jobManifestLocation) \n                    .build(); \n                JobReport jobReport = JobReport.builder() \n                    .bucket(reportBucketName) \n                    .prefix(\"reports\") \n                    .format(\"Report_CSV_20180820\") \n                    .enabled(true) \n                    .reportScope(\"AllTasks\") \n                    .build(); \n                CreateJobRequest jobRequest = CreateJobRequest.builder() \n                    .accountId(accountId) \n                    .description(\"Job created using the AWS Java SDK\") \n                    .manifest(jobManifest) \n                    .operation(jobOperation) \n                    .report(jobReport) \n                    .priority(42) \nBasics API Version 2006-03-01 2606Amazon Simple Storage Service API Reference\n                    .roleArn(iamRoleArn) \n                    .clientRequestToken(uuid) \n                    .confirmationRequired(false) \n                    .build(); \n                // Create the job asynchronously. \n                 return getAsyncClient().createJob(jobRequest) \n                    .thenApply(CreateJobResponse::jobId); \n                 }) \n                 .handle((jobId, ex) -> { \n                    if (ex != null) { \n                    Throwable cause = (ex instanceof CompletionException) ?", "\n ex.getCause() : ex; \n                    if (cause instanceof S3ControlException) { \n                        throw new CompletionException(cause); \n                    } else { \n                        throw new RuntimeException(cause); \n                    } \n                } \n                return jobId; \n            }); \n    } \n    /** \n     * Retrieves the ETag (Entity Tag) for an object stored in an Amazon S3 \n bucket. \n     * \n     * @param bucketName the name of the Amazon S3 bucket where the object is \n stored \n     * @param key the key (file name) of the object in the Amazon S3 bucket \n     * @return the ETag of the object \n     */ \n    public String getETag(String bucketName, String key) { \n        S3Client s3Client = S3Client.builder() \n            .region(Region.US_EAST_1) \n            .build(); \n        HeadObjectRequest headObjectRequest = HeadObjectRequest.builder() \n            .bucket(bucketName) \n            .key(key) \n            .build(); \n        HeadObjectResponse headObjectResponse = \n s3Client.headObject(headObjectRequest); \nBasics API Version 2006-03-01 2607Amazon Simple Storage Service API Reference\n        return headObjectResponse.eTag(); \n    } \n    /** \n     * Asynchronously adds tags to a job in the system.", "\n     * \n     * @param jobId     the ID of the job to add tags to \n     * @param accountId the account ID associated with the job \n     * @return a CompletableFuture that completes when the tagging operation is \n finished \n     */ \n    public CompletableFuture<Void> putJobTaggingAsync(String jobId, String \n accountId) { \n        S3Tag departmentTag = S3Tag.builder() \n            .key(\"department\") \n            .value(\"Marketing\") \n            .build(); \n        S3Tag fiscalYearTag = S3Tag.builder() \n            .key(\"FiscalYear\") \n            .value(\"2020\") \n            .build(); \n        PutJobTaggingRequest putJobTaggingRequest = \n PutJobTaggingRequest.builder() \n            .jobId(jobId) \n            .accountId(accountId) \n            .tags(departmentTag, fiscalYearTag) \n            .build(); \n        return asyncClient.putJobTagging(putJobTaggingRequest) \n            .thenRun(() -> { \n                System.out.println(\"Additional Tags were added to job \" + jobId); \n            }) \n            .exceptionally(ex -> { \n                System.err.println(\"Failed to add tags to job: \" + \n ex.getMessage()); \n                throw new RuntimeException(ex); // Propagate the exception \n            }); \n    } \n    // Setup the S3 bucket required for this scenario.", "\n    /** \n     * Creates an Amazon S3 bucket with the specified name. \nBasics API Version 2006-03-01 2608Amazon Simple Storage Service API Reference\n     * \n     * @param bucketName the name of the S3 bucket to create \n     * @throws S3Exception if there is an error creating the bucket \n     */ \n    public void createBucket(String bucketName) { \n        try { \n            S3Client s3Client = S3Client.builder() \n                .region(Region.US_EAST_1) \n                .build(); \n            S3Waiter s3Waiter = s3Client.waiter(); \n            CreateBucketRequest bucketRequest = CreateBucketRequest.builder() \n                .bucket(bucketName) \n                .build(); \n            s3Client.createBucket(bucketRequest); \n            HeadBucketRequest bucketRequestWait = HeadBucketRequest.builder() \n                .bucket(bucketName) \n                .build(); \n            // Wait until the bucket is created and print out the response. \n            WaiterResponse<HeadBucketResponse> waiterResponse = \n s3Waiter.waitUntilBucketExists(bucketRequestWait); \n            waiterResponse.matched().response().ifPresent(System.out::println); \n            System.out.println(bucketName + \" is ready\"); \n        } catch (S3Exception e) { \n            System.err.println(e.awsErrorDetails().errorMessage()); \n            System.exit(1); \n        } \n    } \n    /** \n     * Uploads a file to an Amazon S3 bucket asynchronously. \n     * \n     * @param bucketName the name of the S3 bucket to upload the file to \n     * @param fileName the name of the file to be uploaded \n     * @throws RuntimeException if an error occurs during the file upload \n     */ \n    public void populateBucket(String bucketName, String fileName) { \n        // Define the path to the directory.", "\n        Path filePath = Paths.get(\"src/main/resources/batch/\", \n fileName).toAbsolutePath(); \nBasics API Version 2006-03-01 2609Amazon Simple Storage Service API Reference\n        PutObjectRequest putOb = PutObjectRequest.builder() \n            .bucket(bucketName) \n            .key(fileName) \n            .build(); \n        CompletableFuture<PutObjectResponse> future = \n getS3AsyncClient().putObject(putOb, AsyncRequestBody.fromFile(filePath)); \n        future.whenComplete((result, ex) -> { \n            if (ex != null) { \n                System.err.println(\"Error uploading file: \" + ex.getMessage()); \n            } else { \n                System.out.println(\"Successfully placed \" + fileName + \" into \n bucket \" + bucketName); \n            } \n        }).join(); \n    } \n    // Update the bucketName in CSV.", "\n    public void updateCSV(String newValue) { \n        Path csvFilePath = Paths.get(\"src/main/resources/batch/job-\nmanifest.csv\").toAbsolutePath(); \n        try { \n            // Read all lines from the CSV file.", "\n            List<String> lines = Files.readAllLines(csvFilePath); \n            // Update the first value in each line.", "\n            List<String> updatedLines = lines.stream() \n                .map(line -> { \n                    String[] parts = line.split(\",\"); \n                    parts[0] = newValue; \n                    return String.join(\",\", parts); \n                }) \n                .collect(Collectors.toList()); \n            // Write the updated lines back to the CSV file \n            Files.write(csvFilePath, updatedLines); \n            System.out.println(\"CSV file updated successfully.\"); \n        } catch (Exception e) { \n            e.printStackTrace(); \n        } \n    } \n    /** \nBasics API Version 2006-03-01 2610Amazon Simple Storage Service API Reference\n     * Deletes an object from an Amazon S3 bucket asynchronously.", "\n     * \n     * @param bucketName The name of the S3 bucket where the object is stored.", "\n     * @param objectName The name of the object to be deleted. \n     * @return A {@link CompletableFuture} that completes when the object has \n been deleted, \n     *         or throws a {@link RuntimeException} if an error occurs during the \n deletion. \n     */ \n    public CompletableFuture<Void> deleteBucketObjects(String bucketName, String \n objectName) { \n        ArrayList<ObjectIdentifier> toDelete = new ArrayList<>(); \n        toDelete.add(ObjectIdentifier.builder() \n            .key(objectName) \n            .build()); \n        DeleteObjectsRequest dor = DeleteObjectsRequest.builder() \n            .bucket(bucketName) \n            .delete(Delete.builder() \n                .objects(toDelete).build()) \n            .build(); \n        return getS3AsyncClient().deleteObjects(dor) \n            .thenAccept(result -> { \n                System.out.println(\"The object was deleted!\"); \n            }) \n            .exceptionally(ex -> { \n                throw new RuntimeException(\"Error deleting object: \" + \n ex.getMessage(), ex); \n            }); \n    } \n    /** \n     * Deletes a folder and all its contents asynchronously from an Amazon S3 \n bucket. \n     * \n     * @param bucketName the name of the S3 bucket containing the folder to be \n deleted \n     * @return a {@link CompletableFuture} that completes when the folder and its \n contents have been deleted \n     * @throws RuntimeException if any error occurs during the deletion process \n     */ \n    public void deleteBucketFolderAsync(String bucketName) { \n        String folderName = \"reports/\"; \nBasics API Version 2006-03-01 2611Amazon Simple Storage Service API Reference\n        ListObjectsV2Request request = ListObjectsV2Request.builder() \n            .bucket(bucketName) \n            .prefix(folderName) \n            .build(); \n        CompletableFuture<ListObjectsV2Response> listObjectsFuture = \n getS3AsyncClient().listObjectsV2(request); \n        listObjectsFuture.thenCompose(response -> { \n            List<CompletableFuture<DeleteObjectResponse>> deleteFutures = \n response.contents().stream() \n                .map(obj -> { \n                    DeleteObjectRequest deleteRequest = \n DeleteObjectRequest.builder() \n                        .bucket(bucketName) \n                        .key(obj.key()) \n                        .build(); \n                    return getS3AsyncClient().deleteObject(deleteRequest) \n                        .thenApply(deleteResponse -> { \n                            System.out.println(\"Deleted object: \" + obj.key()); \n                            return deleteResponse; \n                        }); \n                }) \n                .collect(Collectors.toList()); \n            return CompletableFuture.allOf(deleteFutures.toArray(new \n CompletableFuture[0])) \n                .thenCompose(v -> { \n                    // Delete the folder. \n                    DeleteObjectRequest deleteRequest = \n DeleteObjectRequest.builder() \n                        .bucket(bucketName) \n                        .key(folderName) \n                        .build(); \n                    return getS3AsyncClient().deleteObject(deleteRequest) \n                        .thenApply(deleteResponse -> { \n                            System.out.println(\"Deleted folder: \" + folderName); \n                            return deleteResponse; \n                        }); \n                }); \n        }).join(); \n    } \n    /** \n     * Deletes an Amazon S3 bucket. \nBasics API Version 2006-03-01 2612Amazon Simple Storage Service API Reference\n     * \n     * @param bucketName the name of the bucket to delete \n     * @return a {@link CompletableFuture} that completes when the bucket has \n been deleted, or exceptionally if there is an error \n     * @throws RuntimeException if there is an error deleting the bucket \n     */ \n    public CompletableFuture<Void> deleteBucket(String bucketName) { \n        S3AsyncClient s3Client = getS3AsyncClient(); \n        return s3Client.deleteBucket(DeleteBucketRequest.builder() \n                .bucket(bucketName) \n                .build()) \n            .thenAccept(deleteBucketResponse -> { \n                System.out.println(bucketName + \" was deleted\"); \n            }) \n            .exceptionally(ex -> { \n                // Handle the exception or rethrow it. \n                throw new RuntimeException(\"Failed to delete bucket: \" + \n bucketName, ex); \n            }); \n    } \n    /** \n     * Uploads a set of files to an Amazon S3 bucket. \n     * \n     * @param bucketName the name of the S3 bucket to upload the files to \n     * @param fileNames an array of file names to be uploaded \n     * @param actions an instance of {@link S3BatchActions} that provides the \n implementation for the necessary S3 operations \n     * @throws IOException if there's an error creating the text files or \n uploading the files to the S3 bucket \n     */ \n    public static void uploadFilesToBucket(String bucketName, String[] fileNames, \n S3BatchActions actions) throws IOException { \n        actions.updateCSV(bucketName); \n        createTextFiles(fileNames); \n        for (String fileName : fileNames) { \n            actions.populateBucket(bucketName, fileName); \n        } \n        System.out.println(\"All files are placed in the S3 bucket \" + \n bucketName); \n    } \n    /** \n     * Deletes the specified files from the given S3 bucket. \nBasics API Version 2006-03-01 2613Amazon Simple Storage Service API Reference\n     * \n     * @param bucketName the name of the S3 bucket \n     * @param fileNames an array of file names to be deleted from the bucket \n     * @param actions the S3BatchActions instance to be used for the file \n deletion \n     * @throws IOException if an I/O error occurs during the file deletion \n     */ \n    public void deleteFilesFromBucket(String bucketName, String[] fileNames, \n S3BatchActions actions) throws IOException { \n        for (String fileName : fileNames) { \n                   actions.deleteBucketObjects(bucketName, fileName) \n                  .thenRun(() -> System.out.println(\"Object deletion completed\")) \n                  .exceptionally(ex -> { \n                      System.err.println(\"Error occurred: \" + ex.getMessage()); \n                      return null; \n                  }); \n        } \n        System.out.println(\"All files have been deleted from the bucket \" + \n bucketName); \n    } \n    public static void createTextFiles(String[] fileNames) { \n        String currentDirectory = System.getProperty(\"user.dir\"); \n        String directoryPath = currentDirectory + \"\\\\src\\\\main\\\\resources\\\n\\batch\"; \n        Path path = Paths.get(directoryPath); \n        try { \n            // Create the directory if it doesn't exist.", "\n            if (Files.notExists(path)) { \n                Files.createDirectories(path); \n                System.out.println(\"Created directory: \" + path.toString()); \n            } else { \n                System.out.println(\"Directory already exists: \" + \n path.toString()); \n            } \n            for (String fileName : fileNames) { \n                // Check if the file is a .txt file. \n                if (fileName.endsWith(\".txt\")) { \n                    // Define the path for the new file.", "\n                    Path filePath = path.resolve(fileName); \n                    System.out.println(\"Attempting to create file: \" + \n filePath.toString()); \nBasics API Version 2006-03-01 2614Amazon Simple Storage Service API Reference\n                    // Create and write content to the new file. \n                    Files.write(filePath, \"This is a test\".getBytes()); \n                    // Verify the file was created. \n                    if (Files.exists(filePath)) { \n                        System.out.println(\"Successfully created file: \" + \n filePath.toString()); \n                    } else { \n                        System.out.println(\"Failed to create file: \" + \n filePath.toString()); \n                    } \n                } \n            } \n        } catch (IOException e) { \n            System.err.println(\"An error occurred: \" + e.getMessage()); \n            e.printStackTrace(); \n        } \n    } \n    public String getAccountId() { \n        StsClient stsClient = StsClient.builder() \n            .region(Region.US_EAST_1) \n            .build(); \n        GetCallerIdentityResponse callerIdentityResponse = \n stsClient.getCallerIdentity(); \n        return callerIdentityResponse.account(); \n    }\n}\n\u2022For API details, see the following topics in AWS SDK for Java 2.x API Reference.\n\u2022CreateJob\n\u2022DeleteJobTagging\n\u2022DescribeJob\n\u2022GetJobTagging\n\u2022ListJobs\n\u2022PutJobTagging\nBasics API Version 2006-03-01 2615Amazon Simple Storage Service API Reference\n\u2022UpdateJobPriority\n\u2022UpdateJobStatus\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs.", "This topic also includes information about getting started and details \nabout previous SDK versions.\nActions for Amazon S3 Control using AWS SDKs\nThe following code examples demonstrate how to perform individual Amazon S3 Control actions \nwith AWS SDKs.", "Each example includes a link to GitHub, where you can \ufb01nd instructions for setting \nup and running the code.\nThe following examples include only the most commonly used actions.", "For a complete list, see the\nAmazon S3 Control API Reference.\nExamples\n\u2022Use CreateJob with an AWS SDK or CLI\n\u2022Use DeleteJobTagging with an AWS SDK\n\u2022Use DescribeJob with an AWS SDK or CLI\n\u2022Use GetJobTagging with an AWS SDK\n\u2022Use PutJobTagging with an AWS SDK\n\u2022Use UpdateJobPriority with an AWS SDK or CLI\n\u2022Use UpdateJobStatus with an AWS SDK or CLI\nUse CreateJob  with an AWS SDK or CLI\nThe following code examples show how to use CreateJob .\nAction examples are code excerpts from larger programs and must be run in context. You can see \nthis action in context in the following code example:\n\u2022Learn the basics\nBasics API Version 2006-03-01 2616Amazon Simple Storage Service API Reference\nCLI\nAWS CLI\nTo create an Amazon S3 batch operations job\nThe following create-job  example creates an Amazon S3 batch operations job to tag \nobjects as confidential` in the bucket ``employee-records .\naws s3control create-job \\ \n    --account-id 123456789012  \\ \n    --operation ' {\"S3PutObjectTagging\": { \"TagSet\": [{\"Key\":\"confidential\", \n \"Value\":\"true\"}] }} ' \\ \n    --report ' {\"Bucket\":\"arn:aws:s3:::employee-records-logs\",\"Prefix\":\"batch-op-\ncreate-job\", \n \"Format\":\"Report_CSV_20180820\",\"Enabled\":true,\"ReportScope\":\"AllTasks\"} ' \\ \n    --manifest ' {\"Spec\":{\"Format\":\"S3BatchOperations_CSV_20180820\",\"Fields\":\n[\"Bucket\",\"Key\"]},\"Location\":{\"ObjectArn\":\"arn:aws:s3:::employee-records-logs/\ninv-report/7a6a9be4-072c-407e-85a2-\nec3e982f773e.csv\",\"ETag\":\"69f52a4e9f797e987155d9c8f5880897\"}} ' \\ \n    --priority 42 \\ \n    --role-arn arn:aws:iam::123456789012:role/S3BatchJobRole\nOutput:\n{ \n    \"JobId\": \"93735294-df46-44d5-8638-6356f335324e\"\n}\n\u2022For API details, see CreateJob in AWS CLI Command Reference.\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\nBasics API Version 2006-03-01 2617Amazon Simple Storage Service API Reference\nCreate an asynchronous S3 job.\n    /** \n     * Creates an asynchronous S3 job using the AWS Java SDK. \n     * \n     * @param accountId         the AWS account ID associated with the job \n     * @param iamRoleArn        the ARN of the IAM role to be used for the job \n     * @param manifestLocation  the location of the job manifest file in S3 \n     * @param reportBucketName  the name of the S3 bucket to store the job report \n     * @param uuid              a unique identifier for the job \n     * @return a CompletableFuture that represents the asynchronous creation of \n the S3 job.", "\n     *         The CompletableFuture will return the job ID if the job is created \n successfully, \n     *         or throw an exception if there is an error.", "\n     */ \n    public CompletableFuture<String> createS3JobAsync(String accountId, String \n iamRoleArn, \n                                                      String manifestLocation, \n String reportBucketName, String uuid) { \n        String[] bucketName = new String[]{\"\"}; \n        String[] parts = reportBucketName.split(\":::\"); \n        if (parts.length > 1) { \n            bucketName[0] = parts[1]; \n        } else { \n            System.out.println(\"The input string does not contain the expected \n format.\"); \n        } \n        return CompletableFuture.supplyAsync(() -> getETag(bucketName[0], \"job-\nmanifest.csv\")) \n            .thenCompose(eTag -> { \n                  ArrayList<S3Tag> tagSet = new ArrayList<>(); \n                S3Tag s3Tag = S3Tag.builder() \n                    .key(\"keyOne\") \n                    .value(\"ValueOne\") \n                    .build(); \n                S3Tag s3Tag2 = S3Tag.builder() \n                    .key(\"keyTwo\") \n                    .value(\"ValueTwo\") \n                    .build(); \n                tagSet.add(s3Tag); \n                tagSet.add(s3Tag2); \nBasics API Version 2006-03-01 2618Amazon Simple Storage Service API Reference\n                S3SetObjectTaggingOperation objectTaggingOperation = \n S3SetObjectTaggingOperation.builder() \n                    .tagSet(tagSet) \n                    .build(); \n                JobOperation jobOperation = JobOperation.builder() \n                    .s3PutObjectTagging(objectTaggingOperation) \n                    .build(); \n                JobManifestLocation jobManifestLocation = \n JobManifestLocation.builder() \n                    .objectArn(manifestLocation) \n                    .eTag(eTag) \n                    .build(); \n                JobManifestSpec manifestSpec = JobManifestSpec.builder() \n                    .fieldsWithStrings(\"Bucket\", \"Key\") \n                    .format(\"S3BatchOperations_CSV_20180820\") \n                    .build(); \n                JobManifest jobManifest = JobManifest.builder() \n                    .spec(manifestSpec) \n                    .location(jobManifestLocation) \n                    .build(); \n                JobReport jobReport = JobReport.builder() \n                    .bucket(reportBucketName) \n                    .prefix(\"reports\") \n                    .format(\"Report_CSV_20180820\") \n                    .enabled(true) \n                    .reportScope(\"AllTasks\") \n                    .build(); \n                CreateJobRequest jobRequest = CreateJobRequest.builder() \n                    .accountId(accountId) \n                    .description(\"Job created using the AWS Java SDK\") \n                    .manifest(jobManifest) \n                    .operation(jobOperation) \n                    .report(jobReport) \n                    .priority(42) \n                    .roleArn(iamRoleArn) \n                    .clientRequestToken(uuid) \n                    .confirmationRequired(false) \nBasics API Version 2006-03-01 2619Amazon Simple Storage Service API Reference\n                    .build(); \n                // Create the job asynchronously. \n                 return getAsyncClient().createJob(jobRequest) \n                    .thenApply(CreateJobResponse::jobId); \n                 }) \n                 .handle((jobId, ex) -> { \n                    if (ex != null) { \n                    Throwable cause = (ex instanceof CompletionException) ?", "\n ex.getCause() : ex; \n                    if (cause instanceof S3ControlException) { \n                        throw new CompletionException(cause); \n                    } else { \n                        throw new RuntimeException(cause); \n                    } \n                } \n                return jobId; \n            }); \n    }\nCreate a compliance retention job.\n    /** \n     * Creates a compliance retention job in Amazon S3 Control. \n     * <p> \n     * A compliance retention job in Amazon S3 Control is a feature that allows \n you to \n     * set a retention period for objects stored in an S3 bucket.", "\n     * This feature is particularly useful for organizations that need to comply \n with \n     * regulatory requirements or internal policies that mandate the retention of \n data for \n     * a specific duration.", "\n     * \n     * @param s3ControlClient The S3ControlClient instance to use for the API \n call.", "\n     * @return The job ID of the created compliance retention job.", "\n     */ \n    public static String createComplianceRetentionJob(final S3ControlClient \n s3ControlClient, String roleArn, String bucketName, String accountId) { \nBasics API Version 2006-03-01 2620Amazon Simple Storage Service API Reference\n        final String manifestObjectArn = \"arn:aws:s3:::amzn-s3-demo-manifest-\nbucket/compliance-objects-manifest.csv\"; \n        final String manifestObjectVersionId = \"your-object-version-Id\"; \n        Instant jan2025 = Instant.parse(\"2025-01-01T00:00:00Z\"); \n        JobOperation jobOperation = JobOperation.builder() \n            .s3PutObjectRetention(S3SetObjectRetentionOperation.builder() \n                .retention(S3Retention.builder() \n                    .mode(S3ObjectLockRetentionMode.COMPLIANCE) \n                    .retainUntilDate(jan2025) \n                    .build()) \n                .build()) \n            .build(); \n        JobManifestLocation manifestLocation = JobManifestLocation.builder() \n            .objectArn(manifestObjectArn) \n            .eTag(manifestObjectVersionId) \n            .build(); \n        JobManifestSpec manifestSpec = JobManifestSpec.builder() \n            .fieldsWithStrings(\"Bucket\", \"Key\") \n            .format(\"S3BatchOperations_CSV_20180820\") \n            .build(); \n        JobManifest manifestToPublicApi = JobManifest.builder() \n            .location(manifestLocation) \n            .spec(manifestSpec) \n            .build(); \n        // Report details. \n        final String jobReportBucketArn = \"arn:aws:s3:::\" + bucketName; \n        final String jobReportPrefix = \"reports/compliance-objects-bops\"; \n        JobReport jobReport = JobReport.builder() \n            .enabled(true) \n            .reportScope(JobReportScope.ALL_TASKS) \n            .bucket(jobReportBucketArn) \n            .prefix(jobReportPrefix) \n            .format(JobReportFormat.REPORT_CSV_20180820) \n            .build(); \n        final Boolean requiresConfirmation = true; \n        final int priority = 10; \n        CreateJobRequest request = CreateJobRequest.builder() \nBasics API Version 2006-03-01 2621Amazon Simple Storage Service API Reference\n            .accountId(accountId) \n            .description(\"Set compliance retain-until to 1 Jan 2025\") \n            .manifest(manifestToPublicApi) \n            .operation(jobOperation) \n            .priority(priority) \n            .roleArn(roleArn) \n            .report(jobReport) \n            .confirmationRequired(requiresConfirmation) \n            .build(); \n        // Create the job and get the result. \n        CreateJobResponse result = s3ControlClient.createJob(request); \n        return result.jobId(); \n    }\nCreate a legal hold o\ufb00 job.\n    /** \n     * Creates a compliance retention job in Amazon S3 Control. \n     * <p> \n     * A compliance retention job in Amazon S3 Control is a feature that allows \n you to \n     * set a retention period for objects stored in an S3 bucket.", "\n     * This feature is particularly useful for organizations that need to comply \n with \n     * regulatory requirements or internal policies that mandate the retention of \n data for \n     * a specific duration.", "\n     * \n     * @param s3ControlClient The S3ControlClient instance to use for the API \n call.", "\n     * @return The job ID of the created compliance retention job.", "\n     */ \n    public static String createComplianceRetentionJob(final S3ControlClient \n s3ControlClient, String roleArn, String bucketName, String accountId) { \n        final String manifestObjectArn = \"arn:aws:s3:::amzn-s3-demo-manifest-\nbucket/compliance-objects-manifest.csv\"; \n        final String manifestObjectVersionId = \"your-object-version-Id\"; \n        Instant jan2025 = Instant.parse(\"2025-01-01T00:00:00Z\"); \n        JobOperation jobOperation = JobOperation.builder() \nBasics API Version 2006-03-01 2622Amazon Simple Storage Service API Reference\n            .s3PutObjectRetention(S3SetObjectRetentionOperation.builder() \n                .retention(S3Retention.builder() \n                    .mode(S3ObjectLockRetentionMode.COMPLIANCE) \n                    .retainUntilDate(jan2025) \n                    .build()) \n                .build()) \n            .build(); \n        JobManifestLocation manifestLocation = JobManifestLocation.builder() \n            .objectArn(manifestObjectArn) \n            .eTag(manifestObjectVersionId) \n            .build(); \n        JobManifestSpec manifestSpec = JobManifestSpec.builder() \n            .fieldsWithStrings(\"Bucket\", \"Key\") \n            .format(\"S3BatchOperations_CSV_20180820\") \n            .build(); \n        JobManifest manifestToPublicApi = JobManifest.builder() \n            .location(manifestLocation) \n            .spec(manifestSpec) \n            .build(); \n        // Report details. \n        final String jobReportBucketArn = \"arn:aws:s3:::\" + bucketName; \n        final String jobReportPrefix = \"reports/compliance-objects-bops\"; \n        JobReport jobReport = JobReport.builder() \n            .enabled(true) \n            .reportScope(JobReportScope.ALL_TASKS) \n            .bucket(jobReportBucketArn) \n            .prefix(jobReportPrefix) \n            .format(JobReportFormat.REPORT_CSV_20180820) \n            .build(); \n        final Boolean requiresConfirmation = true; \n        final int priority = 10; \n        CreateJobRequest request = CreateJobRequest.builder() \n            .accountId(accountId) \n            .description(\"Set compliance retain-until to 1 Jan 2025\") \n            .manifest(manifestToPublicApi) \n            .operation(jobOperation) \n            .priority(priority) \n            .roleArn(roleArn) \nBasics API Version 2006-03-01 2623Amazon Simple Storage Service API Reference\n            .report(jobReport) \n            .confirmationRequired(requiresConfirmation) \n            .build(); \n        // Create the job and get the result. \n        CreateJobResponse result = s3ControlClient.createJob(request); \n        return result.jobId(); \n    }\n\u2022For API details, see CreateJob in AWS SDK for Java 2.x API Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs.", "This topic also includes information about getting started and details \nabout previous SDK versions.\nUse DeleteJobTagging  with an AWS SDK\nThe following code example shows how to use DeleteJobTagging .\nAction examples are code excerpts from larger programs and must be run in context.", "You can see \nthis action in context in the following code example:\n\u2022Learn the basics\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n    /** \n     * Asynchronously deletes the tags associated with a specific batch job. \n     * \n     * @param jobId     The ID of the batch job whose tags should be deleted. \n     * @param accountId The ID of the account associated with the batch job.", "\nBasics API Version 2006-03-01 2624Amazon Simple Storage Service API Reference\n     * @return A CompletableFuture that completes when the job tags have been \n successfully deleted, or an exception is thrown if the deletion fails. \n     */ \n    public CompletableFuture<Void> deleteBatchJobTagsAsync(String jobId, String \n accountId) { \n        DeleteJobTaggingRequest jobTaggingRequest = \n DeleteJobTaggingRequest.builder() \n            .accountId(accountId) \n            .jobId(jobId) \n            .build(); \n        return asyncClient.deleteJobTagging(jobTaggingRequest) \n            .thenAccept(response -> { \n                System.out.println(\"You have successfully deleted \" + jobId + \" \n tagging.\"); \n            }) \n            .exceptionally(ex -> { \n                System.err.println(\"Failed to delete job tags: \" + \n ex.getMessage()); \n                throw new RuntimeException(ex); \n            }); \n    }\n\u2022For API details, see DeleteJobTagging in AWS SDK for Java 2.x API Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nUse DescribeJob  with an AWS SDK or CLI\nThe following code examples show how to use DescribeJob .\nAction examples are code excerpts from larger programs and must be run in context. You can see \nthis action in context in the following code example:\n\u2022Learn the basics\nBasics API Version 2006-03-01 2625Amazon Simple Storage Service API Reference\nCLI\nAWS CLI\nTo describe an Amazon S3 batch operations job\nThe following describe-job  provides con\ufb01guration parameters and status for the \nspeci\ufb01ed batch operations job.\naws s3control describe-job \\ \n    --account-id 123456789012  \\ \n    --job-id 93735294-df46-44d5-8638-6356f335324e\nOutput:\n{ \n    \"Job\": { \n        \"TerminationDate\": \"2019-10-03T21:49:53.944Z\", \n        \"JobId\": \"93735294-df46-44d5-8638-6356f335324e\", \n        \"FailureReasons\": [], \n        \"Manifest\": { \n            \"Spec\": { \n                \"Fields\": [ \n                    \"Bucket\", \n                    \"Key\" \n                ], \n                \"Format\": \"S3BatchOperations_CSV_20180820\" \n            }, \n            \"Location\": { \n                \"ETag\": \"69f52a4e9f797e987155d9c8f5880897\", \n                \"ObjectArn\": \"arn:aws:s3:::employee-records-logs/inv-\nreport/7a6a9be4-072c-407e-85a2-ec3e982f773e.csv\" \n            } \n        }, \n        \"Operation\": { \n            \"S3PutObjectTagging\": { \n                \"TagSet\": [ \n                    { \n                        \"Value\": \"true\", \n                        \"Key\": \"confidential\" \n                    } \n                ] \n            } \nBasics API Version 2006-03-01 2626Amazon Simple Storage Service API Reference\n        }, \n        \"RoleArn\": \"arn:aws:iam::123456789012:role/S3BatchJobRole\", \n        \"ProgressSummary\": { \n            \"TotalNumberOfTasks\": 8, \n            \"NumberOfTasksFailed\": 0, \n            \"NumberOfTasksSucceeded\": 8 \n        }, \n        \"Priority\": 42, \n        \"Report\": { \n            \"ReportScope\": \"AllTasks\", \n            \"Format\": \"Report_CSV_20180820\", \n            \"Enabled\": true, \n            \"Prefix\": \"batch-op-create-job\", \n            \"Bucket\": \"arn:aws:s3:::employee-records-logs\" \n        }, \n        \"JobArn\": \"arn:aws:s3:us-west-2:123456789012:job/93735294-\ndf46-44d5-8638-6356f335324e\", \n        \"CreationTime\": \"2019-10-03T21:48:48.048Z\", \n        \"Status\": \"Complete\" \n    }\n}\n\u2022For API details, see DescribeJob  in AWS CLI Command Reference.\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n    /** \n     * Asynchronously describes the specified job. \n     * \n     * @param jobId     the ID of the job to describe \n     * @param accountId the ID of the AWS account associated with the job \n     * @return a {@link CompletableFuture} that completes when the job \n description is available \n     * @throws RuntimeException if an error occurs while describing the job \nBasics API Version 2006-03-01 2627Amazon Simple Storage Service API Reference\n     */ \n    public CompletableFuture<Void> describeJobAsync(String jobId, String \n accountId) { \n        DescribeJobRequest jobRequest = DescribeJobRequest.builder() \n            .jobId(jobId) \n            .accountId(accountId) \n            .build(); \n        return getAsyncClient().describeJob(jobRequest) \n            .thenAccept(response -> { \n                System.out.println(\"Job ID: \" + response.job().jobId()); \n                System.out.println(\"Description: \" + \n response.job().description()); \n                System.out.println(\"Status: \" + response.job().statusAsString()); \n                System.out.println(\"Role ARN: \" + response.job().roleArn()); \n                System.out.println(\"Priority: \" + response.job().priority()); \n                System.out.println(\"Progress Summary: \" + \n response.job().progressSummary()); \n                // Print out details about the job manifest. \n                JobManifest manifest = response.job().manifest(); \n                System.out.println(\"Manifest Location: \" + \n manifest.location().objectArn()); \n                System.out.println(\"Manifest ETag: \" + \n manifest.location().eTag()); \n                // Print out details about the job operation.", "\n                JobOperation operation = response.job().operation(); \n                if (operation.s3PutObjectTagging() != null) { \n                    System.out.println(\"Operation: S3 Put Object Tagging\"); \n                    System.out.println(\"Tag Set: \" + \n operation.s3PutObjectTagging().tagSet()); \n                } \n                // Print out details about the job report.", "\n                JobReport report = response.job().report(); \n                System.out.println(\"Report Bucket: \" + report.bucket()); \n                System.out.println(\"Report Prefix: \" + report.prefix()); \n                System.out.println(\"Report Format: \" + report.format()); \n                System.out.println(\"Report Enabled: \" + report.enabled()); \n                System.out.println(\"Report Scope: \" + \n report.reportScopeAsString()); \n            }) \n            .exceptionally(ex -> { \nBasics API Version 2006-03-01 2628Amazon Simple Storage Service API Reference\n                System.err.println(\"Failed to describe job: \" + ex.getMessage()); \n                throw new RuntimeException(ex); \n            }); \n    }\n\u2022For API details, see DescribeJob  in AWS SDK for Java 2.x API Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nUse GetJobTagging  with an AWS SDK\nThe following code example shows how to use GetJobTagging .\nAction examples are code excerpts from larger programs and must be run in context.", "You can see \nthis action in context in the following code example:\n\u2022Learn the basics\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n    /** \n     * Asynchronously retrieves the tags associated with a specific job in an AWS \n account. \n     * \n     * @param jobId     the ID of the job for which to retrieve the tags \n     * @param accountId the ID of the AWS account associated with the job \n     * @return a {@link CompletableFuture} that completes when the job tags have \n been retrieved, or with an exception if the operation fails \n     * @throws RuntimeException if an error occurs while retrieving the job tags \nBasics API Version 2006-03-01 2629Amazon Simple Storage Service API Reference\n     */ \n    public CompletableFuture<Void> getJobTagsAsync(String jobId, String \n accountId) { \n        GetJobTaggingRequest request = GetJobTaggingRequest.builder() \n            .jobId(jobId) \n            .accountId(accountId) \n            .build(); \n        return asyncClient.getJobTagging(request) \n            .thenAccept(response -> { \n                List<S3Tag> tags = response.tags(); \n                if (tags.isEmpty()) { \n                    System.out.println(\"No tags found for job ID: \" + jobId); \n                } else { \n                    for (S3Tag tag : tags) { \n                        System.out.println(\"Tag key is: \" + tag.key()); \n                        System.out.println(\"Tag value is: \" + tag.value()); \n                    } \n                } \n            }) \n            .exceptionally(ex -> { \n                System.err.println(\"Failed to get job tags: \" + ex.getMessage()); \n                throw new RuntimeException(ex); // Propagate the exception \n            }); \n    }\n\u2022For API details, see GetJobTagging in AWS SDK for Java 2.x API Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nUse PutJobTagging  with an AWS SDK\nThe following code example shows how to use PutJobTagging .\nAction examples are code excerpts from larger programs and must be run in context.", "You can see \nthis action in context in the following code example:\n\u2022Learn the basics\nBasics API Version 2006-03-01 2630Amazon Simple Storage Service API Reference\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub.", "Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n    /** \n     * Asynchronously adds tags to a job in the system. \n     * \n     * @param jobId     the ID of the job to add tags to \n     * @param accountId the account ID associated with the job \n     * @return a CompletableFuture that completes when the tagging operation is \n finished \n     */ \n    public CompletableFuture<Void> putJobTaggingAsync(String jobId, String \n accountId) { \n        S3Tag departmentTag = S3Tag.builder() \n            .key(\"department\") \n            .value(\"Marketing\") \n            .build(); \n        S3Tag fiscalYearTag = S3Tag.builder() \n            .key(\"FiscalYear\") \n            .value(\"2020\") \n            .build(); \n        PutJobTaggingRequest putJobTaggingRequest = \n PutJobTaggingRequest.builder() \n            .jobId(jobId) \n            .accountId(accountId) \n            .tags(departmentTag, fiscalYearTag) \n            .build(); \n        return asyncClient.putJobTagging(putJobTaggingRequest) \n            .thenRun(() -> { \n                System.out.println(\"Additional Tags were added to job \" + jobId); \n            }) \n            .exceptionally(ex -> { \nBasics API Version 2006-03-01 2631Amazon Simple Storage Service API Reference\n                System.err.println(\"Failed to add tags to job: \" + \n ex.getMessage()); \n                throw new RuntimeException(ex); // Propagate the exception \n            }); \n    }\n\u2022For API details, see PutJobTagging in AWS SDK for Java 2.x API Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs.", "This topic also includes information about getting started and details \nabout previous SDK versions.\nUse UpdateJobPriority  with an AWS SDK or CLI\nThe following code examples show how to use UpdateJobPriority .\nAction examples are code excerpts from larger programs and must be run in context. You can see \nthis action in context in the following code example:\n\u2022Learn the basics\nCLI\nAWS CLI\nTo update the job priority of an Amazon S3 batch operations job\nThe following update-job-priority  example updates the speci\ufb01ed job to a new priority.\naws s3control update-job-priority \\ \n    --account-id 123456789012  \\ \n    --job-id 8d9a18fe-c303-4d39-8ccc-860d372da386  \\ \n    --priority 52\nOutput:\n{ \n    \"JobId\": \"8d9a18fe-c303-4d39-8ccc-860d372da386\", \n    \"Priority\": 52\nBasics API Version 2006-03-01 2632Amazon Simple Storage Service API Reference\n}\n\u2022For API details, see UpdateJobPriority in AWS CLI Command Reference.\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n    /** \n     * Updates the priority of a job asynchronously. \n     * \n     * @param jobId     the ID of the job to update \n     * @param accountId the ID of the account associated with the job \n     * @return a {@link CompletableFuture} that represents the asynchronous \n operation, which completes when the job priority has been updated or an error \n has occurred \n     */ \n    public CompletableFuture<Void> updateJobPriorityAsync(String jobId, String \n accountId) { \n        UpdateJobPriorityRequest priorityRequest = \n UpdateJobPriorityRequest.builder() \n            .accountId(accountId) \n            .jobId(jobId) \n            .priority(60) \n            .build(); \n        CompletableFuture<Void> future = new CompletableFuture<>(); \n        getAsyncClient().updateJobPriority(priorityRequest) \n            .thenAccept(response -> { \n                System.out.println(\"The job priority was updated\"); \n                future.complete(null); // Complete the CompletableFuture on \n successful execution \n            }) \n            .exceptionally(ex -> { \n                System.err.println(\"Failed to update job priority: \" + \n ex.getMessage()); \nBasics API Version 2006-03-01 2633Amazon Simple Storage Service API Reference\n                future.completeExceptionally(ex); // Complete the \n CompletableFuture exceptionally on error \n                return null; // Return null to handle the exception \n            }); \n        return future; \n    }\n\u2022For API details, see UpdateJobPriority in AWS SDK for Java 2.x API Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs. This topic also includes information about getting started and details \nabout previous SDK versions.\nUse UpdateJobStatus  with an AWS SDK or CLI\nThe following code examples show how to use UpdateJobStatus .\nAction examples are code excerpts from larger programs and must be run in context. You can see \nthis action in context in the following code example:\n\u2022Learn the basics\nCLI\nAWS CLI\nTo update the status of an Amazon S3 batch operations job\nThe following update-job-status  example cancels the speci\ufb01ed job which is awaiting \napproval.\naws s3control update-job-status \\ \n    --account-id 123456789012  \\ \n    --job-id 8d9a18fe-c303-4d39-8ccc-860d372da386  \\ \n    --requested-job-status Cancelled\nOutput:\n{ \nBasics API Version 2006-03-01 2634Amazon Simple Storage Service API Reference\n    \"Status\": \"Cancelled\", \n    \"JobId\": \"8d9a18fe-c303-4d39-8ccc-860d372da386\"\n}\nThe following update-job-status  example con\ufb01rms and runs the speci\ufb01ed which is \nawaiting approval.\naws s3control update-job-status \\ \n    --account-id 123456789012  \\ \n    --job-id 5782949f-3301-4fb3-be34-8d5bab54dbca  \\ \n    --requested-job-status Ready\nOutput::\n{\n    \"Status\": \"Ready\", \n    \"JobId\": \"5782949f-3301-4fb3-\nbe34-8d5bab54dbca\"\n}\nThe following update-job-status  example cancels the speci\ufb01ed job which is running.\n aws s3control update-job-status \\ \n    --account-id 123456789012 \\ \n    --job-id 5782949f-3301-4fb3-be34-8d5bab54dbca \\ \n    --requested-job-status Cancelled\nOutput::\n{ \n         \"Status\": \"Cancelling\", \n         \"JobId\": \"5782949f-3301-4fb3-be34-8d5bab54dbca\"\n}\n\u2022For API details, see UpdateJobStatus  in AWS CLI Command Reference.\nBasics API Version 2006-03-01 2635Amazon Simple Storage Service API Reference\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run \nin the AWS Code Examples Repository.\n    /** \n     * Cancels a job asynchronously.", "\n     * \n     * @param jobId The ID of the job to be canceled. \n     * @param accountId The ID of the account associated with the job. \n     * @return A {@link CompletableFuture} that completes when the job status has \n been updated to \"CANCELLED\".", "\n     *         If an error occurs during the update, the returned future will \n complete exceptionally.", "\n     */ \n    public CompletableFuture<Void> cancelJobAsync(String jobId, String accountId) \n { \n        UpdateJobStatusRequest updateJobStatusRequest = \n UpdateJobStatusRequest.builder() \n            .accountId(accountId) \n            .jobId(jobId) \n            .requestedJobStatus(String.valueOf(JobStatus.CANCELLED)) \n            .build(); \n        return asyncClient.updateJobStatus(updateJobStatusRequest) \n            .thenAccept(updateJobStatusResponse -> { \n                System.out.println(\"Job status updated to: \" + \n updateJobStatusResponse.status()); \n            }) \n            .exceptionally(ex -> { \n                System.err.println(\"Failed to cancel job: \" + ex.getMessage()); \n                throw new RuntimeException(ex); // Propagate the exception \n            }); \n    }\n\u2022For API details, see UpdateJobStatus  in AWS SDK for Java 2.x API Reference.\nBasics API Version 2006-03-01 2636Amazon Simple Storage Service API Reference\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon \nS3 using the AWS SDKs.", "This topic also includes information about getting started and details \nabout previous SDK versions.\nBasics API Version 2006-03-01 2637Amazon Simple Storage Service API Reference\nAuthenticating Requests (AWS Signature Version 4)\nTopics\n\u2022Authentication Methods\n\u2022Introduction to Signing Requests\n\u2022Authenticating Requests: Using the Authorization Header (AWS Signature Version 4)\n\u2022Authenticating Requests: Using Query Parameters (AWS Signature Version 4)\n\u2022Examples: Signature Calculations in AWS Signature Version 4\n\u2022Authenticating Requests: Browser-Based Uploads Using POST (AWS Signature Version 4)\n\u2022Amazon S3 Signature Version 4 Authentication Speci\ufb01c Policy Keys\nEvery interaction with Amazon S3 is either authenticated or anonymous. This section explains \nrequest authentication with the AWS Signature Version 4 algorithm.\nNote\nIf you use the AWS SDKs (see Sample Code and Libraries ) to send your requests, you don't \nneed to read this section because the SDK clients authenticate your requests by using \naccess keys that you provide. Unless you have a good reason not to, you should always use \nthe AWS SDKs. In Regions that support both signature versions, you can request AWS SDKs \nto use speci\ufb01c signature version.", "For more information, see Specifying Signature Version in \nRequest Authentication in the Amazon Simple Storage Service User Guide.", "You need to read \nthis section only if you are implementing the AWS Signature Version 4 algorithm in your \ncustom client.\nAuthentication with AWS Signature Version 4 provides some or all of the following, depending on \nhow you choose to sign your request:\n\u2022Veri\ufb01cation of the identity of the requester \u2013 Authenticated requests require a signature that \nyou create by using your access keys (access key ID, secret access key). For information about \ngetting access keys, see Understanding and Getting Your Security Credentials in the AWS General \nReference.", "If you are using temporary security credentials, the signature calculations also require \nAPI Version 2006-03-01 2638Amazon Simple Storage Service API Reference\na security token.", "For more information, see Requesting Temporary Security Credentials in the\nIAM User Guide .\n\u2022In-transit data protection \u2013 In order to prevent tampering with a request while it is in transit, \nyou use some of the request elements to calculate the request signature.", "Upon receiving the \nrequest, Amazon S3 calculates the signature by using the same request elements. If any request \ncomponent received by Amazon S3 does not match the component that was used to calculate \nthe signature, Amazon S3 will reject the request.\n\u2022Protect against reuse of the signed portions of the request \u2013 The signed portions (using \nAWS Signatures) of requests are valid within 15 minutes of the timestamp in the request.", "An \nunauthorized party who has access to a signed request can modify the unsigned portions of the \nrequest without a\ufb00ecting the request's validity in the 15 minute window.", "Because of this, we \nrecommend that you maximize protection by signing request headers and body, making HTTPS \nrequests to Amazon S3, and by using the s3:x-amz-content-sha256  condition key (see\nAmazon S3 Signature Version 4 Authentication Speci\ufb01c Policy Keys) in AWS policies to require \nusers to sign Amazon S3 request bodies.\nNote\nAmazon S3 supports Signature Version 4, a protocol for authenticating inbound API \nrequests to AWS services, in all AWS Regions.", "At this time, AWS Regions created before \nJanuary 30, 2014 will continue to support the previous protocol, Signature Version 2. Any \nnew Regions after January 30, 2014 will support only Signature Version 4 and therefore all \nrequests to those Regions must be made with Signature Version 4.", "For more information \nabout AWS Signature Version 2, see Signing and Authenticating REST Requests in the\nAmazon Simple Storage Service User Guide.\nAuthentication Methods\nYou can express authentication information by using one of the following methods:\n\u2022HTTP Authorization header \u2013 Using the HTTP Authorization  header is the most common \nmethod of authenticating an Amazon S3 request. All of the Amazon S3 REST operations (except \nfor browser-based uploads using POST requests) require this header.", "For more information about \nAuthentication Methods API Version 2006-03-01 2639Amazon Simple Storage Service API Reference\nthe Authorization  header value, and how to calculate signature and related options, see\nAuthenticating Requests: Using the Authorization Header (AWS Signature Version 4).\n\u2022Query string parameters \u2013 You can use a query string to express a request entirely in a URL.", "In \nthis case, you use query parameters to provide request information, including the authentication \ninformation. Because the request signature is part of the URL, this type of URL is often referred \nto as a presigned URL.", "You can use presigned URLs to embed clickable links, which can be valid \nfor up to seven days, in HTML.", "For more information, see Authenticating Requests: Using Query \nParameters (AWS Signature Version 4).\nAmazon S3 also supports browser-based uploads that use HTTP POST requests. With an HTTP \nPOST request, you can upload content to Amazon S3 directly from the browser.", "For information \nabout authenticating POST requests, see Browser-Based Uploads Using POST (AWS Signature \nVersion 4).\nIntroduction to Signing Requests\nAuthentication information that you send in a request must include a signature.", "To calculate a \nsignature, you \ufb01rst concatenate select request elements to form a string, referred to as the string \nto sign . You then use a signing key to calculate the hash-based message authentication code \n(HMAC) of the string to sign.\nIn AWS Signature Version 4, you don't use your secret access key to sign the request. Instead, you \n\ufb01rst use your secret access key to derive a signing key. The derived signing key is speci\ufb01c to the \ndate, service, and Region. For more information about how to derive a signing key in di\ufb00erent \nprogramming languages, see Examples of how to derive a signing key for Signature Version 4.\nThe following diagram illustrates the general process of computing a signature.\nIntroduction to Signing Requests API Version 2006-03-01 2640Amazon Simple Storage Service API Reference\nThe string to sign depends on the request type.", "For example, when you use the HTTP Authorization \nheader or the query parameters for authentication, you use a varying combination of request \nelements to create the string to sign. For an HTTP POST request, the POST policy in the request is \nthe string you sign. For more information about computing string to sign, follow links provided at \nthe end of this section.\nFor signing key, the diagram shows series of calculations, where result of each step you feed into \nthe next step.", "The \ufb01nal step is the signing key.\nUpon receiving an authenticated request, Amazon S3 servers re-create the signature by using the \nauthentication information that is contained in the request. If the signatures match, Amazon S3 \nprocesses your request; otherwise, the request is rejected.\nFor more information about authenticating requests, see the following topics:\n\u2022Authenticating Requests: Using the Authorization Header (AWS Signature Version 4)\n\u2022Authenticating Requests: Using Query Parameters (AWS Signature Version 4)\n\u2022Browser-Based Uploads Using POST (AWS Signature Version 4)\nAuthenticating Requests: Using the Authorization Header (AWS \nSignature Version 4)\nTopics\n\u2022Overview\nUsing an Authorization Header API Version 2006-03-01 2641Amazon Simple Storage Service API Reference\n\u2022Signature Calculations for the Authorization Header: Transferring Payload in a Single Chunk \n(AWS Signature Version 4)\n\u2022Signature Calculations for the Authorization Header: Transferring Payload in Multiple Chunks \n(Chunked Upload) (AWS Signature Version 4)\n\u2022Signature Calculations for the Authorization Header: Including Trailing Headers (Chunked \nUpload) (AWS Signature Version 4)\nOverview\nUsing the HTTP Authorization  header is the most common method of providing authentication \ninformation. Except for POST requests and requests that are signed by using query parameters, \nall Amazon S3 operations use the Authorization  request header to provide authentication \ninformation.\nThe following is an example of the Authorization  header value.", "Line breaks are added to this \nexample for readability:\nAuthorization: AWS4-HMAC-SHA256  \nCredential=AKIAIOSFODNN7EXAMPLE/20130524/us-east-1/s3/aws4_request,  \nSignedHeaders=host;range;x-amz-date,\nSignature=fe5f80f77d5fa3beca038a248ff027d0445342fe2855ddc963176630326f1024\nThe following table describes the various components of the Authorization  header value in the \npreceding example:\nComponent Description\nAWS4-HMAC-SHA256\nThe algorithm that was used to calculate the signature. You \nmust provide this value when you use AWS Signature  Version \n4 for authentication.\nThe string speci\ufb01es AWS Signature Version 4 (AWS4 ) and  the \nsigning algorithm ( HMAC-SHA256 ).\nCredential\nOverview API Version 2006-03-01 2642Amazon Simple Storage Service API Reference\nComponent Description\nYour access key ID and the scope information, which includes \nthe date, Region, and  service that were used to calculate the \nsignature.\nThis string has the following form:\n<your-access-key-id> /<date>/<aws-region> /<aws-serv \nice>/aws4_request\nWhere:\n\u2022\n<date>  value is  speci\ufb01ed using YYYYMMDD   format.\n\u2022\n<aws-service>   value is s3 when sending request to  \n Amazon S3.\nSignedHeaders\nA semicolon-separated list of request headers that you  \n used to compute Signature .", "The list includes   header \nnames only, and the header names must be in  lowercase.", "For \nexample:   \nhost;range;x-amz-date\nSignature The 256-bit signature expressed as 64 lowercase hexadecimal \ncharacters.", "For example:   \nfe5f80f77d5fa3beca038a248ff027d0445342fe2855d \ndc963176630326f1024\nNote  that the signature calculations vary depending on the \noption you  choose to transfer the payload.\nOverview API Version 2006-03-01 2643Amazon Simple Storage Service API Reference\nThe signature calculations vary depending on the method you choose to transfer the request \npayload.", "S3 supports the following options:\n\u2022Transfer payload in a single chunk \u2013 In this case, you have the following signature calculation \noptions:\n\u2022Signed payload option \u2013 You can optionally compute the entire payload checksum and \ninclude it in signature calculation.", "This provides added security but you need to read your \npayload twice or bu\ufb00er it in memory.\nFor example, in order to upload a \ufb01le, you need to read the \ufb01le \ufb01rst to compute a payload hash \nfor signature calculation and again for transmission when you create the request. For smaller \npayloads, this approach might be preferable.", "However, for large \ufb01les, reading the \ufb01le twice can \nbe ine\ufb03cient, so you might want to upload data in chunks instead.\nWe recommend you include payload checksum for added security.\n\u2022Unsigned payload option \u2013 Do not include payload checksum in signature calculation.\nFor step-by-step instructions to calculate signature and construct the Authorization header \nvalue, see Signature Calculations for the Authorization Header: Transferring Payload in a Single \nChunk (AWS Signature Version 4).\n\u2022Transfer payload in multiple chunks (chunked upload) \u2013 In this case you transfer payload in \nchunks. You can transfer a payload in chunks regardless of the payload size.\nYou can break up your payload into chunks. These can be \ufb01xed or variable-size chunks. By \nuploading data in chunks, you avoid reading the entire payload to calculate the signature. \nInstead, for the \ufb01rst chunk, you calculate a seed signature that uses only the request headers. \nThe second chunk contains the signature for the \ufb01rst chunk, and each subsequent chunk contains \nthe signature for the chunk that precedes it. At the end of the upload, you send a \ufb01nal chunk \nwith 0 bytes of data that contains the signature of the last chunk of the payload. For more \ninformation, see Signature Calculations for the Authorization Header: Transferring Payload in \nMultiple Chunks (Chunked Upload) (AWS Signature Version 4).\nWhen signing your requests, you can use either AWS Signature Version 4 or AWS Signature Version \n4A.", "The key di\ufb00erence between the two is determined by how the signature is calculated.", "With \nAWS Signature Version 4A, the signature does not include Region-speci\ufb01c information and is \ncalculated using the AWS4-ECDSA-P256-SHA256  algorithm.\nOverview API Version 2006-03-01 2644Amazon Simple Storage Service API Reference\nIn addition to these options, you have the option of including a trailer with your request. In order \nto include a trailer with your request, you need to specify that in the header by setting x-amz-\ncontent-sha256  to the appropriate value. If you are using a trailing header, you must include\nx-amz-trailer  in the header and specify the trailing header names as a string in a comma-\nseparated list.", "All trailing headers are written after the \ufb01nal chunk.", "If you're uploading the data \nin multiple chunks, you must send a \ufb01nal chunk with 0 bytes of data before sending the trailing \nheader.\nWhen you send a request, you must tell Amazon S3 which of the preceding options you have \nchosen in your signature calculation, by adding the x-amz-content-sha256  header with one of \nthe following values:\nHeader value Description\nActual payload checksum \nvalueThis value is the actual checksum of your object and is only \npossible  when you are uploading the data in a single chunk.\nUNSIGNED-PAYLOAD Use this when you are uploading the object as a single \nunsigned chunk.\nSTREAMING-UNSIGNED-\nPAYLOAD-TRAILERUse this when sending an unsigned payload over multiple \nchunks. In this case you also have a trailing header after the \nchunk is uploaded.\nSTREAMING-AWS4-HMAC-\nSHA256-PAYLOADUse this when sending a payload over multiple chunks, and \nthe chunks are signed using AWS4-HMAC-SHA256 . This \nproduces a SigV4 signature.\nSTREAMING-AWS4-HMAC-\nSHA256-PAYLOAD-TRAILERUse this when sending a payload over multiple chunks, and \nthe chunks are signed using AWS4-HMAC-SHA256 .", "This \nproduces a SigV4 signature.", "In addition, the digest for the \nchunks is included as a trailing header.\nSTREAMING-AWS4-ECDSA-\nP256-SHA256-PAYLOADUse this when sending a payload over multiple chunks, and \nthe chunks are signed using AWS4-ECDSA-P256-SHA256 . \nThis produces a SigV4A signature.\nOverview API Version 2006-03-01 2645Amazon Simple Storage Service API Reference\nHeader value Description\nSTREAMING-AWS4-ECDSA-\nP256-SHA256-PAYLOAD-TRAI \nLERUse this when sending a payload over multiple chunks, and \nthe chunks are signed using AWS4-ECDSA-P256-SHA256 . \nThis produces a SigV4A signature.", "In addition, the digest for \nthe chunks is included  as a trailing header.\nUpon receiving the request, Amazon S3 re-creates the string to sign using information in the\nAuthorization  header and the date header.", "It then veri\ufb01es with authentication service the \nsignatures match.", "The request date can be speci\ufb01ed by using either the HTTP Date  or the x-amz-\ndate header.", "If both headers are present, x-amz-date  takes precedence.\nIf the signatures match, Amazon S3 processes your request; otherwise, your request will fail.\nFor more information, see the following topics:\nSignature Calculations for the Authorization Header: Transferring Payload in a Single Chunk (AWS \nSignature Version 4)\nSignature Calculations for the Authorization Header: Transferring Payload in Multiple Chunks \n(Chunked Upload) (AWS Signature Version 4)\nSignature Calculations for the Authorization Header: Including Trailing Headers (Chunked Upload) \n(AWS Signature Version 4)\nSignature Calculations for the Authorization Header: Transferring \nPayload in a Single Chunk (AWS Signature Version 4)\nWhen using the Authorization  header to authenticate requests, the header value includes, \namong other things, a signature.", "The signature calculations vary depending on the choice you \nmake for transferring the payload (Overview). This section explains signature calculations when \nyou choose to transfer the payload in a single chunk. The example section (see Examples: Signature \nCalculations ) shows signature calculations and resulting Authorization  headers that you can use \nas a test suite to verify your code.\nSignature Calculation: Transfer Payload in a Single Chunk API Version 2006-03-01 2646Amazon Simple Storage Service API Reference\nImportant\nWhen transferring payload in a single chunk, you can optionally choose to include the \npayload hash in the signature calculations, referred as signed payload  (if you don't include \nit, the payload is considered unsigned ). The signing procedure discussed in the following \nsection applies to both, but note the following di\ufb00erences:\n\u2022Signed payload option \u2013 You include the payload hash when constructing the canonical \nrequest (that then becomes part of StringToSign, as explained in the signature \ncalculation section).", "You also specify the same value as the x-amz-content-sha256\nheader value when sending the request to S3.\n\u2022Unsigned payload option \u2013 You include the literal string UNSIGNED-PAYLOAD  when \nconstructing a canonical request, and set the same value as the x-amz-content-\nsha256 header value when sending the request to Amazon S3.\nWhen you send your request to Amazon S3, the x-amz-content-sha256  header value \ninforms Amazon S3 whether the payload is signed or not. Amazon S3 can then create the \nsignature accordingly for veri\ufb01cation.\nCalculating a Signature\nTo calculate a signature, you \ufb01rst need a string to sign.", "You then calculate a HMAC-SHA256  hash of \nthe string to sign by using a signing key.", "The following diagram illustrates the process, including \nthe various components of the string that you create for signing\nWhen Amazon S3 receives an authenticated request, it computes the signature and then compares \nit with the signature that you provided in the request. For that reason, you must compute the \nsignature by using the same method that is used by Amazon S3.", "The process of putting a request in \nan agreed-upon form for signing is called canonicalization.\nSignature Calculation: Transfer Payload in a Single Chunk API Version 2006-03-01 2647Amazon Simple Storage Service API Reference\nThe following table describes the functions that are shown in the diagram. You need to implement \ncode for these functions.\nFunction Description\nLowercase() Convert the string to lowercase.\nHex() Lowercase base 16 encoding.\nSHA256Hash() Secure Hash Algorithm (SHA) cryptographic hash function.\nSignature Calculation: Transfer Payload in a Single Chunk API Version 2006-03-01 2648Amazon Simple Storage Service API Reference\nFunction Description\nHMAC-SHA256() Computes HMAC by using the SHA256 algorithm with the \nsigning key provided. This is the \ufb01nal signature.\nTrim() Remove any leading or trailing whitespace.\nUriEncode() URI encode every byte. UriEncode() must enforce the following \nrules:\n\u2022URI encode every byte except the unreserved characters: \n'A'-'Z', 'a'-'z', '0'-'9', '-', '.', '_', and '~'.\n\u2022The space character is a reserved character and must be \nencoded as \"%20\" (and not as \"+\").\n\u2022Each URI encoded byte is formed by a '%' and the two-digit \nhexadecimal value of the byte.\n\u2022Letters in the hexadecimal value must be uppercase, for \nexample \"%1A\".\n\u2022Encode the forward slash character, '/', everywhere except in \nthe object key name. For example, if the object key name is\nphotos/Jan/sample.jpg , the forward  slash in the key \nname is not encoded.\nImportant\nThe standard UriEncode functions provided by your \ndevelopment platform may not work because of \ndi\ufb00erences in implementation and related ambiguity \nin the underlying RFCs.", "We recommend that you write \nyour own custom UriEncode function to ensure that \nyour encoding will work.\nTo see an example of a UriEncode function in Java, see Java \nUtilities  on the GitHub website.\nSignature Calculation: Transfer Payload in a Single Chunk API Version 2006-03-01 2649Amazon Simple Storage Service API Reference\nTask 1: Create a Canonical Request\nThis section provides an overview of creating a canonical request.\nThe following is the canonical request format that Amazon S3 uses to calculate a signature. For \nsignatures to match, you must create a canonical request in this format:\n<HTTPMethod> \\n\n<CanonicalURI> \\n\n<CanonicalQueryString> \\n\n<CanonicalHeaders> \\n\n<SignedHeaders> \\n\n<HashedPayload>\nWhere:\n\u2022HTTPMethod  is one of the HTTP methods, for example GET, PUT, HEAD, and DELETE.\n\u2022CanonicalURI  is the URI-encoded version of the absolute path component of the URI\u2014\neverything starting with the \"/\" that follows the domain name and up to the end of the string or \nto the question mark character ('?') if you have query string parameters.", "The URI in the following \nexample, /examplebucket/myphoto.jpg , is the absolute path and you don't encode the \"/\" in \nthe absolute path:\nhttp://s3.amazonaws.com/ examplebucket/myphoto.jpg\nNote\nYou do not normalize URI paths for requests to Amazon S3.", "For example, you may have a \nbucket with an object named \"my-object//example//photo.user\". Normalizing the path \nchanges the object name in the request to \"my-object/example/photo.user\".", "This is an \nincorrect path for that object.\n\u2022CanonicalQueryString  speci\ufb01es the URI-encoded query string parameters. You URI-encode \nname and values individually. You must also sort the parameters in the canonical query string \nalphabetically by key name.", "The sorting occurs after encoding.", "The query string in the following \nURI example is prefix=somePrefix&marker=someMarker&max-keys=20 :\nSignature Calculation: Transfer Payload in a Single Chunk API Version 2006-03-01 2650Amazon Simple Storage Service API Reference\nhttp://s3.amazonaws.com/examplebucket?prefix=somePrefix&marker=someMarker&max-keys=20\nThe canonical query string is as follows (line breaks are added to this example for readability):\nUriEncode(\"marker\")+\"=\"+UriEncode(\"someMarker\")+\"&\"+\nUriEncode(\"max-keys\")+\"=\"+UriEncode(\"20\") + \"&\" +\nUriEncode(\"prefix\")+\"=\"+UriEncode(\"somePrefix\")\nWhen a request targets a subresource, the corresponding query parameter value will be \nan empty string (\"\"). For example, the following URI identi\ufb01es the ACL subresource on the\nexamplebucket  bucket:\nhttp://s3.amazonaws.com/examplebucket?acl \nThe CanonicalQueryString in this case is as follows:\nUriEncode(\"acl\") + \"=\" + \"\"\nIf the URI does not include a '?', there is no query string in the request, and you set the canonical \nquery string to an empty string (\"\").", "You will still need to include the \"\\n\".\n\u2022CanonicalHeaders  is a list of request headers with their values. Individual header name and \nvalue pairs are separated by the newline character (\"\\n\"). Header names must be in lowercase. \nYou must sort the header names alphabetically to construct the string, as shown in the following \nexample:\nLowercase( <HeaderName1> )+\":\"+Trim( <value>)+\"\\n\"\nLowercase( <HeaderName2> )+\":\"+Trim( <value>)+\"\\n\"\n...\nLowercase( <HeaderNameN> )+\":\"+Trim( <value>)+\"\\n\"\nThe Lowercase()  and Trim() functions used in this example are described in the preceding \nsection.\nThe CanonicalHeaders  list must include the following:\nSignature Calculation: Transfer Payload in a Single Chunk API Version 2006-03-01 2651Amazon Simple Storage Service API Reference\n\u2022HTTP host header.\n\u2022If the Content-MD5  header is present in the request, you must add it to the\nCanonicalHeaders  list.\n\u2022Any x-amz-* headers that you plan to include in your request must also be added.", "\nFor example, if you are using temporary security credentials, you need to include\nx-amz-security-token  in your request. You must add this header in the list of\nCanonicalHeaders .\nNote\nThe x-amz-content-sha256  header is required for all AWS Signature Version 4 \nrequests. It provides a hash of the request payload. If there is no payload, you must \nprovide the hash of an empty string.\nThe following is an example CanonicalHeaders  string.", "The header names are in lowercase and \nsorted.\nhost:s3.amazonaws.com\nx-amz-content-sha256:e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\nx-amz-date:20130708T220855Z\nNote\nFor the purpose of calculating an authorization signature, only the host and any x-amz-\n* headers are required; however, in order to prevent data tampering, you should consider \nincluding all the headers in the signature calculation.\n\u2022SignedHeaders  is an alphabetically sorted, semicolon-separated list of lowercase request \nheader names.", "The request headers in the list are the same headers that you included \nin the CanonicalHeaders  string.", "For example, for the previous example, the value of\nSignedHeaders  would be as follows:\nhost;x-amz-content-sha256;x-amz-date\nSignature Calculation: Transfer Payload in a Single Chunk API Version 2006-03-01 2652Amazon Simple Storage Service API Reference\n\u2022HashedPayload  is the hexadecimal value of the SHA256 hash of the request payload.\nHex(SHA256Hash( <payload> )\nIf there is no payload in the request, you compute a hash of the empty string as follows:\nHex(SHA256Hash(\"\"))\nThe hash returns the following value:\ne3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855   \nFor example, when you upload an object by using a PUT request, you provide object data in the \nbody. When you retrieve an object by using a GET request, you compute the empty string hash.\nTask 2: Create a String to Sign\nThis section provides an overview of creating a string to sign. For step-by-step instructions, see\nTask 2: Create a String to Sign in the AWS General Reference.\nThe string to sign is a concatenation of the following strings:\n\"AWS4-HMAC-SHA256\" + \"\\n\" +\ntimeStampISO8601Format + \"\\n\" +\n<Scope> + \"\\n\" +\nHex(SHA256Hash( <CanonicalRequest> ))\nThe constant string AWS4-HMAC-SHA256  speci\ufb01es the hash algorithm that you are using, \nHMAC-SHA256. The timeStamp  is the current UTC time in ISO 8601 format (for example,\n20130524T000000Z ).\nScope binds the resulting signature to a speci\ufb01c date, an AWS Region, and a service. Thus, your \nresulting signature will work only in the speci\ufb01c Region and for a speci\ufb01c service.", "The signature is \nvalid for seven days after the speci\ufb01ed date.\nSignature Calculation: Transfer Payload in a Single Chunk API Version 2006-03-01 2653Amazon Simple Storage Service API Reference\ndate.Format( <YYYYMMDD> ) + \"/\" + <region>  + \"/\" + <service>  + \"/aws4_request\"\nFor Amazon S3, the service string is s3.", "For a list of region  strings, see Regions and Endpoints in \nthe AWS General Reference. The Region column in this table provides the list of valid Region strings.\nThe following scope restricts the resulting signature to the us-east-1  Region and Amazon S3.\n20130606/us-east-1/s3/aws4_request\nNote\nScope must use the same date that you use to compute the signing key, as discussed in the \nfollowing section.\nTask 3: Calculate Signature\nIn AWS Signature Version 4, instead of using your AWS access keys to sign a request, you \ufb01rst \ncreate a signing key that is scoped to a speci\ufb01c Region and service. \u00a0For more information about \nsigning keys, see Introduction to Signing Requests.\nDateKey              = HMAC-SHA256(\"AWS4\"+\" <SecretAccessKey> \", \"<YYYYMMDD> \")\nDateRegionKey        = HMAC-SHA256( <DateKey> , \"<aws-region> \")\nDateRegionServiceKey = HMAC-SHA256( <DateRegionKey> , \"<aws-service> \")\nSigningKey           = HMAC-SHA256( <DateRegionServiceKey> , \"aws4_request\")\nNote\nSome use cases can process signature keys for up to 7 days. For more information see Share \nan Object with Others.\nFor a list of Region strings, see Regions and Endpoints in the AWS General Reference.\nUsing a signing key enables you to keep your AWS credentials in one safe place.", "For example, if \nyou have multiple servers that communicate with Amazon S3, you share the signing key with those \nservers; you don\u2019t have to keep a copy of your secret access key on each server.", "Signing key is valid \nSignature Calculation: Transfer Payload in a Single Chunk API Version 2006-03-01 2654Amazon Simple Storage Service API Reference\nfor up to seven days.", "So each time you calculate signing key you will need to share the signing key \nwith your servers. For more information, see Authenticating Requests (AWS Signature Version 4).\nThe \ufb01nal signature is the HMAC-SHA256 hash of the string to sign, using the signing key as the key.\nHMAC-SHA256(SigningKey, StringToSign)\nFor step-by-step instructions on creating a signature, see Task 3: Create a Signature in the AWS \nGeneral Reference.\nExamples: Signature Calculations\nYou can use the examples in this section as a reference to check signature calculations in your code. \nThe calculations shown in the examples use the following data:\n\u2022Example access keys.\nParameter Value\nAWSAccessKeyId AKIAIOSFODNN7EXAMPLE\nAWSSecret \nAccessKeywJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\n\u2022Request timestamp of 20130524T000000Z (Fri, 24 May 2013 00:00:00 GMT ).\n\u2022Bucket name examplebucket .\n\u2022The bucket is assumed to be in the US East (N.", "Virginia) Region.", "The credential Scope  and the\nSigning Key  calculations use us-east-1  as the Region speci\ufb01er.", "For information about other \nRegions, see Regions and Endpoints in the AWS General Reference.\n\u2022You can use either path-style or virtual hosted\u2013style requests.", "The following examples show how \nto sign a virtual hosted\u2013style request, for example:\nhttps://examplebucket.s3.amazonaws.com/photos/photo1.jpg\nFor more information, see Virtual Hosting of Buckets in the Amazon Simple Storage Service User \nGuide .\nSignature Calculation: Transfer Payload in a Single Chunk API Version 2006-03-01 2655Amazon Simple Storage Service API Reference\nExample: GET Object\nThe following example gets the \ufb01rst 10 bytes of an object (test.txt) from examplebucket . For \nmore information about the API action, see GetObject.\nGET /test.txt HTTP/1.1\nHost: examplebucket.s3.amazonaws.com\nAuthorization: SignatureToBeCalculated\nRange: bytes=0-9  \nx-amz-content-sha256:e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\nx-amz-date: 20130524T000000Z \nBecause this GET request does not provide any body content, the x-amz-content-sha256\nvalue is the hash of the empty request body.", "The following steps show signature calculations and \nconstruction of the Authorization  header.\n1.", "StringToSign\na.", "CanonicalRequest\nGET\n/test.txt\nhost:examplebucket.s3.amazonaws.com\nrange:bytes=0-9\nx-amz-content-\nsha256:e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\nx-amz-date:20130524T000000Z\nhost;range;x-amz-content-sha256;x-amz-date\ne3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855   \nIn the canonical request string, the last line is the hash of the empty request body.", "The \nthird line is empty because there are no query parameters in the request.\nb.", "StringToSign\nAWS4-HMAC-SHA256\n20130524T000000Z\n20130524/us-east-1/s3/aws4_request\nSignature Calculation: Transfer Payload in a Single Chunk API Version 2006-03-01 2656Amazon Simple Storage Service API Reference\n7344ae5b7ee6c3e7e6b0fe0640412a37625d1fbfff95c48bbb2dc43964946972\n2. SigningKey\nsigning key  = HMAC-SHA256(HMAC-SHA256(HMAC-SHA256(HMAC-SHA256(\"AWS4\" + \n \"<YourSecretAccessKey> \",\"20130524\"),\"us-east-1\"),\"s3\"),\"aws4_request\")\n3.", "Signature\nf0e8bdb87c964420e857bd35b5d6ed310bd44f0170aba48dd91039c6036bdb41\n4.", "Authorization header\nThe resulting Authorization  header is as follows:\nAWS4-HMAC-SHA256 Credential=AKIAIOSFODNN7EXAMPLE/20130524/us-east-1/\ns3/aws4_request,SignedHeaders=host;range;x-amz-content-sha256;x-amz-\ndate,Signature=f0e8bdb87c964420e857bd35b5d6ed310bd44f0170aba48dd91039c6036bdb41\nExample: PUT Object\nThis example PUT request creates an object (test$file.text ) in examplebucket  .", "The example \nassumes the following:\n\u2022You are requesting REDUCED_REDUNDANCY  as the storage class by adding the x-amz-storage-\nclass request header.", "For information about storage classes, see Storage Classes  in the Amazon \nSimple Storage Service User Guide.\n\u2022The content of the uploaded \ufb01le is a string, \"Welcome to Amazon S3.\"  The value of x-amz-\ncontent-sha256  in the request is based on this string.\nFor information about the API action, see PutObject.\nPUT test$file.text HTTP/1.1\nHost: examplebucket.s3.amazonaws.com\nSignature Calculation: Transfer Payload in a Single Chunk API Version 2006-03-01 2657Amazon Simple Storage Service API Reference\nDate: Fri, 24 May 2013 00:00:00 GMT\nAuthorization: SignatureToBeCalculated\nx-amz-date: 20130524T000000Z  \nx-amz-storage-class: REDUCED_REDUNDANCY\nx-amz-content-sha256: 44ce7dd67c959e0d3524ffac1771dfbba87d2b6b4b4e99e42034a8b803f8b072\n<Payload>\nThe following steps show signature calculations.\n1.", "StringToSign\na.", "CanonicalRequest\nPUT\n/test%24file.text\ndate:Fri, 24 May 2013 00:00:00 GMT\nhost:examplebucket.s3.amazonaws.com\nx-amz-content-\nsha256:44ce7dd67c959e0d3524ffac1771dfbba87d2b6b4b4e99e42034a8b803f8b072\nx-amz-date:20130524T000000Z\nx-amz-storage-class:REDUCED_REDUNDANCY\ndate;host;x-amz-content-sha256;x-amz-date;x-amz-storage-class\n44ce7dd67c959e0d3524ffac1771dfbba87d2b6b4b4e99e42034a8b803f8b072\nIn the canonical request, the third line is empty because there are no query parameters \nin the request. The last line is the hash of the body, which should be same as the x-amz-\ncontent-sha256 header  value.\nb.", "StringToSign\nAWS4-HMAC-SHA256\n20130524T000000Z\n20130524/us-east-1/s3/aws4_request\n9e0e90d9c76de8fa5b200d8c849cd5b8dc7a3be3951ddb7f6a76b4158342019d\n2. SigningKey\nSignature Calculation: Transfer Payload in a Single Chunk API Version 2006-03-01 2658Amazon Simple Storage Service API Reference\nsigning key  = HMAC-SHA256(HMAC-SHA256(HMAC-SHA256(HMAC-SHA256(\"AWS4\" + \n \"<YourSecretAccessKey> \",\"20130524\"),\"us-east-1\"),\"s3\"),\"aws4_request\")\n3. Signature\n98ad721746da40c64f1a55b78f14c238d841ea1380cd77a1b5971af0ece108bd\n4.", "Authorization header\nThe resulting Authorization  header is as follows:\nAWS4-HMAC-SHA256 Credential=AKIAIOSFODNN7EXAMPLE/20130524/us-east-1/s3/\naws4_request,SignedHeaders=date;host;x-amz-content-sha256;x-amz-date;x-amz-storage-\nclass,Signature=98ad721746da40c64f1a55b78f14c238d841ea1380cd77a1b5971af0ece108bd\nExample: GET Bucket Lifecycle\nThe following GET request retrieves the lifecycle con\ufb01guration of examplebucket . For \ninformation about the API action, see GetBucketLifecycleCon\ufb01guration.\nGET ?lifecycle HTTP/1.1\nHost: examplebucket.s3.amazonaws.com\nAuthorization: SignatureToBeCalculated\nx-amz-date: 20130524T000000Z  \nx-amz-content-sha256:e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\nBecause the request does not provide any body content, the x-amz-content-sha256  header \nvalue is the hash of the empty request body.", "The following steps show signature calculations.\n1.", "StringToSign\na.", "CanonicalRequest\nGET\n/\nSignature Calculation: Transfer Payload in a Single Chunk API Version 2006-03-01 2659Amazon Simple Storage Service API Reference\nlifecycle=\nhost:examplebucket.s3.amazonaws.com\nx-amz-content-\nsha256:e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\nx-amz-date:20130524T000000Z\nhost;x-amz-content-sha256;x-amz-date\ne3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\nIn the canonical request, the last line is the hash of the empty request body.\nb. StringToSign\nAWS4-HMAC-SHA256\n20130524T000000Z\n20130524/us-east-1/s3/aws4_request\n9766c798316ff2757b517bc739a67f6213b4ab36dd5da2f94eaebf79c77395ca\n2. SigningKey\nsigning key  = HMAC-SHA256(HMAC-SHA256(HMAC-SHA256(HMAC-SHA256(\"AWS4\" + \n \"<YourSecretAccessKey> \",\"20130524\"),\"us-east-1\"),\"s3\"),\"aws4_request\")\n3.", "Signature\nfea454ca298b7da1c68078a5d1bdbfbbe0d65c699e0f91ac7a200a0136783543\n4.", "Authorization header\nThe resulting Authorization  header is as follows:\nAWS4-HMAC-SHA256 Credential=AKIAIOSFODNN7EXAMPLE/20130524/us-east-1/\ns3/aws4_request,SignedHeaders=host;x-amz-content-sha256;x-amz-\ndate,Signature=fea454ca298b7da1c68078a5d1bdbfbbe0d65c699e0f91ac7a200a0136783543\nSignature Calculation: Transfer Payload in a Single Chunk API Version 2006-03-01 2660Amazon Simple Storage Service API Reference\nExample: Get Bucket (List Objects)\nThe following example retrieves a list of objects from examplebucket  bucket. For information \nabout the API action, see ListObjects.\nGET ?max-keys=2&prefix=J HTTP/1.1\nHost: examplebucket.s3.amazonaws.com\nAuthorization: SignatureToBeCalculated\nx-amz-date: 20130524T000000Z  \nx-amz-content-sha256:e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\nBecause the request does not provide a body, the value of x-amz-content-sha256  is the hash of \nthe empty request body.", "The following steps show signature calculations.\n1.", "StringToSign\na.", "CanonicalRequest\nGET\n/\nmax-keys=2&prefix=J\nhost:examplebucket.s3.amazonaws.com\nx-amz-content-\nsha256:e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\nx-amz-date:20130524T000000Z\nhost;x-amz-content-sha256;x-amz-date\ne3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\nIn the canonical string, the last line is the hash of the empty request body.\nb. StringToSign\nAWS4-HMAC-SHA256\n20130524T000000Z\n20130524/us-east-1/s3/aws4_request\ndf57d21db20da04d7fa30298dd4488ba3a2b47ca3a489c74750e0f1e7df1b9b7\n2. SigningKey\nSignature Calculation: Transfer Payload in a Single Chunk API Version 2006-03-01 2661Amazon Simple Storage Service API Reference\nsigning key  = HMAC-SHA256(HMAC-SHA256(HMAC-SHA256(HMAC-SHA256(\"AWS4\" + \n \"<YourSecretAccessKey> \",\"20130524\"),\"us-east-1\"),\"s3\"),\"aws4_request\")\n3.", "Signature\n34b48302e7b5fa45bde8084f4b7868a86f0a534bc59db6670ed5711ef69dc6f7\n4.", "Authorization header\nThe resulting Authorization  header is as follows:\nAWS4-HMAC-SHA256 Credential=AKIAIOSFODNN7EXAMPLE/20130524/us-east-1/\ns3/aws4_request,SignedHeaders=host;x-amz-content-sha256;x-amz-\ndate,Signature=34b48302e7b5fa45bde8084f4b7868a86f0a534bc59db6670ed5711ef69dc6f7\nSignature Calculation: Transfer Payload in a Single Chunk API Version 2006-03-01 2662Amazon Simple Storage Service API Reference\nSignature Calculations for the Authorization Header: Transferring \nPayload in Multiple Chunks (Chunked Upload) (AWS Signature Version \n4)\nAs described in the Overview, when authenticating requests using the Authorization  header, \nyou have an option of uploading the payload in chunks.", "You can send data in \ufb01xed size or variable \nsize chunks. This section describes the signature calculation process in chunked upload, how you \ncreate the chunk body, and how the delayed signing works where you \ufb01rst upload the chunk, and \nsend its signature in the subsequent chunk. The example section (see Example: PUT Object) shows \nsignature calculations and resulting Authorization  headers that you can use as a test suite to \nverify your code.\nNote\nWhen transferring data in a series of chunks, you must do one of the following:\n\u2022Explicitly specify the total content length (object length in bytes plus metadata in each \nchunk) using the Content-Length  HTTP header. To do this, you must pre-compute the \ntotal length of the payload, including the metadata that you send in each chunk, before \nstarting your request.\n\u2022Specify the Transfer-Encoding  HTTP header. If you include the Transfer-Encoding\nheader and specify any value other than identity , you must omit the Content-\nLength header.\nFor all requests, you must include the x-amz-decoded-content-length  header, \nspecifying the size of the object in bytes.\nEach chunk signature calculation includes the signature of the previous chunk. To begin, you create \na seed signature using only the headers. You use the seed signature in the signature calculation \nof the \ufb01rst chunk. For each subsequent chunk, you create a chunk signature that includes the \nsignature of the previous chunk. Thus, the chunk signatures are chained together; that is, the \nsignature of chunk n is a function F(chunk n, signature(chunk n-1)) . The chaining ensures that you \nsend the chunks in the correct order.\nTo perform a chunked upload, do the following:\nSignature Calculation: Transfer Payload in Multiple Chunks API Version 2006-03-01 2663Amazon Simple Storage Service API Reference\n1.Decide the payload chunk size. You need this when you write the code.\nThe chunk size must be at least 8 KB. We recommend a chunk size of a least 64 KB for better \nperformance. This chunk size applies to all chunks except the last one. The last chunk you send \ncan be smaller than 8 KB. If your payload is small and can \ufb01t into one chunk, then it can be \nsmaller than the 8 KB.\n2.Create the seed signature for inclusion in the \ufb01rst chunk. For more information, see Calculating \nthe Seed Signature.\n3.Create the \ufb01rst chunk and stream it. For more information, see De\ufb01ning the Chunk Body .\n4.For each subsequent chunk, calculate the chunk signature that includes the previous signature \nin the string you sign, construct the chunk, and send it. For more information, see De\ufb01ning the \nChunk Body .\n5.Send the \ufb01nal additional chunk, which is the same as the other chunks in the construction, but it \nhas zero data bytes. For more information, see De\ufb01ning the Chunk Body .\nCalculating the Seed Signature\nThe following diagram illustrates the process of calculating the seed signature.\nSignature Calculation: Transfer Payload in Multiple Chunks API Version 2006-03-01 2664Amazon Simple Storage Service API Reference\nThe following table describes the functions that are shown in the diagram. You need to implement \ncode for these functions.\nSignature Calculation: Transfer Payload in Multiple Chunks API Version 2006-03-01 2665Amazon Simple Storage Service API Reference\nFunction Description\nLowercase() Convert the string to lowercase.\nHex() Lowercase base 16 encoding.\nSHA256Hash() Secure Hash Algorithm (SHA) cryptographic hash function.\nHMAC-SHA256() Computes HMAC by using the SHA256 algorithm with the \nsigning key provided.", "This is the \ufb01nal signature.\nTrim() Remove any leading or trailing whitespace.\nUriEncode() URI encode every byte. UriEncode() must enforce the following \nrules:\n\u2022URI encode every byte except the unreserved characters: \n'A'-'Z', 'a'-'z', '0'-'9', '-', '.', '_', and '~'.\n\u2022The space character is a reserved character and must be \nencoded as \"%20\" (and not as \"+\").\n\u2022Each URI encoded byte is formed by a '%' and the two-digit \nhexadecimal value of the byte.\n\u2022Letters in the hexadecimal value must be uppercase, for \nexample \"%1A\".\n\u2022Encode the forward slash character, '/', everywhere except in \nthe object key name. For example, if the object key name is\nphotos/Jan/sample.jpg , the forward  slash in the key \nname is not encoded.\nImportant\nThe standard UriEncode functions provided by your \ndevelopment platform may not work because of \ndi\ufb00erences in implementation and related ambiguity \nin the underlying RFCs.", "We recommend that you write \nSignature Calculation: Transfer Payload in Multiple Chunks API Version 2006-03-01 2666Amazon Simple Storage Service API Reference\nFunction Description\nyour own custom UriEncode function to ensure that \nyour encoding will work.\nTo see an example of a UriEncode function in Java, see Java \nUtilities  on the GitHub website.\nFor information about the signing process, see Signature Calculations for the Authorization Header: \nTransferring Payload in a Single Chunk (AWS Signature Version 4). The process is the same, except \nthat the creation of CanonicalRequest  di\ufb00ers as follows:\n\u2022In addition to the request headers you plan to add, you must include the following headers:\nHeader Description\nx-amz-content-\nsha256This header is required for all AWS Signature Version 4  requests. Set \nthe value to   STREAMING-AWS4-HMAC-SHA256-PAYLOAD  to  \n indicate that the signature covers only headers and that  there is no \npayload.\nSignature Calculation: Transfer Payload in Multiple Chunks API Version 2006-03-01 2667Amazon Simple Storage Service API Reference\nHeader Description\nContent-E \nncodingSet the value to aws-chunked .\nAmazon S3 supports multiple content encodings. For  example:\nContent-Encoding : aws-chunked,gzip\n That is, you can specify your custom content-encoding when  using \nSignature Version 4 streaming API.\nIf you specify Content-Encoding  in your request as Content-\nEncoding : aws-chunked , S3 adds an empty value for\nContent-Encoding  and stores the object metadata (Content-E \nncoding : ) to the resulting object.\n \nNote\nAmazon S3 stores the resulting object without the   aws-\nchunked  encoding. Therefore, when  you retrieve the object, \nit is not   aws-chunked  encoded.\nx-amz-decoded-\ncontent-lengthSet the value to the length, in bytes, of the data to be  chunked, \nwithout counting any metadata.", "For example, if you are  uploading \na 4 GB \ufb01le, set the value to 4294967296.", "This is the  raw size of the \nobject to be uploaded (data you want to store in  Amazon S3).\nSignature Calculation: Transfer Payload in Multiple Chunks API Version 2006-03-01 2668Amazon Simple Storage Service API Reference\nHeader Description\nContent-Length\nSet the value to the actual size of the transmitted HTTP body, \nwhich includes the  length of your data (value set for   x-amz-dec \noded-content-length ), plus chunk  metadata.", "Each chunk \nhas metadata, such as the signature of  the previous chunk. Chunk \ncalculations are discussed in the  following section. If you include the  \n  Transfer-Encoding  header and specify any  value other than\nidentity , you must not include  the Content-Length   header.\nYou send the \ufb01rst chunk with the seed signature. You must construct the chunk as described in the \nfollowing section.\nDe\ufb01ning the Chunk Body\nAll chunks include some metadata. Each chunk must conform to the following structure:\nstring(IntHexBase( chunk-size )) + \";chunk-signature=\" + signature  + \\r\\n + chunk-data  + \n \\r\\n                     \nWhere:\n\u2022IntHexBase()  is a function that you write to convert an integer chunk-size to hexadecimal. For \nexample, if chunk-size is 65536, hexadecimal string is \"10000\".\n\u2022chunk-size  is the size, in bytes, of the chunk-data, without metadata. For example, if you are \nuploading a 65 KB object and using a chunk size of 64 KB, you upload the data in three chunks: \nthe \ufb01rst would be 64 KB, the second 1 KB, and the \ufb01nal chunk with 0 bytes.\n\u2022signature  For each chunk, you calculate the signature using the following string to sign. For \nthe \ufb01rst chunk, you use the seed-signature as the previous signature.\nSignature Calculation: Transfer Payload in Multiple Chunks API Version 2006-03-01 2669Amazon Simple Storage Service API Reference\nThe size of the \ufb01nal chunk data that you send is 0, although the chunk body still contains \nmetadata, including the signature of the previous chunk.\nExample: PUT Object\nYou can use the examples in this section as a reference to check signature calculations in your code. \nBefore you review the examples, note the following:\n\u2022The signature calculations in these examples use the following example security credentials.\nParameter Value\nAWSAccessKeyId AKIAIOSFODNN7EXAMPLE\nAWSSecret \nAccessKeywJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\n\u2022All examples use the request timestamp 20130524T000000Z (Fri, 24 May 2013 00:00:00 \nGMT).\n\u2022All examples use examplebucket  as the bucket name.\nSignature Calculation: Transfer Payload in Multiple Chunks API Version 2006-03-01 2670Amazon Simple Storage Service API Reference\n\u2022The bucket is assumed to be in the US East (N.", "Virginia) Region, and the credential Scope  and \nthe Signing Key  calculations use us-east-1  as the Region speci\ufb01er.", "For more information, \nsee Regions and Endpoints in the Amazon Web Services General Reference.\n\u2022You can use either path style or virtual-hosted style requests. The following examples use \nvirtual-hosted style requests, for example:\nhttps://examplebucket.s3.amazonaws.com/photos/photo1.jpg\nFor more information, see Virtual Hosting of Buckets in the Amazon Simple Storage Service User \nGuide .\nThe following example sends a PUT request to upload an object.", "The signature calculations assume \nthe following:\n\u2022You are uploading a 65 KB text \ufb01le, and the \ufb01le content is a one-character string made up of the \nletter 'a'.\n\u2022The chunk size is 64 KB.", "As a result, the payload is uploaded in three chunks, 64 KB, 1 KB, and the \n\ufb01nal chunk with 0 bytes of chunk data.\n\u2022The resulting object has the key name chunkObject.txt .\n\u2022You are requesting REDUCED_REDUNDANCY  as the storage class by adding the x-amz-storage-\nclass request header.\nFor information about the API action, see PutObject. The general request syntax is as follows:\nPUT /examplebucket/chunkObject.txt HTTP/1.1\nHost: s3.amazonaws.com\nx-amz-date: 20130524T000000Z  \nx-amz-storage-class: REDUCED_REDUNDANCY\nAuthorization: SignatureToBeCalculated\nx-amz-content-sha256: STREAMING-AWS4-HMAC-SHA256-PAYLOAD\nContent-Encoding: aws-chunked\nx-amz-decoded-content-length: 66560\nContent-Length: 66824\n<Payload>\nThe following steps show signature calculations.\nSignature Calculation: Transfer Payload in Multiple Chunks API Version 2006-03-01 2671Amazon Simple Storage Service API Reference\n1.", "Seed signature \u2014 Create String to Sign\na.", "CanonicalRequest\nPUT\n/examplebucket/chunkObject.txt\ncontent-encoding:aws-chunked\ncontent-length:66824\nhost:s3.amazonaws.com\nx-amz-content-sha256:STREAMING-AWS4-HMAC-SHA256-PAYLOAD\nx-amz-date:20130524T000000Z\nx-amz-decoded-content-length:66560\nx-amz-storage-class:REDUCED_REDUNDANCY\ncontent-encoding;content-length;host;x-amz-content-sha256;x-amz-date;x-amz-\ndecoded-content-length;x-amz-storage-class\nSTREAMING-AWS4-HMAC-SHA256-PAYLOAD\nIn the canonical request, the third line is empty because there are no query parameters \nin the request. The last line is the constant string provided as the value of the hashed \nPayload, which should be same as the value of x-amz-content-sha256 header .\nb.", "StringToSign\nAWS4-HMAC-SHA256\n20130524T000000Z\n20130524/us-east-1/s3/aws4_request\ncee3fed04b70f867d036f722359b0b1f2f0e5dc0efadbc082b76c4c60e316455\nNote\nFor information about each of line in the string to sign, see the diagram that \nexplains seed signature calculation.\n2. SigningKey\nSignature Calculation: Transfer Payload in Multiple Chunks API Version 2006-03-01 2672Amazon Simple Storage Service API Reference\nsigning key  = HMAC-SHA256(HMAC-SHA256(HMAC-SHA256(HMAC-SHA256(\"AWS4\" + \n \"<YourSecretAccessKey> \",\"20130524\"),\"us-east-1\"),\"s3\"),\"aws4_request\")       \n3.", "Seed Signature\n4f232c4386841ef735655705268965c44a0e4690baa4adea153f7db9fa80a0a9\n4.", "Authorization header\nThe resulting Authorization header is as follows:\nAWS4-HMAC-SHA256 Credential=AKIAIOSFODNN7EXAMPLE/20130524/us-east-1/s3/\naws4_request,SignedHeaders=content-encoding;content-length;host;x-amz-\ncontent-sha256;x-amz-date;x-amz-decoded-content-length;x-amz-storage-\nclass,Signature=4f232c4386841ef735655705268965c44a0e4690baa4adea153f7db9fa80a0a9\n5.", "Chunk 1: (65536 bytes, with value 97 for letter 'a')\na. Chunk string to sign:\nAWS4-HMAC-SHA256-PAYLOAD\n20130524T000000Z\n20130524/us-east-1/s3/aws4_request\n4f232c4386841ef735655705268965c44a0e4690baa4adea153f7db9fa80a0a9\ne3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\nbf718b6f653bebc184e1479f1935b8da974d701b893afcf49e701f3e2f9f9c5a\nNote\nFor information about each line in the string to sign, see the preceding diagram \nthat shows various components of the string to sign (for example, the last three \nlines are, previous-signature , hash(\"\") , and hash(current-chunk-\ndata) ).\nb. Chunk signature:\nSignature Calculation: Transfer Payload in Multiple Chunks API Version 2006-03-01 2673Amazon Simple Storage Service API Reference\nad80c730a21e5b8d04586a2213dd63b9a0e99e0e2307b0ade35a65485a288648\nc. Chunk data sent:\n10000;chunk-\nsignature=ad80c730a21e5b8d04586a2213dd63b9a0e99e0e2307b0ade35a65485a288648\n<65536-bytes>\n6. Chunk 2: (1024 bytes, with value 97 for letter 'a')\na.", "Chunk string to sign:\nAWS4-HMAC-SHA256-PAYLOAD\n20130524T000000Z\n20130524/us-east-1/s3/aws4_request\nad80c730a21e5b8d04586a2213dd63b9a0e99e0e2307b0ade35a65485a288648\ne3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\n2edc986847e209b4016e141a6dc8716d3207350f416969382d431539bf292e4a\nb. Chunk signature:\n0055627c9e194cb4542bae2aa5492e3c1575bbb81b612b7d234b86a503ef5497\nc. Chunk data sent:\n400;chunk-\nsignature=0055627c9e194cb4542bae2aa5492e3c1575bbb81b612b7d234b86a503ef5497\n<1024 bytes>\n7. Chunk 3: (0 byte data)\na.", "Chunk string to sign:\nAWS4-HMAC-SHA256-PAYLOAD\n20130524T000000Z\n20130524/us-east-1/s3/aws4_request\n0055627c9e194cb4542bae2aa5492e3c1575bbb81b612b7d234b86a503ef5497\ne3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\ne3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\nb. Chunk signature:\nSignature Calculation: Transfer Payload in Multiple Chunks API Version 2006-03-01 2674Amazon Simple Storage Service API Reference\nb6c6ea8a5354eaf15b3cb7646744f4275b71ea724fed81ceb9323e279d449df9\nc. Chunk data sent:\n0;chunk-\nsignature=b6c6ea8a5354eaf15b3cb7646744f4275b71ea724fed81ceb9323e279d449df9\nSignature Calculation: Transfer Payload in Multiple Chunks API Version 2006-03-01 2675Amazon Simple Storage Service API Reference\nSignature Calculations for the Authorization Header: Including Trailing \nHeaders (Chunked Upload) (AWS Signature Version 4)\nAs described in the Overview, when authenticating requests using the Authorization  header, \nyou have an option of uploading the payload in chunks. This is covered in detail in Signature \nCalculations for the Authorization Header: Transferring Payload in Multiple Chunks (Chunked \nUpload) (AWS Signature Version 4).", "When you send the data for the object in chunks, you also have \nthe option of including trailing headers. This section describes the steps you need to take when you \nwant to include a trailing header at the end of your multiple chunk upload.\nImportant\nWhen you are including trailing headers, you must send the following in your initial header:\n\u2022You must set x-amz-content-sha256  to an appropriate value that indicates a trailer \nwill be included. To see the acceptable values for x-amz-content-sha256 , see\nAuthenticating Requests: Using the Authorization Header (AWS Signature Version 4).\n\u2022You must set x-amz-trailer  to indicate the contents your are including in your trailing \nheader.\nTrailing headers are only sent after the chunks have been uploaded. Previous chunks are sent as \nnormal and signed as described in the previous sections, including sending the \ufb01nal chunk with a \npayload of 0 bytes. The trailing headers are included as their own chunk and sent after the \ufb01nal \nchunk with a payload of 0 bytes. For example, if your data ended with a 100 KB chunk, you would \nsend the following:\n\u2022Previous data chunks\n\u2022100 KB \ufb01nal chunk of the object\n\u20220 bytes chunk signifying the end of the object\n\u2022Trailing headers chunk\nExample: PUT Object\nYou can use the examples in this section as a reference to check signature calculations in your code.", "\nBefore you review the examples, note the following:\nSignature Calculation: Including Trailing Headers API Version 2006-03-01 2676Amazon Simple Storage Service API Reference\n\u2022The signature calculations in these examples use the following example security credentials.\nParameter Value\nAWSAccessKeyId AKIAIOSFODNN7EXAMPLE\nAWSSecret \nAccessKeywJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\n\u2022All examples use the request timestamp 20130524T000000Z (Fri, 24 May 2013 00:00:00 \nGMT).\n\u2022All examples use examplebucket  as the bucket name.\n\u2022The bucket is assumed to be in the US East (N.", "Virginia) Region, and the credential Scope  and \nthe Signing Key  calculations use us-east-1  as the Region speci\ufb01er.", "For more information, \nsee Regions and Endpoints in the Amazon Web Services General Reference.\n\u2022You can use either path style or virtual-hosted style requests. The following examples use \nvirtual-hosted style requests, for example:\nhttps://examplebucket.s3.amazonaws.com/photos/photo1.jpg\nFor more information, see Virtual Hosting of Buckets in the Amazon Simple Storage Service User \nGuide .\nThe following example sends a PUT request to upload an object.", "The signature calculations assume \nthe following:\n\u2022You are uploading a 65 KB text \ufb01le, and the \ufb01le content is a one-character string made up of the \nletter 'a'.\n\u2022The chunk size is 64 KB.", "As a result, the payload is uploaded in three chunks, 64 KB, 1 KB, and the \n\ufb01nal chunk with 0 bytes of chunk data.\n\u2022The resulting object has the key name chunkObject.txt .\n\u2022You are requesting REDUCED_REDUNDANCY  as the storage class by adding the x-amz-storage-\nclass request header.\n\u2022The transfer is including a CRC32 checksum value as a trailing header.\nSignature Calculation: Including Trailing Headers API Version 2006-03-01 2677Amazon Simple Storage Service API Reference\nFor information about the API action, see PutObject. The general request syntax is as follows:\nPUT /examplebucket/chunkObject.txt HTTP/1.1\nHost: s3.amazonaws.com\nx-amz-date: 20130524T000000Z  \nx-amz-storage-class: REDUCED_REDUNDANCY\nAuthorization: SignatureToBeCalculated\nx-amz-content-sha256: STREAMING-AWS4-HMAC-SHA256-PAYLOAD-TRAILER\nContent-Encoding: aws-chunked\nx-amz-decoded-content-length: 66560\nx-amz-trailer: x-amz-checksum-crc32\nContent-Length: 66824\n<Payload>\nThe following steps show signature calculations.\n1.", "Seed signature \u2014 Create String to Sign\na.", "CanonicalRequest\nPUT\n/examplebucket/chunkObject.txt\ncontent-encoding:aws-chunked\nhost:s3.amazonaws.com\nx-amz-content-sha256:STREAMING-AWS4-HMAC-SHA256-PAYLOAD-TRAILER\nx-amz-date:20130524T000000Z\nx-amz-decoded-content-length:66560\nx-amz-storage-class:REDUCED_REDUNDANCY\nx-amz-trailer:x-amz-checksum-crc32c\ncontent-encoding;host;x-amz-content-sha256;x-amz-date;x-amz-decoded-content-\nlength;x-amz-storage-class;x-amz-trailer\nSTREAMING-AWS4-HMAC-SHA256-PAYLOAD-TRAILER\nIn the canonical request, the third line is empty because there are no query parameters \nin the request. The last line is the constant string provided as the value of the hashed \nPayload, which should be same as the value of x-amz-content-sha256 header .\nb. StringToSign\nSignature Calculation: Including Trailing Headers API Version 2006-03-01 2678Amazon Simple Storage Service API Reference\nAWS4-HMAC-SHA256\n20130524T000000Z\n20130524/us-east-1/s3/aws4_request\n44d48b8c2f70eae815a0198cc73d7a546a73a93359c070abbaa5e6c7de112559\nNote\nFor information about each of line in the string to sign, see the diagram that \nexplains seed signature calculation.\n2. SigningKey\nsigning key  = HMAC-SHA256(HMAC-SHA256(HMAC-SHA256(HMAC-SHA256(\"AWS4\" + \n \"<YourSecretAccessKey> \",\"20130524\"),\"us-east-1\"),\"s3\"),\"aws4_request\")       \n3.", "Seed Signature\n106e2a8a18243abcf37539882f36619c00e2dfc72633413f02d3b74544bfeb8e\n4.", "Authorization header\nThe resulting Authorization header is as follows:\nAWS4-HMAC-SHA256 Credential=AKIAIOSFODNN7EXAMPLE/20130524/us-east-1/s3/\naws4_request,SignedHeaders=content-encoding;content-length;host;x-amz-\ncontent-sha256;x-amz-date;x-amz-decoded-content-length;x-amz-storage-\nclass,Signature=106e2a8a18243abcf37539882f36619c00e2dfc72633413f02d3b74544bfeb8e\n5.", "Chunk 1: (65536 bytes, with value 97 for letter 'a')\na.", "Chunk string to sign:\nAWS4-HMAC-SHA256-PAYLOAD\n20130524T000000Z\nSignature Calculation: Including Trailing Headers API Version 2006-03-01 2679Amazon Simple Storage Service API Reference\n20130524/us-east-1/s3/aws4_request\n106e2a8a18243abcf37539882f36619c00e2dfc72633413f02d3b74544bfeb8e\ne3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\nbf718b6f653bebc184e1479f1935b8da974d701b893afcf49e701f3e2f9f9c5a\nNote\nFor information about each line in the string to sign, see the preceding diagram \nthat shows various components of the string to sign (for example, the last three \nlines are, previous-signature , hash(\"\") , and hash(current-chunk-\ndata) ).\nb. Chunk signature:\nb474d8862b1487a5145d686f57f013e54db672cee1c953b3010fb58501ef5aa2\nc. Chunk data sent:\n10000;chunk-\nsignature=b474d8862b1487a5145d686f57f013e54db672cee1c953b3010fb58501ef5aa2\n<65536-bytes>\n6. Chunk 2: (1024 bytes, with value 97 for letter 'a')\na.", "Chunk string to sign:\nAWS4-HMAC-SHA256-PAYLOAD\n20130524T000000Z\n20130524/us-east-1/s3/aws4_request\nb474d8862b1487a5145d686f57f013e54db672cee1c953b3010fb58501ef5aa2\ne3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\n41edece42d63e8d9bf515a9ba6932e1c20cbc9f5a5d134645adb5db1b9737ea3\nb. Chunk signature:\n041169d545f3f4a02fe2e3d066bfb1798dd5f3417ae8cecd0e43690aafbe79d1\nc. Chunk data sent:\nSignature Calculation: Including Trailing Headers API Version 2006-03-01 2680Amazon Simple Storage Service API Reference\n400;chunk-\nsignature=041169d545f3f4a02fe2e3d066bfb1798dd5f3417ae8cecd0e43690aafbe79d1\n<1024 bytes>\n7. Chunk 3: (0 byte data)\na.", "Chunk string to sign:\nAWS4-HMAC-SHA256-PAYLOAD\n20130524T000000Z\n20130524/us-east-1/s3/aws4_request\n041169d545f3f4a02fe2e3d066bfb1798dd5f3417ae8cecd0e43690aafbe79d1\ne3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\ne3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\nb. Chunk signature:\ne05ab64fe1dfdbf0b5870abbaabdb063c371d4e96f2767e6934d90529c5ae850\nc. Chunk data sent:\n0;chunk-\nsignature=e05ab64fe1dfdbf0b5870abbaabdb063c371d4e96f2767e6934d90529c5ae850\n8. Chunk 4: Trailing headers\na.", "Trailer chunk string to sign:\nAWS4-HMAC-SHA256-TRAILER\n20130524T000000Z\n20130524/us-east-1/s3/aws4_request\ne05ab64fe1dfdbf0b5870abbaabdb063c371d4e96f2767e6934d90529c5ae850\n2e4ab969aa65b1ad6def2db10e4d3a8260683d194dbaf757f90e8a37960a4b3c\nb.", "Chunk signature:\n41e14ac611e27a8bb3d66c3bad6856f209297767d5dd4fc87d8fa9e422e03faf\nc. Chunk data sent:\nx-amz-checksum-crc32c:wdBDMA==\nSignature Calculation: Including Trailing Headers API Version 2006-03-01 2681Amazon Simple Storage Service API Reference\nx-amz-trailer-\nsignature:41e14ac611e27a8bb3d66c3bad6856f209297767d5dd4fc87d8fa9e422e03faf\nAuthenticating Requests: Using Query Parameters (AWS \nSignature Version 4)\nAs described in the authentication overview (see Authentication Methods ), you can provide \nauthentication information using query string parameters.", "Using query parameters to authenticate \nrequests is useful when you want to express a request entirely in a URL.", "This method is also \nreferred as presigning a URL.\nA use case scenario for presigned URLs is that you can grant temporary access to your Amazon S3 \nresources.", "For example, you can embed a presigned URL on your website or alternatively use it in \ncommand line client (such as Curl) to download objects.\nNote\nYou can also use the AWS CLI to create presigned URLs. For more information, see presign\nin the AWS CLI Command Reference.\nThe following is an example presigned URL.\nhttps://examplebucket.s3.amazonaws.com/test.txt\n?X-Amz-Algorithm=AWS4-HMAC-SHA256\n&X-Amz-Credential= <your-access-key-id> /20130721/us-east-1/s3/aws4_request\n&X-Amz-Date=20130721T201207Z\n&X-Amz-Expires=86400\n&X-Amz-SignedHeaders=host\n&X-Amz-Signature= <signature-value>   \nIn the example URL, note the following:\n\u2022The line feeds are added for readability.\n\u2022The X-Amz-Credential  value in the URL shows the \"/\" character only for readability.", "In \npractice, it should be encoded as %2F.", "For example:\nUsing Query Parameters API Version 2006-03-01 2682Amazon Simple Storage Service API Reference\n&X-Amz-Credential= <your-access-key-id> %2F20130721%2Fus-east-1%2Fs3%2Faws4_request\nThe following table describes the query parameters in the URL that provide authentication \ninformation.\nQuery String Parameter \nNameExample Value\nX-Amz-Algorithm Identi\ufb01es the version of AWS Signature and the algorithm that \nyou  used to calculate the signature.\nFor AWS Signature Version 4, you set this parameter value to  \n  AWS4-HMAC-SHA256 . This string identi\ufb01es AWS  Signature \nVersion 4 (AWS4) and the HMAC-SHA256 algorithm (HMAC-\nSHA256).\nX-Amz-Credential In addition to your access key ID, this parameter also provides \nscope (AWS Region and  service) for which the signature is \nvalid.", "This value must match the  scope you use in signature \ncalculations, discussed in the following section.", "The general \nform for this parameter value is as  follows:\n<your-access-key-id> /<date>/<AWS Region> /<AWS-serv \nice>/aws4_request\nFor example:\nAKIAIOSFODNN7EXAMPLE/20130721/us-east-1/s3/aw \ns4_request\nFor Amazon S3, the AWS-service  string is   s3. For a list of \nS3 AWS-region  strings, see   Regions and  Endpoints in the\nAWS General Reference.\nUsing Query Parameters API Version 2006-03-01 2683Amazon Simple Storage Service API Reference\nQuery String Parameter \nNameExample Value\nX-Amz-Date\nThe date and time format must follow the ISO 8601 standard, \nand  must be formatted with the  \"yyyyMMdd THHmmss Z\"  \n format.", "For example if the date and time was \"08/01/2016  \n 15:32:41.982-700\" then it must \ufb01rst be converted to UTC  \n (Coordinated Universal Time) and then submitted as  \"201608 \n01T223241Z\".\nX-Amz-Expires Provides the time period, in seconds, for which the generated \n presigned URL is valid.", "For example, 86400  (24 hours).", "This \nvalue is an integer.", "The minimum value you can set is 1, and  \n the maximum is 604800 (seven days).\nA presigned URL can be valid for a maximum of seven days \nbecause  the signing key you use in signature calculation is \nvalid for up to  seven days.\nX-Amz-SignedHeaders Lists the headers that you used to calculate the signature. The \nfollowing headers are  required in the signature calculations:\n\u2022\nThe HTTP host header.\n\u2022\nAny x-amz-* headers that you plan to add  to the request.\nNote\nFor added security, you should sign all the request   \nheaders that you plan to include in your request.\nUsing Query Parameters API Version 2006-03-01 2684Amazon Simple Storage Service API Reference\nQuery String Parameter \nNameExample Value\nX-Amz-Signature Provides the signature to authenticate your request.", "This  \n signature must match the signature Amazon S3 calculates; \notherwise, Amazon S3  denies the request.", "For example,  \n 733255ef022bec3f2a8701cd61d4b371f3f \n28c9f193a1f02279211d48d5193d7\nSignature calculations are described in the following section.\nX-Amz-Security-Token Optional credential parameter if using credentials sourced \nfrom the STS service.\nCalculating a Signature\nThe following diagram illustrates the signature calculation process.\nCalculating a Signature API Version 2006-03-01 2685Amazon Simple Storage Service API Reference\nThe following table describes the functions that are shown in the diagram. You need to implement \ncode for these functions.\nFunction Description\nLowercase() Convert the string to lowercase.\nHex() Lowercase base 16 encoding.\nSHA256Hash() Secure Hash Algorithm (SHA) cryptographic hash function.\nCalculating a Signature API Version 2006-03-01 2686Amazon Simple Storage Service API Reference\nFunction Description\nHMAC-SHA256() Computes HMAC by using the SHA256 algorithm with the \nsigning key provided.", "This is the \ufb01nal signature.\nTrim() Remove any leading or trailing whitespace.\nUriEncode() URI encode every byte. UriEncode() must enforce the following \nrules:\n\u2022URI encode every byte except the unreserved characters: \n'A'-'Z', 'a'-'z', '0'-'9', '-', '.', '_', and '~'.\n\u2022The space character is a reserved character and must be \nencoded as \"%20\" (and not as \"+\").\n\u2022Each URI encoded byte is formed by a '%' and the two-digit \nhexadecimal value of the byte.\n\u2022Letters in the hexadecimal value must be uppercase, for \nexample \"%1A\".\n\u2022Encode the forward slash character, '/', everywhere except in \nthe object key name. For example, if the object key name is\nphotos/Jan/sample.jpg , the forward  slash in the key \nname is not encoded.\nImportant\nThe standard UriEncode functions provided by your \ndevelopment platform may not work because of \ndi\ufb00erences in implementation and related ambiguity \nin the underlying RFCs. We recommend that you write \nyour own custom UriEncode function to ensure that \nyour encoding will work.\nTo see an example of a UriEncode function in Java, see Java \nUtilities  on the GitHub website.\nCalculating a Signature API Version 2006-03-01 2687Amazon Simple Storage Service API Reference\nFor more information about the signing process (details of creating a canonical request, string \nto sign, and signature calculations), see Signature Calculations for the Authorization Header: \nTransferring Payload in a Single Chunk (AWS Signature Version 4).", "The process is generally the \nsame except that the creation of CanonicalRequest in a presigned URL di\ufb00ers as follows:\n\u2022You don't include a payload hash in the Canonical Request, because when you create a \npresigned URL, you don't know the payload content because the URL is used to upload an \narbitrary payload.", "Instead, you use a constant string UNSIGNED-PAYLOAD .\n\u2022The Canonical Query String must include all the query parameters from the preceding table \nexcept for X-Amz-Signature .\n\u2022For S3, you must include the X-Amz-Security-Token  query parameter in the URL if using \ncredentials sourced from the STS service.\n\u2022Canonical Headers  must include the HTTP host header.", "If you plan to include any of the\nx-amz-*  headers, these headers must also be added for signature calculation. You can \noptionally add all other headers that you plan to include in your request. For added security, you \nshould sign as many headers as possible. If you add a signed header that is also a signed query \nparameter, and they di\ufb00er in value, you will receive an InvalidRequest  error as the input is \ncon\ufb02icting.\nAn Example\nSuppose you have an object test.txt  in your examplebucket  bucket. You want to share this \nobject with others for a period of 24 hours (86400 seconds) by creating a presigned URL.\nhttps://examplebucket.s3.amazonaws.com/test.txt\n?X-Amz-Algorithm=AWS4-HMAC-SHA256\n&X-Amz-Credential=AKIAIOSFODNN7EXAMPLE%2F20130524%2Fus-east-1%2Fs3%2Faws4_request\n&X-Amz-Date=20130524T000000Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host\n&X-Amz-Signature= <signature-value>\nThe following steps illustrate \ufb01rst the signature calculations and then construction of the \npresigned URL.", "The example makes the following additional assumptions:\n\u2022Request timestamp is Fri, 24 May 2013 00:00:00 GMT .\nAn Example API Version 2006-03-01 2688Amazon Simple Storage Service API Reference\n\u2022The bucket is in the US East (N.", "Virginia) region, and the credential Scope  and the Signing \nKey calculations use us-east-1  as the region speci\ufb01er.", "For more information, see Regions and \nEndpoints  in the AWS General Reference.\nYou can use this example as a test case to verify the signature that your code calculates; however, \nyou must use the same bucket name, object key, time stamp, and the following example \ncredentials:\nParameter Value\nAWSAccessKeyId AKIAIOSFODNN7EXAMPLE\nAWSSecret \nAccessKeywJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\n1.", "StringToSign\na.", "CanonicalRequest\nGET\n/test.txt\nX-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIOSFODNN7EXAMPLE\n%2F20130524%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20130524T000000Z&X-Amz-\nExpires=86400&X-Amz-SignedHeaders=host\nhost:examplebucket.s3.amazonaws.com\nhost\nUNSIGNED-PAYLOAD\nb. StringToSign\nAWS4-HMAC-SHA256\n20130524T000000Z\n20130524/us-east-1/s3/aws4_request\n3bfa292879f6447bbcda7001decf97f4a54dc650c8942174ae0a9121cf58ad04\nAn Example API Version 2006-03-01 2689Amazon Simple Storage Service API Reference\n2. SigningKey\nsigning key  = HMAC-SHA256(HMAC-SHA256(HMAC-SHA256(HMAC-SHA256(\"AWS4\" + \n \"<YourSecretAccessKey> \",\"20130524\"),\"us-east-1\"),\"s3\"),\"aws4_request\")\n3.", "Signature\naeeed9bbccd4d02ee5c0109b86d86835f995330da4c265957d157751f604d404\nNow you have all information to construct a presigned URL.", "The resulting URL for this example \nis shown as follows (you can use this to compare your presigned URL):\nhttps://examplebucket.s3.amazonaws.com/test.txt?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-\nAmz-Credential=AKIAIOSFODNN7EXAMPLE%2F20130524%2Fus-east-1%2Fs3%2Faws4_request&X-\nAmz-Date=20130524T000000Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-\nSignature=aeeed9bbccd4d02ee5c0109b86d86835f995330da4c265957d157751f604d404\nExample 2\nThe following is an example (unrelated to the previous example) showing a presigned URL with the\nX-Amz-Security-Token  parameter.\nhttps://examplebucket.s3.us-east-1.amazonaws.com/test.txt\n?X-Amz-Algorithm=AWS4-HMAC-SHA256\n&X-Amz-Credential=AKIAIOSFODNN7EXAMPLE%2F20130524%2Fus-east-1%2Fs3%2Faws4_request\n&X-Amz-Date=20200524T000000Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host\n&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEMv%2F%2F%2F%2F%2F%2F%2F%2F%2F\n%2FwEaCXVzLWVhc3QtMSJGMEQCIBSUbVdj9YGs2g0HkHsOHFdkwOozjARSKHL987NhhOC8AiBPepRU1obMvIbGU0T\n%2BWphFPgK%2Fqpxaf5Snvm5M57XFkCqlAgjz%2F%2F%2F%2F%2F%2F%2F%2F%2F\n%2F8BEAAaDDQ3MjM4NTU0NDY2MCIM83pULBe5%2F\n%2BNm1GZBKvkBVslSaJVgwSef7SsoZCJlfJ56weYl3QCwEGr2F4BmCZZyFpmWEYzWnhNK1AnHMj5nkfKlKBx30XAT5PZGVrmq4Vkn9ewlXQy1Iu3QJRi9Tdod8Ef9%2FyajTaUGh76%2BF5u5a4O115jwultOQiKomVwO318CO4l8lv\n%2F3HhMOkpdanMXn%2B4PY8lvM8RgnzSu90jOUpGXEOAo\n%2F6G8OqlMim3%2BZmaQmasn4VYRvESEd7O72QGZ3%2BvDnDVnss0lSYjlv8PP7IujnvhZRnj0WoeOyMe1lL0wTG\n%2Fa9usH5hE52w%2FYUJccOn0OaZuyROuVsRV4Q70sbWQhUvYUt%2B0tUMKzm8vsFOp4BaNZFqobbjtb36Y92v\n%2Bx5kY6i0s8QE886jJtUWMP5ldMziClGx3p0mN5dzsYlM3GyiJ\n%2FO1mWkPQDwg3mtSpOA9oeeuAMPTA7qMqy9RNuTKBDSx9EW27wvPzBum3SJhEfxv48euadKgrIX3Z79ruQFSQOc9LUrDjR\n%2B4SoWAJqK%2BGX8Q3vPSjsLxhqhEMWd6U4TXcM7ku3gxMbzqfT8NDg%3D\nExample 2 API Version 2006-03-01 2690Amazon Simple Storage Service API Reference\n&X-Amz-Signature= <signature-value>\nExamples: Signature Calculations in AWS Signature Version 4\nTopics\n\u2022Signature Calculation Examples Using Java (AWS Signature Version 4)\n\u2022Examples of Signature Calculations Using C# (AWS Signature Version 4)\nFor authenticated requests, unless you are using the AWS SDKs, you have to write code to calculate \nsignatures that provide authentication information in your requests. Signature calculation in AWS \nSignature Version 4 (see Authenticating Requests (AWS Signature Version 4)) can be a complex \nundertaking, and we recommend that you use the AWS SDKs whenever possible.\nThis section provides examples of signature calculations written in Java and C#.", "The code samples \nsend the following requests and use the HTTP Authorization header to provide authentication \ninformation:\n\u2022PUT object \u2013 Separate examples illustrate both uploading the full payload at once and \nuploading the payload in chunks. For information about using the Authorization header for \nauthentication, see Authenticating Requests: Using the Authorization Header (AWS Signature \nVersion 4).\n\u2022GET object \u2013 This example generates a presigned URL to get an object.", "Query parameters \nprovide the signature and other authentication information.", "Users can paste a presigned URL \nin their browser to retrieve the object, or you can use the URL to create a clickable link.", "For \ninformation about using query parameters for authentication, see Authenticating Requests: \nUsing Query Parameters (AWS Signature Version 4).\nThe rest of this section describes the examples in Java and C#. The topics include instructions for \ndownloading the samples and for executing them.\nSignature Calculation Examples Using Java (AWS Signature Version 4)\nThe Java sample that shows signature calculation can be downloaded at https://\ndocs.aws.amazon.com/AmazonS3/latest/API/samples/AWSS3SigV4JavaSamples.zip. In\nRunAllSamples.java , the main() function executes sample requests to create an object, \nExamples: Signature Calculations API Version 2006-03-01 2691Amazon Simple Storage Service API Reference\nretrieve an object, and create a presigned URL for the object.", "The sample creates an object from \nthe text string provided in the code:\nPutS3ObjectSample.putS3Object(bucketName, regionName, awsAccessKey, awsSecretKey);  \nGetS3ObjectSample.getS3Object(bucketName, regionName, awsAccessKey, awsSecretKey);  \nPresignedUrlSample.getPresignedUrlToS3Object(bucketName, regionName, awsAccessKey, \n awsSecretKey);  \nPutS3ObjectChunkedSample.putS3ObjectChunked(bucketName, regionName, awsAccessKey, \n awsSecretKey);\nTo test the examples on a Linux-based computer\nThe following instructions are for the Linux operating system.\n1.In a terminal, navigate to the directory that contains AWSS3SigV4JavaSamples.zip .\n2.Extract the .zip \ufb01le.\n3.In a text editor, open the \ufb01le ./com/amazonaws/services/s3/samples/\nRunAllSamples.java . Update code with the following information:\n\u2022The name of a bucket where the new object can be created.\nNote\nThe examples use a virtual-hosted style request to access the bucket. To avoid \npotential errors, ensure that your bucket name conforms to the bucket naming rules as \nexplained in Bucket Restrictions and Limitations in the Amazon Simple Storage Service \nUser Guide .\n\u2022AWS Region where the bucket resides.\nIf bucket is in the US East (N.", "Virginia) region, use us-east-1 to specify the region.", "For a list of \nother AWS Regions, go to Amazon Simple Storage Service (S3) in the AWS General Reference.\n4.Compile the source code and store the compiled classes into the bin/ directory.\njavac -d bin -source 6 -verbose com\n5.Change the directory to bin/ , and then run RunAllSamples .\nSignature Calculation Examples Using Java API Version 2006-03-01 2692Amazon Simple Storage Service API Reference\njava com.amazonaws.services.s3.sample.RunAllSamples\nThe code runs all the methods in main(). For each request, the output will show the canonical \nrequest, the string to sign, and the signature.\nExamples of Signature Calculations Using C# (AWS Signature Version 4)\nThe C# sample that shows signature calculation can be downloaded at https://\ndocs.aws.amazon.com/AmazonS3/latest/API/samples/AmazonS3SigV4_Samples_CSharp.zip.", "\nIn Program.cs , the main() function executes sample requests to create an object, retrieve an \nobject, and create a presigned URL for the object.", "The code for signature calculation is in the\n\\Signers  folder.\nPutS3ObjectSample.Run(awsRegion, bucketName, \"MySampleFile.txt\");\nConsole.WriteLine(\"\\n\\n************************************************\");\nPutS3ObjectChunkedSample.Run(awsRegion, bucketName, \"MySampleFileChunked.txt\");\nConsole.WriteLine(\"\\n\\n************************************************\");\nGetS3ObjectSample.Run(awsRegion, bucketName, \"MySampleFile.txt\");\nConsole.WriteLine(\"\\n\\n************************************************\");\nPresignedUrlSample.Run(awsRegion, bucketName, \"MySampleFile.txt\");\nTo test the examples with Microsoft Visual Studio 2010 or later\n1.Extract the .zip \ufb01le.\n2.Start Visual Studio, and then open the .sln \ufb01le.\n3.Update the App.con\ufb01g \ufb01le with valid security credentials.\n4.Update the code as follows:\n\u2022In Program.cs , provide the bucket name and the AWS Region where the bucket resides. The \nsample creates an object in this bucket.\n5.Run the code.\n6.To verify that the object was created, copy the presigned URL that the program creates, and \nthen paste it in a browser window.\nSignature Calculation Examples Using C# API Version 2006-03-01 2693Amazon Simple Storage Service API Reference\nAuthenticating Requests: Browser-Based Uploads Using POST \n(AWS Signature Version 4)\nAmazon S3 supports HTTP POST requests so that users can upload content directly to Amazon \nS3. Using HTTP POST to upload content simpli\ufb01es uploads and reduces upload latency where \nusers upload data to store in Amazon S3.", "This section describes how you authenticate HTTP POST \nrequests.", "For more information about HTTP POST requests, how to create a form, create a POST \npolicy, and an example, see Browser-Based Uploads Using POST (AWS Signature Version 4).\nTo authenticate an HTTP POST request you do the following:\n1.The form must include the following \ufb01elds to provide signature and relevant information that \nAmazon S3 can use to re-calculate the signature upon receiving the request:\nElement Name Description\npolicy\nThe Base64-encoded security policy that describes \nwhat  is permitted in the request.", "For signature \ncalculation this  policy is the string you sign.", "Amazon \nS3 must get this  policy so it can re-calculate the \nsignature.\nx-amz-algorithm\nThe signing algorithm used.", "For AWS Signature \nVersion  4, the value is AWS4-HMAC-SHA256 .\nx-amz-credential\nIn addition to your access key ID, this provides scope  \n information you used in calculating the signing key \nfor  signature calculation.\nIt is a string of the following form:\n<your-access-key-id> /<date>/<aws-regi \non>/<aws-service> /aws4_request  \nFor example:\nAuthenticating HTTP POST Requests API Version 2006-03-01 2694Amazon Simple Storage Service API Reference\nElement Name Description\n   AKIAIOSFODNN7EXAMPLE/20130728/us- \neast-1/s3/aws4_request .", ".\nFor Amazon S3, the aws-service string is s3. For a list \nof  Amazon S3 aws-region  strings, see Regions \nand Endpoints  in the AWS General Reference.\nx-amz-date\nIt is the date value in ISO8601 format.", "For example,   \n  20130728T000000Z .\nIt is the same date you used in creating the signing   \nkey. This must also be the same value you provide in \nthe  policy (x-amz-date ) that you signed.\nx-amz-signature\n(AWS Signature Version 4) The HMAC-SHA256 hash \nof the  security policy.\nFor more information on options for the signature, \nsee Add the signature to the HTTP request in the AWS \nGeneral Reference.\n2.The POST policy must include the following elements:\nElement Name Description\nx-amz-algorithm\nThe signing algorithm that you used to calculation \nthe  signature. For AWS Signature Version 4, the value \nis   AWS4-HMAC-SHA256 .\nx-amz-credential\nIn addition to your access key ID, this provides scope  \n information you used in calculating the signing key \nfor  signature calculation.\nIt is a string of the following form:\nAuthenticating HTTP POST Requests API Version 2006-03-01 2695Amazon Simple Storage Service API Reference\nElement Name Description\n<your-access-key-id> /<date>/<aws-regi \non>/<aws-service> /aws4_request  \nFor example,\n   AKIAIOSFODNN7EXAMPLE/20130728/us- \neast-1/s3/aws4_request .", ".", "\nx-amz-date\nThe date value speci\ufb01ed in the ISO8601 formatted \n  string.", "For example, \"20130728T000000Z\".", "The \ndate must be the  same that you used in creating the \nsigning key for signature  calculation.\n3.For signature calculation the POST policy is the string to sign.\nCalculating a Signature\nThe following diagram illustrates the signature calculation process.\nCalculating a Signature API Version 2006-03-01 2696Amazon Simple Storage Service API Reference\nTo Calculate a signature\n1.", "Create a policy using UTF-8 encoding.\n2. Convert the UTF-8-encoded policy to Base64.", "The result is the string to sign.\n3. Create the signature as an HMAC-SHA256 hash of the string to sign. You will provide the \nsigning key as key to the hash function.\n4.", "Encode the signature by using hex encoding.\nFor more information about creating HTML forms, security policies, and an example, see the \nfollowing subtopics:\n\u2022Creating an HTML Form (Using AWS Signature Version 4)\n\u2022POST Policy\n\u2022Example: Browser-Based Upload using HTTP POST (Using AWS Signature Version 4)\nAmazon S3 Signature Version 4 Authentication Speci\ufb01c Policy \nKeys\nThe following table shows the policy keys related Amazon S3 Signature Version 4 authentication \nthat can be in Amazon S3 policies.", "In a bucket policy, you can add these conditions to enforce \nspeci\ufb01c behavior when requests are authenticated by using Signature Version 4. For example \npolicies, see Bucket Policy Examples Using Signature Version 4 Related Condition Keys.\nApplicable Keys Description\ns3:signatureversion Identi\ufb01es the version of AWS Signature \nthat you want to  support for authentic \nated requests. For authenticated requests, \nAmazon S3  supports both Signature Version \n4 and Signature Version 2. You can  add this \ncondition in your bucket policy to require a \nspeci\ufb01c  signature version.\nValid values:\nAmazon S3 Signature Version 4 Authentication Speci\ufb01c Policy Keys API Version 2006-03-01 2697Amazon Simple Storage Service API Reference\nApplicable Keys Description\n\"AWS\" identi\ufb01es Signature Version 2\n\"AWS4-HMAC-SHA256\"  identi\ufb01es Signature \nVersion  4\ns3:authType Amazon S3 supports various methods of \nauthentication (see Authenticating Requests \n(AWS Signature Version  4).", "You can  option \nally use this condition key to restrict incoming \nrequests to  use a speci\ufb01c authentication \nmethod.", "For example, you can allow  only the \nHTTP Authorization  header to be used in  \n request authentication.\nValid values:\nREST-HEADER\nREST-QUERY-STRING\nPOST\nAmazon S3 Signature Version 4 Authentication Speci\ufb01c Policy Keys API Version 2006-03-01 2698Amazon Simple Storage Service API Reference\nApplicable Keys Description\ns3:signatureAge The length of time, in milliseconds, that a \nsignature is valid  in an authenticated request.\nThis  condition works for:\n\u2022Presigned URLs  \u2014 where the most restricti \nve condition wins. For more information, see\nWorking with presigned URLs.\n\u2022Presigned POST  \u2014 upload \ufb01les directly to S3 \nusing pre-signed POST. For more informati \non, see Amazon S3 POST Policy.\nIn Signature Version 2, this value is always set \nto 0.\nIn Signature Version 4, the signing key is valid \nfor up to seven  days.", "Therefore, the signature \ns are also valid for up to seven  days. You can \nuse this condition to further limit the signature \nage.", "For more information, see Introduction to \nSigning Requests.\nExample value: 100\nAmazon S3 Signature Version 4 Authentication Speci\ufb01c Policy Keys API Version 2006-03-01 2699Amazon Simple Storage Service API Reference\nApplicable Keys Description\ns3:x-amz-content-sha256 You can use this condition key to disallow \nunsigned content in  your bucket.\nWhen you use Signature Version 4, for requests \nthat use the Authorization  header, you \nadd the x-amz-content-sha256  header \nin the  signature calculation and then set its \nvalue to the hash payload.\nYou can use this condition key in your bucket \npolicy to deny any  uploads where payloads are \nnot signed.", "For example:\n\u2022\nDeny uploads that use presigned URLs.", "\nFor more  information, see Authenticating \nRequests: Using Query Parameters (AWS S \nignature Version 4).\n\u2022\nDeny uploads that use Authorization header \nto authenticate requests but don't sign  \n the payload. For more information, see\nSignature Calculations for the Authorization \nHeader:  Transferring Payload in a Single \nChunk (AWS Signature Version 4).\n \nValid value: UNSIGNED-PAYLOAD\nBucket Policy Examples Using Signature Version 4 Related Condition \nKeys\nThe following bucket policy denies any Amazon S3 presigned URL request on objects in\nexamplebucket  if the signature is more than ten minutes old.\nBucket Policy Examples Using Signature Version 4 Related Condition Keys API Version 2006-03-01 2700Amazon Simple Storage Service API Reference\n{ \n   \"Version\": \"2012-10-17\", \n   \"Statement\": [ \n      { \n         \"Sid\": \"Deny a presigned URL request if the signature is more than 10 min \n old\", \n         \"Effect\": \"Deny\", \n         \"Principal\": \"*\", \n         \"Action\": \"s3:*\", \n         \"Resource\": \"arn:aws:s3:::examplebucket3/*\", \n         \"Condition\": { \n            \"NumericGreaterThan\": { \n               \"s3:signatureAge\": 600000 \n            } \n         } \n      } \n   ]\n}\nThe following bucket policy allows only requests that use the Authorization  header for request \nauthentication.", "Any POST or presigned URL requests will be denied.\n{ \n   \"Version\": \"2012-10-17\", \n   \"Statement\": [ \n         { \n               \"Sid\": \"Allow only requests that use Authorization header for request \n authentication. Deny POST or presigned URL requests.\", \n               \"Effect\": \"Deny\", \n               \"Principal\": \"*\", \n               \"Action\": \"s3:*\", \n               \"Resource\": \"arn:aws:s3:::examplebucket3/*\", \n               \"Condition\": { \n                     \"StringNotEquals\": { \n                           \"s3:authType\": \"REST-HEADER\" \n                     } \n               } \n         } \n   ]\n}\nBucket Policy Examples Using Signature Version 4 Related Condition Keys API Version 2006-03-01 2701Amazon Simple Storage Service API Reference\nThe following bucket policy denies any uploads with unsigned payloads, such as uploads using \npresigned URLs.\n{ \n   \"Version\": \"2012-10-17\", \n   \"Statement\": [ \n         { \n               \"Sid\": \"Deny uploads with unsigned payloads.\", \n               \"Effect\": \"Deny\", \n               \"Principal\": \"*\", \n               \"Action\": \"s3:*\", \n               \"Resource\": \"arn:aws:s3:::examplebucket3/*\", \n               \"Condition\": { \n                     \"StringEquals\": { \n                           \"s3:x-amz-content-sha256\": \"UNSIGNED-PAYLOAD\" \n                     } \n               } \n         } \n   ]\n}\nBucket Policy Examples Using Signature Version 4 Related Condition Keys API Version 2006-03-01 2702Amazon Simple Storage Service API Reference\nBrowser-Based Uploads Using POST (AWS Signature \nVersion 4)\nThis section discusses how to upload \ufb01les directly to Amazon S3 through a browser using HTTP \nPOST requests. It also contains information about how to use the AWS Amplify JavaScript library \nfor browser-based \ufb01le uploads to Amazon S3.\nTopics\n\u2022POST Object\n\u2022POST Object restore\n\u2022Browser-Based Uploads Using HTTP POST\n\u2022Calculating a Signature\n\u2022Creating an HTML Form (Using AWS Signature Version 4)\n\u2022POST Policy\n\u2022Example: Browser-Based Upload using HTTP POST (Using AWS Signature Version 4)\n\u2022Browser-Based Uploads to Amazon S3 Using the AWS Amplify Library\nAPI Version 2006-03-01 2703Amazon Simple Storage Service API Reference\nPOST Object\nDescription\nThe POST operation adds an object to a speci\ufb01ed bucket by using HTML forms.", "POST  is an \nalternate form of PUT that enables browser-based uploads as a way of putting objects in buckets.", "\nParameters that are passed to PUT through HTTP headers are instead passed as form \ufb01elds to\nPOST in the multipart/form-data encoded message body.", "To add an object to a bucket, you \nmust have WRITE access on the bucket.", "Amazon S3 never stores partial objects. If you receive a \nsuccessful response, you can be con\ufb01dent that the entire object was stored.\nAmazon S3 is a distributed system. Unless you've enabled versioning for a bucket, if Amazon S3 \nreceives multiple write requests for the same object simultaneously, only the last version of the \nobject written is stored.\nTo ensure that data is not corrupted while traversing the network, use the Content-MD5  form \n\ufb01eld. When you use this form \ufb01eld, Amazon S3 checks the object against the provided MD5 value. \nIf they do not match, Amazon S3 returns an error. Additionally, you can calculate the MD5 value \nwhile posting an object to Amazon S3 and compare the returned ETag  to the calculated MD5 \nvalue.", "The ETag re\ufb02ects only changes to the contents of an object, not its metadata.\nNote\nTo con\ufb01gure your application to send the request headers before sending the request body, \nuse the HTTP status code 100 (Continue). For POST operations, using this status code helps \nyou avoid sending the message body if the message is rejected based on the headers (for \nexample, because of an authentication failure or redirect).", "For more information about \nthe HTTP status code 100 (Continue), go to Section 8.2.3 of http://www.ietf.org/rfc/ \nrfc2616.txt.\nAmazon S3 automatically encrypts all new objects that are uploaded to an S3 bucket.", "The \nencryption setting of an uploaded object depends on the default encryption con\ufb01guration of the \ndestination bucket. By default, all buckets have a default encryption con\ufb01guration that uses server-\nside encryption with Amazon S3 managed keys (SSE-S3).\nIf the destination bucket has an encryption con\ufb01guration that uses server-side encryption with an \nAWS Key Management Service (AWS KMS) key (SSE-KMS), dual-layer server-side encryption with \nPOST Object API Version 2006-03-01 2704Amazon Simple Storage Service API Reference\nan AWS KMS key (DSSE-KMS), or a customer-provided encryption key (SSE-C), Amazon S3 uses the \ncorresponding KMS key or customer-provided key to encrypt the uploaded object.", "When uploading \nan object, if you want to change the encryption setting of the uploaded object, you can specify the \ntype of server-side encryption.", "You can con\ufb01gure SSE-S3, SSE-KMS, DSSE-KMS, or SSE-C.", "For more \ninformation, see Protecting data using server-side encryption in the Amazon Simple Storage Service \nUser Guide .\nImportant\nWhen constructing your request, make sure that the file  \ufb01eld is the last \ufb01eld in the form.\nVersioning\nIf you enable versioning for a bucket, POST automatically generates a unique version ID for the \nobject being added.", "Amazon S3 returns this ID in the response by using the x-amz-version-id\nresponse header.\nIf you suspend versioning for a bucket, Amazon S3 always uses null as the version ID of the object \nstored in a bucket.\nFor more information about returning the versioning state of a bucket, see GET Bucket (Versioning \nStatus) .\nAmazon S3 is a distributed system. If you enable versioning for a bucket and Amazon S3 receives \nmultiple write requests for the same object simultaneously, all versions of the object are stored.\nTo see sample requests that use versioning, see Sample Request.\nRequests\nSyntax\nPOST / HTTP/1.1\nHost: destinationBucket .s3.amazonaws.com\nUser-Agent: browser_data\nAccept: file_types\nAccept-Language: Regions\nAccept-Encoding: encoding\nAccept-Charset: character_set\nKeep-Alive: 300\nVersioning API Version 2006-03-01 2705Amazon Simple Storage Service API Reference\nConnection: keep-alive\nContent-Type: multipart/form-data; boundary=9431149156168\nContent-Length: length\n--9431149156168\nContent-Disposition: form-data; name=\"key\"\nacl\n--9431149156168\nContent-Disposition: form-data; name=\"tagging\"\n<Tagging><TagSet><Tag><Key> Tag Name </Key><Value> Tag Value </Value></Tag></TagSet></\nTagging>\n--9431149156168\nContent-Disposition: form-data; name=\"success_action_redirect\"\nsuccess_redirect\n--9431149156168\nContent-Disposition: form-data; name=\"Content-Type\"\ncontent_type\n--9431149156168\nContent-Disposition: form-data; name=\"x-amz-meta-uuid\"\nuuid\n--9431149156168\nContent-Disposition: form-data; name=\"x-amz-meta-tag\"\nmetadata\n--9431149156168\nContent-Disposition: form-data; name=\"AWSAccessKeyId\"\naccess-key-id\n--9431149156168\nContent-Disposition: form-data; name=\"Policy\"\nencoded_policy\n--9431149156168\nContent-Disposition: form-data; name=\"Signature\"\nsignature =\n--9431149156168\nContent-Disposition: form-data; name=\"file\"; filename=\" MyFilename.jpg \"\nContent-Type: image/jpeg\nRequests API Version 2006-03-01 2706Amazon Simple Storage Service API Reference\nfile_content\n--9431149156168\nContent-Disposition: form-data; name=\"submit\"\nUpload to Amazon S3\n--9431149156168--\nRequest Parameters\nThis implementation of the operation does not use request parameters.\nForm Fields\nThis operation can use the following form \ufb01elds.\nName Description Required\nAWSAccessKeyId The AWS access key ID of the owner of the bucket \nwho grants an Anonymous user access for a \nrequest that satis\ufb01es the set of constraints in the \npolicy.\nType: String\nDefault: None\nConstraints: Required if a policy document is \nincluded with the request.Condition \nal\nacl The speci\ufb01ed Amazon S3 access control list \n(ACL).", "If the speci\ufb01ed ACL is not valid, an error is \ngenerated.", "For more information about ACLs, see\nAccess control list (ACL) overview in the Amazon \nSimple Storage Service User Guide.\nType: String\nDefault: privateNo\nRequests API Version 2006-03-01 2707Amazon Simple Storage Service API Reference\nName Description Required\nValid Values: private | public-read | \npublic-read-write | aws-exec-read | \nauthenticated-read | bucket-owner-\nread | bucket-owner-full-control\nCache-Control , Content-\nType , Content-D \nisposition , Content-E \nncoding , ExpiresThe REST-speci\ufb01c headers.", "For more information, \nsee PutObject.\nType: String\nDefault: NoneNo\nfile The \ufb01le or text content.\nThe \ufb01le or text content must be the last \ufb01eld in the \nform.\nYou cannot upload more than one \ufb01le at a time.\nType: File or text content\nDefault: NoneYes\nkey The name of the uploaded key.\nTo use the \ufb01le name provided by the user, use the\n${filename}  variable.", "For example, if a user \nnamed Mary uploads the \ufb01le example.jpg  and \nyou specify /user/mary/${filename} , the \nkey name is /user/mary/example.jpg .\nFor more information, see Object key and \nmetadata  in the Amazon Simple Storage Service \nUser Guide .\nType: String\nDefault: NoneYes\nRequests API Version 2006-03-01 2708Amazon Simple Storage Service API Reference\nName Description Required\npolicy The security policy that describes what is \npermitted in the request.", "Requests without a \nsecurity policy are considered anonymous and \nwork only on publicly writable buckets.", "For \nmore information, see HTML forms  and Upload \nexamples  in the Amazon Simple Storage Service \nUser Guide .\nType: String\nDefault: None\nConstraints: A security policy is required if the \nbucket is not publicly writable.Condition \nal\nRequests API Version 2006-03-01 2709Amazon Simple Storage Service API Reference\nName Description Required\nsuccess_action_red \nirect , redirectThe URL to which the client is redirected upon a \nsuccessful upload.\nIf success_action_redirect  is not speci\ufb01ed \n, Amazon S3 returns the empty document type \nspeci\ufb01ed in the success_action_status\n\ufb01eld.\nIf Amazon S3 cannot interpret the URL, it acts as if \nthe \ufb01eld is not present.\nIf the upload fails, Amazon S3 displays an error \nand does not redirect the user to a URL.\nType: String\nDefault: None\nNote\nThe redirect  \ufb01eld name is deprecated, \nand support for the redirect  \ufb01eld name \nwill be removed in the future.No\nRequests API Version 2006-03-01 2710Amazon Simple Storage Service API Reference\nName Description Required\nsuccess_action_status If you don't specify success_action_red \nirect, the status code is returned to the client \nwhen the upload succeeds.\nThis \ufb01eld accepts the values 200, 201, or 204 (the \ndefault).\nIf the value is set to 200 or 204, Amazon S3 \nreturns an empty document with a 200 or 204 \nstatus code.\nIf the value is set to 201, Amazon S3 returns an \nXML document with a 201 status code.\nIf the value is not set or if it is set to a value that is \nnot valid, Amazon S3 returns an empty document \nwith a 204 status code.\nType: String\nDefault: NoneNo\nRequests API Version 2006-03-01 2711Amazon Simple Storage Service API Reference\nName Description Required\ntagging The speci\ufb01ed set of tags to add to the object.", "To \nadd tags, use the following encoding scheme.\n<Tagging> \n  <TagSet> \n    <Tag> \n      <Key> TagName</Key> \n      <Value> TagValue </Value> \n    </Tag> \n    ...", "\n  </TagSet> \n</Tagging>\nFor more information, see Object tagging in the\nAmazon Simple Storage Service User Guide.\nType: String\nDefault: NoneNo\nx-amz-storage-class The storage class to use for storing the object.", "\nIf you don't specify a class, Amazon S3 uses the \ndefault storage class, STANDARD . Amazon S3 \nsupports other storage classes.", "For more informati \non, see Storage classes  in the Amazon Simple \nStorage Service User Guide.\nType: String\nDefault: STANDARD\nValid values: STANDARD  | REDUCED_REDUNDANCY\n | GLACIER  | GLACIER_IR  | STANDARD_IA\n| ONEZONE_IA  | INTELLIGENT_TIERING  |\nDEEP_ARCHIVENo\nRequests API Version 2006-03-01 2712Amazon Simple Storage Service API Reference\nName Description Required\nx-amz-meta-* Headers starting with this pre\ufb01x are user-de\ufb01ned \nmetadata.", "Each one is stored and returned as a \nset of key-value pairs.", "Amazon S3 doesn't validate \nor interpret user-de\ufb01ned metadata.", "For more \ninformation, see PutObject.\nType: String\nDefault: NoneNo\nx-amz-security-token The Amazon DevPay security token.\nEach request that uses Amazon DevPay requires \ntwo x-amz-security-token  form \ufb01elds: one \nfor the product token and one for the user token.\nType: String\nDefault: NoneNo\nx-amz-signature (AWS Signature Version 4) The HMAC-SHA256 \nhash of the security policy.\nType: String\nDefault: NoneCondition \nal\nRequests API Version 2006-03-01 2713Amazon Simple Storage Service API Reference\nName Description Required\nx-amz-website-redi \nrect-locationIf the bucket is con\ufb01gured as a website, this \ufb01eld \nredirects requests for this object to another object \nin the same bucket or to an external URL.", "Amazon \nS3 stores the value of this header in the object \nmetadata.", "For information about object metadata, \nsee Object key and metadata in the Amazon Simple \nStorage Service User Guide.\nIn the following example, the request header sets \nthe redirect to an object (anotherPage.html ) in \nthe same bucket:\nx-amz-website-redirect-location: /\nanotherPage.html\nIn the following example, the request header sets \nthe object redirect to another website:\nx-amz-website-redirect-location: \nhttp://www.example.com/\nFor more information about website hosting in \nAmazon S3, see Hosting websites on Amazon S3\nand How to con\ufb01gure website page redirects in the\nAmazon Simple Storage Service User Guide.\nType: String\nDefault: None\nConstraints: The value must be pre\ufb01xed by /,\nhttp:// , or https:// . The length of the value is \nlimited to 2 KB.No\nRequests API Version 2006-03-01 2714Amazon Simple Storage Service API Reference\nAdditional Checksum Request Form Fields\nWhen uploading an object, you can specify various checksums that you would like to use to verify \nyour data integrity.", "You can specify one additional checksum algorithm for Amazon S3 to use.", "For \nmore information about additional checksum values, see Checking object integrity in the Amazon \nSimple Storage Service User Guide.\nName Description Required\nx-amz-che \ncksum-alg \norithmIndicates the algorithm used to create the checksum for \nthe object.", "If a value is speci\ufb01ed, you must include the \nmatching checksum header. Otherwise, your request will \ngenerate a 400 error.\nPossible values include CRC32 , CRC32C , SHA1 , and SHA256 .No\nx-amz-che \ncksum-crc32Speci\ufb01es the base64-encoded, 32-bit CRC32 checksum of \nthe object.\nThis parameter is required if the value of x-amz-che \ncksum-algorithm  is CRC32 .Condition \nal\nx-amz-che \ncksum-crc32cSpeci\ufb01es the base64-encoded, 32-bit CRC32C checksum of \nthe object.\nThis parameter is required if the value of x-amz-che \ncksum-algorithm  is CRC32C .Condition \nal\nx-amz-che \ncksum-sha1Speci\ufb01es the base64-encoded, 160-bit SHA-1 digest of the \nobject.\nThis parameter is required if the value of x-amz-che \ncksum-algorithm  is SHA1 .Condition \nal\nx-amz-che \ncksum-sha256Speci\ufb01es the base64-encoded, 256-bit SHA-256 digest of \nthe object.\nThis parameter is required if the value of x-amz-che \ncksum-algorithm  is SHA256 .Condition \nal\nRequests API Version 2006-03-01 2715Amazon Simple Storage Service API Reference\nServer-Side Encryption Speci\ufb01c Request Form Fields\nServer-side encryption is data encryption at rest.", "Amazon S3 encrypts your data while writing it to \ndisks in AWS data centers and decrypts your data when you access it. When uploading an object, \nyou can specify the type of server-side encryption that you want Amazon S3 to use for encrypting \nthe object.\nThere are four types of server-side encryption:\n\u2022Server-side encryption with Amazon S3 managed keys (SSE-S3) \u2013 Starting May 2022, all \nAmazon S3 buckets have encryption con\ufb01gured by default. The default option for server-\nside encryption is with SSE-S3.", "Each object is encrypted with a unique key.", "As an additional \nsafeguard, SSE-S3 encrypts the key itself with a root key that it regularly rotates. SSE-S3 uses \none of the strongest block ciphers available, 256-bit Advanced Encryption Standard (AES-256), \nto encrypt your data.\n\u2022Server-side encryption with AWS KMS keys (SSE-KMS) \u2013 SSE-KMS is provided through an \nintegration of the AWS KMS service with Amazon S3.", "With AWS KMS, you have more control over \nyour keys. For example, you can view separate keys, edit control policies, and follow the keys in \nAWS CloudTrail.", "Additionally, you can create and manage customer managed keys or use AWS \nmanaged keys that are unique to you, your service, and your Region.\n\u2022Dual-layer server-side encryption with AWS KMS keys (DSSE-KMS) \u2013 Dual-layer server-side \nencryption with AWS KMS keys (DSSE-KMS) is similar to SSE-KMS, but applies two individual \nlayers of object-level encryption instead of one layer.\n\u2022Server-side encryption with customer-provided keys (SSE-C) \u2013 With SSE-C, you manage the \nencryption keys, and Amazon S3 manages the encryption as it writes to disks, and the decryption \nwhen you access your objects.\nFor more information, see  Protecting data using server-side encryption in the Amazon Simple \nStorage Service User Guide.\nDepending on which type of server-side encryption you want to use, specify the following form \n\ufb01elds.\n\u2022Use SSE-S3, SSE-KMS, or DSSE-KMS \u2013 If you want to use these types of server-side encryption, \nspecify the following form \ufb01elds in the request.\nRequests API Version 2006-03-01 2716Amazon Simple Storage Service API Reference\nName Description Required\nx-amz-server-\nside-encryptio \nnSpeci\ufb01es the server-side encryption algorithm to use \nwhen Amazon S3 creates an object. To use SSE-S3, specify\nAES256.", "To use SSE-KMS, specify aws:kms. To use DSSE-\nKMS, specify aws:kms:dsse .\nType: String\nValid Value: aws:kms , AES256 , aws:kms:dsseYes\nx-amz-server-\nside-encryptio \nn-aws-kms-\nkey-idIf the x-amz-server-side-encryption  header \nhas a valid value of aws:kms  or aws:kms:dsse , this \nheader speci\ufb01es the ID of the AWS KMS key that was used \nto encrypt the object.\nType: StringYes, if \nthe value \nof x-\namz-ser \nver-\nside- \nencryptio \nn is\naws:kms\nor\naws:kms:d \nsse\nx-amz-server-\nside-encryptio \nn-contextIf x-amz-server-side-encryption  has a valid \nvalue of aws:kms  or aws:kms:dsse , this header \nspeci\ufb01es the encryption context for the object. The value \nof this header is a base64-encoded UTF-8 string that \ncontains JSON-formatted key-value pairs for the encryptio \nn context.\nType: StringNo\nRequests API Version 2006-03-01 2717Amazon Simple Storage Service API Reference\nName Description Required\nx-amz-server-\nside-encryptio \nn-bucket-key-\nenabledIf x-amz-server-side-encryption  has a valid \nvalue of aws:kms  or aws:kms:dsse , this header \nspeci\ufb01es whether Amazon S3 should use an S3 Bucket Key \nwith SSE-KMS or DSSE-KMS. Setting this header to true\ncauses Amazon S3 to use an S3 Bucket Key for object \nencryption with SSE-KMS or DSSE-KMS.\nType: BooleanNo\nNote\nIf you specify x-amz-server-side-encryption:aws:kms  or x-amz-server-side-\nencryption:aws:kms:dsse , but do not provide x-amz-server-side-encryption-\naws-kms-key-id , Amazon S3 uses the AWS managed key (aws/S3) to protect the data.\n\u2022Use SSE-C \u2013 If you want to manage your own encryption keys, you must provide all the following \nform \ufb01elds in the request.\nNote\nIf you use SSE-C, the ETag value that Amazon S3 returns in the response is not the MD5 \nof the object.\nName Description Required\nx-amz-server-\nside-encryptio \nn-customer-\nalgorithmSpeci\ufb01es the algorithm to use to when encrypting the \nobject.\nType: String\nDefault: None\nValid Value: AES256Yes\nRequests API Version 2006-03-01 2718Amazon Simple Storage Service API Reference\nName Description Required\nConstraints: Must be accompanied by valid x-amz-ser \nver-side-encryption-customer-key  and x-\namz-server-side-encryption-customer-key-\nMD5  \ufb01elds.\nx-amz-server-\nside-encryptio \nn-customer-\nkeySpeci\ufb01es the customer-provided base64-encoded \nencryption key for Amazon S3 to use in encrypting \ndata.", "This value is used to store the object, and then it \nis discarded.", "Amazon does not store the encryption key.", "\nThe key must be appropriate for use with the algorithm \nspeci\ufb01ed in the x-amz-server-side-encryption-\ncustomer-algorithm  header.\nType: String\nDefault: None\nConstraints: Must be accompanied by valid x-amz-ser \nver-side-encryption-customer-algorithm\nand x-amz-server-side-encryption-custome \nr-key-MD5  \ufb01elds.Yes\nx-amz-server-\nside-encryptio \nn-customer-\nkey-MD5Speci\ufb01es the base64-encoded 128-bit MD5 digest of the \nencryption key according to RFC 1321.", "Amazon S3 uses \nthis header for a message-integrity check to ensure that \nthe encryption key was transmitted without error.\nType: String\nDefault: None\nConstraints: Must be accompanied by valid x-amz-ser \nver-side-encryption-customer-algorithm\nand x-amz-server-side-encryption-custome \nr-key  \ufb01elds.Yes\nRequests API Version 2006-03-01 2719Amazon Simple Storage Service API Reference\nResponses\nResponse Headers\nThis implementation of the operation can include the following response headers in addition to the \nresponse headers common to all responses. For more information, see Common Response Headers.\nName Description\nx-amz-checksum-crc32 The base64-encoded, 32-bit CRC32 checksum of the \nobject.\nType: String\nx-amz-checksum-crc32c The base64-encoded, 32-bit CRC32C checksum of \nthe object.\nType: String\nx-amz-checksum-sha1 The base64-encoded, 160-bit SHA-1 digest of the \nobject.\nType: String\nx-amz-checksum-sha256 The base64-encoded, 256-bit SHA-256 digest of the \nobject.\nType: String\nx-amz-expiration If an Expiration  action is con\ufb01gured for the \nobject as part of the bucket's lifecycle con\ufb01gura \ntion, Amazon S3 returns this header.", "\u00a0The header \nvalue includes an expiry-date  component and \na URL-encoded rule-id component.", "\u00a0For version-\nenabled buckets, this header applies only to current \nversions.", "Amazon S3 does not provide a header to \nindicate when a noncurrent version is eligible for \npermanent deletion.", "For more information, see\nPutBucketLifecycleCon\ufb01guration.\nRequests API Version 2006-03-01 2720Amazon Simple Storage Service API Reference\nName Description\nType: String\nsuccess_action_redirect, \nredirectThe URL to which the client is redirected on a \nsuccessful upload.\nType: String\nAncestor: PostResponse\nx-amz-server-side-encryptio \nnThe server-side encryption algorithm that was used \nwhen storing this object in Amazon S3 (for example,\nAES256 , aws:kms , aws:kms:dsse ).\nType: String\nx-amz-server-side-encryptio \nn-aws-kms-key-idIf the x-amz-server-side-encryption\nheader has a valid value of aws:kms , this header \nspeci\ufb01es the ID of the KMS key that was used to \nencrypt the object.\nType: String\nx-amz-server-side-encryptio \nn-bucket-key-enabledIf x-amz-server-side-encryption  has \na valid value of aws:kms , this header indicates \nwhether the object is encrypted with SSE-KMS by \nusing an S3 Bucket Key. If this header is set to true , \nthe object uses an S3 Bucket Key with SSE-KMS.\nType: Boolean\nx-amz-server-side-encryptio \nn-customer-algorithmIf SSE-C was requested, the response includes this \nheader, which con\ufb01rms the encryption algorithm \nthat was used.\nType: String\nValid Values: AES256\nRequests API Version 2006-03-01 2721Amazon Simple Storage Service API Reference\nName Description\nx-amz-server-side-encryptio \nn-customer-key-MD5If SSE-C was requested, the response includes this \nheader to verify round-trip message integrity of the \ncustomer-provided encryption key.\nType: String\nx-amz-version-id Version of the object.\nType: String\nResponse Elements\nName Description\nBucket The name of the bucket that the object was stored in.\nType: String\nAncestor: PostResponse\nETag The entity tag (ETag) is an MD5 hash of the object that you \ncan use to do conditional GET operations by using the If-\nModified  request tag with the GET request operation.\nETag re\ufb02ects changes only to the contents of an object, not \nto its metadata.\nType: String\nAncestor: PostResponse\nKey The object key name.\nType: String\nAncestor: PostResponse\nLocation The URI of the object.\nRequests API Version 2006-03-01 2722Amazon Simple Storage Service API Reference\nName Description\nType: String\nAncestor: PostResponse\nSpecial Errors\nThis implementation of the operation does not return special errors. For general information about \nAmazon S3 errors and a list of error codes, see Error Responses.\nExamples\nSample Request\nPOST /Neo HTTP/1.1\nContent-Length: 4\nHost: quotes.s3.amazonaws.com\nDate: Wed, 01 Mar  2006 12:00:00 GMT\nAuthorization: authorization string\nContent-Type: text/plain\nExpect: the 100-continue HTTP status code\nObjectContent\nSample Response with Versioning Suspended\nThe following is a sample response when bucket versioning is suspended:\nHTTP/1.1 100 Continue\nHTTP/1.1 200 OK\nx-amz-id-2: LriYPLdmOdAiIfgSm/F1YsViT1LW94/xUQxMsF7xiEb1a0wiIOIxl+zbwZ163pt7\nx-amz-request-id: 0A49CE4060975EAC\nx-amz-version-id: default\nDate: Wed, 12 Oct 2009 17:50:00 GMT\nETag: \"1b2cf535f27731c974343645a3985328\"\nContent-Length: 0\nConnection: close\nServer: AmazonS3\nIn this response, the version ID is null .\nExamples API Version 2006-03-01 2723Amazon Simple Storage Service API Reference\nSample Response with Versioning Enabled\nThe following is a sample response when bucket versioning is enabled.\nHTTP/1.1 100 Continue\nHTTP/1.1 200 OK\nx-amz-id-2: LriYPLdmOdAiIfgSm/F1YsViT1LW94/xUQxMsF7xiEb1a0wiIOIxl+zbwZ163pt7\nx-amz-request-id: 0A49CE4060975EAC\nx-amz-version-id: 43jfkodU8493jnFJD9fjj3HHNVfdsQUIFDNsidf038jfdsjGFDSIRp\nDate: Wed, 01 Mar  2006 12:00:00 GMT\nETag: \"828ef3fdfa96f00ad9f27c383fc9ac7f\"\nContent-Length: 0\nConnection: close\nServer: AmazonS3\nRelated Resources\n\u2022CopyObject\n\u2022POST Object\n\u2022GetObject\nRelated Resources API Version 2006-03-01 2724Amazon Simple Storage Service API Reference\nPOST Object restore\nDescription\nThis operation performs the following types of requests:\n\u2022select \u2013 Perform a select query on an archived object\n\u2022restore an archive  \u2013 Restore an archived object\nTo use this operation, you must have permissions to perform the s3:RestoreObject  and\ns3:GetObject  actions.", "The bucket owner has this permission by default and can grant this \npermission to others.", "For more information about permissions, see Permissions Related to Bucket \nSubresource Operations and Managing Access Permissions to Your Amazon S3 Resources in the\nAmazon Simple Storage Service User Guide.\nQuerying Archives with Select Requests\nYou use a select type of request to perform SQL queries on archived objects.", "The archived objects \nthat are being queried by the select request must be formatted as uncompressed comma-\nseparated values (CSV) \ufb01les.", "You can run queries and custom analytics on your archived data \nwithout having to restore your data to a hotter Amazon S3 tier.", "For an overview about select \nrequests, see Querying Archived Objects in the Amazon Simple Storage Service User Guide.\nWhen making a select request, do the following:\n\u2022De\ufb01ne an output location for the select query's output.", "This must be an Amazon S3 bucket in \nthe same AWS Region as the bucket that contains the archive object that is being queried. The \nAWS account that initiates the job must have permissions to write to the S3 bucket.", "You can \nspecify the storage class and encryption for the output objects stored in the bucket.", "For more \ninformation about output, see Querying Archived Objects in the Amazon Simple Storage Service \nUser Guide .\nFor more information about the S3 structure in the request body, see the following:\n\u2022PutObject\n\u2022Managing Access with ACLs in the Amazon Simple Storage Service User Guide\n\u2022Protecting Data Using Server-Side Encryption in the Amazon Simple Storage Service User Guide\nPOST Object restore API Version 2006-03-01 2725Amazon Simple Storage Service API Reference\n\u2022De\ufb01ne the SQL expression for the SELECT type of restoration for your query in the request \nbody's SelectParameters  structure.", "You can use expressions like the following examples.\n\u2022The following expression returns all records from the speci\ufb01ed object.\nSELECT * FROM Object\n\u2022Assuming that you are not using any headers for data stored in the object, you can specify \ncolumns with positional headers.\nSELECT s._1, s._2 FROM Object s WHERE s._3 > 100\n\u2022If you have headers and you set the fileHeaderInfo  in the CSV structure in the request \nbody to USE, you can specify headers in the query.", "(If you set the fileHeaderInfo  \ufb01eld to\nIGNORE, the \ufb01rst row is skipped for the query.) You cannot mix ordinal positions with header \ncolumn names.\nSELECT s.Id, s.FirstName, s.SSN FROM S3Object s\nFor more information about using SQL with S3 Glacier Select restore, see SQL Reference for \nAmazon S3 Select and S3 Glacier Select in the Amazon Simple Storage Service User Guide.\nWhen making a select request, you can also do the following:\n\u2022To expedite your queries, specify the Expedited  tier. For more information about tiers, see \n\"Restoring Archives,\" later in this topic.\n\u2022Specify details about the data serialization format of both the input object that is being queried \nand the serialization of the CSV-encoded query results.\nThe following are additional important facts about the select feature:\n\u2022The output results are new Amazon S3 objects. Unlike archive retrievals, they are stored until \nexplicitly deleted\u2014manually or through a lifecycle policy.\n\u2022You can issue more than one select request on the same Amazon S3 object. Amazon S3 doesn't \ndeduplicate requests, so avoid issuing duplicate requests.\n\u2022Amazon S3 accepts a select request even if the object has already been restored.", "A select request \ndoesn\u2019t return error response 409.\nQuerying Archives with Select Requests API Version 2006-03-01 2726Amazon Simple Storage Service API Reference\nRestoring Archives\nObjects in the GLACIER and DEEP_ARCHIVE storage classes are archived. To access an archived \nobject, you must \ufb01rst initiate a restore request. This restores a temporary copy of the archived \nobject. In a restore request, you specify the number of days that you want the restored copy to \nexist.", "After the speci\ufb01ed period, Amazon S3 deletes the temporary copy but the object remains \narchived in the GLACIER or DEEP_ARCHIVE storage class that object was restored from.\nTo restore a speci\ufb01c object version, you can provide a version ID. If you don't provide a version ID, \nAmazon S3 restores the current version.\nThe time it takes restore jobs to \ufb01nish depends on which storage class the object is being restored \nfrom and which data access tier you specify.\nWhen restoring an archived object (or using a select request), you can specify one of the following \ndata access tier options in the Tier element of the request body:\n\u2022Expedited  - Expedited retrievals allow you to quickly access your data stored in the GLACIER \nstorage class when occasional urgent requests for a subset of archives are required.", "For all but \nthe largest archived objects (250 MB+), data accessed using Expedited retrievals are typically \nmade available within 1\u20135 minutes. Provisioned capacity ensures that retrieval capacity for \nExpedited retrievals is available when you need it. Expedited retrievals and provisioned capacity \nare not available for the DEEP_ARCHIVE storage class.\n\u2022Standard  - Standard retrievals allow you to access any of your archived objects within several \nhours.", "This is the default option for the GLACIER and DEEP_ARCHIVE retrieval requests that do \nnot specify the retrieval option. Standard retrievals typically complete within 3-5 hours from the \nGLACIER storage class and typically complete within 12 hours from the DEEP_ARCHIVE storage \nclass.\n\u2022Bulk - Bulk retrievals are Amazon S3 Glacier\u2019s lowest-cost retrieval option, enabling you to \nretrieve large amounts, even petabytes, of data inexpensively in a day. Bulk retrievals typically \ncomplete within 5-12 hours from the GLACIER storage class and typically complete within 48 \nhours from the DEEP_ARCHIVE storage class.\nFor more information about archive retrieval options and provisioned capacity for Expedited  data \naccess, see Restoring Archived Objects in the Amazon Simple Storage Service User Guide.\nYou can use Amazon S3 restore speed upgrade to change the restore speed to a faster speed \nwhile it is in progress.", "You upgrade the speed of an in-progress restoration by issuing another \nRestoring Archives API Version 2006-03-01 2727Amazon Simple Storage Service API Reference\nrestore request to the same object, setting a new Tier request element. When issuing a request \nto upgrade the restore tier, you must choose a tier that is faster than the tier that the in-progress \nrestore is using.", "You must not change any other parameters, such as the Days request element.", "\nFor more information, see  Upgrading the Speed of an In-Progress Restore in the Amazon Simple \nStorage Service User Guide.\nTo get the status of object restoration, you can send a HEAD request.", "Operations return the x-amz-\nrestore header, which provides information about the restoration status, in the response.", "You can \nuse Amazon S3 event noti\ufb01cations to notify you when a restore is initiated or completed. For more \ninformation, see Con\ufb01guring Amazon S3 Event Noti\ufb01cations in the Amazon Simple Storage Service \nUser Guide .\nAfter restoring an archived object, you can update the restoration period by reissuing the request \nwith a new period. Amazon S3 updates the restoration period relative to the current time \nand charges only for the request\u2014there are no data transfer charges. You cannot update the \nrestoration period when Amazon S3 is actively processing your current restore request for the \nobject.\nIf your bucket has a lifecycle con\ufb01guration with a rule that includes an expiration action, the \nobject expiration overrides the life span that you specify in a restore request. For example, \nif you restore an object copy for 10 days, but the object is scheduled to expire in 3 days, \nAmazon S3 deletes the object in 3 days.", "For more information about lifecycle con\ufb01guration, see\nPutBucketLifecycleCon\ufb01guration and Object Lifecycle Management in Amazon Simple Storage \nService User Guide.\nRequests\nSyntax\nPOST /ObjectName ?restore&versionId= VersionID  HTTP/1.1\nHost: BucketName .s3.amazonaws.com\nDate: date\nAuthorization: authorization string  (see Authenticating Requests (AWS Signature Version \n  4))\nContent-MD5: MD5\n request body \n \nRequests API Version 2006-03-01 2728Amazon Simple Storage Service API Reference\nNote\nThe syntax shows some of the request headers.", "For a complete list, see \"Request Headers,\" \nlater in this topic.\nRequest Parameters\nThis implementation of the operation does not use request parameters.\nRequest Headers\nName Description Required\nContent-M \nD5The base64-encoded 128-bit MD5 digest of the data. You must \nuse this header as a  message integrity check to verify that the \nrequest body was not  corrupted in transit.", "For more informati \non, see RFC  1864.\nType: String\nDefault: NoneYes\nRequest Elements\nThe following is an XML example of a request body for restoring an archive.\n<RestoreRequest> \n   <Days>2</Days>  \n   <GlacierJobParameters> \n     <Tier>Bulk</Tier> \n   </GlacierJobParameters>  \n</RestoreRequest> \nThe following table explains the XML for archive restoration in the request body.\nRequests API Version 2006-03-01 2729Amazon Simple Storage Service API Reference\nName Description Required\nRestoreRe \nquestContainer for restore information.\nType: ContainerYes\nDays\nLifetime of the restored (active) copy.", "The minimum \nnumber of days that you can  restore an object from S3 \nGlacier is 1.", "After the object copy reaches  the speci\ufb01ed \nlifetime, Amazon S3 removes it from the bucket.", "If you  are \nrestoring an archive, this element is required.\nDo not use this element with a SELECT type of request.\nType: Positive integer\nAncestors: RestoreRequestYes, if \nrestoring an \narchive\nGlacierJo \nbParamete \nrsContainer for Glacier job parameters.\nDo not use this element with a SELECT type of request.\nType: Container\nAncestors: RestoreRequestNo\nTier\nThe data access tier to use when restoring the archive.\nStandard  is the  default.\nType: Enum\nValid values: Expedited  | Standard  |   Bulk\nAncestors: GlacierJobParametersNo\nThe following XML is the request body for a select query on an archived object:\nRequests API Version 2006-03-01 2730Amazon Simple Storage Service API Reference\n<RestoreRequest> \n    <Type>SELECT</Type> \n    <Tier>Expedited</Tier> \n    <Description>Job description</Description> \n    <SelectParameters> \n          <Expression>Select * from Object</Expression> \n          <ExpressionType>SQL</ExpressionType> \n          <InputSerialization> \n              <CSV> \n                  <FileHeaderInfo>IGNORE</FileHeaderInfo> \n                  <RecordDelimiter>\\n</RecordDelimiter> \n                  <FieldDelimiter>,</FieldDelimiter> \n                  <QuoteCharacter>\"</QuoteCharacter> \n                  <QuoteEscapeCharacter>\"</QuoteEscapeCharacter> \n                  <Comments>#</Comments> \n              </CSV> \n           </InputSerialization> \n         <OutputSerialization> \n             <CSV> \n                 <QuoteFields>ASNEEDED</QuoteFields> \n                 <RecordDelimiter>\\n</RecordDelimiter> \n                 <FieldDelimiter>,</FieldDelimiter> \n                 <QuoteCharacter>\"</QuoteCharacter> \n                 <QuoteEscapeCharacter>\"</QuoteEscapeCharacter> \n             </CSV>                                 \n         </OutputSerialization> \n    </SelectParameters> \n    <OutputLocation> \n        <S3> \n      <BucketName>Name of bucket</BucketName> \n            <Prefix>Key prefix</Prefix> \n       <CannedACL>Canned ACL string</CannedACL> \n       <AccessControlList> \n      <Grantee> \n          <Type>Grantee Type</Type> \n    <ID>Grantee identifier</ID> \n    <URI>Grantee URI</URI> \n         <Permission>Granted permission</Permission> \n                    <DisplayNmae>Display Name</DisplayName> \n                    <EmailAddress>email</EmailAddress> \n      </Grantee> \n       </AccessControlList> \n       <Encryption> \nRequests API Version 2006-03-01 2731Amazon Simple Storage Service API Reference\n             <EncryptionType>Encryption type</EncryptionType> \n       <KMSKeyId>KMS Key ID</KMSKeyId> \n       <KMSContext>Base64-encoded JSON<KMSContext> \n            </Encryption> \n      <UserMetadata> \n               <MetadataEntry> \n                   <Name>Key</Name> \n                   <Value>Value</Value> \n               </MetadataEntry> \n            </UserMetadata> \n            <Tagging> \n                <TagSet> \n                    <Tag> \n                        <Key>Tag name</Key> \n                        <Value>Tag value</Value> \n                    </Tag> \n               </TagSet> \n            </Tagging> \n            <StorageClass>Storage class</StorageClass> \n  </S3> \n    </OutputLocation>\n</RestoreRequest>\nThe following tables explain the XML for a SELECT type of restoration in the request body.\nName Description Required\nRestoreRe \nquestContainer for restore information.\nType: ContainerYes\nTier\nThe data access tier to use when restoring the archive.\nStandard  is the  default.\nType: Enum\nValid values: Expedited  | Standard  |   Bulk\nAncestors: RestoreRequestNo\nRequests API Version 2006-03-01 2732Amazon Simple Storage Service API Reference\nName Description Required\nDescripti \nonThe optional description for the request.\nType: String\nAncestors: RestoreRequestNo\nSelectPar \nametersDescribes the parameters for the select job request.\nType: Container\nAncestors: RestoreRequestYes, if request \ntype is SELECT\nOutputLoc \nationDescribes the location that receives the results of the select \nrestore request.\nType: Container for Amazon S3\nAncestors: RestoreRequestYes, if request \ntype is SELECT\nThe SelectParameters  container element contains the following elements.\nName Description Required\nExpression\nThe SQL expression. For example:\n\u2022\nThe following SQL expression retrieves the \ufb01rst column of \nthe data from the object  stored in CSV format:\nSELECT s._1 FROM Object s\n\u2022\nThe following SQL expression returns everything from \nthe object:\nSELECT * FROM ObjectYes\nRequests API Version 2006-03-01 2733Amazon Simple Storage Service API Reference\nName Description Required\nType: String\nAncestors: SelectParameters\nExpressio \nnTypeIdenti\ufb01es the expression type.\nType: String\nValid values: SQL\nAncestors: SelectParametersYes\nInputSeri \nalizationDescribes the serialization format of the object.\nType: Container for CSV\nAncestors: SelectParametersYes\nOutputSer \nializatio \nnDescribes how the results of the select job are serialized.\nType: Container for CSV\nAncestors: SelectParametersYes\nThe CSV container element in the InputSerialization  element contains the following \nelements.\nName Description Required\nRecordDel \nimiterA single character used to separate individual records in \nthe input. Instead of the  default value, you can specify an \narbitrary delimiter.\nType: String\nDefault: \\nNo\nRequests API Version 2006-03-01 2734Amazon Simple Storage Service API Reference\nName Description Required\nAncestors: CSV\nFieldDeli \nmiterA single character used to separate individual \ufb01elds in a \nrecord.", "You can specify an  arbitrary delimiter.\nType: String\nDefault: ,\nAncestors: CSVNo\nQuoteChar \nacterA single character used for escaping when the \ufb01eld \ndelimiter is part of the  value.\nConsider this example in a CSV \ufb01le:\n\"a, b\"\nWrapping the value in quotation marks makes this value \na single \ufb01eld. If you don't  use the quotation marks, the \ncomma is a \ufb01eld delimiter (which  makes it two separate \n\ufb01eld values, a and b).\n \nType: String\nDefault: \"\nAncestors: CSVNo\nRequests API Version 2006-03-01 2735Amazon Simple Storage Service API Reference\nName Description Required\nQuoteEsca \npeCharact \nerA single character used for escaping the quotation mark \ncharacter inside an already  escaped value. For example, the \nvalue \"\"\" a , b \"\"\"   is parsed as \" a , b \" .\nType: String\nDefault: \"\nAncestors: CSVNo\nFileHeade \nrInfoDescribes the \ufb01rst line in the input data.", "It is one of the \nENUM values.\n\u2022\nNONE: First line is not a header.\n\u2022\nIGNORE: First line is a header, but you can't use the \nheader values to  indicate the column in an expressio \nn. You can use column  position (such as _1, _2, \u2026) to \nindicate the column   (SELECT s._1 FROM OBJECT s ).\n\u2022\nUse: First line is a header, and you can use the header \nvalue to  identify a column in an expression (SELECT \n\"name\"   FROM OBJECT ).\nType: Enum\nValid values: NONE | USE | IGNORE\nAncestors: CSVNo\nRequests API Version 2006-03-01 2736Amazon Simple Storage Service API Reference\nName Description Required\nComments\nA single character used to indicate that a row should be  \n ignored when the character is present at the start of that \nrow. You can specify any character to indicate a comment \nline.\nType: String\nAncestors: CSVNo\nThe CSV container element (in the OutputSerialization  elements) contains the following \nelements.\nName Description Required\nQuoteFiel \ndsIndicates whether to use quotation marks around output \n\ufb01elds.\n\u2022\nALWAYS: Always use quotation marks for output \ufb01elds.\n\u2022\nASNEEDED : Use quotation marks for output \ufb01elds when \nneeded.\nType: Enum\nValid values: ALWAYS | ASNEEDED\nDefault: AsNeeded\nAncestors: CSVNo\nRecordDel \nimiterA single character used to separate individual records in the \noutput. Instead of the  default value, you can specify an \narbitrary delimiter.No\nRequests API Version 2006-03-01 2737Amazon Simple Storage Service API Reference\nName Description Required\nType: String\nDefault: \\n\nAncestors: CSV\nFieldDeli \nmiterA single character used to separate individual \ufb01elds in a \nrecord.", "You can specify an  arbitrary delimiter.\nType: String\nDefault: ,\nAncestors: CSVNo\nQuoteChar \nacterA single character used for escaping when the \ufb01eld \ndelimiter is part of the value. For example, if the value is a, \nb, Amazon S3 wraps this  \ufb01eld value in quotation marks, as \nfollows: \" a , b  \" .\nType: String\nDefault: \"\nAncestors: CSVNo\nQuoteEsca \npeCharact \nerA single character used for escaping the quotation mark \ncharacter inside an already  escaped value. For example, if \nthe value is \" a , b  \" , Amazon S3 wraps the value in \nquotation marks, as  follows: \"\"\" a , b \"\"\" .\nType: String\nAncestors: CSVNo\nRequests API Version 2006-03-01 2738Amazon Simple Storage Service API Reference\nThe S3 container element (in the OutputLocation  element) contains the following elements.\nName Description Required\nAccessCon \ntrolListA list of grants that control access to the staged results.\nType: Container for Grant\nAncestors: S3No\nBucketName\nThe name of the S3 bucket where the select restore results \nare stored. The bucket must  be in the same AWS Region as \nthe bucket that contains the input  archive object.\nType: String\n \nAncestors: S3Yes\nCannedACL\nThe canned access control list (ACL) to apply to the select \nrestore results.\nType: String\nValid values:  private | public-read | public-\nread-write | aws-exec-read |  authenti \ncated-read | bucket-owner-read | bucket-ow \nner-full-control\nAncestors: S3No\nEncryption\nContains encryption information for the stored results.\nType: Container for Encryption\nAncestors: S3No\nPrefix Yes\nRequests API Version 2006-03-01 2739Amazon Simple Storage Service API Reference\nName Description Required\nThe pre\ufb01x that is prepended to the select restore results. \nThe maximum length for the  pre\ufb01x is 512 bytes.\nType: String\nAncestors: S3\nStorageCl \nassThe class of storage used to store the select request  results.\nType: String\nValid values: STANDARD  | REDUCED_REDUNDANCY  |\nSTANDARD_IA  | ONEZONE_IA  \nAncestors: S3No\nTagging\nContainer for tag information.\nType: Tag structure\nAncestors: S3No\nUserMetad \nataContains a list of metadata to store with the select restore \nresults.\nType: MetadataEntry structure\nAncestors: S3No\nThe Grantee container element (in the AccessControlList  element) contains the following \nelements.\nName Description Required\nDisplayNa \nmeThe screen name of the grantee.No\nRequests API Version 2006-03-01 2740Amazon Simple Storage Service API Reference\nName Description Required\nType: String\nAncestors: Grantee\nEmailAddr \nessThe email address of the grantee.\nType: String\nAncestors: GranteeNo\nID\nThe canonical user ID of the grantee.\nType: String\nAncestors: GranteeNo\nType\nThe type of the grantee.\nType: String\nAncestors: GranteeNo\nURI\nThe URI of the grantee group.\nType: String\nAncestors: GranteeNo\nPermission\nGranted permission.\nType: String\nAncestors: GranteeNo\nRequests API Version 2006-03-01 2741Amazon Simple Storage Service API Reference\nThe Encryption  container element (in S3) contains the following elements.\nName Description Required\nEncryptio \nnTypeThe server-side encryption algorithm used when storing job \nresults.", "The default is no encryption.\nType: String\nValid Values aws:kms | AES256\nAncestors: Encryption  No\nKMSContext\nOptional. If the encryption type is aws:kms, you can use \nthis value to  specify the encryption context for the select \nrestore  results.\nType: String\nAncestors: EncryptionNo\nKMSKeyId\nThe AWS Key Management Service (AWS KMS) key ID to use \nfor object encryption.\nType: String\nAncestors: Encryption  No\nThe TagSet container element (in the Tagging element) contains the following element.\nName Description Required\nTag\nContains tags.\nType: Container\nAncestors: TagSet  No\nRequests API Version 2006-03-01 2742Amazon Simple Storage Service API Reference\nThe Tag container element (in the TagSet element) contains the following elements.\nName Description Required\nKey\nName of the tag.\nType: String\nAncestors: TagNo\nValue\nValue of the tag.\nType: String\nAncestors: TagNo\nThe MetadataEntry  container element (in the UserMetadata  element) contains the following \nkey-value pair elements to store with an object.\nName Description Required\nMetadataK \neyThe metadata key.\nType: String\nAncestors:No\nMetadataE \nntryThe metadata value.\nType: String\nAncestors:No\nResponses\nA successful operation returns either the 200 OK  or 202 Accepted  status code.\nResponses API Version 2006-03-01 2743Amazon Simple Storage Service API Reference\n\u2022If the object copy is not previously restored, then Amazon S3 returns 202 Accepted  in the \nresponse.\n\u2022If the object copy is previously restored, Amazon S3 returns 200 OK in the response.\nResponse Headers\nThis implementation of the operation uses only response headers that are common to most \nresponses.", "For more information, see Common Response Headers.\nResponse Elements\nThis operation does not return response elements.\nSpecial Errors\nError Code Description HTTP \nStatus CodeSOAP Fault \nCode Pre\ufb01x\nRestoreAlreadyInPr \nogressObject restore is already in \nprogress.", "(This error does not \napply to SELECT type  requests.)409 Con\ufb02ictClient\nGlacierExpeditedRe \ntrievalNotAvailabl \neGlacier expedited retrievals \nare currently not available.", "Try \nagain later. (Returned if there is \ninsu\ufb03cient capacity to process \nthe   Expedited  request. This \nerror applies only to   Expedited\n retrievals and not to   Standard\nor Bulk retrievals.)503 N/A\nExamples\nRestore an Object for Two Days Using the Expedited Retrieval Option\nThe following restore request restores a copy of the photo1.jpg  object from S3 Glacier for a \nperiod of two days using the expedited retrieval option.\nExamples API Version 2006-03-01 2744Amazon Simple Storage Service API Reference\nPOST /photo1.jpg?restore HTTP/1.1\nHost: examplebucket.s3.amazonaws.com\nDate: Mon, 22 Oct 2012 01:49:52 GMT\nAuthorization: authorization string\nContent-Length: content length\n<RestoreRequest> \n  <Days>2</Days> \n  <GlacierJobParameters> \n    <Tier>Expedited</Tier> \n  </GlacierJobParameters>\n</RestoreRequest>\nIf the examplebucket  does not have a restored copy of the object, Amazon S3 returns the \nfollowing 202 Accepted  response.\nHTTP/1.1 202 Accepted\nx-amz-id-2: GFihv3y6+kE7KG11GEkQhU7/2/cHR3Yb2fCb2S04nxI423Dqwg2XiQ0B/\nUZlzYQvPiBlZNRcovw=\nx-amz-request-id: 9F341CD3C4BA79E0\nDate: Sat, 20 Oct 2012 23:54:05 GMT\nContent-Length: 0\nServer: AmazonS3\nIf a copy of the object is already restored, Amazon S3 returns a 200 OK response, and updates only \nthe restored copy's expiry time.\nQuery an Archive with a SELECT Request\nThe following is an example select restore request.\nPOST /object-one.csv?restore HTTP/1.1\nHost: examplebucket.s3.amazonaws.com\nDate: Date: Sat, 20 Oct 2012 23:54:05 GMT\nAuthorization: authorization string\nContent-Length: content length\n<RestoreRequest xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n  <Type>SELECT</Type> \n  <Tier>Expedited</Tier> \n  <Description>this is a description</Description> \n  <SelectParameters> \nExamples API Version 2006-03-01 2745Amazon Simple Storage Service API Reference\n    <InputSerialization> \n      <CSV> \n        <FileHeaderInfo>IGNORE</FileHeaderInfo> \n        <Comments>#</Comments> \n        <QuoteEscapeCharacter>\"</QuoteEscapeCharacter> \n        <RecordDelimiter>\\n</RecordDelimiter> \n        <FieldDelimiter>,</FieldDelimiter> \n        <QuoteCharacter>\"</QuoteCharacter> \n      </CSV> \n    </InputSerialization> \n    <ExpressionType>SQL</ExpressionType> \n    <Expression>select * from object</Expression> \n    <OutputSerialization> \n      <CSV> \n        <QuoteFields>ALWAYS</QuoteFields> \n        <QuoteEscapeCharacter>\"</QuoteEscapeCharacter> \n        <RecordDelimiter>\\n</RecordDelimiter> \n        <FieldDelimiter>\\t</FieldDelimiter> \n        <QuoteCharacter>\\'</QuoteCharacter> \n      </CSV> \n    </OutputSerialization> \n  </SelectParameters> \n  <OutputLocation> \n    <S3> \n      <BucketName>example-output-bucket</BucketName> \n      <Prefix>test-s3</Prefix> \n      <AccessControlList> \n        <Grant> \n          <Grantee xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" \n xsi:type=\"AmazonCustomerByEmail\"> \n            <EmailAddress>jane-doe@example.com</EmailAddress> \n          </Grantee> \n          <Permission>FULL_CONTROL</Permission> \n        </Grant> \n      </AccessControlList> \n      <UserMetadata> \n        <MetadataEntry> \n          <Name>test</Name> \n          <Value>test-value</Value> \n        </MetadataEntry> \n        <MetadataEntry> \n          <Name>other</Name> \n          <Value>something else</Value> \n        </MetadataEntry> \nExamples API Version 2006-03-01 2746Amazon Simple Storage Service API Reference\n      </UserMetadata> \n      <StorageClass>STANDARD</StorageClass> \n    </S3> \n  </OutputLocation>\n</RestoreRequest>\nAmazon S3 returns the following 202 Accepted  response.\nHTTP/1.1 202 Accepted\nx-amz-id-2: GFihv3y6+kE7KG11GEkQhU7/2/cHR3Yb2fCb2S04nxI423Dqwg2XiQ0B/\nUZlzYQvPiBlZNRcovw=\nx-amz-request-id: 9F341CD3C4BA79E0\nx-amz-restore-output-path: js-test-s3/qE8nk5M0XIj-LuZE2HXNw6empQm3znLkHlMWInRYPS-\nOrl2W0uj6LyYm-neTvm1-btz3wbBxfMhPykd3jkl-lvZE7w42/\nDate: Sat, 20 Oct 2012 23:54:05 GMT\nContent-Length: 0\nServer: AmazonS3\nMore Info\n\u2022GetBucketLifecycleCon\ufb01guration\n\u2022PutBucketLifecycleCon\ufb01guration\n\u2022SQL Reference for Amazon S3 Select and S3 Glacier Select  in the Amazon Simple Storage Service \nUser Guide\nBrowser-Based Uploads Using HTTP POST\nAmazon S3 supports HTTP POST requests so that users can upload content directly to Amazon S3.", "\nBy using POST, end users can authenticate requests without having to pass data through a secure \nintermediary node that protects your credentials.", "Thus, HTTP POST has the potential to reduce \nlatency.\nThe following \ufb01gure shows an Amazon S3 upload using a POST request.\nMore Info API Version 2006-03-01 2747Amazon Simple Storage Service API Reference\n1.The user accesses your page from a web browser.\n2.Your webpage contains an HTML form that contains all the information necessary for the user to \nupload content to Amazon S3.\n3.The user uploads content to Amazon S3 through the web browser.\nThe process for sending browser-based POST requests is as follows:\n1.Create a security policy specifying conditions that restrict what you want to allow in the request, \nsuch as the bucket name where objects can be uploaded, and key name pre\ufb01xes that you want \nto allow for the object that is being created.\nBrowser-Based Uploads Using HTTP POST API Version 2006-03-01 2748Amazon Simple Storage Service API Reference\n2.Create a signature that is based on the policy. For authenticated requests, the form must include \na valid signature and the policy.\n3.Create an HTML form that your users can access in order to upload objects to your Amazon S3 \nbucket.\nThe following section describes how to create a signature to authenticate a request.", "For \ninformation about creating forms and security policies, see Creating an HTML Form (Using AWS \nSignature Version 4).\nCalculating a Signature\nFor authenticated requests, the HTML form must include \ufb01elds for a security policy and a signature.\n\u2022A security policy (see POST Policy) controls what is allowed in the request.\n\u2022The security policy is the StringToSign  (see Introduction to Signing Requests) in your \nsignature calculation.\nCalculating a Signature API Version 2006-03-01 2749Amazon Simple Storage Service API Reference\nTo Calculate a signature\n1.", "Create a policy using UTF-8 encoding.\n2. Convert the UTF-8-encoded policy bytes to base64.", "The result is the StringToSign .\n3.", "Create a signing key.\n4.", "Use the signing key to sign the StringToSign  using HMAC-SHA256 signing algorithm.\nFor more information about creating HTML forms, security policies, and an example, see the \nfollowing:\n\u2022Creating an HTML Form (Using AWS Signature Version 4)\n\u2022POST Policy\n\u2022Example: Browser-Based Upload using HTTP POST (Using AWS Signature Version 4)\nCreating an HTML Form (Using AWS Signature Version 4)\nTopics\n\u2022HTML Form Declaration\n\u2022HTML Form Fields\nTo allow users to upload content to Amazon S3 by using their browsers (HTTP POST requests), you \nuse HTML forms.", "HTML forms consist of a form declaration and form \ufb01elds. The form declaration \ncontains high-level information about the request. The form \ufb01elds contain detailed request \ninformation.\nThis section describes how to create HTML forms.", "For a working example of browser-based upload \nusing HTTP POST and related signature calculations for request authentication, see Example: \nBrowser-Based Upload using HTTP POST (Using AWS Signature Version 4).\nThe form and policy must be UTF-8 encoded.", "You can apply UTF-8 encoding to the form by \nspecifying charset=UTF-8  in the content attribute. The following is an example of UTF-8 \nencoding in the HTML heading.\n<html> \nCreating HTML Forms API Version 2006-03-01 2750Amazon Simple Storage Service API Reference\n  <head> \n    ... \n    <meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\" /> \n    ... \n  </head> \n  <body>\nFollowing is an example of UTF-8 encoding in a request header.\nContent-Type: text/html; charset=UTF-8\nNote\nThe form data and boundaries (excluding the contents of the \ufb01le) cannot exceed 20KB.\nHTML Form Declaration\nThe HTML form declaration has the following three attributes:\n\u2022action \u2013 The URL that processes the request, which must be set to the URL of the \nbucket.", "For example, if the name of your bucket is examplebucket , the URL is http://\nexamplebucket.s3.amazonaws.com/ .\nNote\nThe key name is speci\ufb01ed in a form \ufb01eld.\n\u2022method \u2013 The method must be POST.\n\u2022enctype \u2013 The enclosure type (enctype) must be set to multipart/form-data for both \ufb01le \nuploads and text area uploads. For more information about enctype , see RFC 1867.\nThis is a form declaration for the bucket examplebucket .\n<form action=\"http://examplebucket.s3.amazonaws.com/\" method=\"post\"\nenctype=\"multipart/form-data\">\nHTML Form Declaration API Version 2006-03-01 2751Amazon Simple Storage Service API Reference\nHTML Form Fields\nThe following table describes a list of \ufb01elds that you can use within a form.", "Among other \ufb01elds, \nthere is a signature \ufb01eld that you can use to authenticate requests. There are \ufb01elds for you to \nspecify the signature calculation algorithm (x-amz-algorithm ), the credential scope (x-amz-\ncredential ) that you used to generate the signing key, and the date (x-amz-date ) used \nto calculate the signature.", "Amazon S3 uses this information to re-create the signature. If the \nsignatures match, Amazon S3 processes the request.\nNote\nThe variable ${filename}  is automatically replaced with the name of the \ufb01le provided \nby the user and is recognized by all form \ufb01elds.", "If the browser or client provides a full or \npartial path to the \ufb01le, only the text following the last slash (/) or backslash (\\) is used (for \nexample, C:\\Program Files\\directory1\\file.txt  is interpreted as file.txt ).", "If no \n\ufb01le or \ufb01le name is provided, the variable is replaced with an empty string.\nIf you don't provide elements required for authenticated requests, such as the policy  element, \nthe request is assumed to be anonymous and will succeed only if you have con\ufb01gured the bucket \nfor public read and write.\nElement Name Description Required\nacl\nAn Amazon S3 access control list (ACL). If an \ninvalid ACL is speci\ufb01ed, Amazon S3 denies \nthe  request. For more information about \nACLs, see Using Amazon S3  ACLs.\nType: String\nDefault: private\nValid Values: private | public-re \nad | public-read-write | aws-\nexec-read | authenticated-read No\nHTML Form Fields API Version 2006-03-01 2752Amazon Simple Storage Service API Reference\nElement Name Description Required\n| bucket-owner-read | bucket-ow \nner-full-control\nCache-Control  \nContent-Type\nContent-Disposition\nContent-Encoding\nExpiresREST-speci\ufb01c headers.", "For more information, \nsee PutObject.No\nkey\nThe key name of the uploaded object.\nTo use the \ufb01le name provided by the user, \nuse the ${\ufb01lename}  variable.", "For example, \nif you upload a \ufb01le   photo1.jpg  and you \nspecify   /user/user1/${filename}  as \nkey name, the \ufb01le  is stored as /user/use \nr1/photo1.jpg .\nFor more information, see Object Key and  \n Metadata  in the   Amazon Simple Storage \nService User Guide.Yes\npolicy\nThe base64-encoded security policy that \ndescribes what is permitted in the request. \n For authenticated requests, a policy is \nrequired.\nRequests without a security policy are \nconsidered anonymous  and will succeed only \non a publicly writable bucket.Required for \nauthentic \nated requests\nHTML Form Fields API Version 2006-03-01 2753Amazon Simple Storage Service API Reference\nElement Name Description Required\nsuccess_action_red \nirectThe URL to which the client is redirected \nupon successful  upload.\nIf success_action_redirect  is not \nspeci\ufb01ed, or  Amazon S3 cannot interpret \nthe URL, Amazon S3 returns the empty \ndocument  type that is speci\ufb01ed in the\nsuccess_action_status   \ufb01eld.\nIf the upload fails, Amazon S3 returns an \nerror and does not  redirect the user to \nanother URL.No\nHTML Form Fields API Version 2006-03-01 2754Amazon Simple Storage Service API Reference\nElement Name Description Required\nsuccess_action_status\nThe status code returned to the client \nupon successful upload  if success_a \nction_redirect  is not speci\ufb01ed.\nValid values are 200, 201, or   204 (default).\nIf the value is set to 200 or 204, Amazon \nS3 returns an empty  document with the \nspeci\ufb01ed status code.\nIf the value is set to 201, Amazon S3 returns \nan XML document with  a 201 status code. \nFor information about the content of the \nXML  document, see POST Object.\nIf the value is not set or is invalid, Amazon \nS3 returns an empty  document with a 204 \nstatus code.\nNote\nSome versions of the Adobe Flash \nplayer do not properly   handle HTTP \nresponses with an empty body.", "To \nsupport uploads  through Adobe \nFlash, we recommend setting   \n  success_action_status  to \n201.No\nHTML Form Fields API Version 2006-03-01 2755Amazon Simple Storage Service API Reference\nElement Name Description Required\nx-amz-algorithm\nThe signing algorithm used to authenticate \nthe request.", "For  AWS Signature Version 4, \nthe value is   AWS4-HMAC-SHA256 .\nThis \ufb01eld is required if a policy document is \nincluded with  the request.Required for \nauthentic \nated requests\nx-amz-credential In addition to your access key ID, this \ufb01eld \nalso  provides scope information identifying \nregion and service for  which the signature \nis valid.", "This should be the same scope \nyou  used in calculating the signing key for \nsignature calculation.", "\nIt is a string of the following  form:\n<your-access-key-i \nd>/<date>/<aws-region> /<aws-serv \nice>/aws4_request  \nFor example:\n   AKIAIOSFODNN7EXAMPLE/201307 \n28/us-east-1/s3/aws4_request    \nFor Amazon S3, the aws-service string is  \n  s3. For a list of Amazon S3 aws-region  \nstrings, see Regions and  Endpoints in the\nAWS General Reference.", "This is required if a \npolicy document is included with the  reques \nt.Required for \nauthentic \nated requests\nHTML Form Fields API Version 2006-03-01 2756Amazon Simple Storage Service API Reference\nElement Name Description Required\nx-amz-date\nIt is the date value in ISO8601 format.", "For \nexample,    20130728T000000Z .\nIt is the same date you used in creating the \nsigning key (for  example, 20130728). This \nmust also be the same value you provide  in \nthe policy (x-amz-date ) that you signed.\nThis is required if a policy document is \nincluded with the  request.Required for \nauthentic \nated requests\nx-amz-security-token\nA security token used by Amazon DevPay and \nsession credentials\nIf the request is using Amazon DevPay, it \nrequires two   x-amz-security-token\nform \ufb01elds: one for the  product token and \none for the user token. For more informati \non,  see Using  DevPay in the   Amazon Simple \nStorage Service User Guide.\nIf the request is using session credentials, it \nrequires one   x-amz-security-token\nform. For more  information, see Requestin \ng Temporary Security Credentials in the   IAM \nUser Guide .No\nx-amz-signature\n(AWS Signature Version 4) The HMAC-SHA2 \n56 hash of the security  policy.\nThis \ufb01eld is required if a policy document is \nincluded with  the request.Required for \nauthentic \nated requests\nHTML Form Fields API Version 2006-03-01 2757Amazon Simple Storage Service API Reference\nElement Name Description Required\nx-amz-meta-*\nField names starting with this pre\ufb01x are user-\nde\ufb01ned  metadata.", "Each one is stored and \nreturned as a set of key-value  pairs.", "Amazon \nS3 doesn't validate or interpret user-de\ufb01 \nned metadata.", "For more information, see\nPutObject.No\nx-amz-*\nSee POST Object (POST Object for other   x-\namz-*  headers.No\nfile\nFile or text content.\nThe \ufb01le or content must be the last \ufb01eld in \nthe form.\nYou cannot upload more than one \ufb01le at a \ntime.Yes\nConditional items are required for authenticated requests and are optional for anonymous \nrequests.\nNow that you know how to create forms, next you can create a security policy that you can sign. \nFor more information, see POST Policy.\nPOST Policy\nTopics\n\u2022Expiration\n\u2022Condition Matching\n\u2022Conditions\n\u2022Character Escaping\nPOST Policy API Version 2006-03-01 2758Amazon Simple Storage Service API Reference\nThe policy required for making authenticated requests using HTTP POST is a UTF-8 and base64-\nencoded document written in JavaScript Object Notation (JSON) that speci\ufb01es conditions that \nthe request must meet.", "Depending on how you design your policy document, you can control the \naccess granularity per-upload, per-user, for all uploads, or according to other designs that meet \nyour needs.\nThis section describes the POST policy. For example signature calculations using POST policy, see\nExample: Browser-Based Upload using HTTP POST (Using AWS Signature Version 4).\nNote\nAlthough the policy document is optional, we highly recommend that you use one in order \nto control what is allowed in the request. If you make the bucket publicly writable, you have \nno control at all over which users can write to your bucket.\nThe following is an example of a POST policy document.\n{ \"expiration\": \"2007-12-01T12:00:00.000Z\", \n  \"conditions\": [ \n    {\"acl\": \"public-read\" }, \n    {\"bucket\": \"johnsmith\" }, \n    [\"starts-with\", \"$key\", \"user/eric/\"], \n  ]\n}\nThe POST policy always contains the expiration  and conditions  elements.", "The example policy \nuses two condition matching types (exact matching and starts-with matching).", "The following \nsections describe these elements.\nExpiration\nThe expiration  element speci\ufb01es the expiration date and time of the POST policy in ISO8601 \nGMT date format. For example, 2013-08-01T12:00:00.000Z  speci\ufb01es that the POST policy is \nnot valid after midnight GMT on August 1, 2013.\nCondition Matching\nFollowing is a table that describes condition matching types that you can use to specify POST \npolicy conditions (described in the next section).", "Although you must specify at least one condition \nExpiration API Version 2006-03-01 2759Amazon Simple Storage Service API Reference\nfor each form \ufb01eld that you specify in the form, you can create more complex matching criteria by \nspecifying multiple conditions for a form \ufb01eld.\nCondition \nMatch TypeDescription\nExact Matches The form \ufb01eld value must match the value speci\ufb01ed.", "This  example indicates \nthat the ACL must be set to  public-read:\n{\"acl\": \"public-read\" }\nThis example is an alternate way to indicate that the ACL must  be set to \npublic-read:\n[ \"eq\", \"$acl\", \"public-read\" ]\nStarts With The value must start with the speci\ufb01ed value.", "This example  indicates that the \nobject key must start with user/user1:\n[\"starts-with\", \"$key\", \"user/user1/\"]\nMatching \nContent-Types \nin a Comma-\nSeparated ListContent-Types values for a starts-with  condition that include commas \nare interpreted as lists.", "Each value in the list must meet the condition for the \nwhole condition to pass.", "For example,given the following condition:\n[\"starts-with\", \"$Content-Type\", \"image/\"]\nThe following value would pass the condition:\n\"image/jpg,image/png,image/gif\"\nThe following value would not pass the condition:\n[\"image/jpg,text/plain\"]\nCondition Matching API Version 2006-03-01 2760Amazon Simple Storage Service API Reference\nCondition \nMatch TypeDescription\nNote\nData elements other than Content-Type  are treated as strings, \nregardless of the presence of commas.\nMatching Any \nContentTo con\ufb01gure the POST policy to allow any content within a  form \ufb01eld, use\nstarts-with  with an empty value  (\"\"). This example allows any value for  \n  success_action_redirect :\n[\"starts-with\", \"$success_action_redirect\", \"\"]\nSpecifying \nRangesFor form \ufb01elds that accept a range, separate the upper and  lower limit with a \ncomma.", "This example allows a \ufb01le size from 1  to 10 MiB:\n[\"content-length-range\", 1048576, 10485760]\nThe speci\ufb01c conditions supported in a POST policy are described in Conditions .\nConditions\nThe conditions  in a POST policy is an array of objects, each of which is used to validate the \nrequest. You can use these conditions to restrict what is allowed in the request. For example, the \npreceding policy conditions require the following:\n\u2022Request must specify the johnsmith  bucket name.\n\u2022Object key name must have the user/eric  pre\ufb01x.\n\u2022Object ACL must be set to public-read .\nEach form \ufb01eld that you specify in a form (except x-amz-signature , file , policy , and \ufb01eld \nnames that have an x-ignore-  pre\ufb01x) must appear in the list of conditions.\nConditions API Version 2006-03-01 2761Amazon Simple Storage Service API Reference\nNote\nAll variables within the form are expanded prior to validating the POST policy.", "Therefore, \nall condition matching should be against the expanded form \ufb01elds.", "Suppose that you want \nto restrict your object key name to a speci\ufb01c pre\ufb01x (user/user1 ). In this case, you set the \nkey form \ufb01eld to user/user1/${filename} . Your POST policy should be [ \"starts-\nwith\", \"$key\", \"user/user1/\" ]  (do not enter [ \"starts-with\", \"$key\", \n\"user/user1/${filename}\" ] ).", "For more information, see Condition Matching .\nPolicy document conditions are described in the following table.\nElement Name Description\nacl\nSpeci\ufb01es the ACL value that must be used in the form  \n submission.\nThis condition supports exact matching and   starts-\nwith condition match type discussed in  the following \nsection.\nbucket\nSpeci\ufb01es the acceptable bucket name.\nThis condition supports exact matching condition match  \n type.\ncontent-length-range\nThe minimum and maximum allowable size for the \nuploaded  content.\nThis condition supports content-length-range  \n condition match type.\nCache-Control  \nContent-Type\nContent-DispositionREST-speci\ufb01c headers. For more information, see POST \nObject.\nConditions API Version 2006-03-01 2762Amazon Simple Storage Service API Reference\nElement Name Description\nContent-Encoding\nExpiresThis condition supports exact matching and   starts-wi \nth condition match type.\nkey\nThe acceptable key name or a pre\ufb01x of the uploaded   \nobject.\nThis condition supports exact matching and   starts-wi \nth condition match type.\nsuccess_action_redirect  \nredirectThe URL to which the client is redirected upon successful  \n upload.\nThis condition supports exact matching and   starts-wi \nth condition match type.\nsuccess_action_status\nThe status code returned to the client upon successful \nupload  if success_action_redirect  is not speci\ufb01ed.\nThis condition supports exact matching.\nx-amz-algorithm\nThe signing algorithm that must be used during signature \n  calculation. For AWS Signature Version 4, the value is  \n  AWS4-HMAC-SHA256 .\nThis condition supports exact matching.\nConditions API Version 2006-03-01 2763Amazon Simple Storage Service API Reference\nElement Name Description\nx-amz-credential\nThe credentials that you used to calculate the signature.", "\nIt  provides access key ID and scope information identifyi \nng region  and service for which the signature is valid.", "\nThis should be the  same scope you used in calculating the \nsigning key for signature  calculation.\nIt is a string of the following form:\n<your-access-key-id> /<date>/<aws-regi \non>/<aws-service> /aws4_request\nFor example:\n AKIAIOSFODNN7EXAMPLE/20130728/us-e \nast-1/s3/aws4_request\nFor Amazon S3, the aws-service string is s3.", "For a  list of \nAmazon S3 aws-region  strings, see Regions and  Endp \noints  in the AWS General Reference.", "This is required if a \nPOST policy document is included with the  request.\nThis condition supports exact matching.\nx-amz-date\nThe date value speci\ufb01ed in the ISO8601 formatted string.", "\nFor  example, 20130728T000000Z .", "The date must \nbe same  that you used in creating the signing key for \nsignature  calculation.\nThis is required if a POST policy document is included with  \n the request.\nThis condition supports exact matching.\nConditions API Version 2006-03-01 2764Amazon Simple Storage Service API Reference\nElement Name Description\nx-amz-security-token\nAmazon DevPay security token.\nEach request that uses Amazon DevPay requires two  \n  x-amz-security-token  form \ufb01elds: one for the  \n product token and one for the user token.", "As a result, the  \n values must be separated by commas.", "For example, if the \nuser  token is eW91dHViZQ==  and the product token is  \n  b0hnNVNKWVJIQTA= , you set the POST policy entry  to:\n{ \"x-amz-security-token\":  \"eW91dHViZQ \n==,b0hnNVNKWVJIQTA=\" } .\nFor more information about Amazon DevPay, see Using \nDevPay in  the Amazon Simple Storage Service User Guide.\nx-amz-meta-*\nUser-speci\ufb01ed metadata.\nThis condition supports exact matching and   starts-wi \nth condition match type.\nx-amz-*\nSee POST Object (POST Object for other   x-amz-*\nheaders.\nThis condition supports exact matching.\nNote\nIf your toolkit adds more form \ufb01elds (for example, Flash adds filename ), you must add \nthem to the POST policy document.", "If you can control this functionality, pre\ufb01x x-ignore-\nto the \ufb01eld so Amazon S3 ignores the feature and it won't a\ufb00ect future versions of this \nfeature.\nConditions API Version 2006-03-01 2765Amazon Simple Storage Service API Reference\nCharacter Escaping\nCharacters that must be escaped within a POST policy document are described in the following \ntable.\nEscape \nSequenceDescription\n\\\\ Backslash\n\\$ Dollar symbol\n\\b Backspace\n\\f Form feed\n\\n New line\n\\r Carriage return\n\\t Horizontal tab\n\\v Vertical tab\n\\uxxxx All Unicode characters\nNow that you are acquainted with forms and policies, and understand how signing works, you can \ntry a POST upload example.", "You need to write the code to calculate the signature. The example \nprovides a sample form, and a POST policy that you can use to test your signature calculations.", "For \nmore information, see Example: Browser-Based Upload using HTTP POST (Using AWS Signature \nVersion 4).\nCharacter Escaping API Version 2006-03-01 2766Amazon Simple Storage Service API Reference\nExample: Browser-Based Upload using HTTP POST (Using AWS \nSignature Version 4)\nThis section shows an example of using an HTTP POST request to upload content directly to \nAmazon S3.\nFor more information on Signature Version 4, see Signature Version 4 Signing Process.\nUploading a File to Amazon S3 Using HTTP POST\nThis example provides a sample POST policy and a form that you can use to upload a \ufb01le.", "The topic \nuses the example policy and \ufb01ctitious credentials to show you the work\ufb02ow and resulting signature \nand policy hash.", "You can use this data as test suite to verify your signature calculation code.\nThe example uses the following example credentials the signature calculations. You can use these \ncredentials to verify your signature calculation code.", "However, you must then replace these with \nyour own credentials when sending requests to AWS.\nParameter Value\nAWSAccessKeyId AKIAIOSFODNN7EXAMPLE\nAWSSecret \nAccessKeywJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\nSample Policy and Form\nThe following POST policy supports uploads to Amazon S3 with speci\ufb01c conditions.\n{ \"expiration\": \"2015-12-30T12:00:00.000Z\", \n  \"conditions\": [ \n    {\"bucket\": \"sigv4examplebucket\"}, \n    [\"starts-with\", \"$key\", \"user/user1/\"], \n    {\"acl\": \"public-read\"}, \n    {\"success_action_redirect\": \"http://sigv4examplebucket.s3.amazonaws.com/\nsuccessful_upload.html\"}, \n    [\"starts-with\", \"$Content-Type\", \"image/\"], \n    {\"x-amz-meta-uuid\": \"14365123651274\"}, \nPOST Upload Example API Version 2006-03-01 2767Amazon Simple Storage Service API Reference\n    {\"x-amz-server-side-encryption\": \"AES256\"}, \n    [\"starts-with\", \"$x-amz-meta-tag\", \"\"], \n    {\"x-amz-credential\": \"AKIAIOSFODNN7EXAMPLE/20151229/us-east-1/s3/aws4_request\"}, \n    {\"x-amz-algorithm\": \"AWS4-HMAC-SHA256\"}, \n    {\"x-amz-date\": \"20151229T000000Z\" } \n  ]\n}\nThis POST policy sets the following conditions on the request:\n\u2022The upload must occur before noon UTC on December 30, 2015.\n\u2022The content can be uploaded only to the sigv4examplebucket . The bucket must be in the \nregion that you speci\ufb01ed in the credential scope (x-amz-credential  form parameter), because \nthe signature you provided is valid only within this scope.\n\u2022You can provide any key name that starts with user/user1 .", "For example, user/user1/\nMyPhoto.jpg .\n\u2022The ACL must be set to public-read .\n\u2022If the upload succeeds, the user's browser is redirected to http://\nsigv4examplebucket.s3.amazonaws.com/successful_upload.html .\n\u2022The object must be an image \ufb01le.\n\u2022The x-amz-meta-uuid  tag must be set to 14365123651274 .\n\u2022The x-amz-meta-tag  can contain any value.\nThe following is a Base64-encoded version of this POST policy.", "You use this value as your \nStringToSign in signature calculation.\neyAiZXhwaXJhdGlvbiI6ICIyMDE1LTEyLTMwVDEyOjAwOjAwLjAwMFoiLA0KICAiY29uZGl0aW9ucyI6IFsNCiAgICB7ImJ1Y2tldCI6ICJzaWd2NGV4YW1wbGVidWNrZXQifSwNCiAgICBbInN0YXJ0cy13aXRoIiwgIiRrZXkiLCAidXNlci91c2VyMS8iXSwNCiAgICB7ImFjbCI6ICJwdWJsaWMtcmVhZCJ9LA0KICAgIHsic3VjY2Vzc19hY3Rpb25fcmVkaXJlY3QiOiAiaHR0cDovL3NpZ3Y0ZXhhbXBsZWJ1Y2tldC5zMy5hbWF6b25hd3MuY29tL3N1Y2Nlc3NmdWxfdXBsb2FkLmh0bWwifSwNCiAgICBbInN0YXJ0cy13aXRoIiwgIiRDb250ZW50LVR5cGUiLCAiaW1hZ2UvIl0sDQogICAgeyJ4LWFtei1tZXRhLXV1aWQiOiAiMTQzNjUxMjM2NTEyNzQifSwNCiAgICB7IngtYW16LXNlcnZlci1zaWRlLWVuY3J5cHRpb24iOiAiQUVTMjU2In0sDQogICAgWyJzdGFydHMtd2l0aCIsICIkeC1hbXotbWV0YS10YWciLCAiIl0sDQoNCiAgICB7IngtYW16LWNyZWRlbnRpYWwiOiAiQUtJQUlPU0ZPRE5ON0VYQU1QTEUvMjAxNTEyMjkvdXMtZWFzdC0xL3MzL2F3czRfcmVxdWVzdCJ9LA0KICAgIHsieC1hbXotYWxnb3JpdGhtIjogIkFXUzQtSE1BQy1TSEEyNTYifSwNCiAgICB7IngtYW16LWRhdGUiOiAiMjAxNTEyMjlUMDAwMDAwWiIgfQ0KICBdDQp9\nWhen you copy/paste the preceding policy, it should have carriage returns and new lines for your \ncomputed hash to match this value (ie. ASCII text, with CRLF line terminators).\nUsing example credentials to create a signature, the signature value is as follows (in signature \ncalculation, the date is same as the x-amz-date  in the policy (20151229):\n8afdbf4008c03f22c2cd3cdb72e4afbb1f6a588f3255ac628749a66d7f09699e\nUploading a File to Amazon S3 Using HTTP POST API Version 2006-03-01 2768Amazon Simple Storage Service API Reference\nThe following example form speci\ufb01es the preceding POST policy and supports a POST \nrequest to the sigv4examplebucket .", "Copy/paste the content in a text editor and save \nit as exampleform.html.", "You can then upload image \ufb01les to the speci\ufb01c bucket using the \nexampleform.html.", "Your request will succeed if the signature you provide matches the signature \nAmazon S3 calculates.\nNote\nYou must update the bucket name, dates, credential, policy, and signature with valid values \nfor this to successfully upload to S3.\n<html> \n  <head> \n     \n    <meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\" /> \n     \n  </head> \n  <body> \n  <form action=\"http://sigv4examplebucket.s3.amazonaws.com/\" method=\"post\" \n enctype=\"multipart/form-data\"> \n    Key to upload:  \n    <input type=\"input\"  name=\"key\" value=\"user/user1/${filename}\" /><br /> \n    <input type=\"hidden\" name=\"acl\" value=\"public-read\" /> \n    <input type=\"hidden\" name=\"success_action_redirect\" value=\"http://\nsigv4examplebucket.s3.amazonaws.com/successful_upload.html\" /> \n    Content-Type:  \n    <input type=\"input\"  name=\"Content-Type\" value=\"image/jpeg\" /><br /> \n    <input type=\"hidden\" name=\"x-amz-meta-uuid\" value=\"14365123651274\" />  \n    <input type=\"hidden\" name=\"x-amz-server-side-encryption\" value=\"AES256\" />  \n    <input type=\"text\"   name=\"X-Amz-Credential\" value=\"AKIAIOSFODNN7EXAMPLE/20151229/\nus-east-1/s3/aws4_request\" /> \n    <input type=\"text\"   name=\"X-Amz-Algorithm\" value=\"AWS4-HMAC-SHA256\" /> \n    <input type=\"text\"   name=\"X-Amz-Date\" value=\"20151229T000000Z\" /> \n    Tags for File:  \n    <input type=\"input\"  name=\"x-amz-meta-tag\" value=\"\" /><br /> \n    <input type=\"hidden\" name=\"Policy\" value=' <Base64-encoded policy string> ' /> \n    <input type=\"hidden\" name=\"X-Amz-Signature\" value=\" <signature-value> \" /> \n    File:  \n    <input type=\"file\"   name=\"file\" /> <br /> \nUploading a File to Amazon S3 Using HTTP POST API Version 2006-03-01 2769Amazon Simple Storage Service API Reference\n    <!-- The elements after this will be ignored --> \n    <input type=\"submit\" name=\"submit\" value=\"Upload to Amazon S3\" /> \n  </form> \n   \n</html>\nThe post parameters are case insensitive. For example, you can specify x-amz-signature  or X-\nAmz-Signature .\nBrowser-Based Uploads to Amazon S3 Using the AWS Amplify \nLibrary\nThis section describes how to upload \ufb01les to Amazon S3 using the AWS Amplify JavaScript library.\nFor information about setting up the AWS Amplify library, see AWS Amplify Installation and \nCon\ufb01guration .\nUsing the AWS Amplify JavaScript library to Upload Files to Amazon S3\nThe AWS Amplify library Storage module gives a simple browser-based upload mechanism for \nmanaging user content in public or private Amazon S3 storage.\nExample : AWS Amplify Manual Setup\nThe following example shows the manual setup for using the AWS Amplify Storage module. The \ndefault implementation of the Storage module uses Amazon S3.\nimport Amplify from 'aws-amplify';\nAmplify.configure( \n    Auth: { \n        identityPoolId: 'XX-XXXX-X:XXXXXXXX-XXXX-1234-abcd-1234567890ab', //REQUIRED - \n Amazon Cognito Identity Pool ID \n        region: 'XX-XXXX-X', // REQUIRED - Amazon Cognito Region \n        userPoolId: 'XX-XXXX-X_abcd1234', //OPTIONAL - Amazon Cognito User Pool ID \n        userPoolWebClientId: 'XX-XXXX-X_abcd1234', //OPTIONAL - Amazon Cognito Web \n Client ID \n    }, \n    Storage: { \n        bucket: '', //REQUIRED -  Amazon S3 bucket \n        region: 'XX-XXXX-X', //OPTIONAL -  Amazon service region \n    }\nBrowser-Based Uploads Using AWS Amplify API Version 2006-03-01 2770Amazon Simple Storage Service API Reference\n);\nExample : Put data into Amazon S3\nThe following example shows how to put public data into Amazon S3.\nStorage.put('test.txt', 'Hello') \n        .then (result => console.log(result)) \n        .catch(err => console.log(err));\nThe following example shows how to put private data into Amazon S3.\nStorage.put('test.txt', 'Private Content', { \n        level: 'private', \n        contentType: 'text/plain' \n    }) \n    .then (result => console.log(result)) \n    .catch(err => console.log(err));\nFor more information about using the AWS Amplify Storage module, see AWS Amplify Storage.\nMore Info\nAWS Amplify Quick Start\nMore Info API Version 2006-03-01 2771Amazon Simple Storage Service API Reference\nCommon Request Headers\nThe following table describes headers that can be used by various types of Amazon S3 REST \nrequests.\nHeader Name Description\nAuthorization The information required for request authentication.", "For \nmore information, go to The Authentication Header  in \nthe Amazon Simple  Storage Service Developer Guide.", "For \nanonymous requests  this header is not required.\nAccess-Control-Req \nuest-MethodA list of HTTP methods that is sent as a pre-\ufb02ight CORS \nrequest. If the pre-\ufb02ight CORS  evaluation is successful, \nthen the speci\ufb01ed methods are allowed to be used  in the \nfollowing CORS request.\nContent-Length Length of the message (without the headers) according to \nRFC 2616.", "This header is  required for PUTs and operations \nthat load XML, such as logging and  ACLs.\nContent-Type The content type of the resource in case the request has \ncontent in the body.", "Example:   text/plain\nContent-MD5 The base64 encoded 128-bit MD5 digest of the message \n(without the headers) according to  RFC 1864. This header \ncan be used as a message integrity check to verify  that the \ndata is the same data that was originally sent.", "Although it is  \n optional, we recommend using the Content-MD5 mechanism \nas an end-to-end integrity check.", "For more information about \nREST request authentication,  go to REST Authentication  in \nthe Amazon Simple Storage  Service Developer Guide.\nDate The date that can be used to create the signature contained \nin the   Authorization  header.", "If the Date  header  is to be \nused for signing it must be speci\ufb01ed in the ISO 8601 basic  \nformat.", "In this case, the x-amz-date  header is not needed. \nAPI Version 2006-03-01 2772Amazon Simple Storage Service API Reference\nHeader Name Description\n Note that when x-amz-date  is present, it always overrides \n the value of the Date header.\nIf the Date header is not used for signing, it can be one of \nthe full  date formats speci\ufb01ed by RFC  2616, section 3.3.", "For \nexample, the date/time  Wed, 01 Mar 2006 12:00:00 \nGMT is a valid date/time header for use with  Amazon S3.\nIf you are using the Date  header for signing, then it  must be \nin the ISO 8601 basic YYYYMMDD'T'HHMMSS'Z'  format.\nIf Date is speci\ufb01ed but is not in ISO 8601 basic format, then  \n you must also include the x-amz-date  header.", "If   Date\nis speci\ufb01ed in ISO 8601 basic format, then this  is su\ufb03cien \nt for signing requests and you do not need the   x-amz-dat \ne header.", "For more information, see Handling Dates in \nSignature Version 4 in the   Amazon Web Services Glossary.\nExpect When your application uses 100-continue, it does not send \nthe request body until it  receives an acknowledgment.", "If the \nmessage is rejected based on the  headers, the body of the \nmessage is not sent.", "This header can be used  only if you are \nsending a body.\nValid Values: 100-continue\nHost For path-style requests, the value is s3.amazonaws.com . \nFor  virtual-style requests, the value is BucketNam \ne.s3.amazonaws.com .", "For more information, go to  \n  Virtual Hosting in the Amazon Simple Storage Service User \nGuide .\nThis header is required for HTTP 1.1 (most toolkits add this \nheader automatically);  optional for HTTP/1.0 requests.\nOrigin An endpoint that speci\ufb01es the server name of the initial \nrequester.\nAPI Version 2006-03-01 2773Amazon Simple Storage Service API Reference\nHeader Name Description\nx-amz-content-sha256 When using signature version 4 to authenticate request, this \nheader provides a hash of  the request payload.", "For more \ninformation see Signature Calculations for the Authoriza \ntion Header:  Transferring Payload in a Single Chunk (AWS \nSignature Version 4). When uploading object in  chunks, \nyou set the value to STREAMING-AWS4-HMAC-SHA256- \nPAYLOAD  to  indicate that the signature covers only headers \nand that there is no  payload. For more information, see\nSignature Calculations for the Authorization Header:  Transfe \nrring Payload in Multiple Chunks (Chunked Upload) (AWS \nSignature Version  4).\nx-amz-date The date used to create the signature in the Authoriza \ntion header.", "The format must be  ISO 8601 basic in the\nYYYYMMDD'T'HHMMSS'Z'  format.", "For  example, the date/\ntime 20170210T120000Z  is a valid   x-amz-date  for use \nwith Amazon S3.\nx-amz-date  is optional for all requests; it can be used to  \n override the date used for signing requests.", "If the Date  h \neader is speci\ufb01ed in the ISO 8601 basic format, then   x-\namz-date  is not needed. When x-amz-date  is present, \nit always overrides the value of the Date header.", "For more \ninformation, see Handling Dates in Signature Version 4 in the  \n  Amazon Web Services Glossary.\nAPI Version 2006-03-01 2774Amazon Simple Storage Service API Reference\nHeader Name Description\nx-amz-security-token This header can be used in the following scenarios:\n\u2022\nTo provide security tokens for Amazon DevPay operation \ns - Each request that uses Amazon DevPay requires  \n two x-amz-security-token  headers: one for \nthe  product token and one for the user token.", "When \nAmazon S3 receives an  authenticated request, it compares \nthe computed signature with  the provided signature.", "\nImproperly formatted multi-value headers  that are used to \ncalculate a signature can cause authentication  issues.\n\u2022\nTo provide a security token when using temporary security \ncredentials - When making  requests using temporary \nsecurity credentials that you obtained  from IAM, you must \nprovide a security token by using this  header.", "To learn \nmore about temporary security credentials, see   Making  R \nequests .\nThis header is required for requests that use Amazon DevPay \nand requests that are signed by using  temporary security \ncredentials.\nAPI Version 2006-03-01 2775Amazon Simple Storage Service API Reference\nCommon Response Headers\nThe following table describes response headers that are common to most Amazon S3 responses.\nName Description\nAccess-Co \nntrol-All \now-Creden \ntialsA Boolean that determines if the server allows CORS requests to contain \ncredentials.", "If the Access-Control-Allow-Origin  request header \nis set to '*' then the Access-Control-Allow-Credentials\nresponse header will be omitted, else it is set to true when CORS evaluatio \nn is successful.\nType: Boolean\nDefault: None\nAccess-Co \nntrol-All \now-HeadersA list of HTTP headers allowed for your CORS requests. The Access-Co \nntrol-Allow-Headers  response header is returned for successful \nCORS evaluations and explicitly speci\ufb01es all allowed Access-Control-\nRequest-Headers .\nType: String\nDefault: None\nAccess-Co \nntrol-All \now-MethodsA list that speci\ufb01es which HTTP methods are allowed.", "Amazon S3 will \nonly allow CORS requests from allowed CORS methods when the CORS \nevaluation is successful.\nType: String\nDefault: None\nAccess-Co \nntrol-All \now-OriginThe location of the allowed origin. Amazon S3 will only send the Access-\nControl-Allow-Origin  response header when the CORS evaluation \nis successful.", "If the request origin matches '*' in the CORS con\ufb01guration's \nallowed origins then the '*' is returned in this response header instead of \nthe original origin.\nAPI Version 2006-03-01 2776Amazon Simple Storage Service API Reference\nName Description\nType: String\nDefault: None\nAccess-Co \nntrol-Exp \nose-HeadersA list that allows a server to identify a response header that exposes access \nfor applications when the CORS evaluation is successful.\nType: String\nDefault: None\nAccess-Co \nntrol-Max-\nAgeThe time in seconds that your browser can cache the response for a CORS \npre-\ufb02ight request as identi\ufb01ed by the resource, the HTTP method, and \nthe origin. The Access-Control-Max-Age  response header is only \nreturned when the CORS evaluation is successful.\nType: Integer\nDefault: None\nVary A list that indicates which request headers the CORS evaluation result \nvaries on. The Vary response header is only returned when the CORS \nevaluation is successful.\nType: String\nDefault: None\nContent-L \nengthThe length in bytes of the body in the response.\nType: String\nDefault: None\nContent-Type The MIME type of the content.", "For example, Content-Type: text/\nhtml; charset=utf-8 .\nType: String\nDefault: None\nAPI Version 2006-03-01 2777Amazon Simple Storage Service API Reference\nName Description\nConnection A value that speci\ufb01es whether the connection to the server is open or \nclosed.\nType: Enum\nValid Values: open  | close\nDefault: None\nDate The date and time that Amazon S3 responded; for example, Wed, 01 Mar \n2006 12:00:00 GMT.\nType: String\nDefault: None\nETag The entity tag (ETag) represents a speci\ufb01c version of the object.", "The ETag \nre\ufb02ects changes only to the contents of an object, not its metadata. The \nETag might or might not be an MD5 digest of the object data. Whether or \nnot it is depends on how the object was created and how it is encrypted, as \nfollows:\n\u2022Objects created through the AWS Management Console or by the PUT\nObject, POST Object , or Copy  operation:\n\u2022Objects that are plaintext or encrypted by server-side encryption with \nAmazon S3 managed keys (SSE-S3) have ETags that are an MD5 digest \nof their data.\n\u2022Objects encrypted by server-side encryption with customer-provided \nkeys (SSE-C) or AWS Key Management Service (AWS KMS) keys (SSE-\nKMS) have ETags that are not an MD5 digest of their object data.\n\u2022Objects created by either the Multipart Upload or Upload Part Copy \noperation have ETags that are not MD5 digests, regardless of the method \nof encryption.\nType: String\nAPI Version 2006-03-01 2778Amazon Simple Storage Service API Reference\nName Description\nServer The name of the server that created the response.\nType: String\nDefault: AmazonS3\nx-amz-del \nete-markerA value that speci\ufb01es whether the object returned was (true ) or was not \n(false) a delete marker.\nType: Boolean\nValid Values: true  | false\nDefault: false\nx-amz-id-2 A special token that is used together with the x-amz-request-id\nheader to help AWS troubleshoot problems. For information about AWS \nSupport using these request IDs, see  Troubleshooting Amazon S3.\nType: String\nDefault: None\nx-amz-req \nuest-idA value created by Amazon S3 that uniquely identi\ufb01es the request.", "\nThis value is used together with the x-amz-id-2  header to help AWS \ntroubleshoot problems.", "For information about AWS Support using these \nrequest IDs, see  Troubleshooting Amazon S3.\nType: String\nDefault: None\nx-amz-ser \nver-side- \nencryptionThe server-side encryption algorithm used when storing this object in \nAmazon S3 (for example, AES256 , aws:kms ).\nValid Values: AES256  | aws:kms\nAPI Version 2006-03-01 2779Amazon Simple Storage Service API Reference\nName Description\nx-amz-ver \nsion-idThe version of the object. When you enable versioning, Amazon S3 \ngenerates a random number for objects added to a bucket.", "The value is \nUTF-8 encoded and URL ready.", "When you PUT an object in a bucket where \nversioning has been suspended, the version ID is always null .\nType: String\nValid Values: null | any URL-ready, UTF-8 encoded string\nDefault: null\nAPI Version 2006-03-01 2780Amazon Simple Storage Service API Reference\nError responses\nThis section provides reference information about Amazon S3 errors.\nNote\n\u2022In general, S3 bucket owners are billed for requests with HTTP 200 OK successful \nresponses and HTTP 4XX client error responses.", "Bucket owners aren't billed for HTTP\n5XX server error responses, such as HTTP 503 Slow Down  errors.", "For more information \non S3 error codes under HTTP 3XX and 4XX status codes that aren't billed, see Billing \nfor Amazon S3 error responses in the Amazon S3 User Guide. For more information \nabout billing charges if your bucket is con\ufb01gured as a Requester Pays bucket, see How \nRequester Pays charges work in the Amazon S3 User Guide.\n\u2022SOAP support over HTTP is deprecated, but SOAP is still available over HTTPS. New \nAmazon S3 features are not supported for SOAP. Instead of using SOAP, we recommend \nthat you use either the REST API or the AWS SDKs.\nTopics\n\u2022REST error responses\n\u2022List of error codes\n\u2022List of SELECT Object Content Error Codes\n\u2022List of Replication-related error codes\n\u2022List of Tagging-related error codes\n\u2022List of Amazon S3 on Outposts error codes\n\u2022List of Amazon S3 Storage Lens error codes\n\u2022List of Amazon S3 Object Lambda error codes\n\u2022List of Amazon S3 asynchronous error codes\n\u2022List of Amazon S3 Access Grants Error Codes\n\u2022Amazon S3 error best practices\nAPI Version 2006-03-01 2781Amazon Simple Storage Service API Reference\nREST error responses\nWhen an error occurs, the header information contains the following:\n\u2022Content-Type: application/xml\n\u2022An appropriate 3xx, 4xx, or 5xx HTTP status code\nThe body of the response also contains information about the error.", "The following sample error \nresponse shows the structure of response elements common to all REST error responses.\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<Error> \n  <Code>NoSuchKey</Code> \n  <Message>The resource you requested does not exist</Message> \n  <Resource>/mybucket/myfoto.jpg</Resource>  \n  <RequestId>4442587FB7D0A2F9</RequestId>\n</Error>\nThe following table explains the REST error response elements.\nName Description\nCode The error code is a string that uniquely identi\ufb01es an error  condition.", "It is \nmeant to be read and understood by programs that  detect and handle errors \nby type. For more information, see List of error codes.\nType: String\nAncestor: Error\nError Container for all error elements.\nType: Container\nAncestor: None\nMessage The error message contains a generic description of the error  condition in \nEnglish.", "It is intended for a human audience.", "Simple  programs display the \nmessage directly to the end user if they  encounter an error condition they \nREST error responses API Version 2006-03-01 2782Amazon Simple Storage Service API Reference\nName Description\ndon't know how or don't care to  handle.", "Sophisticated programs with more \nexhaustive error handling  and proper internationalization are more likely to \nignore the error  message.\nType: String\nAncestor: Error\nRequestId ID of the request associated with the error.\nType: String\nAncestor: Error\nResource The bucket or object that is involved in the error.\nType: String\nAncestor: Error\nMany error responses contain additional structured data meant to be read and understood by a \ndeveloper diagnosing programming errors.", "For example, if you send a Content-MD5 header with a \nREST PUT request that doesn't match the digest calculated on the server, you receive a BadDigest\nerror. The error response also includes as detail elements the digest that the server calculated, and \nthe digest that you told the server to expect. During development, you can use this information \nto diagnose the error.", "In production, a well-behaved program might include this information in its \nerror log.\nFor information about general response elements, go to Error responses.\nList of error codes\nThe following table lists Amazon S3 error codes.\nList of error codes API Version 2006-03-01 2783Amazon Simple Storage Service API Reference\nError code Description HTTP \nstatus \ncodeSOAP \nfault \ncode \npre\ufb01x\nAccessControlListN \notSupportedThe bucket does not allow ACLs.400 \nBad \nRequestClient\nAccessDenied Access Denied 403 \nForbiddenClient\nAccessPointAlready \nOwnedByYouAn access point with an identical \nname already exists in your  accoun \nt.409 \nConflictClient\nAccountProblem There is a problem with your \nAWS account that prevents the \noperation from completing  \nsuccessfully. For further assistance, \nsee Contact Us.403 \nForbiddenClient\nAllAccessDisabled All access to this Amazon S3 \nresource has been disabled.", "For \nfurther assistance, see Contact Us.403 \nForbiddenClient\nAmbiguousGrantByEm \nailAddressThe email address that you \nprovided is associated with more \nthan one account.400 \nBad \nRequestClient\nAuthorizationHeade \nrMalformedThe authorization header that you \nprovided is not valid.400 \nBad \nRequestN/A\nAuthorizationQuery \nParametersErrorThe authorization query parameter \ns that you provided are not valid.400 \nBad \nRequestN/A\nList of error codes API Version 2006-03-01 2784Amazon Simple Storage Service API Reference\nError code Description HTTP \nstatus \ncodeSOAP \nfault \ncode \npre\ufb01x\nBadDigest The Content-MD5 or checksum \nvalue that you speci\ufb01ed did not \nmatch what the server  received.400 \nBad \nRequestClient\nBucketAlreadyExists The requested bucket name is not \navailable.", "The bucket namespace is \nshared by all users  of the system. \nSpecify a di\ufb00erent name and try \nagain.409 \nConflictClient\nBucketAlreadyOwnedByYou The bucket that you tried to create \nalready exists, and you own it.", "\nAmazon S3 returns this  error in all \nAWS Regions except in the US East \n(N.", "Virginia) Region  (us-east-1).", "\nFor legacy compatibility, if you re-\ncreate an  existing bucket that you \nalready own in us-east-1, Amazon \nS3  returns 200 OK and resets the \nbucket access control lists  (ACLs).\nFor Amazon S3 on Outposts, the \nbucket that you tried to create  alr \neady exists in your Outpost and \nyou own it.409 \nConflict\n(in all \nRegions \nexcept  \n us- \neast-1)Client\nBucketNotEmpty The bucket that you tried to delete \nis not empty.409 \nConflictClient\nClientTokenConflict Your Multi-Region Access Point \nidempotency token was already \nused for  a di\ufb00erent request.409 \nConflictClient\nList of error codes API Version 2006-03-01 2785Amazon Simple Storage Service API Reference\nError code Description HTTP \nstatus \ncodeSOAP \nfault \ncode \npre\ufb01x\nConnectionClosedBy \nRequesterReturned to the original caller \nwhen an error is encountered while \nreading the WriteGetObjectResp \nonse body.400 \nBad \nRequestClient\nConditionalRequestConflict A con\ufb02icting operation occurred.", "If \nusing PutObject  you  can retry \nthe request.", "If using multipart \nupload you should initiate another  \n  CreateMultipartUpload\nrequest and re-upload each  part.409 \nConflictClient\nCredentialsNotSupported This request does not support \ncredentials.400 \nBad \nRequestClient\nCrossLocationLoggi \nngProhibitedCross-Region logging is not \nallowed.", "Buckets in one AWS \nRegion cannot log information  to \na bucket in another  Region.403 \nForbiddenClient\nDeviceNotActiveError The device is not currently active.400 \nBad \nRequestClient\nEndpointNotFound Direct requests to the correct \nendpoint.400 \nBad \nRequestClient\nEntityTooSmall Your proposed upload is smaller \nthan the minimum allowed object  \n size.400 \nBad \nRequestClient\nList of error codes API Version 2006-03-01 2786Amazon Simple Storage Service API Reference\nError code Description HTTP \nstatus \ncodeSOAP \nfault \ncode \npre\ufb01x\nEntityTooLarge Your proposed upload exceeds the \nmaximum allowed object size. For \nmore information, see   Amazon \nSimple Storage Service endpoints \nand quotas  in the AWS General \nReference.400 \nBad \nRequestClient\nExpiredToken The provided token has expired.400 \nBad \nRequestClient\nIllegalLocationCon \nstraintExceptionThis error might occur for the \nfollowing reasons:\n\u2022\nYou are trying to access a bucket \nfrom a di\ufb00erent Region than \nwhere the bucket exists.\n\u2022\nYou attempt to create a bucket \nwith a location constraint that \ncorresponds to a di\ufb00erent region \nthan the regional endpoint the \nrequest was sent to.400 \nBad \nRequestClient\nIllegalVersioningC \nonfigurationExceptionThe versioning con\ufb01guration \nspeci\ufb01ed in the request is not valid.400 \nBad \nRequestClient\nIncompleteBody You did not provide the number \nof bytes speci\ufb01ed by the  Content-\nLength HTTP header.400 \nBad \nRequestClient\nList of error codes API Version 2006-03-01 2787Amazon Simple Storage Service API Reference\nError code Description HTTP \nstatus \ncodeSOAP \nfault \ncode \npre\ufb01x\nIncorrectEndpoint The speci\ufb01ed bucket exists in \nanother Region.", "Direct requests to \nthe correct endpoint.400 \nBad \nRequestClient\nIncorrectNumberOfF \nilesInPostRequestPOST requires exactly one \ufb01le \nupload per request.400 \nBad \nRequestClient\nInlineDataTooLarge The inline data exceeds the \nmaximum allowed  size.400 \nBad \nRequestClient\nInternalError An internal error occurred. Try \nagain.500 \nInternal \nServer \nErrorServer\nInvalidAccessKeyId The AWS access key ID that you \nprovided does not exist in our \nrecords.403 \nForbiddenClient\nInvalidAccessPoint The speci\ufb01ed access point name or \naccount is not valid.400 \nBad \nRequestClient\nInvalidAccessPoint \nAliasErrorThe speci\ufb01ed access point alias \nname is not valid.400 \nBad \nRequestClient\nInvalidAddressingHeader You must specify the Anonymous \nrole.N/A Client\nList of error codes API Version 2006-03-01 2788Amazon Simple Storage Service API Reference\nError code Description HTTP \nstatus \ncodeSOAP \nfault \ncode \npre\ufb01x\nInvalidArgument This error might occur for the \nfollowing reasons:\n\u2022\nThe speci\ufb01ed argument was not \nvalid.\n\u2022\nThe request was missing a \nrequired header.\n\u2022\nThe speci\ufb01ed argument was \nincomplete or in the wrong  fo \nrmat.\n\u2022\nThe speci\ufb01ed argument must \nhave a length greater than or \nequal to 3.400 \nBad \nRequestClient\nInvalidBucketAclWi \nthObjectOwnershipBucket cannot have ACLs set with \nObjectOwnership's  BucketOwner \nEnforced setting.400 \nBad \nRequestClient\nInvalidBucketName The speci\ufb01ed bucket is not valid.400 \nBad \nRequestClient\nInvalidBucketOwner \nAWSAccountIDThe value of the expected bucket \nowner parameter must be an AWS \naccount ID.400 \nBad \nRequestClient\nInvalidBucketState The request is not valid for the \ncurrent state of the bucket.409 \nConflictClient\nList of error codes API Version 2006-03-01 2789Amazon Simple Storage Service API Reference\nError code Description HTTP \nstatus \ncodeSOAP \nfault \ncode \npre\ufb01x\nInvalidDigest The Content-MD5 or checksum \nvalue that you speci\ufb01ed is not \nvalid.400 \nBad \nRequestClient\nInvalidEncryptionA \nlgorithmErrorThe encryption request that you \nspeci\ufb01ed is not valid. The valid \nvalue is   AES256 .400 \nBad \nRequestClient\nInvalidHostHeader The host headers provided in the \nrequest used the incorrect style \naddressing.400 \nBad \nRequestClient\nInvalidHttpMethod The request is made using an \nunexpected HTTP method.400 \nBad \nRequestClient\nInvalidLocationConstraint The speci\ufb01ed location (Region) \nconstraint is not valid.", "For more \ninformation about  selecting \na Region for your buckets, see\nBuckets  overview.400 \nBad \nRequestClient\nInvalidObjectState The operation is not valid for the \ncurrent state of the  object.403 \nForbiddenClient\nInvalidPart One or more of the speci\ufb01ed parts \ncould not be found.", "The part \nmight  not have been uploaded, \nor the speci\ufb01ed entity tag might \nnot have  matched the part's entity \ntag.400 \nBad \nRequestClient\nList of error codes API Version 2006-03-01 2790Amazon Simple Storage Service API Reference\nError code Description HTTP \nstatus \ncodeSOAP \nfault \ncode \npre\ufb01x\nInvalidPartOrder The list of parts was not in \nascending order. The parts list \nmust be speci\ufb01ed in order  by part \nnumber.400 \nBad \nRequestClient\nInvalidPayer All access to this object has been \ndisabled.", "For further assistance, \nsee Contact Us.403 \nForbiddenClient\nInvalidPolicyDocument The content of the form does not \nmeet the conditions speci\ufb01ed in \nthe  policy document.400 \nBad \nRequestClient\nInvalidRange The requested range is not valid \nfor the request.", "Try another range.416 \nRequested \nRange \nNot \nSatisfiab \nleClient\nList of error codes API Version 2006-03-01 2791Amazon Simple Storage Service API Reference\nError code Description HTTP \nstatus \ncodeSOAP \nfault \ncode \npre\ufb01x\nInvalidRequest This error might occur for the \nfollowing reasons:\n\u2022\nThe request is using the wrong \nsignature version.", "Use AWS4-\nHMAC-SHA256   (Signature \nVersion 4).\n\u2022\nAn access point can be created \nonly for an existing bucket.\n\u2022\nThe access point is not in a state \nwhere it can be deleted.\n\u2022\nAn access point can be listed \nonly for an existing bucket.\n\u2022\nThe next token is not valid.\n\u2022\nAt least one action must be \nspeci\ufb01ed in a lifecycle rule.\n\u2022\nAt least one lifecycle rule must \nbe speci\ufb01ed.\n\u2022\nThe number of lifecycle rules \nmust not exceed the allowed \nlimit of 1000 rules.\n\u2022\nThe range for the MaxResults\nparameter is not valid.\n\u2022400 \nBad \nRequestClient\nList of error codes API Version 2006-03-01 2792Amazon Simple Storage Service API Reference\nError code Description HTTP \nstatus \ncodeSOAP \nfault \ncode \npre\ufb01x\nSOAP requests must be made \nover an HTTPS  connection.\n\u2022\nAmazon S3 Transfer Accelerat \nion is not supported for buckets \nwith non-DNS compliant  names.\n\u2022\nAmazon S3 Transfer Accelerat \nion is not supported for buckets \nwith periods (.) in their  names.\n\u2022\nThe Amazon S3 Transfer \nAcceleration endpoint supports \nonly virtual style requests.\n\u2022\nAmazon S3 Transfer Acceleration \nis not con\ufb01gured on this bucket.\n\u2022\nAmazon S3 Transfer Acceleration \nis disabled on this bucket.\n\u2022\nAmazon S3 Transfer Acceleration \nis not supported on this bucket.", "\nFor assistance, contact   AWS \nSupport.\n\u2022\nAmazon S3 Transfer Accelerat \nion cannot be enabled on this \nbucket.", "For assistance, contact   \nAWS Support.\n\u2022\nList of error codes API Version 2006-03-01 2793Amazon Simple Storage Service API Reference\nError code Description HTTP \nstatus \ncodeSOAP \nfault \ncode \npre\ufb01x\nCon\ufb02icting values provided in \nHTTP headers and query  pa \nrameters.\n\u2022\nCon\ufb02icting values provided in \nHTTP headers and POST form  \n \ufb01elds.\n\u2022\nCopyObject request made on \nobjects larger than 5GB in  size.\nInvalidSessionException Returned if the session doesn't \nexist anymore because it timed out \nor expired.400 \nBad \nRequestClient\nInvalidSignature The request signature that the \nserver calculated does not match \nthe signature that you provided.", "\nCheck your AWS secret access key \nand signing method.", "For more \ninformation, see Signing and \nauthenticating REST requests.400 \nBad \nRequestClient\nInvalidSecurity The provided security credentials \nare not valid.403 \nForbiddenClient\nInvalidSOAPRequest The SOAP request body is not \nvalid.400 \nBad \nRequestClient\nList of error codes API Version 2006-03-01 2794Amazon Simple Storage Service API Reference\nError code Description HTTP \nstatus \ncodeSOAP \nfault \ncode \npre\ufb01x\nInvalidStorageClass The storage class that you \nspeci\ufb01ed is not valid.400 \nBad \nRequestClient\nInvalidTargetBucke \ntForLoggingThe target bucket for logging \neither does not exist, is not owned \nby you, or does not  have the \nappropriate grants for the log-\ndelivery group.400 \nBad \nRequestClient\nInvalidToken The provided token is malformed \nor otherwise not valid.400 \nBad \nRequestClient\nInvalidURI The speci\ufb01ed URI couldn't be \nparsed.400 \nBad \nRequestClient\nKeyTooLongError Your key is too long. 400 \nBad \nRequestClient\nKMS.DisabledException The request was rejected because \nthe speci\ufb01ed KMS key is not \nenabled.400 \nBad \nRequestClient\nList of error codes API Version 2006-03-01 2795Amazon Simple Storage Service API Reference\nError code Description HTTP \nstatus \ncodeSOAP \nfault \ncode \npre\ufb01x\nKMS.InvalidKeyUsag \neExceptionThe request was rejected for one \nof the following reasons:\n\u2022The KeyUsage value of the KMS \nkey is incompatible with the API \noperation.\n\u2022The encryption algorithm or \nsigning algorithm speci\ufb01ed for \nthe operation is incompatible \nwith the type of key material in \nthe KMS key (KeySpec).\nFor encrypting, decrypting, re-\nencrypting, and generating data \nkeys, the KeyUsage must be \nENCRYPT_DECRYPT.", "For signing \nand verifying messages, the \nKeyUsage must be SIGN_VERI \nFY. For generating and verifying \nmessage authentication codes \n(MACs), the KeyUsage must be \nGENERATE_VERIFY_MAC. For \nderiving key agreement secrets, \nthe KeyUsage must be KEY_AGREE \nMENT.", "To \ufb01nd the KeyUsage of \na KMS key, use the DescribeKey \noperation.\nTo \ufb01nd the encryption or signing \nalgorithms supported for a 400 \nBad \nRequestClient\nList of error codes API Version 2006-03-01 2796Amazon Simple Storage Service API Reference\nError code Description HTTP \nstatus \ncodeSOAP \nfault \ncode \npre\ufb01x\nparticular KMS key, use the \nDescribeKey operation.\nKMS.KMSInvalidStat \neExceptionThe request was rejected because \nthe state of the speci\ufb01ed resource \nis not valid for this request. T \nhis exception means one of the \nfollowing:\n\u2022The key state of the KMS key \nis not compatible with the \noperation.\nTo \ufb01nd the key state, use the \nDescribeKey operation. For more \ninformation about which key \nstates are compatible with each \nKMS operation, see Key states of \nAWS KMS keys in the AWS Key \nManagement Service Developer \nGuide .\n\u2022For cryptographic operation \ns on KMS keys in custom key \nstores, this exception represent \ns a general failure with many \npossible causes.", "To identify the \ncause, see the error message \nthat accompanies the exception.\n 400 \nBad \nRequestClient\nList of error codes API Version 2006-03-01 2797Amazon Simple Storage Service API Reference\nError code Description HTTP \nstatus \ncodeSOAP \nfault \ncode \npre\ufb01x\nKMS.NotFoundException The request was rejected because \nthe speci\ufb01ed entity or resource \ncould not be found.400 \nBad \nRequestClient\nMalformedACLError The ACL that you provided was not \nwell formed or did not validate \nagainst our published schema.400 \nBad \nRequestClient\nMalformedPOSTRequest The body of your POST request is \nnot well-formed  multipart/form-\ndata.400 \nBad \nRequestClient\nMalformedXML The XML that you provided was \nnot well formed or did not validate \nagainst our published schema.400 \nBad \nRequestClient\nMaxMessageLengthExceeded Your request was too large. 400 \nBad \nRequestClient\nMaxPostPreDataLeng \nthExceededErrorYour POST request \ufb01elds preceding \nthe upload \ufb01le were too large.400 \nBad \nRequestClient\nMetadataTooLarge Your metadata headers exceed the \nmaximum allowed metadata size.400 \nBad \nRequestClient\nMethodNotAllowed The speci\ufb01ed method is not \nallowed against this resource.405 \nMethod \nNot \nAllowedClient\nList of error codes API Version 2006-03-01 2798Amazon Simple Storage Service API Reference\nError code Description HTTP \nstatus \ncodeSOAP \nfault \ncode \npre\ufb01x\nMissingAttachment A SOAP attachment was expected, \nbut none was found.400 Bad \nRequestClient\nMissingAuthenticationToken The request was not signed.\u00a0 403 \nForbiddenClient\nMissingContentLength You must provide the Content-L \nength HTTP header.411 \nLength \nRequiredClient\nMissingRequestBodyError You sent an empty XML document \nas a request.400 \nBad \nRequestClient\nMissingSecurityElement The SOAP 1.1 request is missing a \nsecurity element.400 \nBad \nRequestClient\nMissingSecurityHeader Your request is missing a required \nheader.400 \nBad \nRequestClient\nNoLoggingStatusForKey There is no such thing as a logging \nstatus subresource for a key.400 \nBad \nRequestClient\nNoSuchAsyncRequest The speci\ufb01ed request was not \nfound.404 \nNot \nFoundClient\nNoSuchBucket The speci\ufb01ed bucket does not \nexist.404 \nNot \nFoundClient\nList of error codes API Version 2006-03-01 2799Amazon Simple Storage Service API Reference\nError code Description HTTP \nstatus \ncodeSOAP \nfault \ncode \npre\ufb01x\nNoSuchBucketPolicy The speci\ufb01ed bucket does not have \na bucket policy.404 \nNot \nFoundClient\nNoSuchCORSConfiguration The speci\ufb01ed bucket does not have \na CORS con\ufb01guration.404 \nNot \nFoundClient\nNoSuchKey The speci\ufb01ed key does not exist.404 \nNot \nFoundClient\nNoSuchLifecycleCon \nfigurationThe speci\ufb01ed lifecycle con\ufb01gura \ntion does not exist.404 \nNot \nFoundClient\nNoSuchMultiRegionA \nccessPointThe speci\ufb01ed Multi-Region Access \nPoint does not exist.404 \nNot \nFoundClient\nNoSuchObjectLockCo \nnfigurationThe speci\ufb01ed object does not have \nan ObjectLock con\ufb01guration.404 \nNot \nFoundClient\nNoSuchWebsiteConfiguration The speci\ufb01ed bucket does not have \na website con\ufb01guration.404 \nNot \nFoundClient\nNoSuchTagSet The speci\ufb01ed tag does not exist. 404 \nNot \nFoundClient\nList of error codes API Version 2006-03-01 2800Amazon Simple Storage Service API Reference\nError code Description HTTP \nstatus \ncodeSOAP \nfault \ncode \npre\ufb01x\nNoSuchUpload The speci\ufb01ed multipart upload \ndoes not exist.", "The upload ID \nmight not be valid, or the  multipa \nrt upload might have been aborted \nor completed.404 \nNot \nFoundClient\nNoSuchVersion The version ID speci\ufb01ed in the \nrequest does not match an existing \nversion.404 \nNot \nFoundClient\nNotDeviceOwnerError The device that generated \nthe token is not owned by the \nauthenticated user.400 \nBad \nRequestClient\nNotImplemented A header that you provided implies \nfunctionality that is not implement \ned.501 \nNot \nImplement \nedServer\nNotModified The resource was not changed.304 \nNot \nModifiedServer\nNoTransformationDefined No transformation found for this \nObject Lambda Access Point.404 \nNot \nFoundClient\nNotSignedUp Your account is not signed up \nfor the Amazon S3 service. You \nmust sign up before you can use  \n Amazon S3.", "You can sign up \nat the following URL: https://a \nws.amazon.com/s3403 \nForbiddenClient\nList of error codes API Version 2006-03-01 2801Amazon Simple Storage Service API Reference\nError code Description HTTP \nstatus \ncodeSOAP \nfault \ncode \npre\ufb01x\nObjectLockConfigur \nationNotFoundErrorThe Object Lock con\ufb01guration \ndoes not exist for this bucket.404 \nNot \nFoundClient\nOwnershipControlsN \notFoundErrorThe bucket ownership controls \nwere not found.404 \nNot \nFoundClient\nOperationAborted A con\ufb02icting conditional operation \nis currently in progress against  this \nresource.", "Try again.409 \nConflictClient\nPermanentRedirect The bucket that you are attemptin \ng to access must be addressed \nusing the speci\ufb01ed endpoint.", "\nSend all future requests to this \nendpoint.301 \nMoved \nPermanent \nlyClient\nPermanentRedirectC \nontrolErrorThe API operation you are \nattempting to access must be \naddressed using the speci\ufb01ed \nendpoint. Send all future requests \nto this endpoint.301 \nMoved \nPermanent \nlyClient\nPreconditionFailed At least one of the preconditions \nthat you speci\ufb01ed did not hold.412 \nPrecondit \nion \nFailedClient\nRedirect Temporary redirect. You are being \nredirected to the bucket while \nthe Domain Name System  (DNS) \nserver is being updated.307 \nTemporary \nRedirectClient\nList of error codes API Version 2006-03-01 2802Amazon Simple Storage Service API Reference\nError code Description HTTP \nstatus \ncodeSOAP \nfault \ncode \npre\ufb01x\nRequestHeaderSecti \nonTooLargeThe request header and query \nparameters used to make the \nrequest exceed the maximum  all \nowed size.400 \nBad \nRequestClient\nRequestIsNotMultiP \nartContentA bucket POST request must be \nof the enclosure-type multipart/\nform-data.412 \nPrecondit \nion \nFailedClient\nRequestTimeout Your socket connection to the \nserver was not read from or \nwritten to  within the timeout \nperiod.400 \nBad \nRequestClient\nRequestTimeTooSkewed The di\ufb00erence between the \nrequest time and the server's time \nis too  large.403 \nForbiddenClient\nRequestTorrentOfBu \ncketErrorRequesting the torrent \ufb01le of a \nbucket is not permitted.400 \nBad \nRequestClient\nResponseInterrupted Returned to the original caller \nwhen an error is encountered while \nreading the WriteGetObjectResp \nonse body.400 \nBad \nRequestClient\nRestoreAlreadyInProgress The object restore is already in \nprogress.409 \nConflictClient\nList of error codes API Version 2006-03-01 2803Amazon Simple Storage Service API Reference\nError code Description HTTP \nstatus \ncodeSOAP \nfault \ncode \npre\ufb01x\nServerSideEncrypti \nonConfigurationNot \nFoundErrorThe server-side encryption \ncon\ufb01guration was not found.400 \nBad \nRequestClient\nServiceUnavailable Service is unable to handle \nrequest.503 \nService \nUnavailab \nleServer\nSignatureDoesNotMatch The request signature that the \nserver calculated does not match \nthe signature that you  provide \nd.", "Check your AWS secret access \nkey and signing method.", "For  more \ninformation, see REST Authentic \nation  and SOAP  Authentication.403 \nForbiddenClient\nSlowDown Please reduce your request rate.503 \nSlow \nDownServer\n503 SlowDown Slow Down 503 \nSlow \nDownServer\nTemporaryRedirect You are being redirected to the \nbucket while the Domain Name \nSystem (DNS) server is  being \nupdated.307 \nTemporary \nRedirectClient\nTokenCodeInvalidError The serial number and/or token \ncode you provided is not valid.400 \nBad \nRequestClient\nList of error codes API Version 2006-03-01 2804Amazon Simple Storage Service API Reference\nError code Description HTTP \nstatus \ncodeSOAP \nfault \ncode \npre\ufb01x\nTokenRefreshRequired The provided token must be \nrefreshed.400 \nBad \nRequestClient\nTooManyAccessPoints You have attempted to create \nmore access points than are \nallowed for an account.", "For  \n more information, see Amazon \nSimple Storage Service endpoints \nand  quotas  in the AWS General \nReference.400 \nBad \nRequestClient\nTooManyBuckets You have attempted to create \nmore buckets than are allowed \nfor an account. For more  inform \nation, see Amazon Simple Storage \nService endpoints and  quotas in \nthe AWS General Reference.400 \nBad \nRequestClient\nTooManyMultiRegion \nAccessPointregionsErrorYou have attempted to create a \nMulti-Region Access Point with \nmore Regions than  are allowed \nfor an account. For more informati \non, see Amazon Simple Storage \nService  endpoints and quotas in \nthe AWS General Reference.400 \nBad \nRequestClient\nList of error codes API Version 2006-03-01 2805Amazon Simple Storage Service API Reference\nError code Description HTTP \nstatus \ncodeSOAP \nfault \ncode \npre\ufb01x\nTooManyMultiRegion \nAccessPointsYou have attempted to create \nmore Multi-Region Access Points \nthan are allowed for  an account. \nFor more information, see Amazon \nSimple Storage Service endpoints \nand  quotas  in the AWS General \nReference.400 \nBad \nRequestClient\nUnauthorizedAccessError Applicable in China Regions only.", "\nReturned when a request is made \nto a bucket that doesn't have an \nICP license.", "For more information, \nsee ICP Recordal.403 \nForbiddenClient\nUnexpectedContent This request contains unsupported \ncontent.400 \nBad \nRequestClient\nUnexpectedIPError Applicable in China Regions only.", "\nThis request was rejected because \nthe IP was unexpected.403 \nForbiddenClient\nUnsupportedArgument The request contained an \nunsupported argument.400 \nBad \nRequestClient\nUnsupportedSignature The provided request is signed \nwith an unsupported STS Token \nversion or the signature version is \nnot supported.400 \nBad \nRequestClient\nList of error codes API Version 2006-03-01 2806Amazon Simple Storage Service API Reference\nError code Description HTTP \nstatus \ncodeSOAP \nfault \ncode \npre\ufb01x\nUnresolvableGrantB \nyEmailAddressThe email address that you \nprovided does not match any \naccount on record.400 \nBad \nRequestClient\nUserKeyMustBeSpecified The bucket POST request must \ncontain the speci\ufb01ed \ufb01eld name.", "\nIf it is speci\ufb01ed, check the order of \nthe \ufb01elds.400 \nBad \nRequestClient\nNoSuchAccessPoint The speci\ufb01ed access point does not \nexist.404 \nNot \nFoundClient\nInvalidTag Your request contains tag input \nthat is not valid.", "For example, your \nrequest might  contain duplicate \nkeys, keys or values that are too \nlong, or system  tags.400 \nBad \nRequestClient\nMalformedPolicy Your policy contains a principal \nthat is not valid.400 \nBad \nRequestClient\nList of SELECT Object Content Error Codes\nImportant\nAmazon S3 Select is no longer available to new customers. Existing customers of Amazon \nS3 Select can continue to use the feature as usual.", "Learn more\nList of SELECT Object Content Error Codes API Version 2006-03-01 2807Amazon Simple Storage Service API Reference\nThe following table contains special errors that SELECT Object Content  might return.", "For \ngeneral information about Amazon S3 errors and a list of error codes, see Error responses.\nError code Description HTTP status \ncodeSOAP fault \ncode pre\ufb01x\nAmbiguousFieldName The \ufb01eld name matches to \nmultiple \ufb01elds in the \ufb01le.", "Check \nthe SQL  expression and the \ufb01le, \nand try again.400 Client\nBusy The service is unavailable. Try \nagain later.503 Client\nCastFailed An attempt to convert from one \ndata type to another using   CAST\nfailed in the SQL expression.400 Client\nColumnTooLong The length of a column in the \nresult is greater than   maxCharsP \nerColumn  of 1 MB.400 Client\nCSVEscapingRecordD \nelimiterA quoted record delimiter was \nfound in the \ufb01le. To allow quoted  \n record delimiters, set AllowQuot \nedRecordDelimiter  to  \n  'TRUE' .400 Client\nCSVParsingError An error occurred while parsing \nthe CSV \ufb01le. Check the \ufb01le and \ntry  again.400 Client\nCSVUnescapedQuote An unescaped quote was found \nwhile parsing the CSV \ufb01le.", "To \nallow  quoted record delimiter \ns, set AllowQuotedRecordD \nelimiter  to   'TRUE' .400 Client\nList of SELECT Object Content Error Codes API Version 2006-03-01 2808Amazon Simple Storage Service API Reference\nError code Description HTTP status \ncodeSOAP fault \ncode pre\ufb01x\nEmptyRequestBody The request body cannot be \nempty.400 Client\nEvaluatorBindingDo \nesNotExistA column name or a path \nprovided does not exist in the \nSQL  expression.400 Client\nEvaluatorInvalidAr \ngumentsThere is an incorrect number of \narguments in the function call in \nthe  SQL expression.400 Client\nEvaluatorInvalidTi \nmestampFormatPatte \nrnThe timestamp format string in \nthe SQL expression is not  valid.400 Client\nEvaluatorInvalidTi \nmestampFormatPatte \nrnSymbolThe timestamp format pattern \ncontains a symbol in the SQL \nexpression that is not valid.400 Client\nEvaluatorInvalidTi \nmestampFormatPatte \nrnSymbolForParsingThe timestamp format pattern \ncontains a valid format symbol \nthat  cannot be applied to \ntimestamp parsing in the SQL \nexpression.400 Client\nEvaluatorInvalidTi \nmestampFormatPatte \nrnTokenThe timestamp format pattern \ncontains a token in the SQL \nexpression that is not valid.400 Client\nEvaluatorLikePatte \nrnInvalidEscapeSeq \nuenceAn argument given to the LIKE\nexpression was not  valid.400 Client\nEvaluatorNegativeL \nimitLIMIT must not be negative. 400 Client\nList of SELECT Object Content Error Codes API Version 2006-03-01 2809Amazon Simple Storage Service API Reference\nError code Description HTTP status \ncodeSOAP fault \ncode pre\ufb01x\nEvaluatorTimestamp \nFormatPatternDupli \ncateFieldsThe timestamp format pattern \ncontains multiple format speci\ufb01er \ns representing the timestamp \n\ufb01eld in the SQL expression.400 Client\nEvaluatorTimestamp \nFormatPatternHourC \nlockAmPmMismatchThe timestamp format pattern \ncontains a 12-hour hour of day \nformat  symbol but doesn't also \ncontain an AM/PM \ufb01eld, or it \ncontains a 24-hour  hour of day \nformat speci\ufb01er and contains an \nAM/PM \ufb01eld in the SQL  express \nion.400 Client\nEvaluatorUntermina \ntedTimestampFormat \nPatternTokenThe timestamp format pattern \ncontains an unterminated token \nin the  SQL expression.400 Client\nExpressionTooLong The SQL expression is too long.", "\nThe maximum byte-length for an \nSQL  expression is 256 KB.400 Client\nExternalEvalExcept \nionThe query cannot be evaluated.", "\nCheck the \ufb01le and try again.400 Client\nIllegalSqlFunction \nArgumentAn illegal argument was used in \nthe SQL function.400 Client\nIncorrectSqlFuncti \nonArgumentTypeAn incorrect argument type was \nspeci\ufb01ed in a function call in the  \n SQL expression.400 Client\nIntegerOverflow An integer over\ufb02ow or under\ufb02ow \noccurred in the SQL  expression.400 Client\nList of SELECT Object Content Error Codes API Version 2006-03-01 2810Amazon Simple Storage Service API Reference\nError code Description HTTP status \ncodeSOAP fault \ncode pre\ufb01x\nInternalError An internal error occurred. 500 Client\nInvalidCast An attempt to convert from one \ndata type to another using   CAST\nfailed in the SQL expression.400 Client\nInvalidColumnIndex The column index in the SQL \nexpression is not valid.400 Client\nInvalidCompression \nFormatThe \ufb01le is not in a supported \ncompression format.", "Only GZIP \nand  BZIP2 are supported.400 Client\nInvalidDataSource The data source type is not valid.", "\nOnly CSV, JSON, and Parquet are  \n supported.400 Client\nInvalidDataType The SQL expression contains a \ndata type that is not valid.400 Client\nInvalidExpressionT \nypeThe ExpressionType  value is \nnot valid. Only SQL  expressions \nare supported.400 Client\nInvalidFileHeaderI \nnfoThe FileHeaderInfo  value is \nnot valid.", "Only   NONE , USE, and\nIGNORE are  supported.400 Client\nInvalidJsonType The JsonType  value is not valid.", "\nOnly   DOCUMENT  and LINES are \nsupported.400 Client\nInvalidKeyPath The key path in the SQL expressio \nn is not valid.400 Client\nList of SELECT Object Content Error Codes API Version 2006-03-01 2811Amazon Simple Storage Service API Reference\nError code Description HTTP status \ncodeSOAP fault \ncode pre\ufb01x\nInvalidQuoteFields The QuoteFields  value is \nnot valid.", "Only   ALWAYS  and\nASNEEDED  are supported.400 Client\nInvalidRequestPara \nmeterThe value of a parameter in the\nSelectRequest  element is  \n not valid.", "Check the service API \ndocumentation and try again.400 Client\nInvalidScanRange The provided scan range is not \nvalid.400 Client\nInvalidTableAlias The SQL expression contains a \ntable alias that is not valid.400 Client\nInvalidTextEncoding The encoding type is not valid.", "\nOnly UTF-8 encoding is  supporte \nd.400 Client\nJSONParsingError An error occurred while parsing \nthe JSON \ufb01le.", "Check the \ufb01le and \ntry  again.400 Client\nLexerInvalidChar The SQL expression contains a \ncharacter that is not valid.400 Client\nLexerInvalidIONLit \neralThe SQL expression contains an \noperator that is not valid.400 Client\nLexerInvalidLiteral The SQL expression contains an \noperator that is not valid.400 Client\nLexerInvalidOperat \norThe SQL expression contains a \nliteral that is not valid.400 Client\nList of SELECT Object Content Error Codes API Version 2006-03-01 2812Amazon Simple Storage Service API Reference\nError code Description HTTP status \ncodeSOAP fault \ncode pre\ufb01x\nLikeInvalidInputs The argument given to the LIKE\nclause in the SQL  expression is \nnot valid.400 Client\nMalformedXML The XML provided was not \nwell formed or did not validate \nagainst our  published schema.", "\nCheck the service documentation \nand try again.400 Client\nMaxOperatorsExceed \nedFailed to parse SQL expressio \nn, try reducing complexity.", "For \nexample,  reduce number of \noperators used.400 Client\nMethodNotAllowed The speci\ufb01ed method is not \nallowed against this resource.405 \nMethod \nNot \nAllowedClient\nMissingRequiredPar \nameterThe SelectRequest  entity is \nmissing a required  parameter.", "\nCheck the service documentation \nand try again.400 Client\nMultipleDataSource \nsUnsupportedMultiple data sources are not \nsupported.400 Client\nNumberFormatError An error occurred while parsing a \nnumber.", "This error can be caused \nby  under\ufb02ow or over\ufb02ow of \nintegers.400 Client\nList of SELECT Object Content Error Codes API Version 2006-03-01 2813Amazon Simple Storage Service API Reference\nError code Description HTTP status \ncodeSOAP fault \ncode pre\ufb01x\nObjectSerializatio \nnConflictInputSerialization\nspeci\ufb01es more than one format \n(CSV,  JSON, or Parquet), or\nOutputSerialization\nspeci\ufb01es more  than one format \n(CSV or JSON). For InputSeri \nalization  and   OutputSer \nialization , you can specify \nonly one format  for each.400 Client\nOverMaxColumn The number of columns in \nthe result is greater than the \nmaximum  allowable number of \ncolumns.400 Client\nOverMaxParquetBloc \nkSizeThe Parquet \ufb01le is above the max \nrow group size.400 Client\nOverMaxRecordSize The length of a record in the \ninput or result is greater than the  \n  maxCharsPerRecord  limit of 1 \nMB.400 Client\nParquetParsingError An error occurred while parsing \nthe Parquet \ufb01le. Check the \ufb01le \nand  try again.400 Client\nParquetUnsupported \nCompressionCodecThe speci\ufb01ed Parquet compressi \non codec is not supported.400 Client\nParseAsteriskIsNot \nAloneInSelectListOther expressions are not allowed \nin the SELECT  list  when * is used \nwithout dot notation in the SQL  \n expression.400 Client\nList of SELECT Object Content Error Codes API Version 2006-03-01 2814Amazon Simple Storage Service API Reference\nError code Description HTTP status \ncodeSOAP fault \ncode pre\ufb01x\nParseCannotMixSqbA \nndWildcardInSelect \nListCannot mix [] and * in the same \nexpression in a SELECT  list in the \nSQL expression.400 Client\nParseCastArity The SQL expression CAST  has \nincorrect arity.400 Client\nParseEmptySelect The SQL expression contains an \nempty SELECT  clause.400 Client\nParseExpected2Toke \nnTypesThe expected token in the SQL \nexpression was not found.400 Client\nParseExpectedArgum \nentDelimiterThe expected argument delimiter \nin the SQL expression was not  \n found.400 Client\nParseExpectedDateP \nartThe expected date part in the \nSQL expression was not found.400 Client\nParseExpectedExpre \nssionThe expected SQL expression was \nnot found.400 Client\nParseExpectedIdent \nForAliasThe expected identi\ufb01er for the \nalias in the SQL expression was \nnot  found.400 Client\nParseExpectedIdent \nForAtThe expected identi\ufb01er for AT\nname in the SQL  expression was \nnot found.400 Client\nParseExpectedIdent \nForGroupNameGROUP is not supported in the \nSQL expression.400 Client\nParseExpectedKeywo \nrdThe expected keyword in the SQL \nexpression was not found.400 Client\nList of SELECT Object Content Error Codes API Version 2006-03-01 2815Amazon Simple Storage Service API Reference\nError code Description HTTP status \ncodeSOAP fault \ncode pre\ufb01x\nParseExpectedLeftP \narenAfterCastThe expected left parenthesis \nafter CAST in the SQL  expression \nwas not found.400 Client\nParseExpectedLeftP \narenBuiltinFunctio \nnCallThe expected left parenthesis \nin the SQL expression was not  \n found.400 Client\nParseExpectedLeftP \narenValueConstruct \norThe expected left parenthesis \nin the SQL expression was not  \n found.400 Client\nParseExpectedMember The SQL expression contains an \nunsupported use of   MEMBER .400 Client\nParseExpectedNumber The expected number in the SQL \nexpression was not found.400 Client\nParseExpectedRight \nParenBuiltinFuncti \nonCallThe expected right parenthesis \ncharacter in the SQL expression \nwas  not found.400 Client\nParseExpectedToken \nTypeThe expected token in the SQL \nexpression was not found.400 Client\nParseExpectedTypeN \nameThe expected type name in the \nSQL expression was not found.400 Client\nParseExpectedWhenC \nlauseThe expected WHEN  clause in the \nSQL expression was not  found.\nCASE is not supported.400 Client\nParseInvalidContex \ntForWildcardInSele \nctListThe use of * in the SELECT  list in \nthe SQL  expression is not valid.400 Client\nList of SELECT Object Content Error Codes API Version 2006-03-01 2816Amazon Simple Storage Service API Reference\nError code Description HTTP status \ncodeSOAP fault \ncode pre\ufb01x\nParseInvalidPathCo \nmponentThe SQL expression contains a \npath component that is not  valid.400 Client\nParseInvalidTypePa \nramThe SQL expression contains a \nparameter value that is not  valid.400 Client\nParseMalformedJoin JOIN is not supported in the SQL \nexpression.400 Client\nParseMissingIdentA \nfterAtThe expected identi\ufb01er after the \n@ symbol in the SQL expression \nwas  not found.400 Client\nParseNonUnaryAgreg \nateFunctionCallOnly one argument is supported \nfor aggregate functions in the \nSQL  expression.400 Client\nParseSelectMissing \nFromThe SQL expression contains a \nmissing FROM after the   SELECT\nlist.400 Client\nParseUnExpectedKey \nwordThe SQL expression contains an \nunexpected keyword.400 Client\nParseUnexpectedOpe \nratorThe SQL expression contains an \nunexpected operator.400 Client\nParseUnexpectedTerm The SQL expression contains an \nunexpected term.400 Client\nParseUnexpectedTok \nenThe SQL expression contains an \nunexpected token.400 Client\nParseUnknownOperat \norThe SQL expression contains an \noperator that is not valid.400 Client\nList of SELECT Object Content Error Codes API Version 2006-03-01 2817Amazon Simple Storage Service API Reference\nError code Description HTTP status \ncodeSOAP fault \ncode pre\ufb01x\nParseUnsupportedAl \niasThe SQL expression contains an \nunsupported use of   ALIAS .400 Client\nParseUnsupportedCa \nllWithStarOnly COUNT  with (*) as a \nparameter is  supported in the \nSQL expression.400 Client\nParseUnsupportedCa \nseThe SQL expression contains an \nunsupported use of   CASE .400 Client\nParseUnsupportedCa \nseClauseThe SQL expression contains an \nunsupported use of   CASE .400 Client\nParseUnsupportedLi \nteralsGroupByThe SQL expression contains an \nunsupported use of GROUP  BY .400 Client\nParseUnsupportedSe \nlectThe SQL expression contains an \nunsupported use of   SELECT .400 Client\nParseUnsupportedSy \nntaxThe SQL expression contains \nunsupported syntax.400 Client\nParseUnsupportedTo \nkenThe SQL expression contains an \nunsupported token.400 Client\nTruncatedInput Object decompression failed. \nCheck that the object is properly  \n compressed using the format \nspeci\ufb01ed in the request.400 Client\nUnauthorizedAccess You are not authorized to \nperform this operation.401 Client\nUnrecognizedFormat \nExceptionWe encountered a record type \nthat is not valid.400 Client\nList of SELECT Object Content Error Codes API Version 2006-03-01 2818Amazon Simple Storage Service API Reference\nError code Description HTTP status \ncodeSOAP fault \ncode pre\ufb01x\nUnsupportedFunction We encountered an unsupported \nSQL function.400 Client\nUnsupportedParquet \nTypeThe speci\ufb01ed Parquet type is not \nsupported.400 Client\nUnsupportedRangeHe \naderA range header is not supported \nfor this operation.400 Client\nUnsupportedScanRan \ngeInputScan range queries are not \nsupported on this type of object.400 Client\nUnsupportedSqlOper \nationWe encountered an unsupported \nSQL operation.400 Client\nUnsupportedSqlStru \nctureWe encountered an unsupport \ned SQL structure. Check the SQL  \n Reference.400 Client\nUnsupportedStorage \nClassWe encountered a storage class \nthat is not supported. Only  \nSTANDARD , STANDARD_IA , and \nONEZONE_IA  storage classes \nare supported.400 Client\nUnsupportedSyntax We encountered syntax that is \nnot valid.400 Client\nUnsupportedTypeFor \nQueryingYour query contains an unsupport \ned type for comparison (e.g. verif \nying that a Parquet INT96 column \ntype is greater than 0).400 Client\nValueParseFailure A timestamp parse failure \noccurred in the SQL expression.400 Client\nList of SELECT Object Content Error Codes API Version 2006-03-01 2819Amazon Simple Storage Service API Reference\nList of Replication-related error codes\nThe following table contains special errors that the Replication  operation might return.", "For \ngeneral information about Amazon S3 errors and a list of error codes, see Error responses.\nError code Description HTTP status \ncodeSOAP fault \ncode pre\ufb01x\nInvalidArgument This error might occur for the \nfollowing reasons:\n\u2022\nThe <Account>  element is \nempty.", "It must contain a valid \naccount  ID.\n\u2022\nThe AWS account speci\ufb01ed in \nthe <Account>  element must \nmatch the  destination bucket \nowner.\n\u2022\nReplicationTime-Status\nmust contain a  value.\n\u2022\nReplicationTime-Re \nplicationTimeValue\nmust  contain a value.\n\u2022\nReplication-Replic \nationTimeValue-Min \nutes   value must be 15.\n\u2022\nReplicationMetrics\nmust contain a   Status .\n\u2022\nReplicationMetrics\nmust contain an   EventThre \nshold .400 Client\nList of Replication-related error codes API Version 2006-03-01 2820Amazon Simple Storage Service API Reference\nError code Description HTTP status \ncodeSOAP fault \ncode pre\ufb01x\n\u2022\nEventThreshold-Rep \nlicationTimeValue- \nMinutes   value must be 15.\n\u2022\nRule ID must not contain \nnon-ASCII  characters.\nInvalidRequest This error might occur for the \nfollowing reasons:\n\u2022\nThe <Owner>  in <AccessCo \nntrolTranslation>  has \na  value, so the <Account>\nelement must be  speci\ufb01ed.\n\u2022\nThe <Account>  element is \nempty. It must contain a valid \naccount  ID.\n\u2022\nThe replication destination\nmust contain both   Replicati \nonTime  and Metrics ,  or \nneither.\n\u2022\nReplicationTime  and\nReplicationMetrics\nmust have the same  status.\n\u2022\nS3 Replication Time Control (S3 \nRTC) is not supported in this  \n AWS Region.400 Client\nList of Replication-related error codes API Version 2006-03-01 2821Amazon Simple Storage Service API Reference\nError code Description HTTP status \ncodeSOAP fault \ncode pre\ufb01x\nReplicationConfigu \nrationNotFoundErro \nrThere is no replication con\ufb01gura \ntion for this bucket.404 Not \nFoundClient\nList of Tagging-related error codes\nThe following table contains special errors that the TagResource , UntagResource , and\nListTagsForResource  operations might return for Storage Lens groups. For general information \nabout general Amazon S3 errors and a list of error codes, see Error responses.\nError Code Description HTTP \nStatus CodeSOAP Fault \nCode Pre\ufb01x\nInvalidRequest The AWS Region in the resource \nARN doesn't match the Region  \n that's speci\ufb01ed in this request.", "\nThe AWS account in the resource  \nARN doesn't match the account ID \nthat's speci\ufb01ed in this request. T \nhe AWS partition in the resourceA \nrn is invalid.400 Bad \nRequestNot \nsupported\nInvalidTag This request contains a tag key \nor value that isn't valid.", "Valid \ncharacters include the following \n:   [a-zA-Z+-=._:/] .", "Tag keys \ncan contain up to 128  characters. \nTag values can contain up to 256 \ncharacters. There are  duplicate \ntag keys in your request.", "User-\nde\ufb01ned tag keys can't  start with\naws: .400 Bad \nRequestNot \nsupported\nList of Tagging-related error codes API Version 2006-03-01 2822Amazon Simple Storage Service API Reference\nError Code Description HTTP \nStatus CodeSOAP Fault \nCode Pre\ufb01x\nNoSuchResource The speci\ufb01ed resource doesn't \nexist.404 Not \nFoundNot \nsupported\nTooManyTags The number of tags exceeds the \nlimit of 50 tags.400 Bad \nRequestNot \nsupported\nList of Amazon S3 on Outposts error codes\nThe following table contains special errors that an Amazon S3 on Outposts operation might return. \nFor general information about Amazon S3 errors and a list of error codes, see Error responses.\nError code Description HTTP status \ncodeSOAP fault \ncode pre\ufb01x\nBadRequest The bucket is in a transitional \nstate because of a previous \ndeletion attempt. Try again  later.400 Bad \nRequestNot \nsupported\nInvalidRequest This error might occur for the \nfollowing reasons:\n\u2022\nAmazon VPC con\ufb01guration is \nrequired.\n\u2022\nPublic access is not allowed on \nS3 on Outposts access points.400 Bad \nRequestClient\nInvalidOutpostState The request is not valid for the \ncurrent state of the Outpost.409 Con\ufb02ictNot \nsupported\nInvalidRequest The access point is not in a state \nwhere it can be deleted.400 Bad \nRequestNot \nsupported\nList of Amazon S3 on Outposts error codes API Version 2006-03-01 2823Amazon Simple Storage Service API Reference\nError code Description HTTP status \ncodeSOAP fault \ncode pre\ufb01x\nNoSuchOutpost The speci\ufb01ed Outpost does not \nexist.404 Not \nFoundNot \nsupported\nUnsupportedOperati \nonThe speci\ufb01ed action was not \nsupported.404 Not \nFoundNot \nsupported\nInsufficientCapaci \ntyInsu\ufb03cient capacity.", "507 Insu\ufb03ci \nent StorageNot \nsupported\nList of Amazon S3 Storage Lens error codes\nThe following table contains special errors that Amazon S3 Storage Lens operations might return. \nFor general information about general Amazon S3 errors and a list of error codes, see Error \nresponses.\nError code Description HTTP status \ncodeSOAP fault \ncode pre\ufb01x\nAccessDenied This Region is not supported as \na home Region for  S3 Storage \nLens.403 \nForbiddenNot \nsupported\nAccountNotAuthoriz \nedThis account not authorized to \nuse AWS Organizations. Use \nyour management  account or \ndelegated administrator account.403 \nForbiddenNot \nsupported\nActivityMetricsMus \ntEnabledActivity metrics must be enabled.400 Bad \nRequestNot \nsupported\nAWSOrganizationsNo \ntInUseExceptionThis account is not part of your \norganization.403 \nForbiddenNot \nsupported\nList of Amazon S3 Storage Lens error codes API Version 2006-03-01 2824Amazon Simple Storage Service API Reference\nError code Description HTTP status \ncodeSOAP fault \ncode pre\ufb01x\nDefaultConfigurati \nonDeleteForbiddenThe Default con\ufb01guration cannot \nbe deleted.403 \nForbiddenNot \nsupported\nDuplicateStorageLe \nnsGroupARNThere are two or more entries of \nthe same Storage Lens group  \n ARN in this con\ufb01guration.400 Bad \nRequestNot \nsupported\nEmptyExcludeContai \nnerThis error occurs for the following \nreasons:\n\u2022\nThe exclude container cannot \nbe empty.\n\u2022\nThe exclude container cannot \nhave zero buckets.\n\u2022\nThe exclude container cannot \nhave zero Regions.400 Bad \nRequestNot \nsupported\nEmptyExcludeElement You must specify a Storage Lens \ngroup with your Exclude  el \nement.400 Bad \nRequestNot \nsupported\nList of Amazon S3 Storage Lens error codes API Version 2006-03-01 2825Amazon Simple Storage Service API Reference\nError code Description HTTP status \ncodeSOAP fault \ncode pre\ufb01x\nEmptyIncludeContai \nnerThis error occurs for the following \nreasons:\n\u2022\nThe include container cannot \nbe empty.\n\u2022\nThe include container cannot \nhave zero buckets.\n\u2022\nThe include container cannot \nhave zero Regions.400 Bad \nRequestNot \nsupported\nInvalidAWSOrgArn There is a malformed AWS \nOrganizations ARN in the \ncon\ufb01guration.400 Bad \nRequestNot \nsupported\nEmptyIncludeElement You must specify a Storage Lens \ngroup with your Include  element.400 Bad \nRequestNot \nsupported\nInvalidBucketFilter Organization-level con\ufb01gurations \ndo not support bucket  \ufb01lters.400 Bad \nRequestNot \nsupported\nInvalidConfigId The con\ufb01guration ID is not valid. 400 Bad \nRequestNot \nsupported\nInvalidDestination The S3 bucket ARN is malformed.400 Bad \nRequestNot \nsupported\nInvalidEncryptionM \nethodOnly one encryption method can \nbe speci\ufb01ed.400 Bad \nRequestNot \nsupported\nInvalidFilterForDe \nfaultConfigurationThe default con\ufb01guration must \nnot include any \ufb01lters.400 Bad \nRequestNot \nsupported\nList of Amazon S3 Storage Lens error codes API Version 2006-03-01 2826Amazon Simple Storage Service API Reference\nError code Description HTTP status \ncodeSOAP fault \ncode pre\ufb01x\nInvalidIncludeExcl \nudeContainersYou can specify either an Include \ncontainer or an Exclude  container \nin a con\ufb01guration.", "You cannot \nspecify both in a  con\ufb01guration.400 Bad \nRequestNot \nsupported\nInvalidIncludeExcl \nudeElementsOnly one Include or Exclude \nelement is allowed.", "At least one  \n Include or Exclude element must \nbe present.400 Bad \nRequestNot \nsupported\nInvalidKMSEncrypti \nonKeyIdThe KMS key ID ARN is not valid.", "400 Bad \nRequestNot \nsupported\nInvalidMaximumPref \nixDepthMaxDepth  must be within the \nrange [1,10].400 Bad \nRequestNot \nsupported\nInvalidMinimumStor \nageBytesPercentageMinStorageBytesPer \ncentage  must be within the \nrange  [1.00,100.00].400 Bad \nRequestNot \nsupported\nInvalidOrganizatio \nnARNThe AWS Organizations ARN in \nthe con\ufb01guration is not valid.400 Bad \nRequestNot \nsupported\nInvalidOrganizatio \nnForDefaultConfigu \nrationThe default con\ufb01guration does \nnot support organization-level  \nmetrics.400 Bad \nRequestNot \nsupported\nInvalidRegionForDe \nfaultConfigurationThe speci\ufb01ed Region is not \nsupported for default  con\ufb01gurati \non.400 Bad \nRequestNot \nsupported\nInvalidRegionName The Region name is not valid.", "400 Bad \nRequestNot \nsupported\nInvalidStorageLens \nArnThe S3 Storage Lens ARN is not \nrequired in input.400 Bad \nRequestNot \nsupported\nList of Amazon S3 Storage Lens error codes API Version 2006-03-01 2827Amazon Simple Storage Service API Reference\nError code Description HTTP status \ncodeSOAP fault \ncode pre\ufb01x\nInvalidStorageLens \nGroupARNThis Storage Lens group ARN isn't \nvalid or only Storage Lens  group \ns in your account are allowed. \nAdditionally, you must follow  the \nStorage Lens group ARN structure \n: arn::s3:::storage- \nlens-group/  and adhere to \nthe 64 character limit.", "Storage \nLens group names can  also \ncontain only the following \ncharacters: a-z, A-Z, 0-9, hyphens  \n (-), and underscores (_).400 Bad \nRequestNot \nsupported\nMissingAccountLeve \nlActivityMetricsActivity metrics must be enabled \nat the account level when  activity \nmetrics are enabled at the bucket \nlevel.400 Bad \nRequestNot \nsupported\nMissingBucketLevel \nActivityMetricsActivity metrics must be enabled \nat the bucket level when  activ \nity metrics are enabled at the \naccount level.400 Bad \nRequestNot \nsupported\nMissingEncryptionM \nethodThe encryption method cannot be \nblank. Specify either   SSE-KMS  or\nSSE-S3 .400 Bad \nRequestNot \nsupported\nMissingPrefixLevel \nStorageMetricsStorage metrics at the pre\ufb01x level \nare mandatory when the  pre\ufb01x \nlevel is enabled.400 Bad \nRequestNot \nsupported\nOrganizationAccess \nDeniedThis account is not authorized to \nadd AWS Organizations.403 \nForbiddenNot \nsupported\nList of Amazon S3 Storage Lens error codes API Version 2006-03-01 2828Amazon Simple Storage Service API Reference\nError code Description HTTP status \ncodeSOAP fault \ncode pre\ufb01x\nOrgConfigurationNo \ntSupportedThe speci\ufb01ed Region does not \nsupport AWS Organizations in \nthe  con\ufb01guration.403 \nForbiddenNot \nsupported\nServiceNotEnabledF \norOrgThe S3 Storage Lens service-l \ninked role is not enabled for the  \n organization.403 \nForbiddenNot \nsupported\nStorageMetricsMust \nEnabledPre\ufb01x-level storage metrics must \nbe enabled.400 Bad \nRequestNot \nsupported\nTooManyBuckets The buckets container cannot \nhave more than 50 buckets.400 Bad \nRequestNot \nsupported\nTooManyRegions The Regions container cannot \nhave more than 50 Regions.400 Bad \nRequestNot \nsupported\nTooManyStorageLens \nGroupsYou can't attach more than 50 \nStorage Lens groups to your \nStorage Lens dashboard.400 Bad \nRequestNot \nsupported\nThe following table contains special errors that S3 Storage Lens groups operations might return. \nFor general information about general Amazon S3 errors and a list of error codes, see Error \nresponses.\nError code Description HTTP status \ncodeSOAP fault \ncode pre\ufb01x\nAccessDenied You don't have permission to \nperform Storage Lens group \nactions. This Region is not \nsupported as home Region for S3 \nStorage Lens groups.403 \nForbiddenNot \nsupported\nList of Amazon S3 Storage Lens error codes API Version 2006-03-01 2829Amazon Simple Storage Service API Reference\nError code Description HTTP status \ncodeSOAP fault \ncode pre\ufb01x\nConfigurationAlrea \ndyExistsThe speci\ufb01ed con\ufb01guration \nalready exists.409 \nConflictNot \nsupported\nDuplicateElement Tags must be unique.", "The\nAnd logical operator includes \nduplicate tag keys. The Or logical \noperator includes duplicate \ntags.", "Logical operator includes \nduplicate pre\ufb01xes or su\ufb03xes.400 Bad \nRequestNot \nsupported\nInvalidAge DaysLessThan  and DaysGreat \nerThan must  be positive \nnumbers.400 Bad \nRequestNot \nsupported\nInvalidFilter A \ufb01lter must include one of the \nfollowing elements:   And, Or,\nMatchAnyTag ,   MatchAnyP \nrefix , MatchAnySuffix ,  \n  MatchObjectAge ,   MatchObje \nctSize .400 Bad \nRequestNot \nsupported\nInvalidLogicalOper \natorAt least two sub elements \nmust be present in the logical \noperators And or Or.400 Bad \nRequestNot \nsupported\nInvalidMatchAnyPre \nfixThe MatchAnyPrefix\nparameter can\u2019t be empty.400 Bad \nRequestNot \nsupported\nInvalidMatchAnySuf \nfixThe MatchAnySuffix\nparameter can't be empty.400 Bad \nRequestNot \nsupported\nInvalidMatchAnyTag The MatchAnyTag  parameter \ncan't be empty.400 Bad \nRequestNot \nsupported\nList of Amazon S3 Storage Lens error codes API Version 2006-03-01 2830Amazon Simple Storage Service API Reference\nError code Description HTTP status \ncodeSOAP fault \ncode pre\ufb01x\nInvalidMatchObject \nAgeThe MatchObjectAge\nparameter can't be empty.400 Bad \nRequestNot \nsupported\nInvalidMatchObject \nSizeThe MatchObjectSize\nparameter can't be empty.400 Bad \nRequestNot \nsupported\nInvalidName Storage Lens group Name \nparameter must be between 1 \nand 64  characters. The Storage \nLens group Name  parameter \nmust  use the ^[a-zA-Z0-9\\-\n_]+$ pattern.400 Bad \nRequestNot \nsupported\nInvalidNumericComb \ninationThis object age or object size \ncombination isn't valid.400 Bad \nRequestNot \nsupported\nInvalidPrefix The maximum length of a pre\ufb01x \nis 1,024 characters.", "The pre\ufb01x \nstring can't be empty.400 Bad \nRequestNot \nsupported\nInvalidSize BytesLessThan  and\nBytesGreaterThan  must be \npositive numbers.", "The maximum \nobject size can't exceed 5 TB. \n The minimum object size can't be \ngreater than or equal to 5  TB.400 Bad \nRequestNot \nsupported\nInvalidSuffix The maximum length of a su\ufb03x is \n1,024 characters.", "The su\ufb03x string \ncan't be empty.400 Bad \nRequestNot \nsupported\nList of Amazon S3 Storage Lens error codes API Version 2006-03-01 2831Amazon Simple Storage Service API Reference\nError code Description HTTP status \ncodeSOAP fault \ncode pre\ufb01x\nInvalidTag The object tag key can\u2019t exceed \n128 characters.", "The object tag  \n key string can't be null or empty.", "\nThe maximum length of a tag \nvalue  is 256 characters. The \nobject tag key contains character \ns that  aren't valid. The object tag \nkey must contain only a-z, A-Z, \n0-9,  spaces, and the following \ncharacters:   ^(_.:/=+\\-@]*)$ .400 Bad \nRequestNot \nsupported\nMismatchedName The name speci\ufb01ed in the request \ndoesn't match the Storage Lens \ngroup name.400 Bad \nRequestNot \nsupported\nTooManyConfigurati \nonsYou have attempted to create \nmore Storage Lens group \ncon\ufb01gurations than the 50 \nallowed.400 Bad \nRequestNot \nsupported\nTooManyElements The Element exceeds the \nmaximum number of elements \nallowed within a logical operator.", "\nOnly 10 pre\ufb01xes, su\ufb03xes, or tags \nare allowed.", "400 Bad \nRequestNot \nsupported\nList of Amazon S3 Object Lambda error codes\nThe following table contains special errors that S3 Object Lambda might return. For information \nabout general Amazon S3 errors and a list of error codes, see Error responses.\nError responses received from the supporting access points during non-GetObject  requests are \nsent to the caller unaltered.\nList of Amazon S3 Object Lambda error codes API Version 2006-03-01 2832Amazon Simple Storage Service API Reference\nError code Description HTTP status \ncode\nLambdaInvalidResponse Returned to the original caller \nwhen   WriteGetObjectResp \nonse responds with   Validatio \nnError to AWS Lambda.\nSee the ValidationError\nmessage for more details. Not  all \ncases of ValidationError  result \nin a   LambdaInvalidResponse\nerror.400 Bad \nRequest\nLambdaInvocationFa \niledLambda function invocation failed.\nCallers might receive the following \nerror when S3 Object Lambda is  \n unable to successfully invoke the \ncon\ufb01gured Lambda function.\nThe error message might contain \ndetails about an eventual error  retu \nrned by the AWS Lambda service \nwhen invoking the function (for  \n example, status code, error code, \nerror message and request  ID).400 Bad \nRequest\nLambdaNotFound The AWS Lambda function was not \nfound.\nThe  con\ufb01gured Lambda function, \nversion, or alias was not found \nwhen  attempting to invoke it. \nEnsure that the S3 Object Lambda \nAccess  Point con\ufb01guration points \nto the correct Lambda function  A \nRN.404 Not \nFound\nList of Amazon S3 Object Lambda error codes API Version 2006-03-01 2833Amazon Simple Storage Service API Reference\nError code Description HTTP status \ncode\nThe error message might contain \ndetails about an  eventual error \nreturned by the AWS Lambda \nservice when invoking the  functi \non (for example, status code, error \ncode, error message and  request \nID).\nLambdaPermissionError The caller is not authorized to \ninvoke the Lambda function.\nThe caller must have permission \nto invoke the Lambda function. \nCheck the policies attached to the \ncaller and ensure that they've  been \nallowed to use lambda:Invoke\nfor the con\ufb01gured  function.\nThe error message might contain \ndetails about an eventual error  retu \nrned by the AWS Lambda service \nwhen invoking the function (for  \n example, status code, error code, \nerror message and request  ID).403 \nForbidden\nList of Amazon S3 Object Lambda error codes API Version 2006-03-01 2834Amazon Simple Storage Service API Reference\nError code Description HTTP status \ncode\nLambdaResponseNotR \neceivedThe Lambda function exited \nwithout successfully calling  \n  WriteGetObjectResponse .\nGetObject  response data is \nprovided by the Lambda function \nby calling the   WriteGetO \nbjectResponse  API operation \n.", "The Amazon CloudWatch  logs \nfor the function might provide \nmore insight into why the  functi \non did not successfully call this API \noperation despite  exiting normally.500 \nInternal \nService \nError\nLambdaRuntimeError The Lambda function failed during \nexecution.\nAn  explicit error was received from \nthe Lambda function.", "For details  \n about the failure, check the AWS \nCloudFormation logs.500 \nInternal \nService \nError\nLambdaTimeout The Lambda function did not \nrespond in the allowed  time.\nThe Lambda function failed to \ncomplete its call to   WriteGetO \nbjectResponse  within 60 \nseconds.500 \nInternal \nService \nError\nList of Amazon S3 Object Lambda error codes API Version 2006-03-01 2835Amazon Simple Storage Service API Reference\nError code Description HTTP status \ncode\nSlowDown Reduce your request rate for \noperations involving AWS Lambda.\nThe function invocation was \nthrottled by  AWS Lambda, perhaps \nbecause it has reached its con\ufb01gure \nd concurrency  limitation. For \nmore information, see Managing   \nconcurrency for a Lambda function\nin the   AWS Lambda Developer \nGuide .\nThe error  message might contain \ndetails about an eventual error \nreturned by  the AWS Lambda \nservice when invoking the function \n(for example,  status code, error \ncode, error message and request \nID).503 Slow \nDown\nValidationError Validation errors might be returned \nfrom the   WriteGetObjectResp \nonse API operation and can occur  \nfor numerous reasons.", "See the error \nmessage for more details.400 Bad \nRequest\nList of Amazon S3 asynchronous error codes\nThe following table contains special errors that asynchronous requests might return. For general \ninformation about Amazon S3 errors and a list of error codes, see Error responses.\nThese errors are returned when you query about the state of an asynchronous request, such \nas by using DescribeMultiRegionAccessPointOperation . Because these requests are \nasynchronous, all of these errors have a status code of 200 OK .\nList of Amazon S3 asynchronous error codes API Version 2006-03-01 2836Amazon Simple Storage Service API Reference\nError code Description HTTP status \ncode\nAccessDenied Access denied.", "200 OK\nInternalErrors An internal server error occurred.200 OK\nMalformedPolicy The speci\ufb01ed policy syntax is not \nvalid.200 OK\nMultiRegionAccessP \nointAlreadyOwnedBy \nYouYou already have a Multi-Region \nAccess Point with the same name.200 OK\nMultiRegionAccessP \nointModifiedByAnot \nherRequestThe action failed because another \nrequest is modifying the speci\ufb01ed \nresource. Try  resubmitting your \nrequest after the previous request \nhas been  completed.200 OK\nMultiRegionAccessP \nointNotReadyThe speci\ufb01ed Multi-Region Access \nPoint is not ready to be updated.200 OK\nMultiRegionAccessP \nointSameBucketRegionThe buckets used to create a Multi-\nRegion Access Point cannot be in \nthe same Region.200 OK\nMultiRegionAccessP \nointUnsupportedReg \nionOne of the buckets supplied to \ncreate the Multi-Region Access \nPoint is in a Region that is not \nsupported.200 OK\nNoSuchBucket The speci\ufb01ed bucket does not exist.200 OK\nNoSuchMultiRegionA \nccessPointThe speci\ufb01ed Multi-Region Access \nPoint does not exist.200 OK\nList of Amazon S3 asynchronous error codes API Version 2006-03-01 2837Amazon Simple Storage Service API Reference\nList of Amazon S3 Access Grants Error Codes\nThe following table contains special errors that S3 Access Grants requests might return. For general \ninformation about Amazon S3 errors and a list of error codes, see Error responses.\nError Code Description HTTP Status \nCode\nAccessGrantAlready \nExistsThe speci\ufb01ed access grant already \nexists409\nAccessGrantsInstan \nceAlreadyExistsAccess Grants Instance already \nexists409\nAccessGrantsInstan \nceNotEmptyErrorPlease clean up locations before \ndeleting the access grants instance400\nAccessGrantsInstan \nceNotExistsErrorAccess Grants Instance does not \nexist404\nAccessGrantsInstan \nceResourcePolicyNo \ntExistsAccess Grants Instance Resource \nPolicy does not exist404\nAccessGrantsLocati \nonAlreadyExistsErrorThe speci\ufb01ed access grants location \nalready exists409\nAccessGrantsLocati \nonNotEmptyErrorPlease clean up access grants \nbefore deleting access grants \nlocation400\nAccessGrantsLocati \nonsQuotaExceededEr \nrorThe access grants location quota \nhas been exceeded.", "Access Grants \nLocations Quota: <value> .", "Please \nreach out to S3 if an increase is \nrequired.409\nAccessGrantsQuotaE \nxceededErrorThe access grants quota has been \nexceeded. Access Grants Quota:409\nList of Amazon S3 Access Grants Error Codes API Version 2006-03-01 2838Amazon Simple Storage Service API Reference\nError Code Description HTTP Status \nCode\n<value>.", "Please reach out to S3 if \nan increase is required.\nInvalidTag There are duplicate tag keys in your \nrequest.", "Remove the duplicate tag \nkeys and try again.400\nInvalidAccessGrant The speci\ufb01ed Access Grant is invalid400\nInvalidAccessGrant \nsLocationThe speci\ufb01ed Access Grants \nLocation is invalid400\nInvalidIamRole The speci\ufb01ed IAM Role is invalid400\nInvalidIdentityCen \nterInstanceThe speci\ufb01ed identity center \ninstance is invalid400\nInvalidResourcePolicy The speci\ufb01ed Resource Policy is \ninvalid400\nInvalidResourcePolicy The speci\ufb01ed Resource Policy is \ninvalid400\nInvalidTag This request contains a tag key \nor value that isn't valid.", "Valid \ncharacters include the following: [a-\nzA-Z+-=._:/].", "Tag keys can contain \nup to 128 characters.", "Tag values \ncan contain up to 256 characters.400\nNoSuchAccessGrantE \nrrorThe speci\ufb01ed access grant does not \nexist404\nNoSuchAccessGrants \nLocationErrorThe speci\ufb01ed access grants location \ndoes not exist404\nList of Amazon S3 Access Grants Error Codes API Version 2006-03-01 2839Amazon Simple Storage Service API Reference\nError Code Description HTTP Status \nCode\nAccessDenied You do not have <requested \npermission>  permissions to the \nrequested S3 Pre\ufb01x: <requested \ntarget>403 \nForbiddenClient\nStsNotAuthorizedError An error occurred (StsNotAut \nhorizedError ) when calling \nthe GetDataAccess operation: \nUser: access-grants.s3.a \nmazonaws.com  is not authorized \nto perform: sts:AssumeRole  on \nresource: <IAM Role ARN>403\nStsPackedPolicyToo \nLargeErrorAn error occurred (StsPacked \nPolicyTooLargeError ) when \ncalling the GetDataAccess operation \n: Serialized token too large for \nsession400\nStsValidationError The error message varies depending \non the validation error.400\nInvalidTags Tag keys cannot start with AWS \nreserved pre\ufb01x for system tags.\"400\nTooManyTags The number of tags exceeds the \nlimit of 50 tags. Remove some tags \nand try again.400\nAmazon S3 error best practices\nMany error responses contain additional structured data meant to be read and understood by a \ndeveloper diagnosing programming errors. For example, if you send a Content-MD5 header with a \nREST PUT request that doesn't match the digest calculated on the server, you receive a BadDigest \nAmazon S3 error best practices API Version 2006-03-01 2840Amazon Simple Storage Service API Reference\nerror.", "The error response also includes as detail elements the digest we calculated, and the digest \nyou told us to expect.", "During development, you can use this information to diagnose the error.", "In \nproduction, a well-behaved program might include this information in its error log.\nWhen designing an application for use with Amazon S3, it is important to handle Amazon S3 errors \nappropriately. This section describes issues to consider when designing your application.\nRetry InternalErrors\nInternal errors are errors that occur within the Amazon S3 environment.\nRequests that receive an InternalError response might not have processed. For example, if a PUT \nrequest returns InternalError, a subsequent GET might retrieve the old value or the updated value.\nIf Amazon S3 returns an InternalError response, retry the request.\nTune application for repeated SlowDown errors\nAs with any distributed system, S3 has protection mechanisms which detect intentional or \nunintentional resource over-consumption and react accordingly.", "SlowDown errors can occur when \na high request rate triggers one of these mechanisms. Reducing your request rate will decrease \nor eliminate errors of this type.", "Generally speaking, most users will not experience these errors \nregularly; however, if you would like more information or are experiencing high or unexpected \nSlowDown errors, please post to our Amazon S3 developer forum or sign up for AWS Support\nhttps://aws.amazon.com/premiumsupport/.\nIsolate errors\nNote\nSOAP support over HTTP is deprecated, but it is still available over HTTPS. New Amazon S3 \nfeatures will not be supported for SOAP. We recommend that you use either the REST API \nor the AWS SDKs.\nAmazon S3 provides a set of error codes that are used by both the SOAP and REST API. The SOAP \nAPI returns standard Amazon S3 error codes.", "The REST API is designed to look like a standard HTTP \nserver and interact with existing HTTP clients (e.g., browsers, HTTP client libraries, proxies, caches, \nRetry InternalErrors API Version 2006-03-01 2841Amazon Simple Storage Service API Reference\nand so on).", "To ensure the HTTP clients handle errors properly, we map each Amazon S3 error to an \nHTTP status code.\nHTTP status codes are less expressive than Amazon S3 error codes and contain less information \nabout the error. For example, the NoSuchKey  and NoSuchBucket  Amazon S3 errors both map to \nthe HTTP 404 Not Found  status code.\nAlthough the HTTP status codes contain less information about the error, clients that understand \nHTTP, but not the Amazon S3 API, will usually handle the error correctly.\nTherefore, when handling errors or reporting Amazon S3 errors to end users, use the Amazon S3 \nerror code instead of the HTTP status code as it contains the most information about the error. \nAdditionally, when debugging your application, you should also consult the human readable \n<Details> element of the XML error response.\nIsolate errors API Version 2006-03-01 2842Amazon Simple Storage Service API Reference\nAWS Glossary\nFor the latest AWS terminology, see the AWS glossary in the AWS Glossary Reference.\nAPI Version 2006-03-01 2843Amazon Simple Storage Service API Reference\nAmazon S3 Resources\nFollowing is a table that lists related resources that you'll \ufb01nd useful as you work with this service.\nResource Description\nAmazon Simple Storage Service \nUser GuideThe getting started guide provides a quick tutorial of the \nservice based on a simple use  case.\nAmazon Simple Storage Service \nUser GuideThe developer guide describes how to accomplish tasks \nusing Amazon S3 operations.\nAmazon S3 Technical FAQ The FAQ covers the top 20 questions developers have \nasked about this  product.\nAmazon S3 Release  Notes The Release Notes give a high-level overview of the \ncurrent release. They  speci\ufb01cally note any new features, \ncorrections, and known issues.\nTools for Amazon Web Services A central starting point to \ufb01nd documentation, code \nsamples, release  notes, and other information to help \nyou build innovative applications with  AWS SDKs and \ntools.\nAWS Management Console The console allows you to perform most of the functions \nof Amazon S3 without  programming.\nDiscussion Forums A community-based forum for developers to discuss \ntechnical questions related to Amazon Web Services.\nAWS Support  Center The home page for AWS Technical Support, including \naccess to our  Developer Forums, Technical FAQs, Service \nStatus page, and Premium Support. \nAWS Support The primary web page for information about AWS \nSupport, a one-on-one, fast-response support channel \nto help you build and run  applications on AWS Infrastru \ncture Services.\nAPI Version 2006-03-01 2844Amazon Simple Storage Service API Reference\nResource Description\nAmazon S3 product informationThe primary web page for information about Amazon \nS3.\nContact Us A central contact point for inquiries concerning AWS \nbilling, account,  events, abuse, etc.\nConditions of Use Detailed information about the copyright and trademark \nusage at Amazon.com and other topics.\nAPI Version 2006-03-01 2845Amazon Simple Storage Service API Reference\nDocument History\nThe following table describes the important changes in each release of the Amazon Simple Storage \nService API Reference up to March 27, 2019. For changes after March 27, 2019, see the consolidated\nDocument History in the Amazon Simple Storage Service User Guide.\n\u2022API version: 2006-03-01\n\u2022Latest documentation update:  March 27, 2019\nChange Description Release \nDate\nNew archive storage \nclassAmazon S3 now o\ufb00ers a new archive storage class, \nDEEP_ARCHIVE, for storing rarely accessed objects. Fo \nr more information, see Storage Classes  in the Amazon \nSimple Storage Service User Guide.March 27, \n2019\nSupport for Parquet-f \normatted Amazon S3 \ninventory \ufb01lesAmazon S3 now supports the Apache Parquet  (Parquet)\nformat in addition to the Apache optimized row columnar \n(ORC) and comma-separated values (CSV) \ufb01le formats \nfor inventory output \ufb01les.", "For  more information, see\nAmazon S3  Inventory in the Amazon Simple Storage \nService User Guide.\nThe following APIs were updated accordingly:\n\u2022\nGetBucketInventoryCon\ufb01guration\n\u2022\nPutBucketInventoryCon\ufb01guration December \n04, 2018\nPUT directly to the \nGLACIER storage classThe Amazon S3 PUT and related operations now support \nspecifying GLACIER as the storage class when creating \nobjects. Previously, you had to transition to the GLACIER \nstorage class from another Amazon S3 storage class. For \nmore information about the GLACIER storage class, seeNovember \n26, 2018\nAPI Version 2006-03-01 2846Amazon Simple Storage Service API Reference\nChange Description Release \nDate\nStorage Classes  in the Amazon Simple Storage Service \nUser Guide .\nThe following APIs were updated accordingly:\n\u2022\nPutObject \n\u2022\nPOST Object\n\u2022\nCopyObject\n\u2022\nCreateMultipartUpload\nObject LockAmazon S3 now supports locking objects using a Write \nOnce Read Many (WORM) model.", "You can  lock objects \nfor a de\ufb01nite period of time using a retention period \nor inde\ufb01nitely using a legal hold.", "For more information \nabout Amazon S3 Object  Lock, see Locking Objects in \nthe Amazon Simple Storage Service User Guide.\nThe following APIs were  updated for S3 Object Lock:\n\u2022\nPutObject\n\u2022\nGetObject\n\u2022\nHeadObject\n\u2022\nCreateBucket\n\u2022\nHeadBucketNovember \n26, 2018\nAPI Version 2006-03-01 2847Amazon Simple Storage Service API Reference\nChange Description Release \nDate\nNew storage class Amazon S3 now o\ufb00ers a new storage class named \nINTELLIGENT_TIERING that is for storing data  that has \nchanging or unknown access patterns. For more informati \non, see   Storage  Classes  in the Amazon Simple Storage \nService User Guide.\nThe following APIs were updated accordingly:\n\u2022\n PutObject \n\u2022\nPOST Object\n\u2022\nCopyObject\n\u2022\nCreateMultipartUploadNovember \n26, 2018\nBlock Public AccessAmazon S3 now includes the ability to block public access \nto buckets and objects on a per-bucket or account-wide \nbasis. For more information, see Using  Amazon S3 Block \nPublic Access  in the   Amazon Simple Storage Service User \nGuide .November \n15, 2018\nAPI Version 2006-03-01 2848Amazon Simple Storage Service API Reference\nChange Description Release \nDate\nFiltering enhanceme \nnts in cross-region \nreplication (CRR) rulesIn a CRR rule con\ufb01guration, you can specify an object \n\ufb01lter to choose a subset of  objects to apply the rule to.", "\nPreviously, you could \ufb01lter only on an  object key pre\ufb01x. \nIn this release, you can \ufb01lter on an object key  pre\ufb01x, \none or more object tags, or both.", "For more information, \nsee   Replication  Con\ufb01guration Overview in the   Amazon \nSimple Storage Service User Guide.\nThe following APIs are updated accordingly:\n\u2022\n PutBucketReplication \n\u2022\nGetBucketReplication\n\u2022\nDeleteBucketReplicationSeptember \n19, 2018\nNew storage class Amazon S3 now o\ufb00ers a new storage class, ONEZONE_I \nA (IA, for infrequent access) for storing objects. For more \ninformation, see Storage Classes  in the Amazon Simple \nStorage Service User Guide.April 4, \n2018\nAmazon S3 SelectAmazon S3 Select is now generally available.", "This feature \nretrieves object  content based on an SQL expression.", "For \nmore information, see  Selecting Content from  Objects in \nthe Amazon Simple Storage Service User Guide.\nThe following API has been updated:\n\u2022\n SelectObjectContent April 4, \n2018\nAPI Version 2006-03-01 2849Amazon Simple Storage Service API Reference\nChange Description Release \nDate\nAsia Paci\ufb01c (Osaka-Lo \ncal) RegionAmazon S3 is now available in the Asia Paci\ufb01c (Osaka-\nLocal) Region. For more information about Amazon S3 \nRegions and endpoints, see Regions and Endpoints in the  \n  AWS General Reference.\nImportant\nYou can use the Asia Paci\ufb01c (Osaka-Local) Region \nonly in conjunction with the Asia Paci\ufb01c (Tokyo) \nRegion. To request access to Asia Paci\ufb01c (Osaka-\nLocal) Region, contact your sales representative.February \n12, 2018\nEurope (Paris) RegionAmazon S3 is now available in the Europe (Paris) Region. \nFor more information about Amazon S3 regions and \nendpoints, see Regions and Endpoints in the   AWS \nGeneral Reference.December \n18, 2017\nChina (Ningxia) \nRegionAmazon S3 is now available in the China (Ningxia) \nRegion. For more information about Amazon S3 regions \nand endpoints, see Regions and Endpoints in the   AWS \nGeneral Reference.December \n11, 2017\nQuerying archives \nwith SQLAmazon S3 now supports querying S3 Glacier data \narchives with SQL.", "For more information, see  Querying \nArchived  Objects in the Amazon Simple Storage Service \nUser Guide .\nThe following API changed:\n\u2022\n RestoreObject November \n29, 2017\nAPI Version 2006-03-01 2850Amazon Simple Storage Service API Reference\nChange Description Release \nDate\nSELECT Object \nContent (Preview)Amazon S3 now supports the SELECT Object Content \nfunctionality as part of a Preview program.", "This feature \nretrieves object content based on an SQL expression.\nThe following API has been added:\n\u2022\n SelectObjectContent November \n29, 2017\nSupport for ORC-\nformatted Amazon S3 \ninventory \ufb01lesAmazon S3 now supports the Apache optimized row \ncolumnar (ORC) format in addition to comma-separated \nvalues (CSV) \ufb01le format for inventory output \ufb01les.", "For \nmore information, see Amazon S3 Inventory in the\nAmazon Simple Storage Service User Guide.\nThe following APIs are updated accordingly:\n\u2022\n GetBucketInventoryCon\ufb01guration \n\u2022\nPutBucketInventoryCon\ufb01gurationNovember \n17, 2017\nAPI Version 2006-03-01 2851Amazon Simple Storage Service API Reference\nChange Description Release \nDate\nDefault encryption \nfor S3 bucketsAmazon S3 default encryption provides a way to set the \ndefault encryption behavior for an S3  bucket.", "You can \nset default encryption on a bucket so that all objects  \n are encrypted when they are stored in the bucket.", "The \nobjects are  encrypted using server-side encryption with \neither Amazon S3-managed keys  (SSE-S3) or AWS KMS-\nmanaged keys (SSE-KMS). For more information, see  \n  Amazon S3 Default  Encryption for S3 Buckets in the  \n  Amazon Simple Storage Service User Guide.\nThe following APIs are updated accordingly:\n\u2022\nDeleteBucketEncryption\n\u2022\n GetBucketEncryption \n\u2022\nPutBucketEncryptionNovember \n06, 2017\nEncryption status in \nAmazon S3 inventoryAmazon S3 now supports including encryption status in \nAmazon S3 inventory so you can see how your  objects \nare encrypted at rest for compliance auditing or other \npurposes. You can also con\ufb01gure to encrypt Amazon \nS3 inventory with server-side  encryption (SSE) or SSE-\nKMS so that all inventory \ufb01les are encrypted accordingl \ny. For more information, see Amazon S3 Inventory in  the\nAmazon Simple Storage Service User Guide.\nThe following APIs are updated accordingly:\n\u2022\n GetBucketInventoryCon\ufb01guration \n\u2022\nPutBucketInventoryCon\ufb01gurationNovember \n06, 2017\nAPI Version 2006-03-01 2852Amazon Simple Storage Service API Reference\nChange Description Release \nDate\nCross-region replicati \non (CRR) enhanceme \nntsCross-region replication (CRR) now supports the \nfollowing:\n\u2022\nIn a cross-account scenario, you can add a CRR \ncon\ufb01guration to change replica  ownership to the AWS \naccount that owns the destination bucket. For more \ninformation, see CRR: Change Replica  Owner in the\nAmazon Simple Storage Service User Guide.\n\u2022\nBy default, Amazon S3 does not replicate objects in \nyour source bucket that are created  using server-si \nde encryption using AWS KMS-managed keys. In your  \n CRR con\ufb01guration, you can now direct Amazon S3 \nto replicate these  objects. For more information, see\nCRR: Replicating Objects Created with SEE Using AWS  \n KMS-Managed Encryption Keys in the   Amazon Simple \nStorage Service User Guide.\nThe following APIs are updated accordingly:\n\u2022\n GetBucketReplication \n\u2022\nPutBucketReplicationNovember \n06, 2017\nEurope (London) \nRegionAmazon S3 is now available in the Europe (London) \nRegion.", "For more information about Amazon S3 regions \nand endpoints, see Regions and Endpoints in the   AWS \nGeneral Reference.December \n13, 2016\nCanada (Central) \nRegionAmazon S3 is now available in the Canada (Central) \nRegion. For more information about Amazon S3 regions \nand endpoints, see Regions and Endpoints in the   AWS \nGeneral Reference.December \n8, 2016\nAPI Version 2006-03-01 2853Amazon Simple Storage Service API Reference\nChange Description Release \nDate\nObject tagging \nsupportAmazon S3 now supports object tagging.", "The following \nnew API operations support object tagging:\n\u2022PutObjectTagging\n\u2022GetObjectTagging\n\u2022DeleteObjectTagging\nIn addition, other API operations are updated to support \nobject tagging.", "For more information, see   Object \nTagging in the Amazon Simple Storage Service User Guide.November \n29, 2016\nS3 lifecycle now \nsupports object tag \nbased \ufb01lterAmazon S3 now supports tag-based \ufb01ltering in lifecycle \ncon\ufb01guration.", "You can now specify a lifecycle rule, in \nwhich you can specify a key pre\ufb01x, one or more  object \ntags, or a combination of both, to select a subset of \nobjects to  which the lifecycle rule applies.", "For more \ninformation, see Object Lifecycle Managementin the\nAmazon Simple Storage Service User Guide.\nAmazon S3 now supports Expedited and Bulk data \nretrievals in addition to Standard retrievals when \nrestoring objects archived to S3 Glacier.November \n29, 2016\nAPI Version 2006-03-01 2854Amazon Simple Storage Service API Reference\nChange Description Release \nDate\nCloudWatch request \nmetrics for bucketsAmazon S3 now supports CloudWatch metrics for \nrequests made on buckets. The following new API \noperations support con\ufb01guring request metrics:\n\u2022DeleteBucketMetricsCon\ufb01guration\n\u2022GetBucketMetricsCon\ufb01guration\n\u2022PutBucketMetricsCon\ufb01guration\n\u2022ListBucketMetricsCon\ufb01gurations\nFor more information, see   Monitoring Metrics with \nAmazon CloudWatch in the Amazon Simple Storage \nService User Guide.November \n29, 2016\nAmazon S3 InventoryAmazon S3 now supports storage inventory. Amazon S3 \ninventory provides a \ufb02at-\ufb01le output of  your objects and \ntheir corresponding metadata on a daily or weekly basis  \n for an S3 bucket or a shared pre\ufb01x (that is, objects that \nhave names that begin  with a common string).\nThe following new API operations are for storage \ninventory:\n\u2022DeleteBucketInventoryCon\ufb01guration\n\u2022GetBucketInventoryCon\ufb01guration\n\u2022PutBucketInventoryCon\ufb01guration\n\u2022ListBucketInventoryCon\ufb01gurations\nFor more information, see   Amazon S3 Storage Inventory\n in the Amazon Simple Storage Service User Guide.November \n29, 2016\nAPI Version 2006-03-01 2855Amazon Simple Storage Service API Reference\nChange Description Release \nDate\nAmazon S3 Analytics \n\u2013 Storage Class \nAnalysisThe new Amazon S3 analytics \u2013 storage class analysis \nfeature observes data access patterns to help you \ndetermine when to transition less frequently accessed \nSTANDARD  storage to the STANDARD_IA (IA, for \ninfrequent access) storage class.", "After  storage class \nanalysis observes the infrequent access patterns of a \n\ufb01ltered  set of data over a period of time, you can use \nthe analysis results to help  you improve your lifecycle \ncon\ufb01gurations.", "This feature also includes a detailed  dai \nly analysis of your storage usage at the speci\ufb01ed bucket, \npre\ufb01x, or tag  level that you can export to a S3 bucket.\nThe following new API  operations are for storage class \nanalysis:\n\u2022\nDeleteBucketAnalyticsCon\ufb01guration\n\u2022\nGetBucketAnalyticsCon\ufb01guration\n\u2022\nPutBucketAnalyticsCon\ufb01guration\n\u2022\nListBucketAnalyticsCon\ufb01gurations\nFor more information, see Amazon S3 Analytics \u2013  \n Storage Class Analysis  in the   Amazon Simple Storage \nService User Guide.November \n29, 2016\nAdded S3 Glacier \nretrieval options to\nRestoreObjectAmazon S3 now supports Expedited and Bulk data \nretrievals in addition to Standard retrievals when \nrestoring objects archived to S3 Glacier. For more \ninformation, see   Restoring Archived  Objects in the\nAmazon Simple Storage Service User Guide.November \n21, 2016\nAPI Version 2006-03-01 2856Amazon Simple Storage Service API Reference\nChange Description Release \nDate\nUS East (Ohio) RegionAmazon S3 is now available in the US East (Ohio) Region. \nFor more information about Amazon S3 regions and \nendpoints, see Regions and Endpoints in the   AWS \nGeneral Reference.October \n17, 2016\nAsia Paci\ufb01c (Mumbai) \nregionAmazon S3 is now available in the Asia Paci\ufb01c (Mumbai) \nregion. For more information about Amazon S3 regions \nand endpoints, see Regions and Endpoints in the   AWS \nGeneral Reference.June 27, \n2016\nGET Bucket (List \nObjects) API revisedThe GET Bucket (List Objects) API has been revised.", "We \nrecommend that you use the new version, GET Bucket \n(List Objects) version 2.", "For more information, see\nListObjectsV2 .May 4, \n2016\nAmazon S3 Transfer \nAccelerationAmazon S3 Transfer Acceleration enables fast, easy, and \nsecure transfers of \ufb01les over long distances between \nyour client and an S3 bucket. Transfer Acceleration takes \nadvantage of Amazon CloudFront\u2019s globally distributed \nedge locations.\nFor more information, see Transfer Acceleration in the  \n  Amazon Simple Storage Service User Guide.\nThe following new API operations support Transfer \nAcceleration:  GetBucketAccelerateCon\ufb01guration and  \n  PutBucketAccelerateCon\ufb01guration.April 19, \n2016\nLifecycle support to \nremove expired object \ndelete markerLifecycle con\ufb01guration expiration action now allows you \nto direct Amazon S3 to remove  expired object delete \nmarkers in versioned bucket. For more information,  see\nElements  to Describe Lifecycle Actions in the   Amazon \nSimple Storage Service User Guide.March 16, \n2016\nAPI Version 2006-03-01 2857Amazon Simple Storage Service API Reference\nChange Description Release \nDate\nBucket lifecycle \ncon\ufb01guration now \nsupports the action \nto cancel incomplete \nmultipart uploadsBucket lifecycle con\ufb01guration now supports the  \n  AbortIncompleteMultipartUpload  action that \nyou can use  to direct Amazon S3 to cancel multipart \nuploads that don't complete  within a speci\ufb01ed number \nof days after being initiated. When a multipart upload \nbecomes eligible for an abort operation, Amazon S3 \ndeletes any uploaded parts and cancels the multipart \nupload.\nThe following API operations have been updated to \nsupport the new  action:\n\u2022\nPutBucketLifecycleCon\ufb01guration \u2013 The XML  conf \niguration now allows you to specify the   AbortInco \nmpleteMultipartUpload  action in a  lifecycle \ncon\ufb01guration rule.\n\u2022\nListParts and CreateMultipartUpload \u2013 Both of these \nAPI operations now  return two additional response \nheaders  (x-amz-abort-date , and   x-amz-abo \nrt-rule-id ) if the bucket has a  lifecycle rule that \nspeci\ufb01es the   AbortIncompleteMultipartUpl \noad action. These headers in the response indicate \nwhen the initiated  multipart upload will become \neligible for an abort operation  and which lifecycle rule \nis applicable.\nFor conceptual information, see the following topics in \nthe   Amazon Simple Storage Service User Guide:\n\u2022March 16, \n2016\nAPI Version 2006-03-01 2858Amazon Simple Storage Service API Reference\nChange Description Release \nDate\n Aborting Incomplete Multipart Uploads Using a Bucket \nLifecycle con\ufb01guration \n\u2022\n Elements to Describe Lifecycle Actions\nAmazon S3 Signature \nVersion 4 now \nsupports unsigned \npayloadsAmazon S3 Signature Version 4 now supports unsigned \npayloads when  authenticating requests using the\nAuthorization  header.", "Because you don't  sign the \npayload, it does not provide the same security that comes \nwith payload  signing, but it provides similar performance \ncharacteristics as signature version 2.", "For more informati \non, see Signature Calculations for the Authorization \nHeader:  Transferring Payload in a Single Chunk (AWS \nSignature Version 4).January \n15, 2016\nAsia Paci\ufb01c (Seoul) \nregionAmazon S3 is now available in the Asia Paci\ufb01c (Seoul) \nregion. For more information about Amazon S3 regions \nand endpoints, see Regions and Endpoints in the   AWS \nGeneral Reference.January 6, \n2016\nRenamed the US \nStandard regionChanged the region name string from US Standard to US \nEast (N.", "Virginia).", "This is only a region name update, there \nis no change in the functionality.December \n11, 2015\nAPI Version 2006-03-01 2859Amazon Simple Storage Service API Reference\nChange Description Release \nDate\nNew storage class Amazon S3 now o\ufb00ers a new storage class, STANDARD_ \nIA (IA, for infrequent access) for storing  objects.", "This \nstorage class is optimized for long-lived and less  freque \nntly accessed data.", "For more information, see Storage \nClasses  in the Amazon Simple Storage Service User Guide.\nLifecycle con\ufb01guration feature updates now allow you to \ntransition objects to the  STANDARD_IA storage class. For \nmore information, see Object Lifecycle Management in \nthe Amazon Simple Storage Service User Guide.\nPreviously, the cross-region replication feature used the \nstorage class of the source object for object replicas. \nNow, when you con\ufb01gure cross-region replication you can \nspecify a storage class for the object replica created in \nthe destination bucket. For more information, see Cross-\nRegion Replication in the Amazon Simple Storage Service \nUser Guide .September \n16, 2015\nEvent noti\ufb01cationsAmazon S3 event noti\ufb01cations have been updated to \nadd noti\ufb01cations when objects are deleted and to add \n\ufb01ltering on object names with pre\ufb01x and su\ufb03x matching.", "\n For the relevant API operations, see PutBucketNoti\ufb01cat \nionCon\ufb01guration , and   GetBucketNoti\ufb01cationCon\ufb01g \nuration .", "For more information,  see Con\ufb01guring Amazon \nS3 Event Noti\ufb01cations in the Amazon Simple Storage \nService User Guide.July 28, \n2015\nAPI Version 2006-03-01 2860Amazon Simple Storage Service API Reference\nChange Description Release \nDate\nCross-region replicati \nonAmazon S3 now supports cross-region replication. Cross-\nregion replication is the automatic, asynchronous copying \nof objects across buckets in di\ufb00erent AWS Regions.", "Fo \nr the relevant API operations, see PutBucketReplication,\nGetBucketReplication and DeleteBucketReplication.", "For \nmore information,  see Enabling Cross-Region Replication\nin the Amazon Simple Storage Service User Guide.March 24, \n2015\nEvent noti\ufb01cationsAmazon S3 now supports new event types and destinati \nons in a bucket noti\ufb01cation  con\ufb01guration. Prior to this \nrelease, Amazon S3 supported only the   s3:Reduce \ndRedundancyLostObject  event type and an \nAmazon SNS topic as the destination.", "For more  inform \nation about the new event types, go to Setting Up \nNoti\ufb01cation of  Bucket Events in the Amazon Simple \nStorage Service User Guide.", "For the relevant API operation \ns, see PutBucketNoti\ufb01cationCon\ufb01guration and   GetBucket \nNoti\ufb01cationCon\ufb01guration .November \n13, 2014\nAPI Version 2006-03-01 2861Amazon Simple Storage Service API Reference\nChange Description Release \nDate\nServer-side encryptio \nn with AWS Key \nManagement Service \n(KMS)Amazon S3 now supports server-side encryption using \nAWS Key Management Service (KMS). With server-side \nencryption with KMS, you manage the envelope key \nthrough KMS, and Amazon S3 calls KMS to access the \nenvelope key within the permissions you set.\nFor more information about server-side encryption with \nKMS, see Protecting Data Using Server-Side Encryption \nwith AWS Key Management Service in the Amazon Simple \nStorage Service User Guide.\nThe following Amazon S3 REST API operations support \nheaders related to KMS.\n\u2022PutObject\n\u2022CopyObject\n\u2022POST Object\n\u2022CreateMultipartUpload\n\u2022UploadPartNovember \n12, 2014\nEurope (Frankfurt) \nRegionAmazon S3 is now available in the Europe (Frankfurt) \nRegion region.October \n23, 2014\nAPI Version 2006-03-01 2862Amazon Simple Storage Service API Reference\nChange Description Release \nDate\nServer-side encryptio \nn with customer- \nprovided encryption \nkeysAmazon S3 now supports server-side encryption using \ncustomer-provided encryption keys (SSE-C). Server-\nside encryption enables you to request Amazon S3 to \nencrypt your data  at rest. When using SSE-C, Amazon \nS3 encrypts your objects with the custom encryptio \nn keys that you provide. Since Amazon S3 performs \nthe encryption for you, you get the bene\ufb01ts of using \nyour own encryption keys without the cost of writing or \nexecuting your own encryption code.", "\nFor more information about SSE-C, go to Server-Side \nEncryption (Using Customer-Provided Encryption Keys) in \nthe Amazon Simple Storage Service User Guide.\nThe following Amazon S3 REST API operations support \nheaders related to SSE-C.\n\u2022GetObject\n\u2022HeadObject\n\u2022PutObject\n\u2022CopyObject\n\u2022POST Object\n\u2022CreateMultipartUpload\n\u2022UploadPart\n\u2022UploadPartCopyJune 12, \n2014\nAPI Version 2006-03-01 2863Amazon Simple Storage Service API Reference\nChange Description Release \nDate\nLifecycle support for \nversioningPrior to this release lifecycle con\ufb01guration was supported \nonly on nonversioned  buckets.", "Now you can con\ufb01gure \nlifecycle on both the nonversioned and  versioning-enabl \ned buckets.\nFor more information, go to Object Lifecycle Managemen \nt in the Amazon Simple Storage Service User Guide.\nThe related API operations, see PutBucketLifecycle \nCon\ufb01guration , GetBucketLifecycleCon\ufb01guration, and\nDeleteBucketLifecycle.May 20, \n2014\nAmazon S3 now \nsupports Signature \nVersion 4Amazon S3 now supports Signature Version 4 (SigV4) in \nall regions, the latest speci\ufb01cation  for how to sign and \nauthenticate AWS requests.\nFor more information, see Authenticating Requests (AWS \nSignature Version  4).January \n30, 2014\nAmazon S3 list \nactions now support\nencoding-type\nrequest parameterThe following Amazon S3 list actions now support\nencoding-type  optional  request parameter.\nListObjects\nListObjectVersions\nListMultipartUploads\nListParts\nAn object key can contain any Unicode character; \nhowever, the XML 1.0 parser cannot parse some  charac \nters, such as characters with an ASCII value from 0 to \n10. For  characters that are not supported in XML 1.0, \nyou can add this parameter to request that Amazon S3 \nencode the keys in the response.November \n1, 2013\nAPI Version 2006-03-01 2864Amazon Simple Storage Service API Reference\nChange Description Release \nDate\nSOAP Support Over \nHTTP DeprecatedSOAP support over HTTP is deprecated, but it is still \navailable over HTTPS. New Amazon S3 features will not \nbe supported for SOAP.", "We recommend that you use ei \nther the REST API or the AWS SDKs.September \n19, 2013\nRoot domain support \nfor website hostingAmazon S3 now supports hosting static websites at the \nroot domain.", "Visitors to  your website can access your site \nfrom their  browser without specifying \"www\" in the web \naddress (e.g.,  \"example.com\").", "Many customers already \nhost static websites on Amazon S3  that are accessible \nfrom a \"www\" subdomain (e.g., \"www.example.com\"). \nPreviously, to support root domain access, you needed to \nrun your own  web server to proxy root domain requests \nfrom browsers to your website  on Amazon S3.", "Running \na web server to proxy requests introduces additional  \ncosts, operational burden, and another potential point of \nfailure.", "Now,  you can take advantage of the high availabil \nity and durability of Amazon S3 for both  \"www\" and root \ndomain addresses.\nFor an example walkthrough, go to Example: Setting \nUp a Static Website Using a Custom Domain in the\nAmazon Simple Storage Service User Guide. For conceptua \nl information, go to Hosting Static Websites on  Amazon \nS3 in the Amazon Simple Storage Service User Guide.December \n27, 2012\nAPI Version 2006-03-01 2865Amazon Simple Storage Service API Reference\nChange Description Release \nDate\nSupport for Archiving \nData to Amazon \nGlacierAmazon S3 now supports a storage option that enables \nyou to utilize Amazon Glacier's low-cost  storage service \nfor data archival. To archive objects, you de\ufb01ne  archival \nrules identifying objects and a timeline when you want \nAmazon S3 to  archive these objects to S3 Glacier. You \ncan easily set the rules on a bucket  using the Amazon S3 \nconsole or programmatically using the Amazon S3 API or \nAWS  SDKs.\nTo support data archival rules, Amazon S3 lifecycle  \nmanagement API has been updated.", "For more informati \non, see PutBucketLifecycleCon\ufb01guration.\nAfter you archive objects, you must \ufb01rst restore a copy \nbefore you can access the data.", "Amazon S3 o\ufb00ers a new \nAPI for you to initiate a restore. For more  information, \nsee RestoreObject.\nFor conceptual information, go to Object  Lifecycle \nManagement  in the   Amazon Simple Storage Service User \nGuide .November \n13, 2012\nAPI Version 2006-03-01 2866Amazon Simple Storage Service API Reference\nChange Description Release \nDate\nSupport for Website \nPage RedirectsFor a bucket that is con\ufb01gured as a website, Amazon \nS3 now supports redirecting a request for  an object to \nanother object in the same bucket or to an external URL. \n You can con\ufb01gure redirect by adding the   x-amz-web \nsite-redirect-location  metadata to the object.\nThe object upload API operations PutObject, CreateMul \ntipartUpload, and POST Object allow you  to con\ufb01gure \nthe x-amz-website-redirect-location  object  \n metadata.\nFor conceptual information, go to How  to Con\ufb01gure \nWebsite Page Redirects in the   Amazon Simple Storage \nService User Guide.October \n4, 2012\nCross-Origin Resource \nSharing (CORS) \nsupportAmazon S3 now supports Cross-Origin Resource Sharing \n(CORS).", "CORS de\ufb01nes a way in which  client web applicati \nons that are loaded in one domain can interact with \nor access resources in a di\ufb00erent domain.", "With CORS \nsupport in Amazon S3, you  can build rich client-side web \napplications on top of Amazon S3 and  selectively allow \ncross-domain access to your Amazon S3 resources. For \nmore  information, see Enabling Cross-Origin Resource \nSharing  in the Amazon Simple Storage Service User Guide.August \n31, 2012\nCost Allocation \nTagging supportAmazon S3 now supports cost allocation tagging, which \nallows you to label S3 buckets so you can more easily \ntrack  their cost against projects or other criteria. For \nmore information, see Cost Allocation Tagging in the\nAmazon Simple Storage Service User Guide.August \n21, 2012\nAPI Version 2006-03-01 2867Amazon Simple Storage Service API Reference\nChange Description Release \nDate\nObject Expiration \nsupportYou can use Object Expiration to schedule automatic \nremoval of data after a con\ufb01gured time period.", "You set \nobject expiration by adding lifecycle con\ufb01guration to a \nbucket.", "For more information, see Transitioning Objects: \nGeneral Considerations  in the Amazon Simple Storage \nService User Guide.December \n27, 2011\nNew Region \nsupportedAmazon S3 now supports the South America (S\u00e3o Paulo) \nregion. For more  information, see Buckets and Regions in \nthe Amazon Simple Storage Service User Guide.December \n14, 2011\nMulti-Object DeleteAmazon S3 now supports Multi-Object Delete API \nthat enables you to  delete multiple objects in a single \nrequest. With this feature, you can  remove large numbers \nof objects from Amazon S3 more quickly than using  \n multiple individual DELETE requests.\nFor more information about the API see, see DeleteObj \nects.\nFor conceptual information about the delete operation \n, see Deleting Objects in the Amazon Simple Storage \nService User Guide.December \n7, 2011\nNew region \nsupportedAmazon S3 now supports the US West (Oregon) region. \nFor more  information, see Buckets and  Regions in the\nAmazon Simple Storage Service User Guide.November \n8, 2011\nAPI Version 2006-03-01 2868Amazon Simple Storage Service API Reference\nChange Description Release \nDate\nServer-side encryptio \nn supportAmazon S3 now supports server-side encryption. It \nenables you to request Amazon S3 to  encrypt your data \nat rest, that is, encrypt your object data when Amazon  \nS3 writes your data to disks in its data centers.", "To request \nserver-side  encryption, you must add the x-amz-ser \nver-side-encryption  header to your request.", "\nTo learn more about data encryption, go to   Using Data \nEncryption in the Amazon Simple Storage Service User \nGuide .October \n17, 2011\nMultipart Upload API \nextended to enable \ncopying objects up to \n5 TBPrior to this release, Amazon S3 API supported copying \nobjects (see CopyObject) of up to  5 GB in size. To \nenable copying objects larger than 5 GB, Amazon S3  \n extends the multipart upload API with a new operation \n, Upload Part  (Copy) . You can use this multipart \nupload operation to copy  objects up to 5 TB in size.", "For \nconceptual information about multipart upload, go to\nUploading Objects Using Multipart Upload in the Amazon \nSimple Storage Service User Guide.", "To learn more  about \nthe new API, see UploadPartCopy.", "June 21, \n2011\nSOAP API calls over \nHTTP disabledTo increase security, SOAP API calls over HTTP are \ndisabled.", "Authenticated and anonymous SOAP requests \nmust be sent to Amazon S3 using SSL.June 6, \n2011\nAPI Version 2006-03-01 2869Amazon Simple Storage Service API Reference\nChange Description Release \nDate\nSupport for hosting \nstatic websites in \nAmazon S3Amazon S3 introduces enhanced support for hosting \nstatic websites.", "This includes support  for index \ndocuments and custom error documents.", "When using \nthese  features, requests to the root of your bucket or a \nsubfolder (e.g.,   http://mywebsite.com/subfol \nder) returns your index  document instead of the list \nof objects in your bucket.", "If an error is  encountered, \nAmazon S3 returns your custom error message instead \nof an  Amazon S3 error message. For API information to \ncon\ufb01gure your bucket as  a website, see the following \nsections:\n\u2022PutBucketWebsite\n\u2022GetBucketWebsite\n\u2022DeleteBucketWebsite\nFor conceptual overview, go to Hosting Websites on \nAmazon S3 in the Amazon Simple Storage Service User \nGuide .February \n17, 2011\nResponse Header API \nSupportThe GET Object REST API now allows you to change the \nresponse headers of the REST GET  Object request for \neach request.", "That is, you can alter object metadata  in \nthe response, without altering the object itself.", "For more  \n information, see GetObject.January \n14, 2011\nAPI Version 2006-03-01 2870Amazon Simple Storage Service API Reference\nChange Description Release \nDate\nLarge Object SupportAmazon S3 has increased the maximum size of an object \nyou can store in an S3 bucket from  5 GB to 5 TB.", "If \nyou are using the REST API you can upload objects of \nup  to 5 GB size in a single PUT operation. For larger \nobjects, you must use  the Multipart Upload REST API to \nupload objects in parts.", "For conceptual information, go to\nUploading Objects Using Multipart Upload in the Amazon \nSimple Storage Service User Guide.", "For multipart upload \nAPI information, see CreateMultipartUpload, UploadPar \nt,  CompleteMultipartUpload,  ListParts, and ListMulti \npartUploadsDecember \n9, 2010\nMultipart uploadMultipart upload enables faster, more \ufb02exible uploads \ninto Amazon S3.", "It allows you to  upload a single object \nas a set of parts.", "For conceptual information,  go to\nUploading Objects Using Multipart Upload in the Amazon \nSimple Storage Service User Guide.", "For multipart upload \nAPI information, see CreateMultipartUpload, UploadPar \nt,  CompleteMultipartUpload,  ListParts, and ListMulti \npartUploadsNovember \n10, 2010\nNoti\ufb01cations The Amazon S3 noti\ufb01cations feature enables you to \ncon\ufb01gure a bucket so that Amazon S3 publishes a \nmessage to an Amazon Simple Noti\ufb01cation Service  (SNS \n) topic when Amazon S3 detects a key event on a bucket.", "\nFor more  information, see GET Bucket  noti\ufb01cation and\nPUT  Bucket noti\ufb01cation.July 14, \n2010\nBucket policiesBucket policies is an access management system you use \nto set access  permissions on buckets, objects, and sets \nof objects.", "This functionality  supplements and in many \ncases replaces access control lists.July 6, \n2010\nAPI Version 2006-03-01 2871Amazon Simple Storage Service API Reference\nChange Description Release \nDate\nReduced RedundancyAmazon S3 now enables you to reduce your storage costs \nby storing objects  in Amazon S3 with reduced redundanc \ny. For more information, see PUT Object.May 12, \n2010\nNew region \nsupportedAmazon S3 now supports the Asia Paci\ufb01c (Singapore) \nregion and therefore new location constraints.", "For more \ninformation, see GET Bucket location and PUT Bucket.April 28, \n2010\nObject VersioningThis release introduces object Versioning.", "All objects now \nhave a key and  a version.", "If you enable versioning for a \nbucket, Amazon S3 gives all  objects added to a bucket \na unique version ID.", "This feature enables you to recover \nfrom unintended overwrites and deletions. For more \ninformation, see   GET Object, DELETE Object, PUT Object,\nPUT Object Copy, or POST Object.", "The SOAP API does \nnot  support versioned objects.February \n8, 2010\nNew region \nsupportedAmazon S3 now supports the US-West (Northern \nCalifornia) region.", "The new  endpoint is s3-us-wes \nt-1.amazonaws.com .", "For more  information, see\nHow to Select a Region for Your Buckets in the Amazon \nSimple Storage Service User Guide.December \n2, 2009\nC# Library SupportAWS now provides Amazon S3 C# libraries, sample code, \ntutorials, and  other resources for software developers \nwho prefer to build applications  using language-speci\ufb01c \nAPI operations instead of REST or SOAP. These libraries pr \novide basic functions (not included in the REST or SOAP \nAPIs), such as request authentication, request retries, and \nerror handling so that it's  easier to get started.November \n11, 2009\nAPI Version 2006-03-01 2872Amazon Simple Storage Service API Reference\nChange Description Release \nDate\nTechnical documents \nreorganizedThe API reference has been split out of the Amazon S3  \n Developer Guide .", "Now, on the documentation landing pa \nge, Amazon Simple Storage Service Documentation, you \ncan select the document you want to view.", "When viewing \nthe documents online, the links in one document will take \nyou, when appropriate, to one of the other guides.September \n16, 2009\nAPI Version 2006-03-01 2873Amazon Simple Storage Service API Reference\nAppendix\nTopics\n\u2022Appendix: SelectObjectContent Response\n\u2022Appendix: OPTIONS object\n\u2022Appendix: SOAP API\n\u2022Appendix: Authenticating requests (AWS signature version 2)\n\u2022Appendix: Lifecycle Con\ufb01guration APIs (Deprecated)\nAPI Version 2006-03-01 2874Amazon Simple Storage Service API Reference\nAppendix: SelectObjectContent Response\nDescription\nThe Amazon S3 Select operation \ufb01lters the contents of an Amazon S3 object based on a simple \nstructured query language (SQL) statement. Given the response size of this operation is unknown, \nAmazon S3 Select streams the response as a series of messages and includes a Transfer-\nEncoding  header with chunked as its value in the response.\nFor more information about Amazon S3 Select, see Selecting Content from Objects in the Amazon \nSimple Storage Service User Guide.\nFor more information about using SQL with Amazon S3 Select, see  SQL Reference for Amazon S3 \nSelect and S3 Glacier Select in the Amazon Simple Storage Service User Guide.\nResponses\nA successful Amazon S3 Select Operation returns 200 OK status code.\nResponse Headers\nThis implementation of the operation uses only response headers that are common to most \nresponses. For more information, see Common Response Headers.\nResponse Body\nSince the Amazon S3 Select response size is unknown, Amazon S3 streams the response as a \nseries of messages and includes a Transfer-Encoding  header with chunked  as its value in the \nresponse.", "The following example shows the response format at the top level:\n<Message 1>\n<Message 2>\n<Message 3>\n......\n<Message n>\nEach message consists of two sections: the prelude and the data. The prelude section consists of 1) \nthe total byte-length of the message, and 2) the combined byte-length of all the headers.", "The data \nsection consists of 1) the headers, and 2) a payload.\nAppendix: SelectObjectContent Response API Version 2006-03-01 2875Amazon Simple Storage Service API Reference\nEach section ends with a 4-byte big-endian integer checksum (CRC).", "Amazon S3 Select uses CRC32 \n(often referred to as GZIP CRC32) to calculate both CRCs.", "For more information about CRC32, see\nGZIP \ufb01le format speci\ufb01cation version 4.3 .\nTotal message overhead including the prelude and both checksums is 16 bytes.\nNote\nAll integer values within messages are in network byte order, or big-endian order.\nThe following diagram shows the components that make up a message and a header.", "Note that \nthere are multiple headers per message.\nNote\nFor Amazon S3 Select, the header value type is always 7 (type=String).", "For this type, the \nheader value consists of two components, a 2-byte big-endian integer length, and a UTF-8 \nstring that is of that byte-length.", "The following diagram shows the components that make \nup Amazon S3 Select headers.\nResponses API Version 2006-03-01 2876Amazon Simple Storage Service API Reference\nPayload byte-length calculations (these two calculations are equivalent):\n\u2022payload_length = total_length - header_length - sizeOf(total_length) - sizeOf(header_length) - \nsizeOf(prelude_crc) - sizeOf(message_crc)\n\u2022payload_length = total_length - header_length - 16\nEach message contains the following components:\n\u2022Prelude : Always \ufb01xed size of 8 bytes (two \ufb01elds of 4 bytes each):\n\u2022First four bytes: Total byte-length: Big-endian integer byte-length of the entire message \n(including the 4-byte total length \ufb01eld itself).\n\u2022Second four bytes: Headers byte-length: Big-endian integer byte-length of the headers portion \nof the message (excluding the headers length \ufb01eld itself).\n\u2022Prelude CRC: 4-byte big-endian integer checksum (CRC) for the prelude portion of the message \n(excluding the CRC itself). The prelude has a separate CRC from the message CRC (see below), \nto ensure that corrupted byte-length information can be detected immediately, without causing \npathological bu\ufb00ering behavior.\n\u2022Headers : A set of metadata annotating the message, such as the message type, payload format, \nand so on. Messages can have multiple headers, so this portion of the message can have \ndi\ufb00erent byte-lengths depending on the message type.", "Headers are key-value pairs, where both \nthe key and value are UTF-8 strings.", "Headers can appear in any order within the headers portion \nof the message, and any given header type can only appear once.\nFor Amazon S3 Select, following is a list of header names and the set of valid values depending \non the message type.\n\u2022MessageType Header:\nResponses API Version 2006-03-01 2877Amazon Simple Storage Service API Reference\n\u2022HeaderName => \":message-type\"\n\u2022Valid HeaderValues => \"error\", \"event\"\n\u2022EventType Header:\n\u2022HeaderName => \":event-type\"\n\u2022Valid HeaderValues => \"Records\", \"Cont\", \"Progress\", \"Stats\", \"End\"\n\u2022ErrorCode Header :\n\u2022HeaderName => \":error-code\"\n\u2022Valid HeaderValues => Error Code from the table in the List of SELECT Object Content Error \nCodes  section.\n\u2022ErrorMessage Header :\n\u2022HeaderName => \":error-message\"\n\u2022Valid HeaderValues => Error message returned by the service, to help diagnose request-level \nerrors.\n\u2022Payload: Can be anything.\n\u2022Message CRC: 4-byte big-endian integer checksum (CRC) from the start of the message to the \nstart of the checksum (that is, everything in the message excluding the message CRC itself).\nEach header contains the following components. There can be multiple headers per message.\n\u2022Header Name Byte-Length: Byte-length of the header name.\n\u2022Header Name : Name of the header, indicating the header type. Valid values: \":message-type\" \n\":event-type\" \":error-code\" \":error-message\"\n\u2022Header Value Type: Enum indicating the header value type.", "For Amazon S3 Select, this is always \n7.\n\u2022Value String Byte-Length: (For Amazon S3 Select) Byte-length of the header value string.\n\u2022Header Value String: (For Amazon S3 Select) Value of the header string.", "Valid values for this \n\ufb01eld vary based on the type of the header.", "See the sections below for valid values for each \nheader type and message type.\nFor Amazon S3 Select, responses can be messages of the following types:\n\u2022Records message: Can contain a single record, partial records, or multiple records. Depending on \nthe size of the result, a response can contain one or more of these messages.\nResponses API Version 2006-03-01 2878Amazon Simple Storage Service API Reference\n\u2022Continuation message : Amazon S3 periodically sends this message to keep the TCP connection \nopen.", "These messages appear in responses at random.", "The client must detect the message type \nand process accordingly.\n\u2022Progress message : Amazon S3 periodically sends this message, if requested. It contains \ninformation about the progress of a query that has started but has not yet completed.\n\u2022Stats message : Amazon S3 sends this message at the end of the request.", "It contains statistics \nabout the query.\n\u2022End message : Indicates that the request is complete, and no more messages will be sent.", "You \nshould not assume that the request is complete until the client receives an End message.\n\u2022RequestLevelError message: Amazon S3 sends this message if the request failed for any \nreason.", "It contains the error code and error message for the failure.", "If Amazon S3 sends a\nRequestLevelError  message, it doesn't send an End message.\nThe following sections explain the structure of each message type in more detail.\nFor sample code and unit tests that use this protocol, see AWS C Event Stream on the GitHub \nwebsite.\nRecords Message\nHeader speci\ufb01cation\nRecords messages contain three headers, as follows:\nResponses API Version 2006-03-01 2879Amazon Simple Storage Service API Reference\nPayload speci\ufb01cation\nRecords message payloads can contain a single record, partial records, or multiple records.\nContinuation Message\nHeader speci\ufb01cation\nContinuation messages contain two headers, as follows:\nResponses API Version 2006-03-01 2880Amazon Simple Storage Service API Reference\nPayload speci\ufb01cation\nContinuation messages have no payload.\nProgress Message\nHeader speci\ufb01cation\nProgress messages contain three headers, as follows:\nResponses API Version 2006-03-01 2881Amazon Simple Storage Service API Reference\nPayload speci\ufb01cation\nProgress message payload is an XML document containing information about the progress of a \nrequest.\n\u2022BytesScanned => Number of bytes that have been processed before being uncompressed (if the \n\ufb01le is compressed).\n\u2022BytesProcessed => Number of bytes that have been processed after being uncompressed (if the \n\ufb01le is compressed).\n\u2022BytesReturned => Current number of bytes of records payload data returned by Amazon S3.\nFor uncompressed \ufb01les, BytesScanned  and BytesProcessed  are equal.\nExample:\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\nResponses API Version 2006-03-01 2882Amazon Simple Storage Service API Reference\n<Progress> \n     <BytesScanned>512</BytesScanned> \n     <BytesProcessed>1024</BytesProcessed> \n     <BytesReturned>1024</BytesReturned>\n</Progress>\nStats Message\nHeader speci\ufb01cation\nStats messages contain three headers, as follows:\nPayload speci\ufb01cation\nStats message payload is an XML document containing information about a request's stats when \nprocessing is complete.\n\u2022BytesScanned => Number of bytes that have been processed before being uncompressed (if the \n\ufb01le is compressed).\nResponses API Version 2006-03-01 2883Amazon Simple Storage Service API Reference\n\u2022BytesProcessed => Number of bytes that have been processed after being uncompressed (if the \n\ufb01le is compressed).\n\u2022BytesReturned => Total number of bytes of records payload data returned by Amazon S3.\nFor uncompressed \ufb01les, BytesScanned  and BytesProcessed  are equal.\nExample:\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<Stats> \n     <BytesScanned>512</BytesScanned> \n     <BytesProcessed>1024</BytesProcessed> \n     <BytesReturned>1024</BytesReturned>\n</Stats>\nEnd Message\nHeader speci\ufb01cation\nEnd messages contain two headers, as follows:\nResponses API Version 2006-03-01 2884Amazon Simple Storage Service API Reference\nPayload speci\ufb01cation\nEnd messages have no payload.\nRequest Level Error Message\nHeader speci\ufb01cation\nRequest-level error messages contain three headers, as follows:\nFor a list of possible error codes and error messages, see the List of SELECT Object Content Error \nCodes .\nPayload speci\ufb01cation\nRequest-level error messages have no payload.\nRelated Resources\n\u2022the section called \u201cSelectObjectContent\u201d\nRelated Resources API Version 2006-03-01 2885Amazon Simple Storage Service API Reference\n\u2022the section called \u201cGetObject\u201d\n\u2022the section called \u201cGetBucketLifecycleCon\ufb01guration\u201d\n\u2022the section called \u201cPutBucketLifecycleCon\ufb01guration\u201d\nRelated Resources API Version 2006-03-01 2886Amazon Simple Storage Service API Reference\nAppendix: OPTIONS object\nDescription\nA browser can send this pre\ufb02ight request to Amazon S3 to determine if it can send an actual \nrequest with the speci\ufb01c origin, HTTP method, and headers.\nAmazon S3 supports cross-origin resource sharing (CORS) by enabling you to add a cors\nsubresource on a bucket. When a browser sends this pre\ufb02ight request, Amazon S3 responds by \nevaluating the rules that are de\ufb01ned in the cors con\ufb01guration.\nIf cors is not enabled on the bucket, then Amazon S3 returns a 403 Forbidden  response.\nFor more information about CORS, go to Enabling Cross-Origin Resource Sharing in the Amazon \nSimple Storage Service User Guide.\nRequests\nSyntax\nOPTIONS / ObjectName  HTTP/1.1\nHost: BucketName .s3.amazonaws.com  \nOrigin: Origin\nAccess-Control-Request-Method: HTTPMethod\nAccess-Control-Request-Headers: RequestHeader\nRequest Parameters\nThis operation does not introduce any speci\ufb01c request parameters, but it may contain any request \nparameters that are required by the actual request.\nRequest Headers\nName Description Required\nOrigin\nIdenti\ufb01es the origin of the cross-origin request to Amazon \nS3.", "For example,  http://www.example.com.\nType: StringYes\nAppendix: OPTIONS object API Version 2006-03-01 2887Amazon Simple Storage Service API Reference\nName Description Required\nDefault: None\nAccess-Co \nntrol-Req \nuest-MethodIdenti\ufb01es what HTTP method will be used in the actual \nrequest.\nType: String\nDefault: NoneYes\nAccess-Co \nntrol-Req \nuest-HeadersA comma-delimited list of HTTP headers that will be sent \nin the actual request.\nFor example, to put an object with server-side encryption, \nthis pre\ufb02ight request will  determine if it can include the  \n  x-amz-server-side-encryption  header with the  \n request.\nType: String\nDefault: NoneNo\nRequest Elements\nThis implementation of the operation does not use request elements.\nResponses\nResponse Headers\nHeader Description\nAccess-Control-All \now-OriginThe origin you sent in your request.", "If the origin in your request \nis not allowed,  Amazon S3 will not include this header in the \nresponse.\nResponses API Version 2006-03-01 2888Amazon Simple Storage Service API Reference\nHeader Description\nType: String\nAccess-Control-Max-\nAgeHow long, in seconds, the results of the pre\ufb02ight request can be \ncached.\nType: String\nAccess-Control-All \now-MethodsThe HTTP method that was sent in the original request. If the \nmethod in the request is  not allowed, Amazon S3 will not \ninclude this header in the  response.\nType: String\nAccess-Control-All \now-HeadersA comma-delimited list of HTTP headers that the browser can \nsend in the actual  request. If any of the requested headers is \nnot allowed, Amazon  S3 will not include that header in the \nresponse, nor will the  response contain any of the headers with \nthe   Access-Control  pre\ufb01x.\nType: String\nAccess-Control-Exp \nose-HeadersA comma-delimited list of HTTP headers. This header provides \nthe JavaScript client  with access to these headers in the \nresponse to the actual  request.\nType: String\nResponse Elements\nThis implementation of the operation does not return response elements.\nResponses API Version 2006-03-01 2889Amazon Simple Storage Service API Reference\nExamples\nExample : Send a pre\ufb02ight OPTIONS request to a cors enabled bucket\nA browser can send this pre\ufb02ight request to Amazon S3 to determine if it can send the actual PUT \nrequest from http://www.example.com origin to the Amazon S3 bucket named examplebucket .\nSample Request\nOPTIONS /exampleobject HTTP/1.1\nHost: examplebucket.s3.amazonaws.com  \nOrigin: http://www.example.com\nAccess-Control-Request-Method: PUT\nSample Response\nHTTP/1.1 200 OK\nx-amz-id-2: 6SvaESv3VULYPLik5LLl7lSPPtSnBvDdGmnklX1HfUl7uS2m1DF6td6KWKNjYMXZ\nx-amz-request-id: BDC4B83DF5096BBE\nDate: Wed, 21 Aug 2012 23:09:55 GMT\nEtag: \"1f1a1af1f1111111111111c11aed1da1\"\nAccess-Control-Allow-Origin: http://www.example.com\nAccess-Control-Allow-Methods: PUT\nAccess-Control-Expose-Headers: x-amz-request-id\nContent-Length: 0\nServer: AmazonS3\nRelated Resources\n\u2022GetBucketCors\n\u2022DeleteBucketCors\n\u2022PutBucketCors\nExamples API Version 2006-03-01 2890Amazon Simple Storage Service API Reference\nAppendix: SOAP API\nNote\nSOAP support over HTTP is deprecated, but it is still available over HTTPS.", "New Amazon S3 \nfeatures will not be supported for SOAP.", "We recommend that you use either the REST API \nor the AWS SDKs.\nThis section describes the SOAP API with respect to service, bucket, and object operations.", "Note \nthat SOAP requests, both authenticated and anonymous, must be sent to Amazon S3 using SSL. \nAmazon S3 returns an error when you send a SOAP request over HTTP.\nThe latest Amazon S3 WSDL is available at docs.aws.amazon.com/2006-03-01/AmazonS3.wsdl.\nTopics\n\u2022Operations on the Service (SOAP API)\n\u2022Operations on Buckets (SOAP API)\n\u2022Operations on Objects (SOAP API)\n\u2022Authenticating SOAP requests\n\u2022Setting access policy with SOAP\n\u2022Common elements\n\u2022SOAP Error Responses\nOperations on the Service (SOAP API)\nNote\nSOAP support over HTTP is deprecated, but it is still available over HTTPS. New Amazon S3 \nfeatures will not be supported for SOAP. We recommend that you use either the REST API \nor the AWS SDKs.\nThis section describes operations you can perform on the Amazon S3 service.\nTopics\nAppendix: SOAP API API Version 2006-03-01 2891Amazon Simple Storage Service API Reference\n\u2022ListAllMyBuckets (SOAP API)\nListAllMyBuckets (SOAP API)\nNote\nSOAP support over HTTP is deprecated, but it is still available over HTTPS. New Amazon S3 \nfeatures will not be supported for SOAP.", "We recommend that you use either the REST API \nor the AWS SDKs.\nThe ListAllMyBuckets  operation returns a list of all buckets owned by the sender of the \nrequest.\nExample\nSample Request\n<ListAllMyBuckets xmlns=\"http://doc.s3.amazonaws.com/2006-03-01\"> \n  <AWSAccessKeyId>AKIAIOSFODNN7EXAMPLE</AWSAccessKeyId> \n  <Timestamp>2006-03-01T12:00:00.183Z</Timestamp> \n  <Signature>Iuyz3d3P0aTou39dzbqaEXAMPLE=</Signature>\n</ListAllMyBuckets>\nSample Response\n<ListAllMyBucketsResult xmlns=\"http://s3.amazonaws.com/doc/2006-03-01\"> \n  <Owner> \n    <ID>bcaf1ffd86f41161ca5fb16fd081034f</ID> \n    <DisplayName>webfile</DisplayName> \n  </Owner> \n  <Buckets> \n    <Bucket> \n      <Name>quotes;/Name> \n      <CreationDate>2006-02-03T16:45:09.000Z</CreationDate> \n    </Bucket> \n    <Bucket> \n      <Name>samples</Name> \n      <CreationDate>2006-02-03T16:41:58.000Z</CreationDate> \n    </Bucket> \nOperations on the Service (SOAP API) API Version 2006-03-01 2892Amazon Simple Storage Service API Reference\n </Buckets>\n</ListAllMyBucketsResult>\nResponse Body\n\u2022Owner:\nThis provides information that Amazon S3 uses to represent your identity for purposes of \nauthentication and access control.", "ID is a unique and permanent identi\ufb01er for the developer \nwho made the request.", "DisplayName is a human-readable name representing the developer who \nmade the request.", "It is not unique, and might change over time.We recommend that you match \nyour DisplayName to your Forum name.\n\u2022Name:\nThe name of a bucket. Note that if one of your buckets was recently deleted, the name of the \ndeleted bucket might still be present in this list for a period of time.\n\u2022CreationDate:\nThe time that the bucket was created.\nAccess Control\nYou must authenticate with a valid AWS Access Key ID. Anonymous requests are never allowed to \nlist buckets, and you can only list buckets for which you are the owner.\nOperations on Buckets (SOAP API)\nNote\nSOAP support over HTTP is deprecated, but it is still available over HTTPS.", "New Amazon S3 \nfeatures will not be supported for SOAP.", "We recommend that you use either the REST API \nor the AWS SDKs.\nThis section describes operations you can perform on Amazon S3 buckets.\nTopics\n\u2022CreateBucket (SOAP API)\nOperations on Buckets (SOAP API) API Version 2006-03-01 2893Amazon Simple Storage Service API Reference\n\u2022DeleteBucket (SOAP API)\n\u2022ListBucket (SOAP API)\n\u2022GetBucketAccessControlPolicy (SOAP API)\n\u2022SetBucketAccessControlPolicy (SOAP API)\n\u2022GetBucketLoggingStatus (SOAP API)\n\u2022SetBucketLoggingStatus (SOAP API)\nCreateBucket (SOAP API)\nNote\nSOAP support over HTTP is deprecated, but it is still available over HTTPS.", "New Amazon S3 \nfeatures will not be supported for SOAP.", "We recommend that you use either the REST API \nor the AWS SDKs.\nThe CreateBucket  operation creates a bucket.", "Not every string is an acceptable bucket name. For \ninformation on bucket naming restrictions, see Working with Amazon S3 Buckets .\nNote\nTo determine whether a bucket name exists, use ListBucket  and set MaxKeys  to 0. A \nNoSuchBucket response indicates that the bucket is available, an AccessDenied response \nindicates that someone else owns the bucket, and a Success response indicates that you \nown the bucket or have permission to access it.\nExample Create a bucket named \"quotes\"\nSample Request\n<CreateBucket xmlns=\"http://doc.s3.amazonaws.com/2006-03-01\"> \n  <Bucket>quotes</Bucket> \n  <AWSAccessKeyId>AKIAIOSFODNN7EXAMPLE</AWSAccessKeyId> \n  <Timestamp>2006-03-01T12:00:00.183Z</Timestamp> \n  <Signature>Iuyz3d3P0aTou39dzbqaEXAMPLE=</Signature>\nOperations on Buckets (SOAP API) API Version 2006-03-01 2894Amazon Simple Storage Service API Reference\n</CreateBucket>\nSample Response\n<CreateBucketResponse xmlns=\"http://s3.amazonaws.com/doc/2006-03-01\"> \n  <CreateBucketResponse> \n    <Bucket>quotes</Bucket> \n  </CreateBucketResponse>\n</CreateBucketResponse>\nElements\n\u2022Bucket: The name of the bucket you are trying to create.\n\u2022AccessControlList:  The access control list for the new bucket.", "This element is optional.", "If \nnot provided, the bucket is created with an access policy that give the requester FULL_CONTROL \naccess.\nAccess Control\nYou must authenticate with a valid AWS Access Key ID.", "Anonymous requests are never allowed to \ncreate buckets.\nRelated Resources\n\u2022ListBucket (SOAP API)\nDeleteBucket (SOAP API)\nNote\nSOAP support over HTTP is deprecated, but it is still available over HTTPS.", "New Amazon S3 \nfeatures will not be supported for SOAP.", "We recommend that you use either the REST API \nor the AWS SDKs.\nThe DeleteBucket  operation deletes a bucket. All objects in the bucket must be deleted before \nthe bucket itself can be deleted.\nOperations on Buckets (SOAP API) API Version 2006-03-01 2895Amazon Simple Storage Service API Reference\nExample\nThis example deletes the \"quotes\" bucket.\nSample Request\n<DeleteBucket xmlns=\"http://doc.s3.amazonaws.com/2006-03-01\"> \n  <Bucket>quotes</Bucket> \n  <AWSAccessKeyId> AKIAIOSFODNN7EXAMPLE</AWSAccessKeyId> \n  <Timestamp>2006-03-01T12:00:00.183Z</Timestamp> \n  <Signature>Iuyz3d3P0aTou39dzbqaEXAMPLE=</Signature>\n</DeleteBucket>\nSample Response\n<DeleteBucketResponse xmlns=\"http://s3.amazonaws.com/doc/2006-03-01\"> \n  <DeleteBucketResponse> \n    <Code>204</Code> \n    <Description>No Content</Description> \n  </DeleteBucketResponse>\n</DeleteBucketResponse>\nElements\n\u2022Bucket: The name of the bucket you want to delete.\nAccess Control\nOnly the owner of a bucket is allowed to delete it, regardless the access control policy on the \nbucket.\nListBucket (SOAP API)\nNote\nSOAP support over HTTP is deprecated, but it is still available over HTTPS.", "New Amazon S3 \nfeatures will not be supported for SOAP.", "We recommend that you use either the REST API \nor the AWS SDKs.\nThe ListBucket  operation returns information about some of the items in the bucket.\nOperations on Buckets (SOAP API) API Version 2006-03-01 2896Amazon Simple Storage Service API Reference\nFor a general introduction to the list operation, see the Listing Object Keys.\nRequests\nThis example lists up to 1000 keys in the \"quotes\" bucket that have the pre\ufb01x \"notes.\"\nSyntax\n<ListBucket xmlns=\"http://doc.s3.amazonaws.com/2006-03-01\"> \n  <Bucket>quotes</Bucket> \n  <Prefix>notes/</Prefix> \n  <Delimiter>/</Delimiter> \n  <MaxKeys>1000</MaxKeys> \n  <AWSAccessKeyId>AKIAIOSFODNN7EXAMPLE</AWSAccessKeyId> \n  <Timestamp>2006-03-01T12:00:00.183Z</Timestamp> \n  <Signature>Iuyz3d3P0aTou39dzbqaEXAMPLE=</Signature>\n</ListBucket> \n             \nParameters\nName Description Required\nprefix Limits the response to keys which begin with the indicated \n pre\ufb01x. You can use pre\ufb01xes to separate a bucket into di\ufb00erent \n sets of keys in a way similar to how a \ufb01le system uses folders.\nImportant\nReplacement must be made for object keys containing \nspecial characters (such as carriage returns) when using \nXML requests. For more information, see  XML related \nobject key constraints.\nType: String\nDefault: NoneNo\nmarker Indicates where in the bucket to begin listing.", "The list will only \ninclude keys that occur lexicographically after marker.", "This is No\nOperations on Buckets (SOAP API) API Version 2006-03-01 2897Amazon Simple Storage Service API Reference\nName Description Required\nconvenient for pagination: To get the next page of results use \nthe last key of the current page as the marker.\nType: String\nDefault: None\nmax-keysThe maximum number of keys you'd like to see in the response \nbody.", "The server might return fewer than this many keys, but \nwill not return more.\nType: String\nDefault: NoneNo\ndelimiterCauses keys that contain the same string between the pre\ufb01x \nand the \ufb01rst occurrence of the delimiter to be rolled up into a \nsingle result element in the CommonPre\ufb01xes collection. These \nrolled-up keys are not returned elsewhere in the response.\nType: String\nDefault: NoneNo\nSuccess Response\nThis response assumes the bucket contains the following keys:\nnotes/todos.txt\nnotes/2005-05-23/customer_mtg_notes.txt\nnotes/2005-05-23/phone_notes.txt\nnotes/2005-05-28/sales_notes.txt\nSyntax\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<ListBucketResult xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n  <Name>backups</Name> \n  <Prefix>notes/</Prefix> \nOperations on Buckets (SOAP API) API Version 2006-03-01 2898Amazon Simple Storage Service API Reference\n  <MaxKeys>1000</MaxKeys> \n  <Delimiter>/</Delimiter> \n  <IsTruncated>false</IsTruncated> \n  <Contents> \n    <Key>notes/todos.txt</Key> \n    <LastModified>2006-01-01T12:00:00.000Z</LastModified> \n    <ETag>&quot;828ef3fdfa96f00ad9f27c383fc9ac7f&quot;</ETag> \n    <Size>5126</Size> \n    <StorageClass>STANDARD</StorageClass> \n    <Owner> \n      <ID>75aa57f09aa0c8caeab4f8c24e99d10f8e7faeebf76c078efc7c6caea54ba06a</ID> \n      <DisplayName>webfile</DisplayName> \n    </Owner> \n    <StorageClass>STANDARD</StorageClass> \n  </Contents> \n  <CommonPrefixes> \n    <Prefix>notes/2005-05-23/</Prefix> \n  </CommonPrefixes> \n  <CommonPrefixes> \n    <Prefix>notes/2005-05-28/</Prefix> \n  </CommonPrefixes> \n  </ListBucketResult>\nAs you can see, many of the \ufb01elds in the response echo the request parameters. IsTruncated ,\nContents , and CommonPrefixes  are the only response elements that can contain new \ninformation.\nResponse Elements\nName Description\nContents Metadata about each object returned.\nType: XML metadata\nAncestor: ListBucketResult\nCommonPre \nfixesA response can contain CommonPrefixes  only if you specify a delimiter\n.", "When you do, CommonPrefixes  contains all (if there are any) keys \nbetween Prefix and the next occurrence of the string speci\ufb01ed by\ndelimiter . In e\ufb00ect, CommonPrefixes  lists keys that act like subdirect \nories in the directory speci\ufb01ed by Prefix.", "For example, if prefix  is\nOperations on Buckets (SOAP API) API Version 2006-03-01 2899Amazon Simple Storage Service API Reference\nName Description\nnotes/  and delimiter  is a slash (/), in notes/summer/july , the \ncommon pre\ufb01x is notes/summer/ .\nType: String\nAncestor: ListBucketResult\nDelimiter Causes keys that contain the same string between the pre\ufb01x and the \ufb01rst \noccurrence of the delimiter to be rolled up into a single result element in the \nCommonPre\ufb01xes collection. These rolled-up keys are not returned elsewhere \nin the response.\nType: String\nAncestor: ListBucketResult\nIsTruncated Speci\ufb01es whether (true) or not (false) all of the results were returned. All \nof the results may not be returned if the number of results exceeds that \nspeci\ufb01ed by MaxKeys .\nType: String\nAncestor: boolean\nMarker Indicates where in the bucket to begin listing.\nType: String\nAncestor: ListBucketResult\nMaxKeys The maximum number of keys returned in the response body.\nType: String\nAncestor: ListBucketResult\nOperations on Buckets (SOAP API) API Version 2006-03-01 2900Amazon Simple Storage Service API Reference\nName Description\nName Name of the bucket.\nType: String\nAncestor: ListBucketResult\nPrefix Keys that begin with the indicated pre\ufb01x.\nType: String\nAncestor: ListBucketResult\nResponse Body\nFor information about the list response, see Listing Keys Response.\nAccess Control\nTo list the keys of a bucket you need to have been granted READ access on the bucket.\nGetBucketAccessControlPolicy (SOAP API)\nNote\nSOAP support over HTTP is deprecated, but it is still available over HTTPS.", "New Amazon S3 \nfeatures will not be supported for SOAP.", "We recommend that you use either the REST API \nor the AWS SDKs.\nThe GetBucketAccessControlPolicy  operation fetches the access control policy for a bucket.\nExample\nThis example retrieves the access control policy for the \"quotes\" bucket.\nSample Request\n<GetBucketAccessControlPolicy xmlns=\"http://doc.s3.amazonaws.com/2006-03-01\"> \nOperations on Buckets (SOAP API) API Version 2006-03-01 2901Amazon Simple Storage Service API Reference\n  <Bucket>quotes</Bucket> \n  <AWSAccessKeyId>AKIAIOSFODNN7EXAMPLE</AWSAccessKeyId> \n  <Timestamp>2006-03-01T12:00:00.183Z</Timestamp> \n  <Signature>Iuyz3d3P0aTou39dzbqaEXAMPLE=</Signature>\n</GetBucketAccessControlPolicy>\nSample Response\n<AccessControlPolicy> \n  <Owner> \n    <ID>a9a7b886d6fd2441bf9b1c61be666e9</ID> \n    <DisplayName>chriscustomer</DisplayName> \n  </Owner> \n  <AccessControlList> \n    <Grant> \n      <Grantee xsi:type=\"CanonicalUser\"> \n        <ID>a9a7b886d6f41bf9b1c61be666e9</ID> \n        <DisplayName>chriscustomer</DisplayName> \n      </Grantee> \n      <Permission>FULL_CONTROL</Permission> \n    </Grant> \n    <Grant> \n      <Grantee xsi:type=\"Group\"> \n        <URI>http://acs.amazonaws.com/groups/global/AllUsers<URI> \n      </Grantee> \n      <Permission>READ</Permission> \n    </Grant> \n  </AccessControlList>\n<AccessControlPolicy>\nResponse Body\nThe response contains the access control policy for the bucket. For an explanation of this response, \nsee SOAP Access Policy .\nAccess Control\nYou must have READ_ACP  rights to the bucket in order to retrieve the access control policy for a \nbucket.\nOperations on Buckets (SOAP API) API Version 2006-03-01 2902Amazon Simple Storage Service API Reference\nSetBucketAccessControlPolicy (SOAP API)\nNote\nSOAP support over HTTP is deprecated, but it is still available over HTTPS.", "New Amazon S3 \nfeatures will not be supported for SOAP.", "We recommend that you use either the REST API \nor the AWS SDKs.\nThe SetBucketAccessControlPolicy  operation sets the Access Control Policy for an existing \nbucket. If successful, the previous Access Control Policy for the bucket is entirely replaced with the \nspeci\ufb01ed Access Control Policy.\nExample\nGive the speci\ufb01ed user (usually the owner) FULL_CONTROL  access to the \"quotes\" bucket.\nSample Request\n<SetBucketAccessControlPolicy xmlns=\"http://doc.s3.amazonaws.com/2006-03-01\"> \n  <Bucket>quotes</Bucket> \n  <AccessControlList> \n    <Grant> \n      <Grantee xsi:type=\"CanonicalUser\"> \n        <ID>a9a7b8863000e241bf9b1c61be666e9</ID> \n        <DisplayName>chriscustomer</DisplayName> \n      </Grantee> \n      <Permission>FULL_CONTROL</Permission> \n    </Grant> \n  </AccessControlList> \n  <AWSAccessKeyId>AKIAIOSFODNN7EXAMPLE</AWSAccessKeyId> \n  <Timestamp>2006-03-01T12:00:00.183Z</Timestamp> \n  <Signature>Iuyz3d3P0aTou39dzbqaEXAMPLE=</Signature>\n</SetBucketAccessControlPolicy >\nSample Response\n<GetBucketAccessControlPolicyResponse xmlns=\"http://s3.amazonaws.com/doc/2006-03-01\"> \n  <GetBucketAccessControlPolicyResponse> \n    <Code>200</Code> \nOperations on Buckets (SOAP API) API Version 2006-03-01 2903Amazon Simple Storage Service API Reference\n    <Description>OK</Description> \n  </GetBucketAccessControlPolicyResponse>\n</GetBucketAccessControlPolicyResponse>\nAccess Control\nYou must have WRITE_ACP  rights to the bucket in order to set the access control policy for a \nbucket.\nGetBucketLoggingStatus (SOAP API)\nNote\nSOAP support over HTTP is deprecated, but it is still available over HTTPS.", "New Amazon S3 \nfeatures will not be supported for SOAP.", "We recommend that you use either the REST API \nor the AWS SDKs.\nThe GetBucketLoggingStatus  retrieves the logging status for an existing bucket.\nFor a general introduction to this feature, see Server Logs.\nExample\nSample Request\n<?xml version=\"1.0\" encoding=\"utf-8\"?> \n    <soap:Envelope xmlns:soap=\"http://schemas.xmlsoap.org/soap/envelope/\" \n xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:xsd=\"http://\nwww.w3.org/2001/XMLSchema\"> \n      <soap:Body> \n        <GetBucketLoggingStatus xmlns=\"http://doc.s3.amazonaws.com/2006-03-01\"> \n          <Bucket>mybucket</Bucket> \n          <AWSAccessKeyId> YOUR_AWS_ACCESS_KEY_ID </AWSAccessKeyId> \n          <Timestamp>2006-03-01T12:00:00.183Z</Timestamp> \n          <Signature> YOUR_SIGNATURE_HERE </Signature> \n        </GetBucketLoggingStatus> \n      </soap:Body> \n    </soap:Envelope> \n             \nOperations on Buckets (SOAP API) API Version 2006-03-01 2904Amazon Simple Storage Service API Reference\nSample Response\n<?xml version=\"1.0\" encoding=\"utf-8\"?> \n    <soapenv:Envelope xmlns:soapenv=\"http://schemas.xmlsoap.org/soap/envelope/\" \n xmlns:xsd=\"http://www.w3.org/2001/XMLSchema\" xmlns:xsi=\"http://www.w3.org/2001/\nXMLSchema-instance\" > \n      <soapenv:Header> \n      </soapenv:Header> \n      <soapenv:Body> \n        <GetBucketLoggingStatusResponse xmlns=\"http://s3.amazonaws.com/doc/2006-03-01\"> \n          <GetBucketLoggingStatusResponse> \n            <LoggingEnabled> \n              <TargetBucket>mylogs</TargetBucket> \n              <TargetPrefix>mybucket-access_log-</TargetPrefix> \n            </LoggingEnabled> \n          </GetBucketLoggingStatusResponse> \n        </GetBucketLoggingStatusResponse> \n      </soapenv:Body> \n    </soapenv:Envelope> \n             \nAccess Control\nOnly the owner of a bucket is permitted to invoke this operation.\nSetBucketLoggingStatus (SOAP API)\nNote\nSOAP support over HTTP is deprecated, but it is still available over HTTPS.", "New Amazon S3 \nfeatures will not be supported for SOAP.", "We recommend that you use either the REST API \nor the AWS SDKs.\nThe SetBucketLoggingStatus  operation updates the logging status for an existing bucket.\nFor a general introduction to this feature, see Server Logs.\nExample\nThis sample request enables server access logging for the 'mybucket' bucket, and con\ufb01gures the \nlogs to be delivered to 'mylogs' under pre\ufb01x 'access_log-'\nOperations on Buckets (SOAP API) API Version 2006-03-01 2905Amazon Simple Storage Service API Reference\nSample Request\n<?xml version=\"1.0\" encoding=\"utf-8\"?> \n    <soap:Envelope xmlns:soap=\"http://schemas.xmlsoap.org/soap/envelope/\" \n xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:xsd=\"http://\nwww.w3.org/2001/XMLSchema\"> \n    <soap:Body> \n    <SetBucketLoggingStatus xmlns=\"http://doc.s3.amazonaws.com/2006-03-01\"> \n      <Bucket>myBucket</Bucket> \n      <AWSAccessKeyId> YOUR_AWS_ACCESS_KEY_ID </AWSAccessKeyId> \n      <Timestamp>2006-03-01T12:00:00.183Z</Timestamp> \n      <Signature> YOUR_SIGNATURE_HERE </Signature> \n      <BucketLoggingStatus> \n        <LoggingEnabled> \n          <TargetBucket>mylogs</TargetBucket> \n          <TargetPrefix>mybucket-access_log-</TargetPrefix> \n        </LoggingEnabled> \n      </BucketLoggingStatus> \n    </SetBucketLoggingStatus> \n    </soap:Body> \n    :</soap:Envelope> \n         \nSample Response\n<?xml version=\"1.0\" encoding=\"utf-8\"?> \n    <soapenv:Envelope xmlns:soapenv=\"http://schemas.xmlsoap.org/soap/envelope/\" \n xmlns:xsd=\"http://www.w3.org/2001/XMLSchema\" xmlns:xsi=\"http://www.w3.org/2001/\nXMLSchema-instance\" > \n      <soapenv:Header> \n      </soapenv:Header> \n      <soapenv:Body> \n        <SetBucketLoggingStatusResponse xmlns=\"http://s3.amazonaws.com/doc/2006-03-01\"/\n> \n      </soapenv:Body> \n    </soapenv:Envelope> \n             \nAccess Control\nOnly the owner of a bucket is permitted to invoke this operation.\nOperations on Buckets (SOAP API) API Version 2006-03-01 2906Amazon Simple Storage Service API Reference\nOperations on Objects (SOAP API)\nNote\nSOAP support over HTTP is deprecated, but it is still available over HTTPS.", "New Amazon S3 \nfeatures will not be supported for SOAP. We recommend that you use either the REST API \nor the AWS SDKs.\nThis section describes operations you can perform on Amazon S3 objects.\nTopics\n\u2022PutObjectInline (SOAP API)\n\u2022PutObject (SOAP API)\n\u2022CopyObject (SOAP API)\n\u2022GetObject (SOAP API)\n\u2022GetObjectExtended (SOAP API)\n\u2022DeleteObject (SOAP API)\n\u2022GetObjectAccessControlPolicy (SOAP API)\n\u2022SetObjectAccessControlPolicy (SOAP API)\nPutObjectInline (SOAP API)\nNote\nSOAP support over HTTP is deprecated, but it is still available over HTTPS. New Amazon S3 \nfeatures will not be supported for SOAP.", "We recommend that you use either the REST API \nor the AWS SDKs.\nThe PutObjectInline  operation adds an object to a bucket.", "The data for the object is provided \nin the body of the SOAP message.\nIf an object already exists in a bucket, the new object will overwrite it because Amazon S3 stores \nthe last write request. However, Amazon S3 is a distributed system. If Amazon S3 receives multiple \nOperations on Objects (SOAP API) API Version 2006-03-01 2907Amazon Simple Storage Service API Reference\nwrite requests for the same object nearly simultaneously, all of the objects might be stored, even \nthough only one wins in the end. Amazon S3 does not provide object locking; if you need this, \nmake sure to build it into your application layer.\nTo ensure an object is not corrupted over the network, you can calculate the MD5 of an object, PUT \nit to Amazon S3, and compare the returned Etag to the calculated MD5 value.\nPutObjectInline is not suitable for use with large objects.", "The system limits this \noperation to working with objects 1MB or smaller.", "PutObjectInline will fail with the\nInlineDataTooLargeError  status code if the Data parameter encodes an object larger than \n1MB. To upload large objects, consider using the non-inline PutObject API, or the REST API instead.\nExample\nThis example writes some text and metadata into the \"Nelson\" object in the \"quotes\" bucket, give \na user (usually the owner) FULL_CONTROL  access to the object, and make the object readable by \nanonymous parties.\nSample Request\n<PutObjectInline xmlns=\"http://doc.s3.amazonaws.com/2006-03-01\"> \n  <Bucket>quotes</Bucket> \n  <Key>Nelson</Key> \n  <Metadata> \n    <Name>Content-Type</Name> \n    <Value>text/plain</Value> \n  </Metadata> \n  <Metadata> \n    <Name>family</Name> \n    <Value>Muntz</Value> \n  </Metadata> \n  <Data>aGEtaGE=</Data> \n  <ContentLength>5</ContentLength> \n  <AccessControlList> \n    <Grant> \n      <Grantee xsi:type=\"CanonicalUser\"> \n        <ID>a9a7b886d6fde241bf9b1c61be666e9</ID> \n        <DisplayName>chriscustomer</DisplayName> \n      </Grantee> \n      <Permission>FULL_CONTROL</Permission> \n    </Grant> \n    <Grant> \nOperations on Objects (SOAP API) API Version 2006-03-01 2908Amazon Simple Storage Service API Reference\n      <Grantee xsi:type=\"Group\"> \n        <URI>http://acs.amazonaws.com/groups/global/AllUsers</URI> \n      </Grantee> \n      <Permission>READ</Permission> \n    </Grant> \n  </AccessControlList> \n  <AWSAccessKeyId>AKIAIOSFODNN7EXAMPLE</AWSAccessKeyId> \n  <Timestamp>2006-03-01T12:00:00.183Z</Timestamp> \n  <Signature>Iuyz3d3P0aTou39dzbqaEXAMPLE=</Signature>\n</PutObjectInline>\nSample Response\n<PutObjectInlineResponse xmlns=\"http://s3.amazonaws.com/doc/2006-03-01\"> \n  <PutObjectInlineResponse> \n    <ETag>&quot828ef3fdfa96f00ad9f27c383fc9ac7f&quot</ETag> \n    <LastModified>2006-01-01T12:00:00.000Z</lastModified> \n  </PutObjectInlineResponse>\n</PutObjectInlineResponse>\nElements\n\u2022Bucket: The bucket in which to add the object.\n\u2022Key: The key to assign to the object.\nImportant\nReplacement must be made for object keys containing special characters (such as \ncarriage returns) when using XML requests.", "For more information, see  XML related object \nkey constraints.\n\u2022Metadata:  You can provide name-value metadata pairs in the metadata element.", "These will be \nstored with the object.\n\u2022Data: The base 64 encoded form of the data.\n\u2022ContentLength:  The length of the data in bytes.\nOperations on Objects (SOAP API) API Version 2006-03-01 2909Amazon Simple Storage Service API Reference\n\u2022AccessControlList:  An Access Control List for the resource.", "This element is optional.", "If \nomitted, the requester is given FULL_CONTROL  access to the object. If the object already exists, \nthe preexisting access control policy is replaced.\nResponses\n\u2022ETag: The entity tag is an MD5 hash of the object that you can use to do conditional fetches \nof the object using GetObjectExtended .", "The ETag only re\ufb02ects changes to the contents of an \nobject, not its metadata.\n\u2022LastModified:  The Amazon S3 timestamp for the saved object.\nAccess Control\nYou must have WRITE access to the bucket in order to put objects into the bucket.\nRelated Resources\n\u2022PutObject (SOAP API)\n\u2022CopyObject (SOAP API)\nPutObject (SOAP API)\nNote\nSOAP support over HTTP is deprecated, but it is still available over HTTPS. New Amazon S3 \nfeatures will not be supported for SOAP.", "We recommend that you use either the REST API \nor the AWS SDKs.\nThe PutObject  operation adds an object to a bucket. The data for the object is attached as a DIME \nattachment.\nTo ensure an object is not corrupted over the network, you can calculate the MD5 of an object, PUT \nit to Amazon S3, and compare the returned Etag to the calculated MD5 value.\nIf an object already exists in a bucket, the new object will overwrite it because Amazon S3 stores \nthe last write request. However, Amazon S3 is a distributed system. If Amazon S3 receives multiple \nOperations on Objects (SOAP API) API Version 2006-03-01 2910Amazon Simple Storage Service API Reference\nwrite requests for the same object nearly simultaneously, all of the objects might be stored, even \nthough only one wins in the end. Amazon S3 does not provide object locking; if you need this, \nmake sure to build it into your application layer.\nExample\nThis example puts some data and metadata in the \"Nelson\" object of the \"quotes\" bucket, give a \nuser (usually the owner) FULL_CONTROL  access to the object, and make the object readable by \nanonymous parties.", "In this sample, the actual attachment is not shown.\nSample Request\n<PutObject xmlns=\"http://doc.s3.amazonaws.com/2006-03-01\"> \n  <Bucket>quotes</Bucket> \n  <Key>Nelson</Key> \n  <Metadata> \n    <Name>Content-Type</Name> \n    <Value>text/plain</Value> \n  </Metadata> \n  <Metadata> \n    <Name>family</Name> \n    <Value>Muntz</Value> \n  </Metadata> \n  <ContentLength>5</ContentLength> \n  <AccessControlList> \n    <Grant> \n      <Grantee xsi:type=\"CanonicalUser\"> \n        <ID>a9a7b886d6241bf9b1c61be666e9</ID> \n        <DisplayName>chriscustomer</DisplayName> \n      </Grantee> \n      <Permission>FULL_CONTROL</Permission> \n    </Grant> \n    <Grant> \n      <Grantee xsi:type=\"Group\"> \n        <URI>http://acs.amazonaws.com/groups/global/AllUsers<URI> \n      </Grantee> \n      <Permission>READ</Permission> \n    </Grant> \n  </AccessControlList> \n  <AWSAccessKeyId>AKIAIOSFODNN7EXAMPLE</AWSAccessKeyId> \n  <Timestamp>2007-05-11T12:00:00.183Z</Timestamp> \n  <Signature>Iuyz3d3P0aTou39dzbqaEXAMPLE=</Signature>\n</PutObject>\nOperations on Objects (SOAP API) API Version 2006-03-01 2911Amazon Simple Storage Service API Reference\nSample Response\n<PutObjectResponse xmlns=\"http://s3.amazonaws.com/doc/2006-03-01\"> \n  <PutObjectResponse> \n    <ETag>&quot;828ef3fdfa96f00ad9f27c383fc9ac7f&quot;</ETag> \n    <LastModified>2006-03-01T12:00:00.183Z</LastModified> \n  </PutObjectResponse>\n</PutObjectResponse>\nElements\n\u2022Bucket: The bucket in which to add the object.\n\u2022Key: The key to assign to the object.\nImportant\nReplacement must be made for object keys containing special characters (such as \ncarriage returns) when using XML requests.", "For more information, see  XML related object \nkey constraints.\n\u2022Metadata:  You can provide name-value metadata pairs in the metadata element.", "These will be \nstored with the object.\n\u2022ContentLength:  The length of the data in bytes.\n\u2022AccessControlList:  An Access Control List for the resource.", "This element is optional.", "If \nomitted, the requester is given FULL_CONTROL  access to the object. If the object already exists, \nthe preexisting Access Control Policy is replaced.\nResponses\n\u2022ETag: The entity tag is an MD5 hash of the object that you can use to do conditional fetches \nof the object using GetObjectExtended .", "The ETag only re\ufb02ects changes to the contents of an \nobject, not its metadata.\n\u2022LastModified:  The Amazon S3 timestamp for the saved object.\nAccess Control\nTo put objects into a bucket, you must have WRITE access to the bucket.\nOperations on Objects (SOAP API) API Version 2006-03-01 2912Amazon Simple Storage Service API Reference\nRelated Resources\n\u2022CopyObject (SOAP API)\nCopyObject (SOAP API)\nNote\nSOAP support over HTTP is deprecated, but it is still available over HTTPS. New Amazon S3 \nfeatures will not be supported for SOAP.", "We recommend that you use either the REST API \nor the AWS SDKs.\nDescription\nThe CopyObject  operation creates a copy of an object when you specify the key and bucket of a \nsource object and the key and bucket of a target destination.\nWhen copying an object, you can preserve all metadata (default) or specify new metadata.", "\nHowever, the ACL is not preserved and is set to private for the user making the request. To \noverride the default ACL setting, specify a new ACL when generating a copy request. For more \ninformation, see Using ACLs.\nAll copy requests must be authenticated.", "Additionally, you must have read access to the source \nobject and write  access to the destination bucket. For more information, see Using Auth Access.\nTo only copy an object under certain conditions, such as whether the Etag matches or \nwhether the object was modi\ufb01ed before or after a speci\ufb01ed date, use the request parameters\nCopySourceIfUnmodifiedSince , CopyIfUnmodifiedSince , CopySourceIfMatch , or\nCopySourceIfNoneMatch .\nNote\nYou might need to con\ufb01gure the SOAP stack socket timeout for copying large objects.\nRequest Syntax\n<CopyObject xmlns=\"http:// bucket_name .s3.amazonaws.com/2006-03-01\"> \nOperations on Objects (SOAP API) API Version 2006-03-01 2913Amazon Simple Storage Service API Reference\n  <SourceBucket> source_bucket </SourceBucket> \n  <SourceObject> source_object </SourceObject> \n  <DestinationBucket> destination_bucket </DestinationBucket> \n  <DestinationObject> destination_object </DestinationObject> \n  <MetadataDirective>{REPLACE | COPY}</MetadataDirective> \n  <Metadata> \n    <Name> metadata_name </Name> \n    <Value> metadata_value </Value> \n  </Metadata> \n  ...", "\n  <AccessControlList> \n    <Grant> \n      <Grantee xsi:type=\" user_type \"> \n        <ID> user_id</ID> \n        <DisplayName> display_name </DisplayName> \n      </Grantee> \n      <Permission> permission </Permission> \n    </Grant> \n    ...", "\n  </AccessControlList> \n  <CopySourceIfMatch> etag</CopySourceIfMatch> \n  <CopySourceIfNoneMatch> etag</CopySourceIfNoneMatch> \n  <CopySourceIfModifiedSince> date_time </CopySourceIfModifiedSince> \n  <CopySourceIfUnmodifiedSince> date_time </CopySourceIfUnmodifiedSince> \n  <AWSAccessKeyId> AWSAccessKeyId </AWSAccessKeyId> \n  <Timestamp> TimeStamp </Timestamp> \n  <Signature> Signature </Signature>\n</CopyObject>\nRequest Parameters\nName Description Required\nSourceBucket The name of the source bucket.\nType: String\nDefault: None\nConstraints: A valid source bucket.Yes\nSourceKey The key name of the source object.", "Yes\nOperations on Objects (SOAP API) API Version 2006-03-01 2914Amazon Simple Storage Service API Reference\nName Description Required\nType: String\nDefault: None\nConstraints: The key for a valid source \nobject to which you  have READ access.\nImportant\nReplacement must be made \nfor object keys containing \nspecial characters (such as \ncarriage returns) when using XML \nrequests. For more informati \non, see  XML related object key \nconstraints.\nDestinationBucket The name of the destination bucket.\nType: String\nDefault: None\nConstraints: You must have WRITE access \nto the destination  bucket.Yes\nDestinationKey The key of the destination object.\nType: String\nDefault: None\nConstraints: You must have WRITE access \nto the destination  bucket.Yes\nOperations on Objects (SOAP API) API Version 2006-03-01 2915Amazon Simple Storage Service API Reference\nName Description Required\nMetadataDirective Speci\ufb01es whether the metadata is copied \nfrom the source  object or replaced with \nmetadata provided in the request.\nType: String\nDefault: COPY\nValid values: COPY | REPLACE\nConstraints: Values other than COPY  or  \n  REPLACE will result in an immediate \nerror. You  cannot copy an object to itself \nunless the MetadataDirective header  is \nspeci\ufb01ed and its value set to REPLACE .No\nMetadata Speci\ufb01es metadata name-value pairs to \nset for the object.If MetadataDirective is \nset to COPY, all metadata is  ignored.\nType: String\nDefault: None\nConstraints: None.No\nAccessControlList Grants access to users by e-mail \naddresses or canonical user  ID.\nType: String\nDefault: None\nConstraints: NoneNo\nOperations on Objects (SOAP API) API Version 2006-03-01 2916Amazon Simple Storage Service API Reference\nName Description Required\nCopySourceIfMatch Copies the object if its entity tag (ETag) \nmatches the  specified tag; otherwise \nreturn a PreconditionFailed.\nType: String\nDefault: None\nConstraints: None. If the Etag does not \nmatch, the object is  not copied.No\nCopySourceIfNoneMatch Copies the object if its entity tag (ETag) \nis di\ufb00erent than  the speci\ufb01ed Etag; \notherwise returns an error.\nType: String\nDefault: None\nConstraints: None.No\nCopySourceIfUnmodi \nfiedSinceCopies the object if it hasn't been \nmodi\ufb01ed since the  specified time; \notherwise returns a PreconditionFailed.\nType: dateTime\nDefault: NoneNo\nCopySourceIfModifiedSince Copies the object if it has been modi\ufb01ed \nsince the speci\ufb01ed time; otherwise \nreturns an error.\nType: dateTime\nDefault: NoneNo\nOperations on Objects (SOAP API) API Version 2006-03-01 2917Amazon Simple Storage Service API Reference\nResponse Syntax\n<CopyObjectResponse xmlns=\"http:// bucket_name .s3.amazonaws.com/2006-03-01\"> \n  <CopyObjectResponse> \n    <ETag>\" etag\"</ETag> \n    <LastModified> timestamp </LastModified> \n  </CopyObjectResponse>\n</CopyObjectResponse>\nResponse Elements\nFollowing is a list of response elements.\nNote\nThe SOAP API does not return extra whitespace. Extra whitespace is only returned by the \nREST API.\nName Description\nEtag Returns the etag of the new object.", "The ETag only \nre\ufb02ects changes to the contents of an object, not \nits metadata.\nType: String\nAncestor: CopyObjectResult\nLastModified Returns the date the object was last modi\ufb01ed.\nType: String\nAncestor: CopyObjectResult\nFor information about general response elements, see Using REST Error Response Headers.\nOperations on Objects (SOAP API) API Version 2006-03-01 2918Amazon Simple Storage Service API Reference\nSpecial Errors\nThere are no special errors for this operation. For information about general Amazon S3 errors, see\nList of error codes.\nExamples\nThis example copies the flotsam object from the pacific bucket to the jetsam object of the\natlantic  bucket, preserving its metadata.\nSample Request\n<CopyObject xmlns=\"http://doc.s3.amazonaws.com/2006-03-01\"> \n  <SourceBucket>pacific</SourceBucket> \n  <SourceObject>flotsam</SourceObject> \n  <DestinationBucket>atlantic</DestinationBucket> \n  <DestinationObject>jetsam</DestinationObject> \n  <AWSAccessKeyId>AKIAIOSFODNN7EXAMPLE</AWSAccessKeyId> \n  <Timestamp>2008-02-18T13:54:10.183Z</Timestamp> \n  <Signature>Iuyz3d3P0aTou39dzbq7RrtSFmw=</Signature>\n</CopyObject>\nSample Response\n<CopyObjectResponse xmlns=\"http://doc.s3.amazonaws.com/2006-03-01\"> \n  <CopyObjectResponse> \n    <ETag>\"828ef3fdfa96f00ad9f27c383fc9ac7f\"</ETag> \n    <LastModified>2008-02-18T13:54:10.183Z</LastModified> \n  </CopyObjectResponse>\n</CopyObjectResponse>\nThis example copies the \"tweedledee\" object from the wonderland bucket to the \"tweedledum\" \nobject of the wonderland bucket, replacing its metadata.\nSample Request\n<CopyObject xmlns=\"http://doc.s3.amazonaws.com/2006-03-01\"> \n  <SourceBucket>wonderland</SourceBucket> \n  <SourceObject>tweedledee</SourceObject> \n  <DestinationBucket>wonderland</DestinationBucket> \n  <DestinationObject>tweedledum</DestinationObject> \n  <MetadataDirective >REPLACE</MetadataDirective > \nOperations on Objects (SOAP API) API Version 2006-03-01 2919Amazon Simple Storage Service API Reference\n  <Metadata> \n    <Name>Content-Type</Name> \n    <Value>text/plain</Value> \n  </Metadata> \n  <Metadata> \n    <Name>relationship</Name> \n    <Value>twins</Value> \n  </Metadata> \n  <AWSAccessKeyId>AKIAIOSFODNN7EXAMPLE</AWSAccessKeyId> \n  <Timestamp>2008-02-18T13:54:10.183Z</Timestamp> \n  <Signature>Iuyz3d3P0aTou39dzbq7RrtSFmw=</Signature>\n</CopyObject>\nSample Response\n<CopyObjectResponse xmlns=\"http://doc.s3.amazonaws.com/2006-03-01\"> \n  <CopyObjectResponse> \n    <ETag>\"828ef3fdfa96f00ad9f27c383fc9ac7f\"</ETag> \n    <LastModified>2008-02-18T13:54:10.183Z</LastModified> \n  </CopyObjectResponse>\n</CopyObjectResponse>\nRelated Resources\n\u2022PutObject (SOAP API)\n\u2022PutObjectInline (SOAP API)\nGetObject (SOAP API)\nNote\nSOAP support over HTTP is deprecated, but it is still available over HTTPS.", "New Amazon S3 \nfeatures will not be supported for SOAP.", "We recommend that you use either the REST API \nor the AWS SDKs.\nThe GetObject  operation returns the current version of an object.", "If you try to GetObject\nan object that has a delete marker as its current version, S3 returns a 404 error.", "You cannot use \nthe SOAP API to retrieve a speci\ufb01ed version of an object. To do that, use the REST API. For more \ninformation, see Versioning.", "For more options, use the GetObjectExtended (SOAP API) operation.\nOperations on Objects (SOAP API) API Version 2006-03-01 2920Amazon Simple Storage Service API Reference\nNote\nObject key names with the value \"soap\" aren't supported for virtual-hosted-style requests. \nFor object key name values where \"soap\" is used, a path-style URL must be used instead.\nExample\nThis example gets the \"Nelson\" object from the \"quotes\" bucket.\nSample Request\n<GetObject xmlns=\"http://doc.s3.amazonaws.com/2006-03-01\"> \n  <Bucket>quotes</Bucket> \n  <Key>Nelson</Key> \n  <GetMetadata>true</GetMetadata> \n  <GetData>true</GetData> \n  <InlineData>true</InlineData> \n  <AWSAccessKeyId>AKIAIOSFODNN7EXAMPLE</AWSAccessKeyId> \n  <Timestamp>2006-03-01T12:00:00.183Z</Timestamp> \n  <Signature>Iuyz3d3P0aTou39dzbqaEXAMPLE=</Signature>\n</GetObject>\nSample Response\n<GetObjectResponse xmlns=\"http://s3.amazonaws.com/doc/2006-03-01\"> \n  <GetObjectResponse> \n    <Status> \n      <Code>200</Code> \n      <Description>OK</Description> \n    </Status> \n    <Metadata> \n      <Name>Content-Type</Name> \n      <Value>text/plain</Value> \n    </Metadata> \n    <Metadata> \n      <Name>family</Name> \n      <Value>Muntz</Value> \n    </Metadata> \n    <Data>aGEtaGE=</Data> \n    <LastModified>2006-01-01T12:00:00.000Z</LastModified> \n    <ETag>&quot;828ef3fdfa96f00ad9f27c383fc9ac7f&quot;</ETag> \nOperations on Objects (SOAP API) API Version 2006-03-01 2921Amazon Simple Storage Service API Reference\n  </GetObjectResponse>\n</GetObjectResponse>\nElements\n\u2022Bucket: The bucket from which to retrieve the object.\n\u2022Key: The key that identi\ufb01es the object.\nImportant\nReplacement must be made for object keys containing special characters (such as \ncarriage returns) when using XML requests. For more information, see  XML related object \nkey constraints.\n\u2022GetMetadata:  The metadata is returned with the object if this is true.\n\u2022GetData:  The object data is returned if this is true.\n\u2022InlineData:  If this is true, then the data is returned, base 64-encoded, as part of the SOAP \nbody of the response. If false, then the data is returned as a SOAP attachment.", "The InlineData \noption is not suitable for use with large objects.", "The system limits this operation to working \nwith 1MB of data or less.", "A GetObject request with the InlineData \ufb02ag set will fail with the\nInlineDataTooLargeError  status code if the resulting Data parameter would have encoded \nmore than 1MB. To download large objects, consider calling GetObject without setting the \nInlineData \ufb02ag, or use the REST API instead.\nReturned Elements\n\u2022Metadata:  The name-value paired metadata stored with the object.\n\u2022Data: If InlineData was true in the request, this contains the base 64 encoded object data.\n\u2022LastModified:  The time that the object was stored in Amazon S3.\n\u2022ETag: The object's entity tag.", "This is a hash of the object that can be used to do conditional \ngets.", "The ETag only re\ufb02ects changes to the contents of an object, not its metadata.\nAccess Control\nYou can read an object only if you have been granted READ access to the object.\nOperations on Objects (SOAP API) API Version 2006-03-01 2922Amazon Simple Storage Service API Reference\nSOAP Chunked and Resumable Downloads\nTo provide GET \ufb02exibility, Amazon S3 supports chunked and resumable downloads.\nSelect from the following:\n\u2022For large object downloads, you might want to break them into smaller chunks.", "For more \ninformation, see Range GETs\n\u2022For GET operations that fail, you can design your application to download the remainder instead \nof the entire \ufb01le.", "For more information, see REST GET Error Recovery\nRange GETs\nFor some clients, you might want to break large downloads into smaller downloads.", "To break a GET \ninto smaller units, use Range.\nBefore you can break a GET into smaller units, you must determine its size.", "For example, the \nfollowing request gets the size of the big\ufb01le object.\n<ListBucket xmlns=\"http://doc.s3.amazonaws.com/2006-03-01\"> \n  <Bucket>bigbucket</Bucket> \n  <Prefix>bigfile</Prefix> \n  <MaxKeys>1</MaxKeys> \n  <AWSAccessKeyId>AKIAIOSFODNN7EXAMPLE</AWSAccessKeyId> \n  <Timestamp>2006-03-01T12:00:00.183Z</Timestamp> \n  <Signature>Iuyz3d3P0aTou39dzbqaEXAMPLE=</Signature>\n</ListBucket>\nAmazon S3 returns the following response.\n<ListBucketResult xmlns=\"http://s3.amazonaws.com/doc/2006-03-01\"> \n  <Name>quotes</Name> \n  <Prefix>N</Prefix> \n  <MaxKeys>1</MaxKeys> \n  <IsTruncated>false</IsTruncated> \n  <Contents> \n    <Key>bigfile</Key> \n    <LastModified>2006-01-01T12:00:00.000Z</LastModified> \n    <ETag>&quot;828ef3fdfa96f00ad9f27c383fc9ac7f&quot;</ETag> \n    <Size>2023276</Size> \nOperations on Objects (SOAP API) API Version 2006-03-01 2923Amazon Simple Storage Service API Reference\n    <StorageClass>STANDARD</StorageClass> \n    <Owner> \n      <ID>bcaf1ffd86f41161ca5fb16fd081034f</ID> \n      <DisplayName>bigfile</DisplayName> \n     </Owner> \n  </Contents>\n</ListBucketResult>\nFollowing is a request that downloads the \ufb01rst megabyte from the big\ufb01le object.\n<GetObject xmlns=\"http://doc.s3.amazonaws.com/2006-03-01\"> \n  <Bucket>bigbucket</Bucket> \n  <Key>bigfile</Key> \n  <GetMetadata>true</GetMetadata> \n  <GetData>true</GetData> \n  <InlineData>true</InlineData> \n  <ByteRangeStart>0</ByteRangeStart> \n  <ByteRangeEnd>1048576</ByteRangeEnd> \n  <AWSAccessKeyId>AKIAIOSFODNN7EXAMPLE</AWSAccessKeyId> \n  <Timestamp>2006-03-01T12:00:00.183Z</Timestamp> \n  <Signature>Iuyz3d3P0aTou39dzbqaEXAMPLE=</Signature>\n</GetObject>\nAmazon S3 returns the \ufb01rst megabyte of the \ufb01le and the Etag of the \ufb01le.\n<GetObjectResponse xmlns=\"http://s3.amazonaws.com/doc/2006-03-01\"> \n  <GetObjectResponse> \n    <Status> \n      <Code>200</Code> \n      <Description>OK</Description> \n    </Status> \n    <Metadata> \n      <Name>Content-Type</Name> \n      <Value>text/plain</Value> \n    </Metadata> \n    <Metadata> \n      <Name>family</Name> \n      <Value>Muntz</Value> \n    </Metadata> \n    <Data>--first megabyte of bigfile--</Data> \n    <LastModified>2006-01-01T12:00:00.000Z</LastModified> \n    <ETag>\"828ef3fdfa96f00ad9f27c383fc9ac7f\"</ETag> \n  </GetObjectResponse>\nOperations on Objects (SOAP API) API Version 2006-03-01 2924Amazon Simple Storage Service API Reference\n</GetObjectResponse>\nTo ensure the \ufb01le did not change since the previous portion was downloaded, specify the IfMatch \nelement. Although the IfMatch element is not required, it is recommended for content that is likely \nto change.\nThe following is a request that gets the remainder of the \ufb01le, using the IfMatch request header.\n<GetObject xmlns=\"http://doc.s3.amazonaws.com/2006-03-01\"> \n  <Bucket>bigbucket</Bucket> \n  <Key>bigfile</Key> \n  <GetMetadata>true</GetMetadata> \n  <GetData>true</GetData> \n  <InlineData>true</InlineData> \n  <ByteRangeStart>10485761</ByteRangeStart> \n  <ByteRangeEnd>2023276</ByteRangeEnd> \n  <IfMatch>\"828ef3fdfa96f00ad9f27c383fc9ac7f\"</IfMatch> \n  <AWSAccessKeyId>AKIAIOSFODNN7EXAMPLE</AWSAccessKeyId> \n  <Timestamp>2006-03-01T12:00:00.183Z</Timestamp> \n  <Signature>Iuyz3d3P0aTou39dzbqaEXAMPLE=</Signature>\n</GetObject>\nAmazon S3 returns the following response and the remainder of the \ufb01le.\n<GetObjectResponse xmlns=\"http://s3.amazonaws.com/doc/2006-03-01\"> \n  <GetObjectResponse> \n    <Status> \n      <Code>200</Code> \n      <Description>OK</Description> \n    </Status> \n    <Metadata> \n      <Name>Content-Type</Name> \n      <Value>text/plain</Value> \n    </Metadata> \n    <Metadata> \n      <Name>family</Name> \n      <Value>>Muntz</Value> \n    </Metadata> \n    <Data>--remainder of bigfile--</Data> \n    <LastModified>2006-01-01T12:00:00.000Z</LastModified> \n    <ETag>\"828ef3fdfa96f00ad9f27c383fc9ac7f\"</ETag> \n  </GetObjectResponse>\nOperations on Objects (SOAP API) API Version 2006-03-01 2925Amazon Simple Storage Service API Reference\n</GetObjectResponse>\nVersioned GetObject\nThe following request returns the speci\ufb01ed version of the object in the bucket.\n<GetObject xmlns=\"http://doc.s3.amazonaws.com/2006-03-01\">\n<Bucket>quotes</Bucket>\n<Key>Nelson</Key>\n<GetMetadata>true</GetMetadata>\n<GetData>true</GetData>\n<InlineData>true</InlineData>\n<AWSAccessKeyId>AKIAIOSFODNN7EXAMPLE</AWSAccessKeyId>\n<Timestamp>2006-03-01T12:00:00.183Z</Timestamp>\n<Signature>Iuyz3d3P0aTou39dzbqaEXAMPLE=</Signature>\n</GetObject>\nSample Response\n<GetObjectResponse xmlns=\"http://s3.amazonaws.com/doc/2006-03-01\">\n<GetObjectResponse>\n<Status>\n<Code>200</Code>\n<Description>OK</Description>\n</Status>\n<Metadata>\n<Name>Content-Type</Name>\n<Value>text/plain</Value>\n</Metadata>\n<Metadata>\n<Name>family</Name>\n<Value>Muntz</Value>\n</Metadata>\n<Data>aGEtaGE=</Data>\n<LastModified>2006-01-01T12:00:00.000Z</LastModified>\n<ETag>&quot;828ef3fdfa96f00ad9f27c383fc9ac7f&quot;</ETag>\n</GetObjectResponse>\n</GetObjectResponse>\nOperations on Objects (SOAP API) API Version 2006-03-01 2926Amazon Simple Storage Service API Reference\nREST GET Error Recovery\nIf an object GET fails, you can get the rest of the \ufb01le by specifying the range to download.", "To do so, \nyou must get the size of the object using ListBucket  and perform a range GET on the remainder \nof the \ufb01le.", "For more information, see GetObjectExtended (SOAP API).\nRelated Resources\nOperations on Objects (SOAP API)\nGetObjectExtended (SOAP API)\nNote\nSOAP support over HTTP is deprecated, but it is still available over HTTPS.", "New Amazon S3 \nfeatures will not be supported for SOAP.", "We recommend that you use either the REST API \nor the AWS SDKs.\nGetObjectExtended  is exactly like GetObject (SOAP API), except that it supports the following \nadditional elements that can be used to accomplish much of the same functionality provided by \nHTTP GET headers (go to http://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html).\nGetObjectExtended supports the following elements in addition to those supported by GetObject:\n\u2022ByteRangeStart, ByteRangeEnd:  These elements specify that only a portion of the object \ndata should be retrieved. They follow the behavior of the HTTP byte ranges (go to http:// \nwww.w3.org/Protocols/rfc2616/rfc2616-sec14.html#sec14.35).\n\u2022IfModifiedSince:  Return the object only if the object's timestamp is later than the speci\ufb01ed \ntimestamp. ( http://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html#sec14.25)\n\u2022IfUnmodifiedSince:  Return the object only if the object's timestamp is earlier than or \nequal to the speci\ufb01ed timestamp. (go to http://www.w3.org/Protocols/rfc2616/rfc2616-\nsec14.html#sec14.28 )\n\u2022IfMatch:  Return the object only if its ETag matches the supplied tag(s). (go to http:// \nwww.w3.org/Protocols/rfc2616/rfc2616-sec14.html#sec14.24)\n\u2022IfNoneMatch:  Return the object only if its ETag does not match the supplied tag(s). (go to\nhttp://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html#sec14.26)\nOperations on Objects (SOAP API) API Version 2006-03-01 2927Amazon Simple Storage Service API Reference\n\u2022ReturnCompleteObjectOnConditionFailure: ReturnCompleteObjectOnConditionFailure: \nIf true, then if the request includes a range element and one or both of IfUnmodi\ufb01edSince/\nIfMatch elements, and the condition fails, return the entire object rather than a fault. This \nenables the If-Range functionality (go to http://www.w3.org/Protocols/rfc2616/rfc2616-\nsec14.html#sec14.27 ).\nDeleteObject (SOAP API)\nNote\nSOAP support over HTTP is deprecated, but it is still available over HTTPS.", "New Amazon S3 \nfeatures will not be supported for SOAP. We recommend that you use either the REST API \nor the AWS SDKs.\nThe DeleteObject  operation removes the speci\ufb01ed object from Amazon S3. Once deleted, there \nis no method to restore or undelete an object.\nNote\nIf you delete an object that does not exist, Amazon S3 will return a success (not an error \nmessage).\nExample\nThis example deletes the \"Nelson\" object from the \"quotes\" bucket.\nSample Request\n<DeleteObject xmlns=\"http://doc.s3.amazonaws.com/2006-03-01\"> \n  <Bucket>quotes</Bucket> \n  <Key>Nelson</Key> \n  <AWSAccessKeyId> AKIAIOSFODNN7EXAMPLE</AWSAccessKeyId> \n  <Timestamp>2006-03-01T12:00:00.183Z</Timestamp> \n  <Signature>Iuyz3d3P0aTou39dzbqaEXAMPLE=</Signature>\n</DeleteObject>\nSample Response\nOperations on Objects (SOAP API) API Version 2006-03-01 2928Amazon Simple Storage Service API Reference\n<DeleteObjectResponse xmlns=\"http://s3.amazonaws.com/doc/2006-03-01\"> \n  <DeleteObjectResponse> \n    <Code>200</Code> \n    <Description>OK</Description> \n  </DeleteObjectResponse>\n</DeleteObjectResponse>\nElements\n\u2022Bucket: The bucket that holds the object.\n\u2022Key: The key that identi\ufb01es the object.\nImportant\nReplacement must be made for object keys containing special characters (such as \ncarriage returns) when using XML requests. For more information, see  XML related object \nkey constraints.\nAccess Control\nYou can delete an object only if you have WRITE access to the bucket, regardless of who owns the \nobject or what rights are granted to it.\nGetObjectAccessControlPolicy (SOAP API)\nNote\nSOAP support over HTTP is deprecated, but it is still available over HTTPS.", "New Amazon S3 \nfeatures will not be supported for SOAP.", "We recommend that you use either the REST API \nor the AWS SDKs.\nThe GetObjectAccessControlPolicy  operation fetches the access control policy for an object.\nOperations on Objects (SOAP API) API Version 2006-03-01 2929Amazon Simple Storage Service API Reference\nImportant\nReplacement must be made for object keys containing special characters (such as carriage \nreturns) when using XML requests. For more information, see  XML related object key \nconstraints.\nExample\nThis example retrieves the access control policy for the \"Nelson\" object from the \"quotes\" bucket.\nSample Request\n<GetObjectAccessControlPolicy xmlns=\"http://doc.s3.amazonaws.com/2006-03-01\"> \n  <Bucket>quotes</Bucket> \n  <Key>Nelson</Key> \n  <AWSAccessKeyId>AKIAIOSFODNN7EXAMPLE</AWSAccessKeyId> \n  <Timestamp>2006-03-01T12:00:00.183Z</Timestamp> \n  <Signature>Iuyz3d3P0aTou39dzbqaEXAMPLE=</Signature>\n</GetObjectAccessControlPolicy>\nSample Response\n<AccessControlPolicy> \n  <Owner> \n    <ID>a9a7b886d6fd24a541bf9b1c61be666e9</ID> \n    <DisplayName>chriscustomer</DisplayName> \n  </Owner> \n  <AccessControlList> \n    <Grant> \n      <Grantee xsi:type=\"CanonicalUser\"> \n        <ID>a9a7b841bf9b1c61be666e9</ID> \n        <DisplayName>chriscustomer</DisplayName> \n      </Grantee> \n      <Permission>FULL_CONTROL</Permission> \n    </Grant> \n    <Grant> \n      <Grantee xsi:type=\"Group\"> \n        <URI>http://acs.amazonaws.com/groups/global/AllUsers<URI> \n      </Grantee> \n      <Permission>READ</Permission> \n    </Grant> \nOperations on Objects (SOAP API) API Version 2006-03-01 2930Amazon Simple Storage Service API Reference\n  </AccessControlList>\n</AccessControlPolicy>\nResponse Body\nThe response contains the access control policy for the bucket.", "For an explanation of this response,\nSOAP Access Policy .\nAccess Control\nYou must have READ_ACP  rights to the object in order to retrieve the access control policy for an \nobject.\nSetObjectAccessControlPolicy (SOAP API)\nNote\nSOAP support over HTTP is deprecated, but it is still available over HTTPS.", "New Amazon S3 \nfeatures will not be supported for SOAP.", "We recommend that you use either the REST API \nor the AWS SDKs.\nThe SetObjectAccessControlPolicy  operation sets the access control policy for an existing \nobject. If successful, the previous access control policy for the object is entirely replaced with the \nspeci\ufb01ed access control policy.\nExample\nThis example gives the speci\ufb01ed user (usually the owner) FULL_CONTROL  access to the \"Nelson\" \nobject from the \"quotes\" bucket.\nSample Request\n<SetObjectAccessControlPolicy xmlns=\"http://doc.s3.amazonaws.com/2006-03-01\"> \n  <Bucket>quotes</Bucket> \n  <Key>Nelson</Key> \n  <AccessControlList> \n    <Grant> \n      <Grantee xsi:type=\"CanonicalUser\"> \n        <ID>a9a7b886d6fd24a52fe8ca5bef65f89a64e0193f23000e241bf9b1c61be666e9</ID> \n        <DisplayName>chriscustomer</DisplayName> \nOperations on Objects (SOAP API) API Version 2006-03-01 2931Amazon Simple Storage Service API Reference\n      </Grantee> \n      <Permission>FULL_CONTROL</Permission> \n    </Grant> \n  </AccessControlList> \n  <AWSAccessKeyId>AKIAIOSFODNN7EXAMPLE</AWSAccessKeyId> \n  <Timestamp>2006-03-01T12:00:00.183Z</Timestamp> \n  <Signature>Iuyz3d3P0aTou39dzbqaEXAMPLE=</Signature>\n</SetObjectAccessControlPolicy>\nSample Response\n<SetObjectAccessControlPolicyResponse xmlns=\"http://s3.amazonaws.com/doc/2006-03-01\"> \n  <SetObjectAccessControlPolicyResponse> \n    <Code>200</Code> \n    <Description>OK</Description> \n  </SetObjectAccessControlPolicyResponse>\n</SetObjectAccessControlPolicyResponse>\nKey\nImportant\nReplacement must be made for object keys containing special characters (such as carriage \nreturns) when using XML requests. For more information, see  XML related object key \nconstraints.\nAccess Control\nYou must have WRITE_ACP  rights to the object in order to set the access control policy for a \nbucket.\nAuthenticating SOAP requests\nNote\nSOAP support over HTTP is deprecated, but it is still available over HTTPS.", "New Amazon S3 \nfeatures will not be supported for SOAP.", "We recommend that you use either the REST API \nor the AWS SDKs.\nAuthenticating SOAP requests API Version 2006-03-01 2932Amazon Simple Storage Service API Reference\nEvery non-anonymous request must contain authentication information to establish the identity of \nthe principal making the request. In SOAP, the authentication information is put into the following \nelements of the SOAP request:\n\u2022Your AWS Access Key ID\nNote\nWhen making authenticated SOAP requests, temporary security credentials are not \nsupported.", "For more information about types of credentials, see Making requests.\n\u2022Timestamp:  This must be a dateTime (go to http://www.w3.org/TR/xmlschema-2/ \n#dateTime ) in the Coordinated Universal Time (Greenwich Mean Time) time zone, such as\n2009-01-01T12:00:00.000Z .", "Authorization will fail if this timestamp is more than 15 minutes \naway from the clock on Amazon S3 servers.\n\u2022Signature:  The RFC 2104 HMAC-SHA1 digest (go to http://www.ietf.org/rfc/ \nrfc2104.txt) of the concatenation of \"AmazonS3\" + OPERATION + Timestamp, using \nyour AWS Secret Access Key as the key. For example, in the following CreateBucket \nsample request, the signature element would contain the HMAC-SHA1 digest of the value \n\"AmazonS3CreateBucket2009-01-01T12:00:00.000Z\":\nFor example, in the following CreateBucket sample request, the signature element would contain \nthe HMAC-SHA1 digest of the value \"AmazonS3CreateBucket2009-01-01T12:00:00.000Z\":\nExample\n<CreateBucket xmlns=\"http://doc.s3.amazonaws.com/2006-03-01\"> \n  <Bucket>quotes</Bucket> \n  <Acl>private</Acl> \n  <AWSAccessKeyId>AKIAIOSFODNN7EXAMPLE</AWSAccessKeyId> \n  <Timestamp>2009-01-01T12:00:00.000Z</Timestamp> \n  <Signature>Iuyz3d3P0aTou39dzbqaEXAMPLE=</Signature>\n</CreateBucket>\nNote\nSOAP requests, both authenticated and anonymous, must be sent to Amazon S3 using SSL. \nAmazon S3 returns an error when you send a SOAP request over HTTP.\nAuthenticating SOAP requests API Version 2006-03-01 2933Amazon Simple Storage Service API Reference\nImportant\nDue to di\ufb00erent interpretations regarding how extra time precision should be \ndropped, .NET users should take care not to send Amazon S3 overly speci\ufb01c time \nstamps.", "This can be accomplished by manually constructing DateTime  objects with only \nmillisecond precision.\nSetting access policy with SOAP\nNote\nSOAP support over HTTP is deprecated, but it is still available over HTTPS.", "New Amazon S3 \nfeatures will not be supported for SOAP.", "We recommend that you use either the REST API \nor the AWS SDKs.\nAccess control can be set at the time a bucket or object is written by including the \n\"AccessControlList\" element with the request to CreateBucket , PutObjectInline , or\nPutObject .", "The AccessControlList element is described in Identity and Access Management for \nAmazon S3 .", "If no access control list is speci\ufb01ed with these operations, the resource is created with \na default access policy that gives the requester FULL_CONTROL access (this is the case even if the \nrequest is a PutObjectInline or PutObject request for an object that already exists).\nFollowing is a request that writes data to an object, makes the object readable by anonymous \nprincipals, and gives the speci\ufb01ed user FULL_CONTROL rights to the bucket (Most developers will \nwant to give themselves FULL_CONTROL access to their own bucket).\nExample\nFollowing is a request that writes data to an object and makes the object readable by anonymous \nprincipals.\nSample Request\n<PutObjectInline xmlns=\"http://doc.s3.amazonaws.com/2006-03-01\"> \n  <Bucket>quotes</Bucket> \n  <Key>Nelson</Key> \n  <Metadata> \nSetting access policy with SOAP API Version 2006-03-01 2934Amazon Simple Storage Service API Reference\n    <Name>Content-Type</Name> \n    <Value>text/plain</Value> \n  </Metadata> \n  <Data>aGEtaGE=</Data> \n  <ContentLength>5</ContentLength> \n  <AccessControlList> \n    <Grant> \n      <Grantee xsi:type=\"CanonicalUser\"> \n        <ID>75cc57f09aa0c8caeab4f8c24e99d10f8e7faeebf76c078efc7c6caea54ba06a</ID> \n        <DisplayName>chriscustomer</DisplayName> \n      </Grantee> \n      <Permission>FULL_CONTROL</Permission> \n    </Grant> \n    <Grant> \n      <Grantee xsi:type=\"Group\"> \n        <URI>http://acs.amazonaws.com/groups/global/AllUsers<URI> \n      </Grantee> \n      <Permission>READ</Permission> \n    </Grant> \n  </AccessControlList> \n  <AWSAccessKeyId>AKIAIOSFODNN7EXAMPLE</AWSAccessKeyId> \n  <Timestamp>2009-03-01T12:00:00.183Z</Timestamp> \n  <Signature>Iuyz3d3P0aTou39dzbqaEXAMPLE=</Signature>\n</PutObjectInline>\nSample Response\n<PutObjectInlineResponse xmlns=\"http://s3.amazonaws.com/doc/2006-03-01\"> \n  <PutObjectInlineResponse> \n    <ETag>&quot828ef3fdfa96f00ad9f27c383fc9ac7f&quot</ETag> \n    <LastModified>2009-01-01T12:00:00.000Z</LastModified> \n  </PutObjectInlineResponse>\n</PutObjectInlineResponse>\nThe access control policy can be read or set for an existing bucket or object using \nthe GetBucketAccessControlPolicy , GetObjectAccessControlPolicy ,\nSetBucketAccessControlPolicy , and SetObjectAccessControlPolicy  methods. For more \ninformation, see the detailed explanation of these methods.\nCommon elements\nYou can include the following authorization-related elements with any SOAP request:\nCommon elements API Version 2006-03-01 2935Amazon Simple Storage Service API Reference\n\u2022AWSAccessKeyId:  The AWS Access Key ID of the requester\n\u2022Timestamp:  The current time on your system\n\u2022Signature:  The signature for the request\nSOAP Error Responses\nNote\nSOAP support over HTTP is deprecated, but it is still available over HTTPS.", "New Amazon S3 \nfeatures will not be supported for SOAP.", "We recommend that you use either the REST API \nor the AWS SDKs.\nIn SOAP, an error result is returned to the client as a SOAP fault, with the HTTP response code 500. \nIf you do not receive a SOAP fault, then your request was successful.", "The Amazon S3 SOAP fault \ncode is comprised of a standard SOAP 1.1 fault code (either \"Server\" or \"Client\") concatenated with \nthe Amazon S3-speci\ufb01c error code.", "For example: \"Server.InternalError\" or \"Client.NoSuchBucket\".", "\nThe SOAP fault string element contains a generic, human readable error message in English. \nFinally, the SOAP fault detail element contains miscellaneous information relevant to the error.\nFor example, if you attempt to delete the object \"Fred\", which does not exist, the body of the SOAP \nresponse contains a \"NoSuchKey\" SOAP fault.\nThe following example shows a sample SOAP error response.\n<soapenv:Body> \n  <soapenv:Fault> \n    <Faultcode>soapenv:Client.NoSuchKey</Faultcode> \n    <Faultstring>The specified key does not exist.</Faultstring> \n    <Detail> \n      <Key>Fred</Key> \n    </Detail> \n  </soapenv:Fault> \n  </soapenv:Body>\nThe following table explains the SOAP error response elements\nSOAP Error Responses API Version 2006-03-01 2936Amazon Simple Storage Service API Reference\nName Description\nDetail Container for the key involved in the error\nType: Container\nAncestor: Body.Fault\nFault Container for error information.\nType: Container\nAncestor: Body\nFaultcode The fault code is a string that uniquely identi\ufb01es an error condition.", "It is meant \nto be read and understood by programs that detect and handle errors by type. \nFor more information, see List of Error Codes.\nType: String\nAncestor: Body.Fault\nFaultstri \nngThe fault string contains a generic description of the error condition in English.", "\nIt is intended for a human audience. Simple programs display the message \ndirectly to the end user if they encounter an error condition they don't know \nhow or don't care to handle.", "Sophisticated programs with more exhaustive \nerror handling and proper internationalization are more likely to ignore the \nfault string.\nType: String\nAncestor: Body.Fault\nKey Identi\ufb01es the key involved in the error\nType: String\nAncestor: Body.Fault\nSOAP Error Responses API Version 2006-03-01 2937Amazon Simple Storage Service API Reference\nAppendix: Authenticating requests (AWS signature version 2)\nImportant\nThis section describes how to authenticate requests using AWS Signature Version 2.", "\nSignature Version 2 is being turned o\ufb00 (deprecated), Amazon S3 will only accept API \nrequests that are signed using Signature Version 4. For more information, see AWS \nSignature Version 2 Turned O\ufb00 (Deprecated) for Amazon S3\nSignature Version 4 is supported in all AWS Regions, and it is the only version that is \nsupported for new Regions. For more information, see Authenticating Requests (AWS \nSignature Version 4) in the Amazon Simple Storage Service API Reference.\nAmazon S3 o\ufb00ers you the ability to identify what API signature version was used to sign a \nrequest. It is important to identify if any of your work\ufb02ows are utilizing Signature Version 2 \nsigning and upgrading them to use Signature Version 4 to prevent impact to your business.\n\u2022If you are using CloudTrail event logs(recommended option), please see Identifying \nAmazon S3 Signature Version 2 requests by using CloudTrail  on how to query and \nidentify such requests.\n\u2022If you are using the Amazon S3 Server Access logs, see Using Amazon S3 server access \nlogs to identify requests\nTopics\n\u2022Authenticating requests using the REST API (AWS signature version 2)\n\u2022Signing and authenticating REST requests (AWS signature version 2)\n\u2022Browser-based uploads using POST (AWS signature version 2)\nAppendix: Authenticating requests (AWS signature version 2) API Version 2006-03-01 2938Amazon Simple Storage Service API Reference\nAuthenticating requests using the REST API (AWS signature version 2)\nWhen accessing Amazon S3 using REST, you must provide the following items in your request so \nthe request can be authenticated:\nRequest elements\n\u2022AWS access key Id \u2013 Each request must contain the access key ID of the identity you are using to \nsend your request.\n\u2022Signature  \u2013 Each request must contain a valid request signature, or the request is rejected.\nA request signature is calculated using your secret access key, which is a shared secret known \nonly to you and AWS.\n\u2022Time stamp  \u2013 Each request must contain the date and time the request was created, represented \nas a string in UTC.\n\u2022Date  \u2013 Each request must contain the time stamp of the request.\nDepending on the API action you're using, you can provide an expiration date and time for \nthe request instead of or in addition to the time stamp. See the authentication topic for the \nparticular action to determine what it requires.\nFollowing are the general steps for authenticating requests to Amazon S3. It is assumed you have \nthe necessary security credentials, access key ID and secret access key.\nAuthenticating requests using the REST API (AWS signature version 2) API Version 2006-03-01 2939Amazon Simple Storage Service API Reference\n1Construct a request to AWS.\n2Calculate the signature using your secret access key.\n3Send the request to Amazon S3.", "Include your access key ID and  the signature in your \nrequest.", "Amazon S3 performs the next three  steps.\nAuthenticating requests using the REST API (AWS signature version 2) API Version 2006-03-01 2940Amazon Simple Storage Service API Reference\n4Amazon S3 uses the access key ID to look up your secret access key.\n5Amazon S3 calculates a signature from the request data and the secret access key  \n using the same algorithm that you used to calculate the signature you  sent in the \nrequest.\n6If the signature generated by Amazon S3 matches the one you sent in the request, \nthe  request is considered authentic. If the comparison fails, the  request is discarded, \nand Amazon S3 returns an error  response.\nAuthenticating requests using the REST API (AWS signature version 2) API Version 2006-03-01 2941Amazon Simple Storage Service API Reference\nDetailed authentication information\nFor detailed information about REST authentication, see Signing and authenticating REST requests \n(AWS signature version 2).\nSigning and authenticating REST requests (AWS signature version 2)\nTopics\n\u2022Using temporary security credentials\n\u2022The authentication header\n\u2022Request canonicalization for signing\n\u2022Constructing the CanonicalizedResource element\n\u2022Constructing the CanonicalizedAmzHeaders element\n\u2022Positional versus named HTTP header StringToSign elements\n\u2022Time stamp requirement\n\u2022Authentication examples\n\u2022REST request signing problems\n\u2022Query string request authentication alternative\nNote\nThis topic explains authenticating requests using Signature Version 2. Amazon S3 now \nsupports the latest Signature Version 4. This latest signature version is supported in all \nregions and any new regions after January 30, 2014 will support only Signature Version \n4.", "For more information, go to Authenticating Requests (AWS Signature Version 4) in the\nAmazon Simple Storage Service API Reference.\nAuthentication is the process of proving your identity to the system.", "Identity is an important factor \nin Amazon S3 access control decisions.", "Requests are allowed or denied in part based on the identity \nof the requester.", "For example, the right to create buckets is reserved for registered developers \nand (by default) the right to create objects in a bucket is reserved for the owner of the bucket in \nquestion.", "As a developer, you'll be making requests that invoke these privileges, so you'll need to \nprove your identity to the system by authenticating your requests.", "This section shows you how.\nSigning and authenticating REST requests (AWS signature version 2) API Version 2006-03-01 2942Amazon Simple Storage Service API Reference\nNote\nThe content in this section does not apply to HTTP POST.", "For more information, see\nBrowser-based uploads using POST (AWS signature version 2).\nThe Amazon S3 REST API uses a custom HTTP scheme based on a keyed-HMAC (Hash Message \nAuthentication Code) for authentication.", "To authenticate a request, you \ufb01rst concatenate selected \nelements of the request to form a string.", "You then use your AWS secret access key to calculate the \nHMAC of that string. Informally, we call this process \"signing the request,\" and we call the output of \nthe HMAC algorithm the signature, because it simulates the security properties of a real signature. \nFinally, you add this signature as a parameter of the request by using the syntax described in this \nsection.\nWhen the system receives an authenticated request, it fetches the AWS secret access key that you \nclaim to have and uses it in the same way to compute a signature for the message it received. It \nthen compares the signature it calculated against the signature presented by the requester. If the \ntwo signatures match, the system concludes that the requester must have access to the AWS secret \naccess key and therefore acts with the authority of the principal to whom the key was issued. If \nthe two signatures do not match, the request is dropped and the system responds with an error \nmessage.\nExample Authenticated Amazon S3 REST request\nGET /photos/puppy.jpg HTTP/1.1\nHost: awsexamplebucket1.us-west-1.s3.amazonaws.com\nDate: Tue, 27 Mar 2007 19:36:42 +0000\nAuthorization: AWS AKIAIOSFODNN7EXAMPLE:\nqgk2+6Sv9/oM7G3qLEjTH1a1l1g=\nUsing temporary security credentials\nIf you are signing your request using temporary security credentials (see Making requests), you \nmust include the corresponding security token in your request by adding the x-amz-security-\ntoken header.\nWhen you obtain temporary security credentials using the AWS Security Token Service API, the \nresponse includes temporary security credentials and a session token. You provide the session \nSigning and authenticating REST requests (AWS signature version 2) API Version 2006-03-01 2943Amazon Simple Storage Service API Reference\ntoken value in the x-amz-security-token  header when you send requests to Amazon S3. For \ninformation about the AWS Security Token Service API provided by IAM, go to Action in the AWS \nSecurity Token Service API Reference Guide .\nThe authentication header\nThe Amazon S3 REST API uses the standard HTTP Authorization  header to pass authentication \ninformation. (The name of the standard header is unfortunate because it carries authentication \ninformation, not authorization.) Under the Amazon S3 authentication scheme, the Authorization \nheader has the following form:\nAuthorization: AWS AWSAccessKeyId :Signature\nDevelopers are issued an AWS access key ID and AWS secret access key when they register.", "For \nrequest authentication, the AWSAccessKeyId  element identi\ufb01es the access key ID that was used \nto compute the signature and, indirectly, the developer making the request.\nThe Signature  element is the RFC 2104 HMAC-SHA1 of selected elements from the request, \nand so the Signature  part of the Authorization header will vary from request to request. If the \nrequest signature calculated by the system matches the Signature  included with the request, the \nrequester will have demonstrated possession of the AWS secret access key.", "The request will then be \nprocessed under the identity, and with the authority, of the developer to whom the key was issued.\nFollowing is pseudogrammar that illustrates the construction of the Authorization  request \nheader.", "(In the example, \\n means the Unicode code point U+000A, commonly called newline).\nAuthorization = \"AWS\" + \" \" + AWSAccessKeyId + \":\" + Signature;\nSignature = Base64( HMAC-SHA1( UTF-8-Encoding-Of(YourSecretAccessKey), UTF-8-Encoding-\nOf( StringToSign ) ) );\nStringToSign = HTTP-Verb + \"\\n\" + \n Content-MD5 + \"\\n\" + \n Content-Type + \"\\n\" + \n Date + \"\\n\" + \n CanonicalizedAmzHeaders + \n CanonicalizedResource;\nCanonicalizedResource = [ \"/\" + Bucket ] + \n <HTTP-Request-URI, from the protocol name up to the query string> + \nSigning and authenticating REST requests (AWS signature version 2) API Version 2006-03-01 2944Amazon Simple Storage Service API Reference\n [ subresource, if present. For example \"?acl\", \"?location\", or \"?logging\"];\nCanonicalizedAmzHeaders = <described below>\nHMAC-SHA1 is an algorithm de\ufb01ned by  RFC 2104 - Keyed-Hashing for Message Authentication\n.", "The algorithm takes as input two byte-strings, a key and a message.", "For Amazon S3 request \nauthentication, use your AWS secret access key (YourSecretAccessKey ) as the key, and the \nUTF-8 encoding of the StringToSign  as the message.", "The output of HMAC-SHA1 is also a byte \nstring, called the digest.", "The Signature  request parameter is constructed by Base64 encoding this \ndigest.\nRequest canonicalization for signing\nRecall that when the system receives an authenticated request, it compares the computed request \nsignature with the signature provided in the request in StringToSign .", "For that reason, you must \ncompute the signature by using the same method used by Amazon S3. We call the process of \nputting a request in an agreed-upon form for signing canonicalization .\nConstructing the CanonicalizedResource element\nCanonicalizedResource  represents the Amazon S3 resource targeted by the request.", "Construct \nit for a REST request as follows:\nLaunch process\n1 Start with an empty string (\"\").\n2 If the request speci\ufb01es a bucket using the HTTP Host header (virtual hosted-style), append \nthe bucket name preceded by a \"/\" (e.g., \"/bucketname\"). For path-style requests and \nrequests that don't address a bucket, do nothing. For more information about virtual \nhosted-style requests, see Virtual hosting of buckets .\nFor a virtual hosted-style request \"https://awsexamplebucket1.s3.us-west-1.amazo \nnaws.com/photos/puppy.jpg\", the CanonicalizedResource  is \"/awsexamplebucket1\".\nFor the path-style request, \"https://s3.us-west-1.amazonaws.com/awsexamplebucket1/ \nphotos/puppy.jpg\", the CanonicalizedResource  is \"\".\n3 Append the path part of the un-decoded HTTP Request-URI, up-to but not including the \nquery string.\nSigning and authenticating REST requests (AWS signature version 2) API Version 2006-03-01 2945Amazon Simple Storage Service API Reference\nFor a virtual hosted-style request \"https://awsexamplebucket1.s3.us-west-1.amazo \nnaws.com/photos/puppy.jpg\", the CanonicalizedResource  is \"/awsexamplebucket1/\nphotos/puppy.jpg\".\nFor a path-style request, \"https://s3.us-west-1.amazonaws.com/awsexamplebucket1/ \nphotos/puppy.jpg\", the CanonicalizedResource  is \"/awsexamplebucket1/photos/ \npuppy.jpg\". At this point, the CanonicalizedResource  is the same for both the virtual \nhosted-style and path-style request.\nFor a request that does not address a bucket, such as GET Service, append \"/\".\n4If the request addresses a subresource, such as ?versioning , ?location , ?acl , ?\nlifecycle , or ?versionid , append the subresource, its value if it has one, and the \nquestion mark. Note that in case of multiple subresources, subresources must be lexicogra \nphically sorted by subresource name and separated by '&', e.g., ?acl&versionId=value .\nThe subresources that must be included when constructing the CanonicalizedResource \nElement are acl, lifecycle, location, logging, noti\ufb01cation, partNumber, policy, requestPa \nyment, uploadId, uploads, versionId, versioning, versions, and website.\nIf the request speci\ufb01es query string parameters overriding the response header values \n(see Get Object), append the query string parameters and their values.", "When signing, \nyou do not encode these values; however, when making the request, you must encode \nthese parameter values.", "The query string parameters in a GET request include response- \ncontent-type , response-content-language , response-expires ,\nresponse-cache-control , response-content-disposition , and response- \ncontent-encoding .\nThe delete query string parameter must be included when you create the Canonical \nizedResource for a multi-object Delete request.\nElements of the CanonicalizedResource that come from the HTTP Request-URI should be signed \nliterally as they appear in the HTTP request, including URL-Encoding meta characters.\nThe CanonicalizedResource  might be di\ufb00erent than the HTTP Request-URI.", "In particular, \nif your request uses the HTTP Host header to specify a bucket, the bucket does not appear \nin the HTTP Request-URI.", "However, the CanonicalizedResource  continues to include the \nSigning and authenticating REST requests (AWS signature version 2) API Version 2006-03-01 2946Amazon Simple Storage Service API Reference\nbucket.", "Query string parameters might also appear in the Request-URI but are not included in\nCanonicalizedResource .", "For more information, see Virtual hosting of buckets .\nConstructing the CanonicalizedAmzHeaders element\nTo construct the CanonicalizedAmzHeaders part of StringToSign , select all HTTP request \nheaders that start with 'x-amz-' (using a case-insensitive comparison), and use the following \nprocess.\nCanonicalizedAmzHeaders process\n1 Convert each HTTP header name to lowercase.", "For example, 'X-Amz-Date ' becomes 'x-\namz-date '.\n2 Sort the collection of headers lexicographically by header name.\n3 Combine header \ufb01elds with the same name into one \"header-name:comma-separate \nd-value-list\" pair as prescribed by RFC 2616, section 4.2, without any spaces between \nvalues. For example, the two metadata headers 'x-amz-meta-username: fred ' and \n'x-amz-meta-username: barney ' would be combined into the single header 'x-\namz-meta-username: fred,barney '.\n4 \"Unfold\" long headers that span multiple lines (as allowed by RFC 2616, section 4.2) by \nreplacing the folding spaces (including new-line) by a single space.\n5 Trim any spaces around the colon in the header. For example, the header 'x-amz-meta-\nusername: fred,barney ' would become 'x-amz-meta-username:fred,ba \nrney '\n6 Finally, append a newline character (U+000A) to each canonicalized header in the \nresulting list. Construct the CanonicalizedResource element by concatenating all headers \nin this list into a single string.\nPositional versus named HTTP header StringToSign elements\nThe \ufb01rst few header elements of StringToSign  (Content-Type, Date, and Content-MD5) are \npositional in nature. StringToSign  does not include the names of these headers, only their \nvalues from the request.", "In contrast, the 'x-amz-' elements are named.", "Both the header names and \nthe header values appear in StringToSign .\nSigning and authenticating REST requests (AWS signature version 2) API Version 2006-03-01 2947Amazon Simple Storage Service API Reference\nIf a positional header called for in the de\ufb01nition of StringToSign  is not present in your request \n(for example, Content-Type  or Content-MD5  are optional for PUT requests and meaningless for \nGET requests), substitute the empty string (\"\") for that position.\nTime stamp requirement\nA valid time stamp (using either the HTTP Date  header or an x-amz-date  alternative) is \nmandatory for authenticated requests.", "Furthermore, the client timestamp included with an \nauthenticated request must be within 15 minutes of the Amazon S3 system time when the \nrequest is received.", "If not, the request will fail with the RequestTimeTooSkewed  error code.", "The \nintention of these restrictions is to limit the possibility that intercepted requests could be replayed \nby an adversary. For stronger protection against eavesdropping, use the HTTPS transport for \nauthenticated requests.\nNote\nThe validation constraint on request date applies only to authenticated requests that \ndo not use query string authentication. For more information, see Query string request \nauthentication alternative.\nSome HTTP client libraries do not expose the ability to set the Date header for a request. If you \nhave trouble including the value of the 'Date' header in the canonicalized headers, you can set the \ntimestamp for the request by using an 'x-amz-date ' header instead. The value of the x-amz-\ndate header must be in one of the RFC 2616 formats (http://www.ietf.org/rfc/rfc2616.txt). When \nan x-amz-date  header is present in a request, the system will ignore any Date  header when \ncomputing the request signature. Therefore, if you include the x-amz-date  header, use the empty \nstring for the Date when constructing the StringToSign .", "See the next section for an example.\nAuthentication examples\nThe examples in this section use the (non-working) credentials in the following table.\nParameter Value\nAWSAccessKeyIdAKIAIOSFODNN7EXAMPLE\nAWSSecretAccessKeywJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\nSigning and authenticating REST requests (AWS signature version 2) API Version 2006-03-01 2948Amazon Simple Storage Service API Reference\nIn the example StringToSign s, formatting is not signi\ufb01cant, and \\n means the Unicode code \npoint U+000A, commonly called newline.", "Also, the examples use \"+0000\" to designate the time \nzone.", "You can use \"GMT\" to designate timezone instead, but the signatures shown in the examples \nwill be di\ufb00erent.\nObject GET\nThis example gets an object from the awsexamplebucket1 bucket.\nRequest StringToSign\nGET /photos/puppy.jpg HTTP/1.1 \nHost: awsexamplebucket1.us-\nwest-1.s3.amazonaws.com \nDate: Tue, 27 Mar 2007 19:36:42 \n +0000\nAuthorization: AWS AKIAIOSFO \nDNN7EXAMPLE:\nqgk2+6Sv9/oM7G3qLEjTH1a1l1g=GET\\n\n\\n \n\\n\nTue, 27 Mar 2007 19:36:42 +0000\\n\n/awsexamplebucket1/photos/puppy.jpg\nNote that the CanonicalizedResource includes the bucket name, but the HTTP Request-URI does \nnot. (The bucket is speci\ufb01ed by the Host header.)\nNote\nThe following Python script calculates the preceding signature, using the provided \nparameters.", "You can use this script to construct your own signatures, replacing the keys and \nStringToSign as appropriate.\nimport base64\nimport hmac\nfrom hashlib import sha1\naccess_key = ' AKIAIOSFODNN7EXAMPLE '.encode(\"UTF-8\")\nsecret_key = ' wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY '.encode(\"UTF-8\")\nstring_to_sign = ' GET\\n\\n\\nTue, 27 Mar 2007 19:36:42 +0000\\n/awsexamplebucket1/\nphotos/puppy.jpg '.encode(\"UTF-8\")\nsignature = base64.b64encode( \nSigning and authenticating REST requests (AWS signature version 2) API Version 2006-03-01 2949Amazon Simple Storage Service API Reference\n                                hmac.new( \n                                         secret_key, string_to_sign, sha1 \n                                         ).digest() \n                                ).strip()\nprint(f\"AWS {access_key.decode()}:{signature.decode()}\")\nObject PUT\nThis example puts an object into the awsexamplebucket1 bucket.\nRequest StringToSign\nPUT /photos/puppy.jpg HTTP/1.1 \nContent-Type: image/jpeg\nContent-Length: 94328\nHost: awsexamplebucket1.s3.us-wes \nt-1.amazonaws.com \nDate: Tue, 27 Mar 2007 21:15:45 +0000\nAuthorization: AWS AKIAIOSFODNN7EXAMP \nLE:\niqRzw+ileNPu1fhspnRs8nOjjIA=PUT\\n\n\\n \nimage/jpeg\\n\nTue, 27 Mar 2007 21:15:45 +0000\\n\n/awsexamplebucket1/photos/puppy.jpg\nNote the Content-Type header in the request and in the StringToSign. Also note that the Content-\nMD5 is left blank in the StringToSign, because it is not present in the request.\nList\nThis example lists the content of the awsexamplebucket1 bucket.\nRequest StringToSign\nGET /?prefix=photos&max-keys=50&marker=puppy \n HTTP/1.1 \nUser-Agent: Mozilla/5.0GET\\n\n\\n \n\\n\nSigning and authenticating REST requests (AWS signature version 2) API Version 2006-03-01 2950Amazon Simple Storage Service API Reference\nRequest StringToSign\nHost: awsexamplebucket1.s3.us-west-1.amazo \nnaws.com \nDate: Tue, 27 Mar 2007 19:42:41 +0000\nAuthorization: AWS AKIAIOSFODNN7EXAMPLE:\nm0WP8eCtspQl5Ahe6L1SozdX9YA=Tue, 27 Mar 2007 19:42:41 \n +0000\\n\n/awsexamplebucket1/\nNote the trailing slash on the CanonicalizedResource and the absence of query string parameters.\nFetch\nThis example fetches the access control policy subresource for the 'awsexamplebucket1' bucket.\nRequest StringToSign\nGET /?acl HTTP/1.1 \nHost: awsexamplebucket1.s3.us-west-1.amazo \nnaws.com \nDate: Tue, 27 Mar 2007 19:44:46 +0000\nAuthorization: AWS AKIAIOSFODNN7EXAMPLE:\n82ZHiFIjc+WbcwFKGUVEQspPn+0=GET\\n\n\\n \n\\n\nTue, 27 Mar 2007 19:44:46 \n +0000\\n\n/awsexamplebucket1/?acl\nNotice how the subresource query string parameter is included in the CanonicalizedResource.\nDelete\nThis example deletes an object from the 'awsexamplebucket1' bucket using the path-style and \nDate alternative.\nRequest StringToSign\nDELETE /awsexamplebucket1/photos/p \nuppy.jpg HTTP/1.1 \nUser-Agent: dotnet\nHost: s3.us-west-1.amazonaws.com \nDate: Tue, 27 Mar 2007 21:20:27 +0000DELETE\\n \n\\n\n\\n\nTue, 27 Mar 2007 21:20:26 +0000\\n\nSigning and authenticating REST requests (AWS signature version 2) API Version 2006-03-01 2951Amazon Simple Storage Service API Reference\nRequest StringToSign\nx-amz-date: Tue, 27 Mar 2007 21:20:26 \n +0000\nAuthorization: AWS AKIAIOSFODNN7EXAMP \nLE:XbyTlbQdu9Xw5o8P4iMwPktxQd8=/awsexamplebucket1/photos/puppy.jpg\nNote how we used the alternate 'x-amz-date' method of specifying the date (because our client \nlibrary prevented us from setting the date, say).", "In this case, the x-amz-date  takes precedence \nover the Date header. Therefore, date entry in the signature must contain the value of the x-amz-\ndate header.\nUpload\nThis example uploads an object to a CNAME style virtual hosted bucket with metadata.\nRequest StringToSign\nPUT /db-backup.dat.gz HTTP/1.1 \nUser-Agent: curl/7.15.5\nHost: static.example.com:8080\nDate: Tue, 27 Mar 2007 21:06:08 +0000\nx-amz-acl: public-read\ncontent-type: application/x-download\nContent-MD5: 4gJE4saaMU4BqNR0kLY+lw==\nX-Amz-Meta-ReviewedBy: joe@example.com\nX-Amz-Meta-ReviewedBy: jane@exam \nple.com\nX-Amz-Meta-FileChecksum: 0x02661779\nX-Amz-Meta-ChecksumAlgorithm: crc32\nContent-Disposition: attachment; \n filename=database.dat\nContent-Encoding: gzip\nContent-Length: 5913339\nAuthorization: AWS AKIAIOSFODNN7EXAMP \nLE:\njtBQa0Aq+DkULFI8qrpwIjGEx0E=PUT\\n\n4gJE4saaMU4BqNR0kLY+lw==\\n\napplication/x-download\\n\nTue, 27 Mar 2007 21:06:08 +0000\\n \nx-amz-acl:public-read\\n\nx-amz-meta-checksumalgorithm:c \nrc32\\n\nx-amz-meta-filechecksum:0x026 \n61779\\n\nx-amz-meta-reviewedby:\njoe@example.com,jane@example.com \n\\n\n/static.example.com/db-backup.dat \n.gz\nSigning and authenticating REST requests (AWS signature version 2) API Version 2006-03-01 2952Amazon Simple Storage Service API Reference\nNotice how the 'x-amz-' headers are sorted, trimmed of extra spaces, and converted to lowercase.", "\nNote also that multiple headers with the same name have been joined using commas to separate \nvalues.\nNote how only the Content-Type  and Content-MD5  HTTP entity headers appear in the\nStringToSign .", "The other Content-*  entity headers do not.\nAgain, note that the CanonicalizedResource  includes the bucket name, but the HTTP Request-\nURI does not. (The bucket is speci\ufb01ed by the Host header.)\nList all my buckets\nRequest StringToSign\nGET / HTTP/1.1 \nHost: s3.us-west-1.amazonaws.com \nDate: Wed, 28 Mar 2007 01:29:59 +0000\nAuthorization: AWS AKIAIOSFODNN7EXAMPLE:qGdzdE \nRIC03wnaRNKh6OqZehG9s=GET\\n\n\\n \n\\n\nWed, 28 Mar 2007 01:29:59 \n +0000\\n\n/\nUnicode keys\nRequest StringToSign\nGET /dictionary/fran%C3%A7ais/pr\n%c3%a9f%c3%a8re HTTP/1.1 \nHost: s3.us-west-1.amazonaws.com \nDate: Wed, 28 Mar 2007 01:49:49 +0000\nAuthorization: AWS AKIAIOSFODNN7EXAMP \nLE:DNEZGsoieTZ92F3bUfSPQcbGmlM=GET\\n\n\\n \n\\n\nWed, 28 Mar 2007 01:49:49 +0000\\n\n/dictionary/fran%C3%A7ais/pr \n%c3%a9f%c3%a8re\nNote\nThe elements in StringToSign  that were derived from the Request-URI are taken literally, \nincluding URL-Encoding and capitalization.\nSigning and authenticating REST requests (AWS signature version 2) API Version 2006-03-01 2953Amazon Simple Storage Service API Reference\nREST request signing problems\nWhen REST request authentication fails, the system responds to the request with an XML error \ndocument. The information contained in this error document is meant to help developers diagnose \nthe problem. In particular, the StringToSign  element of the SignatureDoesNotMatch  error \ndocument tells you exactly what request canonicalization the system is using.\nSome toolkits silently insert headers that you do not know about beforehand, such as adding the \nheader Content-Type  during a PUT. In most of these cases, the value of the inserted header \nremains constant, allowing you to discover the missing headers by using tools such as Ethereal or \ntcpmon.\nQuery string request authentication alternative\nYou can authenticate certain types of requests by passing the required information as query-string \nparameters instead of using the Authorization  HTTP header.", "This is useful for enabling direct \nthird-party browser access to your private Amazon S3 data without proxying the request.", "The idea \nis to construct a \"presigned\" request and encode it as a URL that an end-user's browser can retrieve.", "\nAdditionally, you can limit a presigned request by specifying an expiration time.\nFor more information on using query parameters to authenticate requests , see Authenticating \nRequests: Using Query Parameters (AWS Signature Version 4) in the Amazon Simple Storage Service \nAPI Reference. For examples of using the AWS SDKs to generating presigned URLs, see Sharing \nobjects with presigned URLs .\nCreating a signature\nFollowing is an example query string authenticated Amazon S3 REST request.\nGET /photos/puppy.jpg\n?AWSAccessKeyId=AKIAIOSFODNN7EXAMPLE&Expires=1141889120&Signature=vjbyPxybdZaNmGa\n%2ByT272YEAiv4%3D HTTP/1.1\nHost: awsexamplebucket1.s3.us-west-1.amazonaws.com\nDate: Mon, 26 Mar 2007 19:37:58 +0000\nThe query string request authentication method doesn't require any special HTTP headers. Instead, \nthe required authentication elements are speci\ufb01ed as query string parameters:\nSigning and authenticating REST requests (AWS signature version 2) API Version 2006-03-01 2954Amazon Simple Storage Service API Reference\nQuery string \nparameter \nnameExample value Description\nAWSAccess \nKeyIdAKIAIOSFODNN7EXAMPLE Your AWS access key ID. Speci\ufb01es \nthe AWS secret access key used to \nsign the request and, indirectly, the \nidentity of the developer making the \nrequest.\nExpires 1141889120 The time when the signature expires, \nspeci\ufb01ed as the number of seconds \nsince the epoch (00:00:00 UTC on \nJanuary 1, 1970).", "A request received \nafter this time (according to the \nserver) will be rejected.\nSignature vjbyPxybdZaNmGa%2B \nyT272YEAiv4%3DThe URL encoding of the Base64 \nencoding of the HMAC-SHA1 of \nStringToSign.\nThe query string request authentication method di\ufb00ers slightly from the ordinary method but only \nin the format of the Signature  request parameter and the StringToSign  element. Following is \npseudo-grammar that illustrates the query string request authentication method.\nSignature = URL-Encode( Base64( HMAC-SHA1( YourSecretAccessKey, UTF-8-Encoding-\nOf( StringToSign ) ) ) );\nStringToSign = HTTP-VERB + \"\\n\" + \n    Content-MD5 + \"\\n\" + \n    Content-Type + \"\\n\" + \n    Expires + \"\\n\" + \n    CanonicalizedAmzHeaders + \n    CanonicalizedResource;     \nYourSecretAccessKey  is the AWS secret access key ID that Amazon assigns to you when you \nsign up to be an Amazon Web Service developer. Notice how the Signature  is URL-Encoded to \nSigning and authenticating REST requests (AWS signature version 2) API Version 2006-03-01 2955Amazon Simple Storage Service API Reference\nmake it suitable for placement in the query string.", "Note also that in StringToSign , the HTTP\nDate positional element has been replaced with Expires .", "The CanonicalizedAmzHeaders  and\nCanonicalizedResource  are the same.\nNote\nIn the query string authentication method, you do not use the Date  or the x-amz-date \nrequest  header when calculating the string to sign.\nQuery string request authentication\nRequest StringToSign\nGET /photos/puppy.jpg?AWSAccess \nKeyId=AKIAIOSFODNN7EXAMPLE& \n    Signature=NpgCjnDzrM%2BWFzo \nENXmpNDUsSn8%3D& \n    Expires=1175139620 HTTP/1.1 \nHost: awsexamplebucket1.s3.us-wes \nt-1.amazonaws.comGET\\n\n\\n \n\\n\n1175139620\\n\n/awsexamplebucket1/photos/puppy.jpg\nWe assume that when a browser makes the GET request, it won't provide a Content-MD5 or a \nContent-Type header, nor will it set any x-amz- headers, so those parts of the StringToSign  are \nleft blank.\nUsing Base64 encoding\nHMAC request signatures must be Base64 encoded.", "Base64 encoding converts the signature into \na simple ASCII string that can be attached to the request. Characters that could appear in the \nsignature string like plus (+), forward slash (/), and equals (=) must be encoded if used in a URI. \nFor example, if the authentication code includes a plus (+) sign, encode it as %2B in the request.", "\nEncode a forward slash as %2F and equals as %3D.\nFor examples of Base64 encoding, refer to the Amazon S3 Authentication examples .\nSigning and authenticating REST requests (AWS signature version 2) API Version 2006-03-01 2956Amazon Simple Storage Service API Reference\nBrowser-based uploads using POST (AWS signature version 2)\nAmazon S3 supports POST, which allows your users to upload content directly to Amazon S3. POST \nis designed to simplify uploads, reduce upload latency, and save you money on applications where \nusers upload data to store in Amazon S3.\nNote\nThe request authentication discussed in this section is based on AWS Signature Version 2, a \nprotocol for authenticating inbound API requests to AWS services.\nAmazon S3 now supports Signature Version 4, a protocol for authenticating inbound API \nrequests to AWS services, in all AWS Regions.", "At this time, AWS Regions created before \nJanuary 30, 2014 will continue to support the previous protocol, Signature Version 2. Any \nnew regions after January 30, 2014 will support only Signature Version 4 and therefore all \nrequests to those regions must be made with Signature Version 4.", "For more information, \nsee Authenticating Requests in Browser-Based Uploads Using POST (AWS Signature Version \n4) in the Amazon Simple Storage Service API Reference.\nThe following \ufb01gure shows an upload using Amazon S3 POST.\nBrowser-based uploads using POST (AWS signature version 2) API Version 2006-03-01 2957Amazon Simple Storage Service API Reference\nUploading using POST\n1 The user opens a web browser and accesses your web page.\n2 Your web page contains an HTTP form that contains all the information necessary for \nthe user to upload content to Amazon S3.\n3 The user uploads content directly to Amazon S3.\nNote\nQuery string authentication is not supported for POST.\nBrowser-based uploads using POST (AWS signature version 2) API Version 2006-03-01 2958Amazon Simple Storage Service API Reference\nHTML forms (AWS signature version 2)\nTopics\n\u2022HTML form encoding\n\u2022HTML form declaration\n\u2022HTML form \ufb01elds\n\u2022Policy construction\n\u2022Constructing a signature\n\u2022Redirection\nWhen you communicate with Amazon S3, you normally use the REST or SOAP API to perform put, \nget, delete, and other operations. With POST, users upload data directly to Amazon S3 through \ntheir browsers, which cannot process the SOAP API or create a REST PUT request.\nNote\nSOAP support over HTTP is deprecated, but it is still available over HTTPS. New Amazon S3 \nfeatures will not be supported for SOAP. We recommend that you use either the REST API \nor the AWS SDKs.\nTo allow users to upload content to Amazon S3 by using their browsers, you use HTML forms.", "\nHTML forms consist of a form declaration and form \ufb01elds. The form declaration contains high-level \ninformation about the request. The form \ufb01elds contain detailed information about the request, as \nwell as the policy that is used to authenticate it and ensure that it meets the conditions that you \nspecify.\nNote\nThe form data and boundaries (excluding the contents of the \ufb01le) cannot exceed 20 KB.\nThis section explains how to use HTML forms.\nBrowser-based uploads using POST (AWS signature version 2) API Version 2006-03-01 2959Amazon Simple Storage Service API Reference\nHTML form encoding\nThe form and policy must be UTF-8 encoded. You can apply UTF-8 encoding to the form by \nspecifying it in the HTML heading or as a request header.\nNote\nThe HTML form declaration does not accept query string authentication parameters.\nThe following is an example of UTF-8 encoding in the HTML heading:\n<html> \n  <head> \n    ... \n    <meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\" /> \n    ... \n  </head> \n  <body>\nThe following is an example of UTF-8 encoding in a request header:\nContent-Type: text/html; charset=UTF-8\nHTML form declaration\nThe form declaration has three components: the action, the method, and the enclosure type.", "If any \nof these values is improperly set, the request fails.\nThe action speci\ufb01es the URL that processes the request, which must be set to the URL \nof the bucket. For example, if the name of your bucket is awsexamplebucket1  and the \nRegion is US West (N.", "California), the URL is https://awsexamplebucket1.s3.us-\nwest-1.amazonaws.com/ .\nNote\nThe key name is speci\ufb01ed in a form \ufb01eld.\nBrowser-based uploads using POST (AWS signature version 2) API Version 2006-03-01 2960Amazon Simple Storage Service API Reference\nThe method must be POST.\nThe enclosure type (enctype) must be speci\ufb01ed and must be set to multipart/form-data for both \n\ufb01le uploads and text area uploads. For more information, go to RFC 1867.\nExample\nThe following example is a form declaration for the bucket \"awsexamplebucket1\".\n<form action=\"https://awsexamplebucket1.s3.us-west-1.amazonaws.com/\" method=\"post\"\nenctype=\"multipart/form-data\">\nHTML form \ufb01elds\nThe following table describes \ufb01elds that can be used within an HTML form.\nNote\nThe variable ${filename}  is automatically replaced with the name of the \ufb01le provided \nby the user and is recognized by all form \ufb01elds.", "If the browser or client provides a full or \npartial path to the \ufb01le, only the text following the last slash (/) or backslash (\\) will be used.", "\nFor example, \"C:\\Program Files\\directory1\\\ufb01le.txt\" will be interpreted as \"\ufb01le.txt\".", "If no \ufb01le \nor \ufb01le name is provided, the variable is replaced with an empty string.\nField name Description Required\nAWSAccessKeyId\nThe AWS Access Key ID of the owner of the \nbucket who grants  an anonymous user \naccess for a request that satis\ufb01es the set of  \n constraints in the policy.", "This \ufb01eld is required \nif the  request includes a policy document.Conditional\nacl\nAn Amazon S3 access control list (ACL).", "If \nan invalid access  control list is speci\ufb01ed, an \nerror is generated.No\nBrowser-based uploads using POST (AWS signature version 2) API Version 2006-03-01 2961Amazon Simple Storage Service API Reference\nField name Description Required\nType: String\nDefault: private\nValid Values: private | public-re \nad | public-read-write | aws-\nexec-read | authenticated-read \n| bucket-owner-read | bucket-ow \nner-full-control\nCache-Control, \nContent-Type, Content-\nDisposition,  Conten \nt-Encoding, ExpiresREST-speci\ufb01c headers.", "For more information, \nsee PUT Object.No\nkey\nThe name of the uploaded key.\nTo use the \ufb01lename provided by the user, use \nthe  ${\ufb01lename} variable.", "For example, if user \nBetty uploads the  \ufb01le lolcatz.jpg and you \nspecify  /user/betty/${\ufb01lename}, the \ufb01le is \nstored as  /user/betty/lolcatz.jpg.\nFor more information, see Working with \nobject metadata   .Yes\npolicy\nSecurity policy describing what is permitted \nin the request.", "Requests without a  securit \ny policy are considered anonymous and will \nsucceed only on  publicly writable buckets.No\nBrowser-based uploads using POST (AWS signature version 2) API Version 2006-03-01 2962Amazon Simple Storage Service API Reference\nField name Description Required\nsuccess_action_red \nirect, redirectThe URL to which the client is redirected \nupon successful upload.", "Amazon S3 appends  \n the bucket, key, and etag values as query \nstring parameters to  the URL.\nIf success_action_redirect is not speci\ufb01ed \n, Amazon S3  returns the empty document \ntype speci\ufb01ed in the  success_action_status \n\ufb01eld.\nIf Amazon S3 cannot interpret the URL, it \nignores the \ufb01eld.\nIf the upload fails, Amazon S3 displays an \nerror and does not  redirect the user to a URL.\nFor more information, see Redirection.\nNote\nThe redirect \ufb01eld name is deprecate \nd and support for  the redirect \ufb01eld \nname will be removed in the future. No\nBrowser-based uploads using POST (AWS signature version 2) API Version 2006-03-01 2963Amazon Simple Storage Service API Reference\nField name Description Required\nsuccess_action_status\nThe status code returned to the client upon \nsuccessful  upload if success_action_redirect \nis not speci\ufb01ed.\nValid values are 200, 201, or 204 (default).\nIf the value is set to 200 or 204, Amazon S3 \nreturns an empty  document with a 200 or \n204 status code.\nIf the value is set to 201, Amazon S3 returns \nan XML document  with a 201 status code. \nFor information about the content of the  \n XML document, see POST Object.\nIf the value is not set or if it is set to an \ninvalid  value, Amazon S3 returns an empty \ndocument with a 204 status code.\nNote\nSome versions of the Adobe Flash \nplayer do not properly   handle \nHTTP responses with an empty \nbody. To support uploads  through \nAdobe Flash, we recommend setting\nsuccess_action_status  to \n201.No\nBrowser-based uploads using POST (AWS signature version 2) API Version 2006-03-01 2964Amazon Simple Storage Service API Reference\nField name Description Required\nsignature\nThe HMAC signature constructed by using \nthe secret access  key that corresponds to \nthe provided  AWSAccessKeyId.", "This \ufb01eld is \nrequired if a policy document is  included \nwith the request.\nFor more information, see Identity and Access \nManagement for Amazon S3.Conditional\nOther \ufb01eld names pre\ufb01xed \nwith x-amz-meta-User-speci\ufb01ed metadata.\nAmazon S3 does not validate or use this data.\nFor more information, see  PUT Object.No\n\ufb01le\nFile or text content.\nThe \ufb01le or content must be the last \ufb01eld in \nthe form.", "Any \ufb01elds below it are  ignored.\nYou cannot upload more than one \ufb01le at a \ntime.Yes\nPolicy construction\nTopics\n\u2022Expiration\n\u2022Conditions\n\u2022Condition matching\n\u2022Character escaping\nThe policy is a UTF-8 and Base64-encoded JSON document that speci\ufb01es conditions that the \nrequest must meet and is used to authenticate the content. Depending on how you design your \nBrowser-based uploads using POST (AWS signature version 2) API Version 2006-03-01 2965Amazon Simple Storage Service API Reference\npolicy documents, you can use them per upload, per user, for all uploads, or according to other \ndesigns that meet your needs.\nNote\nAlthough the policy document is optional, we highly recommend it over making a bucket \npublicly writable.\nThe following is an example of a policy document:\n{ \"expiration\": \"2007-12-01T12:00:00.000Z\", \n  \"conditions\": [ \n    {\"acl\": \"public-read\" }, \n    {\"bucket\": \"awsexamplebucket1\" }, \n    [\"starts-with\", \"$key\", \"user/eric/\"], \n  ]\n}\nThe policy document contains the expiration and conditions.\nExpiration\nThe expiration element speci\ufb01es the expiration date of the policy in ISO 8601 UTC date format.", "For \nexample, \"2007-12-01T12:00:00.000Z\" speci\ufb01es that the policy is not valid after midnight UTC on \n2007-12-01.", "Expiration is required in a policy.\nConditions\nThe conditions in the policy document validate the contents of the uploaded object.", "Each form \n\ufb01eld that you specify in the form (except AWSAccessKeyId, signature, \ufb01le, policy, and \ufb01eld names \nthat have an x-ignore- pre\ufb01x) must be included in the list of conditions.\nBrowser-based uploads using POST (AWS signature version 2) API Version 2006-03-01 2966Amazon Simple Storage Service API Reference\nNote\nIf you have multiple \ufb01elds with the same name, the values must be separated by commas.", "\nFor example, if you have two \ufb01elds named \"x-amz-meta-tag\" and the \ufb01rst one has a value \nof \"Ninja\" and second has a value of \"Stallman\", you would set the policy document to\nNinja,Stallman .\nAll variables within the form are expanded before the policy is validated.", "Therefore, all \ncondition matching should be performed against the expanded \ufb01elds.", "For example, if \nyou set the key \ufb01eld to user/betty/${filename} , your policy might be [ \"starts-\nwith\", \"$key\", \"user/betty/\" ] . Do not enter [ \"starts-with\", \"$key\", \n\"user/betty/${filename}\" ] .", "For more information, see Condition matching .\nThe following table describes policy document conditions.\nElement name Description\nacl\nSpeci\ufb01es conditions that the ACL must meet.\nSupports exact matching and starts-with .\ncontent-length-range\nSpeci\ufb01es the minimum and maximum allowable size for  the \nuploaded content.\nSupports range matching.\nCache-Control, Content-Type, \nContent-Disposition,  Content-\nEncoding, ExpiresREST-speci\ufb01c headers.\nSupports exact matching and starts-with .\nkey\nThe name of the uploaded key.\nSupports exact matching and starts-with .\nsuccess_action_redirect, redirect\nThe URL to which the client is redirected upon  successful \nupload.\nBrowser-based uploads using POST (AWS signature version 2) API Version 2006-03-01 2967Amazon Simple Storage Service API Reference\nElement name Description\nSupports exact matching and starts-with .\nsuccess_action_status\nThe status code returned to the client upon successful  \n upload if success_action_redirect is not  speci\ufb01ed.\nSupports exact matching.\nOther \ufb01eld names pre\ufb01xed with \nx-amz-meta-User-speci\ufb01ed metadata.\nSupports exact matching and starts-with .\nNote\nIf your toolkit adds additional \ufb01elds (e.g., Flash adds \ufb01lename), you must add them to the \npolicy document.", "If you can control this functionality, pre\ufb01x x-ignore-  to the \ufb01eld so \nAmazon S3 ignores the feature and it won't a\ufb00ect future versions of this feature.\nCondition matching\nThe following table describes condition matching types.", "Although you must specify one condition \nfor each form \ufb01eld that you specify in the form, you can create more complex matching criteria by \nspecifying multiple conditions for a form \ufb01eld.\nCondition Description\nExact Matches Exact matches verify that \ufb01elds match speci\ufb01c values.", "This example indicates \nthat the ACL must be set to  public-read:\n{\"acl\": \"public-read\" }\nThis example is an alternate way to indicate that the  ACL must be set to \npublic-read:\nBrowser-based uploads using POST (AWS signature version 2) API Version 2006-03-01 2968Amazon Simple Storage Service API Reference\nCondition Description\n[ \"eq\", \"$acl\", \"public-read\" ]\nStarts WithIf the value must start with a certain value, use  starts-with.", "This example \nindicates that the key must start  with user/betty:\n[\"starts-with\", \"$key\", \"user/betty/\"]\nMatching Any \nContentTo con\ufb01gure the policy to allow any content within a  \ufb01eld, use starts-with \nwith an empty value.", "This example  allows any success_action_redirect:\n[\"starts-with\", \"$success_action_redirect\", \"\"]\nSpecifying \nRangesFor \ufb01elds that accept ranges, separate the upper and  lower ranges with a \ncomma.", "This example allows a \ufb01le size  from 1 to 10 megabytes:\n[\"content-length-range\", 1048579, 10485760]\nCharacter escaping\nThe following table describes characters that must be escaped within a policy document.\nEscape \nsequenceDescription\n\\\\ Backslash\n\\$ Dollar sign\nBrowser-based uploads using POST (AWS signature version 2) API Version 2006-03-01 2969Amazon Simple Storage Service API Reference\nEscape \nsequenceDescription\n\\bBackspace\n\\fForm feed\n\\n New line\n\\rCarriage return\n\\tHorizontal tab\n\\vVertical tab\n\\uxxxxAll Unicode characters\nConstructing a signature\nStep Description\n1\nEncode the policy by using UTF-8.\n2\nEncode those UTF-8 bytes by using Base64.\n3\nSign the policy with your secret access key by using HMAC  SHA-1.\n4\nEncode the SHA-1 signature by using Base64.\nFor general information about authentication, see Identity and Access Management for Amazon S3.\nBrowser-based uploads using POST (AWS signature version 2) API Version 2006-03-01 2970Amazon Simple Storage Service API Reference\nRedirection\nThis section describes how to handle redirects.\nGeneral redirection\nOn completion of the POST request, the user is redirected to the location that you speci\ufb01ed in \nthe success_action_redirect  \ufb01eld. If Amazon S3 cannot interpret the URL, it ignores the\nsuccess_action_redirect  \ufb01eld.\nIf success_action_redirect  is not speci\ufb01ed, Amazon S3 returns the empty document type \nspeci\ufb01ed in the success_action_status  \ufb01eld.\nIf the POST request fails, Amazon S3 displays an error and does not provide a redirect.\nPre-upload redirection\nIf your bucket was created using <CreateBucketCon\ufb01guration>, your end users might require a \nredirect.", "If this occurs, some browsers might handle the redirect incorrectly.", "This is relatively rare \nbut is most likely to occur right after a bucket is created.\nUpload examples (AWS signature version 2)\nTopics\n\u2022File upload\n\u2022Text area upload\nNote\nThe request authentication discussed in this section is based on AWS Signature Version 2, a \nprotocol for authenticating inbound API requests to AWS services.\nAmazon S3 now supports Signature Version 4, a protocol for authenticating inbound API \nrequests to AWS services, in all AWS Regions.", "At this time, AWS Regions created before \nJanuary 30, 2014 will continue to support the previous protocol, Signature Version 2. Any \nnew regions after January 30, 2014 will support only Signature Version 4 and therefore all \nrequests to those regions must be made with Signature Version 4.", "For more information, \nsee Examples: Browser-Based Upload using HTTP POST (Using AWS Signature Version 4) in \nthe Amazon Simple Storage Service API Reference.\nBrowser-based uploads using POST (AWS signature version 2) API Version 2006-03-01 2971Amazon Simple Storage Service API Reference\nFile upload\nThis example shows the complete process for constructing a policy and form that can be used to \nupload a \ufb01le attachment.\nPolicy and form construction\nThe following policy supports uploads to Amazon S3 for the awsexamplebucket1 bucket.\n{ \"expiration\": \"2007-12-01T12:00:00.000Z\", \n  \"conditions\": [ \n    {\"bucket\": \"awsexamplebucket1\"}, \n    [\"starts-with\", \"$key\", \"user/eric/\"], \n    {\"acl\": \"public-read\"}, \n    {\"success_action_redirect\": \"https://awsexamplebucket1.s3.us-west-1.amazonaws.com/\nsuccessful_upload.html\"}, \n    [\"starts-with\", \"$Content-Type\", \"image/\"], \n    {\"x-amz-meta-uuid\": \"14365123651274\"}, \n    [\"starts-with\", \"$x-amz-meta-tag\", \"\"] \n  ]\n}\nThis policy requires the following:\n\u2022The upload must occur before 12:00 UTC on December 1, 2007.\n\u2022The content must be uploaded to the awsexamplebucket1 bucket.\n\u2022The key must start with \"user/eric/\".\n\u2022The ACL is set to public-read.\n\u2022The success_action_redirect is set to https://awsexamplebucket1.s3.us-west-1.amazonaws.com/\nsuccessful_upload.html.\n\u2022The object is an image \ufb01le.\n\u2022The x-amz-meta-uuid tag must be set to 14365123651274.\n\u2022The x-amz-meta-tag can contain any value.\nThe following is a Base64-encoded version of this policy.\neyAiZXhwaXJhdGlvbiI6ICIyMDA3LTEyLTAxVDEyOjAwOjAwLjAwMFoiLAogICJjb25kaXRpb25zIjogWwogICAgeyJidWNrZXQiOiAiam9obnNtaXRoIn0sCiAgICBbInN0YXJ0cy13aXRoIiwgIiRrZXkiLCAidXNlci9lcmljLyJdLAogICAgeyJhY2wiOiAicHVibGljLXJlYWQifSwKICAgIHsic3VjY2Vzc19hY3Rpb25fcmVkaXJlY3QiOiAiaHR0cDovL2pvaG5zbWl0aC5zMy5hbWF6b25hd3MuY29tL3N1Y2Nlc3NmdWxfdXBsb2FkLmh0bWwifSwKICAgIFsic3RhcnRzLXdpdGgiLCAiJENvbnRlbnQtVHlwZSIsICJpbWFnZS8iXSwKICAgIHsieC1hbXotbWV0YS11dWlkIjogIjE0MzY1MTIzNjUxMjc0In0sCiAgICBbInN0YXJ0cy13aXRoIiwgIiR4LWFtei1tZXRhLXRhZyIsICIiXQogIF0KfQo=\nBrowser-based uploads using POST (AWS signature version 2) API Version 2006-03-01 2972Amazon Simple Storage Service API Reference\nUsing your credentials create a signature, for example 0RavWzkygo6QX9caELEqKi9kDbU=  is the \nsignature for the preceding policy document.\nThe following form supports a POST request to the amzn-s3-demo-bucket bucket that uses this \npolicy.\n<html> \n  <head> \n    ...", "\n    <meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\" /> \n    ... \n  </head> \n  <body> \n  ...", "\n  <form action=\"https://amzn-s3-demo-bucket.s3.us-west-1.amazonaws.com/\" method=\"post\" \n enctype=\"multipart/form-data\"> \n    Key to upload: <input type=\"input\" name=\"key\" value=\"user/eric/\" /><br /> \n    <input type=\"hidden\" name=\"acl\" value=\"public-read\" /> \n    <input type=\"hidden\" name=\"success_action_redirect\" value=\"https://\nawsexamplebucket1.s3.us-west-1.amazonaws.com/successful_upload.html\" /> \n    Content-Type: <input type=\"input\" name=\"Content-Type\" value=\"image/jpeg\" /><br /> \n    <input type=\"hidden\" name=\"x-amz-meta-uuid\" value=\"14365123651274\" /> \n    Tags for File: <input type=\"input\" name=\"x-amz-meta-tag\" value=\"\" /><br /> \n    <input type=\"hidden\" name=\"AWSAccessKeyId\" value=\"AKIAIOSFODNN7EXAMPLE\" /> \n    <input type=\"hidden\" name=\"Policy\" value=\"POLICY\" /> \n    <input type=\"hidden\" name=\"Signature\" value=\"SIGNATURE\" /> \n    File: <input type=\"file\" name=\"file\" /> <br /> \n    <!-- The elements after this will be ignored --> \n    <input type=\"submit\" name=\"submit\" value=\"Upload to Amazon S3\" /> \n  </form> \n  ...\n</html>\nSample request\nThis request assumes that the image uploaded is 117,108 bytes; the image data is not included.\nPOST / HTTP/1.1\nHost: awsexamplebucket1.s3.us-west-1.amazonaws.com\nUser-Agent: Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.8.1.10) Gecko/20071115 \n Firefox/2.0.0.10\nAccept: text/xml,application/xml,application/xhtml+xml,text/html;q=0.9,text/\nplain;q=0.8,image/png,*/*;q=0.5\nBrowser-based uploads using POST (AWS signature version 2) API Version 2006-03-01 2973Amazon Simple Storage Service API Reference\nAccept-Language: en-us,en;q=0.5\nAccept-Encoding: gzip,deflate\nAccept-Charset: ISO-8859-1,utf-8;q=0.7,*;q=0.7\nKeep-Alive: 300\nConnection: keep-alive\nContent-Type: multipart/form-data; boundary=9431149156168\nContent-Length: 118698  \n--9431149156168\nContent-Disposition: form-data; name=\"key\"\nuser/eric/MyPicture.jpg\n--9431149156168\nContent-Disposition: form-data; name=\"acl\"\npublic-read\n--9431149156168\nContent-Disposition: form-data; name=\"success_action_redirect\"\nhttps://awsexamplebucket1.s3.us-west-1.amazonaws.com/successful_upload.html\n--9431149156168\nContent-Disposition: form-data; name=\"Content-Type\"\nimage/jpeg\n--9431149156168\nContent-Disposition: form-data; name=\"x-amz-meta-uuid\"\n14365123651274\n--9431149156168\nContent-Disposition: form-data; name=\"x-amz-meta-tag\"\nSome,Tag,For,Picture\n--9431149156168\nContent-Disposition: form-data; name=\"AWSAccessKeyId\"\nAKIAIOSFODNN7EXAMPLE\n--9431149156168\nContent-Disposition: form-data; name=\"Policy\"\neyAiZXhwaXJhdGlvbiI6ICIyMDA3LTEyLTAxVDEyOjAwOjAwLjAwMFoiLAogICJjb25kaXRpb25zIjogWwogICAgeyJidWNrZXQiOiAiam9obnNtaXRoIn0sCiAgICBbInN0YXJ0cy13aXRoIiwgIiRrZXkiLCAidXNlci9lcmljLyJdLAogICAgeyJhY2wiOiAicHVibGljLXJlYWQifSwKICAgIHsic3VjY2Vzc19hY3Rpb25fcmVkaXJlY3QiOiAiaHR0cDovL2pvaG5zbWl0aC5zMy5hbWF6b25hd3MuY29tL3N1Y2Nlc3NmdWxfdXBsb2FkLmh0bWwifSwKICAgIFsic3RhcnRzLXdpdGgiLCAiJENvbnRlbnQtVHlwZSIsICJpbWFnZS8iXSwKICAgIHsieC1hbXotbWV0YS11dWlkIjogIjE0MzY1MTIzNjUxMjc0In0sCiAgICBbInN0YXJ0cy13aXRoIiwgIiR4LWFtei1tZXRhLXRhZyIsICIiXQogIF0KfQo=\n--9431149156168\nContent-Disposition: form-data; name=\"Signature\"\n0RavWzkygo6QX9caELEqKi9kDbU=\nBrowser-based uploads using POST (AWS signature version 2) API Version 2006-03-01 2974Amazon Simple Storage Service API Reference\n--9431149156168\nContent-Disposition: form-data; name=\"file\"; filename=\"MyFilename.jpg\"\nContent-Type: image/jpeg\n...file content...\n--9431149156168\nContent-Disposition: form-data; name=\"submit\"\nUpload to Amazon S3\n--9431149156168--\nSample response\nHTTP/1.1 303 Redirect\nx-amz-request-id: 1AEE782442F35865\nx-amz-id-2: cxzFLJRatFHy+NGtaDFRR8YvI9BHmgLxjvJzNiGGICARZ/mVXHj7T+qQKhdpzHFh\nContent-Type: application/xml\nDate: Wed, 14 Nov 2007 21:21:33 GMT\nConnection: close\nLocation: https://awsexamplebucket1.s3.us-west-1.amazonaws.com/\nsuccessful_upload.html?bucket=awsexamplebucket1&key=user/eric/\nMyPicture.jpg&etag=&quot;39d459dfbc0faabbb5e179358dfb94c3&quot;\nServer: AmazonS3\nText area upload\nTopics\n\u2022Policy and form construction\n\u2022Sample request\n\u2022Sample response\nThe following example shows the complete process for constructing a policy and form to upload \na text area. Uploading a text area is useful for submitting user-created content, such as blog \npostings.\nPolicy and form construction\nThe following policy supports text area uploads to Amazon S3 for the awsexamplebucket1 bucket.\n{ \"expiration\": \"2007-12-01T12:00:00.000Z\", \n  \"conditions\": [ \nBrowser-based uploads using POST (AWS signature version 2) API Version 2006-03-01 2975Amazon Simple Storage Service API Reference\n    {\"bucket\": \"awsexamplebucket1\"}, \n    [\"starts-with\", \"$key\", \"user/eric/\"], \n    {\"acl\": \"public-read\"}, \n    {\"success_action_redirect\": \"https://awsexamplebucket1.s3.us-west-1.amazonaws.com/\nnew_post.html\"}, \n    [\"eq\", \"$Content-Type\", \"text/html\"], \n    {\"x-amz-meta-uuid\": \"14365123651274\"}, \n    [\"starts-with\", \"$x-amz-meta-tag\", \"\"] \n  ]\n}\nThis policy requires the following:\n\u2022The upload must occur before 12:00 GMT on 2007-12-01.\n\u2022The content must be uploaded to the awsexamplebucket1 bucket.\n\u2022The key must start with \"user/eric/\".\n\u2022The ACL is set to public-read.\n\u2022The success_action_redirect is set to https://awsexamplebucket1.s3.us-west-1.amazonaws.com/\nnew_post.html.\n\u2022The object is HTML text.\n\u2022The x-amz-meta-uuid tag must be set to 14365123651274.\n\u2022The x-amz-meta-tag can contain any value.\nFollowing is a Base64-encoded version of this policy.\neyAiZXhwaXJhdGlvbiI6ICIyMDA3LTEyLTAxVDEyOjAwOjAwLjAwMFoiLAogICJjb25kaXR\npb25zIjogWwogICAgeyJidWNrZXQiOiAiam9obnNtaXRoIn0sCiAgICBbInN0YXJ0cy13aXRoIiwgIiRrZXkiLCAidXNlci9lcmljLyJd\nLAogICAgeyJhY2wiOiAicHVibGljLXJlYWQifSwKICAgIHsic3VjY2Vzc19hY3Rpb25fcmVkaXJlY3QiOiAiaHR0cDovL2pvaG5zbWl0a\nC5zMy5hbWF6b25hd3MuY29tL25ld19wb3N0Lmh0bWwifSwKICAgIFsiZXEiLCAiJENvbnRlbnQtVHlwZSIsICJ0ZXh0L2h0bWwiXSwKI\nCAgIHsieC1hbXotbWV0YS11dWlkIjogIjE0MzY1MTIzNjUxMjc0In0sCiAgICBbInN0YXJ0cy13aXRoIiwgIiR4LWFtei1tZXRhLXRhZy\nIsICIiXQogIF0KfQo=\nUsing your credentials, create a signature. For example, qA7FWXKq6VvU68lI9KdveT1cWgF=  is the \nsignature for the preceding policy document.\nThe following form supports a POST request to the amzn-s3-demo-bucket bucket that uses this \npolicy.\n<html> \nBrowser-based uploads using POST (AWS signature version 2) API Version 2006-03-01 2976Amazon Simple Storage Service API Reference\n  <head> \n    ...", "\n    <meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\" /> \n    ... \n  </head> \n  <body> \n  ...", "\n  <form action=\"https://amzn-s3-demo-bucket.s3.us-west-1.amazonaws.com/\" method=\"post\" \n enctype=\"multipart/form-data\"> \n    Key to upload: <input type=\"input\" name=\"key\" value=\"user/eric/\" /><br /> \n    <input type=\"hidden\" name=\"acl\" value=\"public-read\" /> \n    <input type=\"hidden\" name=\"success_action_redirect\" value=\"https://\nawsexamplebucket1.s3.us-west-1.amazonaws.com/new_post.html\" /> \n    <input type=\"hidden\" name=\"Content-Type\" value=\"text/html\" /> \n    <input type=\"hidden\" name=\"x-amz-meta-uuid\" value=\"14365123651274\" /> \n    Tags for File: <input type=\"input\" name=\"x-amz-meta-tag\" value=\"\" /><br /> \n    <input type=\"hidden\" name=\"AWSAccessKeyId\" value=\"AKIAIOSFODNN7EXAMPLE\" /> \n    <input type=\"hidden\" name=\"Policy\" value=\"POLICY\" /> \n    <input type=\"hidden\" name=\"Signature\" value=\"SIGNATURE\" /> \n    Entry: <textarea name=\"file\" cols=\"60\" rows=\"10\">\nYour blog post goes here. \n    </textarea><br /> \n    <!-- The elements after this will be ignored --> \n    <input type=\"submit\" name=\"submit\" value=\"Upload to Amazon S3\" /> \n  </form> \n  ...\n</html>\nSample request\nThis request assumes that the image uploaded is 117,108 bytes; the image data is not included.\nPOST / HTTP/1.1\nHost: awsexamplebucket1.s3.us-west-1.amazonaws.com\nUser-Agent: Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.8.1.10) Gecko/20071115 \n Firefox/2.0.0.10\nAccept: text/xml,application/xml,application/xhtml+xml,text/html;q=0.9,text/\nplain;q=0.8,image/png,*/*;q=0.5\nAccept-Language: en-us,en;q=0.5\nAccept-Encoding: gzip,deflate\nAccept-Charset: ISO-8859-1,utf-8;q=0.7,*;q=0.7\nKeep-Alive: 300\nBrowser-based uploads using POST (AWS signature version 2) API Version 2006-03-01 2977Amazon Simple Storage Service API Reference\nConnection: keep-alive\nContent-Type: multipart/form-data; boundary=178521717625888\nContent-Length: 118635\n-178521717625888\nContent-Disposition: form-data; name=\"key\"\nser/eric/NewEntry.html\n--178521717625888\nContent-Disposition: form-data; name=\"acl\"\npublic-read\n--178521717625888\nContent-Disposition: form-data; name=\"success_action_redirect\"\nhttps://awsexamplebucket1.s3.us-west-1.amazonaws.com/new_post.html\n--178521717625888\nContent-Disposition: form-data; name=\"Content-Type\"\ntext/html\n--178521717625888\nContent-Disposition: form-data; name=\"x-amz-meta-uuid\"\n14365123651274\n--178521717625888\nContent-Disposition: form-data; name=\"x-amz-meta-tag\"\nInteresting Post\n--178521717625888\nContent-Disposition: form-data; name=\"AWSAccessKeyId\"\nAKIAIOSFODNN7EXAMPLE\n--178521717625888\nContent-Disposition: form-data; name=\"Policy\"\neyAiZXhwaXJhdGlvbiI6ICIyMDA3LTEyLTAxVDEyOjAwOjAwLjAwMFoiLAogICJjb25kaXRpb25zIjogWwogICAgeyJidWNrZXQiOiAiam9obnNtaXRoIn0sCiAgICBbInN0YXJ0cy13aXRoIiwgIiRrZXkiLCAidXNlci9lcmljLyJdLAogICAgeyJhY2wiOiAicHVibGljLXJlYWQifSwKICAgIHsic3VjY2Vzc19hY3Rpb25fcmVkaXJlY3QiOiAiaHR0cDovL2pvaG5zbWl0aC5zMy5hbWF6b25hd3MuY29tL25ld19wb3N0Lmh0bWwifSwKICAgIFsiZXEiLCAiJENvbnRlbnQtVHlwZSIsICJ0ZXh0L2h0bWwiXSwKICAgIHsieC1hbXotbWV0YS11dWlkIjogIjE0MzY1MTIzNjUxMjc0In0sCiAgICBbInN0YXJ0cy13aXRoIiwgIiR4LWFtei1tZXRhLXRhZyIsICIiXQogIF0KfQo=\n--178521717625888\nContent-Disposition: form-data; name=\"Signature\"\nqA7FWXKq6VvU68lI9KdveT1cWgF=\n--178521717625888\nContent-Disposition: form-data; name=\"file\"\n...content goes here...\nBrowser-based uploads using POST (AWS signature version 2) API Version 2006-03-01 2978Amazon Simple Storage Service API Reference\n--178521717625888\nContent-Disposition: form-data; name=\"submit\"\nUpload to Amazon S3\n--178521717625888--\nSample response\nHTTP/1.1 303 Redirect\nx-amz-request-id: 1AEE782442F35865\nx-amz-id-2: cxzFLJRatFHy+NGtaDFRR8YvI9BHmgLxjvJzNiGGICARZ/mVXHj7T+qQKhdpzHFh\nContent-Type: application/xml\nDate: Wed, 14 Nov 2007 21:21:33 GMT\nConnection: close\nLocation: https://awsexamplebucket1.s3.us-west-1.amazonaws.com/new_post.html?\nbucket=awsexamplebucket1&key=user/eric/\nNewEntry.html&etag=40c3271af26b7f1672e41b8a274d28d4\nServer: AmazonS3\nPOST with adobe \ufb02ash (AWS signature version 2)\nThis section describes how to use POST with Adobe Flash.\nAdobe \ufb02ash player security\nBy default, the Adobe Flash Player security model prohibits Adobe Flash Players from making \nnetwork connections to servers outside the domain that serves the SWF \ufb01le.\nTo override the default, you must upload a publicly readable crossdomain.xml \ufb01le to the bucket \nthat will accept POST uploads. The following is a sample crossdomain.xml \ufb01le.\n<?xml version=\"1.0\"?>\n<!DOCTYPE cross-domain-policy SYSTEM\n\"http://www.macromedia.com/xml/dtds/cross-domain-policy.dtd\">\n<cross-domain-policy>\n<allow-access-from domain=\"*\" secure=\"false\" />\n</cross-domain-policy>\nNote\nFor more information about the Adobe Flash security model, go to the Adobe website.\nBrowser-based uploads using POST (AWS signature version 2) API Version 2006-03-01 2979Amazon Simple Storage Service API Reference\nAdding the crossdomain.xml \ufb01le to your bucket allows any Adobe Flash Player to connect \nto the crossdomain.xml \ufb01le within your bucket; however, it does not grant access to the \nactual Amazon S3 bucket.\nAdobe \ufb02ash considerations\nThe FileReference API in Adobe Flash adds the Filename  form \ufb01eld to the POST request. When \nyou build Adobe Flash applications that upload to Amazon S3 by using the FileReference API \naction, include the following condition in your policy:\n['starts-with', '$Filename', '']\nSome versions of the Adobe Flash Player do not properly handle HTTP responses that have an \nempty body.", "To con\ufb01gure POST to return a response that does not have an empty body, set\nsuccess_action_status  to 201.", "Amazon S3 will then return an XML document with a 201 \nstatus code.", "For information about the content of the XML document, see POST Object.", "For \ninformation about form \ufb01elds, see HTML form \ufb01elds .\nAppendix: Lifecycle Con\ufb01guration APIs (Deprecated)\nBucket lifecycle con\ufb01guration is updated to support \ufb01lters based on object tags. That is, you can \nnow specify a rule that speci\ufb01es key name pre\ufb01x, one or more object tags, or both to select a \nsubset of objects to which the rule applies. The APIs have been updated accordingly.", "The following \ntopics describes the prior version of the PUT and GET bucket lifecycle operations for backward \ncompatibility.\nTopics\n\u2022PUT Bucket lifecycle (Deprecated)\n\u2022GET Bucket lifecycle (Deprecated)\nAppendix: Lifecycle Con\ufb01guration APIs (Deprecated) API Version 2006-03-01 2980Amazon Simple Storage Service API Reference\nPUT Bucket lifecycle (Deprecated)\nDescription\nImportant\nFor an updated version of this API, see PutBucketLifecycleCon\ufb01guration.", "This version \nhas been deprecated. Existing lifecycle con\ufb01gurations will work. For new lifecycle \ncon\ufb01gurations, use the updated API.\nCreates a new lifecycle con\ufb01guration for the bucket or replaces an existing lifecycle con\ufb01guration.", "\nFor information about lifecycle con\ufb01guration, see Object Lifecycle Management in the Amazon \nSimple Storage Service User Guide.\nPermissions\nBy default, all Amazon S3 resources, including buckets, objects, and related subresources (for \nexample, lifecycle con\ufb01guration and website con\ufb01guration) are private.", "Only the resource owner, \nthe AWS account that created the resource, can access it.\u00a0The resource owner can optionally grant \naccess permissions to others by writing an access policy.", "For this operation, users must get the\ns3:PutLifecycleConfiguration  permission.\nYou can also explicitly deny permissions.", "Explicit denial also supersedes any other permissions.", "If \nyou want to prevent users or accounts from removing or deleting objects from your bucket, you \nmust deny them permissions for the following actions:\n\u2022s3:DeleteObject\n\u2022s3:DeleteObjectVersion\n\u2022s3:PutLifecycleConfiguration\nFor more information about permissions, see Managing Access Permissions to Your Amazon S3 \nResources in the Amazon Simple Storage Service User Guide.\nPUT Bucket lifecycle (Deprecated) API Version 2006-03-01 2981Amazon Simple Storage Service API Reference\nRequests\nSyntax\nPUT /?lifecycle HTTP/1.1\nHost: bucketname .s3.amazonaws.com\nContent-Length: length\nDate: date\nAuthorization: authorization string  \nContent-MD5: MD5\nLifecycle configuration in the request body\nFor details about authorization strings, see Authenticating Requests (AWS Signature Version 4).\nRequest Parameters\nThis implementation of the operation does not use request parameters.\nRequest Headers\nName Description Required\nContent-MD5\nThe base64-encoded 128-bit MD5 digest \nof the data.", "You must use this header as a  \n message integrity check to verify that the \nrequest body was not  corrupted in transit. For \nmore information, see RFC  1864.\nType: String\nDefault: NoneYes\nRequest Body\nIn the request, you specify the lifecycle con\ufb01guration in the request body.", "The lifecycle \ncon\ufb01guration is speci\ufb01ed as XML. The following is an example of a basic lifecycle con\ufb01guration. \nIt speci\ufb01es one rule. The Prefix in the rule identi\ufb01es objects to which the rule applies. The rule \nalso speci\ufb01es two actions (Transition and Expiration ).", "Each action speci\ufb01es a timeline when \nPUT Bucket lifecycle (Deprecated) API Version 2006-03-01 2982Amazon Simple Storage Service API Reference\nAmazon S3 should perform the action. The Status  indicates whether the rule is enabled or \ndisabled.\n<LifecycleConfiguration> \n    <Rule> \n        <ID>sample-rule</ID> \n        <Prefix> key-prefix </Prefix> \n        <Status> rule-status </Status> \n        <Transition>   \u00a0\u00a0\u00a0\u00a0\u00a0 \n           <Date> value</Date>   \u00a0\u00a0\u00a0\u00a0\u00a0 \n           <StorageClass> storage class </StorageClass>   \u00a0\u00a0\u00a0  \n        </Transition>     \n        <Expiration> \n           <Days> value</Days> \n        </Expiration> \n    </Rule>\n</LifecycleConfiguration>\nIf the state of your bucket is versioning-enabled or versioning-suspended, you can have many \nversions of the same object: one current version and zero or more noncurrent versions. The \nfollowing lifecycle con\ufb01guration speci\ufb01es the actions (NoncurrentVersionTransition ,\nNoncurrentVersionExpiration ) that are speci\ufb01c to noncurrent object versions.\n<LifecycleConfiguration> \n    <Rule> \n        <ID>sample-rule</ID> \n        <Prefix> key-prefix </Prefix> \n        <Status> rule-status </Status> \n        <NoncurrentVersionTransition>       \n           <NoncurrentDays> value</NoncurrentDays>       \n           <StorageClass> storage class </StorageClass>    \n        </NoncurrentVersionTransition>     \n        <NoncurrentVersionExpiration>      \n           <NoncurrentDays> value</NoncurrentDays>     \n        </NoncurrentVersionExpiration>  \n    </Rule>\n</LifecycleConfiguration>\nYou can use the multipart upload API to upload large objects in parts.", "For more information \nabout multipart uploads, see Multipart Upload Overview in the Amazon Simple Storage Service \nUser Guide .", "With lifecycle con\ufb01guration, you can tell Amazon S3 to cancel incomplete multipart \nPUT Bucket lifecycle (Deprecated) API Version 2006-03-01 2983Amazon Simple Storage Service API Reference\nuploads, which are identi\ufb01ed by the key name pre\ufb01x speci\ufb01ed in the rule, if they don't complete \nwithin a speci\ufb01ed number of days. When Amazon S3 cancels a multipart upload, it deletes \nall parts associated with the upload. This ensures that you don't have incomplete multipart \nuploads that have left parts stored in Amazon S3, so you don't have to pay storage costs \nfor them.", "The following is an example lifecycle con\ufb01guration that speci\ufb01es a rule with the\nAbortIncompleteMultipartUpload  action. This action tells Amazon S3 to cancel incomplete \nmultipart uploads seven days after initiation.\n<LifecycleConfiguration> \n    <Rule> \n        <ID>sample-rule</ID> \n        <Prefix> SomeKeyPrefix /</Prefix> \n        <Status> rule-status </Status> \n        <AbortIncompleteMultipartUpload> \n          <DaysAfterInitiation>7</DaysAfterInitiation> \n        </AbortIncompleteMultipartUpload> \n    </Rule>\n</LifecycleConfiguration>\nThe following table describes the XML elements in the lifecycle con\ufb01guration.\nName Description Required\nAbortIncompleteMul \ntipartUploadContainer for specifying when an incomplet \ne multipart upload becomes eligible for an  \n abort operation.\nChild: DaysAfterInitiation\nType: Container\nAncestor: RuleYes, if \nno other \naction is \nspeci\ufb01ed \nfor the rule\nDate\nDate when you want Amazon S3 to take the \naction.", "For more information, see Lifecycle \nRules: Based on a Speci\ufb01c Date  in the  \n  Amazon Simple Storage Service User Guide.\n Yes, if\nDays  and\nExpiredOb \njectDelet \nPUT Bucket lifecycle (Deprecated) API Version 2006-03-01 2984Amazon Simple Storage Service API Reference\nName Description Required\nThe date value must conform to ISO 8601 \nformat.", "The time is always midnight UTC.\nType: String\nAncestor: Expiration  or TransitioneMarker\nare  absent\nDays\nSpeci\ufb01es the number of days after object \ncreation when the speci\ufb01c rule action  takes \ne\ufb00ect.\nType: Nonnegative Integer when used with\nTransition , Positive Integer  when used \nwith Expiration\nAncestor: Expiration , TransitionYes, if\nDate  and\nExpiredOb \njectDelet \neMarker\nare  absent\nDaysAfterInitiation\nSpeci\ufb01es the number of days after initiating a \nmultipart upload when the multipart  upload \nmust be completed.", "If it does not complete \nby the speci\ufb01ed number of days,  it becomes \neligible for an abort operation and Amazon \nS3 cancels the incomplete multipart  upload.\nType: Positive Integer\nAncestor: AbortIncompleteMul \ntipartUploadYes, if a \nparent tag \nis speci\ufb01ed\nPUT Bucket lifecycle (Deprecated) API Version 2006-03-01 2985Amazon Simple Storage Service API Reference\nName Description Required\nExpiration\nThis action speci\ufb01es a period in an object's \nlifetime when Amazon S3 should take the  \n appropriate expiration action. The action \nAmazon S3 takes  depends on whether the \nbucket is versioning-enabled.\n\u2022\nIf versioning has never been enabled on \nthe  bucket, Amazon S3 deletes the only \ncopy of the  object permanently.\n\u2022\nIf the bucket is versioning-enabled (or \nversioning is suspended), the action  applies \nonly to the current version of the object. A  \n versioning-enabled bucket can have many \nversions of the  same object: one current \nversion and zero or more  noncurrent \nversions.\nInstead of deleting the current version, \nAmazon S3  makes it a noncurrent version \nby adding a delete   marker as the new \ncurrent version.\nImportant\nIf a bucket's state is versioning-\nsuspended, Amazon S3 creates \na delete marker with  version \nID null. If you have a version   \n with version ID null, Amazon S3 \noverwrites  that version.Yes, if \nno other \naction is \npresent in \nthe Rule .\nPUT Bucket lifecycle (Deprecated) API Version 2006-03-01 2986Amazon Simple Storage Service API Reference\nName Description Required\nNote\nTo set the expiration for noncurren \nt objects, use the   Noncurren \ntVersionExpiration   action.\n \nType: Container\nChildren: Days or Date\nAncestor: Rule\nID\nUnique identi\ufb01er for the rule.", "The value \ncannot be longer than 255  characters.\nType: String\nAncestor: RuleNo\nLifecycleConfiguration\nContainer for lifecycle rules.", "You can add as \nmany as 1000 rules.\nType: Container\nChildren: Rule\nAncestor: NoneYes\nPUT Bucket lifecycle (Deprecated) API Version 2006-03-01 2987Amazon Simple Storage Service API Reference\nName Description Required\nExpiredObjectDelet \neMarkerOn a versioned bucket (a versioning-enabled \nor versioning-suspended bucket), you can  \nadd this element in the lifecycle con\ufb01guration \nto tell Amazon S3 to  delete expired object \ndelete markers. For an example, see Example \n8: Removing Expired Object Delete Markers \n in the Amazon Simple Storage Service User \nGuide .", "Don't add it to a  non-versioned bucket, \nbecause that type of bucket cannot include  d \nelete markers.\nType: String\nValid values: true | false (the value false  is \nallowed, but it is no-op,  which means that \nAmazon S3 will not take action)\nAncestor: ExpirationYes, if\nDate  and\nDays are \nabsent\nNoncurrentDays\nSpeci\ufb01es the number of days an object is \nnoncurrent before Amazon S3 can perform  \n the associated action. For information about \nthe noncurrent days  calculations, see How \nAmazon S3 Calculates When an Object \nBecame Noncurrent  in the Amazon Simple \nStorage Service User Guide.\nType: Nonnegative Integer when used with\nNoncurrentVersionTransition ,  \n Positive Integer when used with   Noncurren \ntVersionExpiration\nAncestor: NoncurrentVersionE \nxpiration  or   NoncurrentVersionT \nransitionYes\nPUT Bucket lifecycle (Deprecated) API Version 2006-03-01 2988Amazon Simple Storage Service API Reference\nName Description Required\nNoncurrentVersionE \nxpirationSpeci\ufb01es when noncurrent object versions \nexpire. Upon expiration, Amazon S3  perman \nently deletes the noncurrent object versions.\nSet this lifecycle con\ufb01guration action on a \nbucket that has versioning enabled (or  suspe \nnded) to tell Amazon S3 to delete noncurren \nt object versions at  a speci\ufb01c period in the \nobject's lifetime.\nType: Container\nChildren: NoncurrentDays\nAncestor: RuleYes, if \nno other \naction is \npresent in \nthe Rule\nNoncurrentVersionT \nransitionContainer for the transition rule that \ndescribes when noncurrent objects transitio \nn to  the STANDARD_IA , ONEZONE_IA , or  \n GLACIER storage class.\nIf your bucket is versioning-enabled (or if \nversioning is suspended), you can set this  acti \non to tell Amazon S3 to transition noncurren \nt object versions at  a speci\ufb01c period in the \nobject's lifetime.\nType: Container\nChildren: NoncurrentDays and StorageClass\nAncestor: RuleYes, if \nno other \naction is \npresent in \nthe Rule\nPUT Bucket lifecycle (Deprecated) API Version 2006-03-01 2989Amazon Simple Storage Service API Reference\nName Description Required\nPrefix\nObject key pre\ufb01x that identi\ufb01es one or more \nobjects to which the rule  applies.\nType: String\nAncestor: RuleYes\nRule\nContainer for a lifecycle rule. A lifecycle \ncon\ufb01guration can contain as many as  1000 \nrules.\nType: Container\nAncestor:LifecycleCon\ufb01gurationYes\nStatus\nIf enabled, Amazon S3 executes the rule as \nscheduled. If it is disabled, Amazon S3 ignores \nthe  rule.\nType: String\nAncestor: Rule\nValid values: Enabled, DisabledYes\nStorageClass\nSpeci\ufb01es the Amazon S3 storage class to \nwhich you want the object to transition.\nType: String\nAncestor: Transition and NoncurrentVersionT \nransition\nValid values: STANDARD_IA | ONEZONE_IA | \nGLACIERYes\nThis \nelement is \nrequired \nonly if you \nspecify one \nor both its  \n ancestors.\nPUT Bucket lifecycle (Deprecated) API Version 2006-03-01 2990Amazon Simple Storage Service API Reference\nName Description Required\nTransition\nThis action speci\ufb01es a period in the objects' \nlifetime when Amazon S3 should transition  \n them to the STANDARD_IA , ONEZONE_IA ,  \n or GLACIER storage class. When this action  \nis in e\ufb00ect, what Amazon S3 does depends on \nwhether the bucket is  versioning-enabled.\n\u2022\nIf versioning has never been enabled on \nthe bucket, Amazon S3 transitions the only \ncopy  of the object to the speci\ufb01ed storage \nclass.\n\u2022\nIf your bucket is versioning-enabled (or \nversioning is suspended), Amazon S3 \ntransitions  only the current versions of \nobjects identi\ufb01ed in the  rule.\nNote\nA versioning-enabled bucket \ncan have many versions of an \nobject.", "This action has  no e\ufb00ect \non noncurrent object versions.", "\nTo  transition noncurrent objects, \nyou must use the   Noncurren \ntVersionTransition   action.\nType: Container\nChildren: Days or Date, and StorageClassYes, if \nno other \naction is \npresent in \nthe Rule\nPUT Bucket lifecycle (Deprecated) API Version 2006-03-01 2991Amazon Simple Storage Service API Reference\nName Description Required\nAncestor: Rule\nResponses\nResponse Headers\nThis implementation of the operation uses only response headers that are common to most \nresponses.", "For more information, see Common Response Headers.\nResponse Elements\nThis implementation of the operation does not return response elements.\nSpecial Errors\nThis implementation of the operation does not return special errors.", "For general information about \nAmazon S3 errors and a list of error codes, see Error Responses.\nExamples\nExample 1: Add Lifecycle Con\ufb01guration to a Bucket That Is Not Versioning-enabled\nThe following lifecycle con\ufb01guration speci\ufb01es two rules, each with one action.\n\u2022The Transition action tells Amazon S3 to transition objects with the \"documents/\" pre\ufb01x to the \nGLACIER storage class 30 days after creation.\n\u2022The Expiration action tells Amazon S3 to delete objects with the \"logs/\" pre\ufb01x 365 days after \ncreation.\n<LifecycleConfiguration> \n  <Rule> \n    <ID>id1</ID> \n    <Prefix>documents/</Prefix> \n    <Status>Enabled</Status> \n    <Transition> \n      <Days>30</Days> \n      <StorageClass>GLACIER</StorageClass> \n    </Transition> \nPUT Bucket lifecycle (Deprecated) API Version 2006-03-01 2992Amazon Simple Storage Service API Reference\n  </Rule> \n  <Rule> \n    <ID>id2</ID> \n    <Prefix>logs/</Prefix> \n    <Status>Enabled</Status> \n    <Expiration> \n      <Days>365</Days> \n    </Expiration> \n  </Rule>\n</LifecycleConfiguration>\nThe following is a sample PUT /?lifecycle  request that adds the preceding lifecycle \ncon\ufb01guration to the examplebucket  bucket.\nPUT /?lifecycle HTTP/1.1\nHost: examplebucket.s3.amazonaws.com  \nx-amz-date: Wed, 14 May 2014 02:11:21 GMT\nContent-MD5: q6yJDlIkcBaGGfb3QLY69A==\nAuthorization: authorization string\nContent-Length: 415\n<LifecycleConfiguration> \n  <Rule> \n    <ID>id1</ID> \n    <Prefix>documents/</Prefix> \n    <Status>Enabled</Status> \n    <Transition> \n      <Days>30</Days> \n      <StorageClass>GLACIER</StorageClass> \n    </Transition> \n  </Rule> \n  <Rule> \n    <ID>id2</ID> \n    <Prefix>logs/</Prefix> \n    <Status>Enabled</Status> \n    <Expiration> \n      <Days>365</Days> \n    </Expiration> \n  </Rule>\n</LifecycleConfiguration>\nThe following is a sample response.\nPUT Bucket lifecycle (Deprecated) API Version 2006-03-01 2993Amazon Simple Storage Service API Reference\nHTTP/1.1 200 OK\nx-amz-id-2: r+qR7+nhXtJDDIJ0JJYcd+1j5nM/rUFiiiZ/fNbDOsd3JUE8NWMLNHXmvPfwMpdc\nx-amz-request-id: 9E26D08072A8EF9E\nDate: Wed, 14 May 2014 02:11:22 GMT\nContent-Length: 0\nServer: AmazonS3\nExample 2: Add Lifecycle Con\ufb01guration to a Versioning-enabled Bucket\nThe following lifecycle con\ufb01guration speci\ufb01es two rules, each with one action for Amazon S3 \nto perform. You specify these actions when your bucket is versioning-enabled or versioning is \nsuspended:\n\u2022The NoncurrentVersionExpiration  action tells Amazon S3 to expire noncurrent versions of \nobjects with the \"logs/\" pre\ufb01x 100 days after the objects become noncurrent.\n\u2022The NoncurrentVersionTransition  action tells Amazon S3 to transition noncurrent versions \nof objects with the \"documents/\" pre\ufb01x to the GLACIER storage class 30 days after they become \nnoncurrent.\n<LifeCycleConfiguration> \n  <Rule> \n    <ID>DeleteAfterBecomingNonCurrent</ID> \n    <Prefix>logs/</Prefix> \n    <Status>Enabled</Status> \n    <NoncurrentVersionExpiration> \n      <NoncurrentDays>100</NoncurrentDays> \n    </NoncurrentVersionExpiration> \n  </Rule> \n  <Rule> \n    <ID>TransitionAfterBecomingNonCurrent</ID> \n    <Prefix>documents/</Prefix> \n    <Status>Enabled</Status> \n    <NoncurrentVersionTransition> \n      <NoncurrentDays>30</NoncurrentDays> \n      <StorageClass>GLACIER</StorageClass> \n    </NoncurrentVersionTransition> \n  </Rule>\n</LifeCycleConfiguration>\nPUT Bucket lifecycle (Deprecated) API Version 2006-03-01 2994Amazon Simple Storage Service API Reference\nThe following is a sample PUT /?lifecycle  request that adds the preceding lifecycle \ncon\ufb01guration to the examplebucket  bucket.\nPUT /?lifecycle HTTP/1.1\nHost: examplebucket.s3.amazonaws.com  \nx-amz-date: Wed, 14 May 2014 02:21:48 GMT\nContent-MD5: 96rxH9mDqVNKkaZDddgnw==\nAuthorization: authorization string\nContent-Length: 598\n<LifeCycleConfiguration> \n  <Rule> \n    <ID>DeleteAfterBecomingNonCurrent</ID> \n    <Prefix>logs/</Prefix> \n    <Status>Enabled</Status> \n    <NoncurrentVersionExpiration> \n      <NoncurrentDays>1</NoncurrentDays> \n    </NoncurrentVersionExpiration> \n  </Rule> \n  <Rule> \n    <ID>TransitionSoonAfterBecomingNonCurrent</ID> \n    <Prefix>documents/</Prefix> \n    <Status>Enabled</Status> \n    <NoncurrentVersionTransition> \n      <NoncurrentDays>0</NoncurrentDays> \n      <StorageClass>GLACIER</StorageClass> \n    </NoncurrentVersionTransition> \n  </Rule>\n</LifeCycleConfiguration>\nThe following is a sample response.\nHTTP/1.1 200 OK\nx-amz-id-2: aXQ+KbIrmMmoO//3bMdDTw/CnjArwje+J49Hf+j44yRb/VmbIkgIO5A+PT98Cp/6k07hf\n+LD2mY=\nx-amz-request-id: 02D7EC4C10381EB1\nDate: Wed, 14 May 2014 02:21:50 GMT\nContent-Length: 0\nServer: AmazonS3\nPUT Bucket lifecycle (Deprecated) API Version 2006-03-01 2995Amazon Simple Storage Service API Reference\nAdditional Examples\nFor more examples of transitioning objects to storage classes such as STANDARD_IA or \nONEZONE_IA, see Examples of Lifecycle Con\ufb01guration.\nRelated Resources\n\u2022GetBucketLifecycleCon\ufb01guration\n\u2022POST Object restore\n\u2022By default, a resource owner\u2014in this case, a bucket owner, which is the AWS account that \ncreated the bucket\u2014can perform any of the operations.", "A resource owner can also grant others \npermission to perform the operation.", "For more information, see the following topics in the\nAmazon Simple Storage Service User Guide:\n\u2022Specifying Permissions in a Policy\n\u2022Managing Access Permissions to Your Amazon S3 Resources\nPUT Bucket lifecycle (Deprecated) API Version 2006-03-01 2996Amazon Simple Storage Service API Reference\nGET Bucket lifecycle (Deprecated)\nDescription\nImportant\nFor an updated version of this API, see GetBucketLifecycleCon\ufb01guration.", "If you con\ufb01gured a \nbucket lifecycle using the <\ufb01lter> element, you should see an updated version of this topic. \nThis topic is provided for backward compatibility.\nReturns the lifecycle  con\ufb01guration information set on the bucket.", "For information about \nlifecycle con\ufb01guration, go to Object Lifecycle Management in the Amazon Simple Storage Service \nUser Guide .\nTo use this operation, you must have permission to perform the\ns3:GetLifecycleConfiguration  action.", "The bucket owner has this permission by default. The \nbucket owner can grant this permission to others.", "For more information about permissions, see\nManaging Access Permissions to Your Amazon S3 Resources in the Amazon Simple Storage Service \nUser Guide .\nRequests\nSyntax\nGET /?lifecycle HTTP/1.1\nHost: bucketname .s3.amazonaws.com\nDate: date\nAuthorization: authorization string  (see Authenticating Requests (AWS Signature Version \n  4))\nRequest Parameters\nThis implementation of the operation does not use request parameters.\nRequest Headers\nThis implementation of the operation uses only request headers that are common to all operations.", "\nFor more information, see Common Request Headers.\nGET Bucket lifecycle (Deprecated) API Version 2006-03-01 2997Amazon Simple Storage Service API Reference\nRequest Elements\nThis implementation of the operation does not use request elements.\nResponses\nResponse Headers\nThis implementation of the operation uses only response headers that are common to most \nresponses.", "For more information, see Common Response Headers.\nResponse Elements\nThis implementation of GET returns the following response elements.\nName Description Required\nAbortIncompleteMul \ntipartUploadContainer for specifying when an incomplet \ne multipart upload becomes eligible for an  \n abort operation.\nChild:   DaysAfterInitiation\nType:  Container\nAncestor: RuleYes, if \nno other \naction is \nspeci\ufb01ed \nfor the rule\nDate\nDate when you want Amazon S3 to take the \naction.", "For more information, see Lifecycle \nRules: Based on a Speci\ufb01c Date  in the  \n  Amazon Simple Storage Service User Guide.\n \nThe date value must conform to the ISO 8601 \nformat. The time is always  midnight UTC.\nType: String\nAncestor: Expiration  or TransitionYes, if\nDays  and\nExpiredOb \njectDelet \neMarker\nare  absent\nGET Bucket lifecycle (Deprecated) API Version 2006-03-01 2998Amazon Simple Storage Service API Reference\nName Description Required\nDays\nSpeci\ufb01es the number of days after object \ncreation when the speci\ufb01c rule action takes  \n e\ufb00ect. The object's eligibility time is calculate \nd as creation  time + the number of days with \nthe resulting time rounded to  midnight UTC \nof the next day.\nType: Non-negative Integer when used with\nTransition , Positive Integer  when used \nwith Expiration .\nAncestor: Transition  or ExpirationYes, if\nDate  and\nExpiredOb \njectDelet \neMarker\nare  absent\nDaysAfterInitiation\nSpeci\ufb01es the number of days after initiating a \nmultipart  upload when the multipart upload \nmust be completed.", "If it does  not complete \nby the speci\ufb01ed number of days, it becomes  e \nligible for an abort operation and Amazon S3 \ncancels the incomplete  multipart upload.\nType: Positive Integer\nAncestor: AbortIncompleteMul \ntipartUploadYes, if\nDate  is \nabsent\nGET Bucket lifecycle (Deprecated) API Version 2006-03-01 2999Amazon Simple Storage Service API Reference\nName Description Required\nExpiration\nThis action speci\ufb01es a period in the object's \nlifetime when Amazon S3 should take the  \n appropriate expiration action.", "The expiration \naction occurs only on objects  that are eligible \naccording to the period speci\ufb01ed in the child\nDate  or Days element.", "The action Amazon \nS3 takes  depends on whether the bucket is \nversioning enabled.\n\u2022\nIf versioning has never been enabled on \nthe  bucket, Amazon S3 deletes the only \ncopy of the  object permanently.\n\u2022\nOtherwise, if your bucket is versioning-\nenabled (or versioning is suspended), the  \n action applies only to the current version \nof the  object. Buckets that are versionin \ng-enabled or  versioning-suspended can \nhave many versions of the same  object: \none current version, and zero or more \nnoncurrent  versions.\nInstead of deleting the current version, \nAmazon S3  makes it a noncurrent version \nby adding a delete   marker as the new \ncurrent version.\nImportant\nIf the state of a bucket is versionin \ng-suspended, Amazon S3 creates \na delete marker   with version ID\nnull. If you have a  version with Yes, if the \nparent tag \nis speci\ufb01ed\nGET Bucket lifecycle (Deprecated) API Version 2006-03-01 3000Amazon Simple Storage Service API Reference\nName Description Required\nversion ID null, then Amazon S3  \n overwrites that version.\nNote\nTo set the expiration for noncurren \nt objects, you must use the  \n  NoncurrentVersionE \nxpiration   action.\nType: Container\nChildren: Days or Date\nAncestor: Rule\nID\nUnique identi\ufb01er for the rule.", "The value \ncannot be longer than 255  characters.\nType: String\nAncestor: RuleNo\nLifecycleConfiguration\nContainer for lifecycle rules.", "You can add as \nmany as 1000 rules.\nType: Container\nChildren: Rule\nAncestor: NoneYes\nGET Bucket lifecycle (Deprecated) API Version 2006-03-01 3001Amazon Simple Storage Service API Reference\nName Description Required\nExpiredObjectDelet \neMarkerOn a versioned bucket (versioning-enabled or \nversioning-suspended bucket), this  element \nindicates whether Amazon S3 will delete any \nexpired  object delete markers in the bucket. \nFor an example, go to   Example 8: Specify \nExpiration Action to Remove Expired  Object \nDelete Markers in the   Amazon Simple Storage \nService User Guide.\nType: String\nValid values: true | false (the value false is \nallowed but it is no-op, Amazon S3  doesn't \ntake action if the value is false)\nAncestor: ExpirationYes, if\nDate  and\nDays are \nabsent\nNoncurrentDays\nSpeci\ufb01es the number of days that an object \nis noncurrent before Amazon S3 can perform \nthe  associated action. For information about \ncalculating noncurrent  days, see Lifecycle \nRules Based on the Number of Days in the  \n  Amazon Simple Storage Service User Guide.\nType: Nonnegative Integer when used with\nNoncurrentVersionTransition ,  \n Positive Integer when used with   Noncurren \ntVersionExpiration\nAncestor: NoncurrentVersionE \nxpiration  or   NoncurrentVersionT \nransitionYes, only \nif the \nancestor is \npresent\nGET Bucket lifecycle (Deprecated) API Version 2006-03-01 3002Amazon Simple Storage Service API Reference\nName Description Required\nNoncurrentVersionE \nxpirationSpeci\ufb01es when noncurrent object versions \nexpire.", "Upon expiration, Amazon S3  perman \nently deletes the noncurrent object versions.\nSet this lifecycle con\ufb01guration action on a \nbucket that has versioning enabled (or  suspe \nnded) to request that Amazon S3 delete \nnoncurrent object  versions at a speci\ufb01c \nperiod in the object's lifetime.\nType: Container\nChildren: NoncurrentDays\nAncestor: RuleYes, if \nno other \naction is \npresent in \nthe Rule\nNoncurrentVersionT \nransitionContainer for the transition rule that \ndescribes when noncurrent objects transitio \nn to  the STANDARD_IA , ONEZONE_IA , or \nthe  GLACIER storage class.\nIf your bucket is versioning-enabled (or \nversioning is suspended), you can set this  \n action to request Amazon S3 to transition \nnoncurrent object  versions to the GLACIER \nstorage class at a speci\ufb01c period in  the \nobject's lifetime.\nType: Container\nChildren: NoncurrentDays and StorageClass\nAncestor: RuleYes, if \nno other \naction is \npresent in \nthe Rule\nGET Bucket lifecycle (Deprecated) API Version 2006-03-01 3003Amazon Simple Storage Service API Reference\nName Description Required\nPrefix\nObject key pre\ufb01x identifying one or more \nobjects to which the rule applies.\nType: String\nAncestor: RuleYes\nRule\nContainer for a lifecycle rule.\nType: Container\nAncestor: LifecycleCon\ufb01gurationYes\nStatus\nIf Enabled, Amazon S3 executes the rule as \nscheduled. If Disabled, Amazon S3 ignores the \nrule.\nType: String\nAncestor: Rule\nValid values: Enabled or DisabledYes\nStorageClass\nSpeci\ufb01es the Amazon S3 storage class to \nwhich you want to transition the  object.\nType: String\nAncestor: Transition and  NoncurrentVers \nionTransition\nValid values: STANDARD_IA  | ONEZONE_IA\n|  GLACIERYes\nGET Bucket lifecycle (Deprecated) API Version 2006-03-01 3004Amazon Simple Storage Service API Reference\nName Description Required\nTransition\nThis action speci\ufb01es a period in the objects' \nlifetime when Amazon S3 should transition  \n them to the STANDARD_IA , ONEZONE_IA ,  \n or GLACIER storage class. When this action  \nis in e\ufb00ect, what Amazon S3 does depends on \nwhether the bucket is  versioning-enabled.\n\u2022\nIf versioning has never been enabled on \nthe bucket, Amazon S3 transitions the only \ncopy  of the object to the speci\ufb01ed storage \nclass.\n\u2022\nWhen your bucket is versioning-enabled \n(or versioning is suspended), Amazon S3  \n transitions only the current versions of the \nobjects   identi\ufb01ed in the rule.\nNote\nA versioning-enabled or versioning-\nsuspended bucket can contain many \nversions of  an object.", "This action \nhas no e\ufb00ect on the  noncurrent \nobject versions.", "To transition \nnoncurrent  objects, you must \nuse the   NoncurrentVersionT \nransition   action.\nType: ContainerYes, if \nno other \naction is \npresent in \nthe Rule\nGET Bucket lifecycle (Deprecated) API Version 2006-03-01 3005Amazon Simple Storage Service API Reference\nName Description Required\nChildren: Days or Date, and StorageClass\nAncestor: Rule\nSpecial Errors\nError Code Description HTTP \nStatus CodeSOAP Fault \nCode Pre\ufb01x\nNoSuchLifecycleCon \nfigurationThe lifecycle con\ufb01guration does \nnot exist.404 Not \nFoundClient\nFor general information about Amazon S3 errors and a list of error codes, see Error responses.\nExamples\nExample 1: Retrieve a Lifecycle Subresource\nThis example is a GET request to retrieve the lifecycle  subresource from the speci\ufb01ed bucket, \nand an example response with the returned lifecycle con\ufb01guration.\nSample Request\nGET /?lifecycle HTTP/1.1\nHost: examplebucket.s3.amazonaws.com\nx-amz-date: Thu, 15 Nov 2012 00:17:21 GMT\nAuthorization: signatureValue\nSample Response\nHTTP/1.1 200 OK\nx-amz-id-2: ITnGT1y4RyTmXa3rPi4hklTXouTf0hccUjo0iCPjz6FnfIutBj3M7fPGlWO2SEWp\nx-amz-request-id: 51991C342C575321\nDate: Thu, 15 Nov 2012 00:17:23 GMT\nServer: AmazonS3\nContent-Length: 358\nGET Bucket lifecycle (Deprecated) API Version 2006-03-01 3006Amazon Simple Storage Service API Reference\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<LifecycleConfiguration xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"> \n    <Rule> \n        <ID>Archive and then delete rule</ID> \n        <Prefix>projectdocs/</Prefix> \n        <Status>Enabled</Status> \n       <Transition> \n           <Days>30</Days> \n           <StorageClass>STANDARD_IA</StorageClass> \n        </Transition> \n        <Transition> \n           <Days>365</Days> \n           <StorageClass>GLACIER</StorageClass> \n        </Transition> \n        <Expiration> \n           <Days>3650</Days> \n        </Expiration> \n    </Rule>\n</LifecycleConfiguration>\nRelated Resources\n\u2022PutBucketLifecycleCon\ufb01guration\n\u2022DeleteBucketLifecycle\nGET Bucket lifecycle (Deprecated) API Version 2006-03-01 3007"]