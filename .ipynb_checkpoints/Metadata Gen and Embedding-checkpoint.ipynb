{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZVU9JMPnMV5nvRUEQFQbpxao",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 22841,
     "status": "ok",
     "timestamp": 1730254518759,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 300
    },
    "id": "ZVU9JMPnMV5nvRUEQFQbpxao",
    "outputId": "39de6025-70a4-4702-f29e-3c58ab8cd3b7",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.3.5-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.35)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.10)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
      "Collecting langchain-core<0.4.0,>=0.3.13 (from langchain)\n",
      "  Downloading langchain_core-0.3.13-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.3.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.1.137-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.9.2)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.15.2)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.4.0,>=0.3.13->langchain)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.13->langchain) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.13->langchain) (4.12.2)\n",
      "Collecting httpx<1,>=0.23.0 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Downloading orjson-3.10.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.6/50.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (3.7.1)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.13->langchain)\n",
      "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain) (0.2.0)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.2.2)\n",
      "Downloading langchain-0.3.5-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-0.3.13-py3-none-any.whl (408 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m408.0/408.0 kB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_text_splitters-0.3.1-py3-none-any.whl (25 kB)\n",
      "Downloading langsmith-0.1.137-py3-none-any.whl (296 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.9/296.9 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading orjson-3.10.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.5/144.5 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: orjson, jsonpointer, h11, requests-toolbelt, jsonpatch, httpcore, httpx, langsmith, langchain-core, langchain-text-splitters, langchain\n",
      "Successfully installed h11-0.14.0 httpcore-1.0.6 httpx-0.27.2 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.5 langchain-core-0.3.13 langchain-text-splitters-0.3.1 langsmith-0.1.137 orjson-3.10.10 requests-toolbelt-1.0.0\n",
      "Collecting langchain_community\n",
      "  Downloading langchain_community-0.3.3-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.35)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.10.10)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: langchain<0.4.0,>=0.3.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.3.5)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.12 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.3.13)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.1.137)\n",
      "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.26.4)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
      "  Downloading pydantic_settings-2.6.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (9.0.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.15.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading marshmallow-3.23.0-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.4->langchain_community) (0.3.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.4->langchain_community) (2.9.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.12->langchain_community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.12->langchain_community) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.12->langchain_community) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (3.10.10)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (1.0.0)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.1)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (3.7.1)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.0.6)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.12->langchain_community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.4->langchain_community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.4->langchain_community) (2.23.4)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain_community) (0.2.0)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.2.2)\n",
      "Downloading langchain_community-0.3.3-py3-none-any.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading pydantic_settings-2.6.0-py3-none-any.whl (28 kB)\n",
      "Downloading marshmallow-3.23.0-py3-none-any.whl (49 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, typing-inspect, pydantic-settings, dataclasses-json, langchain_community\n",
      "Successfully installed dataclasses-json-0.6.7 langchain_community-0.3.3 marshmallow-3.23.0 mypy-extensions-1.0.0 pydantic-settings-2.6.0 python-dotenv-1.0.1 typing-inspect-0.9.0\n",
      "Collecting openai\n",
      "  Downloading openai-1.52.2-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading jiter-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
      "Downloading openai-1.52.2-py3-none-any.whl (386 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.9/386.9 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jiter-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.2/325.2 kB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: jiter, openai\n",
      "Successfully installed jiter-0.6.1 openai-1.52.2\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain\n",
    "!pip install langchain_community\n",
    "!pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vZomeLEnHf_k",
   "metadata": {
    "id": "vZomeLEnHf_k"
   },
   "source": [
    "Initialling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "OipxUFYSCOq_",
   "metadata": {
    "id": "OipxUFYSCOq_"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prana\\anaconda3\\Lib\\site-packages\\langchain_community\\llms\\__init__.py:424: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  from langchain_community.llms.openai import AzureOpenAI\n",
      "C:\\Users\\prana\\anaconda3\\Lib\\site-packages\\pydantic\\_internal\\_config.py:341: UserWarning: Valid config keys have changed in V2:\n",
      "* 'allow_population_by_field_name' has been renamed to 'populate_by_name'\n",
      "  warnings.warn(message, UserWarning)\n",
      "C:\\Users\\prana\\anaconda3\\Lib\\site-packages\\pydantic\\_internal\\_config.py:341: UserWarning: Valid config keys have changed in V2:\n",
      "* 'allow_population_by_field_name' has been renamed to 'populate_by_name'\n",
      "  warnings.warn(message, UserWarning)\n",
      "C:\\Users\\prana\\anaconda3\\Lib\\site-packages\\pydantic\\_internal\\_config.py:341: UserWarning: Valid config keys have changed in V2:\n",
      "* 'allow_population_by_field_name' has been renamed to 'populate_by_name'\n",
      "  warnings.warn(message, UserWarning)\n",
      "C:\\Users\\prana\\anaconda3\\Lib\\site-packages\\pydantic\\_internal\\_config.py:341: UserWarning: Valid config keys have changed in V2:\n",
      "* 'allow_population_by_field_name' has been renamed to 'populate_by_name'\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "#This basic example demostrate the LLM response and ChatModel Response\n",
    "\n",
    "from langchain.llms import AzureOpenAI\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "#app.py\n",
    "\n",
    "from langchain import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mFOgmFKEHFf2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1730254521331,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 300
    },
    "id": "mFOgmFKEHFf2",
    "outputId": "84565bf7-0c6d-48ce-9b81-d9a7436c6e7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None Azure https://testopenaisaturday.openai.azure.com/ 2023-10-01-preview\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables from the .env file\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "# Retrieve Azure OpenAI specific configuration from environment variables\n",
    "OPENAI_API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "OPENAI_API_TYPE = \"Azure\"\n",
    "OPENAI_API_BASE = \"https://testopenaisaturday.openai.azure.com/\"\n",
    "OPENAI_API_VERSION = \"2023-10-01-preview\"\n",
    "\n",
    "print(OPENAI_API_KEY, OPENAI_API_TYPE,OPENAI_API_BASE, OPENAI_API_VERSION )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PeaD9RddHMkQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 550
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 137,
     "status": "error",
     "timestamp": 1730184601825,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 300
    },
    "id": "PeaD9RddHMkQ",
    "outputId": "0cdc0746-5f20-4f3a-a014-82da70438aff"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-43e95b94f39c>:8: LangChainDeprecationWarning: The class `AzureChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import AzureChatOpenAI``.\n",
      "  llm = AzureChatOpenAI(\n"
     ]
    },
    {
     "ename": "OpenAIError",
     "evalue": "Missing credentials. Please pass one of `api_key`, `azure_ad_token`, `azure_ad_token_provider`, or the `AZURE_OPENAI_API_KEY` or `AZURE_OPENAI_AD_TOKEN` environment variables.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-43e95b94f39c>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m llm = AzureChatOpenAI(\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mopenai_api_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mOPENAI_API_KEY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mazure_endpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mOPENAI_API_BASE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\u001b[0m in \u001b[0;36mwarn_if_direct_instance\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                         \u001b[0mwarned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                         \u001b[0memit_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 obj.__init__ = functools.wraps(obj.__init__)(  # type: ignore[misc]\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\u001b[0m in \u001b[0;36mwarn_if_direct_instance\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                         \u001b[0mwarned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                         \u001b[0memit_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 obj.__init__ = functools.wraps(obj.__init__)(  # type: ignore[misc]\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/load/serializable.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;34m\"\"\"\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_decorators_v1.py\u001b[0m in \u001b[0;36m_wrapper1\u001b[0;34m(values, _)\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;31m# mode='before' for pydantic-core\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_wrapper1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRootValidatorValues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcore_schema\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mValidationInfo\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mRootValidatorValues\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mvalidator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapper1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/utils/pydantic.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(cls, values)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0;31m# Call the decorated function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_community/chat_models/azure_openai.py\u001b[0m in \u001b[0;36mvalidate_environment\u001b[0;34m(cls, values)\u001b[0m\n\u001b[1;32m    208\u001b[0m                 \u001b[0;34m\"http_client\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"http_client\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m             }\n\u001b[0;32m--> 210\u001b[0;31m             \u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"client\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopenai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAzureOpenAI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mclient_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompletions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m             values[\"async_client\"] = openai.AsyncAzureOpenAI(\n\u001b[1;32m    212\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0mclient_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/lib/azure.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, api_version, azure_endpoint, azure_deployment, api_key, azure_ad_token, azure_ad_token_provider, organization, project, base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mapi_key\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mazure_ad_token\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mazure_ad_token_provider\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m             raise OpenAIError(\n\u001b[0m\u001b[1;32m    170\u001b[0m                 \u001b[0;34m\"Missing credentials. Please pass one of `api_key`, `azure_ad_token`, `azure_ad_token_provider`, or the `AZURE_OPENAI_API_KEY` or `AZURE_OPENAI_AD_TOKEN` environment variables.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             )\n",
      "\u001b[0;31mOpenAIError\u001b[0m: Missing credentials. Please pass one of `api_key`, `azure_ad_token`, `azure_ad_token_provider`, or the `AZURE_OPENAI_API_KEY` or `AZURE_OPENAI_AD_TOKEN` environment variables."
     ]
    }
   ],
   "source": [
    "# Set the OpenAI library configuration using the retrieved environment variables\n",
    "openai.api_type = \"Azure\"\n",
    "openai.api_base = \"https://testopenaisaturday.openai.azure.com/\"\n",
    "openai.api_version = \"2023-10-01-preview\"\n",
    "openai.api_key = OPENAI_API_KEY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "gc6xZkWVHS1h",
   "metadata": {
    "id": "gc6xZkWVHS1h"
   },
   "outputs": [],
   "source": [
    "#app.py\n",
    "\n",
    "from langchain import PromptTemplate\n",
    "import openai\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from dotenv import find_dotenv, load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cW8n0fUDCiHj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13001,
     "status": "ok",
     "timestamp": 1730254534330,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 300
    },
    "id": "cW8n0fUDCiHj",
    "outputId": "cec6c84f-a857-4a08-8c3c-fbc44dc7a090"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting unstructured\n",
      "  Downloading unstructured-0.16.3-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from unstructured) (5.2.0)\n",
      "Collecting filetype (from unstructured)\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting python-magic (from unstructured)\n",
      "  Downloading python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.9.4)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from unstructured) (3.8.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from unstructured) (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.12.3)\n",
      "Collecting emoji (from unstructured)\n",
      "  Downloading emoji-2.14.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.6.7)\n",
      "Collecting python-iso639 (from unstructured)\n",
      "  Downloading python_iso639-2024.10.22-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting langdetect (from unstructured)\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.26.4)\n",
      "Collecting rapidfuzz (from unstructured)\n",
      "  Downloading rapidfuzz-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting backoff (from unstructured)\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.12.2)\n",
      "Collecting unstructured-client (from unstructured)\n",
      "  Downloading unstructured_client-0.26.2-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.16.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.66.5)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from unstructured) (5.9.5)\n",
      "Collecting python-oxmsg (from unstructured)\n",
      "  Downloading python_oxmsg-0.0.1-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: html5lib in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->unstructured) (2.6)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->unstructured) (3.23.0)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->unstructured) (0.9.0)\n",
      "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.10/dist-packages (from html5lib->unstructured) (1.16.0)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from html5lib->unstructured) (0.5.1)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (8.1.7)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (2024.9.11)\n",
      "Collecting olefile (from python-oxmsg->unstructured)\n",
      "  Downloading olefile-0.47-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured) (2024.8.30)\n",
      "Requirement already satisfied: cryptography>=3.1 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured) (43.0.1)\n",
      "Requirement already satisfied: eval-type-backport<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured) (0.2.0)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured) (0.27.2)\n",
      "Collecting jsonpath-python<2.0.0,>=1.0.6 (from unstructured-client->unstructured)\n",
      "  Downloading jsonpath_python-1.0.6-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: nest-asyncio>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured) (1.6.0)\n",
      "Requirement already satisfied: pydantic<2.10.0,>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured) (2.9.2)\n",
      "Collecting pypdf>=4.0 (from unstructured-client->unstructured)\n",
      "  Downloading pypdf-5.1.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: python-dateutil==2.8.2 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured) (2.8.2)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured) (1.0.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=3.1->unstructured-client->unstructured) (1.17.1)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->unstructured-client->unstructured) (3.7.1)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->unstructured-client->unstructured) (1.0.6)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->unstructured-client->unstructured) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.27.0->unstructured-client->unstructured) (0.14.0)\n",
      "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->unstructured) (24.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2.10.0,>=2.9.0->unstructured-client->unstructured) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<2.10.0,>=2.9.0->unstructured-client->unstructured) (2.23.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->unstructured) (1.0.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=3.1->unstructured-client->unstructured) (2.22)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.27.0->unstructured-client->unstructured) (1.2.2)\n",
      "Downloading unstructured-0.16.3-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading emoji-2.14.0-py3-none-any.whl (586 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m586.9/586.9 kB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Downloading python_iso639-2024.10.22-py3-none-any.whl (274 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.9/274.9 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
      "Downloading python_oxmsg-0.0.1-py3-none-any.whl (31 kB)\n",
      "Downloading rapidfuzz-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m74.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading unstructured_client-0.26.2-py3-none-any.whl (59 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jsonpath_python-1.0.6-py3-none-any.whl (7.6 kB)\n",
      "Downloading pypdf-5.1.0-py3-none-any.whl (297 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading olefile-0.47-py2.py3-none-any.whl (114 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.6/114.6 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: langdetect\n",
      "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993225 sha256=ef130ba63cf9fa11a84daf8e3f8f0df71bd228c2adc9eeccef19a8f58e291e63\n",
      "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
      "Successfully built langdetect\n",
      "Installing collected packages: filetype, rapidfuzz, python-magic, python-iso639, pypdf, olefile, langdetect, jsonpath-python, emoji, backoff, python-oxmsg, unstructured-client, unstructured\n",
      "Successfully installed backoff-2.2.1 emoji-2.14.0 filetype-1.2.0 jsonpath-python-1.0.6 langdetect-1.0.9 olefile-0.47 pypdf-5.1.0 python-iso639-2024.10.22 python-magic-0.4.27 python-oxmsg-0.0.1 rapidfuzz-3.10.1 unstructured-0.16.3 unstructured-client-0.26.2\n"
     ]
    }
   ],
   "source": [
    "pip install unstructured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "OyMhfh83HXHr",
   "metadata": {
    "id": "OyMhfh83HXHr"
   },
   "outputs": [],
   "source": [
    "from test_unstructured.unit_utils import assert_round_trips_through_JSON, example_doc_path\n",
    "from unstructured.chunking.title import chunk_by_title\n",
    "from unstructured.documents.elements import ElementType\n",
    "\n",
    "#!pip install unstructured_inference\n",
    "#!pip install -U langchain-unstructured"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eG7WO9Y4MacD",
   "metadata": {
    "id": "eG7WO9Y4MacD"
   },
   "source": [
    "# PINECONE Initialising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vA4mNn9dMYsU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7417,
     "status": "ok",
     "timestamp": 1730254543356,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 300
    },
    "id": "vA4mNn9dMYsU",
    "outputId": "7eb18239-c9cf-47ad-e08a-e0fcd5a65e49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.5/1.2 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/244.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.8/244.8 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/85.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "%pip install -qU langchain-pinecone pinecone-notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "n2yY286kNZIe",
   "metadata": {
    "id": "n2yY286kNZIe"
   },
   "outputs": [],
   "source": [
    "# PINECONE API.     1203aeba-36cc-4ede-9dc6-1f01153fbde8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1X8uEFfoMZBm",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 39189,
     "status": "ok",
     "timestamp": 1730254582542,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 300
    },
    "id": "1X8uEFfoMZBm",
    "outputId": "87b8580c-4c2b-4f44-8429-954feee682bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your Pinecone API key: ········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "import time\n",
    "\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "if not os.getenv(\"PINECONE_API_KEY\"):\n",
    "    os.environ[\"PINECONE_API_KEY\"] = getpass.getpass(\"Enter your Pinecone API key: \")\n",
    "\n",
    "pinecone_api_key = os.environ.get(\"PINECONE_API_KEY\")\n",
    "\n",
    "pc = Pinecone(api_key=pinecone_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "BHruwwwlMZOq",
   "metadata": {
    "id": "BHruwwwlMZOq"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "index_name = \"langchain-test-index\"  # change if desired\n",
    "\n",
    "existing_indexes = [index_info[\"name\"] for index_info in pc.list_indexes()]\n",
    "\n",
    "if index_name not in existing_indexes:\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=3072,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n",
    "    )\n",
    "    while not pc.describe_index(index_name).status[\"ready\"]:\n",
    "        time.sleep(1)\n",
    "\n",
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b-p9xGW8MZX5",
   "metadata": {
    "id": "b-p9xGW8MZX5"
   },
   "outputs": [],
   "source": [
    "# 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"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "IZFFakKDN_Tj",
   "metadata": {
    "id": "IZFFakKDN_Tj"
   },
   "source": [
    "# Open AI Initialise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "JDYC4vzrDrd_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4290,
     "status": "ok",
     "timestamp": 1730254670457,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 300
    },
    "id": "JDYC4vzrDrd_",
    "outputId": "1e2fb601-13f9-4c6d-94b6-3f7fc35d7303",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_openai\n",
      "  Downloading langchain_openai-0.2.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.13 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (0.3.13)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.52.0 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (1.52.2)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain_openai)\n",
      "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.13->langchain_openai) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.13->langchain_openai) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.13->langchain_openai) (0.1.137)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.13->langchain_openai) (24.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.13->langchain_openai) (2.9.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.13->langchain_openai) (9.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.13->langchain_openai) (4.12.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.52.0->langchain_openai) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.52.0->langchain_openai) (1.7.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.52.0->langchain_openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.52.0->langchain_openai) (0.6.1)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.52.0->langchain_openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.52.0->langchain_openai) (4.66.5)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.9.11)\n",
      "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2.32.3)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.52.0->langchain_openai) (3.10)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.52.0->langchain_openai) (1.2.2)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.52.0->langchain_openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.52.0->langchain_openai) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.52.0->langchain_openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.13->langchain_openai) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.13->langchain_openai) (3.10.10)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.13->langchain_openai) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.13->langchain_openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.13->langchain_openai) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.2.3)\n",
      "Downloading langchain_openai-0.2.4-py3-none-any.whl (50 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tiktoken, langchain_openai\n",
      "Successfully installed langchain_openai-0.2.4 tiktoken-0.8.0\n"
     ]
    }
   ],
   "source": [
    "pip install langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "tRbW-yAJN-kN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3632,
     "status": "ok",
     "timestamp": 1730254674083,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 300
    },
    "id": "tRbW-yAJN-kN",
    "outputId": "b32d3641-c882-48f0-ff4f-af54186619b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "BM1QRlW6N-m8",
   "metadata": {
    "id": "BM1QRlW6N-m8"
   },
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "vector_store = PineconeVectorStore(index=index, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eWWeJMZMWDcr",
   "metadata": {
    "id": "eWWeJMZMWDcr"
   },
   "source": [
    "## Vertex AI Embedding Initialising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d24d91a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gcloud\n",
      "  Downloading gcloud-0.18.3.tar.gz (454 kB)\n",
      "     ---------------------------------------- 0.0/454.4 kB ? eta -:--:--\n",
      "     --------------------------- ---------- 327.7/454.4 kB 6.8 MB/s eta 0:00:01\n",
      "     -------------------------------------- 454.4/454.4 kB 7.0 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting httplib2>=0.9.1 (from gcloud)\n",
      "  Obtaining dependency information for httplib2>=0.9.1 from https://files.pythonhosted.org/packages/a8/6c/d2fbdaaa5959339d53ba38e94c123e4e84b8fbc4b84beb0e70d7c1608486/httplib2-0.22.0-py3-none-any.whl.metadata\n",
      "  Downloading httplib2-0.22.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: googleapis-common-protos in c:\\users\\prana\\anaconda3\\lib\\site-packages (from gcloud) (1.65.0)\n",
      "Collecting oauth2client>=2.0.1 (from gcloud)\n",
      "  Obtaining dependency information for oauth2client>=2.0.1 from https://files.pythonhosted.org/packages/95/a9/4f25a14d23f0786b64875b91784607c2277eff25d48f915e39ff0cff505a/oauth2client-4.1.3-py2.py3-none-any.whl.metadata\n",
      "  Downloading oauth2client-4.1.3-py2.py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: protobuf!=3.0.0.b2.post1,>=3.0.0b2 in c:\\users\\prana\\anaconda3\\lib\\site-packages (from gcloud) (4.25.5)\n",
      "Requirement already satisfied: six in c:\\users\\prana\\anaconda3\\lib\\site-packages (from gcloud) (1.16.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\prana\\anaconda3\\lib\\site-packages (from httplib2>=0.9.1->gcloud) (3.0.9)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in c:\\users\\prana\\anaconda3\\lib\\site-packages (from oauth2client>=2.0.1->gcloud) (0.4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in c:\\users\\prana\\anaconda3\\lib\\site-packages (from oauth2client>=2.0.1->gcloud) (0.2.8)\n",
      "Requirement already satisfied: rsa>=3.1.4 in c:\\users\\prana\\anaconda3\\lib\\site-packages (from oauth2client>=2.0.1->gcloud) (4.9)\n",
      "Downloading httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "   ---------------------------------------- 0.0/96.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 96.9/96.9 kB ? eta 0:00:00\n",
      "Downloading oauth2client-4.1.3-py2.py3-none-any.whl (98 kB)\n",
      "   ---------------------------------------- 0.0/98.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 98.2/98.2 kB ? eta 0:00:00\n",
      "Building wheels for collected packages: gcloud\n",
      "  Building wheel for gcloud (setup.py): started\n",
      "  Building wheel for gcloud (setup.py): finished with status 'done'\n",
      "  Created wheel for gcloud: filename=gcloud-0.18.3-py3-none-any.whl size=602982 sha256=ea481e3da10d402aeda26ce2bca99e7cee40f0defa516308b3ddaf3312db2ab3\n",
      "  Stored in directory: c:\\users\\prana\\appdata\\local\\pip\\cache\\wheels\\3c\\e8\\d1\\cb82a63f69083ea485de71d14248b8d145f1af46a41578be9c\n",
      "Successfully built gcloud\n",
      "Installing collected packages: httplib2, oauth2client, gcloud\n",
      "Successfully installed gcloud-0.18.3 httplib2-0.22.0 oauth2client-4.1.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f3ea960",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'gcloud' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!gcloud auth login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372dfe24",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud config set project YOUR_PROJECT_ID\n",
    "!gcloud config set compute/region YOUR_REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "K0zm0DJOWNCl",
   "metadata": {
    "id": "K0zm0DJOWNCl",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "GoogleAuthError",
     "evalue": "\nUnable to authenticate your request.\nDepending on your runtime environment, you can complete authentication by:\n- if in local JupyterLab instance: `!gcloud auth login` \n- if in Colab:\n    -`from google.colab import auth`\n    -`auth.authenticate_user()`\n- if in service account or other: please follow guidance in https://cloud.google.com/docs/authentication",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDefaultCredentialsError\u001b[0m                   Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\vertexai\\_model_garden\\_model_garden_models.py:289\u001b[0m, in \u001b[0;36m_ModelGardenModel.from_pretrained\u001b[1;34m(cls, model_name)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _from_pretrained(interface_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcls\u001b[39m, model_name\u001b[38;5;241m=\u001b[39mmodel_name)\n\u001b[0;32m    290\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m auth_exceptions\u001b[38;5;241m.\u001b[39mGoogleAuthError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\vertexai\\_model_garden\\_model_garden_models.py:206\u001b[0m, in \u001b[0;36m_from_pretrained\u001b[1;34m(interface_class, model_name, publisher_model, tuned_vertex_model)\u001b[0m\n\u001b[0;32m    202\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    203\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClass \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minterface_class\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a correct model interface class since it does not have an instance schema URI.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    204\u001b[0m         )\n\u001b[1;32m--> 206\u001b[0m     model_info \u001b[38;5;241m=\u001b[39m _get_model_info(\n\u001b[0;32m    207\u001b[0m         model_id\u001b[38;5;241m=\u001b[39mmodel_name,\n\u001b[0;32m    208\u001b[0m         schema_to_class_map\u001b[38;5;241m=\u001b[39m{interface_class\u001b[38;5;241m.\u001b[39m_INSTANCE_SCHEMA_URI: interface_class},\n\u001b[0;32m    209\u001b[0m     )\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\vertexai\\_model_garden\\_model_garden_models.py:122\u001b[0m, in \u001b[0;36m_get_model_info\u001b[1;34m(model_id, schema_to_class_map, interface_class, publisher_model_res, tuned_vertex_model)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m publisher_model_res:\n\u001b[0;32m    121\u001b[0m     publisher_model_res \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 122\u001b[0m         _publisher_models\u001b[38;5;241m.\u001b[39m_PublisherModel(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    123\u001b[0m             resource_name\u001b[38;5;241m=\u001b[39mmodel_id\n\u001b[0;32m    124\u001b[0m         )\u001b[38;5;241m.\u001b[39m_gca_resource\n\u001b[0;32m    125\u001b[0m     )\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m publisher_model_res\u001b[38;5;241m.\u001b[39mname\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpublishers/google/models/\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\google\\cloud\\aiplatform\\_publisher_models.py:63\u001b[0m, in \u001b[0;36m_PublisherModel.__init__\u001b[1;34m(self, resource_name, project, location, credentials)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Retrieves an existing PublisherModel resource given a resource name or model garden id.\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \n\u001b[0;32m     46\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;124;03m        Overrides credentials set in aiplatform.init.\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(project\u001b[38;5;241m=\u001b[39mproject, location\u001b[38;5;241m=\u001b[39mlocation, credentials\u001b[38;5;241m=\u001b[39mcredentials)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_resource_name(resource_name):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\google\\cloud\\aiplatform\\base.py:558\u001b[0m, in \u001b[0;36mVertexAiResourceNoun.__init__\u001b[1;34m(self, project, location, credentials, resource_name)\u001b[0m\n\u001b[0;32m    557\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlocation \u001b[38;5;241m=\u001b[39m location \u001b[38;5;129;01mor\u001b[39;00m initializer\u001b[38;5;241m.\u001b[39mglobal_config\u001b[38;5;241m.\u001b[39mlocation\n\u001b[1;32m--> 558\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcredentials \u001b[38;5;241m=\u001b[39m credentials \u001b[38;5;129;01mor\u001b[39;00m initializer\u001b[38;5;241m.\u001b[39mglobal_config\u001b[38;5;241m.\u001b[39mcredentials\n\u001b[0;32m    560\u001b[0m appended_user_agent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\google\\cloud\\aiplatform\\initializer.py:392\u001b[0m, in \u001b[0;36m_Config.credentials\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    391\u001b[0m logger\u001b[38;5;241m.\u001b[39maddFilter(logging_warning_filter)\n\u001b[1;32m--> 392\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_project_as_env_var_or_google_auth_default()\n\u001b[0;32m    393\u001b[0m credentials \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_credentials\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\google\\cloud\\aiplatform\\initializer.py:117\u001b[0m, in \u001b[0;36m_Config._set_project_as_env_var_or_google_auth_default\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_credentials \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_api_key:\n\u001b[1;32m--> 117\u001b[0m     credentials, _ \u001b[38;5;241m=\u001b[39m google\u001b[38;5;241m.\u001b[39mauth\u001b[38;5;241m.\u001b[39mdefault()\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_credentials \u001b[38;5;241m=\u001b[39m credentials\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\google\\auth\\_default.py:693\u001b[0m, in \u001b[0;36mdefault\u001b[1;34m(scopes, request, quota_project_id, default_scopes)\u001b[0m\n\u001b[0;32m    691\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m credentials, effective_project_id\n\u001b[1;32m--> 693\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mDefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)\n",
      "\u001b[1;31mDefaultCredentialsError\u001b[0m: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mGoogleAuthError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 10\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvertexai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlanguage_models\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TextEmbeddingModel\n\u001b[0;32m      8\u001b[0m vertexai\u001b[38;5;241m.\u001b[39minit(project\u001b[38;5;241m=\u001b[39mPROJECT_ID, location\u001b[38;5;241m=\u001b[39mREGION)\n\u001b[1;32m---> 10\u001b[0m embeddingsmodel \u001b[38;5;241m=\u001b[39m TextEmbeddingModel\u001b[38;5;241m.\u001b[39mfrom_pretrained(MODEL_ID)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\vertexai\\_model_garden\\_model_garden_models.py:291\u001b[0m, in \u001b[0;36m_ModelGardenModel.from_pretrained\u001b[1;34m(cls, model_name)\u001b[0m\n\u001b[0;32m    289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _from_pretrained(interface_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcls\u001b[39m, model_name\u001b[38;5;241m=\u001b[39mmodel_name)\n\u001b[0;32m    290\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m auth_exceptions\u001b[38;5;241m.\u001b[39mGoogleAuthError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 291\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m auth_exceptions\u001b[38;5;241m.\u001b[39mGoogleAuthError(credential_exception_str) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[1;31mGoogleAuthError\u001b[0m: \nUnable to authenticate your request.\nDepending on your runtime environment, you can complete authentication by:\n- if in local JupyterLab instance: `!gcloud auth login` \n- if in Colab:\n    -`from google.colab import auth`\n    -`auth.authenticate_user()`\n- if in service account or other: please follow guidance in https://cloud.google.com/docs/authentication"
     ]
    }
   ],
   "source": [
    "PROJECT_ID = \"ids-560-project-group-1-bosch\"\n",
    "REGION = \"us-central1\"\n",
    "MODEL_ID = \"text-embedding-004\"\n",
    "\n",
    "import vertexai\n",
    "from vertexai.language_models import TextEmbeddingModel\n",
    "\n",
    "vertexai.init(project=PROJECT_ID, location=REGION)\n",
    "\n",
    "embeddingsmodel = TextEmbeddingModel.from_pretrained(MODEL_ID)\n",
    "#embeddings = model.get_embeddings(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nIds-jgQdkmW",
   "metadata": {
    "id": "nIds-jgQdkmW"
   },
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from vertexai.language_models import TextEmbeddingInput, TextEmbeddingModel\n",
    "\n",
    "\n",
    "def embed_text() -> list[list[float]]:\n",
    "    \"\"\"Embeds texts with a pre-trained, foundational model.\n",
    "\n",
    "    Returns:\n",
    "        A list of lists containing the embedding vectors for each input text\n",
    "    \"\"\"\n",
    "\n",
    "    # A list of texts to be embedded.\n",
    "    texts = [\"banana muffins? \", \"banana bread? banana muffins?\"]\n",
    "    # The dimensionality of the output embeddings.\n",
    "    dimensionality = 256\n",
    "    # The task type for embedding. Check the available tasks in the model's documentation.\n",
    "    task = \"RETRIEVAL_DOCUMENT\"\n",
    "\n",
    "    model = TextEmbeddingModel.from_pretrained(\"text-embedding-004\")\n",
    "    inputs = [TextEmbeddingInput(text, task) for text in texts]\n",
    "    kwargs = dict(output_dimensionality=dimensionality) if dimensionality else {}\n",
    "    embeddings = model.get_embeddings(inputs, **kwargs)\n",
    "\n",
    "    print(embeddings)\n",
    "    # Example response:\n",
    "    # [[0.006135190837085247, -0.01462465338408947, 0.004978656303137541, ...], [0.1234434666, ...]],\n",
    "    return [embedding.values for embedding in embeddings]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78VywpqJdkw8",
   "metadata": {
    "id": "78VywpqJdkw8"
   },
   "outputs": [],
   "source": [
    "from vertexai.language_models import TextEmbeddingInput, TextEmbeddingModel\n",
    "\n",
    "MODEL_NAME = \"text-embedding-preview-0815\"\n",
    "DIMENSIONALITY = 256\n",
    "\n",
    "\n",
    "def embed_text(\n",
    "    texts: list[str] = [\"Retrieve a function that adds two numbers\"],\n",
    "    task: str = \"CODE_RETRIEVAL_QUERY\",\n",
    "    model_name: str = \"text-embedding-preview-0815\",\n",
    "    dimensionality: int | None = 256,\n",
    ") -> list[list[float]]:\n",
    "    \"\"\"Embeds texts with a pre-trained, foundational model.\"\"\"\n",
    "    model = TextEmbeddingModel.from_pretrained(model_name)\n",
    "    inputs = [TextEmbeddingInput(text, task) for text in texts]\n",
    "    kwargs = dict(output_dimensionality=dimensionality) if dimensionality else {}\n",
    "    embeddings = model.get_embeddings(inputs, **kwargs)\n",
    "    # Example response:\n",
    "    # [[0.025890009477734566, -0.05553026497364044, 0.006374752148985863,...],\n",
    "    return [embedding.values for embedding in embeddings]\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Embeds code block with a pre-trained, foundational model.\n",
    "    # Using this function to calculate the embedding for corpus.\n",
    "    texts = [\"Retrieve a function that adds two numbers\"]\n",
    "    task = \"CODE_RETRIEVAL_QUERY\"\n",
    "    code_block_embeddings = embed_text(\n",
    "        texts=texts, task=task, model_name=MODEL_NAME, dimensionality=DIMENSIONALITY\n",
    "    )\n",
    "\n",
    "    # Embeds code retrieval with a pre-trained, foundational model.\n",
    "    # Using this function to calculate the embedding for query.\n",
    "    texts = [\n",
    "        \"def func(a, b): return a + b\",\n",
    "        \"def func(a, b): return a - b\",\n",
    "        \"def func(a, b): return (a ** 2 + b ** 2) ** 0.5\",\n",
    "    ]\n",
    "    task = \"RETRIEVAL_DOCUMENT\"\n",
    "    code_query_embeddings = embed_text(\n",
    "        texts=texts, task=task, model_name=MODEL_NAME, dimensionality=DIMENSIONALITY\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tChW_iDOgRxP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 487,
     "status": "ok",
     "timestamp": 1730254705528,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 300
    },
    "id": "tChW_iDOgRxP",
    "outputId": "f1478a25-811c-4da2-90a8-093dee478384"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding for code block:\n",
      "[[0.025890009477734566, -0.05553026497364044, 0.006374752148985863, 0.0013089277781546116, 0.01370274182409048, 0.03205537050962448, -0.03532978892326355, 0.03360385075211525, 0.006645943503826857, 0.002619285136461258, -0.021650824695825577, -0.030939241871237755, -0.022856291383504868, -0.09032443910837173, -0.029076239094138145, 0.12006844580173492, 0.05262797698378563, 0.010034149512648582, -0.00973017793148756, -0.002025249879807234, 0.04520053416490555, -0.08984410762786865, -0.040977127850055695, 0.01136861089617014, 0.0051070768386125565, -0.056515101343393326, -0.008173064328730106, 0.0407724492251873, 0.0892593264579773, -0.02318394184112549, -0.008366814814507961, 0.02309362031519413, 0.023220965638756752, -0.06416771560907364, 0.055061567574739456, 0.01653783954679966, 0.03559465333819389, 0.009101028554141521, 0.05719698593020439, 0.017261572182178497, -0.040880728513002396, -0.008997108787298203, -0.02235596254467964, 0.004586406052112579, 0.0520702488720417, 0.023592228069901466, 0.01685861498117447, -0.012999968603253365, -0.008227864280343056, 0.02073053829371929, 0.03559311851859093, 0.0027010745834559202, 0.020841002464294434, 0.02513585239648819, -0.017061183229088783, -0.004426642786711454, -0.06668981164693832, 0.040359895676374435, -0.034283094108104706, 0.05404745414853096, -0.04058633744716644, -0.015756115317344666, -0.019756916910409927, -0.010098377242684364, -0.0030901588033884764, -0.0008452699985355139, 0.04407969117164612, 0.058365609496831894, 0.032613810151815414, 0.010351184755563736, -0.05874253809452057, -0.02150016836822033, -0.003971440251916647, -0.08725924044847488, 0.004290857817977667, -0.03020416758954525, -0.0072013502940535545, 0.06196332722902298, 0.040974099189043045, -0.05346108600497246, -0.023906640708446503, -0.051473405212163925, -0.03815013915300369, -0.055053360760211945, 0.06908595561981201, 0.003083788324147463, -0.005252233240753412, -0.044586192816495895, -0.011221681721508503, -0.05998372659087181, -0.015616306103765965, -0.06828759610652924, 0.012842092663049698, 0.00535618094727397, 0.014834139496088028, 0.05627002939581871, -0.025747893378138542, 0.05769338458776474, 0.027772631496191025, 0.017645612359046936, 0.00046192898298613727, 0.05814113840460777, 0.005120496265590191, -0.00830825511366129, -0.011631917208433151, -0.038987260311841965, 0.022663624957203865, -0.02190660685300827, -0.024119334295392036, -0.0004794169799424708, -0.04819531738758087, -0.04822375625371933, 0.007039108779281378, -0.0006081705214455724, 0.022851914167404175, 0.061900313943624496, -0.03154890239238739, -0.0018040005816146731, -0.054030559957027435, -0.08186015486717224, 0.020277660340070724, -0.012199876829981804, 0.07627001404762268, -0.001238916884176433, -0.005160324741154909, 0.048363443464040756, -0.016007592901587486, -0.03344162926077843, -0.028533469885587692, -0.018023056909441948, 0.007262466475367546, -0.02356455661356449, 0.07261952012777328, 0.0003490161616355181, -0.05393115058541298, 0.003595463465899229, -0.002982417354360223, -0.06051087751984596, 0.024291526526212692, 0.012824463658034801, -0.05173615738749504, -0.07068859785795212, 0.01891183666884899, 0.031268160790205, 0.03513995558023453, -0.10550618916749954, 0.08207883685827255, 0.05543290823698044, 0.018357113003730774, -0.02122221514582634, -0.01603015698492527, 0.003028101986274123, 0.0579194612801075, 0.05340250954031944, -0.0644233375787735, 0.013239610940217972, -0.02743968553841114, -0.02062329649925232, -0.02411181665956974, -0.05176232382655144, -0.021456526592373848, 0.026905030012130737, 0.06557317823171616, -0.028176190331578255, 0.055718179792165756, 0.018025793135166168, 0.008646349422633648, -0.02075284533202648, -0.027729451656341553, 0.044855453073978424, -0.007294963579624891, -0.03938988596200943, -0.004290090408176184, -0.07727515697479248, 0.061476316303014755, 0.00469604367390275, -0.05866533890366554, -0.012244053184986115, -0.03633996844291687, -0.07342778891324997, -0.030434589833021164, -0.04191724210977554, 0.008899226784706116, -0.004533492960035801, -0.09805530309677124, -0.014834594912827015, -0.015083825215697289, 0.014014113694429398, -0.03185530751943588, 0.05994720384478569, -0.033950019627809525, -0.05532809719443321, -0.0011806479888036847, 0.03612272068858147, 0.015387299470603466, 0.028627999126911163, 0.03587166965007782, 0.024877086281776428, 0.018965156748890877, 0.01397011335939169, 0.009572556242346764, 0.018022160977125168, 0.0210759025067091, 0.0005474591162055731, -0.035049017518758774, -0.01990942656993866, 0.05432327836751938, 0.014414939098060131, -0.042467597872018814, -0.05103917419910431, 0.03902874514460564, -0.002043703803792596, -0.08463288098573685, -0.009798120707273483, 0.025140896439552307, -0.05611381679773331, 0.01846211962401867, -0.06639706343412399, 0.009928074665367603, 0.02271641604602337, 0.02524239383637905, 0.010849257931113243, 0.0008280543843284249, -0.037573326379060745, 0.07089048624038696, 0.0099549675360322, 0.06678695976734161, -0.027520785108208656, -0.05782070383429527, 0.06062266230583191, -0.0034424138721078634, -0.05647929012775421, -0.007204299792647362, -0.0353616327047348, -0.011188349686563015, -0.0414697527885437, 0.0014211296802386642, -0.013357087969779968, -0.03450492396950722, 0.07110472023487091, -0.025207003578543663, 0.04937770217657089, 0.009384148754179478, 0.009176526218652725, -0.07558882236480713, -0.037660062313079834, -0.0075158593244850636, 0.008000336587429047, -0.02313852496445179, -0.058102142065763474, -0.030760999768972397, -0.02483847178518772, 0.0025307033210992813, -0.027657104656100273, 0.006849504075944424, -0.012147464789450169]]\n",
      "Embedding for document retrieval:\n",
      "[[0.05099866911768913, -0.05238570272922516, -0.004836205393075943, 0.05836086720228195, 0.017988622188568115, 0.0732152909040451, -0.041590262204408646, -0.03346577286720276, 0.0208976361900568, -0.0326516255736351, -0.022190451622009277, 0.0229136161506176, -0.032891396433115005, -0.1067623645067215, -0.024582630023360252, 0.047285374253988266, 0.03801422938704491, -0.032720062881708145, -0.02923574112355709, 0.012860720977187157, -0.009563949890434742, -0.07334037870168686, -0.008132757619023323, 0.020701413974165916, 0.040760237723588943, -0.0445023849606514, -0.011026907712221146, 0.025792352855205536, 0.051008231937885284, 0.02735248953104019, 0.011033623479306698, -0.06080665439367294, 0.028312992304563522, -0.12490130960941315, 0.058825429528951645, 0.006709841080009937, 0.02274148352444172, 0.007612084969878197, -0.017301632091403008, 0.009264023043215275, -0.002885164227336645, 0.0023861085064709187, 0.030238179489970207, 0.023237988352775574, -0.05000380426645279, -0.0027880885172635317, -0.010149062611162663, -0.06150394305586815, -0.001177722355350852, -0.021326646208763123, -0.007738362066447735, 0.0017364457016810775, 0.07581645995378494, 0.041681766510009766, 0.03394586965441704, 0.07155925035476685, -0.04477996006608009, 0.026163896545767784, -0.021623792126774788, 0.01277199573814869, -0.03944166377186775, 0.025129947811365128, -0.03382298722863197, 0.010934781283140182, 0.006497524678707123, 0.036179717630147934, 0.027470896020531654, 0.033597275614738464, 0.011683511547744274, 0.010915176942944527, -0.09064904600381851, -0.04362507909536362, 0.007625928148627281, -0.03867586329579353, 0.017670556902885437, -0.02536863088607788, -0.00826127640902996, 0.04900781810283661, -0.02355724386870861, -0.07286881655454636, -0.04809129238128662, -0.05270598828792572, -0.06445403397083282, -0.03517688065767288, 0.031225183978676796, 0.002289467491209507, -0.03912264108657837, -0.01105501502752304, -0.0585738867521286, -0.010197516530752182, -0.05868256092071533, -0.0012689384166151285, -0.05960054695606232, -0.02101864665746689, 0.02209104597568512, 0.009766205213963985, -0.02986263297498226, -0.0060205464251339436, -0.0876087173819542, -0.049637310206890106, 0.04509679228067398, 0.048873357474803925, 0.05546646937727928, -0.05606212839484215, -0.013111584819853306, -0.03621641919016838, -0.002896436955779791, -0.04272790625691414, -0.036263152956962585, -0.0021897987462580204, -0.01824316568672657, -0.041897159069776535, -0.07329512387514114, -0.04146891087293625, 0.002084903884679079, 0.0007723357994109392, -0.04567980021238327, 0.024221444502472878, -0.08372696489095688, -0.05225857347249985, 0.039749350398778915, 0.0005023815901950002, 0.15746213495731354, 0.003637445392087102, -0.008060994558036327, 0.03532233461737633, -0.018528543412685394, -0.04132954776287079, -0.049930207431316376, -0.07153987884521484, 0.022692833095788956, -0.0280198585242033, 0.035982318222522736, 0.01495831273496151, -0.05494450032711029, -0.0018383163260295987, 0.0011907698353752494, -0.08200079947710037, -0.051633745431900024, 0.06168649345636368, -0.019976384937763214, 0.002888456219807267, -0.012316783890128136, 0.05268547311425209, -0.02558554708957672, -0.02655036747455597, 0.03237975388765335, 0.04965043440461159, 0.029175033792853355, 0.002796315122395754, -0.030710993334650993, -0.03279856964945793, 0.018559053540229797, 0.03961190581321716, 0.007210518233478069, -0.022648146376013756, 0.013658357784152031, -0.02939635142683983, -0.03043941967189312, -0.02781255543231964, -0.053683288395404816, -0.00642362842336297, 0.025669347494840622, -0.02671698108315468, -0.0195896178483963, 0.015092332847416401, 0.028329748660326004, -0.03130532056093216, -0.017571641132235527, 0.029682446271181107, -0.012803363613784313, -0.0029253147076815367, -0.05215083807706833, 0.04619568586349487, 0.06922090798616409, -0.0032624704763293266, -0.03278319537639618, -0.04364607483148575, -0.050618890672922134, -0.08697814494371414, -0.062025465071201324, 0.013184483163058758, 0.04236558824777603, 0.04926136136054993, -0.19781853258609772, -0.00536698941141367, 0.00829740334302187, 0.04139052331447601, -0.023527968674898148, 0.027822420001029968, 0.007435609120875597, -0.018569549545645714, -0.02247052639722824, -0.0033842583652585745, 0.054831311106681824, 0.0731230080127716, 0.01704682782292366, 0.018768759444355965, 0.032123714685440063, -0.007422958500683308, 0.011293863877654076, 0.026336530223488808, 0.08383399248123169, 0.02139207348227501, -0.08409907668828964, -0.030588848516345024, 0.029217584058642387, 0.03857649490237236, -0.02419557049870491, -0.05317920446395874, -0.015025041997432709, -0.03915051370859146, -0.0848800465464592, -0.03634689375758171, -0.01735490746796131, -0.06131100654602051, 0.022530538961291313, -0.07069741189479828, 0.016139483079314232, 0.0787392258644104, 0.026624169200658798, 0.0034928862005472183, -0.11412810534238815, -0.0027237243484705687, 0.006484792102128267, -0.0583706870675087, 0.1069609597325325, 0.024333611130714417, -0.01480591669678688, -0.01321076974272728, -0.027034953236579895, -0.007713512051850557, 0.002915935590863228, -0.041704751551151276, 0.026142176240682602, 0.022164104506373405, -0.0012461007572710514, -0.027523593977093697, -0.03223683685064316, 0.01302824541926384, 0.05062480643391609, -0.002045478904619813, -0.04540567472577095, -0.0477159284055233, -0.012759990990161896, 0.011641774326562881, 0.02781032770872116, -0.025507435202598572, -0.018536953255534172, -0.04939704015851021, -0.05813648924231529, -0.02220601961016655, 0.0228781346231699, -0.028650222346186638, -0.0021335373166948557, -0.0471898578107357], [0.03353843837976456, -0.06042002886533737, 0.0022613429464399815, 0.003550768829882145, -0.012224563397467136, 0.06079135090112686, -0.018583713099360466, -0.007933048531413078, 0.012113560922443867, -0.021253706887364388, 0.004847085103392601, 0.018445981666445732, -0.005404490977525711, -0.014176576398313046, 0.011284184642136097, 0.028436698019504547, 0.03327417001128197, -0.029917659237980843, -0.027370642870664597, 0.06184198707342148, -0.00016273233632091433, -0.039663318544626236, -0.008474639616906643, 0.01805332489311695, -0.03406762331724167, -0.04350052401423454, -0.001198364538140595, 0.03237946331501007, 0.03375983238220215, 0.04291962832212448, -0.012126301415264606, -0.05007074400782585, 0.028110595420002937, -0.08830352872610092, 0.04251493886113167, -0.06116431578993797, 0.025945249944925308, -0.007262931205332279, -0.026364808902144432, 0.025088366121053696, -0.033181965351104736, 0.00547569477930665, 0.036765776574611664, 0.006053377408534288, -0.08099251985549927, -0.016077326610684395, -0.027787530794739723, -0.040648676455020905, 0.00730011286213994, -0.0414426364004612, -0.038701508194208145, -0.03662145510315895, 0.08128757029771805, -0.0024195765145123005, -0.03573320060968399, 0.08165772259235382, -0.09977423399686813, 0.015399483032524586, -0.01614299602806568, 0.002820800058543682, -0.04784011468291283, 0.05951269716024399, 0.011651769280433655, -0.0014794840244576335, -0.015080437995493412, 0.018821662291884422, 0.06468155235052109, 0.039166808128356934, 0.021516453474760056, 0.0017946561565622687, -0.029081489890813828, -0.012894629500806332, 0.006771964021027088, -0.01567251607775688, 0.03603274002671242, -0.03947291150689125, -0.035955704748630524, 0.07964280992746353, 0.00985642522573471, -0.033430252224206924, -0.07530763000249863, -0.03179933503270149, -0.09110195934772491, -0.021871551871299744, 0.010372944176197052, 0.013107169419527054, -0.030134161934256554, -0.03129036724567413, -0.11826793104410172, -0.06853077560663223, -0.07256795465946198, -0.008500782772898674, -0.045568544417619705, 0.02471165359020233, 0.010246130637824535, 0.014255538582801819, -0.02925318107008934, -0.012790019623935223, -0.059045564383268356, -0.10106705874204636, 0.05429466441273689, 0.057757459580898285, 0.04247850552201271, -0.06526616215705872, -0.045969486236572266, -0.025269625708460808, 0.009278766810894012, -0.0027237948961555958, -0.03816251456737518, -0.0025738144759088755, -0.008717125281691551, -0.033133164048194885, -0.07108809798955917, -0.03137155622243881, -0.054505255073308945, -0.022368410602211952, -0.049220506101846695, -0.004773796536028385, -0.11467631906270981, -0.0404934324324131, 0.028500014916062355, 0.024069692939519882, 0.13364000618457794, -0.006789125502109528, -0.0020672595128417015, 0.03542536124587059, 0.035345178097486496, -0.08416150510311127, -0.021626323461532593, -0.034012384712696075, 0.022228604182600975, -0.0717104896903038, 0.013858145102858543, -0.022247856482863426, -0.011563334614038467, -0.04989809915423393, 0.018170997500419617, -0.07617693394422531, -0.025764551013708115, 0.04588412120938301, -0.019369591027498245, 0.020277876406908035, -0.0007819360471330583, 0.010179564356803894, 0.009402338415384293, -0.015424567274749279, 0.034170001745224, 0.07178868353366852, 0.024531688541173935, -0.004102030768990517, 0.012586197815835476, -0.03643999248743057, 0.01641640067100525, 0.031023558229207993, 0.04022999480366707, -0.014655273407697678, -0.010324598290026188, -0.0001196517696371302, -0.007214980665594339, -0.0021275696344673634, -0.02497195079922676, -0.033309243619441986, 0.03659416735172272, -0.05542110279202461, 0.025400668382644653, -0.041703689843416214, 0.05335262045264244, -0.008564525283873081, 0.003811977803707123, -0.0028111867140978575, 0.01292717456817627, -0.01116267405450344, -0.019739124923944473, -0.01089504361152649, 0.024821974337100983, -0.039307497441768646, -0.029364410787820816, -0.03557027131319046, -0.04077422618865967, -0.04121769219636917, -0.03954383358359337, -0.004961928818374872, 0.04294441640377045, 0.01249909121543169, -0.15439344942569733, -0.01894688792526722, 0.008254490792751312, 0.05539372190833092, -0.061561308801174164, 0.038926903158426285, 0.017630062997341156, -0.028750209137797356, -0.043681010603904724, -0.0437539778649807, 0.015871329233050346, 0.01822875626385212, 0.04119759425520897, -0.023447880521416664, 0.019766809418797493, 0.006389308720827103, -0.02455821819603443, 0.029864773154258728, 0.07181473821401596, -0.003340073861181736, -0.07322216778993607, -0.040465693920850754, 0.009959837421774864, 0.002585312584415078, -0.0140965161845088, -0.08403933793306351, -0.03490465506911278, -0.044435806572437286, -0.06268350034952164, -0.016862833872437477, -0.023303264752030373, 0.0171485748142004, 0.027995506301522255, -0.07499692589044571, 0.03039540722966194, 0.08208668977022171, 0.07428140193223953, 0.05267784371972084, -0.1360221803188324, -0.033836305141448975, -0.015034972690045834, -0.04714522883296013, 0.1260329782962799, 0.019746074452996254, -0.005775296129286289, -0.02007107622921467, 0.01094073336571455, 0.0064430455677211285, 0.02295682579278946, -0.033444665372371674, 0.034592658281326294, 0.013539204373955727, 0.027404045686125755, 0.0055852849036455154, -0.03798438236117363, -0.001250410103239119, 0.0820428878068924, 0.03548986464738846, -0.039246972650289536, -0.03099798411130905, -0.03270233795046806, -0.0067720795050263405, -0.01645543798804283, 0.029515353962779045, -0.013324192725121975, -0.06505610048770905, -0.07541058212518692, -0.05711925029754639, 0.047830965369939804, -0.05298919975757599, -0.004157222807407379, -0.07835221290588379], [0.05635126680135727, 0.0317411832511425, 0.04694051295518875, 0.04254669323563576, 0.012481655925512314, 0.03922855108976364, -0.0644468292593956, -0.014949089847505093, 0.056052085012197495, -0.023444315418601036, -0.00847008265554905, 0.05752355232834816, 0.04210079461336136, -0.05207882449030876, -0.006864857394248247, 0.06264793872833252, -0.007809843868017197, -0.021076489239931107, -0.0550801046192646, 0.037512440234422684, -0.038656141608953476, -0.05476544052362442, -0.0038935949560254812, 0.024908676743507385, 0.04234088584780693, -0.006488916464149952, 0.05702879652380943, 0.020383503288030624, 0.05297880619764328, 0.034931931644678116, 0.007173917721956968, 0.008529448881745338, -0.03084661066532135, -0.07947870343923569, 0.06601572036743164, -0.02900291606783867, -0.04583063721656799, 0.0003248823049943894, 0.001428753836080432, 0.04077562317252159, 0.01446138322353363, -0.028079787269234657, -0.0018409263575449586, 0.06706225126981735, -0.059153564274311066, 0.020077187567949295, -0.008341041393578053, -0.020655278116464615, 0.0021392449270933867, -0.01991787552833557, -0.008363251574337482, -0.011397306807339191, 0.07493002712726593, 0.030366813763976097, 0.007227621972560883, 0.04300837218761444, -0.04387596622109413, 0.06000075489282608, -0.026793697848916054, -0.017473848536610603, -0.07207586616277695, 0.006236258894205093, -0.02434130385518074, 0.062424737960100174, 0.01645815372467041, -0.0034010768868029118, -0.045728180557489395, 0.06044350564479828, 0.07923107594251633, -0.006371909752488136, -0.06201910227537155, -0.06311625242233276, 0.027019327506422997, -0.0037448368966579437, 0.026871465146541595, -0.06188962608575821, -0.013521195389330387, -0.015702741220593452, 0.0540895089507103, -0.01482210773974657, -0.04957927390933037, -0.016963904723525047, -0.04622432217001915, -0.022214341908693314, -0.01754331775009632, -0.008483129553496838, -0.011883171275258064, 0.022281955927610397, -0.04252998158335686, -0.026287099346518517, -0.051460735499858856, 0.026608077809214592, -0.06014362350106239, 0.022697191685438156, 0.03281091898679733, 0.021844690665602684, -0.0423930287361145, 0.05265511944890022, -0.05662533640861511, -0.06250759959220886, 0.024807630106806755, 0.04968482628464699, 0.07645900547504425, 0.03567873686552048, 0.017810417339205742, -0.04086063802242279, -0.03923221305012703, -0.07117077708244324, -0.06482986360788345, -0.017185768112540245, 0.006062914151698351, -0.11707966774702072, -0.07641582936048508, 0.018166406080126762, 0.03350656107068062, 0.009219104424118996, -0.01585826836526394, 0.05209463834762573, -0.09781934320926666, -0.0045869722962379456, 0.0012707423884421587, 0.026218540966510773, 0.09110726416110992, -0.03096909075975418, 0.013635535724461079, 0.03312882035970688, 0.0027493906673043966, -0.01686997339129448, 0.00951708946377039, -0.06066349521279335, 0.021281372755765915, 0.01989092119038105, 0.05712186172604561, -0.01285800151526928, -0.03646411374211311, -0.009816399775445461, -0.004271244164556265, -0.04486115276813507, -0.015320158563554287, 0.06874322891235352, -0.03517398610711098, -0.044303733855485916, -0.024139096960425377, 0.048359863460063934, 0.04753394052386284, 0.021886369213461876, 0.052340514957904816, 0.007943651638925076, 0.030519548803567886, -0.05788487568497658, -0.020411847159266472, -0.022117525339126587, 0.015841027721762657, 0.07807590812444687, 0.012855276465415955, -0.06833486258983612, 0.020658474415540695, -0.07181666046380997, -0.10104142129421234, 0.006063561886548996, 0.02928658202290535, -0.021913375705480576, 0.02917034737765789, -0.03450912982225418, -0.003289538435637951, 0.023086678236722946, 0.06336759775876999, -0.037313781678676605, -0.008133255876600742, 0.05191309377551079, 0.0025316555984318256, 0.023478776216506958, -0.03229648992419243, 0.0006033949903212488, 0.1030939444899559, -0.07469514012336731, -0.021163854748010635, -0.027184391394257545, -0.09759265184402466, -0.07472387701272964, 0.003998815547674894, -0.00684324512258172, 0.010838555172085762, 0.007953834719955921, -0.107323557138443, -0.055336806923151016, 0.013860167004168034, 0.026209883391857147, -0.08813131600618362, 0.01719936728477478, -0.0004302638990338892, -0.044486649334430695, -0.03709275647997856, 0.01835791952908039, 0.027222150936722755, 0.07971173524856567, 0.026741694658994675, -0.06377232074737549, 0.025681978091597557, -0.02343831956386566, 0.009675344452261925, 0.0034035295248031616, 0.052170224487781525, 0.027566000819206238, -0.033882077783346176, -0.07325960695743561, 0.07782275974750519, -0.010277129709720612, -0.015419422648847103, -0.02439766190946102, -0.02054680325090885, -0.09448843449354172, -0.06982097029685974, -0.02665460668504238, 0.014770581386983395, -0.03991169482469559, 0.0077918111346662045, -0.054311685264110565, 0.021615156903862953, 0.0550985261797905, -0.01641203835606575, 0.010318329557776451, -0.08556543290615082, 0.021641753613948822, 0.028982525691390038, -0.0014282457996159792, 0.026595275849103928, -0.042501434683799744, 0.019907988607883453, 0.006277792155742645, -0.01722932979464531, 0.01989705301821232, 0.02153061144053936, -0.053948041051626205, 0.020054522901773453, 0.004361732397228479, -0.058078646659851074, -0.04736762121319771, -0.08835752308368683, 0.03504833206534386, 0.02825913578271866, 0.020794257521629333, -0.00945606455206871, -0.005671823397278786, -0.03204740956425667, 0.04319952428340912, 0.05867624282836914, -0.00300614139996469, -0.037650734186172485, -0.07190851867198944, -0.03431618586182594, -0.02189822867512703, 0.023387271910905838, -0.03422066941857338, 0.03238226845860481, -0.060065582394599915]]\n"
     ]
    }
   ],
   "source": [
    "from vertexai.language_models import TextEmbeddingInput, TextEmbeddingModel\n",
    "\n",
    "# Configuration for the embedding model\n",
    "MODEL_NAME = \"text-embedding-preview-0815\"\n",
    "DIMENSIONALITY = 256\n",
    "\n",
    "# Function to embed text using Vertex AI\n",
    "def embed_text(\n",
    "    texts: list[str],\n",
    "    task: str,\n",
    "    model_name: str = MODEL_NAME,\n",
    "    dimensionality: int | None = DIMENSIONALITY\n",
    ") -> list[list[float]]:\n",
    "    \"\"\"Embeds texts with a pre-trained, foundational model.\"\"\"\n",
    "    model = TextEmbeddingModel.from_pretrained(model_name)\n",
    "    inputs = [TextEmbeddingInput(text, task) for text in texts]\n",
    "    kwargs = dict(output_dimensionality=dimensionality) if dimensionality else {}\n",
    "    embeddings = model.get_embeddings(inputs, **kwargs)\n",
    "    return [embedding.values for embedding in embeddings]\n",
    "\n",
    "# Test embedding code block (CODE_RETRIEVAL_QUERY)\n",
    "def test_code_block_embedding():\n",
    "    texts = [\"Retrieve a function that adds two numbers\"]\n",
    "    task = \"CODE_RETRIEVAL_QUERY\"\n",
    "    print(\"Embedding for code block:\")\n",
    "    embeddings = embed_text(texts=texts, task=task)\n",
    "    print(embeddings)\n",
    "\n",
    "# Test embedding retrieval documents (RETRIEVAL_DOCUMENT)\n",
    "def test_document_embedding():\n",
    "    texts = [\n",
    "        \"def func(a, b): return a + b\",\n",
    "        \"def func(a, b): return a - b\",\n",
    "        \"def func(a, b): return (a ** 2 + b ** 2) ** 0.5\"\n",
    "    ]\n",
    "    task = \"RETRIEVAL_DOCUMENT\"\n",
    "    print(\"Embedding for document retrieval:\")\n",
    "    embeddings = embed_text(texts=texts, task=task)\n",
    "    print(embeddings)\n",
    "\n",
    "\n",
    "    # Test embedding for a code block (CODE_RETRIEVAL_QUERY)\n",
    "test_code_block_embedding()\n",
    "\n",
    "    # Test embedding for document retrieval (RETRIEVAL_DOCUMENT)\n",
    "test_document_embedding()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6xhfXP3THab-",
   "metadata": {
    "id": "6xhfXP3THab-"
   },
   "source": [
    "# CHUNKING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "kMURodS9HZS4",
   "metadata": {
    "id": "kMURodS9HZS4"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m OPENAI_API_KEY \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "h9OBNYYROAjK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4130,
     "status": "ok",
     "timestamp": 1730254749333,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 300
    },
    "id": "h9OBNYYROAjK",
    "outputId": "fca7a7cb-f968-4e5f-e6eb-6d3bd0d3c982"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyPDF2\n",
      "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m153.6/232.6 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: PyPDF2\n",
      "Successfully installed PyPDF2-3.0.1\n"
     ]
    }
   ],
   "source": [
    "pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "_UN2b_oHKeRX",
   "metadata": {
    "id": "_UN2b_oHKeRX"
   },
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.schema import Document  # Import the Document class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sQU2O2_EKgQb",
   "metadata": {
    "id": "sQU2O2_EKgQb"
   },
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.schema import Document  # Import the Document class\n",
    "\n",
    "# Step 1: Extract text from the PDF using PyPDF2\n",
    "with open('/content/s3-userguide.pdf', 'rb') as file:\n",
    "    reader = PyPDF2.PdfReader(file)\n",
    "\n",
    "    # Iterate through all the pages and extract text\n",
    "    text = ''\n",
    "    for page_num in range(len(reader.pages)):\n",
    "        page = reader.pages[page_num]\n",
    "        extracted_text = page.extract_text()\n",
    "        if extracted_text:  # Ensure the text extraction is successful\n",
    "            text += extracted_text\n",
    "\n",
    "# Step 2: Create a Document object\n",
    "document = Document(page_content=text)\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Step 3: Use RecursiveCharacterTextSplitter for better splitting\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=2000,\n",
    "    chunk_overlap=200,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \"]\n",
    ")\n",
    "\n",
    "# Split the document text into smaller chunks\n",
    "texts = text_splitter.split_documents([document])  # Pass in a list of Document objects\n",
    "\n",
    "# Step 4: Print the number of chunks\n",
    "print(f\"Number of chunks: {len(texts)}\")\n",
    "\n",
    "# Step 5: Optionally, output the first few chunks to inspect the splitting\n",
    "for i, chunk in enumerate(texts[:3]):  # Limit to first 3 chunks for display\n",
    "    print(f\"Chunk {i+1}:\")\n",
    "    print(chunk.page_content[:500])  # Print first 500 characters of the chunk\n",
    "    print(\"\\n\" + \"-\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oVyUOPv6KkZG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 170,
     "status": "ok",
     "timestamp": 1729819660035,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 300
    },
    "id": "oVyUOPv6KkZG",
    "outputId": "bcecd3c8-d1db-44e7-a034-4a9c57ff43d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delete directories, and it does not support symbolic links or ﬁle locking. Mountpoint is ideal \n",
      "for applications that do not need all of the features of a shared ﬁle system and POSIX-style \n",
      "permissions but require Amazon S3's elastic throughput to read and write large S3 datasets. For \n",
      "details, see Mountpoint ﬁle system behavior on GitHub. For workloads that require full POSIX \n",
      "support, we recommend Amazon FSx for Lustre and its support for linking S3 buckets.\n",
      "Mountpoint for Amazon S3 is availab\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "wget download-link\n",
      "3. (Optional) Verify the authenticity and integrity of the downloaded ﬁle. First, copy the \n",
      "appropriate signature URL for your architecture.\n",
      "x86_64 :\n",
      "https://s3.amazonaws.com/mountpoint-s3-release/latest/x86_64/mount-s3.rpm.asc\n",
      "Installing Mountpoint API Version 2006-03-01 85Amazon Simple Storage Service User Guide\n",
      "ARM64 (Graviton) :\n",
      "https://s3.amazonaws.com/mountpoint-s3-release/latest/arm64/mount-s3.rpm.asc\n",
      "Next, see Verifying the signature of the Mountpoint for Amazon S3 pac\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Output only the first 2-3 split text chunks with truncation to avoid large data output\n",
    "for chunk in texts[125:127]:  # Display the first 3 chunks\n",
    "    print(chunk.page_content[:500])  # Print only the first 500 characters of each chunk\n",
    "    print(\"\\n\" + \"-\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Kl2hvCmiTe9K",
   "metadata": {
    "id": "Kl2hvCmiTe9K"
   },
   "source": [
    "## Semantic Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TucBUcJlOJps",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4370,
     "status": "ok",
     "timestamp": 1730254786591,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 300
    },
    "id": "TucBUcJlOJps",
    "outputId": "9f8c09b7-01ba-4787-a8e0-6fac29c3e8cd",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_experimental\n",
      "  Downloading langchain_experimental-0.3.2-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: langchain-community<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain_experimental) (0.3.3)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.6 in /usr/local/lib/python3.10/dist-packages (from langchain_experimental) (0.3.13)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.0.35)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.9.5)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.6.7)\n",
      "Requirement already satisfied: langchain<0.4.0,>=0.3.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.3.5)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.1.137)\n",
      "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.26.4)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.6.0)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.6->langchain_experimental) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.6->langchain_experimental) (24.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.6->langchain_experimental) (2.9.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.6->langchain_experimental) (4.12.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.15.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (4.0.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.23.0)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.6->langchain_experimental) (3.0.0)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.4->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.3.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.10.10)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.6->langchain_experimental) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.6->langchain_experimental) (2.23.4)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.1.1)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.7.1)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.0.6)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.14.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.0.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.0->aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.2.0)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.2.2)\n",
      "Downloading langchain_experimental-0.3.2-py3-none-any.whl (208 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.1/208.1 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: langchain_experimental\n",
      "Successfully installed langchain_experimental-0.3.2\n"
     ]
    }
   ],
   "source": [
    "pip install langchain_experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "_DSDByDVOGz-",
   "metadata": {
    "id": "_DSDByDVOGz-"
   },
   "outputs": [],
   "source": [
    "# Semantic Chunker\n",
    "import PyPDF2\n",
    "from langchain.schema import Document  # Import the Document class\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VWuChKTLYX9-",
   "metadata": {
    "id": "VWuChKTLYX9-"
   },
   "source": [
    "## Vertex AI embedding for semantic chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "n_tCD0ygESYh",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3975,
     "status": "ok",
     "timestamp": 1730185089018,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 300
    },
    "id": "n_tCD0ygESYh",
    "outputId": "270676b0-4308-423e-e56c-d66a499b005b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyPDF2\n",
      "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.9/232.6 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: PyPDF2\n",
      "Successfully installed PyPDF2-3.0.1\n"
     ]
    }
   ],
   "source": [
    "pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "voHkwmzHYU3q",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336,
     "referenced_widgets": [
      "2cc8a99119424076a6d7bbde0f097569",
      "42319bb46b42497eabbc1be82155d350",
      "c77751583cc44e34b48df2fc18c71fa9",
      "4af004c9c1cf4a35bd1e5118e749ae85",
      "58baf9e67c7c4202bf11324bd3314630",
      "6a0c04457e3c494fafdb3eb807b4c60c",
      "fadc946362f54a59aabf4d92ae856074",
      "6ab3edee5ea5487faf76fdd54eb81f6e",
      "a0c345c72c734207b3ff7e0834e46715",
      "7bc107fa811b4158979891922d592f4e",
      "64c052c5396146bb895b4a37fa34000d",
      "6e6f55560c394f43a9e2a07966cb846c",
      "74e0469ab29d4def95ce2e5f152db8e6",
      "23548a462398487b818fbc5af2f95481",
      "18e91be23ddd4d04ad5c1ca3162836ec",
      "96466c1a07164aa6b40e3d1cb3b650f4",
      "1bd4a29008514651bb14c5ff9fb9d4f7",
      "4c1843c47bae4bf49030392b4929747c",
      "729aa5228b894811920f1d6cabcbba66",
      "5aba8b2efa93488b8241fa41d7f7bee9",
      "dfe4c76bc29143b8aa10b7bc4ea6ccae",
      "dd440b5ed6b34ff6aebd33184be8db0c",
      "65c06940e2614e02b0fb8d8a70124e6e",
      "9c945530c5e542259da5927f4cffb753",
      "c18857af221d42f984d57c93eacaf41c",
      "5d02d4bda06f40c884fcec4c71530d08",
      "9ab8bc95ad284cb0af88ea201f9047e8",
      "8724fae499744512b333b5b6b1272d27",
      "19d8e1514f5d4234ba6323894e01ce81",
      "d1354f2ab29141868857566bf886bc21",
      "43d8976b81dc49578d21e5109f3b7789",
      "34a0cab8722c415ca054ae6c3873a2ad",
      "1a1448c4fc864f6a918809d7b2bb3477",
      "29066facb7c44860ae7f4be2890dda1f",
      "a2f2fd6006b74592b4ee555ad6cb73c3",
      "bec43f2939154741868c5ca0b81cf5d1",
      "34e9959d97854f618eab08c70eca3173",
      "ca87511b726a4d4b9b3bcfa022c3d64a",
      "530fd991c391442d956636ddeb87d73d",
      "97344813fbed4c6fb923a86b9aad5991",
      "50f07acc22244042a9fce8aabe64897f",
      "4a8962c73d0d4da3b19c449b31ec308e",
      "6b1254c3b46244f2a38b702b70221792",
      "aa0a6d7df5234ffd8a05c5bb3981ccc6",
      "9c2210911ed348b6ad7333fac8ed3b5c",
      "7588aef355f449b7b961ae60c1e354dc",
      "830708a2ac654b37aeff799029ca6dfa",
      "99c9e62f119a49e39a80f2f26dc47437",
      "b424d2d4d0b04771bd2e8ecc3dbf3265",
      "c3bd92f254374e7bb147c90e6567b4f5",
      "6ceb0b17c239442b8708f8f8f3d505a0",
      "6641bcba5e7649e6b1122f8539c66244",
      "9824b41b7d824825876a8cae8fe1085c",
      "d68d9e8cc4e54b22a04c21e6365324c2",
      "9f92534be3dc4e9a8d6a312d62890861",
      "90af30e55b8a482ca51460e1d0d2d2ec",
      "91d9d223090d4bfa84fa1e0fe7c11176",
      "46f7482090154d1588d0cd6d60ddbe48",
      "c040ecdf50a645a78d55b0b89a05459f",
      "f372c2cd040045d38dbe38156b76e6ab",
      "fc61fc9c32054126a96b12c953a4cd9c",
      "4d12a6d743be4f3d91bc54bf052d0118",
      "13692dfb7f31480f8c5c4ec51ec2d423",
      "b8785fae33394325801f10a532e915b6",
      "92bff9dec70547dcb2095f2caf8d71e4",
      "def95cae2e984b17a92c48c31dcea93b"
     ]
    },
    "executionInfo": {
     "elapsed": 18212,
     "status": "ok",
     "timestamp": 1730254817603,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 300
    },
    "id": "voHkwmzHYU3q",
    "outputId": "4054e213-f02d-43c0-deb7-6d0dbf79570d"
   },
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "import tiktoken  # Tokenizer library\n",
    "import PyPDF2\n",
    "\n",
    "# Configuration for the embedding model\n",
    "MODEL_NAME = \"avsolatorio/NoInstruct-small-Embedding-v0\"\n",
    "DIMENSIONALITY = 256\n",
    "THRESHOLD = 0.8  # Threshold for semantic similarity splitting\n",
    "MAX_TOKENS = 20000  # Max tokens per request\n",
    "MAX_INSTANCES = 250  # Max instances per request (sentences)\n",
    "\n",
    "# Load the Hugging Face model and tokenizer\n",
    "model = AutoModel.from_pretrained(MODEL_NAME)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# Function to get embeddings using Hugging Face model\n",
    "def get_embedding(text: Union[str, list[str]], mode: str = \"sentence\"):\n",
    "    model.eval()\n",
    "    if isinstance(text, str):\n",
    "        text = [text]\n",
    "\n",
    "    inp = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(**inp)\n",
    "\n",
    "    if mode == \"query\":\n",
    "        vectors = output.last_hidden_state * inp[\"attention_mask\"].unsqueeze(2)\n",
    "        vectors = vectors.sum(dim=1) / inp[\"attention_mask\"].sum(dim=-1).view(-1, 1)\n",
    "    else:\n",
    "        vectors = output.last_hidden_state[:, 0, :]\n",
    "\n",
    "    return vectors\n",
    "\n",
    "# Function to compute semantic similarity between two embeddings\n",
    "def compute_similarity(embedding1, embedding2):\n",
    "    return cosine_similarity(embedding1.cpu().numpy(), embedding2.cpu().numpy())[0][0]\n",
    "\n",
    "# Function to split text into sentences or smaller segments (basic sentence splitting)\n",
    "def split_text_into_sentences(text):\n",
    "    sentences = re.split(r'(?<=[.!?]) +', text)\n",
    "    return sentences\n",
    "\n",
    "# Function to split sentences into batches based on both token count and instance count limits\n",
    "def split_into_token_and_instance_batches(sentences, max_tokens=MAX_TOKENS, max_instances=MAX_INSTANCES):\n",
    "    enc = tiktoken.get_encoding(\"cl100k_base\")  # Use a compatible tokenizer\n",
    "    current_batch = []\n",
    "    current_tokens = 0\n",
    "    current_instances = 0\n",
    "\n",
    "    for sentence in sentences:\n",
    "        sentence_tokens = len(enc.encode(sentence))\n",
    "\n",
    "        # If adding this sentence exceeds either the token limit or the instance limit, yield the batch\n",
    "        if (current_tokens + sentence_tokens > max_tokens) or (current_instances + 1 > max_instances):\n",
    "            yield current_batch\n",
    "            current_batch = []\n",
    "            current_tokens = 0\n",
    "            current_instances = 0\n",
    "\n",
    "        current_batch.append(sentence)\n",
    "        current_tokens += sentence_tokens\n",
    "        current_instances += 1\n",
    "\n",
    "    if current_batch:\n",
    "        yield current_batch\n",
    "\n",
    "# Function to perform semantic chunking on a PDF's text content\n",
    "def semantic_chunking(text, threshold=THRESHOLD):\n",
    "    sentences = split_text_into_sentences(text)  # Split the text into sentences\n",
    "    chunks = []\n",
    "    chunk_count = 0\n",
    "    # Process the text in token-and-instance-based batches\n",
    "    for batch in split_into_token_and_instance_batches(sentences):\n",
    "        embeddings = get_embedding(batch, mode=\"sentence\")  # Get embeddings for each sentence batch\n",
    "        current_chunk = [batch[0]]  # Start with the first sentence in a chunk\n",
    "\n",
    "        # Compare embeddings of consecutive sentences\n",
    "        for i in range(1, len(batch)):\n",
    "            similarity = compute_similarity(embeddings[i-1:i], embeddings[i:i+1])\n",
    "\n",
    "            if similarity < threshold:\n",
    "                # If similarity is below threshold, start a new chunk\n",
    "                chunks.append(\" \".join(current_chunk))\n",
    "                current_chunk = [batch[i]]\n",
    "                chunk_count += 1\n",
    "                # Progress update every 100 chunks\n",
    "                if chunk_count % 100 == 0:\n",
    "                    print(f\"Processed {chunk_count} chunks...\")\n",
    "            else:\n",
    "                # Otherwise, continue adding to the current chunk\n",
    "                current_chunk.append(batch[i])\n",
    "\n",
    "        # Add the last chunk of the batch\n",
    "        if current_chunk:\n",
    "            chunks.append(\" \".join(current_chunk))\n",
    "            chunk_count += 1\n",
    "            if chunk_count % 100 == 0:\n",
    "                print(f\"Processed {chunk_count} chunks...\")\n",
    "                \n",
    "    print(f\"Semantic chunking completed. Total chunks created: {chunk_count}\")\n",
    "    return chunks\n",
    "\n",
    "# Function to extract text from the PDF\n",
    "def extract_text_from_pdf(pdf_file_path):\n",
    "    with open(pdf_file_path, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        text = ''\n",
    "        for page_num in range(len(reader.pages)):  # uncomment to run all pages of the pdf\n",
    "        #for page_num in range(10):\n",
    "            page = reader.pages[page_num]\n",
    "            extracted_text = page.extract_text()\n",
    "            if extracted_text:  # Ensure the text extraction is successful\n",
    "                text += extracted_text\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_JeFV0xSitqz",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3598,
     "status": "ok",
     "timestamp": 1730254821199,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 300
    },
    "id": "_JeFV0xSitqz",
    "outputId": "b31c6fb8-d6ce-4028-bbe7-d634b0e346ed",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.8.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.9.11)\n",
      "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "gXsnUGVCYcO-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8049,
     "status": "ok",
     "timestamp": 1730187839593,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 300
    },
    "id": "gXsnUGVCYcO-",
    "outputId": "3b09c40e-6a0b-4dba-f645-80f06be1eb93",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 100 chunks...\n",
      "Processed 200 chunks...\n",
      "Processed 300 chunks...\n",
      "Processed 400 chunks...\n",
      "Processed 500 chunks...\n",
      "Processed 600 chunks...\n",
      "Processed 700 chunks...\n",
      "Processed 800 chunks...\n",
      "Processed 900 chunks...\n",
      "Processed 1000 chunks...\n",
      "Processed 1100 chunks...\n",
      "Processed 1200 chunks...\n",
      "Processed 1300 chunks...\n",
      "Processed 1400 chunks...\n",
      "Processed 1500 chunks...\n",
      "Processed 1600 chunks...\n",
      "Processed 1700 chunks...\n",
      "Processed 1800 chunks...\n",
      "Processed 1900 chunks...\n",
      "Processed 2000 chunks...\n",
      "Processed 2100 chunks...\n",
      "Processed 2200 chunks...\n",
      "Processed 2300 chunks...\n",
      "Processed 2400 chunks...\n",
      "Processed 2500 chunks...\n",
      "Processed 2600 chunks...\n",
      "Processed 2700 chunks...\n",
      "Processed 2800 chunks...\n",
      "Processed 2900 chunks...\n",
      "Processed 3000 chunks...\n",
      "Processed 3100 chunks...\n",
      "Processed 3200 chunks...\n",
      "Processed 3300 chunks...\n",
      "Processed 3400 chunks...\n",
      "Processed 3500 chunks...\n",
      "Processed 3600 chunks...\n",
      "Processed 3700 chunks...\n",
      "Processed 3800 chunks...\n",
      "Processed 3900 chunks...\n",
      "Processed 4000 chunks...\n",
      "Processed 4100 chunks...\n",
      "Processed 4200 chunks...\n",
      "Processed 4300 chunks...\n",
      "Processed 4400 chunks...\n",
      "Semantic chunking completed. Total chunks created: 4437\n"
     ]
    }
   ],
   "source": [
    "# Example usage (this part will run the script)\n",
    "#pdf_file_path = '/content/s3-userguide.pdf'  # Path to your PDF\n",
    "pdf_file_path = 's3-userguide.pdf'\n",
    "pdf_text = extract_text_from_pdf(pdf_file_path)\n",
    "\n",
    "# Perform semantic chunking on the entire PDF text\n",
    "chunks = semantic_chunking(pdf_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be1a9b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of semantic chunks: 4437\n",
      "Chunk 1: This suﬃx is reserved for Multi-Region Access \n",
      "Point names. For more information, see Rules for naming Amazon S3 Multi-Region Access Points.\n",
      "•Bucket names must not end with the suﬃx --x-s3. This suﬃx is reserved for directory buckets. \n",
      "For more information, see Directory bucket naming rules.\n",
      "•Bucket names must be unique across all AWS accounts in all the AWS Regions within a partition.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Chunk 2: \n",
      "A partition is a grouping of Regions. AWS currently has three partitions: aws (Standard Regions),\n",
      "aws-cn (China Regions), and aws-us-gov  (AWS GovCloud (US)).\n",
      "•A bucket name cannot be used by another AWS account in the same partition until the bucket is \n",
      "deleted.\n",
      "•Buckets used with Amazon S3 Transfer Acceleration can't have dots (.) in their names.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Chunk 3: For more \n",
      "information about Transfer Acceleration, see Conﬁguring fast, secure ﬁle transfers using Amazon \n",
      "S3 Transfer Acceleration.\n",
      "For best compatibility, we recommend that you avoid using dots (.) in bucket names, except for \n",
      "buckets that are used only for static website hosting. If you include dots in a bucket's name, \n",
      "you can't use virtual-host-style addressing over HTTPS, unless you perform your own certiﬁcate \n",
      "validation. This is because the security certiﬁcates used for virtual hosting o\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Chunk 4: Virginia) Region could have names \n",
      "that were up to 255 characters long and included uppercase letters and underscores.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Output the number of chunks and the chunked text\n",
    "print(f\"Number of semantic chunks: {len(chunks)}\")\n",
    "for i, chunk in enumerate(chunks[100:104]):  # Display first 3 chunks for inspection\n",
    "    print(f\"Chunk {i+1}: {chunk[:500]}\")  # Print first 500 characters of each chunk\n",
    "    print(\"\\n\" + \"-\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "y5Hbme3_j1-C",
   "metadata": {
    "id": "y5Hbme3_j1-C"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunks saved to semantic_chunks.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Save chunks to a JSON file\n",
    "with open(\"semantic_chunks.json\", \"w\") as json_file:\n",
    "    json.dump(chunks, json_file)\n",
    "\n",
    "print(\"Chunks saved to semantic_chunks.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mBkZwdIaK0IJ",
   "metadata": {
    "id": "mBkZwdIaK0IJ"
   },
   "source": [
    "# Metdata Gen: Topic Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "UKP2r8bwKtWS",
   "metadata": {
    "id": "UKP2r8bwKtWS"
   },
   "outputs": [],
   "source": [
    "# Modify the function to work with strings (plain text chunks) and generate 2-3 tags\n",
    "def generate_metadata_for_chunks(llm, chunks, max_tokens=2048):\n",
    "    results = []\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        # Truncate the chunk if it exceeds the max_tokens limit\n",
    "        truncated_chunk = chunk[:max_tokens]  # Now 'chunk' is a string, so we handle it directly\n",
    "\n",
    "        # Create a prompt that requests the LLM to generate only the most relevant 2-3 tags and headings\n",
    "        prompt = f\"\"\"\n",
    "        The following text is a chunk from a larger document. Please generate the 2-3 most relevant topic headings and tags for this text:\n",
    "        Text: \"{truncated_chunk}\"\n",
    "        \"\"\"\n",
    "\n",
    "        # Call the LLM with the prompt using the invoke method\n",
    "        response = llm.invoke([{\n",
    "            \"role\": \"system\",\n",
    "            \"content\": prompt\n",
    "        }])\n",
    "\n",
    "        # Store the result (response with tags and headings)\n",
    "        results.append({\n",
    "            \"chunk_index\": i, \n",
    "            \"chunk_text\": truncated_chunk,\n",
    "            \"metadata\": response\n",
    "        })\n",
    "\n",
    "    return results\n",
    "\n",
    "# Display the results with truncated chunk text and the most relevant metadata\n",
    "def display_metadata_results(results):\n",
    "    for result in results:\n",
    "        print(f\"Chunk Index: {result['chunk_index']}\")\n",
    "        print(\"Chunk Text (truncated):\")\n",
    "        print(result['chunk_text'][:1000])  # Display only the first 1000 characters of the chunk text\n",
    "        print(\"\\nGenerated Metadata:\")\n",
    "\n",
    "        # Extract and display the topic headings and tags from the metadata\n",
    "        metadata_content = result['metadata'].content\n",
    "\n",
    "        # Format the metadata output\n",
    "        print(f\"{metadata_content}\")\n",
    "        print(\"\\n\" + \"-\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xi6Idrh4MOLB",
   "metadata": {
    "id": "xi6Idrh4MOLB"
   },
   "source": [
    "### Metadata generation with Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PhQo3YmkMcuD",
   "metadata": {
    "id": "PhQo3YmkMcuD"
   },
   "outputs": [],
   "source": [
    "import vertexai\n",
    "from vertexai.generative_models import GenerativeModel\n",
    "\n",
    "# Initialize Vertex AI for Google Gemini model\n",
    "PROJECT_ID = \"ids-560-project-group-1-bosch\"\n",
    "vertexai.init(project=PROJECT_ID, location=\"us-central1\")\n",
    "\n",
    "# Load the Gemini generative model\n",
    "#model = GenerativeModel(\"gemini-1.5-pro-002\")\n",
    "model = GenerativeModel(\"gemini-1.5-flash\")\n",
    "# Function to generate metadata for each chunk\n",
    "def generate_metadata_for_chunks(model, chunks, max_tokens=2048):\n",
    "    results = []\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        # Truncate the chunk if it exceeds the max_tokens limit\n",
    "        truncated_chunk = chunk[:max_tokens]\n",
    "\n",
    "        # Define the prompt for metadata generation\n",
    "        prompt = f\"\"\"\n",
    "        The following text is a chunk from a larger document. Please generate the 2-3 most relevant topic headings and tags for this text:\n",
    "        Text: \"{truncated_chunk}\"\n",
    "        \"\"\"\n",
    "\n",
    "        # Use the Gemini model to generate content based on the prompt\n",
    "        response = model.generate_content(prompt)\n",
    "\n",
    "        # Store the response metadata (topic headings and tags)\n",
    "        results.append({\n",
    "            \"chunk_index\": i,\n",
    "            \"chunk_text\": truncated_chunk,\n",
    "            \"metadata\": response.text\n",
    "        })\n",
    "        # Print progress every 100 chunks\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f\"Processed {i + 1} chunks...\")\n",
    "            \n",
    "    print(f\"Metadata generation completed. Total chunks processed: {len(chunks)}\")\n",
    "    return results\n",
    "\n",
    "# Display the results with truncated chunk text and the most relevant metadata\n",
    "def display_metadata_results(results):\n",
    "    for result in results:\n",
    "        print(f\"Chunk Index: {result['chunk_index']}\")\n",
    "        print(\"Chunk Text (truncated):\")\n",
    "        print(result['chunk_text'][:1000])  # Display only the first 1000 characters of the chunk text\n",
    "        print(\"\\nGenerated Metadata:\")\n",
    "\n",
    "        # Display the generated metadata content\n",
    "        print(result['metadata'])\n",
    "        print(\"\\n\" + \"-\"*80 + \"\\n\")\n",
    "\n",
    "# Function to pick a specific chunk by index\n",
    "def pick_chunks_by_index(indices, texts):\n",
    "    selected_chunks = [texts[i] for i in indices if i < len(texts)]\n",
    "    return selected_chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5J9MlGKMega",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 919,
     "status": "ok",
     "timestamp": 1730188245645,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 300
    },
    "id": "d5J9MlGKMega",
    "outputId": "ad5ec487-e240-43b9-cc5c-806cbe2d85cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk Index: 0\n",
      "Chunk Text (truncated):\n",
      "def func(a, b): return (a ** 2 + b ** 2) ** 0.5\n",
      "\n",
      "Generated Metadata:\n",
      "## Topic Headings & Tags:\n",
      "\n",
      "**1. Python Function Definition** \n",
      "\n",
      "**Tags:** Python, function, definition, math, square root, hypotenuse\n",
      "\n",
      "**2. Calculating the Euclidean Distance**\n",
      "\n",
      "**Tags:** Python, function, distance, Euclidean, math, formula,  geometry \n",
      "\n",
      "**3.  Pythagorean Theorem Implementation**\n",
      "\n",
      "**Tags:** Python, function,  Pythagorean Theorem,  math,  hypotenuse,  legs \n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example usage: pick chunk(s) by index\n",
    "indices = [2]  # Update this list with indices of chunks you want to process\n",
    "selected_chunks = pick_chunks_by_index(indices, texts)\n",
    "\n",
    "# Generate metadata for the selected chunks\n",
    "results = generate_metadata_for_chunks(model, selected_chunks)\n",
    "\n",
    "# Output the results to inspect the metadata\n",
    "display_metadata_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0c8678",
   "metadata": {},
   "source": [
    "### Metadata Gen with Azure OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "762f03af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "# Retrieve Azure OpenAI specific configuration from environment variables\n",
    "OPENAI_API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "OPENAI_API_TYPE = \"Azure\"\n",
    "OPENAI_API_BASE = \"https://testopenaisaturday.openai.azure.com/\"\n",
    "OPENAI_API_VERSION = \"2023-10-01-preview\"\n",
    "\n",
    "# Initialize Azure OpenAI model\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_deployment=\"varelabsAssistant\",  # Specify your deployment name\n",
    "    api_version=OPENAI_API_VERSION,\n",
    "    temperature=0.5,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")\n",
    "\n",
    "# Function to generate metadata for each chunk\n",
    "def generate_metadata_for_chunks(llm, chunks, max_tokens=2048):\n",
    "    \"\"\"Generate metadata for each chunk using Azure OpenAI model.\"\"\"\n",
    "    results = []\n",
    "    print(\"Starting metadata generation for chunks...\")\n",
    "\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        # Truncate the chunk if it exceeds the max_tokens limit\n",
    "        truncated_chunk = chunk[:max_tokens]\n",
    "\n",
    "        # Define the prompt for metadata generation\n",
    "        prompt = f\"\"\"\n",
    "        The following text is a chunk from a larger document. Please generate the 2-3 most relevant topic headings and tags for this text:\n",
    "        Text: \"{truncated_chunk}\"\n",
    "        \"\"\"\n",
    "\n",
    "        # Use Azure OpenAI model to generate content based on the prompt\n",
    "        response = llm.invoke({\n",
    "            \"role\": \"system\",\n",
    "            \"content\": prompt\n",
    "        })\n",
    "\n",
    "        # Store the response metadata (topic headings and tags)\n",
    "        results.append({\n",
    "            \"chunk_index\": i,\n",
    "            \"chunk_text\": truncated_chunk,\n",
    "            \"metadata\": response['choices'][0]['message']['content']\n",
    "        })\n",
    "        \n",
    "        # Print progress every 100 chunks\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f\"Processed {i + 1} chunks...\")\n",
    "\n",
    "    print(f\"Metadata generation completed. Total chunks processed: {len(chunks)}\")\n",
    "    return results\n",
    "\n",
    "# Display the results with truncated chunk text and the most relevant metadata\n",
    "def display_metadata_results(results):\n",
    "    \"\"\"Display metadata results for each processed chunk.\"\"\"\n",
    "    print(\"Displaying metadata for processed chunks:\")\n",
    "    for result in results:\n",
    "        print(f\"Chunk Index: {result['chunk_index']}\")\n",
    "        print(\"Chunk Text (truncated):\")\n",
    "        print(result['chunk_text'][:1000])  # Display only the first 1000 characters of the chunk text\n",
    "        print(\"\\nGenerated Metadata:\")\n",
    "\n",
    "        # Display the generated metadata content\n",
    "        print(result['metadata'])\n",
    "        print(\"\\n\" + \"-\"*80 + \"\\n\")\n",
    "\n",
    "# Function to pick specific chunks by index\n",
    "def pick_chunks_by_index(indices, texts):\n",
    "    \"\"\"Select specific chunks by their indices for targeted processing.\"\"\"\n",
    "    selected_chunks = [texts[i] for i in indices if i < len(texts)]\n",
    "    print(f\"Picked {len(selected_chunks)} chunks by index for focused processing.\")\n",
    "    return selected_chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b043b84c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting metadata generation for chunks...\n",
      "Processed 100 chunks out of 4437\n",
      "Processed 200 chunks out of 4437\n",
      "Processed 300 chunks out of 4437\n",
      "Processed 400 chunks out of 4437\n",
      "Processed 500 chunks out of 4437\n",
      "Processed 600 chunks out of 4437\n",
      "Processed 700 chunks out of 4437\n",
      "Processed 800 chunks out of 4437\n",
      "Processed 900 chunks out of 4437\n",
      "Processed 1000 chunks out of 4437\n",
      "Processed 1100 chunks out of 4437\n",
      "Processed 1200 chunks out of 4437\n",
      "Processed 1300 chunks out of 4437\n",
      "Processed 1400 chunks out of 4437\n",
      "Processed 1500 chunks out of 4437\n",
      "Processed 1600 chunks out of 4437\n",
      "Processed 1700 chunks out of 4437\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema import BaseMessage, HumanMessage\n",
    "import json\n",
    "\n",
    "# Function to generate metadata for each chunk and save it to a JSON file\n",
    "def generate_and_save_metadata(llm, chunks, output_file=\"metadata_results.json\", max_tokens=2048):\n",
    "    \"\"\"Generates metadata for each chunk and saves the results to a JSON file.\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    print(\"Starting metadata generation for chunks...\")\n",
    "    \n",
    "    for i, chunk in enumerate(chunks):\n",
    "        # Truncate the chunk if it exceeds the max_tokens limit\n",
    "        truncated_chunk = chunk[:max_tokens]\n",
    "\n",
    "        # Define the prompt for metadata generation\n",
    "        prompt = f\"\"\"\n",
    "        The following text is a chunk from a larger document. Please generate the 2-3 most relevant topic headings and tags for this text:\n",
    "        Text: \"{truncated_chunk}\"\n",
    "        \"\"\"\n",
    "\n",
    "        # Use Azure OpenAI model to generate content based on the prompt\n",
    "        response = llm.invoke([\n",
    "            HumanMessage(content=prompt)\n",
    "        ])\n",
    "\n",
    "        # Store the response metadata (topic headings and tags)\n",
    "        results.append({\n",
    "            \"chunk_index\": i,\n",
    "            \"chunk_text\": truncated_chunk,\n",
    "            \"metadata\": response.content  # Directly access the content of AIMessage\n",
    "        })\n",
    "\n",
    "        # Print progress every 100 chunks\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f\"Processed {i + 1} chunks out of {len(chunks)}\")\n",
    "\n",
    "    # Save results to a JSON file\n",
    "    with open(output_file, \"w\") as file:\n",
    "        json.dump(results, file, indent=4)\n",
    "\n",
    "    print(f\"Metadata saved to {output_file}\")\n",
    "    return results\n",
    "\n",
    "# Example usage with chunks and llm\n",
    "metadata_results = generate_and_save_metadata(llm, chunks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0b7849",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee342dc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d8cd82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "A0QvIW9_jH7Z",
   "metadata": {
    "id": "A0QvIW9_jH7Z"
   },
   "source": [
    "## Embedings : Split and add metadata with chunks to Vector DB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nkSBdsojSnIS",
   "metadata": {
    "id": "nkSBdsojSnIS"
   },
   "source": [
    "## Embedd metadata with chunks on Pinecode Vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "Htqqd9fTNBhu",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22360,
     "status": "ok",
     "timestamp": 1730189010139,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 300
    },
    "id": "Htqqd9fTNBhu",
    "outputId": "a61e658e-2eb0-47ed-f509-5fb8455815c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your Pinecone API key: 1203aeba-36cc-4ede-9dc6-1f01153fbde8\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "import tiktoken  # Ensure tiktoken is installed if used for chunk tokenization\n",
    "\n",
    "# Initialize Pinecone\n",
    "pinecone_api_key = os.getenv(\"PINECONE_API_KEY\") or input(\"Enter your Pinecone API key: \")\n",
    "pc = Pinecone(api_key=pinecone_api_key)\n",
    "index_name = \"capstone-indexed-chunks\"  # change if desired\n",
    "\n",
    "# Delete existing index if dimension mismatch\n",
    "existing_indexes = [index_info[\"name\"] for index_info in pc.list_indexes()]\n",
    "if index_name in existing_indexes:\n",
    "    pc.delete_index(index_name)\n",
    "\n",
    "# Create index with the correct dimension (384 for avsolatorio/NoInstruct-small-Embedding-v0)\n",
    "pc.create_index(\n",
    "    name=index_name,\n",
    "    dimension=384,\n",
    "    metric=\"cosine\",\n",
    "    spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n",
    ")\n",
    "\n",
    "# Wait until the index is ready\n",
    "while not pc.describe_index(index_name).status[\"ready\"]:\n",
    "    time.sleep(1)\n",
    "\n",
    "# Re-initialize the index after creation\n",
    "index = pc.Index(index_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "pbCXH9vWNFcm",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1377,
     "status": "ok",
     "timestamp": 1730189026660,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 300
    },
    "id": "pbCXH9vWNFcm",
    "outputId": "70b56223-66b0-4edc-d2f6-c613c61f44bb"
   },
   "outputs": [],
   "source": [
    "# Load the embedding model\n",
    "MODEL_NAME = \"avsolatorio/NoInstruct-small-Embedding-v0\"\n",
    "embedding_model = AutoModel.from_pretrained(MODEL_NAME)\n",
    "embedding_tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# Function to compute embeddings\n",
    "def get_embedding(text, mode=\"sentence\"):\n",
    "    embedding_model.eval()\n",
    "    inp = embedding_tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        output = embedding_model(**inp)\n",
    "    return output.last_hidden_state[:, 0, :].numpy()  # [CLS] token representation\n",
    "\n",
    "# Function to index semantic chunks and metadata in Pinecone\n",
    "def index_chunks_with_metadata(index, chunks, metadata):\n",
    "    # Process each chunk, compute embeddings, and store it in Pinecone\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        # Generate embedding for the chunk\n",
    "        embedding = get_embedding(chunk).flatten().tolist()\n",
    "\n",
    "        # Prepare metadata for Pinecone\n",
    "        doc_metadata = {\n",
    "            \"topics\": metadata[i].get(\"topics\", []),\n",
    "            \"tags\": metadata[i].get(\"tags\", []),\n",
    "            \"text\": chunk  # Storing the text as part of metadata if desired\n",
    "        }\n",
    "\n",
    "        # Index each chunk in Pinecone\n",
    "        index.upsert(\n",
    "            [(f\"chunk-{i}\", embedding, doc_metadata)]\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607706ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Assuming `chunks` and `metadata` are already generated\n",
    "# chunks = semantic_chunking(pdf_text)\n",
    "# metadata = generate_metadata_for_chunks(model, chunks)\n",
    "\n",
    "# Index the chunks with metadata\n",
    "index_chunks_with_metadata(index, chunks, metadata)\n",
    "\n",
    "print(\"Data and metadata successfully indexed in Pinecone.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd392212",
   "metadata": {},
   "source": [
    "#### Uplaod indexed chunks to pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67d421d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from pinecone import Pinecone\n",
    "\n",
    "# Function to load JSON file containing chunks and metadata\n",
    "def load_json_chunks(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "    chunks = [item[\"content\"] for item in data]\n",
    "    metadata = [{\"topics\": item[\"title\"]} for item in data]\n",
    "    return chunks, metadata\n",
    "\n",
    "# Load the embedding model\n",
    "MODEL_NAME = \"avsolatorio/NoInstruct-small-Embedding-v0\"\n",
    "embedding_model = AutoModel.from_pretrained(MODEL_NAME)\n",
    "embedding_tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# Function to compute embeddings\n",
    "def get_embedding(text, mode=\"sentence\"):\n",
    "    embedding_model.eval()\n",
    "    inp = embedding_tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        output = embedding_model(**inp)\n",
    "    return output.last_hidden_state[:, 0, :].numpy()  # [CLS] token representation\n",
    "\n",
    "# Helper function to check and truncate metadata if needed\n",
    "def check_and_truncate_metadata(metadata, chunk_text):\n",
    "    import sys\n",
    "    import warnings\n",
    "\n",
    "    # Create metadata with content, ensuring it’s within size limits\n",
    "    metadata_str = f\"{metadata}\"\n",
    "    if sys.getsizeof(metadata_str) > 40960:  # 40 KB size check\n",
    "        warnings.warn(f\"Metadata for chunk exceeded 40 KB, truncating metadata.\")\n",
    "        metadata[\"text\"] = chunk_text[:200] + \"...\"  # Truncate text\n",
    "    return metadata\n",
    "\n",
    "# Function to index semantic chunks and metadata in Pinecone\n",
    "def index_chunks_with_metadata(index, chunks, metadata):\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        # Generate embedding for the chunk\n",
    "        embedding = get_embedding(chunk).flatten().tolist()\n",
    "\n",
    "        # Prepare metadata and ensure it's within the size limit\n",
    "        doc_metadata = {\n",
    "            \"topics\": metadata[i].get(\"topics\", \"\"),\n",
    "            \"text\": chunk[:200]  # Truncate text to prevent excessive metadata size\n",
    "        }\n",
    "        doc_metadata = check_and_truncate_metadata(doc_metadata, chunk)\n",
    "\n",
    "        # Index each chunk in Pinecone\n",
    "        index.upsert(\n",
    "            [(f\"chunk-{i}\", embedding, doc_metadata)]\n",
    "        )\n",
    "        \n",
    "        # Print progress every 100 chunks\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f\"Indexed {i + 1} chunks so far.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "43915bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 100 chunks so far.\n",
      "Indexed 200 chunks so far.\n",
      "Indexed 300 chunks so far.\n",
      "Indexed 400 chunks so far.\n",
      "Data and metadata successfully indexed in Pinecone.\n"
     ]
    }
   ],
   "source": [
    "# Load chunks and metadata from JSON file\n",
    "file_path = \"s3-userguide-chunks.json\"  # Path to your JSON file\n",
    "chunks, metadata = load_json_chunks(file_path)\n",
    "\n",
    "# Index the chunks with metadata\n",
    "index_chunks_with_metadata(index, chunks, metadata)\n",
    "\n",
    "print(\"Data and metadata successfully indexed in Pinecone.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bOUD3g3cThB6",
   "metadata": {
    "id": "bOUD3g3cThB6"
   },
   "source": [
    "### **Verify Embedding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8GWhi9aeNHx_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 624,
     "status": "ok",
     "timestamp": 1730189101039,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 300
    },
    "id": "8GWhi9aeNHx_",
    "outputId": "699970c0-c171-4325-f0dc-a815260e89cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved Chunk Metadata and Embedding:\n",
      "{'namespace': '',\n",
      " 'usage': {'read_units': 1},\n",
      " 'vectors': {'chunk-0': {'id': 'chunk-0',\n",
      "                         'metadata': {'text': '',\n",
      "                                      'topics': 'What is Amazon S3? '\n",
      "                                                '........................................................................................................................'},\n",
      "                         'values': [0.285306126,\n",
      "                                    -0.117097296,\n",
      "                                    0.279554158,\n",
      "                                    -0.292920738,\n",
      "                                    0.0225107074,\n",
      "                                    0.60063827,\n",
      "                                    0.358730435,\n",
      "                                    0.426127017,\n",
      "                                    0.09043172,\n",
      "                                    -0.22232312,\n",
      "                                    0.0863945708,\n",
      "                                    -0.946399152,\n",
      "                                    0.0290437303,\n",
      "                                    0.435297906,\n",
      "                                    -0.0189985652,\n",
      "                                    -0.190097794,\n",
      "                                    0.108566411,\n",
      "                                    0.589170158,\n",
      "                                    -0.156984419,\n",
      "                                    -0.0131953806,\n",
      "                                    0.158462107,\n",
      "                                    -0.327958196,\n",
      "                                    0.267324895,\n",
      "                                    -0.161951557,\n",
      "                                    0.192522526,\n",
      "                                    0.112634189,\n",
      "                                    -0.0566924065,\n",
      "                                    -0.524140835,\n",
      "                                    -0.69210887,\n",
      "                                    -2.07930088,\n",
      "                                    0.183964908,\n",
      "                                    -0.710728884,\n",
      "                                    0.203339651,\n",
      "                                    -0.146567702,\n",
      "                                    -0.172905236,\n",
      "                                    -0.153737873,\n",
      "                                    -0.174710244,\n",
      "                                    0.157124043,\n",
      "                                    0.0960394219,\n",
      "                                    0.128941447,\n",
      "                                    0.223254919,\n",
      "                                    0.150486231,\n",
      "                                    -0.589909375,\n",
      "                                    -0.0378514156,\n",
      "                                    -0.140743732,\n",
      "                                    -0.16816844,\n",
      "                                    0.0589635,\n",
      "                                    -0.0822063237,\n",
      "                                    0.76179868,\n",
      "                                    -0.243941873,\n",
      "                                    0.216758609,\n",
      "                                    -0.526834905,\n",
      "                                    0.314698815,\n",
      "                                    0.548675299,\n",
      "                                    -0.01685239,\n",
      "                                    0.163734704,\n",
      "                                    0.0753393546,\n",
      "                                    -0.120199166,\n",
      "                                    0.243538231,\n",
      "                                    0.397039801,\n",
      "                                    -0.0033914,\n",
      "                                    0.380639374,\n",
      "                                    -2.23043823,\n",
      "                                    0.546957314,\n",
      "                                    0.0913948938,\n",
      "                                    -0.00361853093,\n",
      "                                    -0.0467863381,\n",
      "                                    0.194133982,\n",
      "                                    0.345546037,\n",
      "                                    0.219076455,\n",
      "                                    -0.347011805,\n",
      "                                    0.149535716,\n",
      "                                    0.200935096,\n",
      "                                    0.633930564,\n",
      "                                    0.355975598,\n",
      "                                    0.0433533713,\n",
      "                                    0.20321098,\n",
      "                                    -0.437766671,\n",
      "                                    0.0958659351,\n",
      "                                    0.0134357326,\n",
      "                                    0.00952780806,\n",
      "                                    0.0864797756,\n",
      "                                    0.182863355,\n",
      "                                    -0.0876551867,\n",
      "                                    -0.267507821,\n",
      "                                    -0.456852317,\n",
      "                                    -0.0713441074,\n",
      "                                    -0.379455924,\n",
      "                                    0.482648909,\n",
      "                                    0.269508153,\n",
      "                                    -0.342683077,\n",
      "                                    -0.262180924,\n",
      "                                    -0.414117426,\n",
      "                                    0.0246809684,\n",
      "                                    -0.55223608,\n",
      "                                    -0.112239912,\n",
      "                                    -0.103735954,\n",
      "                                    -0.265445471,\n",
      "                                    -0.0465437472,\n",
      "                                    3.56933403,\n",
      "                                    -0.57641381,\n",
      "                                    -0.00963950157,\n",
      "                                    -0.0298215374,\n",
      "                                    -0.299856067,\n",
      "                                    0.130687177,\n",
      "                                    -0.325895846,\n",
      "                                    -0.0301064625,\n",
      "                                    -0.171276078,\n",
      "                                    -0.119118631,\n",
      "                                    0.204827189,\n",
      "                                    0.169813976,\n",
      "                                    -0.0288169384,\n",
      "                                    0.269132972,\n",
      "                                    -0.0138581172,\n",
      "                                    -0.0107512623,\n",
      "                                    0.426507026,\n",
      "                                    0.599476635,\n",
      "                                    0.227917254,\n",
      "                                    -0.267661333,\n",
      "                                    -0.155139029,\n",
      "                                    -0.0732327551,\n",
      "                                    -0.0932065398,\n",
      "                                    -0.119562328,\n",
      "                                    -0.464981467,\n",
      "                                    0.190412953,\n",
      "                                    -0.38267225,\n",
      "                                    0.460285574,\n",
      "                                    1.04922807,\n",
      "                                    0.367306679,\n",
      "                                    0.227126986,\n",
      "                                    0.425130367,\n",
      "                                    0.169821307,\n",
      "                                    -0.211435556,\n",
      "                                    0.0427557454,\n",
      "                                    0.112201944,\n",
      "                                    0.128092512,\n",
      "                                    0.227289215,\n",
      "                                    -0.236110941,\n",
      "                                    -0.19440797,\n",
      "                                    0.0481957942,\n",
      "                                    -0.115044653,\n",
      "                                    -0.660565853,\n",
      "                                    0.0938183516,\n",
      "                                    -1.24208772,\n",
      "                                    -0.0534378886,\n",
      "                                    0.898461342,\n",
      "                                    -0.129206076,\n",
      "                                    -0.268039733,\n",
      "                                    -0.730818,\n",
      "                                    -0.0193321183,\n",
      "                                    0.107161231,\n",
      "                                    0.347263664,\n",
      "                                    0.0113328323,\n",
      "                                    0.168332964,\n",
      "                                    0.0893494338,\n",
      "                                    -0.0624404475,\n",
      "                                    0.198975801,\n",
      "                                    0.062641263,\n",
      "                                    -0.164969414,\n",
      "                                    0.142802298,\n",
      "                                    -0.330265433,\n",
      "                                    -0.378876209,\n",
      "                                    -0.297552407,\n",
      "                                    0.656631947,\n",
      "                                    -0.13152875,\n",
      "                                    -0.774086058,\n",
      "                                    -0.20643416,\n",
      "                                    0.115116403,\n",
      "                                    0.108705074,\n",
      "                                    0.0141092166,\n",
      "                                    0.0630061701,\n",
      "                                    0.136774167,\n",
      "                                    -0.18289271,\n",
      "                                    0.205983534,\n",
      "                                    0.615598917,\n",
      "                                    0.334947169,\n",
      "                                    -0.455229968,\n",
      "                                    -0.0915019959,\n",
      "                                    -0.165934324,\n",
      "                                    -0.00313531235,\n",
      "                                    0.165925607,\n",
      "                                    -0.155113161,\n",
      "                                    -0.447999328,\n",
      "                                    0.227752209,\n",
      "                                    0.52031225,\n",
      "                                    -0.441053033,\n",
      "                                    -0.233774126,\n",
      "                                    -0.15091987,\n",
      "                                    0.290431648,\n",
      "                                    0.382913947,\n",
      "                                    -0.151728183,\n",
      "                                    0.44912371,\n",
      "                                    -0.171020612,\n",
      "                                    -0.00391256157,\n",
      "                                    -0.155788183,\n",
      "                                    -0.238297746,\n",
      "                                    -0.384634316,\n",
      "                                    -0.393840194,\n",
      "                                    -0.145196438,\n",
      "                                    -0.268340349,\n",
      "                                    0.89995259,\n",
      "                                    -0.00535167288,\n",
      "                                    -0.270551145,\n",
      "                                    0.578238249,\n",
      "                                    0.127448246,\n",
      "                                    0.117812917,\n",
      "                                    -0.102764405,\n",
      "                                    0.102243334,\n",
      "                                    0.121103227,\n",
      "                                    0.00118398666,\n",
      "                                    -0.15260081,\n",
      "                                    0.3127985,\n",
      "                                    0.770146728,\n",
      "                                    0.15206255,\n",
      "                                    -0.0983547643,\n",
      "                                    -0.296223879,\n",
      "                                    0.253805608,\n",
      "                                    0.363570839,\n",
      "                                    -0.202397913,\n",
      "                                    0.0365430526,\n",
      "                                    0.431329548,\n",
      "                                    0.167895913,\n",
      "                                    0.119458631,\n",
      "                                    -3.15402246,\n",
      "                                    0.317321867,\n",
      "                                    0.117572762,\n",
      "                                    0.102978051,\n",
      "                                    -0.0742787123,\n",
      "                                    -0.0309592187,\n",
      "                                    -0.00848640501,\n",
      "                                    -0.133748323,\n",
      "                                    0.296529,\n",
      "                                    0.245157301,\n",
      "                                    0.913014233,\n",
      "                                    0.0813318491,\n",
      "                                    -0.517592549,\n",
      "                                    0.519047618,\n",
      "                                    0.0791521594,\n",
      "                                    0.66887033,\n",
      "                                    0.347503424,\n",
      "                                    -0.128234819,\n",
      "                                    0.150302991,\n",
      "                                    -0.217418745,\n",
      "                                    0.0853575468,\n",
      "                                    0.20084998,\n",
      "                                    -0.07727319,\n",
      "                                    -0.101897769,\n",
      "                                    0.798220098,\n",
      "                                    -0.0327512473,\n",
      "                                    2.29323936,\n",
      "                                    0.320976079,\n",
      "                                    -0.0345208496,\n",
      "                                    -0.265623033,\n",
      "                                    0.0620365553,\n",
      "                                    0.0860259235,\n",
      "                                    -0.231690079,\n",
      "                                    -0.887519121,\n",
      "                                    0.0109815896,\n",
      "                                    0.00862497836,\n",
      "                                    -0.182767868,\n",
      "                                    -0.130835831,\n",
      "                                    -0.841272354,\n",
      "                                    -0.251799464,\n",
      "                                    0.00621268898,\n",
      "                                    0.193261102,\n",
      "                                    -0.178501651,\n",
      "                                    -0.365589797,\n",
      "                                    0.289294302,\n",
      "                                    -0.349693328,\n",
      "                                    0.0363701731,\n",
      "                                    0.484131068,\n",
      "                                    -0.0605077893,\n",
      "                                    -0.201237753,\n",
      "                                    0.358297259,\n",
      "                                    -0.0896731243,\n",
      "                                    0.422554553,\n",
      "                                    0.170278713,\n",
      "                                    0.0450913981,\n",
      "                                    -0.324340701,\n",
      "                                    -0.140774369,\n",
      "                                    -0.13689515,\n",
      "                                    -0.310095072,\n",
      "                                    0.0709423274,\n",
      "                                    0.281198114,\n",
      "                                    0.17761454,\n",
      "                                    -0.251123607,\n",
      "                                    -0.499281883,\n",
      "                                    0.139461145,\n",
      "                                    -0.0660688877,\n",
      "                                    -0.214535207,\n",
      "                                    -0.28517729,\n",
      "                                    0.084380284,\n",
      "                                    0.0405298546,\n",
      "                                    -0.438544244,\n",
      "                                    0.215080082,\n",
      "                                    0.218202323,\n",
      "                                    -0.19906415,\n",
      "                                    0.579587281,\n",
      "                                    0.392168641,\n",
      "                                    0.387022138,\n",
      "                                    -0.268755376,\n",
      "                                    -0.473519504,\n",
      "                                    -0.214385822,\n",
      "                                    0.284049332,\n",
      "                                    -0.350339502,\n",
      "                                    0.296394229,\n",
      "                                    0.0429474376,\n",
      "                                    0.565876186,\n",
      "                                    0.310227185,\n",
      "                                    0.32155332,\n",
      "                                    -0.240406364,\n",
      "                                    0.209734231,\n",
      "                                    -0.426530838,\n",
      "                                    0.0361527242,\n",
      "                                    0.228944331,\n",
      "                                    -0.195409596,\n",
      "                                    -0.655186772,\n",
      "                                    0.022183571,\n",
      "                                    -0.0411736742,\n",
      "                                    -3.42742896,\n",
      "                                    0.1209604,\n",
      "                                    0.0518591031,\n",
      "                                    -0.209734023,\n",
      "                                    -0.43363753,\n",
      "                                    0.231137663,\n",
      "                                    -0.0219027922,\n",
      "                                    0.0646231398,\n",
      "                                    -0.130815282,\n",
      "                                    0.0398051664,\n",
      "                                    0.125224039,\n",
      "                                    0.168816984,\n",
      "                                    0.311823696,\n",
      "                                    -0.0191941652,\n",
      "                                    -0.0309057981,\n",
      "                                    0.380005419,\n",
      "                                    1.04835808,\n",
      "                                    -0.388737947,\n",
      "                                    0.222021252,\n",
      "                                    -0.353281021,\n",
      "                                    -0.0259340927,\n",
      "                                    0.281907588,\n",
      "                                    2.41359687,\n",
      "                                    -0.202425033,\n",
      "                                    0.508219719,\n",
      "                                    -0.0475675687,\n",
      "                                    -0.20413363,\n",
      "                                    -0.127618894,\n",
      "                                    0.041902367,\n",
      "                                    -0.111758731,\n",
      "                                    0.424393713,\n",
      "                                    0.106955782,\n",
      "                                    0.72163856,\n",
      "                                    -0.369269788,\n",
      "                                    0.203387558,\n",
      "                                    0.375243783,\n",
      "                                    -0.24726069,\n",
      "                                    0.529522479,\n",
      "                                    -0.162852585,\n",
      "                                    -0.0939976871,\n",
      "                                    -0.530634046,\n",
      "                                    -0.0462400205,\n",
      "                                    -0.728078246,\n",
      "                                    -0.351926088,\n",
      "                                    0.607823253,\n",
      "                                    -0.463307738,\n",
      "                                    -0.124766588,\n",
      "                                    -0.429158121,\n",
      "                                    0.105412535,\n",
      "                                    0.174050152,\n",
      "                                    -0.0593902655,\n",
      "                                    -0.0451246426,\n",
      "                                    -0.166371107,\n",
      "                                    0.0798607692,\n",
      "                                    0.346208155,\n",
      "                                    -0.284913719,\n",
      "                                    0.0208273083,\n",
      "                                    -0.347305298,\n",
      "                                    -0.203043506,\n",
      "                                    -0.380137861,\n",
      "                                    -0.0732477456,\n",
      "                                    -0.476550698,\n",
      "                                    -0.370238721,\n",
      "                                    0.368753403,\n",
      "                                    0.412253678]}}}\n"
     ]
    }
   ],
   "source": [
    "# Check a specific chunk in Pinecone by ID (e.g., \"chunk-0\")\n",
    "chunk_id = \"chunk-0\"  # replace with any valid ID\n",
    "result = index.fetch(ids=[chunk_id])\n",
    "\n",
    "# Display the retrieved metadata and embedding\n",
    "print(\"Retrieved Chunk Metadata and Embedding:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "AHOG9R0iOWPe",
   "metadata": {
    "id": "AHOG9R0iOWPe"
   },
   "source": [
    "# Integrate LLM with chain and chat History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BuAjRtbMScTf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3965,
     "status": "ok",
     "timestamp": 1730255905280,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 300
    },
    "id": "BuAjRtbMScTf",
    "outputId": "834d602c-f981-4cd3-9ca7-037029890675",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-pinecone in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
      "Requirement already satisfied: aiohttp<3.10,>=3.9.5 in /usr/local/lib/python3.10/dist-packages (from langchain-pinecone) (3.9.5)\n",
      "Requirement already satisfied: langchain-core<0.4,>=0.3 in /usr/local/lib/python3.10/dist-packages (from langchain-pinecone) (0.3.13)\n",
      "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-pinecone) (1.26.4)\n",
      "Requirement already satisfied: pinecone-client<6.0.0,>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain-pinecone) (5.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<3.10,>=3.9.5->langchain-pinecone) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<3.10,>=3.9.5->langchain-pinecone) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<3.10,>=3.9.5->langchain-pinecone) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<3.10,>=3.9.5->langchain-pinecone) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<3.10,>=3.9.5->langchain-pinecone) (1.15.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<3.10,>=3.9.5->langchain-pinecone) (4.0.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3->langchain-pinecone) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3->langchain-pinecone) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3->langchain-pinecone) (0.1.137)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3->langchain-pinecone) (24.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3->langchain-pinecone) (2.9.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3->langchain-pinecone) (9.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3->langchain-pinecone) (4.12.2)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.10/dist-packages (from pinecone-client<6.0.0,>=5.0.0->langchain-pinecone) (2024.8.30)\n",
      "Requirement already satisfied: pinecone-plugin-inference<2.0.0,>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from pinecone-client<6.0.0,>=5.0.0->langchain-pinecone) (1.1.0)\n",
      "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from pinecone-client<6.0.0,>=5.0.0->langchain-pinecone) (0.0.7)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from pinecone-client<6.0.0,>=5.0.0->langchain-pinecone) (4.66.5)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client<6.0.0,>=5.0.0->langchain-pinecone) (2.2.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.3->langchain-pinecone) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3->langchain-pinecone) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3->langchain-pinecone) (3.10.10)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3->langchain-pinecone) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3->langchain-pinecone) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.3->langchain-pinecone) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.3->langchain-pinecone) (2.23.4)\n",
      "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.0->aiohttp<3.10,>=3.9.5->langchain-pinecone) (3.10)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.0->aiohttp<3.10,>=3.9.5->langchain-pinecone) (0.2.0)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3->langchain-pinecone) (3.7.1)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3->langchain-pinecone) (1.0.6)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3->langchain-pinecone) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3->langchain-pinecone) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3->langchain-pinecone) (3.4.0)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3->langchain-pinecone) (1.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U langchain-pinecone\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4Q0IFtwKPuwH",
   "metadata": {
    "id": "4Q0IFtwKPuwH"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pGeGewNYOlo_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2313,
     "status": "ok",
     "timestamp": 1730257555139,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 300
    },
    "id": "pGeGewNYOlo_",
    "outputId": "9da13eb7-636f-4c95-a3b4-2588e8666758"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to index 'langchain-test-index' in Pinecone.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from langchain_pinecone import Pinecone as LangchainPinecone\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.embeddings.base import Embeddings\n",
    "from langchain.llms.base import LLM\n",
    "from typing import Optional, List\n",
    "\n",
    "import vertexai\n",
    "from vertexai.generative_models import GenerativeModel\n",
    "\n",
    "# Initialize Vertex AI for Google Gemini model\n",
    "PROJECT_ID = \"ids-560-project-group-1-bosch\"\n",
    "vertexai.init(project=PROJECT_ID, location=\"us-central1\")\n",
    "gemini_model = GenerativeModel(\"gemini-1.5-flash\")\n",
    "\n",
    "# Custom wrapper for Google Gemini to make it compatible with LangChain\n",
    "class RunnableGemini(LLM):\n",
    "    def __init__(self, model: GenerativeModel):\n",
    "        super().__init__()\n",
    "        self._model = model\n",
    "\n",
    "    def _call(self, prompt: str, stop: Optional[List[str]] = None) -> str:\n",
    "        response = self._model.generate_content(prompt)\n",
    "        return response.text\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"google_gemini\"\n",
    "\n",
    "# Instantiate the wrapped model\n",
    "llm = RunnableGemini(gemini_model)\n",
    "\n",
    "# Load the embedding model for the retriever function\n",
    "MODEL_NAME = \"avsolatorio/NoInstruct-small-Embedding-v0\"\n",
    "embedding_model = AutoModel.from_pretrained(MODEL_NAME)\n",
    "embedding_tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# Custom LangChain Embedding wrapper\n",
    "class HFEmbeddingWrapper(Embeddings):\n",
    "    def embed_query(self, text: str) -> List[float]:\n",
    "        return get_embedding(text).flatten().tolist()\n",
    "\n",
    "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "        return [get_embedding(text).flatten().tolist() for text in texts]\n",
    "\n",
    "# Initialize the custom embedding wrapper\n",
    "embedding = HFEmbeddingWrapper()\n",
    "\n",
    "# Initialize Pinecone client\n",
    "pinecone_api_key = os.getenv(\"PINECONE_API_KEY\") or input(\"Enter your Pinecone API key: \")\n",
    "pc = Pinecone(api_key=pinecone_api_key)\n",
    "index_name = \"langchain-test-index\"\n",
    "\n",
    "# Check if the index exists; if not, create it with dimension 384\n",
    "if index_name not in [index_info[\"name\"] for index_info in pc.list_indexes()]:\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=384,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n",
    "    )\n",
    "index = pc.Index(index_name)\n",
    "print(f\"Connected to index '{index_name}' in Pinecone.\")\n",
    "\n",
    "# Initialize LangChain Pinecone Retriever with embedding wrapper\n",
    "vectorstore = LangchainPinecone(index=index, embedding=embedding)\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5})\n",
    "\n",
    "# Define the QA PromptTemplate for debugging and documentation assistance\n",
    "QA_PROMPT = PromptTemplate.from_template(\"\"\"\n",
    "You are an expert code debugger and documentation assistant. Help answer technical queries based on the script provided, offering solutions, clarifications, or steps as needed. Use precise language and avoid assumptions. Refer to the documentation context for direct responses.\n",
    "\n",
    "Documentation Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Answer:\n",
    "\"\"\")\n",
    "\n",
    "# Set up the conversational retrieval chain with the custom Gemini wrapper\n",
    "qa_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    condense_question_prompt=QA_PROMPT,\n",
    "    combine_docs_chain_kwargs={\"prompt\": QA_PROMPT},\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "# Function to maintain conversation history in the RAG chain\n",
    "def ask_question_with_history(qa_chain, question, chat_history):\n",
    "    result = qa_chain.invoke({\"question\": question, \"chat_history\": chat_history})\n",
    "    print(\"Response:\", result[\"answer\"])\n",
    "    chat_history.append((question, result[\"answer\"]))\n",
    "    return chat_history\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ho54mv6rOlgs",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5120,
     "status": "ok",
     "timestamp": 1730257769134,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 300
    },
    "id": "ho54mv6rOlgs",
    "outputId": "56c4d384-c171-4888-a176-d7a48a27b05d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: To help you with installation errors in Python, I need more information!  Please tell me:\n",
      "\n",
      "* **What are you trying to install?** (e.g., a specific library like NumPy, a framework like Django, or Python itself?)\n",
      "* **What error message are you seeing?** (Please copy and paste the entire error message)\n",
      "* **What operating system are you using?** (e.g., Windows, macOS, Linux)\n",
      "* **What version of Python do you have?** (You can find this by running `python --version` in your terminal)\n",
      "\n",
      "Once I have this information, I can provide more specific guidance on how to troubleshoot the installation errors. \n",
      "\n",
      "Response: Here are some common techniques for debugging memory leaks in C++:\n",
      "\n",
      "**1. Memory Leak Detection Tools:**\n",
      "\n",
      "* **Valgrind:** A powerful tool that can detect memory leaks, invalid memory accesses, and other memory-related errors. Valgrind is highly effective but can be relatively slow. \n",
      "* **AddressSanitizer (ASan):** Built-in to modern compilers (clang and GCC), ASan is a fast and accurate memory leak detector.\n",
      "* **LeakSanitizer:** Similar to ASan, LeakSanitizer focuses specifically on detecting memory leaks. It's faster than ASan but provides less detailed information about the leak. \n",
      "* **MSVC Memory Leak Detector:** Included in Microsoft Visual C++ (MSVC), this tool helps identify leaks in Windows applications.\n",
      "\n",
      "**2. Manual Debugging:**\n",
      "\n",
      "* **Use a debugger (e.g., gdb):** Step through your code line by line and inspect memory allocation and deallocation.\n",
      "* **Use `malloc_debug`:** This is a library function that can be used to track memory allocations and deallocations. It provides information about where memory was allocated and when it was freed.\n",
      "* **Set breakpoints at memory allocation and deallocation points:** This will allow you to track down the exact location where memory is being leaked.\n",
      "\n",
      "**3. Code Review and Best Practices:**\n",
      "\n",
      "* **Always use RAII (Resource Acquisition Is Initialization):**  Ensure that resources (like memory) are automatically released when an object goes out of scope. Use smart pointers (e.g., `std::unique_ptr`, `std::shared_ptr`) to manage dynamically allocated memory.\n",
      "* **Avoid manual memory management:**  Minimize the use of `new` and `delete` whenever possible. Prefer using containers like `std::vector` and `std::map` which handle memory management for you.\n",
      "* **Check for dangling pointers:**  Dangling pointers point to memory that has been deallocated. Make sure you are not using pointers after the memory they point to has been freed.\n",
      "* **Use `nullptr`:** Initialize pointers to `nullptr` to prevent accidental access to uninitialized memory.\n",
      "\n",
      "**Steps to Debug:**\n",
      "\n",
      "1. **Run your program with a memory leak detector.**\n",
      "2. **Identify the location of the memory leak.**\n",
      "3. **Examine the code around the leak location.**\n",
      "4. **Fix the code to prevent the leak.**\n",
      "5. **Rerun your program with the leak detector to verify the fix.**\n",
      "\n",
      "**Example:**\n",
      "\n",
      "```c++\n",
      "#include <iostream>\n",
      "\n",
      "int main() {\n",
      "  int* ptr = new int; // Memory leak: no delete\n",
      "  *ptr = 5;\n",
      "  std::cout << *ptr << std::endl;\n",
      "\n",
      "  return 0;\n",
      "}\n",
      "```\n",
      "\n",
      "To fix the leak:\n",
      "\n",
      "```c++\n",
      "#include <iostream>\n",
      "\n",
      "int main() {\n",
      "  int* ptr = new int; // Memory leak: no delete\n",
      "  *ptr = 5;\n",
      "  std::cout << *ptr << std::endl;\n",
      "\n",
      "  delete ptr; // Deallocate memory\n",
      "  return 0;\n",
      "}\n",
      "```\n",
      "\n",
      "**Remember:** The best way to prevent memory leaks is to write code that avoids them in the first place. Follow best practices, use memory management tools, and thoroughly test your code.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# Define the QA PromptTemplate with the 'context' and 'question' placeholders\n",
    "QA_PROMPT = PromptTemplate.from_template(\"\"\"\n",
    "You are an assistant helping with error debugging and code understanding. Use the context provided to answer the user's question. If there is no context, let the user know more information is needed.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "User's Question: {question}\n",
    "Answer:\n",
    "\"\"\")\n",
    "\n",
    "# Initialize your LLM and retriever (already defined in your environment)\n",
    "\n",
    "# Create the RetrievalQA chain with the custom prompt and specify the input key\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    input_key=\"question\",  # Specify 'question' as the input key\n",
    "    chain_type_kwargs={\n",
    "        \"prompt\": QA_PROMPT,\n",
    "    },\n",
    "    return_source_documents=True,\n",
    ")\n",
    "\n",
    "# Initialize memory to store conversation history\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", input_key=\"question\")\n",
    "\n",
    "# Function to ask a question with context management\n",
    "def ask_question_with_history(qa_chain, question, memory):\n",
    "    # Retrieve the conversation history\n",
    "    chat_history = memory.load_memory_variables({}).get(\"chat_history\", \"\")\n",
    "\n",
    "    # Prepare the inputs\n",
    "    inputs = {\n",
    "        \"question\": question,  # Use 'question' as the key\n",
    "        \"chat_history\": chat_history,\n",
    "    }\n",
    "\n",
    "    # Call the QA chain with the inputs\n",
    "    result = qa_chain(inputs)\n",
    "\n",
    "    # Display the result and update memory\n",
    "    print(\"Response:\", result[\"result\"])\n",
    "    memory.save_context({\"question\": question}, {\"result\": result[\"result\"]})\n",
    "    return memory\n",
    "\n",
    "# Example usage\n",
    "question = \"What to do with installation errors in Python?\"\n",
    "memory = ask_question_with_history(qa_chain, question, memory)\n",
    "\n",
    "question = \"How can I debug a memory leak in C++?\"\n",
    "memory = ask_question_with_history(qa_chain, question, memory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca7c2f8",
   "metadata": {
    "id": "N26InkWmOkuS"
   },
   "source": [
    "# CHUNKING by PDF Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "753eb90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import re\n",
    "import json\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"Extracts text from each page of the PDF.\"\"\"\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        text = [page.extract_text() for page in reader.pages]\n",
    "    return text\n",
    "\n",
    "def parse_index(index_text):\n",
    "    \"\"\"Parses the index to identify section titles and page numbers.\"\"\"\n",
    "    index_pattern = re.compile(r'^(.*)\\s+(\\d+)$')\n",
    "    sections = []\n",
    "    \n",
    "    for line in index_text.splitlines():\n",
    "        match = index_pattern.match(line)\n",
    "        if match:\n",
    "            section_title, page_number = match.groups()\n",
    "            sections.append({\n",
    "                \"title\": section_title.strip(),\n",
    "                \"start_page\": int(page_number)\n",
    "            })\n",
    "    \n",
    "    return sections\n",
    "\n",
    "def create_chunks(text_by_page, sections):\n",
    "    \"\"\"Creates chunks by mapping sections from the index to content.\"\"\"\n",
    "    chunks = []\n",
    "    \n",
    "    for i, section in enumerate(sections):\n",
    "        start_page = section['start_page'] - 1\n",
    "        end_page = sections[i + 1]['start_page'] - 1 if i + 1 < len(sections) else len(text_by_page)\n",
    "        content = \" \".join(text_by_page[start_page:end_page])\n",
    "        chunks.append({\n",
    "            \"title\": section['title'],\n",
    "            \"content\": content\n",
    "        })\n",
    "    \n",
    "    return chunks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bce09eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_text = \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1zi7RvfbVsZb",
   "metadata": {
    "id": "1zi7RvfbVsZb"
   },
   "outputs": [],
   "source": [
    "# Example Usage\n",
    "pdfname = 's3-userguide'\n",
    "pdf_path = f'{pdfname}.pdf'\n",
    "\n",
    "# Extract and parse\n",
    "text_by_page = extract_text_from_pdf(pdf_path)\n",
    "sections = parse_index(index_text)\n",
    "chunks = create_chunks(text_by_page, sections)\n",
    "\n",
    "# Save chunks to JSON\n",
    "with open(f\"{pdfname}_chunks.json\", \"w\") as f:\n",
    "    json.dump(chunks, f, indent=4)\n",
    "\n",
    "print(\"Chunks created and saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf9f8227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunks created and saved successfully.\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1564e926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The JSON file contains a list with 4437 items.\n",
      "\n",
      "Unique headers found: 0\n",
      "\n",
      "Detailed statistics for each header:\n",
      "\n",
      "Analysis complete.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "from statistics import mean\n",
    "\n",
    "def analyze_json(file_path):\n",
    "    \"\"\"Reads a JSON file and prints out detailed statistics on its structure and key lengths.\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            data = json.load(file)\n",
    "        \n",
    "        if isinstance(data, list):\n",
    "            print(f\"The JSON file contains a list with {len(data)} items.\\n\")\n",
    "            \n",
    "            # Identify unique headers and their types\n",
    "            headers = set()\n",
    "            for item in data:\n",
    "                if isinstance(item, dict):\n",
    "                    headers.update(item.keys())\n",
    "            \n",
    "            print(f\"Unique headers found: {len(headers)}\")\n",
    "            for header in headers:\n",
    "                print(f\"- {header}\")\n",
    "            \n",
    "            # Gather statistics on each header\n",
    "            header_stats = defaultdict(list)\n",
    "            for item in data:\n",
    "                for header in headers:\n",
    "                    if header in item:\n",
    "                        header_stats[header].append(len(str(item[header])))\n",
    "                    else:\n",
    "                        header_stats[header].append(0)\n",
    "            \n",
    "            # Print average length and data type information\n",
    "            print(\"\\nDetailed statistics for each header:\")\n",
    "            for header, lengths in header_stats.items():\n",
    "                avg_length = mean(lengths)\n",
    "                sample_value = next((item[header] for item in data if header in item), None)\n",
    "                value_type = type(sample_value).__name__ if sample_value is not None else \"NoneType\"\n",
    "                print(f\"- {header}:\")\n",
    "                print(f\"  * Average length: {avg_length:.2f}\")\n",
    "                print(f\"  * Sample data type: {value_type}\")\n",
    "                if sample_value:\n",
    "                    print(f\"  * Sample value: {sample_value}\")\n",
    "                print(\"\")\n",
    "\n",
    "        elif isinstance(data, dict):\n",
    "            print(\"The JSON file contains a dictionary with the following keys:\")\n",
    "            for key, value in data.items():\n",
    "                value_type = type(value).__name__\n",
    "                print(f\"- {key}:\")\n",
    "                print(f\"  * Data type: {value_type}\")\n",
    "                if isinstance(value, (list, dict)):\n",
    "                    print(f\"  * Length: {len(value)}\")\n",
    "                print(\"\")\n",
    "\n",
    "        else:\n",
    "            print(\"The JSON file contains a single item of an unrecognized structure.\")\n",
    "\n",
    "        print(\"\\nAnalysis complete.\")\n",
    "\n",
    "    except UnicodeDecodeError as e:\n",
    "        print(\"Failed to read the file due to encoding error:\", e)\n",
    "\n",
    "\n",
    "# Example usage\n",
    "file_path = 'semantic_chunks.json'  # Replace with your file path\n",
    "analyze_json(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78f27c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The JSON file contains a list with 497 items.\n",
      "\n",
      "Unique headers found: 2\n",
      "- title\n",
      "- content\n",
      "\n",
      "Detailed statistics for each header:\n",
      "- title:\n",
      "  * Average length: 134.89\n",
      "  * Sample data type: str\n",
      "  * Sample value: What is Amazon S3? ........................................................................................................................\n",
      "\n",
      "- content:\n",
      "  * Average length: 8693.42\n",
      "  * Sample data type: str\n",
      "\n",
      "\n",
      "Analysis complete.\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "file_path = 'chunks.json'  # Replace with your file path\n",
    "analyze_json(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610b8af5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Metadata Gen and Embedding",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "13692dfb7f31480f8c5c4ec51ec2d423": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "18e91be23ddd4d04ad5c1ca3162836ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dfe4c76bc29143b8aa10b7bc4ea6ccae",
      "placeholder": "​",
      "style": "IPY_MODEL_dd440b5ed6b34ff6aebd33184be8db0c",
      "value": " 133M/133M [00:03&lt;00:00, 42.2MB/s]"
     }
    },
    "19d8e1514f5d4234ba6323894e01ce81": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1a1448c4fc864f6a918809d7b2bb3477": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1bd4a29008514651bb14c5ff9fb9d4f7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "23548a462398487b818fbc5af2f95481": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_729aa5228b894811920f1d6cabcbba66",
      "max": 133462128,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5aba8b2efa93488b8241fa41d7f7bee9",
      "value": 133462128
     }
    },
    "29066facb7c44860ae7f4be2890dda1f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a2f2fd6006b74592b4ee555ad6cb73c3",
       "IPY_MODEL_bec43f2939154741868c5ca0b81cf5d1",
       "IPY_MODEL_34e9959d97854f618eab08c70eca3173"
      ],
      "layout": "IPY_MODEL_ca87511b726a4d4b9b3bcfa022c3d64a"
     }
    },
    "2cc8a99119424076a6d7bbde0f097569": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_42319bb46b42497eabbc1be82155d350",
       "IPY_MODEL_c77751583cc44e34b48df2fc18c71fa9",
       "IPY_MODEL_4af004c9c1cf4a35bd1e5118e749ae85"
      ],
      "layout": "IPY_MODEL_58baf9e67c7c4202bf11324bd3314630"
     }
    },
    "34a0cab8722c415ca054ae6c3873a2ad": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "34e9959d97854f618eab08c70eca3173": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6b1254c3b46244f2a38b702b70221792",
      "placeholder": "​",
      "style": "IPY_MODEL_aa0a6d7df5234ffd8a05c5bb3981ccc6",
      "value": " 232k/232k [00:00&lt;00:00, 2.37MB/s]"
     }
    },
    "42319bb46b42497eabbc1be82155d350": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6a0c04457e3c494fafdb3eb807b4c60c",
      "placeholder": "​",
      "style": "IPY_MODEL_fadc946362f54a59aabf4d92ae856074",
      "value": "config.json: 100%"
     }
    },
    "43d8976b81dc49578d21e5109f3b7789": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "46f7482090154d1588d0cd6d60ddbe48": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_13692dfb7f31480f8c5c4ec51ec2d423",
      "max": 695,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b8785fae33394325801f10a532e915b6",
      "value": 695
     }
    },
    "4a8962c73d0d4da3b19c449b31ec308e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4af004c9c1cf4a35bd1e5118e749ae85": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7bc107fa811b4158979891922d592f4e",
      "placeholder": "​",
      "style": "IPY_MODEL_64c052c5396146bb895b4a37fa34000d",
      "value": " 756/756 [00:00&lt;00:00, 30.0kB/s]"
     }
    },
    "4c1843c47bae4bf49030392b4929747c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4d12a6d743be4f3d91bc54bf052d0118": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "50f07acc22244042a9fce8aabe64897f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "530fd991c391442d956636ddeb87d73d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "58baf9e67c7c4202bf11324bd3314630": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5aba8b2efa93488b8241fa41d7f7bee9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5d02d4bda06f40c884fcec4c71530d08": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_34a0cab8722c415ca054ae6c3873a2ad",
      "placeholder": "​",
      "style": "IPY_MODEL_1a1448c4fc864f6a918809d7b2bb3477",
      "value": " 1.24k/1.24k [00:00&lt;00:00, 72.3kB/s]"
     }
    },
    "64c052c5396146bb895b4a37fa34000d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "65c06940e2614e02b0fb8d8a70124e6e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9c945530c5e542259da5927f4cffb753",
       "IPY_MODEL_c18857af221d42f984d57c93eacaf41c",
       "IPY_MODEL_5d02d4bda06f40c884fcec4c71530d08"
      ],
      "layout": "IPY_MODEL_9ab8bc95ad284cb0af88ea201f9047e8"
     }
    },
    "6641bcba5e7649e6b1122f8539c66244": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6a0c04457e3c494fafdb3eb807b4c60c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6ab3edee5ea5487faf76fdd54eb81f6e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6b1254c3b46244f2a38b702b70221792": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6ceb0b17c239442b8708f8f8f3d505a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6e6f55560c394f43a9e2a07966cb846c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_74e0469ab29d4def95ce2e5f152db8e6",
       "IPY_MODEL_23548a462398487b818fbc5af2f95481",
       "IPY_MODEL_18e91be23ddd4d04ad5c1ca3162836ec"
      ],
      "layout": "IPY_MODEL_96466c1a07164aa6b40e3d1cb3b650f4"
     }
    },
    "729aa5228b894811920f1d6cabcbba66": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "74e0469ab29d4def95ce2e5f152db8e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1bd4a29008514651bb14c5ff9fb9d4f7",
      "placeholder": "​",
      "style": "IPY_MODEL_4c1843c47bae4bf49030392b4929747c",
      "value": "model.safetensors: 100%"
     }
    },
    "7588aef355f449b7b961ae60c1e354dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c3bd92f254374e7bb147c90e6567b4f5",
      "placeholder": "​",
      "style": "IPY_MODEL_6ceb0b17c239442b8708f8f8f3d505a0",
      "value": "tokenizer.json: 100%"
     }
    },
    "7bc107fa811b4158979891922d592f4e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "830708a2ac654b37aeff799029ca6dfa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6641bcba5e7649e6b1122f8539c66244",
      "max": 711396,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9824b41b7d824825876a8cae8fe1085c",
      "value": 711396
     }
    },
    "8724fae499744512b333b5b6b1272d27": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "90af30e55b8a482ca51460e1d0d2d2ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_91d9d223090d4bfa84fa1e0fe7c11176",
       "IPY_MODEL_46f7482090154d1588d0cd6d60ddbe48",
       "IPY_MODEL_c040ecdf50a645a78d55b0b89a05459f"
      ],
      "layout": "IPY_MODEL_f372c2cd040045d38dbe38156b76e6ab"
     }
    },
    "91d9d223090d4bfa84fa1e0fe7c11176": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fc61fc9c32054126a96b12c953a4cd9c",
      "placeholder": "​",
      "style": "IPY_MODEL_4d12a6d743be4f3d91bc54bf052d0118",
      "value": "special_tokens_map.json: 100%"
     }
    },
    "92bff9dec70547dcb2095f2caf8d71e4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "96466c1a07164aa6b40e3d1cb3b650f4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "97344813fbed4c6fb923a86b9aad5991": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9824b41b7d824825876a8cae8fe1085c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "99c9e62f119a49e39a80f2f26dc47437": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d68d9e8cc4e54b22a04c21e6365324c2",
      "placeholder": "​",
      "style": "IPY_MODEL_9f92534be3dc4e9a8d6a312d62890861",
      "value": " 711k/711k [00:00&lt;00:00, 10.2MB/s]"
     }
    },
    "9ab8bc95ad284cb0af88ea201f9047e8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9c2210911ed348b6ad7333fac8ed3b5c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7588aef355f449b7b961ae60c1e354dc",
       "IPY_MODEL_830708a2ac654b37aeff799029ca6dfa",
       "IPY_MODEL_99c9e62f119a49e39a80f2f26dc47437"
      ],
      "layout": "IPY_MODEL_b424d2d4d0b04771bd2e8ecc3dbf3265"
     }
    },
    "9c945530c5e542259da5927f4cffb753": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8724fae499744512b333b5b6b1272d27",
      "placeholder": "​",
      "style": "IPY_MODEL_19d8e1514f5d4234ba6323894e01ce81",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "9f92534be3dc4e9a8d6a312d62890861": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a0c345c72c734207b3ff7e0834e46715": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a2f2fd6006b74592b4ee555ad6cb73c3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_530fd991c391442d956636ddeb87d73d",
      "placeholder": "​",
      "style": "IPY_MODEL_97344813fbed4c6fb923a86b9aad5991",
      "value": "vocab.txt: 100%"
     }
    },
    "aa0a6d7df5234ffd8a05c5bb3981ccc6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b424d2d4d0b04771bd2e8ecc3dbf3265": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b8785fae33394325801f10a532e915b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "bec43f2939154741868c5ca0b81cf5d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_50f07acc22244042a9fce8aabe64897f",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4a8962c73d0d4da3b19c449b31ec308e",
      "value": 231508
     }
    },
    "c040ecdf50a645a78d55b0b89a05459f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_92bff9dec70547dcb2095f2caf8d71e4",
      "placeholder": "​",
      "style": "IPY_MODEL_def95cae2e984b17a92c48c31dcea93b",
      "value": " 695/695 [00:00&lt;00:00, 39.4kB/s]"
     }
    },
    "c18857af221d42f984d57c93eacaf41c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d1354f2ab29141868857566bf886bc21",
      "max": 1242,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_43d8976b81dc49578d21e5109f3b7789",
      "value": 1242
     }
    },
    "c3bd92f254374e7bb147c90e6567b4f5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c77751583cc44e34b48df2fc18c71fa9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6ab3edee5ea5487faf76fdd54eb81f6e",
      "max": 756,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a0c345c72c734207b3ff7e0834e46715",
      "value": 756
     }
    },
    "ca87511b726a4d4b9b3bcfa022c3d64a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d1354f2ab29141868857566bf886bc21": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d68d9e8cc4e54b22a04c21e6365324c2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dd440b5ed6b34ff6aebd33184be8db0c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "def95cae2e984b17a92c48c31dcea93b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dfe4c76bc29143b8aa10b7bc4ea6ccae": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f372c2cd040045d38dbe38156b76e6ab": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fadc946362f54a59aabf4d92ae856074": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fc61fc9c32054126a96b12c953a4cd9c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
